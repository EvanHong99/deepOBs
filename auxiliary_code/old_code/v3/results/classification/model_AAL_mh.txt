##################### deepLOB seq2seq #####################

Prediction horizon: 10  orderbook updates
accuracy_score: 0.8764739421583851
              precision    recall  f1-score   support

           0     0.4879    0.1909    0.2744    109290
           1     0.9010    0.9747    0.9364   1429067
           2     0.5211    0.2832    0.3670    110283

    accuracy                         0.8765   1648640
   macro avg     0.6367    0.4829    0.5259   1648640
weighted avg     0.8482    0.8765    0.8544   1648640

Prediction horizon: 20  orderbook updates
accuracy_score: 0.8232603843167702
              precision    recall  f1-score   support

           0     0.5713    0.3355    0.4228    184284
           1     0.8680    0.9482    0.9063   1283232
           2     0.5677    0.4346    0.4923    181124

    accuracy                         0.8233   1648640
   macro avg     0.6690    0.5728    0.6071   1648640
weighted avg     0.8018    0.8233    0.8068   1648640

Prediction horizon: 30  orderbook updates
accuracy_score: 0.7725707249611802
              precision    recall  f1-score   support

           0     0.5724    0.4230    0.4865    240566
           1     0.8385    0.8998    0.8681   1176293
           2     0.5442    0.4896    0.5154    231781

    accuracy                         0.7726   1648640
   macro avg     0.6517    0.6041    0.6233   1648640
weighted avg     0.7583    0.7726    0.7628   1648640

Prediction horizon: 50  orderbook updates
accuracy_score: 0.691405036878882
              precision    recall  f1-score   support

           0     0.5674    0.4736    0.5163    329016
           1     0.7708    0.8132    0.7914   1007768
           2     0.5294    0.5275    0.5285    311856

    accuracy                         0.6914   1648640
   macro avg     0.6225    0.6048    0.6121   1648640
weighted avg     0.6845    0.6914    0.6868   1648640

Prediction horizon: 100  orderbook updates
accuracy_score: 0.6072016935170808
              precision    recall  f1-score   support

           0     0.5018    0.5268    0.5140    370345
           1     0.7205    0.6628    0.6904    910150
           2     0.4797    0.5505    0.5127    368145

    accuracy                         0.6072   1648640
   macro avg     0.5673    0.5801    0.5724   1648640
weighted avg     0.6176    0.6072    0.6111   1648640

################# deepLOB attention ################

Prediction horizon: 10  orderbook updates
accuracy_score: 0.8594841809006211
              precision    recall  f1-score   support

           0     0.2098    0.0016    0.0033    109290
           1     0.8665    0.9906    0.9244   1429067
           2     0.0839    0.0107    0.0190    110283

    accuracy                         0.8595   1648640
   macro avg     0.3867    0.3343    0.3155   1648640
weighted avg     0.7706    0.8595    0.8028   1648640

Prediction horizon: 20  orderbook updates
accuracy_score: 0.7582558957686335
              precision    recall  f1-score   support

           0     0.3166    0.0055    0.0108    184284
           1     0.7770    0.9678    0.8620   1283232
           2     0.1516    0.0394    0.0626    181124

    accuracy                         0.7583   1648640
   macro avg     0.4151    0.3376    0.3118   1648640
weighted avg     0.6568    0.7583    0.6790   1648640

Prediction horizon: 30  orderbook updates
accuracy_score: 0.6546383685947205
              precision    recall  f1-score   support

           0     0.3720    0.0315    0.0581    240566
           1     0.7122    0.8798    0.7872   1176293
           2     0.2099    0.1588    0.1808    231781

    accuracy                         0.6546   1648640
   macro avg     0.4314    0.3567    0.3420   1648640
weighted avg     0.5920    0.6546    0.5956   1648640

Prediction horizon: 50  orderbook updates
accuracy_score: 0.48227144798136645
              precision    recall  f1-score   support

           0     0.3581    0.2005    0.2570    329016
           1     0.6580    0.5568    0.6032   1007768
           2     0.2747    0.5389    0.3639    311856

    accuracy                         0.4823   1648640
   macro avg     0.4303    0.4320    0.4080   1648640
weighted avg     0.5257    0.4823    0.4888   1648640

Prediction horizon: 100  orderbook updates
accuracy_score: 0.4369340789984472
              precision    recall  f1-score   support

           0     0.3496    0.2219    0.2714    370345
           1     0.6072    0.4661    0.5274    910150
           2     0.2993    0.5812    0.3951    368145

    accuracy                         0.4369   1648640
   macro avg     0.4187    0.4231    0.3980   1648640
weighted avg     0.4806    0.4369    0.4403   1648640


##################### deepOF seq2seq #####################
Epoch 1/50
28082/28082 - 2138s - loss: 0.9086 - accuracy10: 0.5755 - accuracy20: 0.5755 - accuracy30: 0.5755 - accuracy50: 0.5755 - accuracy100: 0.5755 - val_loss: 0.8983 - val_accuracy10: 0.5760 - val_accuracy20: 0.5760 - val_accuracy30: 0.5760 - val_accuracy50: 0.5760 - val_accuracy100: 0.5760 - 2138s/epoch - 76ms/step
Epoch 2/50
28082/28082 - 1746s - loss: 0.8022 - accuracy10: 0.6341 - accuracy20: 0.6341 - accuracy30: 0.6341 - accuracy50: 0.6341 - accuracy100: 0.6341 - val_loss: 0.8534 - val_accuracy10: 0.5979 - val_accuracy20: 0.5979 - val_accuracy30: 0.5979 - val_accuracy50: 0.5979 - val_accuracy100: 0.5979 - 1746s/epoch - 62ms/step
Epoch 3/50
28082/28082 - 1770s - loss: 0.7842 - accuracy10: 0.6429 - accuracy20: 0.6429 - accuracy30: 0.6429 - accuracy50: 0.6429 - accuracy100: 0.6429 - val_loss: 0.8442 - val_accuracy10: 0.6022 - val_accuracy20: 0.6022 - val_accuracy30: 0.6022 - val_accuracy50: 0.6022 - val_accuracy100: 0.6022 - 1770s/epoch - 63ms/step
Epoch 4/50
28082/28082 - 2146s - loss: 0.7757 - accuracy10: 0.6462 - accuracy20: 0.6462 - accuracy30: 0.6462 - accuracy50: 0.6462 - accuracy100: 0.6462 - val_loss: 0.8458 - val_accuracy10: 0.6000 - val_accuracy20: 0.6000 - val_accuracy30: 0.6000 - val_accuracy50: 0.6000 - val_accuracy100: 0.6000 - 2146s/epoch - 76ms/step
Epoch 5/50
28082/28082 - 2249s - loss: 0.7704 - accuracy10: 0.6482 - accuracy20: 0.6482 - accuracy30: 0.6482 - accuracy50: 0.6482 - accuracy100: 0.6482 - val_loss: 0.8510 - val_accuracy10: 0.6010 - val_accuracy20: 0.6010 - val_accuracy30: 0.6010 - val_accuracy50: 0.6010 - val_accuracy100: 0.6010 - 2249s/epoch - 80ms/step
Epoch 6/50
28082/28082 - 1942s - loss: 0.7666 - accuracy10: 0.6499 - accuracy20: 0.6499 - accuracy30: 0.6499 - accuracy50: 0.6499 - accuracy100: 0.6499 - val_loss: 0.8371 - val_accuracy10: 0.6076 - val_accuracy20: 0.6076 - val_accuracy30: 0.6076 - val_accuracy50: 0.6076 - val_accuracy100: 0.6076 - 1942s/epoch - 69ms/step
Epoch 7/50
28082/28082 - 2047s - loss: 0.7635 - accuracy10: 0.6513 - accuracy20: 0.6513 - accuracy30: 0.6513 - accuracy50: 0.6513 - accuracy100: 0.6513 - val_loss: 0.8365 - val_accuracy10: 0.6072 - val_accuracy20: 0.6072 - val_accuracy30: 0.6072 - val_accuracy50: 0.6072 - val_accuracy100: 0.6072 - 2047s/epoch - 73ms/step
Epoch 8/50
28082/28082 - 1922s - loss: 0.7609 - accuracy10: 0.6523 - accuracy20: 0.6523 - accuracy30: 0.6523 - accuracy50: 0.6523 - accuracy100: 0.6523 - val_loss: 0.8345 - val_accuracy10: 0.6077 - val_accuracy20: 0.6077 - val_accuracy30: 0.6077 - val_accuracy50: 0.6077 - val_accuracy100: 0.6077 - 1922s/epoch - 68ms/step
Epoch 9/50
28082/28082 - 1800s - loss: 0.7591 - accuracy10: 0.6531 - accuracy20: 0.6531 - accuracy30: 0.6531 - accuracy50: 0.6531 - accuracy100: 0.6531 - val_loss: 0.8280 - val_accuracy10: 0.6118 - val_accuracy20: 0.6118 - val_accuracy30: 0.6118 - val_accuracy50: 0.6118 - val_accuracy100: 0.6118 - 1800s/epoch - 64ms/step
Epoch 10/50
28082/28082 - 1851s - loss: 0.7569 - accuracy10: 0.6543 - accuracy20: 0.6543 - accuracy30: 0.6543 - accuracy50: 0.6543 - accuracy100: 0.6543 - val_loss: 0.8422 - val_accuracy10: 0.6039 - val_accuracy20: 0.6039 - val_accuracy30: 0.6039 - val_accuracy50: 0.6039 - val_accuracy100: 0.6039 - 1851s/epoch - 66ms/step
Epoch 11/50
28082/28082 - 1834s - loss: 0.7554 - accuracy10: 0.6550 - accuracy20: 0.6550 - accuracy30: 0.6550 - accuracy50: 0.6550 - accuracy100: 0.6550 - val_loss: 0.8355 - val_accuracy10: 0.6098 - val_accuracy20: 0.6098 - val_accuracy30: 0.6098 - val_accuracy50: 0.6098 - val_accuracy100: 0.6098 - 1834s/epoch - 65ms/step
Epoch 12/50
28082/28082 - 1853s - loss: 0.7539 - accuracy10: 0.6558 - accuracy20: 0.6558 - accuracy30: 0.6558 - accuracy50: 0.6558 - accuracy100: 0.6558 - val_loss: 0.8269 - val_accuracy10: 0.6117 - val_accuracy20: 0.6117 - val_accuracy30: 0.6117 - val_accuracy50: 0.6117 - val_accuracy100: 0.6117 - 1853s/epoch - 66ms/step
Epoch 13/50
28082/28082 - 1789s - loss: 0.7525 - accuracy10: 0.6561 - accuracy20: 0.6561 - accuracy30: 0.6561 - accuracy50: 0.6561 - accuracy100: 0.6561 - val_loss: 0.8286 - val_accuracy10: 0.6108 - val_accuracy20: 0.6108 - val_accuracy30: 0.6108 - val_accuracy50: 0.6108 - val_accuracy100: 0.6108 - 1789s/epoch - 64ms/step
Epoch 14/50
28082/28082 - 1649s - loss: 0.7514 - accuracy10: 0.6571 - accuracy20: 0.6571 - accuracy30: 0.6571 - accuracy50: 0.6571 - accuracy100: 0.6571 - val_loss: 0.8303 - val_accuracy10: 0.6103 - val_accuracy20: 0.6103 - val_accuracy30: 0.6103 - val_accuracy50: 0.6103 - val_accuracy100: 0.6103 - 1649s/epoch - 59ms/step
Epoch 15/50
28082/28082 - 1741s - loss: 0.7501 - accuracy10: 0.6576 - accuracy20: 0.6576 - accuracy30: 0.6576 - accuracy50: 0.6576 - accuracy100: 0.6576 - val_loss: 0.8297 - val_accuracy10: 0.6117 - val_accuracy20: 0.6117 - val_accuracy30: 0.6117 - val_accuracy50: 0.6117 - val_accuracy100: 0.6117 - 1741s/epoch - 62ms/step
Epoch 16/50
28082/28082 - 1727s - loss: 0.7491 - accuracy10: 0.6581 - accuracy20: 0.6581 - accuracy30: 0.6581 - accuracy50: 0.6581 - accuracy100: 0.6581 - val_loss: 0.8232 - val_accuracy10: 0.6147 - val_accuracy20: 0.6147 - val_accuracy30: 0.6147 - val_accuracy50: 0.6147 - val_accuracy100: 0.6147 - 1727s/epoch - 61ms/step
Epoch 17/50
28082/28082 - 1681s - loss: 0.7481 - accuracy10: 0.6584 - accuracy20: 0.6584 - accuracy30: 0.6584 - accuracy50: 0.6584 - accuracy100: 0.6584 - val_loss: 0.8242 - val_accuracy10: 0.6138 - val_accuracy20: 0.6138 - val_accuracy30: 0.6138 - val_accuracy50: 0.6138 - val_accuracy100: 0.6138 - 1681s/epoch - 60ms/step
Epoch 18/50
28082/28082 - 1677s - loss: 0.7469 - accuracy10: 0.6592 - accuracy20: 0.6592 - accuracy30: 0.6592 - accuracy50: 0.6592 - accuracy100: 0.6592 - val_loss: 0.8300 - val_accuracy10: 0.6108 - val_accuracy20: 0.6108 - val_accuracy30: 0.6108 - val_accuracy50: 0.6108 - val_accuracy100: 0.6108 - 1677s/epoch - 60ms/step
Epoch 19/50
28082/28082 - 1689s - loss: 0.7461 - accuracy10: 0.6597 - accuracy20: 0.6597 - accuracy30: 0.6597 - accuracy50: 0.6597 - accuracy100: 0.6597 - val_loss: 0.8330 - val_accuracy10: 0.6100 - val_accuracy20: 0.6100 - val_accuracy30: 0.6100 - val_accuracy50: 0.6100 - val_accuracy100: 0.6100 - 1689s/epoch - 60ms/step
Epoch 20/50
28082/28082 - 1683s - loss: 0.7455 - accuracy10: 0.6600 - accuracy20: 0.6600 - accuracy30: 0.6600 - accuracy50: 0.6600 - accuracy100: 0.6600 - val_loss: 0.8310 - val_accuracy10: 0.6082 - val_accuracy20: 0.6082 - val_accuracy30: 0.6082 - val_accuracy50: 0.6082 - val_accuracy100: 0.6082 - 1683s/epoch - 60ms/step
Epoch 21/50
28082/28082 - 1689s - loss: 0.7446 - accuracy10: 0.6603 - accuracy20: 0.6603 - accuracy30: 0.6603 - accuracy50: 0.6603 - accuracy100: 0.6603 - val_loss: 0.8236 - val_accuracy10: 0.6147 - val_accuracy20: 0.6147 - val_accuracy30: 0.6147 - val_accuracy50: 0.6147 - val_accuracy100: 0.6147 - 1689s/epoch - 60ms/step
Epoch 22/50
28082/28082 - 2306s - loss: 0.7438 - accuracy10: 0.6608 - accuracy20: 0.6608 - accuracy30: 0.6608 - accuracy50: 0.6608 - accuracy100: 0.6608 - val_loss: 0.8247 - val_accuracy10: 0.6153 - val_accuracy20: 0.6153 - val_accuracy30: 0.6153 - val_accuracy50: 0.6153 - val_accuracy100: 0.6153 - 2306s/epoch - 82ms/step
Epoch 23/50
28082/28082 - 1660s - loss: 0.7429 - accuracy10: 0.6613 - accuracy20: 0.6613 - accuracy30: 0.6613 - accuracy50: 0.6613 - accuracy100: 0.6613 - val_loss: 0.8276 - val_accuracy10: 0.6118 - val_accuracy20: 0.6118 - val_accuracy30: 0.6118 - val_accuracy50: 0.6118 - val_accuracy100: 0.6118 - 1660s/epoch - 59ms/step
Epoch 24/50
28082/28082 - 1684s - loss: 0.7423 - accuracy10: 0.6617 - accuracy20: 0.6617 - accuracy30: 0.6617 - accuracy50: 0.6617 - accuracy100: 0.6617 - val_loss: 0.8241 - val_accuracy10: 0.6149 - val_accuracy20: 0.6149 - val_accuracy30: 0.6149 - val_accuracy50: 0.6149 - val_accuracy100: 0.6149 - 1684s/epoch - 60ms/step
Epoch 25/50
28082/28082 - 1691s - loss: 0.7415 - accuracy10: 0.6621 - accuracy20: 0.6621 - accuracy30: 0.6621 - accuracy50: 0.6621 - accuracy100: 0.6621 - val_loss: 0.8287 - val_accuracy10: 0.6126 - val_accuracy20: 0.6126 - val_accuracy30: 0.6126 - val_accuracy50: 0.6126 - val_accuracy100: 0.6126 - 1691s/epoch - 60ms/step
Epoch 26/50
28082/28082 - 1629s - loss: 0.7406 - accuracy10: 0.6624 - accuracy20: 0.6624 - accuracy30: 0.6624 - accuracy50: 0.6624 - accuracy100: 0.6624 - val_loss: 0.8225 - val_accuracy10: 0.6153 - val_accuracy20: 0.6153 - val_accuracy30: 0.6153 - val_accuracy50: 0.6153 - val_accuracy100: 0.6153 - 1629s/epoch - 58ms/step
Epoch 27/50
28082/28082 - 1631s - loss: 0.7401 - accuracy10: 0.6629 - accuracy20: 0.6629 - accuracy30: 0.6629 - accuracy50: 0.6629 - accuracy100: 0.6629 - val_loss: 0.8231 - val_accuracy10: 0.6161 - val_accuracy20: 0.6161 - val_accuracy30: 0.6161 - val_accuracy50: 0.6161 - val_accuracy100: 0.6161 - 1631s/epoch - 58ms/step
Epoch 28/50
28082/28082 - 1670s - loss: 0.7393 - accuracy10: 0.6633 - accuracy20: 0.6633 - accuracy30: 0.6633 - accuracy50: 0.6633 - accuracy100: 0.6633 - val_loss: 0.8234 - val_accuracy10: 0.6159 - val_accuracy20: 0.6159 - val_accuracy30: 0.6159 - val_accuracy50: 0.6159 - val_accuracy100: 0.6159 - 1670s/epoch - 59ms/step
Epoch 29/50
28082/28082 - 1659s - loss: 0.7388 - accuracy10: 0.6634 - accuracy20: 0.6634 - accuracy30: 0.6634 - accuracy50: 0.6634 - accuracy100: 0.6634 - val_loss: 0.8253 - val_accuracy10: 0.6134 - val_accuracy20: 0.6134 - val_accuracy30: 0.6134 - val_accuracy50: 0.6134 - val_accuracy100: 0.6134 - 1659s/epoch - 59ms/step
Epoch 30/50
28082/28082 - 1662s - loss: 0.7381 - accuracy10: 0.6638 - accuracy20: 0.6638 - accuracy30: 0.6638 - accuracy50: 0.6638 - accuracy100: 0.6638 - val_loss: 0.8275 - val_accuracy10: 0.6137 - val_accuracy20: 0.6137 - val_accuracy30: 0.6137 - val_accuracy50: 0.6137 - val_accuracy100: 0.6137 - 1662s/epoch - 59ms/step
Epoch 31/50
28082/28082 - 1673s - loss: 0.7374 - accuracy10: 0.6642 - accuracy20: 0.6642 - accuracy30: 0.6642 - accuracy50: 0.6642 - accuracy100: 0.6642 - val_loss: 0.8259 - val_accuracy10: 0.6143 - val_accuracy20: 0.6143 - val_accuracy30: 0.6143 - val_accuracy50: 0.6143 - val_accuracy100: 0.6143 - 1673s/epoch - 60ms/step
Epoch 32/50
28082/28082 - 1664s - loss: 0.7369 - accuracy10: 0.6645 - accuracy20: 0.6645 - accuracy30: 0.6645 - accuracy50: 0.6645 - accuracy100: 0.6645 - val_loss: 0.8264 - val_accuracy10: 0.6137 - val_accuracy20: 0.6137 - val_accuracy30: 0.6137 - val_accuracy50: 0.6137 - val_accuracy100: 0.6137 - 1664s/epoch - 59ms/step
Epoch 33/50
28082/28082 - 1670s - loss: 0.7363 - accuracy10: 0.6648 - accuracy20: 0.6648 - accuracy30: 0.6648 - accuracy50: 0.6648 - accuracy100: 0.6648 - val_loss: 0.8233 - val_accuracy10: 0.6162 - val_accuracy20: 0.6162 - val_accuracy30: 0.6162 - val_accuracy50: 0.6162 - val_accuracy100: 0.6162 - 1670s/epoch - 59ms/step
Epoch 34/50
28082/28082 - 1671s - loss: 0.7357 - accuracy10: 0.6652 - accuracy20: 0.6652 - accuracy30: 0.6652 - accuracy50: 0.6652 - accuracy100: 0.6652 - val_loss: 0.8256 - val_accuracy10: 0.6139 - val_accuracy20: 0.6139 - val_accuracy30: 0.6139 - val_accuracy50: 0.6139 - val_accuracy100: 0.6139 - 1671s/epoch - 59ms/step
Epoch 35/50
28082/28082 - 1644s - loss: 0.7352 - accuracy10: 0.6654 - accuracy20: 0.6654 - accuracy30: 0.6654 - accuracy50: 0.6654 - accuracy100: 0.6654 - val_loss: 0.8243 - val_accuracy10: 0.6150 - val_accuracy20: 0.6150 - val_accuracy30: 0.6150 - val_accuracy50: 0.6150 - val_accuracy100: 0.6150 - 1644s/epoch - 59ms/step
Epoch 36/50
28082/28082 - 1572s - loss: 0.7344 - accuracy10: 0.6656 - accuracy20: 0.6656 - accuracy30: 0.6656 - accuracy50: 0.6656 - accuracy100: 0.6656 - val_loss: 0.8233 - val_accuracy10: 0.6166 - val_accuracy20: 0.6166 - val_accuracy30: 0.6166 - val_accuracy50: 0.6166 - val_accuracy100: 0.6166 - 1572s/epoch - 56ms/step
Prediction horizon: 10  orderbook updates
accuracy_score: 0.8779612286490683
              precision    recall  f1-score   support

           0     0.4900    0.2128    0.2967    109291
           1     0.8983    0.9796    0.9372   1429062
           2     0.5665    0.2199    0.3168    110287

    accuracy                         0.8780   1648640
   macro avg     0.6516    0.4708    0.5169   1648640
weighted avg     0.8491    0.8780    0.8533   1648640

Prediction horizon: 20  orderbook updates
accuracy_score: 0.8209305852096274
              precision    recall  f1-score   support

           0     0.5247    0.3979    0.4526    184282
           1     0.8671    0.9461    0.9049   1283231
           2     0.6072    0.3646    0.4556    181127

    accuracy                         0.8209   1648640
   macro avg     0.6663    0.5695    0.6044   1648640
weighted avg     0.8003    0.8209    0.8050   1648640

Prediction horizon: 30  orderbook updates
accuracy_score: 0.7683957686335404
              precision    recall  f1-score   support

           0     0.5217    0.4719    0.4956    240566
           1     0.8309    0.9028    0.8653   1176293
           2     0.5974    0.3942    0.4750    231781

    accuracy                         0.7684   1648640
   macro avg     0.6500    0.5896    0.6120   1648640
weighted avg     0.7529    0.7684    0.7565   1648640

Prediction horizon: 50  orderbook updates
accuracy_score: 0.6846788868400621
              precision    recall  f1-score   support

           0     0.5199    0.5136    0.5167    329016
           1     0.7587    0.8189    0.7877   1007761
           2     0.5702    0.4315    0.4912    311863

    accuracy                         0.6847   1648640
   macro avg     0.6163    0.5880    0.5985   1648640
weighted avg     0.6754    0.6847    0.6775   1648640

Prediction horizon: 100  orderbook updates
accuracy_score: 0.6060971467391304
              precision    recall  f1-score   support

           0     0.4772    0.5457    0.5092    370342
           1     0.6951    0.6954    0.6953    910149
           2     0.5220    0.4461    0.4810    368149

    accuracy                         0.6061   1648640
   macro avg     0.5648    0.5624    0.5618   1648640
weighted avg     0.6075    0.6061    0.6056   1648640

##################### deepOF attention #####################
Epoch 1/50
28082/28082 - 1899s - loss: 0.7387 - accuracy10: 0.6744 - accuracy20: 0.6744 - accuracy30: 0.6744 - accuracy50: 0.6744 - accuracy100: 0.6744 - val_loss: 1.4908 - val_accuracy10: 0.5137 - val_accuracy20: 0.5137 - val_accuracy30: 0.5137 - val_accuracy50: 0.5137 - val_accuracy100: 0.5137 - 1899s/epoch - 68ms/step
Epoch 2/50
28082/28082 - 1816s - loss: 0.5895 - accuracy10: 0.7506 - accuracy20: 0.7506 - accuracy30: 0.7506 - accuracy50: 0.7506 - accuracy100: 0.7506 - val_loss: 1.5109 - val_accuracy10: 0.4317 - val_accuracy20: 0.4317 - val_accuracy30: 0.4317 - val_accuracy50: 0.4317 - val_accuracy100: 0.4317 - 1816s/epoch - 65ms/step
Epoch 3/50
28082/28082 - 1817s - loss: 0.5463 - accuracy10: 0.7710 - accuracy20: 0.7710 - accuracy30: 0.7710 - accuracy50: 0.7710 - accuracy100: 0.7710 - val_loss: 1.5882 - val_accuracy10: 0.4910 - val_accuracy20: 0.4910 - val_accuracy30: 0.4910 - val_accuracy50: 0.4910 - val_accuracy100: 0.4910 - 1817s/epoch - 65ms/step
Epoch 4/50
28082/28082 - 1839s - loss: 0.5206 - accuracy10: 0.7829 - accuracy20: 0.7829 - accuracy30: 0.7829 - accuracy50: 0.7829 - accuracy100: 0.7829 - val_loss: 1.3712 - val_accuracy10: 0.5042 - val_accuracy20: 0.5042 - val_accuracy30: 0.5042 - val_accuracy50: 0.5042 - val_accuracy100: 0.5042 - 1839s/epoch - 65ms/step
Epoch 5/50
28082/28082 - 1853s - loss: 0.5043 - accuracy10: 0.7903 - accuracy20: 0.7903 - accuracy30: 0.7903 - accuracy50: 0.7903 - accuracy100: 0.7903 - val_loss: 1.7516 - val_accuracy10: 0.4248 - val_accuracy20: 0.4248 - val_accuracy30: 0.4248 - val_accuracy50: 0.4248 - val_accuracy100: 0.4248 - 1853s/epoch - 66ms/step
Epoch 6/50
28082/28082 - 1845s - loss: 0.4919 - accuracy10: 0.7962 - accuracy20: 0.7962 - accuracy30: 0.7962 - accuracy50: 0.7962 - accuracy100: 0.7962 - val_loss: 1.4189 - val_accuracy10: 0.4446 - val_accuracy20: 0.4446 - val_accuracy30: 0.4446 - val_accuracy50: 0.4446 - val_accuracy100: 0.4446 - 1845s/epoch - 66ms/step
Epoch 7/50
28082/28082 - 1837s - loss: 0.4760 - accuracy10: 0.8035 - accuracy20: 0.8035 - accuracy30: 0.8035 - accuracy50: 0.8035 - accuracy100: 0.8035 - val_loss: 1.9060 - val_accuracy10: 0.4697 - val_accuracy20: 0.4697 - val_accuracy30: 0.4697 - val_accuracy50: 0.4697 - val_accuracy100: 0.4697 - 1837s/epoch - 65ms/step
Epoch 8/50
28082/28082 - 1830s - loss: 0.4660 - accuracy10: 0.8080 - accuracy20: 0.8080 - accuracy30: 0.8080 - accuracy50: 0.8080 - accuracy100: 0.8080 - val_loss: 2.2674 - val_accuracy10: 0.4554 - val_accuracy20: 0.4554 - val_accuracy30: 0.4554 - val_accuracy50: 0.4554 - val_accuracy100: 0.4554 - 1830s/epoch - 65ms/step
Epoch 9/50
28082/28082 - 1841s - loss: 0.4575 - accuracy10: 0.8121 - accuracy20: 0.8121 - accuracy30: 0.8121 - accuracy50: 0.8121 - accuracy100: 0.8121 - val_loss: 2.3002 - val_accuracy10: 0.4790 - val_accuracy20: 0.4790 - val_accuracy30: 0.4790 - val_accuracy50: 0.4790 - val_accuracy100: 0.4790 - 1841s/epoch - 66ms/step
Epoch 10/50
28082/28082 - 1836s - loss: 0.4535 - accuracy10: 0.8138 - accuracy20: 0.8138 - accuracy30: 0.8138 - accuracy50: 0.8138 - accuracy100: 0.8138 - val_loss: 1.6997 - val_accuracy10: 0.4625 - val_accuracy20: 0.4625 - val_accuracy30: 0.4625 - val_accuracy50: 0.4625 - val_accuracy100: 0.4625 - 1836s/epoch - 65ms/step
Epoch 11/50
28082/28082 - 1843s - loss: 0.4438 - accuracy10: 0.8184 - accuracy20: 0.8184 - accuracy30: 0.8184 - accuracy50: 0.8184 - accuracy100: 0.8184 - val_loss: 1.8391 - val_accuracy10: 0.4340 - val_accuracy20: 0.4340 - val_accuracy30: 0.4340 - val_accuracy50: 0.4340 - val_accuracy100: 0.4340 - 1843s/epoch - 66ms/step
Epoch 12/50
28082/28082 - 1845s - loss: 0.4374 - accuracy10: 0.8212 - accuracy20: 0.8212 - accuracy30: 0.8212 - accuracy50: 0.8212 - accuracy100: 0.8212 - val_loss: 1.8246 - val_accuracy10: 0.4018 - val_accuracy20: 0.4018 - val_accuracy30: 0.4018 - val_accuracy50: 0.4018 - val_accuracy100: 0.4018 - 1845s/epoch - 66ms/step
Epoch 13/50
28082/28082 - 1858s - loss: 0.4318 - accuracy10: 0.8239 - accuracy20: 0.8239 - accuracy30: 0.8239 - accuracy50: 0.8239 - accuracy100: 0.8239 - val_loss: 1.9851 - val_accuracy10: 0.4246 - val_accuracy20: 0.4246 - val_accuracy30: 0.4246 - val_accuracy50: 0.4246 - val_accuracy100: 0.4246 - 1858s/epoch - 66ms/step
Epoch 14/50
28082/28082 - 1853s - loss: 0.4270 - accuracy10: 0.8262 - accuracy20: 0.8262 - accuracy30: 0.8262 - accuracy50: 0.8262 - accuracy100: 0.8262 - val_loss: 2.0850 - val_accuracy10: 0.4275 - val_accuracy20: 0.4275 - val_accuracy30: 0.4275 - val_accuracy50: 0.4275 - val_accuracy100: 0.4275 - 1853s/epoch - 66ms/step
Prediction horizon: 10  orderbook updates
accuracy_score: 0.8265285326086956
              precision    recall  f1-score   support

           0     0.2185    0.2356    0.2267    109291
           1     0.8887    0.9237    0.9059   1429062
           2     0.3717    0.1534    0.2172    110287

    accuracy                         0.8265   1648640
   macro avg     0.4930    0.4376    0.4499   1648640
weighted avg     0.8097    0.8265    0.8148   1648640

Prediction horizon: 20  orderbook updates
accuracy_score: 0.702631259704969
              precision    recall  f1-score   support

           0     0.2804    0.4210    0.3366    184282
           1     0.8413    0.7990    0.8196   1283231
           2     0.3622    0.3063    0.3319    181127

    accuracy                         0.7026   1648640
   macro avg     0.4946    0.5088    0.4960   1648640
weighted avg     0.7260    0.7026    0.7120   1648640

Prediction horizon: 30  orderbook updates
accuracy_score: 0.5657275087344721
              precision    recall  f1-score   support

           0     0.2817    0.4762    0.3540    240566
           1     0.7770    0.6163    0.6874   1176293
           2     0.3016    0.4019    0.3446    231781

    accuracy                         0.5657   1648640
   macro avg     0.4534    0.4982    0.4620   1648640
weighted avg     0.6379    0.5657    0.5905   1648640

Prediction horizon: 50  orderbook updates
accuracy_score: 0.36887252523291925
              precision    recall  f1-score   support

           0     0.2982    0.5732    0.3923    329016
           1     0.6004    0.2665    0.3691   1007761
           2     0.2654    0.4842    0.3429    311863

    accuracy                         0.3689   1648640
   macro avg     0.3880    0.4413    0.3681   1648640
weighted avg     0.4767    0.3689    0.3688   1648640

Prediction horizon: 100  orderbook updates
accuracy_score: 0.35898740780279503
              precision    recall  f1-score   support

           0     0.3289    0.5719    0.4176    370342
           1     0.5179    0.2238    0.3126    910149
           2     0.2884    0.4790    0.3600    368149

    accuracy                         0.3590   1648640
   macro avg     0.3784    0.4249    0.3634   1648640
weighted avg     0.4242    0.3590    0.3468   1648640

