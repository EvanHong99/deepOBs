This machine has 1 visible gpus.
This machine has 1 physical gpus.
getting alphas...
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-10-09.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-10-01.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-09-18.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-09-19.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-09-27.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-09-23.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-09-25.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-09-20.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-10-11.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-09-24.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-10-07.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-09-26.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-09-17.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-10-03.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-10-02.csv
training model: results/QRTEA/W7/deepLOB_L1/h10
Epoch 1/50
538/538 - 22s - loss: 3.0340 - accuracy10: 0.3708 - val_loss: 3.7729 - val_accuracy10: 0.6002 - 22s/epoch - 41ms/step
Epoch 2/50
538/538 - 14s - loss: 2.9173 - accuracy10: 0.4063 - val_loss: 3.4173 - val_accuracy10: 0.4105 - 14s/epoch - 25ms/step
Epoch 3/50
538/538 - 13s - loss: 2.8410 - accuracy10: 0.4382 - val_loss: 3.2059 - val_accuracy10: 0.4572 - 13s/epoch - 25ms/step
Epoch 4/50
538/538 - 14s - loss: 2.7636 - accuracy10: 0.4849 - val_loss: 3.0575 - val_accuracy10: 0.3890 - 14s/epoch - 26ms/step
Epoch 5/50
538/538 - 14s - loss: 2.7021 - accuracy10: 0.5174 - val_loss: 3.0215 - val_accuracy10: 0.4343 - 14s/epoch - 26ms/step
Epoch 6/50
538/538 - 13s - loss: 2.6396 - accuracy10: 0.5359 - val_loss: 3.0230 - val_accuracy10: 0.5511 - 13s/epoch - 25ms/step
Epoch 7/50
538/538 - 14s - loss: 2.6031 - accuracy10: 0.5476 - val_loss: 3.4149 - val_accuracy10: 0.7015 - 14s/epoch - 26ms/step
Epoch 8/50
538/538 - 14s - loss: 2.5589 - accuracy10: 0.5655 - val_loss: 3.1926 - val_accuracy10: 0.5118 - 14s/epoch - 26ms/step
Epoch 9/50
538/538 - 14s - loss: 2.5148 - accuracy10: 0.5843 - val_loss: 2.9836 - val_accuracy10: 0.6688 - 14s/epoch - 25ms/step
Epoch 10/50
538/538 - 13s - loss: 2.4706 - accuracy10: 0.6014 - val_loss: 3.1879 - val_accuracy10: 0.7016 - 13s/epoch - 24ms/step
Epoch 11/50
538/538 - 14s - loss: 2.4313 - accuracy10: 0.6110 - val_loss: 3.0905 - val_accuracy10: 0.7126 - 14s/epoch - 25ms/step
Epoch 12/50
538/538 - 14s - loss: 2.4139 - accuracy10: 0.6190 - val_loss: 3.5097 - val_accuracy10: 0.7509 - 14s/epoch - 26ms/step
Epoch 13/50
538/538 - 14s - loss: 2.3823 - accuracy10: 0.6265 - val_loss: 3.1240 - val_accuracy10: 0.6029 - 14s/epoch - 26ms/step
Epoch 14/50
538/538 - 14s - loss: 2.3497 - accuracy10: 0.6337 - val_loss: 3.1427 - val_accuracy10: 0.7141 - 14s/epoch - 25ms/step
Epoch 15/50
538/538 - 14s - loss: 2.3286 - accuracy10: 0.6398 - val_loss: 2.9484 - val_accuracy10: 0.6368 - 14s/epoch - 26ms/step
Epoch 16/50
538/538 - 14s - loss: 2.3122 - accuracy10: 0.6417 - val_loss: 3.2613 - val_accuracy10: 0.6661 - 14s/epoch - 26ms/step
Epoch 17/50
538/538 - 14s - loss: 2.2871 - accuracy10: 0.6477 - val_loss: 2.9747 - val_accuracy10: 0.6665 - 14s/epoch - 26ms/step
Epoch 18/50
538/538 - 14s - loss: 2.2720 - accuracy10: 0.6492 - val_loss: 3.1727 - val_accuracy10: 0.6356 - 14s/epoch - 26ms/step
Epoch 19/50
538/538 - 13s - loss: 2.2555 - accuracy10: 0.6529 - val_loss: 3.3829 - val_accuracy10: 0.5709 - 13s/epoch - 25ms/step
Epoch 20/50
538/538 - 14s - loss: 2.2382 - accuracy10: 0.6538 - val_loss: 3.5302 - val_accuracy10: 0.6793 - 14s/epoch - 26ms/step
Epoch 21/50
538/538 - 14s - loss: 2.2324 - accuracy10: 0.6543 - val_loss: 3.2722 - val_accuracy10: 0.5929 - 14s/epoch - 25ms/step
Epoch 22/50
538/538 - 14s - loss: 2.2196 - accuracy10: 0.6545 - val_loss: 3.2638 - val_accuracy10: 0.5116 - 14s/epoch - 25ms/step
Epoch 23/50
538/538 - 14s - loss: 2.2087 - accuracy10: 0.6571 - val_loss: 3.5284 - val_accuracy10: 0.5639 - 14s/epoch - 25ms/step
Epoch 24/50
538/538 - 14s - loss: 2.1989 - accuracy10: 0.6591 - val_loss: 3.3135 - val_accuracy10: 0.4754 - 14s/epoch - 25ms/step
Epoch 25/50
538/538 - 14s - loss: 2.1855 - accuracy10: 0.6630 - val_loss: 3.2390 - val_accuracy10: 0.5764 - 14s/epoch - 26ms/step
testing model: results/QRTEA/W7/deepLOB_L1/h10
Evaluating performance on  test set...
2006/2006 - 32s - 32s/epoch - 16ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.8651802
{'0': {'precision': 0.24226432505695417, 'recall': 0.5215960595210993, 'f1-score': 0.33085658024286185, 'support': 48319}, '1': {'precision': 0.8993425565016645, 'recall': 0.6446584245680093, 'f1-score': 0.7509953202486555, 'support': 416965}, '2': {'precision': 0.24947923270599742, 'recall': 0.573325563002123, 'f1-score': 0.3476713366149186, 'support': 48046}, 'accuracy': 0.6263982233650868, 'macro avg': {'precision': 0.46369537142153866, 'recall': 0.5798600156970772, 'f1-score': 0.4765077457021453, 'support': 513330}, 'weighted avg': {'precision': 0.7766676761707594, 'recall': 0.6263982233650868, 'f1-score': 0.6736984782639546, 'support': 513330}}
[[ 25203  16203   6913]
 [ 72210 268800  75955]
 [  6618  13882  27546]]
Evaluating performance on  train set...
538/538 - 9s - 9s/epoch - 16ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.8521287
{'0': {'precision': 0.29290916059793026, 'recall': 0.5305839061306672, 'f1-score': 0.3774479539673524, 'support': 14403}, '1': {'precision': 0.8983695032495914, 'recall': 0.6495227801491198, 'f1-score': 0.7539432344357201, 'support': 109174}, '2': {'precision': 0.25253736851817676, 'recall': 0.5881805157593123, 'f1-score': 0.35335886732366484, 'support': 13960}, 'accuracy': 0.6308411554708915, 'macro avg': {'precision': 0.4812720107885662, 'recall': 0.5894290673463665, 'f1-score': 0.4949166852422458, 'support': 137537}, 'weighted avg': {'precision': 0.7694132084630072, 'recall': 0.6308411554708915, 'f1-score': 0.6738570082604349, 'support': 137537}}
[[ 7642  4492  2269]
 [16229 70911 22034]
 [ 2219  3530  8211]]
Evaluating performance on  val set...
153/153 - 2s - 2s/epoch - 16ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.8493469
{'0': {'precision': 0.26667372432775777, 'recall': 0.57709049255441, 'f1-score': 0.3647816957497647, 'support': 4365}, '1': {'precision': 0.8718429234635205, 'recall': 0.6758229060054806, 'f1-score': 0.7614194316321976, 'support': 30289}, '2': {'precision': 0.3028571428571429, 'recall': 0.42197452229299365, 'f1-score': 0.3526280771789754, 'support': 4396}, 'accuracy': 0.6362099871959027, 'macro avg': {'precision': 0.4804579302161404, 'recall': 0.5582959736176281, 'f1-score': 0.49294306818697925, 'support': 39050}, 'weighted avg': {'precision': 0.7401444587830278, 'recall': 0.6362099871959027, 'f1-score': 0.6710642328792351, 'support': 39050}}
[[ 2519  1429   417]
 [ 5966 20470  3853]
 [  961  1580  1855]]
training model: results/QRTEA/W7/deepLOB_L1/h20
Epoch 1/50
538/538 - 16s - loss: 3.0402 - accuracy20: 0.4027 - val_loss: 3.4094 - val_accuracy20: 0.4493 - 16s/epoch - 29ms/step
Epoch 2/50
538/538 - 14s - loss: 2.9348 - accuracy20: 0.4323 - val_loss: 3.3957 - val_accuracy20: 0.4921 - 14s/epoch - 25ms/step
Epoch 3/50
538/538 - 14s - loss: 2.8655 - accuracy20: 0.4736 - val_loss: 3.6021 - val_accuracy20: 0.1880 - 14s/epoch - 25ms/step
Epoch 4/50
538/538 - 14s - loss: 2.7801 - accuracy20: 0.5209 - val_loss: 3.8477 - val_accuracy20: 0.6980 - 14s/epoch - 26ms/step
Epoch 5/50
538/538 - 14s - loss: 2.7427 - accuracy20: 0.5277 - val_loss: 3.3574 - val_accuracy20: 0.6797 - 14s/epoch - 25ms/step
Epoch 6/50
538/538 - 14s - loss: 2.6972 - accuracy20: 0.5433 - val_loss: 3.0231 - val_accuracy20: 0.6355 - 14s/epoch - 26ms/step
Epoch 7/50
538/538 - 13s - loss: 2.6482 - accuracy20: 0.5625 - val_loss: 2.9920 - val_accuracy20: 0.5499 - 13s/epoch - 25ms/step
Epoch 8/50
538/538 - 14s - loss: 2.6173 - accuracy20: 0.5689 - val_loss: 2.9667 - val_accuracy20: 0.5040 - 14s/epoch - 25ms/step
Epoch 9/50
538/538 - 14s - loss: 2.5833 - accuracy20: 0.5813 - val_loss: 2.9386 - val_accuracy20: 0.6235 - 14s/epoch - 25ms/step
Epoch 10/50
538/538 - 14s - loss: 2.5653 - accuracy20: 0.5854 - val_loss: 2.9682 - val_accuracy20: 0.5354 - 14s/epoch - 25ms/step
Epoch 11/50
538/538 - 14s - loss: 2.5309 - accuracy20: 0.5955 - val_loss: 2.8876 - val_accuracy20: 0.5411 - 14s/epoch - 25ms/step
Epoch 12/50
538/538 - 14s - loss: 2.5060 - accuracy20: 0.6012 - val_loss: 2.8672 - val_accuracy20: 0.5646 - 14s/epoch - 25ms/step
Epoch 13/50
538/538 - 14s - loss: 2.4846 - accuracy20: 0.6031 - val_loss: 2.8525 - val_accuracy20: 0.5757 - 14s/epoch - 25ms/step
Epoch 14/50
538/538 - 14s - loss: 2.4663 - accuracy20: 0.6067 - val_loss: 2.7744 - val_accuracy20: 0.5711 - 14s/epoch - 25ms/step
Epoch 15/50
538/538 - 14s - loss: 2.4483 - accuracy20: 0.6071 - val_loss: 2.8519 - val_accuracy20: 0.5819 - 14s/epoch - 25ms/step
Epoch 16/50
538/538 - 14s - loss: 2.4277 - accuracy20: 0.6124 - val_loss: 2.7629 - val_accuracy20: 0.6037 - 14s/epoch - 26ms/step
Epoch 17/50
538/538 - 14s - loss: 2.4151 - accuracy20: 0.6136 - val_loss: 2.7363 - val_accuracy20: 0.6239 - 14s/epoch - 26ms/step
Epoch 18/50
538/538 - 14s - loss: 2.3984 - accuracy20: 0.6163 - val_loss: 2.7626 - val_accuracy20: 0.5815 - 14s/epoch - 26ms/step
Epoch 19/50
538/538 - 14s - loss: 2.3901 - accuracy20: 0.6179 - val_loss: 2.7852 - val_accuracy20: 0.6170 - 14s/epoch - 27ms/step
Epoch 20/50
538/538 - 14s - loss: 2.3756 - accuracy20: 0.6200 - val_loss: 2.8294 - val_accuracy20: 0.5982 - 14s/epoch - 27ms/step
Epoch 21/50
538/538 - 14s - loss: 2.3668 - accuracy20: 0.6222 - val_loss: 2.7809 - val_accuracy20: 0.6281 - 14s/epoch - 26ms/step
Epoch 22/50
538/538 - 14s - loss: 2.3570 - accuracy20: 0.6228 - val_loss: 2.8139 - val_accuracy20: 0.6204 - 14s/epoch - 27ms/step
Epoch 23/50
538/538 - 14s - loss: 2.3489 - accuracy20: 0.6245 - val_loss: 2.8597 - val_accuracy20: 0.6058 - 14s/epoch - 27ms/step
Epoch 24/50
538/538 - 14s - loss: 2.3334 - accuracy20: 0.6268 - val_loss: 2.8257 - val_accuracy20: 0.6143 - 14s/epoch - 27ms/step
Epoch 25/50
538/538 - 14s - loss: 2.3312 - accuracy20: 0.6271 - val_loss: 2.8267 - val_accuracy20: 0.6309 - 14s/epoch - 27ms/step
Epoch 26/50
538/538 - 14s - loss: 2.3216 - accuracy20: 0.6268 - val_loss: 2.9215 - val_accuracy20: 0.5787 - 14s/epoch - 26ms/step
Epoch 27/50
538/538 - 14s - loss: 2.3140 - accuracy20: 0.6286 - val_loss: 2.8594 - val_accuracy20: 0.5998 - 14s/epoch - 27ms/step
testing model: results/QRTEA/W7/deepLOB_L1/h20
Evaluating performance on  test set...
2006/2006 - 33s - 33s/epoch - 16ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.89397687
{'0': {'precision': 0.33529057895494946, 'recall': 0.5903625242428763, 'f1-score': 0.4276828800397724, 'support': 67030}, '1': {'precision': 0.8712131402352449, 'recall': 0.6128742278880274, 'f1-score': 0.7195588239832368, 'support': 380450}, '2': {'precision': 0.3243649693352445, 'recall': 0.628883826879271, 'f1-score': 0.4279845598152138, 'support': 65850}, 'accuracy': 0.611988389534997, 'macro avg': {'precision': 0.5102895628418129, 'recall': 0.6107068596700582, 'f1-score': 0.5250754212794077, 'support': 513330}, 'weighted avg': {'precision': 0.7310833186070852, 'recall': 0.611988389534997, 'f1-score': 0.6440428599484155, 'support': 513330}}
[[ 39572  17740   9718]
 [ 70741 233168  76541]
 [  7710  16728  41412]]
Evaluating performance on  train set...
538/538 - 9s - 9s/epoch - 17ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.8761625
{'0': {'precision': 0.35642321237176544, 'recall': 0.5969942552318425, 'f1-score': 0.44635769208644127, 'support': 19496}, '1': {'precision': 0.8684214294920448, 'recall': 0.6113188906922589, 'f1-score': 0.717534580478743, 'support': 99197}, '2': {'precision': 0.3273614241291758, 'recall': 0.6089471449798344, 'f1-score': 0.4258121973393695, 'support': 18844}, 'accuracy': 0.6089634062106924, 'macro avg': {'precision': 0.5174020219976619, 'recall': 0.6057534303013119, 'f1-score': 0.5299014899681845, 'support': 137537}, 'weighted avg': {'precision': 0.7217143471648537, 'recall': 0.6089634062106924, 'f1-score': 0.639125998032022, 'support': 137537}}
[[11639  4791  3066]
 [18044 60641 20512]
 [ 2972  4397 11475]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 17ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.85196775
{'0': {'precision': 0.3669433343580285, 'recall': 0.608599592114208, 'f1-score': 0.4578405676660487, 'support': 5884}, '1': {'precision': 0.8527604345902364, 'recall': 0.6366906474820144, 'f1-score': 0.7290532730902595, 'support': 27244}, '2': {'precision': 0.38927374301675977, 'recall': 0.5883147585275245, 'f1-score': 0.4685314685314685, 'support': 5922}, 'accuracy': 0.6251216389244558, 'macro avg': {'precision': 0.5363258373216749, 'recall': 0.611201666041249, 'f1-score': 0.5518084364292589, 'support': 39050}, 'weighted avg': {'precision': 0.709269627797293, 'recall': 0.6251216389244558, 'f1-score': 0.6486787356942743, 'support': 39050}}
[[ 3581  1485   818]
 [ 5250 17346  4648]
 [  928  1510  3484]]
training model: results/QRTEA/W7/deepLOB_L1/h30
Epoch 1/50
538/538 - 17s - loss: 3.1126 - accuracy30: 0.4019 - val_loss: 3.9913 - val_accuracy30: 0.3314 - 17s/epoch - 31ms/step
Epoch 2/50
538/538 - 14s - loss: 3.0022 - accuracy30: 0.4055 - val_loss: 3.2971 - val_accuracy30: 0.4431 - 14s/epoch - 27ms/step
Epoch 3/50
538/538 - 14s - loss: 2.9409 - accuracy30: 0.4497 - val_loss: 3.2184 - val_accuracy30: 0.5885 - 14s/epoch - 26ms/step
Epoch 4/50
538/538 - 14s - loss: 2.8865 - accuracy30: 0.4860 - val_loss: 3.5992 - val_accuracy30: 0.6446 - 14s/epoch - 25ms/step
Epoch 5/50
538/538 - 14s - loss: 2.8292 - accuracy30: 0.5202 - val_loss: 3.6116 - val_accuracy30: 0.6457 - 14s/epoch - 26ms/step
Epoch 6/50
538/538 - 13s - loss: 2.7819 - accuracy30: 0.5386 - val_loss: 3.0618 - val_accuracy30: 0.5783 - 13s/epoch - 25ms/step
Epoch 7/50
538/538 - 13s - loss: 2.7446 - accuracy30: 0.5493 - val_loss: 3.0403 - val_accuracy30: 0.5980 - 13s/epoch - 24ms/step
Epoch 8/50
538/538 - 13s - loss: 2.7123 - accuracy30: 0.5558 - val_loss: 3.0674 - val_accuracy30: 0.6050 - 13s/epoch - 24ms/step
Epoch 9/50
538/538 - 14s - loss: 2.6842 - accuracy30: 0.5661 - val_loss: 3.0565 - val_accuracy30: 0.6006 - 14s/epoch - 26ms/step
Epoch 10/50
538/538 - 14s - loss: 2.6611 - accuracy30: 0.5701 - val_loss: 3.0420 - val_accuracy30: 0.6007 - 14s/epoch - 26ms/step
Epoch 11/50
538/538 - 14s - loss: 2.6355 - accuracy30: 0.5754 - val_loss: 3.0971 - val_accuracy30: 0.6181 - 14s/epoch - 27ms/step
Epoch 12/50
538/538 - 14s - loss: 2.6138 - accuracy30: 0.5797 - val_loss: 3.0283 - val_accuracy30: 0.6359 - 14s/epoch - 27ms/step
Epoch 13/50
538/538 - 15s - loss: 2.5955 - accuracy30: 0.5818 - val_loss: 3.0459 - val_accuracy30: 0.6279 - 15s/epoch - 27ms/step
Epoch 14/50
538/538 - 14s - loss: 2.5737 - accuracy30: 0.5839 - val_loss: 3.1009 - val_accuracy30: 0.6339 - 14s/epoch - 26ms/step
Epoch 15/50
538/538 - 14s - loss: 2.5646 - accuracy30: 0.5851 - val_loss: 3.0593 - val_accuracy30: 0.6037 - 14s/epoch - 26ms/step
Epoch 16/50
538/538 - 14s - loss: 2.5443 - accuracy30: 0.5882 - val_loss: 3.1814 - val_accuracy30: 0.6326 - 14s/epoch - 26ms/step
Epoch 17/50
538/538 - 14s - loss: 2.5270 - accuracy30: 0.5915 - val_loss: 3.1482 - val_accuracy30: 0.5961 - 14s/epoch - 26ms/step
Epoch 18/50
538/538 - 14s - loss: 2.5176 - accuracy30: 0.5929 - val_loss: 3.1271 - val_accuracy30: 0.6382 - 14s/epoch - 26ms/step
Epoch 19/50
538/538 - 15s - loss: 2.5051 - accuracy30: 0.5970 - val_loss: 3.1663 - val_accuracy30: 0.6349 - 15s/epoch - 27ms/step
Epoch 20/50
538/538 - 14s - loss: 2.4916 - accuracy30: 0.5967 - val_loss: 3.0809 - val_accuracy30: 0.5788 - 14s/epoch - 27ms/step
Epoch 21/50
538/538 - 15s - loss: 2.4811 - accuracy30: 0.6003 - val_loss: 3.1145 - val_accuracy30: 0.6277 - 15s/epoch - 28ms/step
Epoch 22/50
538/538 - 14s - loss: 2.4671 - accuracy30: 0.6021 - val_loss: 3.0865 - val_accuracy30: 0.6331 - 14s/epoch - 27ms/step
testing model: results/QRTEA/W7/deepLOB_L1/h30
Evaluating performance on  test set...
2006/2006 - 34s - 34s/epoch - 17ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.8704555
{'0': {'precision': 0.4404257308483451, 'recall': 0.34044014020886787, 'f1-score': 0.38403163236882687, 'support': 83019}, '1': {'precision': 0.7743925152414418, 'recall': 0.7141376753719273, 'f1-score': 0.7430455547993454, 'support': 349329}, '2': {'precision': 0.3467837178174947, 'recall': 0.5438862957200365, 'f1-score': 0.42352590484249397, 'support': 80982}, 'accuracy': 0.6268423820933903, 'macro avg': {'precision': 0.5205339879690939, 'recall': 0.5328213704336106, 'f1-score': 0.5168676973368888, 'support': 513330}, 'weighted avg': {'precision': 0.6529224976961658, 'recall': 0.6268423820933903, 'f1-score': 0.6345767002241891, 'support': 513330}}
[[ 28263  41076  13680]
 [ 30575 249469  69285]
 [  5334  31603  44045]]
Evaluating performance on  train set...
538/538 - 9s - 9s/epoch - 17ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.90177846
{'0': {'precision': 0.4412352052993035, 'recall': 0.38427929074404005, 'f1-score': 0.41079242716245323, 'support': 23574}, '1': {'precision': 0.777176667342388, 'recall': 0.6720681041283197, 'f1-score': 0.7208108108108109, 'support': 91272}, '2': {'precision': 0.33988129628656966, 'recall': 0.5703582918337667, 'f1-score': 0.4259408580032582, 'support': 22691}, 'accuracy': 0.6059605778808611, 'macro avg': {'precision': 0.5194310563094203, 'recall': 0.5422352289020421, 'f1-score': 0.5191813653255074, 'support': 137537}, 'weighted avg': {'precision': 0.6474504606428727, 'recall': 0.6059605778808611, 'f1-score': 0.619025345988381, 'support': 137537}}
[[ 9059 10226  4289]
 [ 9084 61341 20847]
 [ 2388  7361 12942]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 18ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.8460431
{'0': {'precision': 0.4715234102026555, 'recall': 0.37886019090398654, 'f1-score': 0.4201432129514321, 'support': 7124}, '1': {'precision': 0.7462355173388237, 'recall': 0.7460246993300509, 'f1-score': 0.7461300934428546, 'support': 24778}, '2': {'precision': 0.41005260081823497, 'recall': 0.49076664801343034, 'f1-score': 0.4467936063172642, 'support': 7148}, 'accuracy': 0.6323175416133162, 'macro avg': {'precision': 0.5426038427865714, 'recall': 0.5385505127491559, 'f1-score': 0.5376889709038503, 'support': 39050}, 'weighted avg': {'precision': 0.6345816239066282, 'recall': 0.6323175416133162, 'f1-score': 0.6318666428258352, 'support': 39050}}
[[ 2699  3387  1038]
 [ 2284 18485  4009]
 [  741  2899  3508]]
training model: results/QRTEA/W7/deepLOB_L1/h50
Epoch 1/50
538/538 - 16s - loss: 3.1457 - accuracy50: 0.4077 - val_loss: 3.9628 - val_accuracy50: 0.5130 - 16s/epoch - 30ms/step
Epoch 2/50
538/538 - 13s - loss: 3.0767 - accuracy50: 0.4169 - val_loss: 3.5493 - val_accuracy50: 0.5279 - 13s/epoch - 24ms/step
Epoch 3/50
538/538 - 13s - loss: 3.0169 - accuracy50: 0.4567 - val_loss: 3.5625 - val_accuracy50: 0.5430 - 13s/epoch - 24ms/step
Epoch 4/50
538/538 - 14s - loss: 2.9680 - accuracy50: 0.4826 - val_loss: 3.6576 - val_accuracy50: 0.5453 - 14s/epoch - 25ms/step
Epoch 5/50
538/538 - 14s - loss: 2.9415 - accuracy50: 0.4954 - val_loss: 3.5950 - val_accuracy50: 0.5276 - 14s/epoch - 26ms/step
Epoch 6/50
538/538 - 14s - loss: 2.9187 - accuracy50: 0.5051 - val_loss: 3.5110 - val_accuracy50: 0.5343 - 14s/epoch - 26ms/step
Epoch 7/50
538/538 - 14s - loss: 2.8920 - accuracy50: 0.5165 - val_loss: 3.4273 - val_accuracy50: 0.5517 - 14s/epoch - 26ms/step
Epoch 8/50
538/538 - 14s - loss: 2.8774 - accuracy50: 0.5192 - val_loss: 3.3953 - val_accuracy50: 0.5533 - 14s/epoch - 27ms/step
Epoch 9/50
538/538 - 14s - loss: 2.8558 - accuracy50: 0.5262 - val_loss: 3.7547 - val_accuracy50: 0.5378 - 14s/epoch - 26ms/step
Epoch 10/50
538/538 - 14s - loss: 2.8420 - accuracy50: 0.5317 - val_loss: 3.4015 - val_accuracy50: 0.5596 - 14s/epoch - 26ms/step
Epoch 11/50
538/538 - 14s - loss: 2.8209 - accuracy50: 0.5371 - val_loss: 3.3938 - val_accuracy50: 0.5655 - 14s/epoch - 25ms/step
Epoch 12/50
538/538 - 13s - loss: 2.8015 - accuracy50: 0.5397 - val_loss: 3.2190 - val_accuracy50: 0.5293 - 13s/epoch - 25ms/step
Epoch 13/50
538/538 - 14s - loss: 2.7823 - accuracy50: 0.5468 - val_loss: 3.3271 - val_accuracy50: 0.5076 - 14s/epoch - 26ms/step
Epoch 14/50
538/538 - 14s - loss: 2.7658 - accuracy50: 0.5515 - val_loss: 3.4595 - val_accuracy50: 0.5586 - 14s/epoch - 25ms/step
Epoch 15/50
538/538 - 14s - loss: 2.7457 - accuracy50: 0.5576 - val_loss: 3.2916 - val_accuracy50: 0.4910 - 14s/epoch - 25ms/step
Epoch 16/50
538/538 - 14s - loss: 2.7293 - accuracy50: 0.5587 - val_loss: 3.4475 - val_accuracy50: 0.5538 - 14s/epoch - 26ms/step
Epoch 17/50
538/538 - 14s - loss: 2.7140 - accuracy50: 0.5632 - val_loss: 3.2944 - val_accuracy50: 0.5653 - 14s/epoch - 26ms/step
Epoch 18/50
538/538 - 14s - loss: 2.7050 - accuracy50: 0.5649 - val_loss: 3.4009 - val_accuracy50: 0.4923 - 14s/epoch - 26ms/step
Epoch 19/50
538/538 - 14s - loss: 2.6901 - accuracy50: 0.5671 - val_loss: 3.4193 - val_accuracy50: 0.4708 - 14s/epoch - 26ms/step
Epoch 20/50
538/538 - 14s - loss: 2.6780 - accuracy50: 0.5698 - val_loss: 3.4685 - val_accuracy50: 0.5774 - 14s/epoch - 26ms/step
Epoch 21/50
538/538 - 14s - loss: 2.6766 - accuracy50: 0.5703 - val_loss: 3.4901 - val_accuracy50: 0.5699 - 14s/epoch - 26ms/step
Epoch 22/50
538/538 - 14s - loss: 2.6585 - accuracy50: 0.5721 - val_loss: 3.4516 - val_accuracy50: 0.5586 - 14s/epoch - 26ms/step
testing model: results/QRTEA/W7/deepLOB_L1/h50
Evaluating performance on  test set...
2006/2006 - 31s - 31s/epoch - 16ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0512744
{'0': {'precision': 0.3716543832428239, 'recall': 0.41743060976273894, 'f1-score': 0.39321471626809396, 'support': 110174}, '1': {'precision': 0.679472812596811, 'recall': 0.5989541893112889, 'f1-score': 0.6366778658782422, 'support': 296612}, '2': {'precision': 0.35612653465810196, 'recall': 0.42825499324222854, 'f1-score': 0.3888744476215232, 'support': 106544}, 'accuracy': 0.5245650945785362, 'macro avg': {'precision': 0.4690845768325789, 'recall': 0.4815465974387521, 'f1-score': 0.47292234325595306, 'support': 513330}, 'weighted avg': {'precision': 0.5462949475346717, 'recall': 0.5245650945785362, 'f1-score': 0.5329915891363951, 'support': 513330}}
[[ 45990  39774  24410]
 [ 60870 177657  58085]
 [ 16884  44032  45628]]
Evaluating performance on  train set...
538/538 - 8s - 8s/epoch - 16ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0269417
{'0': {'precision': 0.3977469407585097, 'recall': 0.43114344019485223, 'f1-score': 0.41377240780225855, 'support': 30382}, '1': {'precision': 0.7061228849117347, 'recall': 0.5921414588584516, 'f1-score': 0.6441286587148047, 'support': 78157}, '2': {'precision': 0.3612369761667051, 'recall': 0.48661976688047454, 'f1-score': 0.41465743964972596, 'support': 28998}, 'accuracy': 0.5343289442113759, 'macro avg': {'precision': 0.48836893394564984, 'recall': 0.5033015553112595, 'f1-score': 0.4908528353889297, 'support': 137537}, 'weighted avg': {'precision': 0.5652874768611618, 'recall': 0.5343289442113759, 'f1-score': 0.5448616249299023, 'support': 137537}}
[[13099  9637  7646]
 [14571 46280 17306]
 [ 5263  9624 14111]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 17ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.030735
{'0': {'precision': 0.38989237248479175, 'recall': 0.45704882062534286, 'f1-score': 0.4208080808080808, 'support': 9115}, '1': {'precision': 0.6561733442354865, 'recall': 0.6188548293811452, 'f1-score': 0.6369679531699574, 'support': 20748}, '2': {'precision': 0.4049107650335342, 'recall': 0.38772178077718517, 'f1-score': 0.39612989323843417, 'support': 9187}, 'accuracy': 0.5267093469910371, 'macro avg': {'precision': 0.4836588272512708, 'recall': 0.4878751435945577, 'f1-score': 0.4846353090721574, 'support': 39050}, 'weighted avg': {'precision': 0.5349057290591506, 'recall': 0.5267093469910371, 'f1-score': 0.5298520378519187, 'support': 39050}}
[[ 4166  3125  1824]
 [ 4497 12840  3411]
 [ 2022  3603  3562]]
training model: results/QRTEA/W7/deepLOB_L1/h100
Epoch 1/50
538/538 - 18s - loss: 3.2579 - accuracy100: 0.3974 - val_loss: 4.0144 - val_accuracy100: 0.3728 - 18s/epoch - 33ms/step
Epoch 2/50
538/538 - 15s - loss: 3.2039 - accuracy100: 0.4114 - val_loss: 3.7015 - val_accuracy100: 0.3769 - 15s/epoch - 28ms/step
Epoch 3/50
538/538 - 15s - loss: 3.1670 - accuracy100: 0.4300 - val_loss: 3.9728 - val_accuracy100: 0.3758 - 15s/epoch - 28ms/step
Epoch 4/50
538/538 - 14s - loss: 3.1488 - accuracy100: 0.4375 - val_loss: 3.9672 - val_accuracy100: 0.3763 - 14s/epoch - 26ms/step
Epoch 5/50
538/538 - 14s - loss: 3.1225 - accuracy100: 0.4470 - val_loss: 4.1430 - val_accuracy100: 0.3762 - 14s/epoch - 26ms/step
Epoch 6/50
538/538 - 14s - loss: 3.1070 - accuracy100: 0.4532 - val_loss: 4.0074 - val_accuracy100: 0.3775 - 14s/epoch - 26ms/step
Epoch 7/50
538/538 - 14s - loss: 3.0919 - accuracy100: 0.4625 - val_loss: 3.7856 - val_accuracy100: 0.3783 - 14s/epoch - 26ms/step
Epoch 8/50
538/538 - 14s - loss: 3.0820 - accuracy100: 0.4677 - val_loss: 4.1537 - val_accuracy100: 0.3767 - 14s/epoch - 26ms/step
Epoch 9/50
538/538 - 14s - loss: 3.0708 - accuracy100: 0.4727 - val_loss: 4.0530 - val_accuracy100: 0.3781 - 14s/epoch - 26ms/step
Epoch 10/50
538/538 - 14s - loss: 3.0635 - accuracy100: 0.4755 - val_loss: 4.0253 - val_accuracy100: 0.3774 - 14s/epoch - 26ms/step
Epoch 11/50
538/538 - 14s - loss: 3.0527 - accuracy100: 0.4790 - val_loss: 3.9624 - val_accuracy100: 0.3800 - 14s/epoch - 26ms/step
Epoch 12/50
538/538 - 14s - loss: 3.0460 - accuracy100: 0.4799 - val_loss: 3.8034 - val_accuracy100: 0.3806 - 14s/epoch - 26ms/step
testing model: results/QRTEA/W7/deepLOB_L1/h100
Evaluating performance on  test set...
2006/2006 - 32s - 32s/epoch - 16ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.1239744
{'0': {'precision': 0.3305235137533274, 'recall': 0.014480734468035479, 'f1-score': 0.02774588001613854, 'support': 154343}, '1': {'precision': 0.4127688679150114, 'recall': 0.9692941104009627, 'f1-score': 0.5789814775509048, 'support': 211067}, '2': {'precision': 0.3559725400457666, 'recall': 0.026291238507301244, 'f1-score': 0.0489659731184488, 'support': 147920}, 'accuracy': 0.41047669140708704, 'macro avg': {'precision': 0.36642164057136845, 'recall': 0.3366886944587664, 'f1-score': 0.21856444356183072, 'support': 513330}, 'weighted avg': {'precision': 0.3716738461633205, 'recall': 0.41047669140708704, 'f1-score': 0.26051333961632606, 'support': 513330}}
[[  2235 148564   3544]
 [  2989 204586   3492]
 [  1538 142493   3889]]
Evaluating performance on  train set...
538/538 - 9s - 9s/epoch - 16ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.1044223
{'0': {'precision': 0.3772455089820359, 'recall': 0.02573838648434308, 'f1-score': 0.04818897637795276, 'support': 41611}, '1': {'precision': 0.4168456381005165, 'recall': 0.953514579518242, 'f1-score': 0.5800933042672508, 'support': 56792}, '2': {'precision': 0.370641052411777, 'recall': 0.04535697858639546, 'f1-score': 0.08082325888486669, 'support': 39134}, 'accuracy': 0.41441939259980953, 'macro avg': {'precision': 0.3882440664981098, 'recall': 0.3415366481963269, 'f1-score': 0.23636851317669008, 'support': 137537}, 'weighted avg': {'precision': 0.39171806349083166, 'recall': 0.41441939259980953, 'f1-score': 0.277109343996227, 'support': 137537}}
[[ 1071 39121  1419]
 [ 1045 54152  1595]
 [  723 36636  1775]]
Evaluating performance on  val set...
153/153 - 2s - 2s/epoch - 16ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.1526285
{'0': {'precision': 0.38181818181818183, 'recall': 0.013886592825260374, 'f1-score': 0.026798532461317595, 'support': 12098}, '1': {'precision': 0.3776467789262206, 'recall': 0.972829417773238, 'f1-score': 0.5440834824999048, 'support': 14685}, '2': {'precision': 0.40717029449423814, 'recall': 0.025923208608461725, 'f1-score': 0.04874310239117106, 'support': 12267}, 'accuracy': 0.3782842509603073, 'macro avg': {'precision': 0.3888784184128802, 'recall': 0.33754640640232, 'f1-score': 0.20654170578413114, 'support': 39050}, 'weighted avg': {'precision': 0.38821350357820056, 'recall': 0.3782842509603073, 'f1-score': 0.2282203898402207, 'support': 39050}}
[[  168 11694   236]
 [  172 14286   227]
 [  100 11849   318]]
training model: results/QRTEA/W7/deepLOB_L1/h200
Epoch 1/50
538/538 - 16s - loss: 3.3095 - accuracy200: 0.3759 - val_loss: 3.4576 - val_accuracy200: 0.3236 - 16s/epoch - 31ms/step
Epoch 2/50
538/538 - 14s - loss: 3.2663 - accuracy200: 0.3870 - val_loss: 3.5936 - val_accuracy200: 0.3090 - 14s/epoch - 27ms/step
Epoch 3/50
538/538 - 14s - loss: 3.2373 - accuracy200: 0.3997 - val_loss: 3.4458 - val_accuracy200: 0.3072 - 14s/epoch - 26ms/step
Epoch 4/50
538/538 - 13s - loss: 3.2257 - accuracy200: 0.4083 - val_loss: 3.4649 - val_accuracy200: 0.3048 - 13s/epoch - 25ms/step
Epoch 5/50
538/538 - 13s - loss: 3.2133 - accuracy200: 0.4144 - val_loss: 3.3908 - val_accuracy200: 0.3210 - 13s/epoch - 24ms/step
Epoch 6/50
538/538 - 13s - loss: 3.2044 - accuracy200: 0.4223 - val_loss: 3.3994 - val_accuracy200: 0.3103 - 13s/epoch - 25ms/step
Epoch 7/50
538/538 - 14s - loss: 3.1927 - accuracy200: 0.4259 - val_loss: 3.4444 - val_accuracy200: 0.3073 - 14s/epoch - 25ms/step
Epoch 8/50
538/538 - 14s - loss: 3.1930 - accuracy200: 0.4247 - val_loss: 3.4103 - val_accuracy200: 0.3098 - 14s/epoch - 26ms/step
Epoch 9/50
538/538 - 14s - loss: 3.1877 - accuracy200: 0.4284 - val_loss: 3.4526 - val_accuracy200: 0.3109 - 14s/epoch - 26ms/step
Epoch 10/50
538/538 - 14s - loss: 3.1821 - accuracy200: 0.4303 - val_loss: 3.4474 - val_accuracy200: 0.3131 - 14s/epoch - 26ms/step
Epoch 11/50
538/538 - 14s - loss: 3.1717 - accuracy200: 0.4348 - val_loss: 3.5777 - val_accuracy200: 0.3081 - 14s/epoch - 26ms/step
Epoch 12/50
538/538 - 14s - loss: 3.1673 - accuracy200: 0.4386 - val_loss: 3.5340 - val_accuracy200: 0.3096 - 14s/epoch - 25ms/step
Epoch 13/50
538/538 - 14s - loss: 3.1596 - accuracy200: 0.4405 - val_loss: 3.4634 - val_accuracy200: 0.3109 - 14s/epoch - 26ms/step
Epoch 14/50
538/538 - 14s - loss: 3.1512 - accuracy200: 0.4442 - val_loss: 3.4632 - val_accuracy200: 0.3152 - 14s/epoch - 26ms/step
Epoch 15/50
538/538 - 14s - loss: 3.1475 - accuracy200: 0.4444 - val_loss: 3.5044 - val_accuracy200: 0.3156 - 14s/epoch - 27ms/step
testing model: results/QRTEA/W7/deepLOB_L1/h200
Evaluating performance on  test set...
2006/2006 - 31s - 31s/epoch - 16ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1309106
{'0': {'precision': 0.3790640966093823, 'recall': 0.03683019974841065, 'f1-score': 0.06713728232312066, 'support': 177273}, '1': {'precision': 0.32600149171137793, 'recall': 0.814000012015115, 'f1-score': 0.46555240024257544, 'support': 166457}, '2': {'precision': 0.36230677469059097, 'recall': 0.17191627358490566, 'f1-score': 0.2331851117260353, 'support': 169600}, 'accuracy': 0.33347359398437654, 'macro avg': {'precision': 0.3557907876704504, 'recall': 0.3409154951161437, 'f1-score': 0.25529159809724383, 'support': 513330}, 'weighted avg': {'precision': 0.3563210583670545, 'recall': 0.33347359398437654, 'f1-score': 0.2511917836190765, 'support': 513330}}
[[  6529 143144  27600]
 [  7242 135496  23719]
 [  3453 136990  29157]]
Evaluating performance on  train set...
538/538 - 9s - 9s/epoch - 17ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1379845
{'0': {'precision': 0.4041614123581337, 'recall': 0.02639978583637075, 'f1-score': 0.04956217501401426, 'support': 48561}, '1': {'precision': 0.31752494942110543, 'recall': 0.8510206871411646, 'f1-score': 0.4624899399492355, 'support': 43892}, '2': {'precision': 0.3572666945656723, 'recall': 0.1325525685387277, 'f1-score': 0.1933636407759137, 'support': 45084}, 'accuracy': 0.3243563550171954, 'macro avg': {'precision': 0.3596510187816371, 'recall': 0.33665768050542105, 'f1-score': 0.23513858524638784, 'support': 137537}, 'weighted avg': {'precision': 0.36114135893114774, 'recall': 0.3243563550171954, 'f1-score': 0.22847672703235264, 'support': 137537}}
[[ 1282 41752  5527]
 [ 1315 37353  5224]
 [  575 38533  5976]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 17ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.13805
{'0': {'precision': 0.4309623430962343, 'recall': 0.023135669362084457, 'f1-score': 0.04391387763803027, 'support': 13356}, '1': {'precision': 0.30740207833733013, 'recall': 0.8098045822102425, 'f1-score': 0.4456393260249844, 'support': 11872}, '2': {'precision': 0.3663927458203457, 'recall': 0.18709304008103025, 'f1-score': 0.24770114942528734, 'support': 13822}, 'accuracy': 0.3203329065300896, 'macro avg': {'precision': 0.36825238908463676, 'recall': 0.3400110972177857, 'f1-score': 0.245751451029434, 'support': 39050}, 'weighted avg': {'precision': 0.3705426648180002, 'recall': 0.3203329065300896, 'f1-score': 0.23817846647012728, 'support': 39050}}
[[  309 10609  2438]
 [  224  9614  2034]
 [  184 11052  2586]]
training model: results/QRTEA/W7/deepLOB_L1/h300
Epoch 1/50
538/538 - 16s - loss: 3.3165 - accuracy300: 0.3665 - val_loss: 3.6297 - val_accuracy300: 0.3389 - 16s/epoch - 30ms/step
Epoch 2/50
538/538 - 15s - loss: 3.2845 - accuracy300: 0.3750 - val_loss: 3.4514 - val_accuracy300: 0.3389 - 15s/epoch - 27ms/step
Epoch 3/50
538/538 - 14s - loss: 3.2668 - accuracy300: 0.3810 - val_loss: 3.4571 - val_accuracy300: 0.3404 - 14s/epoch - 26ms/step
Epoch 4/50
538/538 - 14s - loss: 3.2484 - accuracy300: 0.3942 - val_loss: 3.4454 - val_accuracy300: 0.3408 - 14s/epoch - 26ms/step
Epoch 5/50
538/538 - 14s - loss: 3.2436 - accuracy300: 0.3967 - val_loss: 3.4810 - val_accuracy300: 0.3407 - 14s/epoch - 26ms/step
Epoch 6/50
538/538 - 14s - loss: 3.2341 - accuracy300: 0.4021 - val_loss: 3.4013 - val_accuracy300: 0.3391 - 14s/epoch - 27ms/step
Epoch 7/50
538/538 - 14s - loss: 3.2228 - accuracy300: 0.4090 - val_loss: 3.4076 - val_accuracy300: 0.3405 - 14s/epoch - 26ms/step
Epoch 8/50
538/538 - 14s - loss: 3.2190 - accuracy300: 0.4082 - val_loss: 3.4520 - val_accuracy300: 0.3390 - 14s/epoch - 27ms/step
Epoch 9/50
538/538 - 15s - loss: 3.2092 - accuracy300: 0.4130 - val_loss: 3.4572 - val_accuracy300: 0.3392 - 15s/epoch - 27ms/step
Epoch 10/50
538/538 - 14s - loss: 3.2031 - accuracy300: 0.4159 - val_loss: 3.4323 - val_accuracy300: 0.3402 - 14s/epoch - 26ms/step
Epoch 11/50
538/538 - 14s - loss: 3.1972 - accuracy300: 0.4198 - val_loss: 3.4429 - val_accuracy300: 0.3403 - 14s/epoch - 26ms/step
Epoch 12/50
538/538 - 14s - loss: 3.1962 - accuracy300: 0.4220 - val_loss: 3.4444 - val_accuracy300: 0.3411 - 14s/epoch - 26ms/step
Epoch 13/50
538/538 - 14s - loss: 3.1918 - accuracy300: 0.4248 - val_loss: 3.4514 - val_accuracy300: 0.3364 - 14s/epoch - 27ms/step
Epoch 14/50
538/538 - 14s - loss: 3.1846 - accuracy300: 0.4281 - val_loss: 3.4956 - val_accuracy300: 0.3410 - 14s/epoch - 27ms/step
Epoch 15/50
538/538 - 15s - loss: 3.1760 - accuracy300: 0.4295 - val_loss: 3.4712 - val_accuracy300: 0.3431 - 15s/epoch - 27ms/step
Epoch 16/50
538/538 - 15s - loss: 3.1702 - accuracy300: 0.4329 - val_loss: 3.4962 - val_accuracy300: 0.3411 - 15s/epoch - 27ms/step
testing model: results/QRTEA/W7/deepLOB_L1/h300
Evaluating performance on  test set...
2006/2006 - 34s - 34s/epoch - 17ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1290432
{'0': {'precision': 0.31799861014593467, 'recall': 0.013335198396046067, 'f1-score': 0.02559699280084577, 'support': 171576}, '1': {'precision': 0.3446336876704177, 'recall': 0.836090997270533, 'f1-score': 0.4880818149944775, 'support': 177324}, '2': {'precision': 0.3229438255510785, 'recall': 0.14915161466885604, 'f1-score': 0.2040587090010484, 'support': 164430}, 'accuracy': 0.3410515652699044, 'macro avg': {'precision': 0.32852537445581026, 'recall': 0.3328592701118117, 'f1-score': 0.2392458389321239, 'support': 513330}, 'weighted avg': {'precision': 0.3287834469098472, 'recall': 0.3410515652699044, 'f1-score': 0.24252200907782717, 'support': 513330}}
[[  2288 144100  25188]
 [  2836 148259  26229]
 [  2071 137834  24525]]
Evaluating performance on  train set...
538/538 - 10s - 10s/epoch - 18ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1241
{'0': {'precision': 0.3579393398751115, 'recall': 0.03428022212729603, 'f1-score': 0.06256822080149696, 'support': 46820}, '1': {'precision': 0.3469217970049917, 'recall': 0.8571967948986869, 'f1-score': 0.4939384782740074, 'support': 47674}, '2': {'precision': 0.3282427738087435, 'recall': 0.1163487675115582, 'f1-score': 0.17180102915951972, 'support': 43043}, 'accuracy': 0.34520892559820265, 'macro avg': {'precision': 0.34436797022961557, 'recall': 0.3359419281791804, 'f1-score': 0.24276924274500802, 'support': 137537}, 'weighted avg': {'precision': 0.3448266528746333, 'recall': 0.34520892559820265, 'f1-score': 0.24627772024454747, 'support': 137537}}
[[ 1605 40252  4963]
 [ 1522 40866  5286]
 [ 1357 36678  5008]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 18ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1274978
{'0': {'precision': 0.3150406504065041, 'recall': 0.012309402795425667, 'f1-score': 0.02369306022623051, 'support': 12592}, '1': {'precision': 0.3394716514753592, 'recall': 0.8256556699481475, 'f1-score': 0.4811262918199334, 'support': 13307}, '2': {'precision': 0.3513644437267883, 'recall': 0.165462702456087, 'f1-score': 0.22497932175351532, 'support': 13151}, 'accuracy': 0.34104993597951344, 'macro avg': {'precision': 0.33529224853621714, 'recall': 0.33447592506655344, 'f1-score': 0.24326622459989308, 'support': 39050}, 'weighted avg': {'precision': 0.3355988459808527, 'recall': 0.34104993597951344, 'f1-score': 0.24735963226624913, 'support': 39050}}
[[  155 10559  1878]
 [  181 10987  2139]
 [  156 10819  2176]]
training model: results/QRTEA/W7/deepLOB_L1/h500
Epoch 1/50
538/538 - 16s - loss: 3.3014 - accuracy500: 0.3822 - val_loss: 3.3127 - val_accuracy500: 0.3703 - 16s/epoch - 29ms/step
Epoch 2/50
538/538 - 14s - loss: 3.2733 - accuracy500: 0.3796 - val_loss: 3.4053 - val_accuracy500: 0.3111 - 14s/epoch - 26ms/step
Epoch 3/50
538/538 - 14s - loss: 3.2731 - accuracy500: 0.3832 - val_loss: 3.3442 - val_accuracy500: 0.3049 - 14s/epoch - 26ms/step
Epoch 4/50
538/538 - 14s - loss: 3.2614 - accuracy500: 0.3956 - val_loss: 3.3359 - val_accuracy500: 0.3108 - 14s/epoch - 27ms/step
Epoch 5/50
538/538 - 14s - loss: 3.2552 - accuracy500: 0.3970 - val_loss: 3.3286 - val_accuracy500: 0.3064 - 14s/epoch - 27ms/step
Epoch 6/50
538/538 - 15s - loss: 3.2495 - accuracy500: 0.4004 - val_loss: 3.3524 - val_accuracy500: 0.3066 - 15s/epoch - 27ms/step
Epoch 7/50
538/538 - 14s - loss: 3.2405 - accuracy500: 0.4070 - val_loss: 3.3321 - val_accuracy500: 0.3100 - 14s/epoch - 27ms/step
Epoch 8/50
538/538 - 14s - loss: 3.2319 - accuracy500: 0.4102 - val_loss: 3.2969 - val_accuracy500: 0.3795 - 14s/epoch - 26ms/step
Epoch 9/50
538/538 - 14s - loss: 3.2284 - accuracy500: 0.4122 - val_loss: 3.3066 - val_accuracy500: 0.3536 - 14s/epoch - 26ms/step
Epoch 10/50
538/538 - 15s - loss: 3.2191 - accuracy500: 0.4168 - val_loss: 3.3109 - val_accuracy500: 0.3403 - 15s/epoch - 27ms/step
Epoch 11/50
538/538 - 14s - loss: 3.2080 - accuracy500: 0.4213 - val_loss: 3.3105 - val_accuracy500: 0.3569 - 14s/epoch - 26ms/step
Epoch 12/50
538/538 - 14s - loss: 3.2059 - accuracy500: 0.4205 - val_loss: 3.3265 - val_accuracy500: 0.3460 - 14s/epoch - 27ms/step
Epoch 13/50
538/538 - 14s - loss: 3.1922 - accuracy500: 0.4288 - val_loss: 3.3172 - val_accuracy500: 0.3508 - 14s/epoch - 26ms/step
Epoch 14/50
538/538 - 14s - loss: 3.1873 - accuracy500: 0.4327 - val_loss: 3.3335 - val_accuracy500: 0.3435 - 14s/epoch - 26ms/step
Epoch 15/50
538/538 - 13s - loss: 3.1752 - accuracy500: 0.4403 - val_loss: 3.3402 - val_accuracy500: 0.3388 - 13s/epoch - 25ms/step
Epoch 16/50
538/538 - 14s - loss: 3.1717 - accuracy500: 0.4435 - val_loss: 3.3137 - val_accuracy500: 0.3823 - 14s/epoch - 25ms/step
Epoch 17/50
538/538 - 13s - loss: 3.1652 - accuracy500: 0.4440 - val_loss: 3.3299 - val_accuracy500: 0.3613 - 13s/epoch - 25ms/step
Epoch 18/50
538/538 - 14s - loss: 3.1582 - accuracy500: 0.4472 - val_loss: 3.3436 - val_accuracy500: 0.3755 - 14s/epoch - 26ms/step
testing model: results/QRTEA/W7/deepLOB_L1/h500
Evaluating performance on  test set...
2006/2006 - 31s - 31s/epoch - 15ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.106135
{'0': {'precision': 0.35474567882433566, 'recall': 0.20130817093721642, 'f1-score': 0.25685715073326715, 'support': 185144}, '1': {'precision': 0.2912838931227068, 'recall': 0.7759787852136137, 'f1-score': 0.4235698036213396, 'support': 150084}, '2': {'precision': 0.3629041809783252, 'recall': 0.01720362488910849, 'f1-score': 0.03284998257793026, 'support': 178102}, 'accuracy': 0.30545068474470616, 'macro avg': {'precision': 0.33631125097512254, 'recall': 0.3314968603466462, 'f1-score': 0.23775897897751233, 'support': 513330}, 'weighted avg': {'precision': 0.33902177199127814, 'recall': 0.30545068474470616, 'f1-score': 0.22787925568184147, 'support': 513330}}
[[ 37271 144971   2902]
 [ 31145 116462   2477]
 [ 36648 138390   3064]]
Evaluating performance on  train set...
538/538 - 9s - 9s/epoch - 16ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1015552
{'0': {'precision': 0.3647681141591832, 'recall': 0.30502407110233304, 'f1-score': 0.3322315716350517, 'support': 48606}, '1': {'precision': 0.32569448325973954, 'recall': 0.6536174985978688, 'f1-score': 0.43475341341490714, 'support': 44575}, '2': {'precision': 0.3602258975393304, 'recall': 0.060397691405897735, 'f1-score': 0.10345027320294248, 'support': 44356}, 'accuracy': 0.33910874891847287, 'macro avg': {'precision': 0.3502294983194177, 'recall': 0.3396797537020331, 'f1-score': 0.29014508608430045, 'support': 137537}, 'weighted avg': {'precision': 0.35063968575276966, 'recall': 0.33910874891847287, 'f1-score': 0.29167585080416564, 'support': 137537}}
[[14826 31342  2438]
 [13120 29135  2320]
 [12699 28978  2679]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 17ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0939972
{'0': {'precision': 0.30150397275822927, 'recall': 0.18383943247685786, 'f1-score': 0.22840866340624494, 'support': 11559}, '1': {'precision': 0.3995220646805799, 'recall': 0.8091765616933402, 'f1-score': 0.5349288624389411, 'support': 15496}, '2': {'precision': 0.3581847649918963, 'recall': 0.01842434347644852, 'f1-score': 0.035045987947986044, 'support': 11995}, 'accuracy': 0.38117797695262484, 'macro avg': {'precision': 0.3530702674769018, 'recall': 0.33714677921554886, 'f1-score': 0.2661278379310574, 'support': 39050}, 'weighted avg': {'precision': 0.35781061693931976, 'recall': 0.38117797695262484, 'f1-score': 0.2906481438694676, 'support': 39050}}
[[ 2125  9247   187]
 [ 2748 12539   209]
 [ 2175  9599   221]]
training model: results/QRTEA/W7/deepLOB_L1/h1000
Epoch 1/50
538/538 - 16s - loss: 3.2634 - accuracy1000: 0.4099 - val_loss: 3.5435 - val_accuracy1000: 0.3364 - 16s/epoch - 30ms/step
Epoch 2/50
538/538 - 14s - loss: 3.2274 - accuracy1000: 0.4199 - val_loss: 3.4420 - val_accuracy1000: 0.3273 - 14s/epoch - 26ms/step
Epoch 3/50
538/538 - 14s - loss: 3.2408 - accuracy1000: 0.4026 - val_loss: 3.3562 - val_accuracy1000: 0.3438 - 14s/epoch - 26ms/step
Epoch 4/50
538/538 - 14s - loss: 3.2243 - accuracy1000: 0.4074 - val_loss: 3.4031 - val_accuracy1000: 0.3352 - 14s/epoch - 26ms/step
Epoch 5/50
538/538 - 14s - loss: 3.2115 - accuracy1000: 0.4201 - val_loss: 3.3558 - val_accuracy1000: 0.3383 - 14s/epoch - 26ms/step
Epoch 6/50
538/538 - 14s - loss: 3.2029 - accuracy1000: 0.4280 - val_loss: 3.3489 - val_accuracy1000: 0.3498 - 14s/epoch - 27ms/step
Epoch 7/50
538/538 - 14s - loss: 3.1828 - accuracy1000: 0.4333 - val_loss: 3.3485 - val_accuracy1000: 0.3390 - 14s/epoch - 26ms/step
Epoch 8/50
538/538 - 14s - loss: 3.1880 - accuracy1000: 0.4301 - val_loss: 3.3670 - val_accuracy1000: 0.3369 - 14s/epoch - 26ms/step
Epoch 9/50
538/538 - 14s - loss: 3.1688 - accuracy1000: 0.4458 - val_loss: 3.3989 - val_accuracy1000: 0.3315 - 14s/epoch - 26ms/step
Epoch 10/50
538/538 - 14s - loss: 3.1418 - accuracy1000: 0.4580 - val_loss: 3.3740 - val_accuracy1000: 0.3305 - 14s/epoch - 26ms/step
Epoch 11/50
538/538 - 14s - loss: 3.1401 - accuracy1000: 0.4600 - val_loss: 3.3973 - val_accuracy1000: 0.3292 - 14s/epoch - 25ms/step
Epoch 12/50
538/538 - 14s - loss: 3.1292 - accuracy1000: 0.4635 - val_loss: 3.3465 - val_accuracy1000: 0.3378 - 14s/epoch - 26ms/step
Epoch 13/50
538/538 - 14s - loss: 3.1070 - accuracy1000: 0.4711 - val_loss: 3.3623 - val_accuracy1000: 0.3322 - 14s/epoch - 26ms/step
Epoch 14/50
538/538 - 14s - loss: 3.0884 - accuracy1000: 0.4781 - val_loss: 3.3659 - val_accuracy1000: 0.3324 - 14s/epoch - 25ms/step
Epoch 15/50
538/538 - 14s - loss: 3.0884 - accuracy1000: 0.4807 - val_loss: 3.4143 - val_accuracy1000: 0.3173 - 14s/epoch - 26ms/step
Epoch 16/50
538/538 - 14s - loss: 3.0684 - accuracy1000: 0.4861 - val_loss: 3.4113 - val_accuracy1000: 0.3251 - 14s/epoch - 26ms/step
Epoch 17/50
538/538 - 14s - loss: 3.0560 - accuracy1000: 0.4906 - val_loss: 3.4526 - val_accuracy1000: 0.3230 - 14s/epoch - 27ms/step
Epoch 18/50
538/538 - 14s - loss: 3.0499 - accuracy1000: 0.4935 - val_loss: 3.3987 - val_accuracy1000: 0.3374 - 14s/epoch - 25ms/step
Epoch 19/50
538/538 - 14s - loss: 3.0330 - accuracy1000: 0.4984 - val_loss: 3.4164 - val_accuracy1000: 0.3364 - 14s/epoch - 26ms/step
Epoch 20/50
538/538 - 14s - loss: 3.0281 - accuracy1000: 0.4994 - val_loss: 3.3795 - val_accuracy1000: 0.3414 - 14s/epoch - 26ms/step
Epoch 21/50
538/538 - 14s - loss: 3.0395 - accuracy1000: 0.4959 - val_loss: 3.3955 - val_accuracy1000: 0.3397 - 14s/epoch - 27ms/step
Epoch 22/50
538/538 - 14s - loss: 3.0535 - accuracy1000: 0.4892 - val_loss: 3.4492 - val_accuracy1000: 0.3088 - 14s/epoch - 25ms/step
testing model: results/QRTEA/W7/deepLOB_L1/h1000
Evaluating performance on  test set...
2006/2006 - 32s - 32s/epoch - 16ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1085174
{'0': {'precision': 0.39648227876512476, 'recall': 0.4780969815071796, 'f1-score': 0.433481536343944, 'support': 203214}, '1': {'precision': 0.22289880859351519, 'recall': 0.32164635468621244, 'f1-score': 0.2633191664625075, 'support': 115285}, '2': {'precision': 0.3873556564992593, 'recall': 0.20264742263808122, 'f1-score': 0.2660888670229615, 'support': 194831}, 'accuracy': 0.3384158338690511, 'macro avg': {'precision': 0.3355789146192998, 'recall': 0.3341302529438244, 'f1-score': 0.3209631899431377, 'support': 513330}, 'weighted avg': {'precision': 0.3540344979975584, 'recall': 0.3384158338690511, 'f1-score': 0.33173324583246455, 'support': 513330}}
[[97156 66546 39512]
 [55271 37081 22933]
 [92618 62731 39482]]
Evaluating performance on  train set...
538/538 - 9s - 9s/epoch - 17ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1042672
{'0': {'precision': 0.3691717993358009, 'recall': 0.5021791478437382, 'f1-score': 0.42552402151734375, 'support': 50249}, '1': {'precision': 0.32318220701454237, 'recall': 0.2665694529375794, 'f1-score': 0.29215858122390065, 'support': 42518}, '2': {'precision': 0.33927419827636746, 'recall': 0.258521331248604, 'f1-score': 0.29344353734597634, 'support': 44770}, 'accuracy': 0.3500294466216364, 'macro avg': {'precision': 0.34387606820890354, 'recall': 0.34242331067664056, 'f1-score': 0.3370420466957402, 'support': 137537}, 'weighted avg': {'precision': 0.3452225995877614, 'recall': 0.3500294466216364, 'f1-score': 0.34130177538176765, 'support': 137537}}
[[25234 12657 12358]
 [21002 11334 10182]
 [22117 11079 11574]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 17ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1060601
{'0': {'precision': 0.32509391844068164, 'recall': 0.4672509586039596, 'f1-score': 0.38342002183265905, 'support': 12779}, '1': {'precision': 0.3446605733927037, 'recall': 0.3393846153846154, 'f1-score': 0.34200224797488465, 'support': 13000}, '2': {'precision': 0.3592996701344836, 'recall': 0.21339763393866326, 'f1-score': 0.26776343781023965, 'support': 13271}, 'accuracy': 0.3384122919334187, 'macro avg': {'precision': 0.3430180539892896, 'recall': 0.34001106930907943, 'f1-score': 0.3310619025392611, 'support': 39050}, 'weighted avg': {'precision': 0.3432324855368335, 'recall': 0.3384122919334187, 'f1-score': 0.33032630642388583, 'support': 39050}}
[[5971 4165 2643]
 [6181 4412 2407]
 [6215 4224 2832]]
training model: results/QRTEA/W7/deepOF_L1/h10
Epoch 1/50
538/538 - 15s - loss: 3.0257 - accuracy10: 0.4215 - val_loss: 3.1459 - val_accuracy10: 0.5710 - 15s/epoch - 28ms/step
Epoch 2/50
538/538 - 13s - loss: 2.8936 - accuracy10: 0.4569 - val_loss: 3.0890 - val_accuracy10: 0.5758 - 13s/epoch - 24ms/step
Epoch 3/50
538/538 - 13s - loss: 2.8486 - accuracy10: 0.4843 - val_loss: 3.0594 - val_accuracy10: 0.5759 - 13s/epoch - 25ms/step
Epoch 4/50
538/538 - 13s - loss: 2.8191 - accuracy10: 0.4950 - val_loss: 3.0300 - val_accuracy10: 0.5941 - 13s/epoch - 25ms/step
Epoch 5/50
538/538 - 13s - loss: 2.7930 - accuracy10: 0.5056 - val_loss: 3.0152 - val_accuracy10: 0.6052 - 13s/epoch - 24ms/step
Epoch 6/50
538/538 - 13s - loss: 2.7713 - accuracy10: 0.5135 - val_loss: 2.9996 - val_accuracy10: 0.6076 - 13s/epoch - 24ms/step
Epoch 7/50
538/538 - 14s - loss: 2.7510 - accuracy10: 0.5274 - val_loss: 2.9838 - val_accuracy10: 0.6203 - 14s/epoch - 25ms/step
Epoch 8/50
538/538 - 13s - loss: 2.7368 - accuracy10: 0.5331 - val_loss: 2.9834 - val_accuracy10: 0.6366 - 13s/epoch - 25ms/step
Epoch 9/50
538/538 - 13s - loss: 2.7192 - accuracy10: 0.5388 - val_loss: 2.9850 - val_accuracy10: 0.6424 - 13s/epoch - 25ms/step
Epoch 10/50
538/538 - 14s - loss: 2.7070 - accuracy10: 0.5435 - val_loss: 2.9829 - val_accuracy10: 0.6534 - 14s/epoch - 25ms/step
Epoch 11/50
538/538 - 13s - loss: 2.6948 - accuracy10: 0.5471 - val_loss: 2.9798 - val_accuracy10: 0.6601 - 13s/epoch - 25ms/step
Epoch 12/50
538/538 - 13s - loss: 2.6829 - accuracy10: 0.5501 - val_loss: 2.9930 - val_accuracy10: 0.6671 - 13s/epoch - 25ms/step
Epoch 13/50
538/538 - 13s - loss: 2.6692 - accuracy10: 0.5526 - val_loss: 2.9962 - val_accuracy10: 0.6752 - 13s/epoch - 25ms/step
Epoch 14/50
538/538 - 13s - loss: 2.6573 - accuracy10: 0.5563 - val_loss: 3.0261 - val_accuracy10: 0.6925 - 13s/epoch - 24ms/step
Epoch 15/50
538/538 - 14s - loss: 2.6465 - accuracy10: 0.5581 - val_loss: 2.9921 - val_accuracy10: 0.6803 - 14s/epoch - 25ms/step
Epoch 16/50
538/538 - 14s - loss: 2.6334 - accuracy10: 0.5607 - val_loss: 3.0413 - val_accuracy10: 0.6993 - 14s/epoch - 25ms/step
Epoch 17/50
538/538 - 14s - loss: 2.6244 - accuracy10: 0.5616 - val_loss: 3.0329 - val_accuracy10: 0.6931 - 14s/epoch - 26ms/step
Epoch 18/50
538/538 - 14s - loss: 2.6131 - accuracy10: 0.5627 - val_loss: 3.0223 - val_accuracy10: 0.6982 - 14s/epoch - 26ms/step
Epoch 19/50
538/538 - 14s - loss: 2.5970 - accuracy10: 0.5666 - val_loss: 3.0456 - val_accuracy10: 0.6952 - 14s/epoch - 27ms/step
Epoch 20/50
538/538 - 14s - loss: 2.5918 - accuracy10: 0.5646 - val_loss: 3.0254 - val_accuracy10: 0.6925 - 14s/epoch - 27ms/step
Epoch 21/50
538/538 - 14s - loss: 2.5774 - accuracy10: 0.5689 - val_loss: 3.0575 - val_accuracy10: 0.7069 - 14s/epoch - 26ms/step
testing model: results/QRTEA/W7/deepOF_L1/h10
Evaluating performance on  test set...
2006/2006 - 35s - 35s/epoch - 18ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.7946616
{'0': {'precision': 0.27325163789913587, 'recall': 0.5196407136056956, 'f1-score': 0.35816381843599326, 'support': 48318}, '1': {'precision': 0.8818794980140519, 'recall': 0.7673241206632738, 'f1-score': 0.8206232422498688, 'support': 416962}, '2': {'precision': 0.3609993178717599, 'recall': 0.44060776355500053, 'f1-score': 0.3968505413132118, 'support': 48045}, 'accuracy': 0.713431062192568, 'macro avg': {'precision': 0.5053768179283159, 'recall': 0.57585753260799, 'f1-score': 0.5252125339996913, 'support': 513325}, 'weighted avg': {'precision': 0.7758387456642366, 'recall': 0.713431062192568, 'f1-score': 0.7374297997790354, 'support': 513325}}
[[ 25108  20653   2557]
 [ 62103 319945  34914]
 [  4675  22201  21169]]
Evaluating performance on  train set...
538/538 - 9s - 9s/epoch - 18ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.82231146
{'0': {'precision': 0.29292725289817023, 'recall': 0.5000689560060682, 'f1-score': 0.3694439491581548, 'support': 14502}, '1': {'precision': 0.8600349672714868, 'recall': 0.739623921593795, 'f1-score': 0.795297597042514, 'support': 109073}, '2': {'precision': 0.3125526981450253, 'recall': 0.4248567335243553, 'f1-score': 0.36015302404663585, 'support': 13960}, 'accuracy': 0.6824153851746828, 'macro avg': {'precision': 0.48850497277156074, 'recall': 0.5548498703747395, 'f1-score': 0.5082981900824349, 'support': 137535}, 'weighted avg': {'precision': 0.7446676167727247, 'recall': 0.6824153851746828, 'f1-score': 0.7062268307601755, 'support': 137535}}
[[ 7252  6328   922]
 [16277 80673 12123]
 [ 1228  6801  5931]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 18ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.8448461
{'0': {'precision': 0.2881154049761779, 'recall': 0.5011510128913443, 'f1-score': 0.3658823529411765, 'support': 4344}, '1': {'precision': 0.8429252412510173, 'recall': 0.7171827084775942, 'f1-score': 0.774986638161411, 'support': 30327}, '2': {'precision': 0.3148831488314883, 'recall': 0.4092258506508335, 'f1-score': 0.3559086395233366, 'support': 4379}, 'accuracy': 0.658617157490397, 'macro avg': {'precision': 0.48197459835289447, 'recall': 0.542519857339924, 'f1-score': 0.49892587687530804, 'support': 39050}, 'weighted avg': {'precision': 0.7219933526086865, 'recall': 0.658617157490397, 'f1-score': 0.6824823725779839, 'support': 39050}}
[[ 2177  1893   274]
 [ 4952 21750  3625]
 [  427  2160  1792]]
training model: results/QRTEA/W7/deepOF_L1/h20
Epoch 1/50
538/538 - 16s - loss: 3.0625 - accuracy20: 0.4020 - val_loss: 3.1590 - val_accuracy20: 0.5400 - 16s/epoch - 29ms/step
Epoch 2/50
538/538 - 14s - loss: 2.9359 - accuracy20: 0.4347 - val_loss: 3.1081 - val_accuracy20: 0.5436 - 14s/epoch - 25ms/step
Epoch 3/50
538/538 - 14s - loss: 2.8964 - accuracy20: 0.4485 - val_loss: 3.0973 - val_accuracy20: 0.5483 - 14s/epoch - 26ms/step
Epoch 4/50
538/538 - 14s - loss: 2.8660 - accuracy20: 0.4607 - val_loss: 3.0708 - val_accuracy20: 0.5669 - 14s/epoch - 26ms/step
Epoch 5/50
538/538 - 14s - loss: 2.8377 - accuracy20: 0.4757 - val_loss: 3.0538 - val_accuracy20: 0.5745 - 14s/epoch - 26ms/step
Epoch 6/50
538/538 - 14s - loss: 2.8181 - accuracy20: 0.4873 - val_loss: 3.0368 - val_accuracy20: 0.5822 - 14s/epoch - 27ms/step
Epoch 7/50
538/538 - 14s - loss: 2.7989 - accuracy20: 0.4972 - val_loss: 3.0262 - val_accuracy20: 0.5905 - 14s/epoch - 26ms/step
Epoch 8/50
538/538 - 14s - loss: 2.7857 - accuracy20: 0.5025 - val_loss: 3.0500 - val_accuracy20: 0.6118 - 14s/epoch - 25ms/step
Epoch 9/50
538/538 - 14s - loss: 2.7717 - accuracy20: 0.5063 - val_loss: 3.0269 - val_accuracy20: 0.6109 - 14s/epoch - 25ms/step
Epoch 10/50
538/538 - 13s - loss: 2.7602 - accuracy20: 0.5122 - val_loss: 3.0323 - val_accuracy20: 0.6133 - 13s/epoch - 25ms/step
Epoch 11/50
538/538 - 13s - loss: 2.7452 - accuracy20: 0.5170 - val_loss: 3.0486 - val_accuracy20: 0.6196 - 13s/epoch - 24ms/step
Epoch 12/50
538/538 - 13s - loss: 2.7395 - accuracy20: 0.5195 - val_loss: 3.0423 - val_accuracy20: 0.6324 - 13s/epoch - 24ms/step
Epoch 13/50
538/538 - 13s - loss: 2.7286 - accuracy20: 0.5258 - val_loss: 3.0533 - val_accuracy20: 0.6297 - 13s/epoch - 24ms/step
Epoch 14/50
538/538 - 13s - loss: 2.7158 - accuracy20: 0.5260 - val_loss: 3.0679 - val_accuracy20: 0.6344 - 13s/epoch - 25ms/step
Epoch 15/50
538/538 - 13s - loss: 2.7082 - accuracy20: 0.5292 - val_loss: 3.0744 - val_accuracy20: 0.6421 - 13s/epoch - 24ms/step
Epoch 16/50
538/538 - 13s - loss: 2.6972 - accuracy20: 0.5312 - val_loss: 3.1045 - val_accuracy20: 0.6529 - 13s/epoch - 23ms/step
Epoch 17/50
538/538 - 13s - loss: 2.6912 - accuracy20: 0.5334 - val_loss: 3.1162 - val_accuracy20: 0.6521 - 13s/epoch - 24ms/step
testing model: results/QRTEA/W7/deepOF_L1/h20
Evaluating performance on  test set...
2006/2006 - 32s - 32s/epoch - 16ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.8812329
{'0': {'precision': 0.3245807327001357, 'recall': 0.44609876174847085, 'f1-score': 0.37575947975244256, 'support': 67030}, '1': {'precision': 0.8103974356313216, 'recall': 0.7183512113318736, 'f1-score': 0.7616032638228976, 'support': 380449}, '2': {'precision': 0.3586460702928671, 'recall': 0.4573246666464174, 'f1-score': 0.40201857031286503, 'support': 65846}, 'accuracy': 0.649317683728632, 'macro avg': {'precision': 0.4978747462081081, 'recall': 0.5405915465755874, 'f1-score': 0.5131271046294018, 'support': 513325}, 'weighted avg': {'precision': 0.6890117365136997, 'recall': 0.649317683728632, 'f1-score': 0.6650945752238536, 'support': 513325}}
[[ 29902  33246   3882]
 [ 57185 273296  49968]
 [  5038  30695  30113]]
Evaluating performance on  train set...
538/538 - 9s - 9s/epoch - 17ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.9044972
{'0': {'precision': 0.347269241750622, 'recall': 0.4352093237233553, 'f1-score': 0.38629764065335753, 'support': 19563}, '1': {'precision': 0.7851110052627299, 'recall': 0.6816416691042232, 'f1-score': 0.7297268113594646, 'support': 99143}, '2': {'precision': 0.3180282840280613, 'recall': 0.45504275319985127, 'f1-score': 0.37439370766877866, 'support': 18829}, 'accuracy': 0.6155669465954121, 'macro avg': {'precision': 0.48346951034713775, 'recall': 0.5239645820091433, 'f1-score': 0.4968060532272003, 'support': 137535}, 'weighted avg': {'precision': 0.6588871424080752, 'recall': 0.6155669465954121, 'f1-score': 0.6322311057142433, 'support': 137535}}
[[ 8514  9591  1458]
 [14648 67580 16915]
 [ 1355  8906  8568]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 18ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.9228857
{'0': {'precision': 0.35170639219934996, 'recall': 0.4417417928219085, 'f1-score': 0.39161577320364926, 'support': 5879}, '1': {'precision': 0.7610679570440172, 'recall': 0.6572821584368929, 'f1-score': 0.7053778669499194, 'support': 27279}, '2': {'precision': 0.3212038978660417, 'recall': 0.4419551934826884, 'f1-score': 0.3720265733266663, 'support': 5892}, 'accuracy': 0.5923431498079386, 'macro avg': {'precision': 0.47799274903646954, 'recall': 0.5136597149138299, 'f1-score': 0.4896734044934117, 'support': 39050}, 'weighted avg': {'precision': 0.6330701164192175, 'recall': 0.5923431498079386, 'f1-score': 0.6078435988023515, 'support': 39050}}
[[ 2597  2824   458]
 [ 4304 17930  5045]
 [  483  2805  2604]]
training model: results/QRTEA/W7/deepOF_L1/h30
Epoch 1/50
538/538 - 16s - loss: 3.1057 - accuracy30: 0.3952 - val_loss: 3.2152 - val_accuracy30: 0.5292 - 16s/epoch - 29ms/step
Epoch 2/50
538/538 - 13s - loss: 2.9940 - accuracy30: 0.4216 - val_loss: 3.1590 - val_accuracy30: 0.5217 - 13s/epoch - 25ms/step
Epoch 3/50
538/538 - 13s - loss: 2.9559 - accuracy30: 0.4320 - val_loss: 3.1282 - val_accuracy30: 0.5225 - 13s/epoch - 25ms/step
Epoch 4/50
538/538 - 13s - loss: 2.9230 - accuracy30: 0.4452 - val_loss: 3.1095 - val_accuracy30: 0.5507 - 13s/epoch - 25ms/step
Epoch 5/50
538/538 - 13s - loss: 2.8981 - accuracy30: 0.4586 - val_loss: 3.0973 - val_accuracy30: 0.5515 - 13s/epoch - 25ms/step
Epoch 6/50
538/538 - 14s - loss: 2.8787 - accuracy30: 0.4663 - val_loss: 3.0764 - val_accuracy30: 0.5502 - 14s/epoch - 25ms/step
Epoch 7/50
538/538 - 13s - loss: 2.8603 - accuracy30: 0.4750 - val_loss: 3.0910 - val_accuracy30: 0.5660 - 13s/epoch - 25ms/step
Epoch 8/50
538/538 - 13s - loss: 2.8494 - accuracy30: 0.4803 - val_loss: 3.0775 - val_accuracy30: 0.5705 - 13s/epoch - 25ms/step
Epoch 9/50
538/538 - 13s - loss: 2.8348 - accuracy30: 0.4872 - val_loss: 3.0937 - val_accuracy30: 0.5745 - 13s/epoch - 24ms/step
Epoch 10/50
538/538 - 13s - loss: 2.8229 - accuracy30: 0.4916 - val_loss: 3.0848 - val_accuracy30: 0.5803 - 13s/epoch - 25ms/step
Epoch 11/50
538/538 - 13s - loss: 2.8092 - accuracy30: 0.4992 - val_loss: 3.1092 - val_accuracy30: 0.5855 - 13s/epoch - 24ms/step
Epoch 12/50
538/538 - 14s - loss: 2.8006 - accuracy30: 0.5012 - val_loss: 3.0889 - val_accuracy30: 0.5831 - 14s/epoch - 25ms/step
Epoch 13/50
538/538 - 13s - loss: 2.7901 - accuracy30: 0.5049 - val_loss: 3.1092 - val_accuracy30: 0.5952 - 13s/epoch - 25ms/step
Epoch 14/50
538/538 - 13s - loss: 2.7800 - accuracy30: 0.5069 - val_loss: 3.1218 - val_accuracy30: 0.5986 - 13s/epoch - 25ms/step
Epoch 15/50
538/538 - 14s - loss: 2.7682 - accuracy30: 0.5106 - val_loss: 3.1285 - val_accuracy30: 0.5945 - 14s/epoch - 26ms/step
Epoch 16/50
538/538 - 13s - loss: 2.7595 - accuracy30: 0.5130 - val_loss: 3.1520 - val_accuracy30: 0.6093 - 13s/epoch - 25ms/step
testing model: results/QRTEA/W7/deepOF_L1/h30
Evaluating performance on  test set...
2006/2006 - 32s - 32s/epoch - 16ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.92467684
{'0': {'precision': 0.34022176971162826, 'recall': 0.4608759546122528, 'f1-score': 0.39146293425825035, 'support': 83018}, '1': {'precision': 0.7451806825892899, 'recall': 0.66958941284577, 'f1-score': 0.7053656241801387, 'support': 349329}, '2': {'precision': 0.3935704184057121, 'recall': 0.42270740201042256, 'f1-score': 0.407618888842579, 'support': 80978}, 'accuracy': 0.596888910534262, 'macro avg': {'precision': 0.4929909569022101, 'recall': 0.5177242564894818, 'f1-score': 0.5014824824269893, 'support': 513325}, 'weighted avg': {'precision': 0.6242211053188755, 'recall': 0.596888910534262, 'f1-score': 0.6076292804483894, 'support': 513325}}
[[ 38261  40075   4682]
 [ 67361 233907  48061]
 [  6837  39911  34230]]
Evaluating performance on  train set...
538/538 - 8s - 8s/epoch - 15ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.94278014
{'0': {'precision': 0.3552773290253096, 'recall': 0.4460407335417899, 'f1-score': 0.3955187530443254, 'support': 23666}, '1': {'precision': 0.7220515626748915, 'recall': 0.6367614639656931, 'f1-score': 0.6767297650130549, 'support': 91177}, '2': {'precision': 0.3509264662970528, 'recall': 0.4239820200951877, 'f1-score': 0.3840105372395625, 'support': 22692}, 'accuracy': 0.5688370233031592, 'macro avg': {'precision': 0.476085119332418, 'recall': 0.5022614058675569, 'f1-score': 0.4854196850989809, 'support': 137535}, 'weighted avg': {'precision': 0.5977075796846931, 'recall': 0.5688370233031592, 'f1-score': 0.5800451063742499, 'support': 137535}}
[[10556 11260  1850]
 [17174 58058 15945]
 [ 1982 11089  9621]]
Evaluating performance on  val set...
153/153 - 2s - 2s/epoch - 16ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.9590311
{'0': {'precision': 0.3634649511978705, 'recall': 0.4610946953707612, 'f1-score': 0.4065000310115983, 'support': 7107}, '1': {'precision': 0.6932952924393724, 'recall': 0.6068637718520905, 'f1-score': 0.6472066499130098, 'support': 24826}, '2': {'precision': 0.3609538720944237, 'recall': 0.4211043979204721, 'f1-score': 0.38871595330739295, 'support': 7117}, 'accuracy': 0.5464788732394367, 'macro avg': {'precision': 0.47257137191055554, 'recall': 0.4963542883811079, 'f1-score': 0.48080754474400034, 'support': 39050}, 'weighted avg': {'precision': 0.5726966208952404, 'recall': 0.5464788732394367, 'f1-score': 0.5562878220442644, 'support': 39050}}
[[ 3277  3256   574]
 [ 5028 15066  4732]
 [  711  3409  2997]]
training model: results/QRTEA/W7/deepOF_L1/h50
Epoch 1/50
538/538 - 15s - loss: 3.1819 - accuracy50: 0.3885 - val_loss: 3.2620 - val_accuracy50: 0.4801 - 15s/epoch - 29ms/step
Epoch 2/50
538/538 - 13s - loss: 3.0846 - accuracy50: 0.4170 - val_loss: 3.2164 - val_accuracy50: 0.4814 - 13s/epoch - 25ms/step
Epoch 3/50
538/538 - 13s - loss: 3.0549 - accuracy50: 0.4238 - val_loss: 3.1887 - val_accuracy50: 0.4834 - 13s/epoch - 24ms/step
Epoch 4/50
538/538 - 13s - loss: 3.0280 - accuracy50: 0.4360 - val_loss: 3.1701 - val_accuracy50: 0.4894 - 13s/epoch - 25ms/step
Epoch 5/50
538/538 - 13s - loss: 3.0082 - accuracy50: 0.4428 - val_loss: 3.1649 - val_accuracy50: 0.4983 - 13s/epoch - 24ms/step
Epoch 6/50
538/538 - 13s - loss: 2.9895 - accuracy50: 0.4510 - val_loss: 3.1614 - val_accuracy50: 0.5081 - 13s/epoch - 24ms/step
Epoch 7/50
538/538 - 13s - loss: 2.9733 - accuracy50: 0.4578 - val_loss: 3.1652 - val_accuracy50: 0.5184 - 13s/epoch - 24ms/step
Epoch 8/50
538/538 - 14s - loss: 2.9617 - accuracy50: 0.4659 - val_loss: 3.1690 - val_accuracy50: 0.5243 - 14s/epoch - 25ms/step
Epoch 9/50
538/538 - 13s - loss: 2.9502 - accuracy50: 0.4688 - val_loss: 3.1760 - val_accuracy50: 0.5301 - 13s/epoch - 24ms/step
Epoch 10/50
538/538 - 13s - loss: 2.9389 - accuracy50: 0.4745 - val_loss: 3.1793 - val_accuracy50: 0.5323 - 13s/epoch - 24ms/step
Epoch 11/50
538/538 - 13s - loss: 2.9299 - accuracy50: 0.4796 - val_loss: 3.1900 - val_accuracy50: 0.5345 - 13s/epoch - 24ms/step
Epoch 12/50
538/538 - 14s - loss: 2.9205 - accuracy50: 0.4830 - val_loss: 3.1947 - val_accuracy50: 0.5375 - 14s/epoch - 25ms/step
Epoch 13/50
538/538 - 13s - loss: 2.9116 - accuracy50: 0.4867 - val_loss: 3.2156 - val_accuracy50: 0.5455 - 13s/epoch - 25ms/step
Epoch 14/50
538/538 - 13s - loss: 2.9023 - accuracy50: 0.4885 - val_loss: 3.2247 - val_accuracy50: 0.5469 - 13s/epoch - 24ms/step
Epoch 15/50
538/538 - 13s - loss: 2.8921 - accuracy50: 0.4929 - val_loss: 3.2385 - val_accuracy50: 0.5479 - 13s/epoch - 24ms/step
Epoch 16/50
538/538 - 13s - loss: 2.8846 - accuracy50: 0.4946 - val_loss: 3.2478 - val_accuracy50: 0.5502 - 13s/epoch - 25ms/step
testing model: results/QRTEA/W7/deepOF_L1/h50
Evaluating performance on  test set...
2006/2006 - 33s - 33s/epoch - 16ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.96922016
{'0': {'precision': 0.391976938096555, 'recall': 0.4245634099408198, 'f1-score': 0.40761994396587414, 'support': 110172}, '1': {'precision': 0.6312138876679895, 'recall': 0.6633244777689372, 'f1-score': 0.6468709365080147, 'support': 296612}, '2': {'precision': 0.4488717144836134, 'recall': 0.34671159459738504, 'f1-score': 0.3912325110944003, 'support': 106541}, 'accuracy': 0.5463673111576487, 'macro avg': {'precision': 0.4906875134160526, 'recall': 0.47819982743571404, 'f1-score': 0.4819077971894297, 'support': 513325}, 'weighted avg': {'precision': 0.5420225747932597, 'recall': 0.5463673111576487, 'f1-score': 0.5424639159414252, 'support': 513325}}
[[ 46775  56565   6832]
 [ 61340 196750  38522]
 [ 11216  58386  36939]]
Evaluating performance on  train set...
538/538 - 9s - 9s/epoch - 17ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.97884697
{'0': {'precision': 0.40228195212374956, 'recall': 0.413298308980463, 'f1-score': 0.40771572946359164, 'support': 30455}, '1': {'precision': 0.618854358473313, 'recall': 0.6325054410446805, 'f1-score': 0.6256054399371925, 'support': 78110}, '2': {'precision': 0.4076780373301026, 'recall': 0.3716948567483604, 'f1-score': 0.3888557860715382, 'support': 28970}, 'accuracy': 0.5290289744428691, 'macro avg': {'precision': 0.476271449309055, 'recall': 0.47249953559116803, 'f1-score': 0.4740589851574408, 'support': 137535}, 'weighted avg': {'precision': 0.5264161379556648, 'recall': 0.5290289744428691, 'f1-score': 0.5274888252212182, 'support': 137535}}
[[12587 15310  2558]
 [15618 49405 13087]
 [ 3084 15118 10768]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 17ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.9936212
{'0': {'precision': 0.4137857674715456, 'recall': 0.42695642629788166, 'f1-score': 0.4202679343128781, 'support': 9111}, '1': {'precision': 0.5786926055688734, 'recall': 0.6038870447876077, 'f1-score': 0.5910214458909108, 'support': 20787}, '2': {'precision': 0.4215156466004776, 'recall': 0.3664772727272727, 'f1-score': 0.3920743468349991, 'support': 9152}, 'accuracy': 0.5069654289372599, 'macro avg': {'precision': 0.4713313398802989, 'recall': 0.46577358127092067, 'f1-score': 0.4677879090129293, 'support': 39050}, 'weighted avg': {'precision': 0.503380192498873, 'recall': 0.5069654289372599, 'f1-score': 0.5045553999357978, 'support': 39050}}
[[ 3890  4462   759]
 [ 4390 12553  3844]
 [ 1121  4677  3354]]
training model: results/QRTEA/W7/deepOF_L1/h100
Epoch 1/50
538/538 - 16s - loss: 3.2727 - accuracy100: 0.3776 - val_loss: 3.3042 - val_accuracy100: 0.4037 - 16s/epoch - 30ms/step
Epoch 2/50
538/538 - 14s - loss: 3.2080 - accuracy100: 0.4023 - val_loss: 3.2640 - val_accuracy100: 0.4135 - 14s/epoch - 26ms/step
Epoch 3/50
538/538 - 14s - loss: 3.1862 - accuracy100: 0.4136 - val_loss: 3.2567 - val_accuracy100: 0.4177 - 14s/epoch - 25ms/step
Epoch 4/50
538/538 - 14s - loss: 3.1717 - accuracy100: 0.4189 - val_loss: 3.2433 - val_accuracy100: 0.4209 - 14s/epoch - 26ms/step
Epoch 5/50
538/538 - 13s - loss: 3.1593 - accuracy100: 0.4258 - val_loss: 3.2460 - val_accuracy100: 0.4239 - 13s/epoch - 25ms/step
Epoch 6/50
538/538 - 14s - loss: 3.1493 - accuracy100: 0.4297 - val_loss: 3.2452 - val_accuracy100: 0.4225 - 14s/epoch - 26ms/step
Epoch 7/50
538/538 - 14s - loss: 3.1408 - accuracy100: 0.4338 - val_loss: 3.2535 - val_accuracy100: 0.4261 - 14s/epoch - 26ms/step
Epoch 8/50
538/538 - 14s - loss: 3.1311 - accuracy100: 0.4384 - val_loss: 3.2561 - val_accuracy100: 0.4279 - 14s/epoch - 26ms/step
Epoch 9/50
538/538 - 14s - loss: 3.1237 - accuracy100: 0.4438 - val_loss: 3.2641 - val_accuracy100: 0.4269 - 14s/epoch - 26ms/step
Epoch 10/50
538/538 - 14s - loss: 3.1145 - accuracy100: 0.4467 - val_loss: 3.2771 - val_accuracy100: 0.4278 - 14s/epoch - 25ms/step
Epoch 11/50
538/538 - 14s - loss: 3.1090 - accuracy100: 0.4496 - val_loss: 3.2788 - val_accuracy100: 0.4283 - 14s/epoch - 26ms/step
Epoch 12/50
538/538 - 14s - loss: 3.1012 - accuracy100: 0.4531 - val_loss: 3.2850 - val_accuracy100: 0.4297 - 14s/epoch - 25ms/step
Epoch 13/50
538/538 - 13s - loss: 3.0929 - accuracy100: 0.4569 - val_loss: 3.2846 - val_accuracy100: 0.4309 - 13s/epoch - 25ms/step
Epoch 14/50
538/538 - 14s - loss: 3.0867 - accuracy100: 0.4595 - val_loss: 3.2936 - val_accuracy100: 0.4336 - 14s/epoch - 25ms/step
testing model: results/QRTEA/W7/deepOF_L1/h100
Evaluating performance on  test set...
2006/2006 - 34s - 34s/epoch - 17ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0524133
{'0': {'precision': 0.4329546031799787, 'recall': 0.3313312729605225, 'f1-score': 0.3753867611165147, 'support': 154341}, '1': {'precision': 0.44037301930668976, 'recall': 0.6172779259666362, 'f1-score': 0.5140307305054219, 'support': 211067}, '2': {'precision': 0.4647174274067737, 'recall': 0.31214802896218824, 'f1-score': 0.3734510983855835, 'support': 147917}, 'accuracy': 0.44337797691520964, 'macro avg': {'precision': 0.44601501663114734, 'recall': 0.420252409296449, 'f1-score': 0.42095619666917333, 'support': 513325}, 'weighted avg': {'precision': 0.4451574853847639, 'recall': 0.44337797691520964, 'f1-score': 0.4318360851565231, 'support': 513325}}
[[ 51138  84670  18533]
 [ 46130 130287  34650]
 [ 20846  80899  46172]]
Evaluating performance on  train set...
538/538 - 9s - 9s/epoch - 18ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0527738
{'0': {'precision': 0.4453923188454665, 'recall': 0.3171352428513121, 'f1-score': 0.3704773657934594, 'support': 41651}, '1': {'precision': 0.4377726422933112, 'recall': 0.5941674008810572, 'f1-score': 0.5041188870782065, 'support': 56750}, '2': {'precision': 0.4348544759188436, 'recall': 0.3428476516584045, 'f1-score': 0.3834085843287421, 'support': 39134}, 'accuracy': 0.4387610426436907, 'macro avg': {'precision': 0.43933981235254044, 'recall': 0.41805009846359126, 'f1-score': 0.41933494573346936, 'support': 137535}, 'weighted avg': {'precision': 0.43924984900560554, 'recall': 0.4387610426436907, 'f1-score': 0.42930025915928743, 'support': 137535}}
[[13209 22675  5767]
 [11361 33719 11670]
 [ 5087 20630 13417]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 17ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0620953
{'0': {'precision': 0.4475280898876404, 'recall': 0.32920076039342094, 'f1-score': 0.37935139768560405, 'support': 12099}, '1': {'precision': 0.3978067234939182, 'recall': 0.5637597556837461, 'f1-score': 0.46646264424291767, 'support': 14735}, '2': {'precision': 0.44108761329305135, 'recall': 0.3346430910281598, 'f1-score': 0.3805622789052318, 'support': 12216}, 'accuracy': 0.4194110115236876, 'macro avg': {'precision': 0.42880747555820325, 'recall': 0.4092012023684423, 'f1-score': 0.4087921069445845, 'support': 39050}, 'weighted avg': {'precision': 0.42675161880208345, 'recall': 0.4194110115236876, 'f1-score': 0.41260047177013637, 'support': 39050}}
[[3983 6211 1905]
 [3153 8307 3275]
 [1764 6364 4088]]
training model: results/QRTEA/W7/deepOF_L1/h200
Epoch 1/50
538/538 - 15s - loss: 3.3202 - accuracy200: 0.3543 - val_loss: 3.3170 - val_accuracy200: 0.3414 - 15s/epoch - 28ms/step
Epoch 2/50
538/538 - 13s - loss: 3.2829 - accuracy200: 0.3771 - val_loss: 3.2925 - val_accuracy200: 0.3532 - 13s/epoch - 25ms/step
Epoch 3/50
538/538 - 13s - loss: 3.2691 - accuracy200: 0.3837 - val_loss: 3.2876 - val_accuracy200: 0.3555 - 13s/epoch - 24ms/step
Epoch 4/50
538/538 - 12s - loss: 3.2562 - accuracy200: 0.3923 - val_loss: 3.2819 - val_accuracy200: 0.3561 - 12s/epoch - 23ms/step
Epoch 5/50
538/538 - 13s - loss: 3.2488 - accuracy200: 0.3970 - val_loss: 3.2789 - val_accuracy200: 0.3577 - 13s/epoch - 24ms/step
Epoch 6/50
538/538 - 13s - loss: 3.2424 - accuracy200: 0.3990 - val_loss: 3.2802 - val_accuracy200: 0.3557 - 13s/epoch - 25ms/step
Epoch 7/50
538/538 - 13s - loss: 3.2365 - accuracy200: 0.4030 - val_loss: 3.2824 - val_accuracy200: 0.3471 - 13s/epoch - 24ms/step
Epoch 8/50
538/538 - 13s - loss: 3.2295 - accuracy200: 0.4058 - val_loss: 3.2877 - val_accuracy200: 0.3492 - 13s/epoch - 24ms/step
Epoch 9/50
538/538 - 13s - loss: 3.2239 - accuracy200: 0.4105 - val_loss: 3.2927 - val_accuracy200: 0.3447 - 13s/epoch - 25ms/step
Epoch 10/50
538/538 - 13s - loss: 3.2195 - accuracy200: 0.4128 - val_loss: 3.2982 - val_accuracy200: 0.3427 - 13s/epoch - 24ms/step
Epoch 11/50
538/538 - 13s - loss: 3.2152 - accuracy200: 0.4140 - val_loss: 3.3049 - val_accuracy200: 0.3422 - 13s/epoch - 24ms/step
Epoch 12/50
538/538 - 13s - loss: 3.2110 - accuracy200: 0.4166 - val_loss: 3.3075 - val_accuracy200: 0.3429 - 13s/epoch - 24ms/step
Epoch 13/50
538/538 - 13s - loss: 3.2083 - accuracy200: 0.4181 - val_loss: 3.3127 - val_accuracy200: 0.3410 - 13s/epoch - 24ms/step
Epoch 14/50
538/538 - 13s - loss: 3.2034 - accuracy200: 0.4190 - val_loss: 3.3101 - val_accuracy200: 0.3416 - 13s/epoch - 25ms/step
Epoch 15/50
538/538 - 13s - loss: 3.1990 - accuracy200: 0.4208 - val_loss: 3.3156 - val_accuracy200: 0.3421 - 13s/epoch - 25ms/step
testing model: results/QRTEA/W7/deepOF_L1/h200
Evaluating performance on  test set...
2006/2006 - 33s - 33s/epoch - 17ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0875425
{'0': {'precision': 0.44054251434533126, 'recall': 0.23820026964365293, 'f1-score': 0.3092109358123323, 'support': 177271}, '1': {'precision': 0.33675816194780045, 'recall': 0.7019692891815255, 'f1-score': 0.4551605665404572, 'support': 166456}, '2': {'precision': 0.46518390331777754, 'recall': 0.19336902557813182, 'f1-score': 0.2731812559090701, 'support': 169598}, 'accuracy': 0.3737748989431647, 'macro avg': {'precision': 0.41416152653696975, 'recall': 0.3778461948011034, 'f1-score': 0.34585091942061985, 'support': 513325}, 'weighted avg': {'precision': 0.41502963678095306, 'recall': 0.3737748989431647, 'f1-score': 0.3446341668652662, 'support': 513325}}
[[ 42226 116764  18281]
 [ 30186 116847  19423]
 [ 23438 113365  32795]]
Evaluating performance on  train set...
538/538 - 9s - 9s/epoch - 17ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0858094
{'0': {'precision': 0.46230684551718515, 'recall': 0.23350494233937397, 'f1-score': 0.3102877392696376, 'support': 48560}, '1': {'precision': 0.3336314360188023, 'recall': 0.696437108708025, 'f1-score': 0.4511414582350166, 'support': 43925}, '2': {'precision': 0.45128301355725475, 'recall': 0.21354051054384018, 'f1-score': 0.28990311449967604, 'support': 45050}, 'accuracy': 0.37481368378958085, 'macro avg': {'precision': 0.4157404316977474, 'recall': 0.3811608538637464, 'f1-score': 0.35044410400144343, 'support': 137535}, 'weighted avg': {'precision': 0.4176004726520138, 'recall': 0.37481368378958085, 'f1-score': 0.3485956046105872, 'support': 137535}}
[[11339 31745  5476]
 [ 7113 30591  6221]
 [ 6075 29355  9620]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 20ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0936415
{'0': {'precision': 0.4338009352037408, 'recall': 0.24338505359418333, 'f1-score': 0.3118217612599635, 'support': 13341}, '1': {'precision': 0.30931290399808475, 'recall': 0.6516476126429052, 'f1-score': 0.41950321987120515, 'support': 11896}, '2': {'precision': 0.44871597724127327, 'recall': 0.2112502714833852, 'f1-score': 0.2872612719039181, 'support': 13813}, 'accuracy': 0.35638924455825866, 'macro avg': {'precision': 0.3972766054810329, 'recall': 0.3687609792401579, 'f1-score': 0.33952875101169555, 'support': 39050}, 'weighted avg': {'precision': 0.40115335150187015, 'recall': 0.35638924455825866, 'f1-score': 0.3359376278966927, 'support': 39050}}
[[3247 8425 1669]
 [2228 7752 1916]
 [2010 8885 2918]]
training model: results/QRTEA/W7/deepOF_L1/h300
Epoch 1/50
538/538 - 16s - loss: 3.3243 - accuracy300: 0.3465 - val_loss: 3.3255 - val_accuracy300: 0.3455 - 16s/epoch - 29ms/step
Epoch 2/50
538/538 - 14s - loss: 3.2967 - accuracy300: 0.3597 - val_loss: 3.3162 - val_accuracy300: 0.3477 - 14s/epoch - 25ms/step
Epoch 3/50
538/538 - 14s - loss: 3.2847 - accuracy300: 0.3642 - val_loss: 3.3068 - val_accuracy300: 0.3507 - 14s/epoch - 26ms/step
Epoch 4/50
538/538 - 14s - loss: 3.2770 - accuracy300: 0.3707 - val_loss: 3.3032 - val_accuracy300: 0.3553 - 14s/epoch - 26ms/step
Epoch 5/50
538/538 - 14s - loss: 3.2712 - accuracy300: 0.3737 - val_loss: 3.2982 - val_accuracy300: 0.3559 - 14s/epoch - 25ms/step
Epoch 6/50
538/538 - 14s - loss: 3.2668 - accuracy300: 0.3763 - val_loss: 3.2910 - val_accuracy300: 0.3598 - 14s/epoch - 26ms/step
Epoch 7/50
538/538 - 14s - loss: 3.2616 - accuracy300: 0.3805 - val_loss: 3.2913 - val_accuracy300: 0.3584 - 14s/epoch - 25ms/step
Epoch 8/50
538/538 - 14s - loss: 3.2578 - accuracy300: 0.3829 - val_loss: 3.2891 - val_accuracy300: 0.3602 - 14s/epoch - 26ms/step
Epoch 9/50
538/538 - 13s - loss: 3.2551 - accuracy300: 0.3857 - val_loss: 3.2885 - val_accuracy300: 0.3612 - 13s/epoch - 25ms/step
Epoch 10/50
538/538 - 13s - loss: 3.2517 - accuracy300: 0.3864 - val_loss: 3.2862 - val_accuracy300: 0.3648 - 13s/epoch - 25ms/step
Epoch 11/50
538/538 - 14s - loss: 3.2511 - accuracy300: 0.3881 - val_loss: 3.2879 - val_accuracy300: 0.3610 - 14s/epoch - 25ms/step
Epoch 12/50
538/538 - 14s - loss: 3.2467 - accuracy300: 0.3904 - val_loss: 3.2853 - val_accuracy300: 0.3606 - 14s/epoch - 25ms/step
Epoch 13/50
538/538 - 14s - loss: 3.2449 - accuracy300: 0.3917 - val_loss: 3.2876 - val_accuracy300: 0.3612 - 14s/epoch - 25ms/step
Epoch 14/50
538/538 - 13s - loss: 3.2425 - accuracy300: 0.3916 - val_loss: 3.2873 - val_accuracy300: 0.3622 - 13s/epoch - 25ms/step
Epoch 15/50
538/538 - 13s - loss: 3.2404 - accuracy300: 0.3935 - val_loss: 3.2875 - val_accuracy300: 0.3597 - 13s/epoch - 23ms/step
Epoch 16/50
538/538 - 13s - loss: 3.2378 - accuracy300: 0.3939 - val_loss: 3.2872 - val_accuracy300: 0.3619 - 13s/epoch - 24ms/step
Epoch 17/50
538/538 - 13s - loss: 3.2350 - accuracy300: 0.3965 - val_loss: 3.2899 - val_accuracy300: 0.3606 - 13s/epoch - 24ms/step
Epoch 18/50
538/538 - 13s - loss: 3.2336 - accuracy300: 0.3964 - val_loss: 3.2908 - val_accuracy300: 0.3583 - 13s/epoch - 24ms/step
Epoch 19/50
538/538 - 13s - loss: 3.2312 - accuracy300: 0.3998 - val_loss: 3.2923 - val_accuracy300: 0.3596 - 13s/epoch - 25ms/step
Epoch 20/50
538/538 - 13s - loss: 3.2291 - accuracy300: 0.4003 - val_loss: 3.2957 - val_accuracy300: 0.3610 - 13s/epoch - 25ms/step
Epoch 21/50
538/538 - 13s - loss: 3.2265 - accuracy300: 0.4013 - val_loss: 3.2959 - val_accuracy300: 0.3588 - 13s/epoch - 25ms/step
Epoch 22/50
538/538 - 13s - loss: 3.2243 - accuracy300: 0.4018 - val_loss: 3.2962 - val_accuracy300: 0.3619 - 13s/epoch - 24ms/step
testing model: results/QRTEA/W7/deepOF_L1/h300
Evaluating performance on  test set...
2006/2006 - 32s - 32s/epoch - 16ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0885401
{'0': {'precision': 0.36715052775566037, 'recall': 0.5240712462261182, 'f1-score': 0.4317960809548621, 'support': 171574}, '1': {'precision': 0.3595711673481573, 'recall': 0.3803680289640938, 'f1-score': 0.36967733802500397, 'support': 177323}, '2': {'precision': 0.3880332999344392, 'recall': 0.19077651008344076, 'f1-score': 0.255792619532024, 'support': 164428}, 'accuracy': 0.3676696050260556, 'macro avg': {'precision': 0.37158499834608566, 'recall': 0.36507192842455094, 'f1-score': 0.3524220128372966, 'support': 513325}, 'weighted avg': {'precision': 0.37122147216373047, 'recall': 0.3676696050260556, 'f1-score': 0.3539604426995937, 'support': 513325}}
[[89917 60370 21287]
 [81690 67448 28185]
 [73298 59761 31369]]
Evaluating performance on  train set...
538/538 - 9s - 9s/epoch - 17ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0839638
{'0': {'precision': 0.3867715598453046, 'recall': 0.4998825162875147, 'f1-score': 0.43611222407543726, 'support': 46815}, '1': {'precision': 0.36572909520542723, 'recall': 0.40235644353131095, 'f1-score': 0.3831694534564512, 'support': 47699}, '2': {'precision': 0.3922942206654991, 'recall': 0.22389065805071942, 'f1-score': 0.285080060378252, 'support': 43021}, 'accuracy': 0.3797287963063947, 'macro avg': {'precision': 0.38159829190541034, 'recall': 0.3753765392898483, 'f1-score': 0.36812057930338016, 'support': 137535}, 'weighted avg': {'precision': 0.38120123862007527, 'recall': 0.3797287963063947, 'f1-score': 0.37050803655828435, 'support': 137535}}
[[23402 17015  6398]
 [19984 19192  8523]
 [17120 16269  9632]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 18ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0910373
{'0': {'precision': 0.3585770274344287, 'recall': 0.4718343383052999, 'f1-score': 0.4074822707184213, 'support': 12604}, '1': {'precision': 0.351865066493675, 'recall': 0.4076969332531569, 'f1-score': 0.3777290295623107, 'support': 13304}, '2': {'precision': 0.3931914893617021, 'recall': 0.21092679957388524, 'f1-score': 0.2745641838351822, 'support': 13142}, 'accuracy': 0.36217669654289375, 'macro avg': {'precision': 0.367877861096602, 'recall': 0.3634860237107807, 'f1-score': 0.35325849470530474, 'support': 39050}, 'weighted avg': {'precision': 0.3679395711038894, 'recall': 0.36217669654289375, 'f1-score': 0.35261295911380097, 'support': 39050}}
[[5947 4831 1826]
 [5428 5424 2452]
 [5210 5160 2772]]
training model: results/QRTEA/W7/deepOF_L1/h500
Epoch 1/50
538/538 - 15s - loss: 3.3175 - accuracy500: 0.3607 - val_loss: 3.3467 - val_accuracy500: 0.3171 - 15s/epoch - 29ms/step
Epoch 2/50
538/538 - 13s - loss: 3.2893 - accuracy500: 0.3730 - val_loss: 3.3537 - val_accuracy500: 0.3158 - 13s/epoch - 24ms/step
Epoch 3/50
538/538 - 13s - loss: 3.2845 - accuracy500: 0.3730 - val_loss: 3.3562 - val_accuracy500: 0.3141 - 13s/epoch - 25ms/step
Epoch 4/50
538/538 - 13s - loss: 3.2781 - accuracy500: 0.3763 - val_loss: 3.3433 - val_accuracy500: 0.3212 - 13s/epoch - 25ms/step
Epoch 5/50
538/538 - 13s - loss: 3.2716 - accuracy500: 0.3814 - val_loss: 3.3414 - val_accuracy500: 0.3221 - 13s/epoch - 25ms/step
Epoch 6/50
538/538 - 13s - loss: 3.2689 - accuracy500: 0.3832 - val_loss: 3.3388 - val_accuracy500: 0.3215 - 13s/epoch - 24ms/step
Epoch 7/50
538/538 - 13s - loss: 3.2653 - accuracy500: 0.3846 - val_loss: 3.3324 - val_accuracy500: 0.3282 - 13s/epoch - 25ms/step
Epoch 8/50
538/538 - 13s - loss: 3.2628 - accuracy500: 0.3870 - val_loss: 3.3269 - val_accuracy500: 0.3274 - 13s/epoch - 24ms/step
Epoch 9/50
538/538 - 14s - loss: 3.2604 - accuracy500: 0.3894 - val_loss: 3.3211 - val_accuracy500: 0.3288 - 14s/epoch - 26ms/step
Epoch 10/50
538/538 - 14s - loss: 3.2588 - accuracy500: 0.3906 - val_loss: 3.3194 - val_accuracy500: 0.3307 - 14s/epoch - 25ms/step
Epoch 11/50
538/538 - 14s - loss: 3.2570 - accuracy500: 0.3896 - val_loss: 3.3182 - val_accuracy500: 0.3317 - 14s/epoch - 25ms/step
Epoch 12/50
538/538 - 14s - loss: 3.2553 - accuracy500: 0.3938 - val_loss: 3.3205 - val_accuracy500: 0.3310 - 14s/epoch - 25ms/step
Epoch 13/50
538/538 - 13s - loss: 3.2536 - accuracy500: 0.3944 - val_loss: 3.3119 - val_accuracy500: 0.3357 - 13s/epoch - 25ms/step
Epoch 14/50
538/538 - 13s - loss: 3.2522 - accuracy500: 0.3951 - val_loss: 3.3167 - val_accuracy500: 0.3330 - 13s/epoch - 25ms/step
Epoch 15/50
538/538 - 14s - loss: 3.2506 - accuracy500: 0.3959 - val_loss: 3.3155 - val_accuracy500: 0.3349 - 14s/epoch - 26ms/step
Epoch 16/50
538/538 - 13s - loss: 3.2489 - accuracy500: 0.3962 - val_loss: 3.3166 - val_accuracy500: 0.3344 - 13s/epoch - 25ms/step
Epoch 17/50
538/538 - 13s - loss: 3.2461 - accuracy500: 0.3976 - val_loss: 3.3143 - val_accuracy500: 0.3353 - 13s/epoch - 25ms/step
Epoch 18/50
538/538 - 13s - loss: 3.2446 - accuracy500: 0.3985 - val_loss: 3.3161 - val_accuracy500: 0.3366 - 13s/epoch - 25ms/step
Epoch 19/50
538/538 - 13s - loss: 3.2430 - accuracy500: 0.4002 - val_loss: 3.3127 - val_accuracy500: 0.3359 - 13s/epoch - 25ms/step
Epoch 20/50
538/538 - 13s - loss: 3.2408 - accuracy500: 0.4026 - val_loss: 3.3130 - val_accuracy500: 0.3368 - 13s/epoch - 25ms/step
Epoch 21/50
538/538 - 13s - loss: 3.2389 - accuracy500: 0.4034 - val_loss: 3.3175 - val_accuracy500: 0.3349 - 13s/epoch - 25ms/step
Epoch 22/50
538/538 - 13s - loss: 3.2374 - accuracy500: 0.4026 - val_loss: 3.3162 - val_accuracy500: 0.3361 - 13s/epoch - 25ms/step
Epoch 23/50
538/538 - 14s - loss: 3.2357 - accuracy500: 0.4040 - val_loss: 3.3150 - val_accuracy500: 0.3366 - 14s/epoch - 26ms/step
testing model: results/QRTEA/W7/deepOF_L1/h500
Evaluating performance on  test set...
2006/2006 - 32s - 32s/epoch - 16ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0933095
{'0': {'precision': 0.40671087564179037, 'recall': 0.18782880167655097, 'f1-score': 0.25697869903378967, 'support': 185142}, '1': {'precision': 0.33024879798519424, 'recall': 0.11532874923376242, 'f1-score': 0.1709564633375474, 'support': 150084}, '2': {'precision': 0.3622492741269545, 'recall': 0.763575314852975, 'f1-score': 0.4913813506194118, 'support': 178099}, 'accuracy': 0.36638776603516293, 'macro avg': {'precision': 0.3664029825846464, 'recall': 0.35557762192109615, 'f1-score': 0.306438837663583, 'support': 513325}, 'weighted avg': {'precision': 0.368929156007634, 'recall': 0.36638776603516293, 'f1-score': 0.3131542537457419, 'support': 513325}}
[[ 34775  18374 131993]
 [ 25350  17309 107425]
 [ 25378  16729 135992]]
Evaluating performance on  train set...
538/538 - 9s - 9s/epoch - 16ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.092397
{'0': {'precision': 0.41038410107437634, 'recall': 0.1831275720164609, 'f1-score': 0.253247399945936, 'support': 48600}, '1': {'precision': 0.3966639841978199, 'recall': 0.1216786355475763, 'f1-score': 0.18623022892373217, 'support': 44560}, '2': {'precision': 0.3420076532359878, 'recall': 0.7875154929577465, 'f1-score': 0.4769027116284782, 'support': 44375}, 'accuracy': 0.35822154360708186, 'macro avg': {'precision': 0.38301857950272805, 'recall': 0.36410723350726126, 'f1-score': 0.3054601134993821, 'support': 137535}, 'weighted avg': {'precision': 0.38387758796245686, 'recall': 0.35822154360708186, 'f1-score': 0.3036957899205854, 'support': 137535}}
[[ 8900  4555 35145]
 [ 7050  5422 32088]
 [ 5737  3692 34946]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 17ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.099729
{'0': {'precision': 0.3279569892473118, 'recall': 0.17919474684637982, 'f1-score': 0.23175773829478152, 'support': 11574}, '1': {'precision': 0.43186180422264875, 'recall': 0.11624903125807284, 'f1-score': 0.18318746183594545, 'support': 15484}, '2': {'precision': 0.32197632887457106, 'recall': 0.7667611741160774, 'f1-score': 0.453514180024661, 'support': 11992}, 'accuracy': 0.33467349551856596, 'macro avg': {'precision': 0.3605983741148438, 'recall': 0.3540683174068433, 'f1-score': 0.28948646005179596, 'support': 39050}, 'weighted avg': {'precision': 0.36732042268875126, 'recall': 0.33467349551856596, 'f1-score': 0.28059873928162143, 'support': 39050}}
[[ 2074  1172  8328]
 [ 2649  1800 11035]
 [ 1601  1196  9195]]
training model: results/QRTEA/W7/deepOF_L1/h1000
Epoch 1/50
538/538 - 15s - loss: 3.3110 - accuracy1000: 0.3750 - val_loss: 3.4262 - val_accuracy1000: 0.3390 - 15s/epoch - 29ms/step
Epoch 2/50
538/538 - 13s - loss: 3.2821 - accuracy1000: 0.3840 - val_loss: 3.4086 - val_accuracy1000: 0.3389 - 13s/epoch - 25ms/step
Epoch 3/50
538/538 - 13s - loss: 3.2774 - accuracy1000: 0.3799 - val_loss: 3.4145 - val_accuracy1000: 0.3372 - 13s/epoch - 24ms/step
Epoch 4/50
538/538 - 13s - loss: 3.2728 - accuracy1000: 0.3796 - val_loss: 3.3972 - val_accuracy1000: 0.3434 - 13s/epoch - 25ms/step
Epoch 5/50
538/538 - 13s - loss: 3.2666 - accuracy1000: 0.3818 - val_loss: 3.3806 - val_accuracy1000: 0.3446 - 13s/epoch - 24ms/step
Epoch 6/50
538/538 - 13s - loss: 3.2604 - accuracy1000: 0.3875 - val_loss: 3.3642 - val_accuracy1000: 0.3448 - 13s/epoch - 24ms/step
Epoch 7/50
538/538 - 13s - loss: 3.2519 - accuracy1000: 0.3922 - val_loss: 3.3656 - val_accuracy1000: 0.3439 - 13s/epoch - 24ms/step
Epoch 8/50
538/538 - 13s - loss: 3.2485 - accuracy1000: 0.3935 - val_loss: 3.3607 - val_accuracy1000: 0.3451 - 13s/epoch - 25ms/step
Epoch 9/50
538/538 - 13s - loss: 3.2453 - accuracy1000: 0.3943 - val_loss: 3.3595 - val_accuracy1000: 0.3436 - 13s/epoch - 25ms/step
Epoch 10/50
538/538 - 13s - loss: 3.2412 - accuracy1000: 0.3954 - val_loss: 3.3638 - val_accuracy1000: 0.3418 - 13s/epoch - 25ms/step
Epoch 11/50
538/538 - 13s - loss: 3.2379 - accuracy1000: 0.3973 - val_loss: 3.3596 - val_accuracy1000: 0.3425 - 13s/epoch - 25ms/step
Epoch 12/50
538/538 - 13s - loss: 3.2353 - accuracy1000: 0.3977 - val_loss: 3.3637 - val_accuracy1000: 0.3435 - 13s/epoch - 25ms/step
Epoch 13/50
538/538 - 13s - loss: 3.2332 - accuracy1000: 0.3985 - val_loss: 3.3660 - val_accuracy1000: 0.3428 - 13s/epoch - 25ms/step
Epoch 14/50
538/538 - 13s - loss: 3.2330 - accuracy1000: 0.3990 - val_loss: 3.3665 - val_accuracy1000: 0.3426 - 13s/epoch - 25ms/step
Epoch 15/50
538/538 - 14s - loss: 3.2298 - accuracy1000: 0.4002 - val_loss: 3.3681 - val_accuracy1000: 0.3428 - 14s/epoch - 25ms/step
Epoch 16/50
538/538 - 14s - loss: 3.2293 - accuracy1000: 0.4021 - val_loss: 3.3638 - val_accuracy1000: 0.3429 - 14s/epoch - 25ms/step
Epoch 17/50
538/538 - 14s - loss: 3.2261 - accuracy1000: 0.4033 - val_loss: 3.3674 - val_accuracy1000: 0.3429 - 14s/epoch - 25ms/step
Epoch 18/50
538/538 - 13s - loss: 3.2250 - accuracy1000: 0.4038 - val_loss: 3.3686 - val_accuracy1000: 0.3423 - 13s/epoch - 25ms/step
Epoch 19/50
538/538 - 13s - loss: 3.2221 - accuracy1000: 0.4061 - val_loss: 3.3676 - val_accuracy1000: 0.3431 - 13s/epoch - 25ms/step
testing model: results/QRTEA/W7/deepOF_L1/h1000
Evaluating performance on  test set...
2006/2006 - 32s - 32s/epoch - 16ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0766821
{'0': {'precision': 0.41644818129765243, 'recall': 0.13600574769206544, 'f1-score': 0.20504640586398, 'support': 203212}, '1': {'precision': 0.2830317514510072, 'recall': 0.007190874788567463, 'f1-score': 0.01402541154178016, 'support': 115285}, '2': {'precision': 0.38442898002387227, 'recall': 0.8761471657051347, 'f1-score': 0.534384792864768, 'support': 194828}, 'accuracy': 0.3879900647737788, 'macro avg': {'precision': 0.3613029709241773, 'recall': 0.3397812627285892, 'f1-score': 0.2511522034235094, 'support': 513325}, 'weighted avg': {'precision': 0.37433227020694276, 'recall': 0.3879900647737788, 'f1-score': 0.2871434865285779, 'support': 513325}}
[[ 27638    990 174584]
 [ 15708    829  98748]
 [ 23020   1110 170698]]
Evaluating performance on  train set...
538/538 - 9s - 9s/epoch - 17ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1024648
{'0': {'precision': 0.4064337802869913, 'recall': 0.13749950260634278, 'f1-score': 0.20548271043320548, 'support': 50262}, '1': {'precision': 0.39503386004514673, 'recall': 0.008233163181294254, 'f1-score': 0.016130147245201284, 'support': 42511}, '2': {'precision': 0.33309373563458566, 'recall': 0.8903310844019481, 'f1-score': 0.48480904097757394, 'support': 44762}, 'accuracy': 0.34256007561711566, 'macro avg': {'precision': 0.37818712532224125, 'recall': 0.34535458339652836, 'f1-score': 0.23547396621866024, 'support': 137535}, 'weighted avg': {'precision': 0.37904097781393326, 'recall': 0.34256007561711566, 'f1-score': 0.23786456519120724, 'support': 137535}}
[[ 6911   267 43084]
 [ 5453   350 36708]
 [ 4640   269 39853]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 18ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1084057
{'0': {'precision': 0.3321845682557917, 'recall': 0.13576962203615306, 'f1-score': 0.1927563604043995, 'support': 12779}, '1': {'precision': 0.344, 'recall': 0.006607252612169637, 'f1-score': 0.012965475652042816, 'support': 13016}, '2': {'precision': 0.3464573964320815, 'recall': 0.8776310826103357, 'f1-score': 0.49679706183805944, 'support': 13255}, 'accuracy': 0.3445326504481434, 'macro avg': {'precision': 0.34088065489595776, 'recall': 0.3400026524195528, 'f1-score': 0.23417296596483392, 'support': 39050}, 'weighted avg': {'precision': 0.3409675643392574, 'recall': 0.3445326504481434, 'f1-score': 0.23603168285168472, 'support': 39050}}
[[ 1735    89 10955]
 [ 1941    86 10989]
 [ 1547    75 11633]]
training model: results/QRTEA/W7/deepLOB_L2/h10
Epoch 1/50
538/538 - 29s - loss: 3.1644 - accuracy10: 0.3828 - val_loss: 3.4962 - val_accuracy10: 0.3004 - 29s/epoch - 54ms/step
Epoch 2/50
538/538 - 27s - loss: 2.9028 - accuracy10: 0.4134 - val_loss: 3.5654 - val_accuracy10: 0.6501 - 27s/epoch - 49ms/step
Epoch 3/50
538/538 - 26s - loss: 2.7580 - accuracy10: 0.4815 - val_loss: 3.8397 - val_accuracy10: 0.7769 - 26s/epoch - 49ms/step
Epoch 4/50
538/538 - 27s - loss: 2.6692 - accuracy10: 0.5309 - val_loss: 3.4614 - val_accuracy10: 0.7619 - 27s/epoch - 51ms/step
Epoch 5/50
538/538 - 27s - loss: 2.5935 - accuracy10: 0.5598 - val_loss: 3.1289 - val_accuracy10: 0.6575 - 27s/epoch - 49ms/step
Epoch 6/50
538/538 - 27s - loss: 2.5266 - accuracy10: 0.5852 - val_loss: 3.0830 - val_accuracy10: 0.6550 - 27s/epoch - 50ms/step
Epoch 7/50
538/538 - 26s - loss: 2.4535 - accuracy10: 0.6084 - val_loss: 3.4218 - val_accuracy10: 0.7667 - 26s/epoch - 49ms/step
Epoch 8/50
538/538 - 27s - loss: 2.3982 - accuracy10: 0.6280 - val_loss: 3.4331 - val_accuracy10: 0.7628 - 27s/epoch - 50ms/step
Epoch 9/50
538/538 - 26s - loss: 2.3543 - accuracy10: 0.6359 - val_loss: 3.0415 - val_accuracy10: 0.7132 - 26s/epoch - 49ms/step
Epoch 10/50
538/538 - 27s - loss: 2.2978 - accuracy10: 0.6546 - val_loss: 3.3772 - val_accuracy10: 0.7490 - 27s/epoch - 50ms/step
Epoch 11/50
538/538 - 27s - loss: 2.2605 - accuracy10: 0.6651 - val_loss: 2.9987 - val_accuracy10: 0.6996 - 27s/epoch - 49ms/step
Epoch 12/50
538/538 - 27s - loss: 2.2295 - accuracy10: 0.6704 - val_loss: 2.8600 - val_accuracy10: 0.6705 - 27s/epoch - 49ms/step
Epoch 13/50
538/538 - 27s - loss: 2.1984 - accuracy10: 0.6765 - val_loss: 2.9112 - val_accuracy10: 0.7219 - 27s/epoch - 50ms/step
Epoch 14/50
538/538 - 26s - loss: 2.1704 - accuracy10: 0.6802 - val_loss: 3.4598 - val_accuracy10: 0.7570 - 26s/epoch - 49ms/step
Epoch 15/50
538/538 - 26s - loss: 2.1460 - accuracy10: 0.6842 - val_loss: 2.9801 - val_accuracy10: 0.7133 - 26s/epoch - 49ms/step
Epoch 16/50
538/538 - 27s - loss: 2.1257 - accuracy10: 0.6851 - val_loss: 2.9485 - val_accuracy10: 0.6781 - 27s/epoch - 50ms/step
Epoch 17/50
538/538 - 27s - loss: 2.1102 - accuracy10: 0.6867 - val_loss: 3.2511 - val_accuracy10: 0.7433 - 27s/epoch - 50ms/step
Epoch 18/50
538/538 - 27s - loss: 2.0901 - accuracy10: 0.6895 - val_loss: 2.8410 - val_accuracy10: 0.6731 - 27s/epoch - 50ms/step
Epoch 19/50
538/538 - 27s - loss: 2.0754 - accuracy10: 0.6905 - val_loss: 2.9202 - val_accuracy10: 0.6609 - 27s/epoch - 50ms/step
Epoch 20/50
538/538 - 27s - loss: 2.0605 - accuracy10: 0.6895 - val_loss: 2.9205 - val_accuracy10: 0.5642 - 27s/epoch - 50ms/step
Epoch 21/50
538/538 - 28s - loss: 2.0442 - accuracy10: 0.6917 - val_loss: 2.9666 - val_accuracy10: 0.6206 - 28s/epoch - 52ms/step
Epoch 22/50
538/538 - 27s - loss: 2.0281 - accuracy10: 0.6921 - val_loss: 2.9854 - val_accuracy10: 0.6180 - 27s/epoch - 50ms/step
Epoch 23/50
538/538 - 26s - loss: 2.0068 - accuracy10: 0.6953 - val_loss: 2.9684 - val_accuracy10: 0.6655 - 26s/epoch - 48ms/step
Epoch 24/50
538/538 - 26s - loss: 1.9896 - accuracy10: 0.6945 - val_loss: 2.9771 - val_accuracy10: 0.5744 - 26s/epoch - 48ms/step
Epoch 25/50
538/538 - 26s - loss: 1.9772 - accuracy10: 0.6955 - val_loss: 3.0827 - val_accuracy10: 0.6167 - 26s/epoch - 49ms/step
Epoch 26/50
538/538 - 26s - loss: 1.9604 - accuracy10: 0.6966 - val_loss: 3.1761 - val_accuracy10: 0.5802 - 26s/epoch - 49ms/step
Epoch 27/50
538/538 - 26s - loss: 1.9439 - accuracy10: 0.6978 - val_loss: 3.0604 - val_accuracy10: 0.5418 - 26s/epoch - 49ms/step
Epoch 28/50
538/538 - 26s - loss: 1.9327 - accuracy10: 0.6982 - val_loss: 3.1379 - val_accuracy10: 0.5761 - 26s/epoch - 49ms/step
testing model: results/QRTEA/W7/deepLOB_L2/h10
Evaluating performance on  test set...
2006/2006 - 40s - 40s/epoch - 20ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.8559668
{'0': {'precision': 0.26781137878011274, 'recall': 0.41091496098843106, 'f1-score': 0.32427709318372977, 'support': 48319}, '1': {'precision': 0.8968474103080075, 'recall': 0.7118726991474105, 'f1-score': 0.7937256244225738, 'support': 416965}, '2': {'precision': 0.24761147968140743, 'recall': 0.5577571493984931, 'f1-score': 0.3429661103716597, 'support': 48046}, 'accuracy': 0.6691192799953246, 'macro avg': {'precision': 0.4707567562565093, 'recall': 0.5601816031781115, 'f1-score': 0.4869896093259877, 'support': 513330}, 'weighted avg': {'precision': 0.7768708230633852, 'recall': 0.6691192799953246, 'f1-score': 0.7073475144484442, 'support': 513330}}
[[ 19855  21155   7309]
 [ 46020 296826  74119]
 [  8263  12985  26798]]
Evaluating performance on  train set...
538/538 - 12s - 12s/epoch - 22ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.9085981
{'0': {'precision': 0.3365375553670719, 'recall': 0.4958689161980143, 'f1-score': 0.40095438596491223, 'support': 14403}, '1': {'precision': 0.9102386760896356, 'recall': 0.6630150035722792, 'f1-score': 0.7672022724382075, 'support': 109174}, '2': {'precision': 0.23933900470198136, 'recall': 0.6308022922636103, 'f1-score': 0.34701396961755954, 'support': 13960}, 'accuracy': 0.642241724045166, 'macro avg': {'precision': 0.49537174538622963, 'recall': 0.596562070677968, 'f1-score': 0.5050568760068931, 'support': 137537}, 'weighted avg': {'precision': 0.7820638820026717, 'recall': 0.642241724045166, 'f1-score': 0.6861993640117395, 'support': 137537}}
[[ 7142  4499  2762]
 [11565 72384 25225]
 [ 2515  2639  8806]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 21ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.8427419
{'0': {'precision': 0.3181155900922778, 'recall': 0.45017182130584193, 'f1-score': 0.3727945361411497, 'support': 4365}, '1': {'precision': 0.8912299290895753, 'recall': 0.7220112912278385, 'f1-score': 0.7977456362740986, 'support': 30289}, '2': {'precision': 0.30401919616076784, 'recall': 0.5764331210191083, 'f1-score': 0.39808341842746053, 'support': 4396}, 'accuracy': 0.675236875800256, 'macro avg': {'precision': 0.504454905114207, 'recall': 0.5828720778509295, 'f1-score': 0.5228745302809029, 'support': 39050}, 'weighted avg': {'precision': 0.7610629003654207, 'recall': 0.675236875800256, 'f1-score': 0.705253276178474, 'support': 39050}}
[[ 1965  1637   763]
 [ 3382 21869  5038]
 [  830  1032  2534]]
training model: results/QRTEA/W7/deepLOB_L2/h20
Epoch 1/50
538/538 - 29s - loss: 3.1711 - accuracy20: 0.4008 - val_loss: 3.4899 - val_accuracy20: 0.4856 - 29s/epoch - 54ms/step
Epoch 2/50
538/538 - 26s - loss: 2.9233 - accuracy20: 0.4186 - val_loss: 3.4180 - val_accuracy20: 0.6692 - 26s/epoch - 49ms/step
Epoch 3/50
538/538 - 26s - loss: 2.8102 - accuracy20: 0.4781 - val_loss: 3.9741 - val_accuracy20: 0.6975 - 26s/epoch - 49ms/step
Epoch 4/50
538/538 - 26s - loss: 2.7586 - accuracy20: 0.5095 - val_loss: 3.8101 - val_accuracy20: 0.7032 - 26s/epoch - 49ms/step
Epoch 5/50
538/538 - 26s - loss: 2.7004 - accuracy20: 0.5406 - val_loss: 3.6014 - val_accuracy20: 0.7018 - 26s/epoch - 48ms/step
Epoch 6/50
538/538 - 26s - loss: 2.6322 - accuracy20: 0.5637 - val_loss: 2.9621 - val_accuracy20: 0.4589 - 26s/epoch - 49ms/step
Epoch 7/50
538/538 - 31s - loss: 2.5821 - accuracy20: 0.5820 - val_loss: 3.0269 - val_accuracy20: 0.4198 - 31s/epoch - 58ms/step
Epoch 8/50
538/538 - 27s - loss: 2.5339 - accuracy20: 0.5969 - val_loss: 3.0569 - val_accuracy20: 0.6851 - 27s/epoch - 50ms/step
Epoch 9/50
538/538 - 28s - loss: 2.4949 - accuracy20: 0.6050 - val_loss: 3.0256 - val_accuracy20: 0.4521 - 28s/epoch - 53ms/step
Epoch 10/50
538/538 - 27s - loss: 2.4461 - accuracy20: 0.6171 - val_loss: 3.0395 - val_accuracy20: 0.4538 - 27s/epoch - 49ms/step
Epoch 11/50
538/538 - 28s - loss: 2.4045 - accuracy20: 0.6279 - val_loss: 2.9844 - val_accuracy20: 0.4612 - 28s/epoch - 52ms/step
Epoch 12/50
538/538 - 27s - loss: 2.3689 - accuracy20: 0.6354 - val_loss: 2.7504 - val_accuracy20: 0.5699 - 27s/epoch - 50ms/step
Epoch 13/50
538/538 - 27s - loss: 2.3369 - accuracy20: 0.6401 - val_loss: 2.8424 - val_accuracy20: 0.6559 - 27s/epoch - 50ms/step
Epoch 14/50
538/538 - 27s - loss: 2.3091 - accuracy20: 0.6457 - val_loss: 2.7540 - val_accuracy20: 0.5732 - 27s/epoch - 50ms/step
Epoch 15/50
538/538 - 27s - loss: 2.2788 - accuracy20: 0.6520 - val_loss: 2.7456 - val_accuracy20: 0.6322 - 27s/epoch - 50ms/step
Epoch 16/50
538/538 - 27s - loss: 2.2570 - accuracy20: 0.6542 - val_loss: 2.9984 - val_accuracy20: 0.5891 - 27s/epoch - 50ms/step
Epoch 17/50
538/538 - 27s - loss: 2.2402 - accuracy20: 0.6563 - val_loss: 3.1244 - val_accuracy20: 0.4718 - 27s/epoch - 50ms/step
Epoch 18/50
538/538 - 26s - loss: 2.2143 - accuracy20: 0.6603 - val_loss: 4.2031 - val_accuracy20: 0.2959 - 26s/epoch - 49ms/step
Epoch 19/50
538/538 - 26s - loss: 2.1981 - accuracy20: 0.6612 - val_loss: 3.6655 - val_accuracy20: 0.3789 - 26s/epoch - 48ms/step
Epoch 20/50
538/538 - 27s - loss: 2.1775 - accuracy20: 0.6638 - val_loss: 3.9745 - val_accuracy20: 0.2921 - 27s/epoch - 49ms/step
Epoch 21/50
538/538 - 27s - loss: 2.1618 - accuracy20: 0.6669 - val_loss: 4.0615 - val_accuracy20: 0.2988 - 27s/epoch - 49ms/step
Epoch 22/50
538/538 - 27s - loss: 2.1451 - accuracy20: 0.6667 - val_loss: 3.5109 - val_accuracy20: 0.4172 - 27s/epoch - 50ms/step
Epoch 23/50
538/538 - 27s - loss: 2.1292 - accuracy20: 0.6675 - val_loss: 3.2540 - val_accuracy20: 0.4875 - 27s/epoch - 50ms/step
Epoch 24/50
538/538 - 27s - loss: 2.1103 - accuracy20: 0.6695 - val_loss: 3.5812 - val_accuracy20: 0.4065 - 27s/epoch - 50ms/step
Epoch 25/50
538/538 - 27s - loss: 2.0913 - accuracy20: 0.6714 - val_loss: 3.1438 - val_accuracy20: 0.5964 - 27s/epoch - 50ms/step
testing model: results/QRTEA/W7/deepLOB_L2/h20
Evaluating performance on  test set...
2006/2006 - 40s - 40s/epoch - 20ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.8821249
{'0': {'precision': 0.3157099819889672, 'recall': 0.5831567954647173, 'f1-score': 0.4096456249377761, 'support': 67030}, '1': {'precision': 0.8653143562366054, 'recall': 0.6505585490866079, 'f1-score': 0.742724076827627, 'support': 380450}, '2': {'precision': 0.3551329622758194, 'recall': 0.5581169324221716, 'f1-score': 0.4340667776872291, 'support': 65850}, 'accuracy': 0.629898895447373, 'macro avg': {'precision': 0.512052433500464, 'recall': 0.5972774256578323, 'f1-score': 0.528812159817544, 'support': 513330}, 'weighted avg': {'precision': 0.728101596417119, 'recall': 0.629898895447373, 'f1-score': 0.6596365273398279, 'support': 513330}}
[[ 39089  19639   8302]
 [ 74511 247505  58434]
 [ 10213  18885  36752]]
Evaluating performance on  train set...
538/538 - 12s - 12s/epoch - 22ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.85200787
{'0': {'precision': 0.36916352076296444, 'recall': 0.5718096019696348, 'f1-score': 0.44866583490964707, 'support': 19496}, '1': {'precision': 0.8703900114116936, 'recall': 0.6535580713126405, 'f1-score': 0.7465482894024712, 'support': 99197}, '2': {'precision': 0.3476289036342607, 'recall': 0.6060815113563999, 'f1-score': 0.4418352740918411, 'support': 18844}, 'accuracy': 0.635465365683416, 'macro avg': {'precision': 0.5290608119363062, 'recall': 0.610483061546225, 'f1-score': 0.5456831328013197, 'support': 137537}, 'weighted avg': {'precision': 0.7277169708724528, 'recall': 0.635465365683416, 'f1-score': 0.6625743159022086, 'support': 137537}}
[[11148  5268  3080]
 [16013 64831 18353]
 [ 3037  4386 11421]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 22ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.878801
{'0': {'precision': 0.36609613610741004, 'recall': 0.6070700203942896, 'f1-score': 0.45674828975129467, 'support': 5884}, '1': {'precision': 0.8547435097653439, 'recall': 0.6537953310820731, 'f1-score': 0.7408855520662189, 'support': 27244}, '2': {'precision': 0.39117577478116866, 'recall': 0.5584262073623776, 'f1-score': 0.4600723427935448, 'support': 5922}, 'accuracy': 0.6322919334186939, 'macro avg': {'precision': 0.5373384735513075, 'recall': 0.6064305196129134, 'f1-score': 0.5525687282036862, 'support': 39050}, 'weighted avg': {'precision': 0.7108139509131143, 'recall': 0.6322919334186939, 'f1-score': 0.6554863337109361, 'support': 39050}}
[[ 3572  1515   797]
 [ 5082 17812  4350]
 [ 1103  1512  3307]]
training model: results/QRTEA/W7/deepLOB_L2/h30
Epoch 1/50
538/538 - 30s - loss: 3.1954 - accuracy30: 0.4102 - val_loss: 3.7950 - val_accuracy30: 0.5552 - 30s/epoch - 55ms/step
Epoch 2/50
538/538 - 27s - loss: 2.9570 - accuracy30: 0.4281 - val_loss: 3.5146 - val_accuracy30: 0.5275 - 27s/epoch - 49ms/step
Epoch 3/50
538/538 - 27s - loss: 2.8785 - accuracy30: 0.4767 - val_loss: 3.9220 - val_accuracy30: 0.6371 - 27s/epoch - 50ms/step
Epoch 4/50
538/538 - 27s - loss: 2.8222 - accuracy30: 0.5051 - val_loss: 3.5413 - val_accuracy30: 0.6385 - 27s/epoch - 50ms/step
Epoch 5/50
538/538 - 27s - loss: 2.7839 - accuracy30: 0.5252 - val_loss: 3.3315 - val_accuracy30: 0.6255 - 27s/epoch - 51ms/step
Epoch 6/50
538/538 - 27s - loss: 2.7423 - accuracy30: 0.5394 - val_loss: 3.1777 - val_accuracy30: 0.5405 - 27s/epoch - 50ms/step
Epoch 7/50
538/538 - 27s - loss: 2.7078 - accuracy30: 0.5516 - val_loss: 3.3997 - val_accuracy30: 0.6256 - 27s/epoch - 50ms/step
Epoch 8/50
538/538 - 27s - loss: 2.6778 - accuracy30: 0.5592 - val_loss: 3.9053 - val_accuracy30: 0.6242 - 27s/epoch - 50ms/step
Epoch 9/50
538/538 - 26s - loss: 2.6482 - accuracy30: 0.5685 - val_loss: 3.3024 - val_accuracy30: 0.3833 - 26s/epoch - 49ms/step
Epoch 10/50
538/538 - 26s - loss: 2.6173 - accuracy30: 0.5776 - val_loss: 3.2778 - val_accuracy30: 0.3986 - 26s/epoch - 49ms/step
Epoch 11/50
538/538 - 27s - loss: 2.5887 - accuracy30: 0.5830 - val_loss: 3.4629 - val_accuracy30: 0.3794 - 27s/epoch - 49ms/step
Epoch 12/50
538/538 - 27s - loss: 2.5580 - accuracy30: 0.5892 - val_loss: 3.7175 - val_accuracy30: 0.6034 - 27s/epoch - 49ms/step
Epoch 13/50
538/538 - 26s - loss: 2.5341 - accuracy30: 0.5948 - val_loss: 3.4383 - val_accuracy30: 0.5822 - 26s/epoch - 48ms/step
Epoch 14/50
538/538 - 26s - loss: 2.5024 - accuracy30: 0.6006 - val_loss: 3.5870 - val_accuracy30: 0.4663 - 26s/epoch - 49ms/step
Epoch 15/50
538/538 - 26s - loss: 2.4757 - accuracy30: 0.6027 - val_loss: 3.6267 - val_accuracy30: 0.4012 - 26s/epoch - 49ms/step
Epoch 16/50
538/538 - 27s - loss: 2.4600 - accuracy30: 0.6044 - val_loss: 3.5288 - val_accuracy30: 0.4423 - 27s/epoch - 49ms/step
testing model: results/QRTEA/W7/deepLOB_L2/h30
Evaluating performance on  test set...
2006/2006 - 39s - 39s/epoch - 20ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.9552303
{'0': {'precision': 0.2770382404223883, 'recall': 0.47655356002842725, 'f1-score': 0.350384809543631, 'support': 83019}, '1': {'precision': 0.7585438335809807, 'recall': 0.5874719819997767, 'f1-score': 0.6621367211131276, 'support': 349329}, '2': {'precision': 0.3261350110525421, 'recall': 0.4026326838062779, 'f1-score': 0.36036892334727755, 'support': 80982}, 'accuracy': 0.5403736387898622, 'macro avg': {'precision': 0.45390569501863703, 'recall': 0.4888860752781606, 'f1-score': 0.4576301513346787, 'support': 513330}, 'weighted avg': {'precision': 0.612455656181586, 'recall': 0.5403736387898622, 'f1-score': 0.564111879889622, 'support': 513330}}
[[ 39563  34074   9382]
 [ 86119 205221  57989]
 [ 17125  31251  32606]]
Evaluating performance on  train set...
538/538 - 11s - 11s/epoch - 21ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.94888586
{'0': {'precision': 0.2985693342095951, 'recall': 0.5010604903707474, 'f1-score': 0.3741763811454638, 'support': 23574}, '1': {'precision': 0.7664631582000377, 'recall': 0.5790713471820492, 'f1-score': 0.6597182782143057, 'support': 91272}, '2': {'precision': 0.32862361292990555, 'recall': 0.42025472654356355, 'f1-score': 0.36883327853951925, 'support': 22691}, 'accuracy': 0.5394984622319812, 'macro avg': {'precision': 0.4645520351131795, 'recall': 0.5001288546987867, 'f1-score': 0.4675759792997629, 'support': 137537}, 'weighted avg': {'precision': 0.614030386447889, 'recall': 0.5394984622319812, 'f1-score': 0.5627855531358071, 'support': 137537}}
[[11812  8963  2799]
 [21736 52853 16683]
 [ 6014  7141  9536]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 22ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.94915175
{'0': {'precision': 0.31964607851559146, 'recall': 0.5223189219539585, 'f1-score': 0.39658939515054625, 'support': 7124}, '1': {'precision': 0.7394109116367455, 'recall': 0.5967390426991687, 'f1-score': 0.6604578447794529, 'support': 24778}, '2': {'precision': 0.36225040474905557, 'recall': 0.375629546726357, 'f1-score': 0.3688186813186813, 'support': 7148}, 'accuracy': 0.5426888604353393, 'macro avg': {'precision': 0.4737691316337975, 'recall': 0.49822917045982806, 'f1-score': 0.47528864041622687, 'support': 39050}, 'weighted avg': {'precision': 0.593793806018607, 'recall': 0.5426888604353393, 'f1-score': 0.5589358069926686, 'support': 39050}}
[[ 3721  2687   716]
 [ 5981 14786  4011]
 [ 1939  2524  2685]]
training model: results/QRTEA/W7/deepLOB_L2/h50
Epoch 1/50
538/538 - 29s - loss: 3.2496 - accuracy50: 0.4017 - val_loss: 3.6991 - val_accuracy50: 0.5052 - 29s/epoch - 54ms/step
Epoch 2/50
538/538 - 27s - loss: 3.0296 - accuracy50: 0.4590 - val_loss: 3.5438 - val_accuracy50: 0.4417 - 27s/epoch - 50ms/step
Epoch 3/50
538/538 - 27s - loss: 2.9798 - accuracy50: 0.4721 - val_loss: 3.8542 - val_accuracy50: 0.5197 - 27s/epoch - 50ms/step
Epoch 4/50
538/538 - 27s - loss: 2.9382 - accuracy50: 0.4938 - val_loss: 3.4622 - val_accuracy50: 0.5416 - 27s/epoch - 50ms/step
Epoch 5/50
538/538 - 27s - loss: 2.9063 - accuracy50: 0.5104 - val_loss: 3.3615 - val_accuracy50: 0.5487 - 27s/epoch - 50ms/step
Epoch 6/50
538/538 - 27s - loss: 2.8812 - accuracy50: 0.5172 - val_loss: 3.3487 - val_accuracy50: 0.5511 - 27s/epoch - 50ms/step
Epoch 7/50
538/538 - 27s - loss: 2.8531 - accuracy50: 0.5306 - val_loss: 4.1305 - val_accuracy50: 0.5365 - 27s/epoch - 50ms/step
Epoch 8/50
538/538 - 27s - loss: 2.8279 - accuracy50: 0.5374 - val_loss: 4.1232 - val_accuracy50: 0.5386 - 27s/epoch - 50ms/step
Epoch 9/50
538/538 - 27s - loss: 2.8030 - accuracy50: 0.5425 - val_loss: 3.9418 - val_accuracy50: 0.5470 - 27s/epoch - 50ms/step
Epoch 10/50
538/538 - 27s - loss: 2.7854 - accuracy50: 0.5500 - val_loss: 3.9207 - val_accuracy50: 0.5499 - 27s/epoch - 50ms/step
Epoch 11/50
538/538 - 27s - loss: 2.7583 - accuracy50: 0.5584 - val_loss: 3.6241 - val_accuracy50: 0.5486 - 27s/epoch - 50ms/step
Epoch 12/50
538/538 - 26s - loss: 2.7329 - accuracy50: 0.5644 - val_loss: 3.8207 - val_accuracy50: 0.5643 - 26s/epoch - 48ms/step
Epoch 13/50
538/538 - 26s - loss: 2.7082 - accuracy50: 0.5693 - val_loss: 4.2095 - val_accuracy50: 0.5372 - 26s/epoch - 48ms/step
Epoch 14/50
538/538 - 26s - loss: 2.6862 - accuracy50: 0.5732 - val_loss: 4.2113 - val_accuracy50: 0.5494 - 26s/epoch - 49ms/step
Epoch 15/50
538/538 - 27s - loss: 2.6693 - accuracy50: 0.5770 - val_loss: 3.2816 - val_accuracy50: 0.4344 - 27s/epoch - 49ms/step
Epoch 16/50
538/538 - 27s - loss: 2.6428 - accuracy50: 0.5845 - val_loss: 4.0740 - val_accuracy50: 0.5487 - 27s/epoch - 49ms/step
Epoch 17/50
538/538 - 27s - loss: 2.6207 - accuracy50: 0.5869 - val_loss: 3.9361 - val_accuracy50: 0.5559 - 27s/epoch - 49ms/step
Epoch 18/50
538/538 - 27s - loss: 2.6045 - accuracy50: 0.5893 - val_loss: 3.3909 - val_accuracy50: 0.4272 - 27s/epoch - 50ms/step
Epoch 19/50
538/538 - 26s - loss: 2.5830 - accuracy50: 0.5924 - val_loss: 3.4444 - val_accuracy50: 0.5088 - 26s/epoch - 49ms/step
Epoch 20/50
538/538 - 26s - loss: 2.5585 - accuracy50: 0.5974 - val_loss: 3.3814 - val_accuracy50: 0.3963 - 26s/epoch - 49ms/step
Epoch 21/50
538/538 - 27s - loss: 2.5496 - accuracy50: 0.5983 - val_loss: 3.5245 - val_accuracy50: 0.3472 - 27s/epoch - 49ms/step
Epoch 22/50
538/538 - 26s - loss: 2.5310 - accuracy50: 0.6015 - val_loss: 3.5314 - val_accuracy50: 0.3256 - 26s/epoch - 49ms/step
Epoch 23/50
538/538 - 26s - loss: 2.5039 - accuracy50: 0.6041 - val_loss: 3.3839 - val_accuracy50: 0.3799 - 26s/epoch - 49ms/step
Epoch 24/50
538/538 - 27s - loss: 2.4849 - accuracy50: 0.6094 - val_loss: 3.5611 - val_accuracy50: 0.3474 - 27s/epoch - 49ms/step
Epoch 25/50
538/538 - 27s - loss: 2.4695 - accuracy50: 0.6100 - val_loss: 3.4117 - val_accuracy50: 0.4446 - 27s/epoch - 50ms/step
testing model: results/QRTEA/W7/deepLOB_L2/h50
Evaluating performance on  test set...
2006/2006 - 40s - 40s/epoch - 20ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.1233134
{'0': {'precision': 0.2919338605319914, 'recall': 0.6450160654963966, 'f1-score': 0.4019468380849493, 'support': 110174}, '1': {'precision': 0.6928505028310656, 'recall': 0.3869668118619611, 'f1-score': 0.49658427685744816, 'support': 296612}, '2': {'precision': 0.3616933511123049, 'recall': 0.35388196425889773, 'f1-score': 0.3577450222262284, 'support': 106544}, 'accuracy': 0.4354839966493289, 'macro avg': {'precision': 0.44882590482512064, 'recall': 0.4619549472057518, 'f1-score': 0.418758712389542, 'support': 513330}, 'weighted avg': {'precision': 0.5380701515533655, 'recall': 0.4354839966493289, 'f1-score': 0.4474558901963336, 'support': 513330}}
[[ 71064  22447  16663]
 [131957 114779  49876]
 [ 40404  28436  37704]]
Evaluating performance on  train set...
538/538 - 12s - 12s/epoch - 22ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0803865
{'0': {'precision': 0.32443599400343703, 'recall': 0.5840958462247383, 'f1-score': 0.4171603196991067, 'support': 30382}, '1': {'precision': 0.7181421198888448, 'recall': 0.46291439026574716, 'f1-score': 0.5629507456996818, 'support': 78157}, '2': {'precision': 0.35370775439785573, 'recall': 0.3959238568177116, 'f1-score': 0.37362708885887697, 'support': 28998}, 'accuracy': 0.47555930404182145, 'macro avg': {'precision': 0.4654286227633792, 'recall': 0.4809780311027323, 'f1-score': 0.45124605141922186, 'support': 137537}, 'weighted avg': {'precision': 0.5543356732806001, 'recall': 0.47555930404182145, 'f1-score': 0.4908289739304916, 'support': 137537}}
[[17746  6786  5850]
 [26849 36180 15128]
 [10103  7414 11481]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 21ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.1299764
{'0': {'precision': 0.31382232448510017, 'recall': 0.6134942402633022, 'f1-score': 0.41523724660280686, 'support': 9115}, '1': {'precision': 0.7046979865771812, 'recall': 0.3643724696356275, 'f1-score': 0.4803659931376286, 'support': 20748}, '2': {'precision': 0.36437208416642863, 'recall': 0.41656688799390446, 'f1-score': 0.3887252412392077, 'support': 9187}, 'accuracy': 0.43480153649167735, 'macro avg': {'precision': 0.46096413174290335, 'recall': 0.4648111992976114, 'f1-score': 0.42810949365988105, 'support': 39050}, 'weighted avg': {'precision': 0.5333943828533169, 'recall': 0.43480153649167735, 'f1-score': 0.4436040952540001, 'support': 39050}}
[[5592 1464 2059]
 [8571 7560 4617]
 [3656 1704 3827]]
training model: results/QRTEA/W7/deepLOB_L2/h100
Epoch 1/50
538/538 - 29s - loss: 3.3032 - accuracy100: 0.3838 - val_loss: 3.8185 - val_accuracy100: 0.3669 - 29s/epoch - 53ms/step
Epoch 2/50
538/538 - 26s - loss: 3.1717 - accuracy100: 0.4333 - val_loss: 3.5399 - val_accuracy100: 0.3782 - 26s/epoch - 49ms/step
Epoch 3/50
538/538 - 27s - loss: 3.1131 - accuracy100: 0.4558 - val_loss: 3.4621 - val_accuracy100: 0.3968 - 27s/epoch - 50ms/step
Epoch 4/50
538/538 - 26s - loss: 3.0754 - accuracy100: 0.4674 - val_loss: 3.4505 - val_accuracy100: 0.4174 - 26s/epoch - 49ms/step
Epoch 5/50
538/538 - 27s - loss: 3.0388 - accuracy100: 0.4851 - val_loss: 3.7830 - val_accuracy100: 0.3932 - 27s/epoch - 50ms/step
Epoch 6/50
538/538 - 27s - loss: 3.0157 - accuracy100: 0.4920 - val_loss: 3.2853 - val_accuracy100: 0.4166 - 27s/epoch - 50ms/step
Epoch 7/50
538/538 - 27s - loss: 2.9871 - accuracy100: 0.4995 - val_loss: 3.6852 - val_accuracy100: 0.4045 - 27s/epoch - 50ms/step
Epoch 8/50
538/538 - 27s - loss: 2.9660 - accuracy100: 0.5046 - val_loss: 4.6203 - val_accuracy100: 0.3828 - 27s/epoch - 50ms/step
Epoch 9/50
538/538 - 27s - loss: 2.9393 - accuracy100: 0.5128 - val_loss: 3.7718 - val_accuracy100: 0.4110 - 27s/epoch - 50ms/step
Epoch 10/50
538/538 - 27s - loss: 2.9086 - accuracy100: 0.5199 - val_loss: 4.3258 - val_accuracy100: 0.3937 - 27s/epoch - 50ms/step
Epoch 11/50
538/538 - 27s - loss: 2.8801 - accuracy100: 0.5256 - val_loss: 4.3298 - val_accuracy100: 0.4037 - 27s/epoch - 50ms/step
Epoch 12/50
538/538 - 27s - loss: 2.8530 - accuracy100: 0.5316 - val_loss: 3.8157 - val_accuracy100: 0.4351 - 27s/epoch - 50ms/step
Epoch 13/50
538/538 - 27s - loss: 2.8242 - accuracy100: 0.5390 - val_loss: 3.5342 - val_accuracy100: 0.4411 - 27s/epoch - 49ms/step
Epoch 14/50
538/538 - 27s - loss: 2.8058 - accuracy100: 0.5434 - val_loss: 3.8351 - val_accuracy100: 0.4335 - 27s/epoch - 50ms/step
Epoch 15/50
538/538 - 27s - loss: 2.7729 - accuracy100: 0.5508 - val_loss: 3.5006 - val_accuracy100: 0.4310 - 27s/epoch - 50ms/step
Epoch 16/50
538/538 - 27s - loss: 2.7608 - accuracy100: 0.5545 - val_loss: 3.7015 - val_accuracy100: 0.4395 - 27s/epoch - 49ms/step
testing model: results/QRTEA/W7/deepLOB_L2/h100
Evaluating performance on  test set...
2006/2006 - 39s - 39s/epoch - 19ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0646774
{'0': {'precision': 0.3789021760042123, 'recall': 0.24244701735744414, 'f1-score': 0.2956910652622263, 'support': 154343}, '1': {'precision': 0.472556562467449, 'recall': 0.6233281375108378, 'f1-score': 0.5375707899876604, 'support': 211067}, '2': {'precision': 0.3819200658039688, 'recall': 0.35156165494862085, 'f1-score': 0.36611260129117645, 'support': 147920}, 'accuracy': 0.4304969512789044, 'macro avg': {'precision': 0.41112626809187663, 'recall': 0.4057789366056343, 'f1-score': 0.3997914855136877, 'support': 513330}, 'weighted avg': {'precision': 0.41827987971686487, 'recall': 0.4304969512789044, 'f1-score': 0.415437780763026, 'support': 513330}}
[[ 37420  76533  40390]
 [ 35734 131564  43769]
 [ 25605  70312  52003]]
Evaluating performance on  train set...
538/538 - 12s - 12s/epoch - 22ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0537453
{'0': {'precision': 0.40791281252861983, 'recall': 0.21407800821898057, 'f1-score': 0.2807924474775016, 'support': 41611}, '1': {'precision': 0.4779567613395507, 'recall': 0.6750070432455275, 'f1-score': 0.5596432064701674, 'support': 56792}, '2': {'precision': 0.3848927957625447, 'recall': 0.34908263913732307, 'f1-score': 0.36611414099454626, 'support': 39134}, 'accuracy': 0.44281902324465416, 'macro avg': {'precision': 0.42358745654357177, 'recall': 0.4127225635339437, 'f1-score': 0.4021832649807384, 'support': 137537}, 'weighted avg': {'precision': 0.4302854875524083, 'recall': 0.44281902324465416, 'f1-score': 0.4202129049457283, 'support': 137537}}
[[ 8908 22268 10435]
 [ 7060 38335 11397]
 [ 5870 19603 13661]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 21ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0717012
{'0': {'precision': 0.36928758270503154, 'recall': 0.19837989750371962, 'f1-score': 0.25810614615260524, 'support': 12098}, '1': {'precision': 0.46208710903244665, 'recall': 0.5382362955396663, 'f1-score': 0.4972632903428751, 'support': 14685}, '2': {'precision': 0.392917260132073, 'recall': 0.49474199070677427, 'f1-score': 0.43798939126041936, 'support': 12267}, 'accuracy': 0.4192829705505762, 'macro avg': {'precision': 0.4080973172898504, 'recall': 0.41045272791672005, 'f1-score': 0.39778627591863325, 'support': 39050}, 'weighted avg': {'precision': 0.4116083585594646, 'recall': 0.4192829705505762, 'f1-score': 0.4045504593452216, 'support': 39050}}
[[2400 4853 4845]
 [2249 7904 4532]
 [1850 4348 6069]]
training model: results/QRTEA/W7/deepLOB_L2/h200
Epoch 1/50
538/538 - 29s - loss: 3.3344 - accuracy200: 0.3631 - val_loss: 3.3998 - val_accuracy200: 0.3321 - 29s/epoch - 54ms/step
Epoch 2/50
538/538 - 27s - loss: 3.2702 - accuracy200: 0.3820 - val_loss: 3.4028 - val_accuracy200: 0.3130 - 27s/epoch - 50ms/step
Epoch 3/50
538/538 - 27s - loss: 3.2410 - accuracy200: 0.3969 - val_loss: 3.6175 - val_accuracy200: 0.3078 - 27s/epoch - 49ms/step
Epoch 4/50
538/538 - 27s - loss: 3.2094 - accuracy200: 0.4135 - val_loss: 3.9065 - val_accuracy200: 0.3040 - 27s/epoch - 50ms/step
Epoch 5/50
538/538 - 27s - loss: 3.1742 - accuracy200: 0.4287 - val_loss: 3.7993 - val_accuracy200: 0.3048 - 27s/epoch - 49ms/step
Epoch 6/50
538/538 - 26s - loss: 3.1455 - accuracy200: 0.4420 - val_loss: 3.7840 - val_accuracy200: 0.3058 - 26s/epoch - 49ms/step
Epoch 7/50
538/538 - 27s - loss: 3.1224 - accuracy200: 0.4503 - val_loss: 3.9587 - val_accuracy200: 0.3054 - 27s/epoch - 50ms/step
Epoch 8/50
538/538 - 27s - loss: 3.0920 - accuracy200: 0.4643 - val_loss: 4.2065 - val_accuracy200: 0.3050 - 27s/epoch - 49ms/step
Epoch 9/50
538/538 - 27s - loss: 3.0602 - accuracy200: 0.4746 - val_loss: 4.1356 - val_accuracy200: 0.3105 - 27s/epoch - 50ms/step
Epoch 10/50
538/538 - 27s - loss: 3.0360 - accuracy200: 0.4839 - val_loss: 4.2097 - val_accuracy200: 0.3056 - 27s/epoch - 50ms/step
Epoch 11/50
538/538 - 27s - loss: 3.0059 - accuracy200: 0.4923 - val_loss: 4.4743 - val_accuracy200: 0.3058 - 27s/epoch - 50ms/step
testing model: results/QRTEA/W7/deepLOB_L2/h200
Evaluating performance on  test set...
2006/2006 - 41s - 41s/epoch - 21ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1420113
{'0': {'precision': 0.3492587101556709, 'recall': 0.05315530283799563, 'f1-score': 0.09226792262537147, 'support': 177273}, '1': {'precision': 0.3292041428182066, 'recall': 0.5804982668196591, 'f1-score': 0.42014274626774817, 'support': 166457}, '2': {'precision': 0.33407664782450863, 'recall': 0.37983490566037736, 'f1-score': 0.3554893358717546, 'support': 169600}, 'accuracy': 0.332088520055325, 'macro avg': {'precision': 0.33751316693279537, 'recall': 0.3378294917726774, 'f1-score': 0.2893000015882914, 'support': 513330}, 'weighted avg': {'precision': 0.3377396076550233, 'recall': 0.332088520055325, 'f1-score': 0.2855537450118006, 'support': 513330}}
[[  9423 100591  67259]
 [  8678  96628  61151]
 [  8879  96301  64420]]
Evaluating performance on  train set...
538/538 - 12s - 12s/epoch - 22ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1389523
{'0': {'precision': 0.35946666666666666, 'recall': 0.08327670352752209, 'f1-score': 0.13522596177960575, 'support': 48561}, '1': {'precision': 0.3196707764519221, 'recall': 0.6610088398797047, 'f1-score': 0.4309362722891029, 'support': 43892}, '2': {'precision': 0.325208286421977, 'recall': 0.256277171502085, 'f1-score': 0.2866570733885774, 'support': 45084}, 'accuracy': 0.3243563550171954, 'macro avg': {'precision': 0.33478190984685524, 'recall': 0.33352090496977066, 'f1-score': 0.28427310248576204, 'support': 137537}, 'weighted avg': {'precision': 0.3355369166484377, 'recall': 0.3243563550171954, 'f1-score': 0.27923402640702766, 'support': 137537}}
[[ 4044 31886 12631]
 [ 3536 29013 11343]
 [ 3670 29860 11554]]
Evaluating performance on  val set...
153/153 - 4s - 4s/epoch - 23ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.141752
{'0': {'precision': 0.3466593647316539, 'recall': 0.04739442946990117, 'f1-score': 0.08338822289553419, 'support': 13356}, '1': {'precision': 0.31294020162960917, 'recall': 0.5726078167115903, 'f1-score': 0.40470308081559764, 'support': 11872}, '2': {'precision': 0.3571382491452164, 'recall': 0.40052090869628126, 'f1-score': 0.37758755925382803, 'support': 13822}, 'accuracy': 0.3320614596670935, 'macro avg': {'precision': 0.3389126051688265, 'recall': 0.34017438495925756, 'f1-score': 0.28855962098831994, 'support': 39050}, 'weighted avg': {'precision': 0.3401171172544909, 'recall': 0.3320614596670935, 'f1-score': 0.2852082797552353, 'support': 39050}}
[[ 633 7299 5424]
 [ 533 6798 4541]
 [ 660 7626 5536]]
training model: results/QRTEA/W7/deepLOB_L2/h300
Epoch 1/50
538/538 - 30s - loss: 3.3338 - accuracy300: 0.3648 - val_loss: 3.4859 - val_accuracy300: 0.3352 - 30s/epoch - 56ms/step
Epoch 2/50
538/538 - 28s - loss: 3.2940 - accuracy300: 0.3694 - val_loss: 3.3776 - val_accuracy300: 0.3403 - 28s/epoch - 52ms/step
Epoch 3/50
538/538 - 27s - loss: 3.2696 - accuracy300: 0.3799 - val_loss: 3.3758 - val_accuracy300: 0.3378 - 27s/epoch - 50ms/step
Epoch 4/50
538/538 - 26s - loss: 3.2529 - accuracy300: 0.3915 - val_loss: 3.4937 - val_accuracy300: 0.3365 - 26s/epoch - 49ms/step
Epoch 5/50
538/538 - 27s - loss: 3.2241 - accuracy300: 0.4037 - val_loss: 3.4237 - val_accuracy300: 0.3410 - 27s/epoch - 50ms/step
Epoch 6/50
538/538 - 27s - loss: 3.1950 - accuracy300: 0.4166 - val_loss: 3.5124 - val_accuracy300: 0.3402 - 27s/epoch - 50ms/step
Epoch 7/50
538/538 - 26s - loss: 3.1646 - accuracy300: 0.4291 - val_loss: 3.4875 - val_accuracy300: 0.3400 - 26s/epoch - 49ms/step
Epoch 8/50
538/538 - 27s - loss: 3.1398 - accuracy300: 0.4411 - val_loss: 3.5177 - val_accuracy300: 0.3383 - 27s/epoch - 50ms/step
Epoch 9/50
538/538 - 27s - loss: 3.1051 - accuracy300: 0.4527 - val_loss: 3.6372 - val_accuracy300: 0.3436 - 27s/epoch - 50ms/step
Epoch 10/50
538/538 - 27s - loss: 3.0773 - accuracy300: 0.4627 - val_loss: 3.7298 - val_accuracy300: 0.3401 - 27s/epoch - 50ms/step
Epoch 11/50
538/538 - 27s - loss: 3.0380 - accuracy300: 0.4753 - val_loss: 3.8595 - val_accuracy300: 0.3364 - 27s/epoch - 50ms/step
Epoch 12/50
538/538 - 27s - loss: 3.0097 - accuracy300: 0.4830 - val_loss: 3.4698 - val_accuracy300: 0.3405 - 27s/epoch - 50ms/step
Epoch 13/50
538/538 - 27s - loss: 2.9839 - accuracy300: 0.4905 - val_loss: 3.5532 - val_accuracy300: 0.3412 - 27s/epoch - 51ms/step
testing model: results/QRTEA/W7/deepLOB_L2/h300
Evaluating performance on  test set...
2006/2006 - 42s - 42s/epoch - 21ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1184762
{'0': {'precision': 0.3375374504687349, 'recall': 0.04071082202639064, 'f1-score': 0.07265824101523899, 'support': 171576}, '1': {'precision': 0.34749309316950816, 'recall': 0.8625284789425007, 'f1-score': 0.4954005713656416, 'support': 177324}, '2': {'precision': 0.33321268002743276, 'recall': 0.10637353281031442, 'f1-score': 0.1612653396151612, 'support': 164430}, 'accuracy': 0.34563146513938403, 'macro avg': {'precision': 0.3394144078885586, 'recall': 0.3365376112597353, 'f1-score': 0.24310805066534724, 'support': 513330}, 'weighted avg': {'precision': 0.33959120221246425, 'recall': 0.34563146513938403, 'f1-score': 0.24707241164590543, 'support': 513330}}
[[  6985 147293  17298]
 [  6674 152947  17703]
 [  7035 139904  17491]]
Evaluating performance on  train set...
538/538 - 12s - 12s/epoch - 22ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1130087
{'0': {'precision': 0.36679622431982234, 'recall': 0.07054677488252883, 'f1-score': 0.11833407971339005, 'support': 46820}, '1': {'precision': 0.34683026584867077, 'recall': 0.8537987162814112, 'f1-score': 0.49328017257050066, 'support': 47674}, '2': {'precision': 0.3198174006444683, 'recall': 0.08301001324257139, 'f1-score': 0.13180854007193582, 'support': 43043}, 'accuracy': 0.34594327344641806, 'macro avg': {'precision': 0.3444812969376538, 'recall': 0.3357851681355038, 'f1-score': 0.24780759745194217, 'support': 137537}, 'weighted avg': {'precision': 0.3451731947960437, 'recall': 0.34594327344641806, 'f1-score': 0.2525173266075551, 'support': 137537}}
[[ 3303 39914  3603]
 [ 2974 40704  3996]
 [ 2728 36742  3573]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 22ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1181906
{'0': {'precision': 0.3558606124604013, 'recall': 0.026763024142312578, 'f1-score': 0.049782110938769476, 'support': 12592}, '1': {'precision': 0.3408828287497111, 'recall': 0.8867513338844217, 'f1-score': 0.4924566492081046, 'support': 13307}, '2': {'precision': 0.3366790937768856, 'recall': 0.0892707778876131, 'f1-score': 0.14112273109748766, 'support': 13151}, 'accuracy': 0.3408706786171575, 'macro avg': {'precision': 0.3444741783289993, 'recall': 0.3342617119714491, 'f1-score': 0.22778716374812058, 'support': 39050}, 'weighted avg': {'precision': 0.34429683473837647, 'recall': 0.3408706786171575, 'f1-score': 0.23139262506059652, 'support': 39050}}
[[  337 11154  1101]
 [  295 11800  1212]
 [  315 11662  1174]]
training model: results/QRTEA/W7/deepLOB_L2/h500
Epoch 1/50
538/538 - 29s - loss: 3.3073 - accuracy500: 0.3832 - val_loss: 3.3435 - val_accuracy500: 0.3593 - 29s/epoch - 54ms/step
Epoch 2/50
538/538 - 27s - loss: 3.2696 - accuracy500: 0.3831 - val_loss: 3.4428 - val_accuracy500: 0.3171 - 27s/epoch - 50ms/step
Epoch 3/50
538/538 - 27s - loss: 3.2635 - accuracy500: 0.3843 - val_loss: 3.3457 - val_accuracy500: 0.3651 - 27s/epoch - 50ms/step
Epoch 4/50
538/538 - 27s - loss: 3.2575 - accuracy500: 0.3890 - val_loss: 3.3454 - val_accuracy500: 0.3661 - 27s/epoch - 50ms/step
Epoch 5/50
538/538 - 26s - loss: 3.2417 - accuracy500: 0.3973 - val_loss: 3.3313 - val_accuracy500: 0.3458 - 26s/epoch - 49ms/step
Epoch 6/50
538/538 - 26s - loss: 3.2213 - accuracy500: 0.4098 - val_loss: 3.3323 - val_accuracy500: 0.3570 - 26s/epoch - 49ms/step
Epoch 7/50
538/538 - 26s - loss: 3.1985 - accuracy500: 0.4219 - val_loss: 3.3594 - val_accuracy500: 0.3184 - 26s/epoch - 49ms/step
Epoch 8/50
538/538 - 27s - loss: 3.1711 - accuracy500: 0.4342 - val_loss: 3.3125 - val_accuracy500: 0.3628 - 27s/epoch - 49ms/step
Epoch 9/50
538/538 - 26s - loss: 3.1429 - accuracy500: 0.4462 - val_loss: 3.4202 - val_accuracy500: 0.3075 - 26s/epoch - 49ms/step
Epoch 10/50
538/538 - 27s - loss: 3.1119 - accuracy500: 0.4586 - val_loss: 3.4230 - val_accuracy500: 0.3104 - 27s/epoch - 49ms/step
Epoch 11/50
538/538 - 26s - loss: 3.0893 - accuracy500: 0.4659 - val_loss: 3.4312 - val_accuracy500: 0.3249 - 26s/epoch - 49ms/step
Epoch 12/50
538/538 - 26s - loss: 3.0544 - accuracy500: 0.4780 - val_loss: 3.3663 - val_accuracy500: 0.3231 - 26s/epoch - 49ms/step
Epoch 13/50
538/538 - 26s - loss: 3.0347 - accuracy500: 0.4849 - val_loss: 3.4463 - val_accuracy500: 0.3169 - 26s/epoch - 49ms/step
Epoch 14/50
538/538 - 27s - loss: 2.9970 - accuracy500: 0.4991 - val_loss: 3.3913 - val_accuracy500: 0.3494 - 27s/epoch - 49ms/step
Epoch 15/50
538/538 - 26s - loss: 2.9750 - accuracy500: 0.5058 - val_loss: 3.5144 - val_accuracy500: 0.3006 - 26s/epoch - 48ms/step
Epoch 16/50
538/538 - 26s - loss: 2.9426 - accuracy500: 0.5121 - val_loss: 3.6714 - val_accuracy500: 0.2931 - 26s/epoch - 49ms/step
Epoch 17/50
538/538 - 26s - loss: 2.9041 - accuracy500: 0.5254 - val_loss: 3.4471 - val_accuracy500: 0.3594 - 26s/epoch - 48ms/step
Epoch 18/50
538/538 - 26s - loss: 2.8838 - accuracy500: 0.5310 - val_loss: 3.9616 - val_accuracy500: 0.2782 - 26s/epoch - 49ms/step
testing model: results/QRTEA/W7/deepLOB_L2/h500
Evaluating performance on  test set...
2006/2006 - 40s - 40s/epoch - 20ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1188011
{'0': {'precision': 0.3550869488664022, 'recall': 0.3703495657434213, 'f1-score': 0.36255770054409037, 'support': 185144}, '1': {'precision': 0.29713763652448555, 'recall': 0.47891180938674344, 'f1-score': 0.3667362276839243, 'support': 150084}, '2': {'precision': 0.36928379931060895, 'recall': 0.16241255011173372, 'f1-score': 0.225603668808885, 'support': 178102}, 'accuracy': 0.3299456489977208, 'macro avg': {'precision': 0.3405027949004989, 'recall': 0.3372246417472995, 'f1-score': 0.31829919901229986, 'support': 513330}, 'weighted avg': {'precision': 0.34306977251647114, 'recall': 0.3299456489977208, 'f1-score': 0.3162626137717437, 'support': 513330}}
[[68568 89428 27148]
 [55951 71877 22256]
 [68583 80593 28926]]
Evaluating performance on  train set...
538/538 - 11s - 11s/epoch - 21ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1097428
{'0': {'precision': 0.3685279639404543, 'recall': 0.5113566226391804, 'f1-score': 0.4283498492029298, 'support': 48606}, '1': {'precision': 0.32463179066015796, 'recall': 0.34761637689287717, 'f1-score': 0.33573115507117623, 'support': 44575}, '2': {'precision': 0.335703425453895, 'recall': 0.16924429614933717, 'f1-score': 0.22503672172427233, 'support': 44356}, 'accuracy': 0.3479572769509296, 'macro avg': {'precision': 0.3429543933515024, 'recall': 0.34273909856046486, 'f1-score': 0.3297059086661261, 'support': 137537}, 'weighted avg': {'precision': 0.34371546146418225, 'recall': 0.3479572769509296, 'f1-score': 0.33276367694843645, 'support': 137537}}
[[24855 16701  7050]
 [21275 15495  7805]
 [21314 15535  7507]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 22ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0993042
{'0': {'precision': 0.29091759673862194, 'recall': 0.37658967038671165, 'f1-score': 0.32825578764799035, 'support': 11559}, '1': {'precision': 0.4112414272935096, 'recall': 0.5340087764584409, 'f1-score': 0.4646527036891459, 'support': 15496}, '2': {'precision': 0.3475409836065574, 'recall': 0.11488120050020842, 'f1-score': 0.17268170426065163, 'support': 11995}, 'accuracy': 0.3586683738796415, 'macro avg': {'precision': 0.3499000025462296, 'recall': 0.3418265491151203, 'f1-score': 0.321863398532596, 'support': 39050}, 'weighted avg': {'precision': 0.356058073147314, 'recall': 0.3586683738796415, 'f1-score': 0.3345937000869819, 'support': 39050}}
[[4353 6095 1111]
 [5745 8275 1476]
 [4865 5752 1378]]
training model: results/QRTEA/W7/deepLOB_L2/h1000
Epoch 1/50
538/538 - 30s - loss: 3.2598 - accuracy1000: 0.4089 - val_loss: 3.4487 - val_accuracy1000: 0.3214 - 30s/epoch - 55ms/step
Epoch 2/50
538/538 - 27s - loss: 3.2301 - accuracy1000: 0.4176 - val_loss: 3.4159 - val_accuracy1000: 0.3415 - 27s/epoch - 49ms/step
Epoch 3/50
538/538 - 27s - loss: 3.2284 - accuracy1000: 0.4157 - val_loss: 3.3717 - val_accuracy1000: 0.3431 - 27s/epoch - 50ms/step
Epoch 4/50
538/538 - 26s - loss: 3.2270 - accuracy1000: 0.4182 - val_loss: 3.4093 - val_accuracy1000: 0.3269 - 26s/epoch - 49ms/step
Epoch 5/50
538/538 - 27s - loss: 3.2073 - accuracy1000: 0.4286 - val_loss: 3.4844 - val_accuracy1000: 0.3327 - 27s/epoch - 50ms/step
Epoch 6/50
538/538 - 26s - loss: 3.1821 - accuracy1000: 0.4346 - val_loss: 3.3669 - val_accuracy1000: 0.3265 - 26s/epoch - 49ms/step
Epoch 7/50
538/538 - 27s - loss: 3.1941 - accuracy1000: 0.4353 - val_loss: 3.2625 - val_accuracy1000: 0.3996 - 27s/epoch - 50ms/step
Epoch 8/50
538/538 - 27s - loss: 3.1529 - accuracy1000: 0.4526 - val_loss: 3.3100 - val_accuracy1000: 0.3564 - 27s/epoch - 50ms/step
Epoch 9/50
538/538 - 27s - loss: 3.1122 - accuracy1000: 0.4661 - val_loss: 3.3277 - val_accuracy1000: 0.3559 - 27s/epoch - 50ms/step
Epoch 10/50
538/538 - 27s - loss: 3.0785 - accuracy1000: 0.4789 - val_loss: 3.5452 - val_accuracy1000: 0.3048 - 27s/epoch - 50ms/step
Epoch 11/50
538/538 - 27s - loss: 3.0563 - accuracy1000: 0.4873 - val_loss: 3.4177 - val_accuracy1000: 0.3412 - 27s/epoch - 50ms/step
Epoch 12/50
538/538 - 27s - loss: 3.0376 - accuracy1000: 0.4949 - val_loss: 3.4930 - val_accuracy1000: 0.3123 - 27s/epoch - 50ms/step
Epoch 13/50
538/538 - 27s - loss: 3.0085 - accuracy1000: 0.5050 - val_loss: 3.6321 - val_accuracy1000: 0.3167 - 27s/epoch - 50ms/step
Epoch 14/50
538/538 - 27s - loss: 2.9711 - accuracy1000: 0.5168 - val_loss: 3.6119 - val_accuracy1000: 0.3089 - 27s/epoch - 50ms/step
Epoch 15/50
538/538 - 27s - loss: 2.9406 - accuracy1000: 0.5262 - val_loss: 3.5183 - val_accuracy1000: 0.3366 - 27s/epoch - 50ms/step
Epoch 16/50
538/538 - 27s - loss: 2.9173 - accuracy1000: 0.5319 - val_loss: 3.6080 - val_accuracy1000: 0.3181 - 27s/epoch - 50ms/step
Epoch 17/50
538/538 - 27s - loss: 2.8975 - accuracy1000: 0.5356 - val_loss: 3.5854 - val_accuracy1000: 0.3319 - 27s/epoch - 50ms/step
testing model: results/QRTEA/W7/deepLOB_L2/h1000
Evaluating performance on  test set...
2006/2006 - 40s - 40s/epoch - 20ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1074724
{'0': {'precision': 0.4318402559561218, 'recall': 0.07438955977442499, 'f1-score': 0.12691629586096884, 'support': 203214}, '1': {'precision': 0.22001871206608398, 'recall': 0.2386607104133235, 'f1-score': 0.22896088009386778, 'support': 115285}, '2': {'precision': 0.39187196231788063, 'recall': 0.7105491425902449, 'f1-score': 0.5051505011840861, 'support': 194831}, 'accuracy': 0.3527321605984454, 'macro avg': {'precision': 0.3479103101133621, 'recall': 0.34119980425933116, 'f1-score': 0.2870092257129742, 'support': 513330}, 'weighted avg': {'precision': 0.36909911613340507, 'recall': 0.3527321605984454, 'f1-score': 0.2933900229967256, 'support': 513330}}
[[ 15117  54029 134068]
 [  7005  27514  80766]
 [ 12884  43510 138437]]
Evaluating performance on  train set...
538/538 - 12s - 12s/epoch - 22ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1114354
{'0': {'precision': 0.3873015873015873, 'recall': 0.11411172361639038, 'f1-score': 0.17628431764380362, 'support': 50249}, '1': {'precision': 0.31040564373897706, 'recall': 0.16143750881979396, 'f1-score': 0.21240581145270845, 'support': 42518}, '2': {'precision': 0.3288146373945279, 'recall': 0.7389993299084208, 'f1-score': 0.4551238401804814, 'support': 44770}, 'accuracy': 0.33215062128736267, 'macro avg': {'precision': 0.3421739561450307, 'recall': 0.33818285411486837, 'f1-score': 0.28127132309233116, 'support': 137537}, 'weighted avg': {'precision': 0.3444918526430292, 'recall': 0.33215062128736267, 'f1-score': 0.2782165911246421, 'support': 137537}}
[[ 5734  8315 36200]
 [ 4320  6864 31334]
 [ 4751  6934 33085]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 22ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0862601
{'0': {'precision': 0.33646616541353386, 'recall': 0.07003677909069567, 'f1-score': 0.11594015156422047, 'support': 12779}, '1': {'precision': 0.44395356895356897, 'recall': 0.3942307692307692, 'f1-score': 0.41761734028683184, 'support': 13000}, '2': {'precision': 0.38589712629799566, 'recall': 0.7224775826991183, 'f1-score': 0.5030826140567201, 'support': 13271}, 'accuracy': 0.39969270166453263, 'macro avg': {'precision': 0.3887722868883661, 'recall': 0.3955817103401944, 'f1-score': 0.34554670196925746, 'support': 39050}, 'weighted avg': {'precision': 0.3890483556291075, 'recall': 0.39969270166453263, 'f1-score': 0.3479394107993526, 'support': 39050}}
[[ 895 3526 8358]
 [ 975 5125 6900]
 [ 790 2893 9588]]
training model: results/QRTEA/W7/deepOF_L2/h10
Epoch 1/50
538/538 - 20s - loss: 2.9213 - accuracy10: 0.4875 - val_loss: 2.9406 - val_accuracy10: 0.6541 - 20s/epoch - 37ms/step
Epoch 2/50
538/538 - 18s - loss: 2.5907 - accuracy10: 0.5649 - val_loss: 2.8550 - val_accuracy10: 0.7264 - 18s/epoch - 33ms/step
Epoch 3/50
538/538 - 18s - loss: 2.4339 - accuracy10: 0.6119 - val_loss: 2.7121 - val_accuracy10: 0.7195 - 18s/epoch - 33ms/step
Epoch 4/50
538/538 - 18s - loss: 2.3321 - accuracy10: 0.6331 - val_loss: 2.6146 - val_accuracy10: 0.7135 - 18s/epoch - 33ms/step
Epoch 5/50
538/538 - 18s - loss: 2.2734 - accuracy10: 0.6486 - val_loss: 2.5551 - val_accuracy10: 0.7140 - 18s/epoch - 33ms/step
Epoch 6/50
538/538 - 18s - loss: 2.2220 - accuracy10: 0.6578 - val_loss: 2.5600 - val_accuracy10: 0.7250 - 18s/epoch - 33ms/step
Epoch 7/50
538/538 - 17s - loss: 2.1929 - accuracy10: 0.6617 - val_loss: 2.5903 - val_accuracy10: 0.7394 - 17s/epoch - 31ms/step
Epoch 8/50
538/538 - 17s - loss: 2.1638 - accuracy10: 0.6653 - val_loss: 2.4903 - val_accuracy10: 0.7221 - 17s/epoch - 32ms/step
Epoch 9/50
538/538 - 17s - loss: 2.1410 - accuracy10: 0.6686 - val_loss: 2.5175 - val_accuracy10: 0.7273 - 17s/epoch - 33ms/step
Epoch 10/50
538/538 - 18s - loss: 2.1159 - accuracy10: 0.6717 - val_loss: 2.4697 - val_accuracy10: 0.7046 - 18s/epoch - 34ms/step
Epoch 11/50
538/538 - 18s - loss: 2.0925 - accuracy10: 0.6744 - val_loss: 2.5201 - val_accuracy10: 0.7190 - 18s/epoch - 33ms/step
Epoch 12/50
538/538 - 18s - loss: 2.0807 - accuracy10: 0.6739 - val_loss: 2.4781 - val_accuracy10: 0.7044 - 18s/epoch - 33ms/step
Epoch 13/50
538/538 - 18s - loss: 2.0619 - accuracy10: 0.6768 - val_loss: 2.5224 - val_accuracy10: 0.7148 - 18s/epoch - 33ms/step
Epoch 14/50
538/538 - 18s - loss: 2.0466 - accuracy10: 0.6746 - val_loss: 2.5283 - val_accuracy10: 0.7060 - 18s/epoch - 34ms/step
Epoch 15/50
538/538 - 18s - loss: 2.0239 - accuracy10: 0.6768 - val_loss: 2.5728 - val_accuracy10: 0.7193 - 18s/epoch - 33ms/step
Epoch 16/50
538/538 - 18s - loss: 2.0130 - accuracy10: 0.6777 - val_loss: 2.5762 - val_accuracy10: 0.7277 - 18s/epoch - 33ms/step
Epoch 17/50
538/538 - 18s - loss: 1.9994 - accuracy10: 0.6806 - val_loss: 2.5800 - val_accuracy10: 0.7056 - 18s/epoch - 33ms/step
Epoch 18/50
538/538 - 18s - loss: 1.9844 - accuracy10: 0.6819 - val_loss: 2.5934 - val_accuracy10: 0.7154 - 18s/epoch - 33ms/step
Epoch 19/50
538/538 - 18s - loss: 1.9690 - accuracy10: 0.6834 - val_loss: 2.6290 - val_accuracy10: 0.7068 - 18s/epoch - 33ms/step
Epoch 20/50
538/538 - 18s - loss: 1.9583 - accuracy10: 0.6829 - val_loss: 2.6684 - val_accuracy10: 0.7044 - 18s/epoch - 33ms/step
testing model: results/QRTEA/W7/deepOF_L2/h10
Evaluating performance on  test set...
2006/2006 - 34s - 34s/epoch - 17ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.62466323
{'0': {'precision': 0.35896806848554497, 'recall': 0.5753756364087917, 'f1-score': 0.44211028505546063, 'support': 48318}, '1': {'precision': 0.9164075934569543, 'recall': 0.7783515044536432, 'f1-score': 0.8417564831949828, 'support': 416962}, '2': {'precision': 0.3452912603540884, 'recall': 0.5873868248517016, 'f1-score': 0.43491862902231543, 'support': 48045}, 'accuracy': 0.7413724248770273, 'macro avg': {'precision': 0.540222307432196, 'recall': 0.6470379885713788, 'f1-score': 0.5729284657575863, 'support': 513325}, 'weighted avg': {'precision': 0.8104831845707794, 'recall': 0.7413724248770273, 'f1-score': 0.7660605211720319, 'support': 513325}}
[[ 27801  16301   4216]
 [ 43125 324543  49294]
 [  6521  13303  28221]]
Evaluating performance on  train set...
538/538 - 10s - 10s/epoch - 18ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.6483763
{'0': {'precision': 0.400193485972267, 'recall': 0.5990208247138326, 'f1-score': 0.47982545775912067, 'support': 14502}, '1': {'precision': 0.9133772538911911, 'recall': 0.753752074298864, 'f1-score': 0.8259227260854713, 'support': 109073}, '2': {'precision': 0.3255606770732463, 'recall': 0.6020773638968482, 'f1-score': 0.422606028609498, 'support': 13960}, 'accuracy': 0.7220416621223689, 'macro avg': {'precision': 0.5463771389789014, 'recall': 0.6516167543031816, 'f1-score': 0.5761180708180299, 'support': 137535}, 'weighted avg': {'precision': 0.7996017755421254, 'recall': 0.7220416621223689, 'f1-score': 0.7484922270704328, 'support': 137535}}
[[ 8687  4443  1372]
 [10819 82214 16040]
 [ 2201  3354  8405]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 18ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.6777918
{'0': {'precision': 0.3651229902432321, 'recall': 0.6116482504604052, 'f1-score': 0.4572756217193012, 'support': 4344}, '1': {'precision': 0.9035446627506583, 'recall': 0.7354502588452534, 'f1-score': 0.8108776266996292, 'support': 30327}, '2': {'precision': 0.34452595936794583, 'recall': 0.5576615665677095, 'f1-score': 0.42591785122525505, 'support': 4379}, 'accuracy': 0.701741357234315, 'macro avg': {'precision': 0.537731204120612, 'recall': 0.6349200252911227, 'f1-score': 0.5646903665480618, 'support': 39050}, 'weighted avg': {'precision': 0.7809621621748539, 'recall': 0.701741357234315, 'f1-score': 0.7283735046397871, 'support': 39050}}
[[ 2657  1240   447]
 [ 3824 22304  4199]
 [  796  1141  2442]]
training model: results/QRTEA/W7/deepOF_L2/h20
Epoch 1/50
538/538 - 20s - loss: 2.9730 - accuracy20: 0.4534 - val_loss: 3.0296 - val_accuracy20: 0.6325 - 20s/epoch - 38ms/step
Epoch 2/50
538/538 - 18s - loss: 2.6750 - accuracy20: 0.5354 - val_loss: 2.9777 - val_accuracy20: 0.6827 - 18s/epoch - 33ms/step
Epoch 3/50
538/538 - 16s - loss: 2.5413 - accuracy20: 0.5716 - val_loss: 2.8667 - val_accuracy20: 0.6889 - 16s/epoch - 30ms/step
Epoch 4/50
538/538 - 16s - loss: 2.4537 - accuracy20: 0.5954 - val_loss: 2.8296 - val_accuracy20: 0.7020 - 16s/epoch - 30ms/step
Epoch 5/50
538/538 - 17s - loss: 2.3968 - accuracy20: 0.6107 - val_loss: 2.7991 - val_accuracy20: 0.7033 - 17s/epoch - 31ms/step
Epoch 6/50
538/538 - 17s - loss: 2.3531 - accuracy20: 0.6241 - val_loss: 2.7684 - val_accuracy20: 0.7091 - 17s/epoch - 32ms/step
Epoch 7/50
538/538 - 17s - loss: 2.3179 - accuracy20: 0.6314 - val_loss: 2.7435 - val_accuracy20: 0.7075 - 17s/epoch - 31ms/step
Epoch 8/50
538/538 - 18s - loss: 2.2907 - accuracy20: 0.6355 - val_loss: 2.6779 - val_accuracy20: 0.7025 - 18s/epoch - 33ms/step
Epoch 9/50
538/538 - 17s - loss: 2.2726 - accuracy20: 0.6387 - val_loss: 2.6854 - val_accuracy20: 0.7014 - 17s/epoch - 32ms/step
Epoch 10/50
538/538 - 17s - loss: 2.2512 - accuracy20: 0.6440 - val_loss: 2.7005 - val_accuracy20: 0.7041 - 17s/epoch - 31ms/step
Epoch 11/50
538/538 - 17s - loss: 2.2311 - accuracy20: 0.6447 - val_loss: 2.6832 - val_accuracy20: 0.6955 - 17s/epoch - 32ms/step
Epoch 12/50
538/538 - 17s - loss: 2.2184 - accuracy20: 0.6473 - val_loss: 2.6575 - val_accuracy20: 0.6903 - 17s/epoch - 32ms/step
Epoch 13/50
538/538 - 17s - loss: 2.2010 - accuracy20: 0.6497 - val_loss: 2.6477 - val_accuracy20: 0.6854 - 17s/epoch - 32ms/step
Epoch 14/50
538/538 - 17s - loss: 2.1793 - accuracy20: 0.6533 - val_loss: 2.6678 - val_accuracy20: 0.6750 - 17s/epoch - 32ms/step
Epoch 15/50
538/538 - 18s - loss: 2.1656 - accuracy20: 0.6521 - val_loss: 2.6918 - val_accuracy20: 0.6900 - 18s/epoch - 33ms/step
Epoch 16/50
538/538 - 18s - loss: 2.1531 - accuracy20: 0.6555 - val_loss: 2.6963 - val_accuracy20: 0.6828 - 18s/epoch - 33ms/step
Epoch 17/50
538/538 - 17s - loss: 2.1420 - accuracy20: 0.6562 - val_loss: 2.6840 - val_accuracy20: 0.6696 - 17s/epoch - 32ms/step
Epoch 18/50
538/538 - 17s - loss: 2.1246 - accuracy20: 0.6591 - val_loss: 2.7526 - val_accuracy20: 0.6750 - 17s/epoch - 31ms/step
Epoch 19/50
538/538 - 17s - loss: 2.1111 - accuracy20: 0.6594 - val_loss: 2.6949 - val_accuracy20: 0.6719 - 17s/epoch - 31ms/step
Epoch 20/50
538/538 - 17s - loss: 2.0945 - accuracy20: 0.6621 - val_loss: 2.7559 - val_accuracy20: 0.6743 - 17s/epoch - 31ms/step
Epoch 21/50
538/538 - 17s - loss: 2.0801 - accuracy20: 0.6612 - val_loss: 2.7524 - val_accuracy20: 0.6828 - 17s/epoch - 32ms/step
Epoch 22/50
538/538 - 17s - loss: 2.0703 - accuracy20: 0.6613 - val_loss: 2.7995 - val_accuracy20: 0.6805 - 17s/epoch - 31ms/step
Epoch 23/50
538/538 - 17s - loss: 2.0582 - accuracy20: 0.6640 - val_loss: 2.8148 - val_accuracy20: 0.6548 - 17s/epoch - 31ms/step
testing model: results/QRTEA/W7/deepOF_L2/h20
Evaluating performance on  test set...
2006/2006 - 35s - 35s/epoch - 18ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.6652698
{'0': {'precision': 0.4065092316246979, 'recall': 0.534417425033567, 'f1-score': 0.4617695019690495, 'support': 67030}, '1': {'precision': 0.8514025903834314, 'recall': 0.8032745519110315, 'f1-score': 0.826638643642344, 'support': 380449}, '2': {'precision': 0.476554836178144, 'recall': 0.47955836345412023, 'f1-score': 0.4780518821864095, 'support': 65846}, 'accuracy': 0.7266429649831978, 'macro avg': {'precision': 0.5781555527287577, 'recall': 0.6057501134662396, 'f1-score': 0.5888200092659343, 'support': 513325}, 'weighted avg': {'precision': 0.7452253594653985, 'recall': 0.7266429649831978, 'f1-score': 0.7342795680836074, 'support': 513325}}
[[ 35822  27443   3765]
 [ 43925 305605  30919]
 [  8374  25895  31577]]
Evaluating performance on  train set...
538/538 - 9s - 9s/epoch - 17ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.66727686
{'0': {'precision': 0.4578627634851388, 'recall': 0.5740428359658539, 'f1-score': 0.5094125652075301, 'support': 19563}, '1': {'precision': 0.8536794537718112, 'recall': 0.7831415228508316, 'f1-score': 0.8168905909707828, 'support': 99143}, '2': {'precision': 0.4302035634945822, 'recall': 0.5039566625949333, 'f1-score': 0.46416866409039764, 'support': 18829}, 'accuracy': 0.7151779547024394, 'macro avg': {'precision': 0.5805819269171774, 'recall': 0.6203803404705396, 'f1-score': 0.5968239400895702, 'support': 137535}, 'weighted avg': {'precision': 0.739403164462849, 'recall': 0.7151779547024394, 'f1-score': 0.7248660606385962, 'support': 137535}}
[[11230  7027  1306]
 [10238 77643 11262]
 [ 3059  6281  9489]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 18ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.7139232
{'0': {'precision': 0.4275282949981745, 'recall': 0.5975506038441912, 'f1-score': 0.4984392735527809, 'support': 5879}, '1': {'precision': 0.8371627963922785, 'recall': 0.7519703801458998, 'f1-score': 0.7922830327140706, 'support': 27279}, '2': {'precision': 0.43333333333333335, 'recall': 0.46554650373387646, 'f1-score': 0.44886270659466543, 'support': 5892}, 'accuracy': 0.68550576184379, 'macro avg': {'precision': 0.5660081415745954, 'recall': 0.6050224959079892, 'f1-score': 0.579861670953839, 'support': 39050}, 'weighted avg': {'precision': 0.7145608903733479, 'recall': 0.68550576184379, 'f1-score': 0.6962282306243202, 'support': 39050}}
[[ 3513  1950   416]
 [ 3595 20513  3171]
 [ 1109  2040  2743]]
training model: results/QRTEA/W7/deepOF_L2/h30
Epoch 1/50
538/538 - 19s - loss: 3.0341 - accuracy30: 0.4365 - val_loss: 3.0698 - val_accuracy30: 0.5890 - 19s/epoch - 35ms/step
Epoch 2/50
538/538 - 17s - loss: 2.7605 - accuracy30: 0.5117 - val_loss: 3.0136 - val_accuracy30: 0.6367 - 17s/epoch - 31ms/step
Epoch 3/50
538/538 - 17s - loss: 2.6392 - accuracy30: 0.5507 - val_loss: 2.9079 - val_accuracy30: 0.6427 - 17s/epoch - 32ms/step
Epoch 4/50
538/538 - 17s - loss: 2.5603 - accuracy30: 0.5702 - val_loss: 2.8688 - val_accuracy30: 0.6487 - 17s/epoch - 32ms/step
Epoch 5/50
538/538 - 17s - loss: 2.5064 - accuracy30: 0.5845 - val_loss: 2.8709 - val_accuracy30: 0.6679 - 17s/epoch - 31ms/step
Epoch 6/50
538/538 - 17s - loss: 2.4672 - accuracy30: 0.5961 - val_loss: 2.8103 - val_accuracy30: 0.6619 - 17s/epoch - 31ms/step
Epoch 7/50
538/538 - 17s - loss: 2.4385 - accuracy30: 0.6059 - val_loss: 2.8157 - val_accuracy30: 0.6647 - 17s/epoch - 32ms/step
Epoch 8/50
538/538 - 17s - loss: 2.4118 - accuracy30: 0.6118 - val_loss: 2.7617 - val_accuracy30: 0.6507 - 17s/epoch - 32ms/step
Epoch 9/50
538/538 - 17s - loss: 2.3931 - accuracy30: 0.6157 - val_loss: 2.7549 - val_accuracy30: 0.6595 - 17s/epoch - 32ms/step
Epoch 10/50
538/538 - 17s - loss: 2.3702 - accuracy30: 0.6210 - val_loss: 2.7531 - val_accuracy30: 0.6550 - 17s/epoch - 32ms/step
Epoch 11/50
538/538 - 17s - loss: 2.3553 - accuracy30: 0.6219 - val_loss: 2.7696 - val_accuracy30: 0.6534 - 17s/epoch - 32ms/step
Epoch 12/50
538/538 - 17s - loss: 2.3418 - accuracy30: 0.6251 - val_loss: 2.7430 - val_accuracy30: 0.6513 - 17s/epoch - 32ms/step
Epoch 13/50
538/538 - 17s - loss: 2.3239 - accuracy30: 0.6295 - val_loss: 2.7420 - val_accuracy30: 0.6509 - 17s/epoch - 32ms/step
Epoch 14/50
538/538 - 17s - loss: 2.3065 - accuracy30: 0.6313 - val_loss: 2.7455 - val_accuracy30: 0.6475 - 17s/epoch - 31ms/step
Epoch 15/50
538/538 - 17s - loss: 2.2946 - accuracy30: 0.6312 - val_loss: 2.7561 - val_accuracy30: 0.6527 - 17s/epoch - 32ms/step
Epoch 16/50
538/538 - 18s - loss: 2.2816 - accuracy30: 0.6359 - val_loss: 2.7453 - val_accuracy30: 0.6472 - 18s/epoch - 33ms/step
Epoch 17/50
538/538 - 17s - loss: 2.2684 - accuracy30: 0.6363 - val_loss: 2.7457 - val_accuracy30: 0.6441 - 17s/epoch - 32ms/step
Epoch 18/50
538/538 - 17s - loss: 2.2503 - accuracy30: 0.6381 - val_loss: 2.7586 - val_accuracy30: 0.6511 - 17s/epoch - 32ms/step
Epoch 19/50
538/538 - 18s - loss: 2.2374 - accuracy30: 0.6424 - val_loss: 2.7610 - val_accuracy30: 0.6434 - 18s/epoch - 33ms/step
Epoch 20/50
538/538 - 17s - loss: 2.2157 - accuracy30: 0.6444 - val_loss: 2.7852 - val_accuracy30: 0.6534 - 17s/epoch - 32ms/step
Epoch 21/50
538/538 - 17s - loss: 2.2066 - accuracy30: 0.6461 - val_loss: 2.7948 - val_accuracy30: 0.6506 - 17s/epoch - 32ms/step
Epoch 22/50
538/538 - 18s - loss: 2.1898 - accuracy30: 0.6472 - val_loss: 2.8296 - val_accuracy30: 0.6565 - 18s/epoch - 33ms/step
Epoch 23/50
538/538 - 17s - loss: 2.1802 - accuracy30: 0.6494 - val_loss: 2.8189 - val_accuracy30: 0.6507 - 17s/epoch - 32ms/step
testing model: results/QRTEA/W7/deepOF_L2/h30
Evaluating performance on  test set...
2006/2006 - 31s - 31s/epoch - 16ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.74047244
{'0': {'precision': 0.4528151356279918, 'recall': 0.4785709123322653, 'f1-score': 0.4653369095445015, 'support': 83018}, '1': {'precision': 0.7945295007209594, 'recall': 0.7760678329025074, 'f1-score': 0.7851901624957822, 'support': 349329}, '2': {'precision': 0.4667962499851848, 'recall': 0.4863666674899355, 'f1-score': 0.4763805480462773, 'support': 80978}, 'accuracy': 0.6822539326937126, 'macro avg': {'precision': 0.571380295444712, 'recall': 0.5803351375749027, 'f1-score': 0.575635873362187, 'support': 513325}, 'weighted avg': {'precision': 0.6875648558286016, 'recall': 0.6822539326937126, 'f1-score': 0.6847462676681363, 'support': 513325}}
[[ 39730  36864   6424]
 [ 39662 271103  38564]
 [  8348  33245  39385]]
Evaluating performance on  train set...
538/538 - 10s - 10s/epoch - 19ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.73418355
{'0': {'precision': 0.5056981840951784, 'recall': 0.5118735739034902, 'f1-score': 0.5087671405472376, 'support': 23666}, '1': {'precision': 0.8005171690816755, 'recall': 0.7537646555600644, 'f1-score': 0.7764377587852839, 'support': 91177}, '2': {'precision': 0.4382934218118869, 'recall': 0.5355631940772079, 'f1-score': 0.482070606902023, 'support': 22692}, 'accuracy': 0.6761406187515905, 'macro avg': {'precision': 0.581502924996247, 'recall': 0.6004004745135875, 'f1-score': 0.5890918354115149, 'support': 137535}, 'weighted avg': {'precision': 0.6900233502592922, 'recall': 0.6761406187515905, 'f1-score': 0.6818111382032025, 'support': 137535}}
[[12114  9396  2156]
 [ 9032 68726 13419]
 [ 2809  7730 12153]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 18ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.77301306
{'0': {'precision': 0.4804651770547498, 'recall': 0.5173772337132405, 'f1-score': 0.4982384823848239, 'support': 7107}, '1': {'precision': 0.7740639425542828, 'recall': 0.7294771610408443, 'f1-score': 0.7511094521172909, 'support': 24826}, '2': {'precision': 0.45019372578427697, 'recall': 0.5061121258957426, 'f1-score': 0.4765180579441725, 'support': 7117}, 'accuracy': 0.6501664532650449, 'macro avg': {'precision': 0.5682409484644365, 'recall': 0.5843221735499425, 'f1-score': 0.5752886641487625, 'support': 39050}, 'weighted avg': {'precision': 0.6616032316923799, 'recall': 0.6501664532650449, 'f1-score': 0.6550423347237256, 'support': 39050}}
[[ 3677  2727   703]
 [ 3020 18110  3696]
 [  956  2559  3602]]
training model: results/QRTEA/W7/deepOF_L2/h50
Epoch 1/50
538/538 - 20s - loss: 3.1251 - accuracy50: 0.4139 - val_loss: 3.1761 - val_accuracy50: 0.5260 - 20s/epoch - 37ms/step
Epoch 2/50
538/538 - 18s - loss: 2.9115 - accuracy50: 0.4868 - val_loss: 3.1767 - val_accuracy50: 0.5701 - 18s/epoch - 33ms/step
Epoch 3/50
538/538 - 17s - loss: 2.8130 - accuracy50: 0.5185 - val_loss: 3.1341 - val_accuracy50: 0.5808 - 17s/epoch - 32ms/step
Epoch 4/50
538/538 - 18s - loss: 2.7503 - accuracy50: 0.5378 - val_loss: 3.0674 - val_accuracy50: 0.5837 - 18s/epoch - 33ms/step
Epoch 5/50
538/538 - 17s - loss: 2.7050 - accuracy50: 0.5478 - val_loss: 3.0330 - val_accuracy50: 0.5905 - 17s/epoch - 32ms/step
Epoch 6/50
538/538 - 18s - loss: 2.6733 - accuracy50: 0.5580 - val_loss: 3.0250 - val_accuracy50: 0.5916 - 18s/epoch - 33ms/step
Epoch 7/50
538/538 - 18s - loss: 2.6461 - accuracy50: 0.5647 - val_loss: 2.9932 - val_accuracy50: 0.5950 - 18s/epoch - 33ms/step
Epoch 8/50
538/538 - 18s - loss: 2.6206 - accuracy50: 0.5719 - val_loss: 2.9935 - val_accuracy50: 0.5995 - 18s/epoch - 33ms/step
Epoch 9/50
538/538 - 17s - loss: 2.6015 - accuracy50: 0.5768 - val_loss: 2.9958 - val_accuracy50: 0.6025 - 17s/epoch - 32ms/step
Epoch 10/50
538/538 - 17s - loss: 2.5819 - accuracy50: 0.5836 - val_loss: 2.9951 - val_accuracy50: 0.6010 - 17s/epoch - 32ms/step
Epoch 11/50
538/538 - 17s - loss: 2.5664 - accuracy50: 0.5874 - val_loss: 2.9779 - val_accuracy50: 0.6000 - 17s/epoch - 32ms/step
Epoch 12/50
538/538 - 17s - loss: 2.5499 - accuracy50: 0.5918 - val_loss: 2.9552 - val_accuracy50: 0.5962 - 17s/epoch - 32ms/step
Epoch 13/50
538/538 - 17s - loss: 2.5340 - accuracy50: 0.5951 - val_loss: 2.9578 - val_accuracy50: 0.5972 - 17s/epoch - 32ms/step
Epoch 14/50
538/538 - 17s - loss: 2.5227 - accuracy50: 0.5960 - val_loss: 2.9285 - val_accuracy50: 0.5896 - 17s/epoch - 32ms/step
Epoch 15/50
538/538 - 18s - loss: 2.5060 - accuracy50: 0.5999 - val_loss: 2.9333 - val_accuracy50: 0.5880 - 18s/epoch - 33ms/step
Epoch 16/50
538/538 - 17s - loss: 2.4885 - accuracy50: 0.6030 - val_loss: 2.9331 - val_accuracy50: 0.5798 - 17s/epoch - 32ms/step
Epoch 17/50
538/538 - 17s - loss: 2.4724 - accuracy50: 0.6075 - val_loss: 2.9558 - val_accuracy50: 0.5837 - 17s/epoch - 32ms/step
Epoch 18/50
538/538 - 17s - loss: 2.4598 - accuracy50: 0.6098 - val_loss: 2.9848 - val_accuracy50: 0.5740 - 17s/epoch - 31ms/step
Epoch 19/50
538/538 - 17s - loss: 2.4430 - accuracy50: 0.6120 - val_loss: 2.9956 - val_accuracy50: 0.5605 - 17s/epoch - 31ms/step
Epoch 20/50
538/538 - 17s - loss: 2.4290 - accuracy50: 0.6143 - val_loss: 3.0391 - val_accuracy50: 0.5720 - 17s/epoch - 31ms/step
Epoch 21/50
538/538 - 17s - loss: 2.4154 - accuracy50: 0.6174 - val_loss: 3.0503 - val_accuracy50: 0.5594 - 17s/epoch - 32ms/step
Epoch 22/50
538/538 - 17s - loss: 2.3931 - accuracy50: 0.6212 - val_loss: 3.0991 - val_accuracy50: 0.5603 - 17s/epoch - 31ms/step
Epoch 23/50
538/538 - 17s - loss: 2.3740 - accuracy50: 0.6229 - val_loss: 3.1574 - val_accuracy50: 0.5589 - 17s/epoch - 31ms/step
Epoch 24/50
538/538 - 17s - loss: 2.3659 - accuracy50: 0.6226 - val_loss: 3.2391 - val_accuracy50: 0.5763 - 17s/epoch - 32ms/step
testing model: results/QRTEA/W7/deepOF_L2/h50
Evaluating performance on  test set...
2006/2006 - 32s - 32s/epoch - 16ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.8481673
{'0': {'precision': 0.4859021198423019, 'recall': 0.427340885161384, 'f1-score': 0.4547438980808052, 'support': 110172}, '1': {'precision': 0.6850635642191232, 'recall': 0.7494167464566505, 'f1-score': 0.7157966597272201, 'support': 296612}, '2': {'precision': 0.4987602766540519, 'recall': 0.43048216179686694, 'f1-score': 0.462112777523086, 'support': 106541}, 'accuracy': 0.6140963327326743, 'macro avg': {'precision': 0.5565753202384923, 'recall': 0.5357465978049673, 'f1-score': 0.5442177784437038, 'support': 513325}, 'weighted avg': {'precision': 0.6036512947789957, 'recall': 0.6140963327326743, 'f1-score': 0.6071161174781196, 'support': 513325}}
[[ 47081  53620   9471]
 [ 37705 222286  36621]
 [ 12108  48569  45864]]
Evaluating performance on  train set...
538/538 - 9s - 9s/epoch - 17ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.82956165
{'0': {'precision': 0.5295808745649871, 'recall': 0.4596946314234116, 'f1-score': 0.49216923590726125, 'support': 30455}, '1': {'precision': 0.7020732464307883, 'recall': 0.7240046088849059, 'f1-score': 0.7128702886675911, 'support': 78110}, '2': {'precision': 0.47215948148875575, 'recall': 0.4978943734898171, 'f1-score': 0.4846855625934575, 'support': 28970}, 'accuracy': 0.6178500018177191, 'macro avg': {'precision': 0.5679378674948438, 'recall': 0.5605312045993782, 'f1-score': 0.5632416957227698, 'support': 137535}, 'weighted avg': {'precision': 0.6154490638187721, 'recall': 0.6178500018177191, 'f1-score': 0.615935238853482, 'support': 137535}}
[[14000 13245  3210]
 [ 8643 56552 12915]
 [ 3793 10753 14424]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 17ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.87277657
{'0': {'precision': 0.5059544864992336, 'recall': 0.47096915816046536, 'f1-score': 0.48783537971805363, 'support': 9111}, '1': {'precision': 0.6597010857220733, 'recall': 0.698609707990571, 'f1-score': 0.6785981308411214, 'support': 20787}, '2': {'precision': 0.4894810659186536, 'recall': 0.4576048951048951, 'f1-score': 0.4730065507115428, 'support': 9152}, 'accuracy': 0.5890140845070423, 'macro avg': {'precision': 0.5517122127133202, 'recall': 0.5423945870853104, 'f1-score': 0.5464800204235726, 'support': 39050}, 'weighted avg': {'precision': 0.5839356852928751, 'recall': 0.5890140845070423, 'f1-score': 0.5859063621643437, 'support': 39050}}
[[ 4291  3875   945]
 [ 2842 14522  3423]
 [ 1348  3616  4188]]
training model: results/QRTEA/W7/deepOF_L2/h100
Epoch 1/50
538/538 - 19s - loss: 3.2428 - accuracy100: 0.3894 - val_loss: 3.2574 - val_accuracy100: 0.4305 - 19s/epoch - 36ms/step
Epoch 2/50
538/538 - 17s - loss: 3.1189 - accuracy100: 0.4342 - val_loss: 3.2398 - val_accuracy100: 0.4418 - 17s/epoch - 32ms/step
Epoch 3/50
538/538 - 17s - loss: 3.0526 - accuracy100: 0.4630 - val_loss: 3.2536 - val_accuracy100: 0.4497 - 17s/epoch - 32ms/step
Epoch 4/50
538/538 - 17s - loss: 3.0067 - accuracy100: 0.4812 - val_loss: 3.2383 - val_accuracy100: 0.4553 - 17s/epoch - 31ms/step
Epoch 5/50
538/538 - 17s - loss: 2.9732 - accuracy100: 0.4922 - val_loss: 3.2202 - val_accuracy100: 0.4591 - 17s/epoch - 31ms/step
Epoch 6/50
538/538 - 18s - loss: 2.9454 - accuracy100: 0.5014 - val_loss: 3.2235 - val_accuracy100: 0.4633 - 18s/epoch - 33ms/step
Epoch 7/50
538/538 - 17s - loss: 2.9282 - accuracy100: 0.5048 - val_loss: 3.2017 - val_accuracy100: 0.4649 - 17s/epoch - 32ms/step
Epoch 8/50
538/538 - 17s - loss: 2.9080 - accuracy100: 0.5115 - val_loss: 3.1800 - val_accuracy100: 0.4731 - 17s/epoch - 31ms/step
Epoch 9/50
538/538 - 17s - loss: 2.8911 - accuracy100: 0.5171 - val_loss: 3.1578 - val_accuracy100: 0.4749 - 17s/epoch - 32ms/step
Epoch 10/50
538/538 - 17s - loss: 2.8749 - accuracy100: 0.5206 - val_loss: 3.1264 - val_accuracy100: 0.4810 - 17s/epoch - 32ms/step
Epoch 11/50
538/538 - 17s - loss: 2.8621 - accuracy100: 0.5262 - val_loss: 3.1232 - val_accuracy100: 0.4815 - 17s/epoch - 31ms/step
Epoch 12/50
538/538 - 17s - loss: 2.8457 - accuracy100: 0.5307 - val_loss: 3.1002 - val_accuracy100: 0.4890 - 17s/epoch - 32ms/step
Epoch 13/50
538/538 - 17s - loss: 2.8317 - accuracy100: 0.5345 - val_loss: 3.0864 - val_accuracy100: 0.4930 - 17s/epoch - 32ms/step
Epoch 14/50
538/538 - 17s - loss: 2.8155 - accuracy100: 0.5389 - val_loss: 3.0864 - val_accuracy100: 0.4916 - 17s/epoch - 32ms/step
Epoch 15/50
538/538 - 17s - loss: 2.8051 - accuracy100: 0.5425 - val_loss: 3.0626 - val_accuracy100: 0.4941 - 17s/epoch - 32ms/step
Epoch 16/50
538/538 - 17s - loss: 2.7904 - accuracy100: 0.5449 - val_loss: 3.0826 - val_accuracy100: 0.4891 - 17s/epoch - 32ms/step
Epoch 17/50
538/538 - 17s - loss: 2.7760 - accuracy100: 0.5497 - val_loss: 3.0859 - val_accuracy100: 0.4871 - 17s/epoch - 32ms/step
Epoch 18/50
538/538 - 17s - loss: 2.7612 - accuracy100: 0.5528 - val_loss: 3.1113 - val_accuracy100: 0.4861 - 17s/epoch - 32ms/step
Epoch 19/50
538/538 - 18s - loss: 2.7404 - accuracy100: 0.5591 - val_loss: 3.0897 - val_accuracy100: 0.4862 - 18s/epoch - 33ms/step
Epoch 20/50
538/538 - 18s - loss: 2.7254 - accuracy100: 0.5612 - val_loss: 3.1140 - val_accuracy100: 0.4781 - 18s/epoch - 33ms/step
Epoch 21/50
538/538 - 18s - loss: 2.7036 - accuracy100: 0.5670 - val_loss: 3.1242 - val_accuracy100: 0.4838 - 18s/epoch - 33ms/step
Epoch 22/50
538/538 - 18s - loss: 2.6908 - accuracy100: 0.5693 - val_loss: 3.1220 - val_accuracy100: 0.4804 - 18s/epoch - 33ms/step
Epoch 23/50
538/538 - 18s - loss: 2.6669 - accuracy100: 0.5750 - val_loss: 3.1434 - val_accuracy100: 0.4772 - 18s/epoch - 33ms/step
Epoch 24/50
538/538 - 18s - loss: 2.6498 - accuracy100: 0.5788 - val_loss: 3.1557 - val_accuracy100: 0.4780 - 18s/epoch - 33ms/step
Epoch 25/50
538/538 - 18s - loss: 2.6329 - accuracy100: 0.5843 - val_loss: 3.2055 - val_accuracy100: 0.4647 - 18s/epoch - 33ms/step
testing model: results/QRTEA/W7/deepOF_L2/h100
Evaluating performance on  test set...
2006/2006 - 34s - 34s/epoch - 17ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 0.9935249
{'0': {'precision': 0.5008617208812204, 'recall': 0.32951710822140584, 'f1-score': 0.3975113528892224, 'support': 154341}, '1': {'precision': 0.4918325398577652, 'recall': 0.7493544703814429, 'f1-score': 0.5938781334014207, 'support': 211067}, '2': {'precision': 0.5257918251055952, 'recall': 0.3206392774326142, 'f1-score': 0.3983537712077944, 'support': 147917}, 'accuracy': 0.49958603224078313, 'macro avg': {'precision': 0.5061620286148603, 'recall': 0.4665036186784876, 'f1-score': 0.4632477524994792, 'support': 513325}, 'weighted avg': {'precision': 0.5043328630922548, 'recall': 0.49958603224078313, 'f1-score': 0.47849543753890117, 'support': 513325}}
[[ 50858  85508  17975]
 [ 28103 158164  24800]
 [ 22580  77909  47428]]
Evaluating performance on  train set...
538/538 - 10s - 10s/epoch - 19ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 0.9549925
{'0': {'precision': 0.5532927293490674, 'recall': 0.34897121317615426, 'f1-score': 0.4279972320784441, 'support': 41651}, '1': {'precision': 0.5218539198100098, 'recall': 0.7279471365638767, 'f1-score': 0.6079080581552769, 'support': 56750}, '2': {'precision': 0.5088309503784693, 'recall': 0.4174119691317013, 'f1-score': 0.45860999199854, 'support': 39134}, 'accuracy': 0.5248191369469589, 'macro avg': {'precision': 0.5279925331791823, 'recall': 0.49811010629057745, 'f1-score': 0.49817176074408703, 'support': 137535}, 'weighted avg': {'precision': 0.5276692902275572, 'recall': 0.5248191369469589, 'f1-score': 0.5109429486347628, 'support': 137535}}
[[14535 20808  6308]
 [ 5979 41311  9460]
 [ 5756 17043 16335]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 19ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 0.99142116
{'0': {'precision': 0.5339920018819101, 'recall': 0.37523762294404495, 'f1-score': 0.4407553031406242, 'support': 12099}, '1': {'precision': 0.47676854232124155, 'recall': 0.67967424499491, 'f1-score': 0.5604208052376822, 'support': 14735}, '2': {'precision': 0.5151959756864389, 'recall': 0.40242305173542897, 'f1-score': 0.45187976836106264, 'support': 12216}, 'accuracy': 0.4986171574903969, 'macro avg': {'precision': 0.5086521732965302, 'recall': 0.48577830655812804, 'f1-score': 0.48435195891312305, 'support': 39050}, 'weighted avg': {'precision': 0.5065195324163447, 'recall': 0.4986171574903969, 'f1-score': 0.4893895576997286, 'support': 39050}}
[[ 4540  5605  1954]
 [ 2048 10015  2672]
 [ 1914  5386  4916]]
training model: results/QRTEA/W7/deepOF_L2/h200
Epoch 1/50
538/538 - 20s - loss: 3.2951 - accuracy200: 0.3644 - val_loss: 3.2850 - val_accuracy200: 0.3670 - 20s/epoch - 38ms/step
Epoch 2/50
538/538 - 18s - loss: 3.2345 - accuracy200: 0.3924 - val_loss: 3.2564 - val_accuracy200: 0.3731 - 18s/epoch - 33ms/step
Epoch 3/50
538/538 - 18s - loss: 3.2039 - accuracy200: 0.4064 - val_loss: 3.2501 - val_accuracy200: 0.3706 - 18s/epoch - 33ms/step
Epoch 4/50
538/538 - 18s - loss: 3.1786 - accuracy200: 0.4170 - val_loss: 3.2606 - val_accuracy200: 0.3681 - 18s/epoch - 33ms/step
Epoch 5/50
538/538 - 18s - loss: 3.1612 - accuracy200: 0.4260 - val_loss: 3.2780 - val_accuracy200: 0.3667 - 18s/epoch - 33ms/step
Epoch 6/50
538/538 - 18s - loss: 3.1479 - accuracy200: 0.4312 - val_loss: 3.2791 - val_accuracy200: 0.3682 - 18s/epoch - 33ms/step
Epoch 7/50
538/538 - 18s - loss: 3.1374 - accuracy200: 0.4349 - val_loss: 3.2857 - val_accuracy200: 0.3667 - 18s/epoch - 33ms/step
Epoch 8/50
538/538 - 18s - loss: 3.1285 - accuracy200: 0.4384 - val_loss: 3.2898 - val_accuracy200: 0.3683 - 18s/epoch - 33ms/step
Epoch 9/50
538/538 - 17s - loss: 3.1209 - accuracy200: 0.4420 - val_loss: 3.2930 - val_accuracy200: 0.3676 - 17s/epoch - 32ms/step
Epoch 10/50
538/538 - 17s - loss: 3.1148 - accuracy200: 0.4428 - val_loss: 3.2836 - val_accuracy200: 0.3706 - 17s/epoch - 32ms/step
Epoch 11/50
538/538 - 17s - loss: 3.1075 - accuracy200: 0.4471 - val_loss: 3.2921 - val_accuracy200: 0.3723 - 17s/epoch - 32ms/step
Epoch 12/50
538/538 - 17s - loss: 3.1004 - accuracy200: 0.4482 - val_loss: 3.2659 - val_accuracy200: 0.3772 - 17s/epoch - 32ms/step
Epoch 13/50
538/538 - 17s - loss: 3.0933 - accuracy200: 0.4510 - val_loss: 3.2836 - val_accuracy200: 0.3744 - 17s/epoch - 32ms/step
testing model: results/QRTEA/W7/deepOF_L2/h200
Evaluating performance on  test set...
2006/2006 - 31s - 31s/epoch - 16ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0790274
{'0': {'precision': 0.473044614239492, 'recall': 0.1756688911327854, 'f1-score': 0.25619698727283197, 'support': 177271}, '1': {'precision': 0.3496535147160355, 'recall': 0.8214723410390734, 'f1-score': 0.49052062145980635, 'support': 166456}, '2': {'precision': 0.47213951509995744, 'recall': 0.15707732402504745, 'f1-score': 0.2357292652927591, 'support': 169598}, 'accuracy': 0.3789412165781912, 'macro avg': {'precision': 0.43161254801849497, 'recall': 0.3847395187323021, 'f1-score': 0.3274822913417991, 'support': 513325}, 'weighted avg': {'precision': 0.43273352113835095, 'recall': 0.3789412165781912, 'f1-score': 0.3254188060812878, 'support': 513325}}
[[ 31141 128863  17267]
 [ 17200 136739  12517]
 [ 17490 125468  26640]]
Evaluating performance on  train set...
538/538 - 9s - 9s/epoch - 17ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0738658
{'0': {'precision': 0.4943932496946819, 'recall': 0.18340197693574958, 'f1-score': 0.26755189713702043, 'support': 48560}, '1': {'precision': 0.35114774090757095, 'recall': 0.8128400682982356, 'f1-score': 0.4904294554370446, 'support': 43925}, '2': {'precision': 0.4671299669338116, 'recall': 0.18501664816870145, 'f1-score': 0.2650533445693479, 'support': 45050}, 'accuracy': 0.3849565565128876, 'macro avg': {'precision': 0.4375569858453548, 'recall': 0.3937528978008955, 'f1-score': 0.341011565714471, 'support': 137535}, 'weighted avg': {'precision': 0.4397142962511871, 'recall': 0.3849565565128876, 'f1-score': 0.3379146190271205, 'support': 137535}}
[[ 8906 34144  5510]
 [ 4223 35704  3998]
 [ 4885 31830  8335]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 17ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0848821
{'0': {'precision': 0.4792746113989637, 'recall': 0.19413837043699872, 'f1-score': 0.2763403574286476, 'support': 13341}, '1': {'precision': 0.33297981404885635, 'recall': 0.7917787491593813, 'f1-score': 0.4688052161361769, 'support': 11896}, '2': {'precision': 0.4676245568203023, 'recall': 0.18142329689423006, 'f1-score': 0.2614229084080952, 'support': 13813}, 'accuracy': 0.37170294494238154, 'macro avg': {'precision': 0.4266263274227075, 'recall': 0.3891134721635367, 'f1-score': 0.33552282732430655, 'support': 39050}, 'weighted avg': {'precision': 0.4305871565161999, 'recall': 0.37170294494238154, 'f1-score': 0.3296952162215766, 'support': 39050}}
[[2590 9078 1673]
 [1297 9419 1180]
 [1517 9790 2506]]
training model: results/QRTEA/W7/deepOF_L2/h300
Epoch 1/50
538/538 - 20s - loss: 3.3125 - accuracy300: 0.3534 - val_loss: 3.3181 - val_accuracy300: 0.3527 - 20s/epoch - 37ms/step
Epoch 2/50
538/538 - 17s - loss: 3.2787 - accuracy300: 0.3721 - val_loss: 3.3025 - val_accuracy300: 0.3652 - 17s/epoch - 32ms/step
Epoch 3/50
538/538 - 17s - loss: 3.2611 - accuracy300: 0.3825 - val_loss: 3.3001 - val_accuracy300: 0.3648 - 17s/epoch - 32ms/step
Epoch 4/50
538/538 - 17s - loss: 3.2492 - accuracy300: 0.3906 - val_loss: 3.3001 - val_accuracy300: 0.3646 - 17s/epoch - 32ms/step
Epoch 5/50
538/538 - 18s - loss: 3.2394 - accuracy300: 0.3969 - val_loss: 3.3047 - val_accuracy300: 0.3595 - 18s/epoch - 33ms/step
Epoch 6/50
538/538 - 18s - loss: 3.2302 - accuracy300: 0.4014 - val_loss: 3.3061 - val_accuracy300: 0.3633 - 18s/epoch - 33ms/step
Epoch 7/50
538/538 - 17s - loss: 3.2230 - accuracy300: 0.4066 - val_loss: 3.3231 - val_accuracy300: 0.3580 - 17s/epoch - 32ms/step
Epoch 8/50
538/538 - 18s - loss: 3.2178 - accuracy300: 0.4084 - val_loss: 3.3263 - val_accuracy300: 0.3574 - 18s/epoch - 33ms/step
Epoch 9/50
538/538 - 18s - loss: 3.2126 - accuracy300: 0.4109 - val_loss: 3.3304 - val_accuracy300: 0.3577 - 18s/epoch - 33ms/step
Epoch 10/50
538/538 - 18s - loss: 3.2077 - accuracy300: 0.4131 - val_loss: 3.3292 - val_accuracy300: 0.3576 - 18s/epoch - 33ms/step
Epoch 11/50
538/538 - 18s - loss: 3.2036 - accuracy300: 0.4156 - val_loss: 3.3391 - val_accuracy300: 0.3581 - 18s/epoch - 33ms/step
Epoch 12/50
538/538 - 18s - loss: 3.1993 - accuracy300: 0.4173 - val_loss: 3.3434 - val_accuracy300: 0.3575 - 18s/epoch - 33ms/step
Epoch 13/50
538/538 - 18s - loss: 3.1933 - accuracy300: 0.4207 - val_loss: 3.3445 - val_accuracy300: 0.3587 - 18s/epoch - 33ms/step
testing model: results/QRTEA/W7/deepOF_L2/h300
Evaluating performance on  test set...
2006/2006 - 32s - 32s/epoch - 16ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0896856
{'0': {'precision': 0.3750728492363053, 'recall': 0.5589016983925303, 'f1-score': 0.44889628521740754, 'support': 171574}, '1': {'precision': 0.3707404482779566, 'recall': 0.41304286527974376, 'f1-score': 0.39075008202646716, 'support': 177323}, '2': {'precision': 0.3945827232796486, 'recall': 0.14423334225314424, 'f1-score': 0.21124828532235942, 'support': 164428}, 'accuracy': 0.37568986509521257, 'macro avg': {'precision': 0.3801320069313035, 'recall': 0.3720593019751395, 'f1-score': 0.35029821752207807, 'support': 513325}, 'weighted avg': {'precision': 0.3798256573677261, 'recall': 0.37568986509521257, 'f1-score': 0.35268697432241874, 'support': 513325}}
[[95893 60053 15628]
 [83321 73242 20760]
 [76451 64261 23716]]
Evaluating performance on  train set...
538/538 - 9s - 9s/epoch - 17ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.085521
{'0': {'precision': 0.38436943866316775, 'recall': 0.5443981629819502, 'f1-score': 0.45059714818645524, 'support': 46815}, '1': {'precision': 0.3714570437515571, 'recall': 0.40636072035053145, 'f1-score': 0.3881257509010813, 'support': 47699}, '2': {'precision': 0.4031919361612768, 'recall': 0.1785174682131982, 'f1-score': 0.24746652918526155, 'support': 43021}, 'accuracy': 0.38207728941723923, 'macro avg': {'precision': 0.38633947285866715, 'recall': 0.37642545051522663, 'f1-score': 0.3620631427575994, 'support': 137535}, 'weighted avg': {'precision': 0.3857789296289381, 'recall': 0.38207728941723923, 'f1-score': 0.36539188742253764, 'support': 137535}}
[[25486 16333  4996]
 [21944 19383  6372]
 [18876 16465  7680]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 18ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.093946
{'0': {'precision': 0.35854858548585483, 'recall': 0.5550618851158362, 'f1-score': 0.43567069373520984, 'support': 12604}, '1': {'precision': 0.3607746427794299, 'recall': 0.3738725195429946, 'f1-score': 0.3672068214536193, 'support': 13304}, '2': {'precision': 0.40705964180142584, 'recall': 0.17813118246842186, 'f1-score': 0.24781665166993067, 'support': 13142}, 'accuracy': 0.3664788732394366, 'macro avg': {'precision': 0.37546095668890356, 'recall': 0.36902186237575085, 'f1-score': 0.35023138895292, 'support': 39050}, 'weighted avg': {'precision': 0.3756330353791444, 'recall': 0.3664788732394366, 'f1-score': 0.3491246968682142, 'support': 39050}}
[[6996 4098 1510]
 [6430 4974 1900]
 [6086 4715 2341]]
training model: results/QRTEA/W7/deepOF_L2/h500
Epoch 1/50
538/538 - 20s - loss: 3.3067 - accuracy500: 0.3679 - val_loss: 3.3638 - val_accuracy500: 0.3183 - 20s/epoch - 38ms/step
Epoch 2/50
538/538 - 18s - loss: 3.2864 - accuracy500: 0.3725 - val_loss: 3.3743 - val_accuracy500: 0.3194 - 18s/epoch - 33ms/step
Epoch 3/50
538/538 - 18s - loss: 3.2777 - accuracy500: 0.3775 - val_loss: 3.3587 - val_accuracy500: 0.3227 - 18s/epoch - 33ms/step
Epoch 4/50
538/538 - 18s - loss: 3.2721 - accuracy500: 0.3808 - val_loss: 3.3441 - val_accuracy500: 0.3253 - 18s/epoch - 33ms/step
Epoch 5/50
538/538 - 18s - loss: 3.2683 - accuracy500: 0.3820 - val_loss: 3.3388 - val_accuracy500: 0.3262 - 18s/epoch - 33ms/step
Epoch 6/50
538/538 - 18s - loss: 3.2624 - accuracy500: 0.3839 - val_loss: 3.3330 - val_accuracy500: 0.3324 - 18s/epoch - 33ms/step
Epoch 7/50
538/538 - 18s - loss: 3.2642 - accuracy500: 0.3853 - val_loss: 3.3220 - val_accuracy500: 0.3345 - 18s/epoch - 33ms/step
Epoch 8/50
538/538 - 18s - loss: 3.2568 - accuracy500: 0.3890 - val_loss: 3.3177 - val_accuracy500: 0.3369 - 18s/epoch - 33ms/step
Epoch 9/50
538/538 - 18s - loss: 3.2558 - accuracy500: 0.3904 - val_loss: 3.3095 - val_accuracy500: 0.3407 - 18s/epoch - 33ms/step
Epoch 10/50
538/538 - 17s - loss: 3.2520 - accuracy500: 0.3927 - val_loss: 3.3096 - val_accuracy500: 0.3395 - 17s/epoch - 32ms/step
Epoch 11/50
538/538 - 18s - loss: 3.2478 - accuracy500: 0.3953 - val_loss: 3.3089 - val_accuracy500: 0.3447 - 18s/epoch - 33ms/step
Epoch 12/50
538/538 - 18s - loss: 3.2444 - accuracy500: 0.3967 - val_loss: 3.3050 - val_accuracy500: 0.3476 - 18s/epoch - 34ms/step
Epoch 13/50
538/538 - 18s - loss: 3.2374 - accuracy500: 0.4033 - val_loss: 3.3000 - val_accuracy500: 0.3495 - 18s/epoch - 34ms/step
Epoch 14/50
538/538 - 18s - loss: 3.2340 - accuracy500: 0.4065 - val_loss: 3.2991 - val_accuracy500: 0.3514 - 18s/epoch - 34ms/step
Epoch 15/50
538/538 - 18s - loss: 3.2290 - accuracy500: 0.4086 - val_loss: 3.2964 - val_accuracy500: 0.3535 - 18s/epoch - 34ms/step
Epoch 16/50
538/538 - 18s - loss: 3.2222 - accuracy500: 0.4118 - val_loss: 3.2974 - val_accuracy500: 0.3550 - 18s/epoch - 34ms/step
Epoch 17/50
538/538 - 18s - loss: 3.2167 - accuracy500: 0.4155 - val_loss: 3.2908 - val_accuracy500: 0.3585 - 18s/epoch - 34ms/step
Epoch 18/50
538/538 - 18s - loss: 3.2121 - accuracy500: 0.4175 - val_loss: 3.2910 - val_accuracy500: 0.3606 - 18s/epoch - 34ms/step
Epoch 19/50
538/538 - 18s - loss: 3.2077 - accuracy500: 0.4198 - val_loss: 3.2914 - val_accuracy500: 0.3591 - 18s/epoch - 34ms/step
Epoch 20/50
538/538 - 18s - loss: 3.2017 - accuracy500: 0.4228 - val_loss: 3.2873 - val_accuracy500: 0.3626 - 18s/epoch - 33ms/step
Epoch 21/50
538/538 - 18s - loss: 3.1989 - accuracy500: 0.4247 - val_loss: 3.2950 - val_accuracy500: 0.3608 - 18s/epoch - 34ms/step
Epoch 22/50
538/538 - 18s - loss: 3.1954 - accuracy500: 0.4275 - val_loss: 3.2969 - val_accuracy500: 0.3615 - 18s/epoch - 34ms/step
Epoch 23/50
538/538 - 18s - loss: 3.1899 - accuracy500: 0.4294 - val_loss: 3.2952 - val_accuracy500: 0.3629 - 18s/epoch - 34ms/step
Epoch 24/50
538/538 - 18s - loss: 3.1850 - accuracy500: 0.4331 - val_loss: 3.2948 - val_accuracy500: 0.3673 - 18s/epoch - 34ms/step
Epoch 25/50
538/538 - 18s - loss: 3.1769 - accuracy500: 0.4378 - val_loss: 3.2965 - val_accuracy500: 0.3651 - 18s/epoch - 34ms/step
Epoch 26/50
538/538 - 18s - loss: 3.1756 - accuracy500: 0.4365 - val_loss: 3.2973 - val_accuracy500: 0.3619 - 18s/epoch - 34ms/step
Epoch 27/50
538/538 - 18s - loss: 3.1690 - accuracy500: 0.4407 - val_loss: 3.3028 - val_accuracy500: 0.3624 - 18s/epoch - 34ms/step
Epoch 28/50
538/538 - 18s - loss: 3.1631 - accuracy500: 0.4460 - val_loss: 3.3090 - val_accuracy500: 0.3592 - 18s/epoch - 33ms/step
Epoch 29/50
538/538 - 17s - loss: 3.1623 - accuracy500: 0.4449 - val_loss: 3.3083 - val_accuracy500: 0.3594 - 17s/epoch - 32ms/step
Epoch 30/50
538/538 - 18s - loss: 3.1568 - accuracy500: 0.4490 - val_loss: 3.3149 - val_accuracy500: 0.3582 - 18s/epoch - 33ms/step
testing model: results/QRTEA/W7/deepOF_L2/h500
Evaluating performance on  test set...
2006/2006 - 33s - 33s/epoch - 16ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0971437
{'0': {'precision': 0.40072228504724033, 'recall': 0.41532985492216784, 'f1-score': 0.40789533011699236, 'support': 185142}, '1': {'precision': 0.3226747102374949, 'recall': 0.32145998240985046, 'f1-score': 0.32206620093924293, 'support': 150084}, '2': {'precision': 0.3881743885059477, 'recall': 0.37469609599155523, 'f1-score': 0.3813161759243916, 'support': 178099}, 'accuracy': 0.37378658744460136, 'macro avg': {'precision': 0.3705237945968943, 'recall': 0.3704953111078579, 'f1-score': 0.3704259023268756, 'support': 513325}, 'weighted avg': {'precision': 0.37354951917015755, 'recall': 0.37378658744460136, 'f1-score': 0.3735792539351167, 'support': 513325}}
[[76895 52231 56016]
 [52672 48246 49166]
 [62324 49042 66733]]
Evaluating performance on  train set...
538/538 - 9s - 9s/epoch - 17ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0825742
{'0': {'precision': 0.41588072887907235, 'recall': 0.38742798353909463, 'f1-score': 0.401150466045273, 'support': 48600}, '1': {'precision': 0.3698948058827981, 'recall': 0.32906193895870733, 'f1-score': 0.3482856498141352, 'support': 44560}, '2': {'precision': 0.3813261369467303, 'recall': 0.45216901408450705, 'f1-score': 0.41373693218137203, 'support': 44375}, 'accuracy': 0.38940633293343513, 'macro avg': {'precision': 0.3890338905695336, 'recall': 0.38955297886076967, 'f1-score': 0.38772434934692673, 'support': 137535}, 'weighted avg': {'precision': 0.3898328665479446, 'recall': 0.38940633293343513, 'f1-score': 0.38808374283685254, 'support': 137535}}
[[18829 13503 16268]
 [13611 14663 16286]
 [12835 11475 20065]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 18ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0911684
{'0': {'precision': 0.332389327768669, 'recall': 0.3853464662173838, 'f1-score': 0.35691421254801536, 'support': 11574}, '1': {'precision': 0.418210009475407, 'recall': 0.31354947042107983, 'f1-score': 0.35839515742073597, 'support': 15484}, '2': {'precision': 0.34464807815731296, 'recall': 0.4030186791194129, 'f1-score': 0.37155487218912164, 'support': 11992}, 'accuracy': 0.3623047375160051, 'macro avg': {'precision': 0.365082471800463, 'recall': 0.3673048719192922, 'f1-score': 0.36228808071929103, 'support': 39050}, 'weighted avg': {'precision': 0.37018329371509023, 'recall': 0.3623047375160051, 'f1-score': 0.3619974837599322, 'support': 39050}}
[[4460 3430 3684]
 [5123 4855 5506]
 [3835 3324 4833]]
training model: results/QRTEA/W7/deepOF_L2/h1000
Epoch 1/50
538/538 - 21s - loss: 3.3019 - accuracy1000: 0.3762 - val_loss: 3.4409 - val_accuracy1000: 0.3439 - 21s/epoch - 39ms/step
Epoch 2/50
538/538 - 18s - loss: 3.2827 - accuracy1000: 0.3811 - val_loss: 3.4281 - val_accuracy1000: 0.3426 - 18s/epoch - 33ms/step
Epoch 3/50
538/538 - 18s - loss: 3.2733 - accuracy1000: 0.3804 - val_loss: 3.4119 - val_accuracy1000: 0.3445 - 18s/epoch - 33ms/step
Epoch 4/50
538/538 - 18s - loss: 3.2660 - accuracy1000: 0.3842 - val_loss: 3.3984 - val_accuracy1000: 0.3478 - 18s/epoch - 33ms/step
Epoch 5/50
538/538 - 18s - loss: 3.2625 - accuracy1000: 0.3869 - val_loss: 3.3840 - val_accuracy1000: 0.3512 - 18s/epoch - 33ms/step
Epoch 6/50
538/538 - 18s - loss: 3.2554 - accuracy1000: 0.3900 - val_loss: 3.3812 - val_accuracy1000: 0.3565 - 18s/epoch - 33ms/step
Epoch 7/50
538/538 - 18s - loss: 3.2497 - accuracy1000: 0.3906 - val_loss: 3.3975 - val_accuracy1000: 0.3564 - 18s/epoch - 33ms/step
Epoch 8/50
538/538 - 18s - loss: 3.2381 - accuracy1000: 0.3964 - val_loss: 3.3977 - val_accuracy1000: 0.3567 - 18s/epoch - 33ms/step
Epoch 9/50
538/538 - 18s - loss: 3.2298 - accuracy1000: 0.3998 - val_loss: 3.3950 - val_accuracy1000: 0.3583 - 18s/epoch - 33ms/step
Epoch 10/50
538/538 - 18s - loss: 3.2230 - accuracy1000: 0.4026 - val_loss: 3.3928 - val_accuracy1000: 0.3595 - 18s/epoch - 33ms/step
Epoch 11/50
538/538 - 18s - loss: 3.2181 - accuracy1000: 0.4068 - val_loss: 3.3776 - val_accuracy1000: 0.3606 - 18s/epoch - 33ms/step
Epoch 12/50
538/538 - 17s - loss: 3.2131 - accuracy1000: 0.4106 - val_loss: 3.3760 - val_accuracy1000: 0.3598 - 17s/epoch - 32ms/step
Epoch 13/50
538/538 - 17s - loss: 3.2054 - accuracy1000: 0.4153 - val_loss: 3.3754 - val_accuracy1000: 0.3601 - 17s/epoch - 32ms/step
Epoch 14/50
538/538 - 18s - loss: 3.1980 - accuracy1000: 0.4219 - val_loss: 3.3702 - val_accuracy1000: 0.3606 - 18s/epoch - 33ms/step
Epoch 15/50
538/538 - 18s - loss: 3.1926 - accuracy1000: 0.4255 - val_loss: 3.3696 - val_accuracy1000: 0.3599 - 18s/epoch - 33ms/step
Epoch 16/50
538/538 - 17s - loss: 3.1854 - accuracy1000: 0.4289 - val_loss: 3.3704 - val_accuracy1000: 0.3623 - 17s/epoch - 32ms/step
Epoch 17/50
538/538 - 18s - loss: 3.1809 - accuracy1000: 0.4306 - val_loss: 3.3700 - val_accuracy1000: 0.3608 - 18s/epoch - 33ms/step
Epoch 18/50
538/538 - 18s - loss: 3.1738 - accuracy1000: 0.4345 - val_loss: 3.3708 - val_accuracy1000: 0.3574 - 18s/epoch - 33ms/step
Epoch 19/50
538/538 - 18s - loss: 3.1698 - accuracy1000: 0.4360 - val_loss: 3.3742 - val_accuracy1000: 0.3591 - 18s/epoch - 33ms/step
Epoch 20/50
538/538 - 18s - loss: 3.1645 - accuracy1000: 0.4394 - val_loss: 3.3762 - val_accuracy1000: 0.3598 - 18s/epoch - 33ms/step
Epoch 21/50
538/538 - 18s - loss: 3.1603 - accuracy1000: 0.4404 - val_loss: 3.3777 - val_accuracy1000: 0.3609 - 18s/epoch - 33ms/step
Epoch 22/50
538/538 - 18s - loss: 3.1558 - accuracy1000: 0.4444 - val_loss: 3.3775 - val_accuracy1000: 0.3566 - 18s/epoch - 33ms/step
Epoch 23/50
538/538 - 18s - loss: 3.1529 - accuracy1000: 0.4467 - val_loss: 3.3752 - val_accuracy1000: 0.3551 - 18s/epoch - 33ms/step
Epoch 24/50
538/538 - 18s - loss: 3.1475 - accuracy1000: 0.4497 - val_loss: 3.3778 - val_accuracy1000: 0.3607 - 18s/epoch - 33ms/step
Epoch 25/50
538/538 - 17s - loss: 3.1436 - accuracy1000: 0.4499 - val_loss: 3.3823 - val_accuracy1000: 0.3592 - 17s/epoch - 32ms/step
testing model: results/QRTEA/W7/deepOF_L2/h1000
Evaluating performance on  test set...
2006/2006 - 33s - 33s/epoch - 16ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0763831
{'0': {'precision': 0.42013499559026224, 'recall': 0.46649804145424484, 'f1-score': 0.4421043304286591, 'support': 203212}, '1': {'precision': 0.28964729764019287, 'recall': 0.0990154833673071, 'f1-score': 0.14758072335886746, 'support': 115285}, '2': {'precision': 0.39312383698918146, 'recall': 0.5009752191676761, 'f1-score': 0.4405447003651496, 'support': 194828}, 'accuracy': 0.39705254955437586, 'macro avg': {'precision': 0.36763537673987884, 'recall': 0.3554962479964094, 'f1-score': 0.34340991805089205, 'support': 513325}, 'weighted avg': {'precision': 0.3805775918672697, 'recall': 0.39705254955437586, 'f1-score': 0.3753668568065788, 'support': 513325}}
[[94798 13570 94844]
 [48040 11415 55830]
 [82799 14425 97604]]
Evaluating performance on  train set...
538/538 - 9s - 9s/epoch - 17ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0974624
{'0': {'precision': 0.40531407839510564, 'recall': 0.4534240579364132, 'f1-score': 0.42802141046107617, 'support': 50262}, '1': {'precision': 0.3759232613908873, 'recall': 0.09218790430712051, 'f1-score': 0.14806558863533323, 'support': 42511}, '2': {'precision': 0.3506955221353799, 'recall': 0.5553371163040078, 'f1-score': 0.4299055722735291, 'support': 44762}, 'accuracy': 0.3749372886901516, 'macro avg': {'precision': 0.37731095397379094, 'recall': 0.3669830261825138, 'f1-score': 0.33533085712331284, 'support': 137535}, 'weighted avg': {'precision': 0.37845350590836285, 'recall': 0.3749372886901516, 'f1-score': 0.3421024582628347, 'support': 137535}}
[[22790  3457 24015]
 [16583  3919 22009]
 [16855  3049 24858]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 17ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1091353
{'0': {'precision': 0.3584883237269, 'recall': 0.47210266844041004, 'f1-score': 0.4075249932450689, 'support': 12779}, '1': {'precision': 0.3878312803284808, 'recall': 0.07982483097725876, 'f1-score': 0.13239885313794203, 'support': 13016}, '2': {'precision': 0.36106846791525943, 'recall': 0.5323274236137306, 'f1-score': 0.4302832576150257, 'support': 13255}, 'accuracy': 0.36179257362355954, 'macro avg': {'precision': 0.36912935732354674, 'recall': 0.3614183076771331, 'f1-score': 0.3234023679993456, 'support': 39050}, 'weighted avg': {'precision': 0.3691446037356805, 'recall': 0.36179257362355954, 'f1-score': 0.3235459651935814, 'support': 39050}}
[[6033  772 5974]
 [5465 1039 6512]
 [5331  868 7056]]
training model: results/QRTEA/W7/deepVOL_L2/h10
Epoch 1/50
538/538 - 20s - loss: 2.8432 - accuracy10: 0.5244 - val_loss: 2.8745 - val_accuracy10: 0.7028 - 20s/epoch - 37ms/step
Epoch 2/50
538/538 - 17s - loss: 2.5411 - accuracy10: 0.6161 - val_loss: 2.7129 - val_accuracy10: 0.7324 - 17s/epoch - 31ms/step
Epoch 3/50
538/538 - 17s - loss: 2.4396 - accuracy10: 0.6434 - val_loss: 2.6221 - val_accuracy10: 0.7351 - 17s/epoch - 32ms/step
Epoch 4/50
538/538 - 17s - loss: 2.3866 - accuracy10: 0.6564 - val_loss: 2.5807 - val_accuracy10: 0.7491 - 17s/epoch - 32ms/step
Epoch 5/50
538/538 - 18s - loss: 2.3432 - accuracy10: 0.6660 - val_loss: 2.5625 - val_accuracy10: 0.7426 - 18s/epoch - 33ms/step
Epoch 6/50
538/538 - 18s - loss: 2.3160 - accuracy10: 0.6712 - val_loss: 2.5474 - val_accuracy10: 0.7230 - 18s/epoch - 34ms/step
Epoch 7/50
538/538 - 18s - loss: 2.2954 - accuracy10: 0.6759 - val_loss: 2.5459 - val_accuracy10: 0.7188 - 18s/epoch - 33ms/step
Epoch 8/50
538/538 - 18s - loss: 2.2773 - accuracy10: 0.6791 - val_loss: 2.5086 - val_accuracy10: 0.7207 - 18s/epoch - 34ms/step
Epoch 9/50
538/538 - 18s - loss: 2.2538 - accuracy10: 0.6867 - val_loss: 2.5245 - val_accuracy10: 0.7053 - 18s/epoch - 33ms/step
Epoch 10/50
538/538 - 18s - loss: 2.2409 - accuracy10: 0.6887 - val_loss: 2.4924 - val_accuracy10: 0.7112 - 18s/epoch - 33ms/step
Epoch 11/50
538/538 - 18s - loss: 2.2220 - accuracy10: 0.6898 - val_loss: 2.5116 - val_accuracy10: 0.7151 - 18s/epoch - 33ms/step
Epoch 12/50
538/538 - 17s - loss: 2.2080 - accuracy10: 0.6897 - val_loss: 2.4793 - val_accuracy10: 0.7047 - 17s/epoch - 32ms/step
Epoch 13/50
538/538 - 17s - loss: 2.1921 - accuracy10: 0.6925 - val_loss: 2.4957 - val_accuracy10: 0.7260 - 17s/epoch - 32ms/step
Epoch 14/50
538/538 - 17s - loss: 2.1876 - accuracy10: 0.6917 - val_loss: 2.4595 - val_accuracy10: 0.7105 - 17s/epoch - 32ms/step
Epoch 15/50
538/538 - 17s - loss: 2.1659 - accuracy10: 0.6938 - val_loss: 2.4790 - val_accuracy10: 0.7162 - 17s/epoch - 32ms/step
Epoch 16/50
538/538 - 17s - loss: 2.1555 - accuracy10: 0.6931 - val_loss: 2.4566 - val_accuracy10: 0.7215 - 17s/epoch - 32ms/step
Epoch 17/50
538/538 - 17s - loss: 2.1409 - accuracy10: 0.6912 - val_loss: 2.4709 - val_accuracy10: 0.7195 - 17s/epoch - 32ms/step
Epoch 18/50
538/538 - 17s - loss: 2.1372 - accuracy10: 0.6897 - val_loss: 2.4850 - val_accuracy10: 0.7170 - 17s/epoch - 32ms/step
Epoch 19/50
538/538 - 17s - loss: 2.1243 - accuracy10: 0.6913 - val_loss: 2.4486 - val_accuracy10: 0.7174 - 17s/epoch - 32ms/step
Epoch 20/50
538/538 - 17s - loss: 2.1177 - accuracy10: 0.6879 - val_loss: 2.4699 - val_accuracy10: 0.7029 - 17s/epoch - 32ms/step
Epoch 21/50
538/538 - 17s - loss: 2.1048 - accuracy10: 0.6898 - val_loss: 2.4787 - val_accuracy10: 0.7205 - 17s/epoch - 32ms/step
Epoch 22/50
538/538 - 17s - loss: 2.0965 - accuracy10: 0.6921 - val_loss: 2.4865 - val_accuracy10: 0.7314 - 17s/epoch - 31ms/step
Epoch 23/50
538/538 - 18s - loss: 2.0839 - accuracy10: 0.6912 - val_loss: 2.4547 - val_accuracy10: 0.7098 - 18s/epoch - 33ms/step
Epoch 24/50
538/538 - 18s - loss: 2.0735 - accuracy10: 0.6930 - val_loss: 2.4795 - val_accuracy10: 0.7110 - 18s/epoch - 33ms/step
Epoch 25/50
538/538 - 16s - loss: 2.0646 - accuracy10: 0.6910 - val_loss: 2.4963 - val_accuracy10: 0.7156 - 16s/epoch - 30ms/step
Epoch 26/50
538/538 - 16s - loss: 2.0570 - accuracy10: 0.6909 - val_loss: 2.4757 - val_accuracy10: 0.7174 - 16s/epoch - 30ms/step
Epoch 27/50
538/538 - 17s - loss: 2.0423 - accuracy10: 0.6915 - val_loss: 2.4896 - val_accuracy10: 0.7011 - 17s/epoch - 31ms/step
Epoch 28/50
538/538 - 16s - loss: 2.0341 - accuracy10: 0.6924 - val_loss: 2.4903 - val_accuracy10: 0.7029 - 16s/epoch - 30ms/step
Epoch 29/50
538/538 - 16s - loss: 2.0273 - accuracy10: 0.6938 - val_loss: 2.4971 - val_accuracy10: 0.6896 - 16s/epoch - 30ms/step
testing model: results/QRTEA/W7/deepVOL_L2/h10
Evaluating performance on  test set...
2006/2006 - 34s - 34s/epoch - 17ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.6757383
{'0': {'precision': 0.32776167927061983, 'recall': 0.5758604275750739, 'f1-score': 0.4177520211991322, 'support': 48319}, '1': {'precision': 0.9194758501834821, 'recall': 0.7421366301727963, 'f1-score': 0.821342782444825, 'support': 416965}, '2': {'precision': 0.31468805432523317, 'recall': 0.6018607168130542, 'f1-score': 0.4132859786904107, 'support': 48046}, 'accuracy': 0.713355930882668, 'macro avg': {'precision': 0.5206418612597784, 'recall': 0.639952591520308, 'f1-score': 0.550793594111456, 'support': 513330}, 'weighted avg': {'precision': 0.8071725141927082, 'recall': 0.713355930882668, 'f1-score': 0.7451606010297211, 'support': 513330}}
[[ 27825  13942   6552]
 [ 51098 309445  56422]
 [  5971  13158  28917]]
Evaluating performance on  train set...
538/538 - 9s - 9s/epoch - 18ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.6583169
{'0': {'precision': 0.3906316136010911, 'recall': 0.5766854127612303, 'f1-score': 0.46576571524701393, 'support': 14403}, '1': {'precision': 0.9212776827561696, 'recall': 0.7597962884935974, 'f1-score': 0.8327811577615807, 'support': 109174}, '2': {'precision': 0.3407912791584083, 'recall': 0.6404727793696275, 'f1-score': 0.4448701363319733, 'support': 13960}, 'accuracy': 0.7285094192835383, 'macro avg': {'precision': 0.5509001918385563, 'recall': 0.6589848268748183, 'f1-score': 0.5811390031135227, 'support': 137537}, 'weighted avg': {'precision': 0.8067885959775912, 'recall': 0.7285094192835383, 'f1-score': 0.754974012937318, 'support': 137537}}
[[ 8306  3765  2332]
 [11261 82950 14963]
 [ 1696  3323  8941]]
Evaluating performance on  val set...
153/153 - 2s - 2s/epoch - 16ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.6812497
{'0': {'precision': 0.36668522126356806, 'recall': 0.6036655211912944, 'f1-score': 0.45623755519002684, 'support': 4365}, '1': {'precision': 0.9136000642080341, 'recall': 0.7516260028393146, 'f1-score': 0.8247355455731055, 'support': 30289}, '2': {'precision': 0.38171346292296615, 'recall': 0.6030482256596906, 'f1-score': 0.4675072744907856, 'support': 4396}, 'accuracy': 0.7183610755441742, 'macro avg': {'precision': 0.5539995827981894, 'recall': 0.6527799165634333, 'f1-score': 0.582826791751306, 'support': 39050}, 'weighted avg': {'precision': 0.7925896470837894, 'recall': 0.7183610755441742, 'f1-score': 0.7433304442235532, 'support': 39050}}
[[ 2635  1052   678]
 [ 3907 22766  3616]
 [  644  1101  2651]]
training model: results/QRTEA/W7/deepVOL_L2/h20
Epoch 1/50
538/538 - 19s - loss: 2.9860 - accuracy20: 0.4709 - val_loss: 2.9457 - val_accuracy20: 0.6366 - 19s/epoch - 35ms/step
Epoch 2/50
538/538 - 17s - loss: 2.6615 - accuracy20: 0.5902 - val_loss: 2.8316 - val_accuracy20: 0.6794 - 17s/epoch - 31ms/step
Epoch 3/50
538/538 - 16s - loss: 2.5579 - accuracy20: 0.6205 - val_loss: 2.7879 - val_accuracy20: 0.6968 - 16s/epoch - 30ms/step
Epoch 4/50
538/538 - 16s - loss: 2.5038 - accuracy20: 0.6291 - val_loss: 2.7593 - val_accuracy20: 0.6823 - 16s/epoch - 30ms/step
Epoch 5/50
538/538 - 17s - loss: 2.4635 - accuracy20: 0.6376 - val_loss: 2.7326 - val_accuracy20: 0.6895 - 17s/epoch - 31ms/step
Epoch 6/50
538/538 - 17s - loss: 2.4382 - accuracy20: 0.6445 - val_loss: 2.7178 - val_accuracy20: 0.6915 - 17s/epoch - 31ms/step
Epoch 7/50
538/538 - 16s - loss: 2.4141 - accuracy20: 0.6466 - val_loss: 2.7086 - val_accuracy20: 0.7095 - 16s/epoch - 30ms/step
Epoch 8/50
538/538 - 16s - loss: 2.3973 - accuracy20: 0.6503 - val_loss: 2.7253 - val_accuracy20: 0.6971 - 16s/epoch - 30ms/step
Epoch 9/50
538/538 - 16s - loss: 2.3772 - accuracy20: 0.6535 - val_loss: 2.7255 - val_accuracy20: 0.6942 - 16s/epoch - 30ms/step
Epoch 10/50
538/538 - 17s - loss: 2.3593 - accuracy20: 0.6559 - val_loss: 2.7304 - val_accuracy20: 0.6998 - 17s/epoch - 31ms/step
Epoch 11/50
538/538 - 17s - loss: 2.3465 - accuracy20: 0.6566 - val_loss: 2.7714 - val_accuracy20: 0.7104 - 17s/epoch - 31ms/step
Epoch 12/50
538/538 - 17s - loss: 2.3352 - accuracy20: 0.6566 - val_loss: 2.7145 - val_accuracy20: 0.7063 - 17s/epoch - 31ms/step
Epoch 13/50
538/538 - 17s - loss: 2.3203 - accuracy20: 0.6580 - val_loss: 2.6778 - val_accuracy20: 0.7027 - 17s/epoch - 31ms/step
Epoch 14/50
538/538 - 17s - loss: 2.3092 - accuracy20: 0.6580 - val_loss: 2.6810 - val_accuracy20: 0.7096 - 17s/epoch - 31ms/step
Epoch 15/50
538/538 - 17s - loss: 2.2941 - accuracy20: 0.6603 - val_loss: 2.6830 - val_accuracy20: 0.6978 - 17s/epoch - 31ms/step
Epoch 16/50
538/538 - 17s - loss: 2.2820 - accuracy20: 0.6596 - val_loss: 2.6959 - val_accuracy20: 0.7012 - 17s/epoch - 31ms/step
Epoch 17/50
538/538 - 17s - loss: 2.2654 - accuracy20: 0.6598 - val_loss: 2.6922 - val_accuracy20: 0.6790 - 17s/epoch - 31ms/step
Epoch 18/50
538/538 - 17s - loss: 2.2512 - accuracy20: 0.6607 - val_loss: 2.6709 - val_accuracy20: 0.6900 - 17s/epoch - 31ms/step
Epoch 19/50
538/538 - 17s - loss: 2.2424 - accuracy20: 0.6585 - val_loss: 2.6968 - val_accuracy20: 0.7017 - 17s/epoch - 32ms/step
Epoch 20/50
538/538 - 17s - loss: 2.2317 - accuracy20: 0.6609 - val_loss: 2.6498 - val_accuracy20: 0.6884 - 17s/epoch - 31ms/step
Epoch 21/50
538/538 - 17s - loss: 2.2225 - accuracy20: 0.6613 - val_loss: 2.6620 - val_accuracy20: 0.6857 - 17s/epoch - 31ms/step
Epoch 22/50
538/538 - 17s - loss: 2.2071 - accuracy20: 0.6610 - val_loss: 2.6811 - val_accuracy20: 0.7035 - 17s/epoch - 31ms/step
Epoch 23/50
538/538 - 17s - loss: 2.1959 - accuracy20: 0.6639 - val_loss: 2.6828 - val_accuracy20: 0.6825 - 17s/epoch - 32ms/step
Epoch 24/50
538/538 - 17s - loss: 2.1827 - accuracy20: 0.6623 - val_loss: 2.7076 - val_accuracy20: 0.6933 - 17s/epoch - 31ms/step
Epoch 25/50
538/538 - 17s - loss: 2.1767 - accuracy20: 0.6640 - val_loss: 2.6409 - val_accuracy20: 0.6873 - 17s/epoch - 31ms/step
Epoch 26/50
538/538 - 17s - loss: 2.1666 - accuracy20: 0.6648 - val_loss: 2.6774 - val_accuracy20: 0.6940 - 17s/epoch - 31ms/step
Epoch 27/50
538/538 - 17s - loss: 2.1551 - accuracy20: 0.6642 - val_loss: 2.6503 - val_accuracy20: 0.6923 - 17s/epoch - 31ms/step
Epoch 28/50
538/538 - 18s - loss: 2.1447 - accuracy20: 0.6657 - val_loss: 2.7114 - val_accuracy20: 0.6886 - 18s/epoch - 33ms/step
Epoch 29/50
538/538 - 18s - loss: 2.1312 - accuracy20: 0.6657 - val_loss: 2.6894 - val_accuracy20: 0.6957 - 18s/epoch - 33ms/step
Epoch 30/50
538/538 - 18s - loss: 2.1222 - accuracy20: 0.6664 - val_loss: 2.7422 - val_accuracy20: 0.6956 - 18s/epoch - 33ms/step
Epoch 31/50
538/538 - 18s - loss: 2.1070 - accuracy20: 0.6675 - val_loss: 2.7413 - val_accuracy20: 0.6958 - 18s/epoch - 34ms/step
Epoch 32/50
538/538 - 18s - loss: 2.1034 - accuracy20: 0.6666 - val_loss: 2.8097 - val_accuracy20: 0.7074 - 18s/epoch - 34ms/step
Epoch 33/50
538/538 - 18s - loss: 2.0936 - accuracy20: 0.6679 - val_loss: 2.7880 - val_accuracy20: 0.6978 - 18s/epoch - 34ms/step
Epoch 34/50
538/538 - 18s - loss: 2.0782 - accuracy20: 0.6683 - val_loss: 2.7646 - val_accuracy20: 0.6914 - 18s/epoch - 34ms/step
Epoch 35/50
538/538 - 18s - loss: 2.0743 - accuracy20: 0.6701 - val_loss: 2.8225 - val_accuracy20: 0.6917 - 18s/epoch - 34ms/step
testing model: results/QRTEA/W7/deepVOL_L2/h20
Evaluating performance on  test set...
2006/2006 - 37s - 37s/epoch - 18ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.73046833
{'0': {'precision': 0.3811754244473396, 'recall': 0.5499776219603163, 'f1-score': 0.4502760406488177, 'support': 67030}, '1': {'precision': 0.8583462890619035, 'recall': 0.7386515967932711, 'f1-score': 0.7940133955501684, 'support': 380450}, '2': {'precision': 0.38638630784922495, 'recall': 0.523507972665148, 'f1-score': 0.4446149778485706, 'support': 65850}, 'accuracy': 0.6864161455593868, 'macro avg': {'precision': 0.5419693404528226, 'recall': 0.6040457304729118, 'f1-score': 0.5629681380158522, 'support': 513330}, 'weighted avg': {'precision': 0.7354948527188706, 'recall': 0.6864161455593868, 'f1-score': 0.7043077467381219, 'support': 513330}}
[[ 36865  23405   6760]
 [ 51444 281020  47986]
 [  8405  22972  34473]]
Evaluating performance on  train set...
538/538 - 10s - 10s/epoch - 19ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.69750994
{'0': {'precision': 0.44886293539499117, 'recall': 0.5598584324989742, 'f1-score': 0.4982539428936617, 'support': 19496}, '1': {'precision': 0.861026910706435, 'recall': 0.7502444630381967, 'f1-score': 0.8018272810037118, 'support': 99197}, '2': {'precision': 0.4005823937877996, 'recall': 0.5694120144343027, 'f1-score': 0.47030462415077795, 'support': 18844}, 'accuracy': 0.6984811359852258, 'macro avg': {'precision': 0.5701574132964086, 'recall': 0.6265049699904911, 'f1-score': 0.5901286160160505, 'support': 137537}, 'weighted avg': {'precision': 0.739516587378991, 'recall': 0.6984811359852258, 'f1-score': 0.7133734195298521, 'support': 137537}}
[[10915  6400  2181]
 [10900 74422 13875]
 [ 2502  5612 10730]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 20ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.7239265
{'0': {'precision': 0.43870449678800855, 'recall': 0.5571040108769545, 'f1-score': 0.49086552860137767, 'support': 5884}, '1': {'precision': 0.8404461088933701, 'recall': 0.7495962413742475, 'f1-score': 0.7924257416137983, 'support': 27244}, '2': {'precision': 0.43165269954664104, 'recall': 0.5305639986491051, 'f1-score': 0.47602454359518226, 'support': 5922}, 'accuracy': 0.6873751600512163, 'macro avg': {'precision': 0.5702677684093399, 'recall': 0.612421416966769, 'f1-score': 0.5864386046034528, 'support': 39050}, 'weighted avg': {'precision': 0.7179180111781517, 'recall': 0.6873751600512163, 'f1-score': 0.6990042771315621, 'support': 39050}}
[[ 3278  1943   663]
 [ 3348 20422  3474]
 [  846  1934  3142]]
training model: results/QRTEA/W7/deepVOL_L2/h30
Epoch 1/50
538/538 - 20s - loss: 3.0564 - accuracy30: 0.4633 - val_loss: 3.0834 - val_accuracy30: 0.6076 - 20s/epoch - 37ms/step
Epoch 2/50
538/538 - 17s - loss: 2.7625 - accuracy30: 0.5726 - val_loss: 3.0084 - val_accuracy30: 0.6505 - 17s/epoch - 32ms/step
Epoch 3/50
538/538 - 18s - loss: 2.6755 - accuracy30: 0.5958 - val_loss: 3.0528 - val_accuracy30: 0.6600 - 18s/epoch - 33ms/step
Epoch 4/50
538/538 - 17s - loss: 2.6365 - accuracy30: 0.6049 - val_loss: 3.0908 - val_accuracy30: 0.6783 - 17s/epoch - 32ms/step
Epoch 5/50
538/538 - 18s - loss: 2.6024 - accuracy30: 0.6101 - val_loss: 3.0670 - val_accuracy30: 0.6776 - 18s/epoch - 33ms/step
Epoch 6/50
538/538 - 18s - loss: 2.5780 - accuracy30: 0.6160 - val_loss: 3.0239 - val_accuracy30: 0.6787 - 18s/epoch - 33ms/step
Epoch 7/50
538/538 - 18s - loss: 2.5528 - accuracy30: 0.6218 - val_loss: 2.9762 - val_accuracy30: 0.6714 - 18s/epoch - 33ms/step
Epoch 8/50
538/538 - 18s - loss: 2.5353 - accuracy30: 0.6243 - val_loss: 2.9284 - val_accuracy30: 0.6738 - 18s/epoch - 33ms/step
Epoch 9/50
538/538 - 18s - loss: 2.5148 - accuracy30: 0.6272 - val_loss: 2.9394 - val_accuracy30: 0.6812 - 18s/epoch - 33ms/step
Epoch 10/50
538/538 - 17s - loss: 2.5035 - accuracy30: 0.6285 - val_loss: 2.9058 - val_accuracy30: 0.6828 - 17s/epoch - 31ms/step
Epoch 11/50
538/538 - 16s - loss: 2.4831 - accuracy30: 0.6310 - val_loss: 2.9460 - val_accuracy30: 0.6845 - 16s/epoch - 30ms/step
Epoch 12/50
538/538 - 17s - loss: 2.4684 - accuracy30: 0.6319 - val_loss: 2.9206 - val_accuracy30: 0.6830 - 17s/epoch - 32ms/step
Epoch 13/50
538/538 - 17s - loss: 2.4601 - accuracy30: 0.6339 - val_loss: 2.8625 - val_accuracy30: 0.6811 - 17s/epoch - 31ms/step
Epoch 14/50
538/538 - 17s - loss: 2.4468 - accuracy30: 0.6344 - val_loss: 2.9921 - val_accuracy30: 0.6886 - 17s/epoch - 31ms/step
Epoch 15/50
538/538 - 17s - loss: 2.4341 - accuracy30: 0.6359 - val_loss: 2.9321 - val_accuracy30: 0.6752 - 17s/epoch - 31ms/step
Epoch 16/50
538/538 - 17s - loss: 2.4195 - accuracy30: 0.6364 - val_loss: 2.9070 - val_accuracy30: 0.6829 - 17s/epoch - 32ms/step
Epoch 17/50
538/538 - 17s - loss: 2.4119 - accuracy30: 0.6369 - val_loss: 2.9095 - val_accuracy30: 0.6793 - 17s/epoch - 31ms/step
Epoch 18/50
538/538 - 16s - loss: 2.3997 - accuracy30: 0.6372 - val_loss: 2.9086 - val_accuracy30: 0.6806 - 16s/epoch - 30ms/step
Epoch 19/50
538/538 - 16s - loss: 2.3870 - accuracy30: 0.6377 - val_loss: 2.9026 - val_accuracy30: 0.6760 - 16s/epoch - 30ms/step
Epoch 20/50
538/538 - 17s - loss: 2.3684 - accuracy30: 0.6380 - val_loss: 2.9204 - val_accuracy30: 0.6714 - 17s/epoch - 32ms/step
Epoch 21/50
538/538 - 17s - loss: 2.3611 - accuracy30: 0.6396 - val_loss: 2.9071 - val_accuracy30: 0.6650 - 17s/epoch - 31ms/step
Epoch 22/50
538/538 - 16s - loss: 2.3497 - accuracy30: 0.6403 - val_loss: 2.9248 - val_accuracy30: 0.6738 - 16s/epoch - 31ms/step
Epoch 23/50
538/538 - 16s - loss: 2.3391 - accuracy30: 0.6383 - val_loss: 2.9286 - val_accuracy30: 0.6613 - 16s/epoch - 30ms/step
testing model: results/QRTEA/W7/deepVOL_L2/h30
Evaluating performance on  test set...
2006/2006 - 35s - 35s/epoch - 17ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.76049834
{'0': {'precision': 0.4495626447131464, 'recall': 0.42097592117467086, 'f1-score': 0.4347999178895116, 'support': 83019}, '1': {'precision': 0.789205653505622, 'recall': 0.7958657884114975, 'f1-score': 0.7925217287195377, 'support': 349329}, '2': {'precision': 0.4492936276451454, 'recall': 0.46222617371761626, 'f1-score': 0.4556681578867281, 'support': 80982}, 'accuracy': 0.6826018350768511, 'macro avg': {'precision': 0.5626873086213046, 'recall': 0.5596892944345949, 'f1-score': 0.5609966014985924, 'support': 513330}, 'weighted avg': {'precision': 0.6806525227219631, 'recall': 0.6826018350768511, 'f1-score': 0.681527275080591, 'support': 513330}}
[[ 34949  38750   9320]
 [ 34749 278019  36561]
 [  8042  35508  37432]]
Evaluating performance on  train set...
538/538 - 9s - 9s/epoch - 17ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.74232984
{'0': {'precision': 0.510655737704918, 'recall': 0.42283872062441674, 'f1-score': 0.4626166055599387, 'support': 23574}, '1': {'precision': 0.7910363489154983, 'recall': 0.8135353668156718, 'f1-score': 0.8021281192610996, 'support': 91272}, '2': {'precision': 0.46105428796223447, 'recall': 0.4906791238817152, 'f1-score': 0.4754056362083689, 'support': 22691}, 'accuracy': 0.693304347193846, 'macro avg': {'precision': 0.5875821248608836, 'recall': 0.5756844037739346, 'f1-score': 0.5800501203431357, 'support': 137537}, 'weighted avg': {'precision': 0.6885379995711857, 'recall': 0.693304347193846, 'f1-score': 0.6900324338314284, 'support': 137537}}
[[ 9968 10523  3083]
 [ 7087 74253  9932]
 [ 2465  9092 11134]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 18ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.765942
{'0': {'precision': 0.4975837879968823, 'recall': 0.4480628860190904, 'f1-score': 0.47152670064258806, 'support': 7124}, '1': {'precision': 0.7651846499068193, 'recall': 0.8119702962305271, 'f1-score': 0.7878835346870043, 'support': 24778}, '2': {'precision': 0.5154525386313465, 'recall': 0.4573307218802462, 'f1-score': 0.48465530022238695, 'support': 7148}, 'accuracy': 0.6806658130601793, 'macro avg': {'precision': 0.5927403255116827, 'recall': 0.5724546347099546, 'f1-score': 0.5813551785173264, 'support': 39050}, 'weighted avg': {'precision': 0.670652673680354, 'recall': 0.6806658130601793, 'f1-score': 0.6746645460650964, 'support': 39050}}
[[ 3192  3132   800]
 [ 2386 20119  2273]
 [  837  3042  3269]]
training model: results/QRTEA/W7/deepVOL_L2/h50
Epoch 1/50
538/538 - 19s - loss: 3.1623 - accuracy50: 0.4313 - val_loss: 3.2992 - val_accuracy50: 0.5321 - 19s/epoch - 36ms/step
Epoch 2/50
538/538 - 17s - loss: 2.9215 - accuracy50: 0.5297 - val_loss: 3.1458 - val_accuracy50: 0.5466 - 17s/epoch - 31ms/step
Epoch 3/50
538/538 - 17s - loss: 2.8450 - accuracy50: 0.5540 - val_loss: 3.0592 - val_accuracy50: 0.5555 - 17s/epoch - 31ms/step
Epoch 4/50
538/538 - 17s - loss: 2.8097 - accuracy50: 0.5636 - val_loss: 3.0501 - val_accuracy50: 0.5717 - 17s/epoch - 31ms/step
Epoch 5/50
538/538 - 16s - loss: 2.7779 - accuracy50: 0.5709 - val_loss: 3.0388 - val_accuracy50: 0.5698 - 16s/epoch - 30ms/step
Epoch 6/50
538/538 - 17s - loss: 2.7569 - accuracy50: 0.5729 - val_loss: 3.0141 - val_accuracy50: 0.5777 - 17s/epoch - 31ms/step
Epoch 7/50
538/538 - 17s - loss: 2.7411 - accuracy50: 0.5764 - val_loss: 3.0051 - val_accuracy50: 0.5788 - 17s/epoch - 31ms/step
Epoch 8/50
538/538 - 17s - loss: 2.7223 - accuracy50: 0.5805 - val_loss: 2.9962 - val_accuracy50: 0.5970 - 17s/epoch - 32ms/step
Epoch 9/50
538/538 - 16s - loss: 2.7093 - accuracy50: 0.5812 - val_loss: 3.0108 - val_accuracy50: 0.6024 - 16s/epoch - 31ms/step
Epoch 10/50
538/538 - 17s - loss: 2.6950 - accuracy50: 0.5843 - val_loss: 3.0134 - val_accuracy50: 0.6003 - 17s/epoch - 31ms/step
Epoch 11/50
538/538 - 17s - loss: 2.6814 - accuracy50: 0.5884 - val_loss: 3.0434 - val_accuracy50: 0.6077 - 17s/epoch - 32ms/step
Epoch 12/50
538/538 - 17s - loss: 2.6696 - accuracy50: 0.5904 - val_loss: 3.0558 - val_accuracy50: 0.6073 - 17s/epoch - 32ms/step
Epoch 13/50
538/538 - 17s - loss: 2.6561 - accuracy50: 0.5930 - val_loss: 3.0486 - val_accuracy50: 0.6081 - 17s/epoch - 31ms/step
Epoch 14/50
538/538 - 17s - loss: 2.6457 - accuracy50: 0.5950 - val_loss: 3.0538 - val_accuracy50: 0.6054 - 17s/epoch - 31ms/step
Epoch 15/50
538/538 - 17s - loss: 2.6319 - accuracy50: 0.5987 - val_loss: 3.0923 - val_accuracy50: 0.6050 - 17s/epoch - 31ms/step
Epoch 16/50
538/538 - 17s - loss: 2.6198 - accuracy50: 0.5996 - val_loss: 3.0890 - val_accuracy50: 0.6068 - 17s/epoch - 32ms/step
Epoch 17/50
538/538 - 17s - loss: 2.6132 - accuracy50: 0.6019 - val_loss: 3.0865 - val_accuracy50: 0.6003 - 17s/epoch - 31ms/step
Epoch 18/50
538/538 - 17s - loss: 2.6013 - accuracy50: 0.6017 - val_loss: 3.1357 - val_accuracy50: 0.6019 - 17s/epoch - 32ms/step
testing model: results/QRTEA/W7/deepVOL_L2/h50
Evaluating performance on  test set...
2006/2006 - 34s - 34s/epoch - 17ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.89328176
{'0': {'precision': 0.4893388516345348, 'recall': 0.3391181222429974, 'f1-score': 0.40060903037646217, 'support': 110174}, '1': {'precision': 0.6890004697596137, 'recall': 0.746675791943684, 'f1-score': 0.7166796375068158, 'support': 296612}, '2': {'precision': 0.4213195772782745, 'recall': 0.45688166391350055, 'f1-score': 0.4383805908654951, 'support': 106544}, 'accuracy': 0.5990551886700562, 'macro avg': {'precision': 0.5332196328908076, 'recall': 0.5142251927000606, 'f1-score': 0.5185564195829243, 'support': 513330}, 'weighted avg': {'precision': 0.5905894824340253, 'recall': 0.5990551886700562, 'f1-score': 0.5910803997935856, 'support': 513330}}
[[ 37362  54010  18802]
 [ 27082 221473  48057]
 [ 11908  45958  48678]]
Evaluating performance on  train set...
538/538 - 10s - 10s/epoch - 18ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.8786906
{'0': {'precision': 0.5436848559166155, 'recall': 0.3502402738463564, 'f1-score': 0.42603194939344197, 'support': 30382}, '1': {'precision': 0.7008367194825804, 'recall': 0.7458960809652366, 'f1-score': 0.7226646997936024, 'support': 78157}, '2': {'precision': 0.4195152804530949, 'recall': 0.5032071177322573, 'f1-score': 0.4575657327417255, 'support': 28998}, 'accuracy': 0.6073274827864502, 'macro avg': {'precision': 0.5546789519507637, 'recall': 0.5331144908479502, 'f1-score': 0.5354207939762566, 'support': 137537}, 'weighted avg': {'precision': 0.6068085888134647, 'recall': 0.6073274827864502, 'f1-score': 0.6012454739181797, 'support': 137537}}
[[10641 14015  5726]
 [ 5395 58297 14465]
 [ 3536 10870 14592]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 19ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.893053
{'0': {'precision': 0.5226406464400061, 'recall': 0.37608337904552935, 'f1-score': 0.43741227510526987, 'support': 9115}, '1': {'precision': 0.6617763514358355, 'recall': 0.7652785810680548, 'f1-score': 0.7097740327663665, 'support': 20748}, '2': {'precision': 0.4750529536361497, 'recall': 0.4394252748448895, 'f1-score': 0.4565450947130337, 'support': 9187}, 'accuracy': 0.5977720870678617, 'macro avg': {'precision': 0.5531566505039971, 'recall': 0.5269290783194912, 'f1-score': 0.5345771341948901, 'support': 39050}, 'weighted avg': {'precision': 0.5853704665031159, 'recall': 0.5977720870678617, 'f1-score': 0.5866244380166389, 'support': 39050}}
[[ 3428  4275  1412]
 [ 1821 15878  3049]
 [ 1310  3840  4037]]
training model: results/QRTEA/W7/deepVOL_L2/h100
Epoch 1/50
538/538 - 20s - loss: 3.2690 - accuracy100: 0.3952 - val_loss: 3.3065 - val_accuracy100: 0.4292 - 20s/epoch - 37ms/step
Epoch 2/50
538/538 - 17s - loss: 3.1275 - accuracy100: 0.4531 - val_loss: 3.4333 - val_accuracy100: 0.4402 - 17s/epoch - 32ms/step
Epoch 3/50
538/538 - 17s - loss: 3.0712 - accuracy100: 0.4733 - val_loss: 3.1698 - val_accuracy100: 0.4663 - 17s/epoch - 31ms/step
Epoch 4/50
538/538 - 17s - loss: 3.0275 - accuracy100: 0.4892 - val_loss: 3.1406 - val_accuracy100: 0.4728 - 17s/epoch - 31ms/step
Epoch 5/50
538/538 - 17s - loss: 2.9972 - accuracy100: 0.4991 - val_loss: 3.1672 - val_accuracy100: 0.4733 - 17s/epoch - 31ms/step
Epoch 6/50
538/538 - 17s - loss: 2.9760 - accuracy100: 0.5039 - val_loss: 3.2166 - val_accuracy100: 0.4723 - 17s/epoch - 31ms/step
Epoch 7/50
538/538 - 17s - loss: 2.9517 - accuracy100: 0.5101 - val_loss: 3.2333 - val_accuracy100: 0.4692 - 17s/epoch - 32ms/step
Epoch 8/50
538/538 - 17s - loss: 2.9384 - accuracy100: 0.5146 - val_loss: 3.2167 - val_accuracy100: 0.4732 - 17s/epoch - 32ms/step
Epoch 9/50
538/538 - 17s - loss: 2.9165 - accuracy100: 0.5190 - val_loss: 3.2364 - val_accuracy100: 0.4705 - 17s/epoch - 32ms/step
Epoch 10/50
538/538 - 17s - loss: 2.9057 - accuracy100: 0.5229 - val_loss: 3.2593 - val_accuracy100: 0.4721 - 17s/epoch - 32ms/step
Epoch 11/50
538/538 - 17s - loss: 2.8887 - accuracy100: 0.5282 - val_loss: 3.2834 - val_accuracy100: 0.4728 - 17s/epoch - 32ms/step
Epoch 12/50
538/538 - 17s - loss: 2.8767 - accuracy100: 0.5309 - val_loss: 3.3480 - val_accuracy100: 0.4611 - 17s/epoch - 31ms/step
Epoch 13/50
538/538 - 16s - loss: 2.8627 - accuracy100: 0.5327 - val_loss: 3.3054 - val_accuracy100: 0.4692 - 16s/epoch - 31ms/step
Epoch 14/50
538/538 - 16s - loss: 2.8467 - accuracy100: 0.5374 - val_loss: 3.3352 - val_accuracy100: 0.4679 - 16s/epoch - 30ms/step
testing model: results/QRTEA/W7/deepVOL_L2/h100
Evaluating performance on  test set...
2006/2006 - 36s - 36s/epoch - 18ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0190347
{'0': {'precision': 0.46293872332653496, 'recall': 0.2956013554226625, 'f1-score': 0.36081234974060483, 'support': 154343}, '1': {'precision': 0.5092705486651251, 'recall': 0.6886723173210403, 'f1-score': 0.585537989917158, 'support': 211067}, '2': {'precision': 0.42833399042958636, 'recall': 0.3745808545159546, 'f1-score': 0.3996581036292227, 'support': 147920}, 'accuracy': 0.4799797401281827, 'macro avg': {'precision': 0.46684775414041546, 'recall': 0.4529515090865524, 'f1-score': 0.4486694810956619, 'support': 513330}, 'weighted avg': {'precision': 0.4720174588156425, 'recall': 0.4799797401281827, 'f1-score': 0.46440697816744314, 'support': 513330}}
[[ 45624  71420  37299]
 [ 29061 145356  36650]
 [ 23868  68644  55408]]
Evaluating performance on  train set...
538/538 - 10s - 10s/epoch - 18ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0018137
{'0': {'precision': 0.4903783116732868, 'recall': 0.3055922712744226, 'f1-score': 0.3765360812531462, 'support': 41611}, '1': {'precision': 0.5231363317772458, 'recall': 0.6965417664459783, 'f1-score': 0.5975122536987667, 'support': 56792}, '2': {'precision': 0.43963433271277336, 'recall': 0.40430316348954876, 'f1-score': 0.4212291841380137, 'support': 39134}, 'accuracy': 0.4951104066542094, 'macro avg': {'precision': 0.48438299205443536, 'recall': 0.4688124004033165, 'f1-score': 0.4650925063633089, 'support': 137537}, 'weighted avg': {'precision': 0.4894664014607862, 'recall': 0.4951104066542094, 'f1-score': 0.48049864168290746, 'support': 137537}}
[[12716 19185  9710]
 [ 6777 39558 10457]
 [ 6438 16874 15822]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 19ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0163796
{'0': {'precision': 0.4778738874263508, 'recall': 0.315093403868408, 'f1-score': 0.37977584059775843, 'support': 12098}, '1': {'precision': 0.4712554664723032, 'recall': 0.7044603336738168, 'f1-score': 0.5647296448945056, 'support': 14685}, '2': {'precision': 0.47516719657932244, 'recall': 0.3533056166951985, 'f1-score': 0.4052739854123808, 'support': 12267}, 'accuracy': 0.4735211267605634, 'macro avg': {'precision': 0.47476551682599216, 'recall': 0.4576197847458077, 'f1-score': 0.4499264903015483, 'support': 39050}, 'weighted avg': {'precision': 0.4745347199915061, 'recall': 0.4735211267605634, 'f1-score': 0.45733876911347426, 'support': 39050}}
[[ 3812  5837  2449]
 [ 2002 10345  2338]
 [ 2163  5770  4334]]
training model: results/QRTEA/W7/deepVOL_L2/h200
Epoch 1/50
538/538 - 20s - loss: 3.3253 - accuracy200: 0.3694 - val_loss: 3.3553 - val_accuracy200: 0.3360 - 20s/epoch - 36ms/step
Epoch 2/50
538/538 - 17s - loss: 3.2631 - accuracy200: 0.3863 - val_loss: 3.2906 - val_accuracy200: 0.3643 - 17s/epoch - 31ms/step
Epoch 3/50
538/538 - 17s - loss: 3.2285 - accuracy200: 0.4020 - val_loss: 3.2768 - val_accuracy200: 0.3746 - 17s/epoch - 31ms/step
Epoch 4/50
538/538 - 17s - loss: 3.2012 - accuracy200: 0.4134 - val_loss: 3.2705 - val_accuracy200: 0.3704 - 17s/epoch - 32ms/step
Epoch 5/50
538/538 - 17s - loss: 3.1741 - accuracy200: 0.4228 - val_loss: 3.2379 - val_accuracy200: 0.3815 - 17s/epoch - 32ms/step
Epoch 6/50
538/538 - 17s - loss: 3.1556 - accuracy200: 0.4312 - val_loss: 3.2377 - val_accuracy200: 0.3879 - 17s/epoch - 32ms/step
Epoch 7/50
538/538 - 18s - loss: 3.1348 - accuracy200: 0.4378 - val_loss: 3.2248 - val_accuracy200: 0.3878 - 18s/epoch - 33ms/step
Epoch 8/50
538/538 - 17s - loss: 3.1134 - accuracy200: 0.4466 - val_loss: 3.2227 - val_accuracy200: 0.3877 - 17s/epoch - 32ms/step
Epoch 9/50
538/538 - 17s - loss: 3.0984 - accuracy200: 0.4528 - val_loss: 3.2430 - val_accuracy200: 0.3865 - 17s/epoch - 32ms/step
Epoch 10/50
538/538 - 17s - loss: 3.0910 - accuracy200: 0.4538 - val_loss: 3.2478 - val_accuracy200: 0.3870 - 17s/epoch - 31ms/step
Epoch 11/50
538/538 - 17s - loss: 3.0892 - accuracy200: 0.4566 - val_loss: 3.2478 - val_accuracy200: 0.3842 - 17s/epoch - 32ms/step
Epoch 12/50
538/538 - 18s - loss: 3.0654 - accuracy200: 0.4627 - val_loss: 3.2834 - val_accuracy200: 0.3799 - 18s/epoch - 33ms/step
Epoch 13/50
538/538 - 17s - loss: 3.0468 - accuracy200: 0.4704 - val_loss: 3.2958 - val_accuracy200: 0.3780 - 17s/epoch - 32ms/step
Epoch 14/50
538/538 - 17s - loss: 3.0321 - accuracy200: 0.4751 - val_loss: 3.3203 - val_accuracy200: 0.3776 - 17s/epoch - 32ms/step
Epoch 15/50
538/538 - 17s - loss: 3.0216 - accuracy200: 0.4803 - val_loss: 3.3533 - val_accuracy200: 0.3749 - 17s/epoch - 32ms/step
Epoch 16/50
538/538 - 15s - loss: 3.0053 - accuracy200: 0.4848 - val_loss: 3.3712 - val_accuracy200: 0.3759 - 15s/epoch - 29ms/step
Epoch 17/50
538/538 - 16s - loss: 2.9928 - accuracy200: 0.4883 - val_loss: 3.3799 - val_accuracy200: 0.3749 - 16s/epoch - 29ms/step
Epoch 18/50
538/538 - 16s - loss: 2.9824 - accuracy200: 0.4905 - val_loss: 3.4487 - val_accuracy200: 0.3751 - 16s/epoch - 29ms/step
testing model: results/QRTEA/W7/deepVOL_L2/h200
Evaluating performance on  test set...
2006/2006 - 33s - 33s/epoch - 16ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0831909
{'0': {'precision': 0.43454181232570016, 'recall': 0.18721971196967388, 'f1-score': 0.26169130691898285, 'support': 177273}, '1': {'precision': 0.3759850185743941, 'recall': 0.6670070949254162, 'f1-score': 0.48089467164476474, 'support': 166457}, '2': {'precision': 0.39180679684301184, 'recall': 0.32724646226415094, 'f1-score': 0.3566283485513439, 'support': 169600}, 'accuracy': 0.38906356534782693, 'macro avg': {'precision': 0.4007778759143687, 'recall': 0.39382442305308035, 'f1-score': 0.36640477570503055, 'support': 513330}, 'weighted avg': {'precision': 0.4014343632318909, 'recall': 0.38906356534782693, 'f1-score': 0.3641385762058118, 'support': 513330}}
[[ 33189  94274  49810]
 [ 19086 111028  36343]
 [ 24102  89997  55501]]
Evaluating performance on  train set...
538/538 - 9s - 9s/epoch - 17ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0584916
{'0': {'precision': 0.48679526010946383, 'recall': 0.18864932764976008, 'f1-score': 0.2719204511724547, 'support': 48561}, '1': {'precision': 0.38341401495824884, 'recall': 0.7019502415018682, 'f1-score': 0.49593960514772756, 'support': 43892}, '2': {'precision': 0.43797085581710593, 'recall': 0.372659923697986, 'f1-score': 0.40268440290011387, 'support': 45084}, 'accuracy': 0.4127761984047929, 'macro avg': {'precision': 0.4360600436282729, 'recall': 0.4210864976165381, 'f1-score': 0.39018148640676537, 'support': 137537}, 'weighted avg': {'precision': 0.43779892417590566, 'recall': 0.4127761984047929, 'f1-score': 0.38627521175304363, 'support': 137537}}
[[ 9161 26694 12706]
 [ 4228 30810  8854]
 [ 5430 22853 16801]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 17ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0764486
{'0': {'precision': 0.4375314439040751, 'recall': 0.19534291704103024, 'f1-score': 0.2700967959004089, 'support': 13356}, '1': {'precision': 0.3559560927689745, 'recall': 0.701987870619946, 'f1-score': 0.4723820320249398, 'support': 11872}, '2': {'precision': 0.434876989869754, 'recall': 0.3043698451743597, 'f1-score': 0.3581035069799115, 'support': 13822}, 'accuracy': 0.3879641485275288, 'macro avg': {'precision': 0.40945484218093453, 'recall': 0.4005668776117786, 'f1-score': 0.3668607783017534, 'support': 39050}, 'weighted avg': {'precision': 0.4117913047916987, 'recall': 0.3879641485275288, 'f1-score': 0.36274619625409177, 'support': 39050}}
[[2609 7452 3295]
 [1366 8334 2172]
 [1988 7627 4207]]
training model: results/QRTEA/W7/deepVOL_L2/h300
Epoch 1/50
538/538 - 20s - loss: 3.3340 - accuracy300: 0.3621 - val_loss: 3.4161 - val_accuracy300: 0.3482 - 20s/epoch - 37ms/step
Epoch 2/50
538/538 - 17s - loss: 3.3095 - accuracy300: 0.3510 - val_loss: 3.3244 - val_accuracy300: 0.3335 - 17s/epoch - 32ms/step
Epoch 3/50
538/538 - 17s - loss: 3.2964 - accuracy300: 0.3520 - val_loss: 3.3168 - val_accuracy300: 0.3429 - 17s/epoch - 32ms/step
Epoch 4/50
538/538 - 17s - loss: 3.2808 - accuracy300: 0.3680 - val_loss: 3.2976 - val_accuracy300: 0.3536 - 17s/epoch - 32ms/step
Epoch 5/50
538/538 - 17s - loss: 3.2673 - accuracy300: 0.3791 - val_loss: 3.2978 - val_accuracy300: 0.3609 - 17s/epoch - 32ms/step
Epoch 6/50
538/538 - 17s - loss: 3.2624 - accuracy300: 0.3828 - val_loss: 3.3135 - val_accuracy300: 0.3622 - 17s/epoch - 31ms/step
Epoch 7/50
538/538 - 16s - loss: 3.2515 - accuracy300: 0.3910 - val_loss: 3.3118 - val_accuracy300: 0.3615 - 16s/epoch - 30ms/step
Epoch 8/50
538/538 - 16s - loss: 3.2391 - accuracy300: 0.3989 - val_loss: 3.3224 - val_accuracy300: 0.3652 - 16s/epoch - 30ms/step
Epoch 9/50
538/538 - 16s - loss: 3.2288 - accuracy300: 0.4037 - val_loss: 3.3263 - val_accuracy300: 0.3600 - 16s/epoch - 30ms/step
Epoch 10/50
538/538 - 17s - loss: 3.2096 - accuracy300: 0.4149 - val_loss: 3.3328 - val_accuracy300: 0.3632 - 17s/epoch - 32ms/step
Epoch 11/50
538/538 - 16s - loss: 3.1992 - accuracy300: 0.4205 - val_loss: 3.3445 - val_accuracy300: 0.3610 - 16s/epoch - 30ms/step
Epoch 12/50
538/538 - 16s - loss: 3.1849 - accuracy300: 0.4262 - val_loss: 3.3470 - val_accuracy300: 0.3567 - 16s/epoch - 30ms/step
Epoch 13/50
538/538 - 16s - loss: 3.1743 - accuracy300: 0.4330 - val_loss: 3.3603 - val_accuracy300: 0.3593 - 16s/epoch - 30ms/step
Epoch 14/50
538/538 - 17s - loss: 3.1592 - accuracy300: 0.4386 - val_loss: 3.3796 - val_accuracy300: 0.3541 - 17s/epoch - 32ms/step
testing model: results/QRTEA/W7/deepVOL_L2/h300
Evaluating performance on  test set...
2006/2006 - 34s - 34s/epoch - 17ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0981098
{'0': {'precision': 0.3476048513583085, 'recall': 0.33842728586748727, 'f1-score': 0.3429546810307658, 'support': 171576}, '1': {'precision': 0.36511111251764317, 'recall': 0.32530847488213666, 'f1-score': 0.344062484156783, 'support': 177324}, '2': {'precision': 0.33742451843157667, 'recall': 0.3863893450100347, 'f1-score': 0.3602507364177353, 'support': 164430}, 'accuracy': 0.3492587614205287, 'macro avg': {'precision': 0.3500468274358428, 'recall': 0.3500417019198862, 'f1-score': 0.3490893005350946, 'support': 513330}, 'weighted avg': {'precision': 0.3503912229139849, 'recall': 0.3492587614205287, 'f1-score': 0.3488776359891693, 'support': 513330}}
[[58066 47221 66289]
 [61171 57685 58468]
 [47809 53087 63534]]
Evaluating performance on  train set...
538/538 - 9s - 9s/epoch - 17ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0938648
{'0': {'precision': 0.38248943506779703, 'recall': 0.3151003844510893, 'f1-score': 0.34553992809546674, 'support': 46820}, '1': {'precision': 0.36413182321382953, 'recall': 0.35876997944372196, 'f1-score': 0.3614310166303912, 'support': 47674}, '2': {'precision': 0.3474631688271724, 'recall': 0.4197198150686523, 'f1-score': 0.380188768584867, 'support': 43043}, 'accuracy': 0.3629786893708602, 'macro avg': {'precision': 0.3646948090362663, 'recall': 0.3645300596544878, 'f1-score': 0.362386571103575, 'support': 137537}, 'weighted avg': {'precision': 0.3651645234780339, 'recall': 0.3629786893708602, 'f1-score': 0.3618917592099977, 'support': 137537}}
[[14753 14883 17184]
 [13826 17104 16744]
 [ 9992 14985 18066]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 16ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0965796
{'0': {'precision': 0.34006277037916705, 'recall': 0.3183767471410419, 'f1-score': 0.3288626389401583, 'support': 12592}, '1': {'precision': 0.3603392568659128, 'recall': 0.3352370932591869, 'f1-score': 0.3473352279363102, 'support': 13307}, '2': {'precision': 0.3599220482494456, 'recall': 0.40726940917040527, 'f1-score': 0.38213470319634707, 'support': 13151}, 'accuracy': 0.35405889884763125, 'macro avg': {'precision': 0.3534413584981751, 'recall': 0.353627749856878, 'f1-score': 0.3527775233576052, 'support': 39050}, 'weighted avg': {'precision': 0.3536604289950738, 'recall': 0.35405889884763125, 'f1-score': 0.35309812316051503, 'support': 39050}}
[[4009 3678 4905]
 [4226 4461 4620]
 [3554 4241 5356]]
training model: results/QRTEA/W7/deepVOL_L2/h500
Epoch 1/50
538/538 - 20s - loss: 3.3096 - accuracy500: 0.3749 - val_loss: 3.3549 - val_accuracy500: 0.3183 - 20s/epoch - 36ms/step
Epoch 2/50
538/538 - 17s - loss: 3.2902 - accuracy500: 0.3560 - val_loss: 3.3401 - val_accuracy500: 0.3127 - 17s/epoch - 32ms/step
Epoch 3/50
538/538 - 17s - loss: 3.2827 - accuracy500: 0.3657 - val_loss: 3.3211 - val_accuracy500: 0.3327 - 17s/epoch - 31ms/step
Epoch 4/50
538/538 - 17s - loss: 3.2711 - accuracy500: 0.3792 - val_loss: 3.3258 - val_accuracy500: 0.3409 - 17s/epoch - 31ms/step
Epoch 5/50
538/538 - 17s - loss: 3.2617 - accuracy500: 0.3894 - val_loss: 3.3313 - val_accuracy500: 0.3342 - 17s/epoch - 31ms/step
Epoch 6/50
538/538 - 17s - loss: 3.2550 - accuracy500: 0.3952 - val_loss: 3.3328 - val_accuracy500: 0.3380 - 17s/epoch - 32ms/step
Epoch 7/50
538/538 - 17s - loss: 3.2483 - accuracy500: 0.4023 - val_loss: 3.3283 - val_accuracy500: 0.3443 - 17s/epoch - 31ms/step
Epoch 8/50
538/538 - 17s - loss: 3.2419 - accuracy500: 0.4069 - val_loss: 3.3452 - val_accuracy500: 0.3366 - 17s/epoch - 31ms/step
Epoch 9/50
538/538 - 17s - loss: 3.2368 - accuracy500: 0.4075 - val_loss: 3.3486 - val_accuracy500: 0.3345 - 17s/epoch - 31ms/step
Epoch 10/50
538/538 - 17s - loss: 3.2212 - accuracy500: 0.4198 - val_loss: 3.3530 - val_accuracy500: 0.3577 - 17s/epoch - 31ms/step
Epoch 11/50
538/538 - 17s - loss: 3.2023 - accuracy500: 0.4307 - val_loss: 3.3646 - val_accuracy500: 0.3540 - 17s/epoch - 32ms/step
Epoch 12/50
538/538 - 17s - loss: 3.1843 - accuracy500: 0.4388 - val_loss: 3.3923 - val_accuracy500: 0.3563 - 17s/epoch - 32ms/step
Epoch 13/50
538/538 - 17s - loss: 3.1774 - accuracy500: 0.4392 - val_loss: 3.4111 - val_accuracy500: 0.3566 - 17s/epoch - 31ms/step
testing model: results/QRTEA/W7/deepVOL_L2/h500
Evaluating performance on  test set...
2006/2006 - 33s - 33s/epoch - 16ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0989552
{'0': {'precision': 0.36426926425949885, 'recall': 0.48354253986086504, 'f1-score': 0.41551600102109487, 'support': 185144}, '1': {'precision': 0.2941765907426677, 'recall': 0.15257455824738148, 'f1-score': 0.2009345179335308, 'support': 150084}, '2': {'precision': 0.3386358006145802, 'recall': 0.36073149094339196, 'f1-score': 0.3493346020526065, 'support': 178102}, 'accuracy': 0.34416652056182184, 'macro avg': {'precision': 0.33236055187224894, 'recall': 0.3322828630172128, 'f1-score': 0.3219283736690774, 'support': 513330}, 'weighted avg': {'precision': 0.3348823982002633, 'recall': 0.34416652056182184, 'f1-score': 0.32981618447657246, 'support': 513330}}
[[89525 25969 69650]
 [71359 22899 55826]
 [84882 28973 64247]]
Evaluating performance on  train set...
538/538 - 10s - 10s/epoch - 18ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.09346
{'0': {'precision': 0.37266073674480626, 'recall': 0.5059663416039172, 'f1-score': 0.42920095288789606, 'support': 48606}, '1': {'precision': 0.36668872711228767, 'recall': 0.18644980370162648, 'f1-score': 0.2472040452111838, 'support': 44575}, '2': {'precision': 0.3613208126189161, 'recall': 0.39816484804761476, 'f1-score': 0.3788491446345257, 'support': 44356}, 'accuracy': 0.3676465242080313, 'macro avg': {'precision': 0.36689009215866997, 'recall': 0.3635269977843862, 'f1-score': 0.35175138091120184, 'support': 137537}, 'weighted avg': {'precision': 0.3670680889198755, 'recall': 0.3676465242080313, 'f1-score': 0.3539781621728452, 'support': 137537}}
[[24593  7363 16650]
 [21696  8311 14568]
 [19704  6991 17661]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 18ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.100867
{'0': {'precision': 0.2963527490473598, 'recall': 0.47097499783718316, 'f1-score': 0.36379431320792543, 'support': 11559}, '1': {'precision': 0.4544014084507042, 'recall': 0.1665591120289107, 'f1-score': 0.24376652814506986, 'support': 15496}, '2': {'precision': 0.3274, 'recall': 0.4094205919132972, 'f1-score': 0.3638451565104649, 'support': 11995}, 'accuracy': 0.3312676056338028, 'macro avg': {'precision': 0.3593847191660213, 'recall': 0.3489849005931303, 'f1-score': 0.32380199928782005, 'support': 39050}, 'weighted avg': {'precision': 0.3686071357641625, 'recall': 0.3312676056338028, 'f1-score': 0.3161799549001137, 'support': 39050}}
[[5444 1390 4725]
 [7551 2581 5364]
 [5375 1709 4911]]
training model: results/QRTEA/W7/deepVOL_L2/h1000
Epoch 1/50
538/538 - 19s - loss: 3.2973 - accuracy1000: 0.3983 - val_loss: 3.4389 - val_accuracy1000: 0.3341 - 19s/epoch - 35ms/step
Epoch 2/50
538/538 - 16s - loss: 3.2559 - accuracy1000: 0.3977 - val_loss: 3.4038 - val_accuracy1000: 0.3390 - 16s/epoch - 30ms/step
Epoch 3/50
538/538 - 17s - loss: 3.2851 - accuracy1000: 0.3630 - val_loss: 3.3743 - val_accuracy1000: 0.3401 - 17s/epoch - 32ms/step
Epoch 4/50
538/538 - 17s - loss: 3.2876 - accuracy1000: 0.3615 - val_loss: 3.3650 - val_accuracy1000: 0.3369 - 17s/epoch - 31ms/step
Epoch 5/50
538/538 - 16s - loss: 3.2780 - accuracy1000: 0.3708 - val_loss: 3.4004 - val_accuracy1000: 0.3306 - 16s/epoch - 30ms/step
Epoch 6/50
538/538 - 17s - loss: 3.2703 - accuracy1000: 0.3740 - val_loss: 3.3869 - val_accuracy1000: 0.3287 - 17s/epoch - 31ms/step
Epoch 7/50
538/538 - 17s - loss: 3.2658 - accuracy1000: 0.3858 - val_loss: 3.3709 - val_accuracy1000: 0.3373 - 17s/epoch - 32ms/step
Epoch 8/50
538/538 - 17s - loss: 3.2626 - accuracy1000: 0.3901 - val_loss: 3.3682 - val_accuracy1000: 0.3390 - 17s/epoch - 32ms/step
Epoch 9/50
538/538 - 17s - loss: 3.2463 - accuracy1000: 0.4030 - val_loss: 3.3716 - val_accuracy1000: 0.3412 - 17s/epoch - 32ms/step
Epoch 10/50
538/538 - 17s - loss: 3.2412 - accuracy1000: 0.4016 - val_loss: 3.3826 - val_accuracy1000: 0.3326 - 17s/epoch - 32ms/step
Epoch 11/50
538/538 - 17s - loss: 3.2291 - accuracy1000: 0.4057 - val_loss: 3.3823 - val_accuracy1000: 0.3430 - 17s/epoch - 32ms/step
Epoch 12/50
538/538 - 17s - loss: 3.2263 - accuracy1000: 0.4103 - val_loss: 3.4052 - val_accuracy1000: 0.3272 - 17s/epoch - 31ms/step
Epoch 13/50
538/538 - 17s - loss: 3.2058 - accuracy1000: 0.4257 - val_loss: 3.4120 - val_accuracy1000: 0.3303 - 17s/epoch - 32ms/step
Epoch 14/50
538/538 - 17s - loss: 3.1881 - accuracy1000: 0.4297 - val_loss: 3.3981 - val_accuracy1000: 0.3412 - 17s/epoch - 32ms/step
testing model: results/QRTEA/W7/deepVOL_L2/h1000
Evaluating performance on  test set...
2006/2006 - 36s - 36s/epoch - 18ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0758153
{'0': {'precision': 0.4051756139668228, 'recall': 0.4457960573582529, 'f1-score': 0.42451634368241875, 'support': 203214}, '1': {'precision': 0.24615384615384617, 'recall': 0.00013878648566595828, 'f1-score': 0.0002774165583008236, 'support': 115285}, '2': {'precision': 0.3863565752318091, 'recall': 0.574441438990715, 'f1-score': 0.4619893541709235, 'support': 194831}, 'accuracy': 0.39453567880310914, 'macro avg': {'precision': 0.3458953451174927, 'recall': 0.34012542761154463, 'f1-score': 0.29559437147054773, 'support': 513330}, 'weighted avg': {'precision': 0.36231944612527744, 'recall': 0.39453567880310914, 'f1-score': 0.34346228370731885, 'support': 513330}}
[[ 90592     15 112607]
 [ 50117     16  65152]
 [ 82878     34 111919]]
Evaluating performance on  train set...
538/538 - 10s - 10s/epoch - 19ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1000786
{'0': {'precision': 0.38178062108489935, 'recall': 0.4560488765945591, 'f1-score': 0.41562304462561095, 'support': 50249}, '1': {'precision': 0.41379310344827586, 'recall': 0.0002822334070276118, 'f1-score': 0.0005640820739417585, 'support': 42518}, '2': {'precision': 0.3401089257136957, 'recall': 0.5886307795398704, 'f1-score': 0.43111881819817754, 'support': 44770}, 'accuracy': 0.3583108545336891, 'macro avg': {'precision': 0.3785608834156236, 'recall': 0.3483206298471524, 'f1-score': 0.28243531496591007, 'support': 137537}, 'weighted avg': {'precision': 0.3781122621949806, 'recall': 0.3583108545336891, 'f1-score': 0.2923563513944945, 'support': 137537}}
[[22916     7 27326]
 [18701    12 23805]
 [18407    10 26353]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 18ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1085937
{'0': {'precision': 0.31610640163694825, 'recall': 0.4231160497691525, 'f1-score': 0.3618658814081114, 'support': 12779}, '1': {'precision': 0.7142857142857143, 'recall': 0.0003846153846153846, 'f1-score': 0.0007688167909587145, 'support': 13000}, '2': {'precision': 0.35003190810465856, 'recall': 0.5786300956973853, 'f1-score': 0.43619529097673887, 'support': 13271}, 'accuracy': 0.3352368758002561, 'macro avg': {'precision': 0.4601413413424404, 'recall': 0.3340435869503844, 'f1-score': 0.266276663058603, 'support': 39050}, 'weighted avg': {'precision': 0.4601923545375102, 'recall': 0.3352368758002561, 'f1-score': 0.2669148892022796, 'support': 39050}}
[[5407    2 7370]
 [6106    5 6889]
 [5592    0 7679]]
training model: results/QRTEA/W7/deepVOL_L3/h10
Epoch 1/50
538/538 - 26s - loss: 3.2276 - accuracy10: 0.3840 - val_loss: 3.3391 - val_accuracy10: 0.5802 - 26s/epoch - 49ms/step
Epoch 2/50
538/538 - 24s - loss: 2.7568 - accuracy10: 0.4826 - val_loss: 2.7622 - val_accuracy10: 0.6133 - 24s/epoch - 44ms/step
Epoch 3/50
538/538 - 23s - loss: 2.4669 - accuracy10: 0.6200 - val_loss: 2.5777 - val_accuracy10: 0.6865 - 23s/epoch - 43ms/step
Epoch 4/50
538/538 - 23s - loss: 2.3714 - accuracy10: 0.6438 - val_loss: 2.5280 - val_accuracy10: 0.6838 - 23s/epoch - 43ms/step
Epoch 5/50
538/538 - 23s - loss: 2.3158 - accuracy10: 0.6566 - val_loss: 2.4460 - val_accuracy10: 0.6939 - 23s/epoch - 43ms/step
Epoch 6/50
538/538 - 23s - loss: 2.2646 - accuracy10: 0.6637 - val_loss: 2.4199 - val_accuracy10: 0.7005 - 23s/epoch - 43ms/step
Epoch 7/50
538/538 - 24s - loss: 2.2357 - accuracy10: 0.6705 - val_loss: 2.4128 - val_accuracy10: 0.6922 - 24s/epoch - 44ms/step
Epoch 8/50
538/538 - 23s - loss: 2.2131 - accuracy10: 0.6758 - val_loss: 2.3837 - val_accuracy10: 0.6989 - 23s/epoch - 42ms/step
Epoch 9/50
538/538 - 22s - loss: 2.1877 - accuracy10: 0.6805 - val_loss: 2.3749 - val_accuracy10: 0.6982 - 22s/epoch - 41ms/step
Epoch 10/50
538/538 - 22s - loss: 2.1697 - accuracy10: 0.6820 - val_loss: 2.3736 - val_accuracy10: 0.7075 - 22s/epoch - 41ms/step
Epoch 11/50
538/538 - 22s - loss: 2.1569 - accuracy10: 0.6867 - val_loss: 2.3763 - val_accuracy10: 0.7004 - 22s/epoch - 41ms/step
Epoch 12/50
538/538 - 22s - loss: 2.1407 - accuracy10: 0.6868 - val_loss: 2.3827 - val_accuracy10: 0.6958 - 22s/epoch - 41ms/step
Epoch 13/50
538/538 - 23s - loss: 2.1248 - accuracy10: 0.6900 - val_loss: 2.3751 - val_accuracy10: 0.6910 - 23s/epoch - 43ms/step
Epoch 14/50
538/538 - 23s - loss: 2.1154 - accuracy10: 0.6916 - val_loss: 2.3648 - val_accuracy10: 0.7002 - 23s/epoch - 43ms/step
Epoch 15/50
538/538 - 23s - loss: 2.1060 - accuracy10: 0.6898 - val_loss: 2.3781 - val_accuracy10: 0.6900 - 23s/epoch - 43ms/step
Epoch 16/50
538/538 - 24s - loss: 2.0951 - accuracy10: 0.6914 - val_loss: 2.3811 - val_accuracy10: 0.6777 - 24s/epoch - 44ms/step
Epoch 17/50
538/538 - 24s - loss: 2.0847 - accuracy10: 0.6924 - val_loss: 2.3946 - val_accuracy10: 0.6817 - 24s/epoch - 44ms/step
Epoch 18/50
538/538 - 23s - loss: 2.0668 - accuracy10: 0.6952 - val_loss: 2.3858 - val_accuracy10: 0.6801 - 23s/epoch - 44ms/step
Epoch 19/50
538/538 - 24s - loss: 2.0605 - accuracy10: 0.6938 - val_loss: 2.4014 - val_accuracy10: 0.6748 - 24s/epoch - 45ms/step
Epoch 20/50
538/538 - 24s - loss: 2.0482 - accuracy10: 0.6959 - val_loss: 2.3929 - val_accuracy10: 0.7056 - 24s/epoch - 44ms/step
Epoch 21/50
538/538 - 24s - loss: 2.0452 - accuracy10: 0.6938 - val_loss: 2.3862 - val_accuracy10: 0.6801 - 24s/epoch - 45ms/step
Epoch 22/50
538/538 - 24s - loss: 2.0258 - accuracy10: 0.6943 - val_loss: 2.3781 - val_accuracy10: 0.6672 - 24s/epoch - 45ms/step
Epoch 23/50
538/538 - 23s - loss: 2.0105 - accuracy10: 0.6955 - val_loss: 2.3679 - val_accuracy10: 0.6867 - 23s/epoch - 43ms/step
Epoch 24/50
538/538 - 25s - loss: 2.0062 - accuracy10: 0.6969 - val_loss: 2.3648 - val_accuracy10: 0.7088 - 25s/epoch - 47ms/step
testing model: results/QRTEA/W7/deepVOL_L3/h10
Evaluating performance on  test set...
2006/2006 - 45s - 45s/epoch - 22ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.7004953
{'0': {'precision': 0.2846235596822911, 'recall': 0.6318632422028602, 'f1-score': 0.39246209516219216, 'support': 48319}, '1': {'precision': 0.9258321262246313, 'recall': 0.7127840466226182, 'f1-score': 0.8054581424970866, 'support': 416965}, '2': {'precision': 0.33465025221348194, 'recall': 0.5923698122632477, 'f1-score': 0.42768590384167454, 'support': 48046}, 'accuracy': 0.6938967136150235, 'macro avg': {'precision': 0.5150353127068015, 'recall': 0.6456723670295753, 'f1-score': 0.5418687138336511, 'support': 513330}, 'weighted avg': {'precision': 0.8101434249106636, 'recall': 0.6938967136150235, 'f1-score': 0.7312251910046496, 'support': 513330}}
[[ 30531  10801   6987]
 [ 70160 297206  49599]
 [  6577  13008  28461]]
Evaluating performance on  train set...
538/538 - 14s - 14s/epoch - 25ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.67327565
{'0': {'precision': 0.3457753017641597, 'recall': 0.6463931125459974, 'f1-score': 0.4505420054200542, 'support': 14403}, '1': {'precision': 0.9322183302790601, 'recall': 0.7362009269606317, 'f1-score': 0.8226948902718637, 'support': 109174}, '2': {'precision': 0.3609084201033041, 'recall': 0.6306590257879656, 'f1-score': 0.4590916201699953, 'support': 13960}, 'accuracy': 0.716083672030072, 'macro avg': {'precision': 0.5463006840488414, 'recall': 0.6710843550981983, 'f1-score': 0.5774428386206377, 'support': 137537}, 'weighted avg': {'precision': 0.8128175487747836, 'recall': 0.716083672030072, 'f1-score': 0.7468169835911691, 'support': 137537}}
[[ 9310  2800  2293]
 [15503 80374 13297]
 [ 2112  3044  8804]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 22ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.70497566
{'0': {'precision': 0.3242397137745975, 'recall': 0.6643757159221076, 'f1-score': 0.4357953264708092, 'support': 4365}, '1': {'precision': 0.9227384276889228, 'recall': 0.7199973587771138, 'f1-score': 0.8088570739758545, 'support': 30289}, '2': {'precision': 0.401885043263288, 'recall': 0.5916742493175614, 'f1-score': 0.47865292602134707, 'support': 4396}, 'accuracy': 0.6993341869398207, 'macro avg': {'precision': 0.5496210615756029, 'recall': 0.6586824413389277, 'f1-score': 0.5744351088226702, 'support': 39050}, 'weighted avg': {'precision': 0.7972040265577801, 'recall': 0.6993341869398207, 'f1-score': 0.7299840403710519, 'support': 39050}}
[[ 2900   793   672]
 [ 5282 21808  3199]
 [  762  1033  2601]]
training model: results/QRTEA/W7/deepVOL_L3/h20
Epoch 1/50
538/538 - 25s - loss: 3.2832 - accuracy20: 0.4153 - val_loss: 3.5055 - val_accuracy20: 0.6175 - 25s/epoch - 47ms/step
Epoch 2/50
538/538 - 23s - loss: 2.9786 - accuracy20: 0.4260 - val_loss: 2.9948 - val_accuracy20: 0.5944 - 23s/epoch - 43ms/step
Epoch 3/50
538/538 - 22s - loss: 2.6529 - accuracy20: 0.5795 - val_loss: 2.7635 - val_accuracy20: 0.6672 - 22s/epoch - 42ms/step
Epoch 4/50
538/538 - 24s - loss: 2.5307 - accuracy20: 0.6127 - val_loss: 2.7708 - val_accuracy20: 0.7078 - 24s/epoch - 45ms/step
Epoch 5/50
538/538 - 24s - loss: 2.4712 - accuracy20: 0.6217 - val_loss: 2.7336 - val_accuracy20: 0.7086 - 24s/epoch - 45ms/step
Epoch 6/50
538/538 - 24s - loss: 2.4329 - accuracy20: 0.6286 - val_loss: 2.7115 - val_accuracy20: 0.7151 - 24s/epoch - 44ms/step
Epoch 7/50
538/538 - 24s - loss: 2.3958 - accuracy20: 0.6360 - val_loss: 2.6870 - val_accuracy20: 0.7175 - 24s/epoch - 45ms/step
Epoch 8/50
538/538 - 24s - loss: 2.3658 - accuracy20: 0.6410 - val_loss: 2.6823 - val_accuracy20: 0.7176 - 24s/epoch - 45ms/step
Epoch 9/50
538/538 - 23s - loss: 2.3408 - accuracy20: 0.6442 - val_loss: 2.6689 - val_accuracy20: 0.7163 - 23s/epoch - 42ms/step
Epoch 10/50
538/538 - 23s - loss: 2.3199 - accuracy20: 0.6491 - val_loss: 2.6782 - val_accuracy20: 0.7185 - 23s/epoch - 42ms/step
Epoch 11/50
538/538 - 24s - loss: 2.3000 - accuracy20: 0.6527 - val_loss: 2.6051 - val_accuracy20: 0.6950 - 24s/epoch - 44ms/step
Epoch 12/50
538/538 - 24s - loss: 2.2817 - accuracy20: 0.6518 - val_loss: 2.6816 - val_accuracy20: 0.7233 - 24s/epoch - 45ms/step
Epoch 13/50
538/538 - 24s - loss: 2.2651 - accuracy20: 0.6539 - val_loss: 2.5713 - val_accuracy20: 0.6984 - 24s/epoch - 44ms/step
Epoch 14/50
538/538 - 24s - loss: 2.2543 - accuracy20: 0.6560 - val_loss: 2.5912 - val_accuracy20: 0.6993 - 24s/epoch - 44ms/step
Epoch 15/50
538/538 - 24s - loss: 2.2375 - accuracy20: 0.6571 - val_loss: 2.6196 - val_accuracy20: 0.7076 - 24s/epoch - 44ms/step
Epoch 16/50
538/538 - 24s - loss: 2.2260 - accuracy20: 0.6567 - val_loss: 2.5672 - val_accuracy20: 0.6912 - 24s/epoch - 44ms/step
Epoch 17/50
538/538 - 24s - loss: 2.2166 - accuracy20: 0.6599 - val_loss: 2.5678 - val_accuracy20: 0.6885 - 24s/epoch - 45ms/step
Epoch 18/50
538/538 - 24s - loss: 2.2002 - accuracy20: 0.6608 - val_loss: 2.5950 - val_accuracy20: 0.7027 - 24s/epoch - 44ms/step
Epoch 19/50
538/538 - 24s - loss: 2.1930 - accuracy20: 0.6580 - val_loss: 2.5305 - val_accuracy20: 0.6948 - 24s/epoch - 44ms/step
Epoch 20/50
538/538 - 24s - loss: 2.1727 - accuracy20: 0.6639 - val_loss: 2.5638 - val_accuracy20: 0.6894 - 24s/epoch - 44ms/step
Epoch 21/50
538/538 - 24s - loss: 2.1680 - accuracy20: 0.6624 - val_loss: 2.5543 - val_accuracy20: 0.6873 - 24s/epoch - 44ms/step
Epoch 22/50
538/538 - 25s - loss: 2.1588 - accuracy20: 0.6633 - val_loss: 2.5458 - val_accuracy20: 0.6914 - 25s/epoch - 46ms/step
Epoch 23/50
538/538 - 25s - loss: 2.1459 - accuracy20: 0.6644 - val_loss: 2.5438 - val_accuracy20: 0.6576 - 25s/epoch - 46ms/step
Epoch 24/50
538/538 - 25s - loss: 2.1395 - accuracy20: 0.6647 - val_loss: 2.5574 - val_accuracy20: 0.6651 - 25s/epoch - 46ms/step
Epoch 25/50
538/538 - 25s - loss: 2.1253 - accuracy20: 0.6653 - val_loss: 2.5775 - val_accuracy20: 0.6610 - 25s/epoch - 47ms/step
Epoch 26/50
538/538 - 24s - loss: 2.1123 - accuracy20: 0.6680 - val_loss: 2.5807 - val_accuracy20: 0.6753 - 24s/epoch - 45ms/step
Epoch 27/50
538/538 - 24s - loss: 2.1066 - accuracy20: 0.6652 - val_loss: 2.5675 - val_accuracy20: 0.6685 - 24s/epoch - 45ms/step
Epoch 28/50
538/538 - 24s - loss: 2.0916 - accuracy20: 0.6680 - val_loss: 2.5933 - val_accuracy20: 0.6637 - 24s/epoch - 45ms/step
Epoch 29/50
538/538 - 24s - loss: 2.0820 - accuracy20: 0.6685 - val_loss: 2.6307 - val_accuracy20: 0.6471 - 24s/epoch - 44ms/step
testing model: results/QRTEA/W7/deepVOL_L3/h20
Evaluating performance on  test set...
2006/2006 - 43s - 43s/epoch - 21ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.7068379
{'0': {'precision': 0.3750686541852555, 'recall': 0.5807101297926301, 'f1-score': 0.4557669002581801, 'support': 67030}, '1': {'precision': 0.8667330562378366, 'recall': 0.750361414114864, 'f1-score': 0.8043599847285012, 'support': 380450}, '2': {'precision': 0.4237590421551509, 'recall': 0.5159757023538345, 'f1-score': 0.4653427377936041, 'support': 65850}, 'accuracy': 0.6981415463736778, 'macro avg': {'precision': 0.555186917526081, 'recall': 0.6156824154204429, 'f1-score': 0.5751565409267618, 'support': 513330}, 'weighted avg': {'precision': 0.745707393025226, 'recall': 0.6981415463736778, 'f1-score': 0.7153519778660373, 'support': 513330}}
[[ 38925  21068   7037]
 [ 55809 285475  39166]
 [  9047  22826  33977]]
Evaluating performance on  train set...
538/538 - 12s - 12s/epoch - 22ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.666706
{'0': {'precision': 0.4590082439206264, 'recall': 0.5683217070168239, 'f1-score': 0.5078492036209465, 'support': 19496}, '1': {'precision': 0.8738160568522324, 'recall': 0.7672812685867516, 'f1-score': 0.817090713902308, 'support': 99197}, '2': {'precision': 0.42479558851492677, 'recall': 0.5927616217363617, 'f1-score': 0.4949157048228804, 'support': 18844}, 'accuracy': 0.7151675549124963, 'macro avg': {'precision': 0.5858732964292619, 'recall': 0.6427881991133124, 'f1-score': 0.606618540782045, 'support': 137537}, 'weighted avg': {'precision': 0.7534961805552157, 'recall': 0.7151675549124963, 'f1-score': 0.7291141086576236, 'support': 137537}}
[[11080  5714  2702]
 [10662 76112 12423]
 [ 2397  5277 11170]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 22ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.7055525
{'0': {'precision': 0.4293652753766362, 'recall': 0.590924541128484, 'f1-score': 0.49735374052353026, 'support': 5884}, '1': {'precision': 0.8562006929081271, 'recall': 0.752899721039495, 'f1-score': 0.8012343508915841, 'support': 27244}, '2': {'precision': 0.46333095067905644, 'recall': 0.5472813238770685, 'f1-score': 0.5018193078888287, 'support': 5922}, 'accuracy': 0.6973111395646607, 'macro avg': {'precision': 0.5829656396546066, 'recall': 0.6303685286816826, 'f1-score': 0.600135799767981, 'support': 39050}, 'weighted avg': {'precision': 0.7323063469353781, 'recall': 0.6973111395646607, 'f1-score': 0.710039231914172, 'support': 39050}}
[[ 3477  1612   795]
 [ 3773 20512  2959]
 [  848  1833  3241]]
training model: results/QRTEA/W7/deepVOL_L3/h30
Epoch 1/50
538/538 - 26s - loss: 3.2633 - accuracy30: 0.3843 - val_loss: 3.2814 - val_accuracy30: 0.5538 - 26s/epoch - 47ms/step
Epoch 2/50
538/538 - 23s - loss: 2.8903 - accuracy30: 0.4829 - val_loss: 3.0905 - val_accuracy30: 0.5923 - 23s/epoch - 43ms/step
Epoch 3/50
538/538 - 22s - loss: 2.7127 - accuracy30: 0.5710 - val_loss: 2.9686 - val_accuracy30: 0.6332 - 22s/epoch - 41ms/step
Epoch 4/50
538/538 - 24s - loss: 2.6388 - accuracy30: 0.5913 - val_loss: 2.9695 - val_accuracy30: 0.6378 - 24s/epoch - 44ms/step
Epoch 5/50
538/538 - 23s - loss: 2.5915 - accuracy30: 0.5999 - val_loss: 2.9492 - val_accuracy30: 0.6730 - 23s/epoch - 44ms/step
Epoch 6/50
538/538 - 23s - loss: 2.5552 - accuracy30: 0.6079 - val_loss: 2.8827 - val_accuracy30: 0.6729 - 23s/epoch - 43ms/step
Epoch 7/50
538/538 - 23s - loss: 2.5218 - accuracy30: 0.6131 - val_loss: 2.8833 - val_accuracy30: 0.6627 - 23s/epoch - 42ms/step
Epoch 8/50
538/538 - 23s - loss: 2.4990 - accuracy30: 0.6146 - val_loss: 2.8429 - val_accuracy30: 0.6695 - 23s/epoch - 42ms/step
Epoch 9/50
538/538 - 23s - loss: 2.4742 - accuracy30: 0.6201 - val_loss: 2.8302 - val_accuracy30: 0.6559 - 23s/epoch - 43ms/step
Epoch 10/50
538/538 - 24s - loss: 2.4633 - accuracy30: 0.6228 - val_loss: 2.7640 - val_accuracy30: 0.6526 - 24s/epoch - 44ms/step
Epoch 11/50
538/538 - 23s - loss: 2.4467 - accuracy30: 0.6280 - val_loss: 2.7605 - val_accuracy30: 0.6353 - 23s/epoch - 42ms/step
Epoch 12/50
538/538 - 25s - loss: 2.4288 - accuracy30: 0.6290 - val_loss: 2.8219 - val_accuracy30: 0.6713 - 25s/epoch - 46ms/step
Epoch 13/50
538/538 - 23s - loss: 2.4150 - accuracy30: 0.6319 - val_loss: 2.7940 - val_accuracy30: 0.6594 - 23s/epoch - 42ms/step
Epoch 14/50
538/538 - 24s - loss: 2.4093 - accuracy30: 0.6313 - val_loss: 2.7745 - val_accuracy30: 0.6585 - 24s/epoch - 44ms/step
Epoch 15/50
538/538 - 23s - loss: 2.3933 - accuracy30: 0.6338 - val_loss: 2.7744 - val_accuracy30: 0.6619 - 23s/epoch - 43ms/step
Epoch 16/50
538/538 - 24s - loss: 2.3802 - accuracy30: 0.6356 - val_loss: 2.7360 - val_accuracy30: 0.6430 - 24s/epoch - 46ms/step
Epoch 17/50
538/538 - 22s - loss: 2.3716 - accuracy30: 0.6349 - val_loss: 2.7937 - val_accuracy30: 0.6699 - 22s/epoch - 41ms/step
Epoch 18/50
538/538 - 23s - loss: 2.3565 - accuracy30: 0.6389 - val_loss: 2.7510 - val_accuracy30: 0.6538 - 23s/epoch - 43ms/step
Epoch 19/50
538/538 - 24s - loss: 2.3502 - accuracy30: 0.6364 - val_loss: 2.7649 - val_accuracy30: 0.6571 - 24s/epoch - 44ms/step
Epoch 20/50
538/538 - 23s - loss: 2.3440 - accuracy30: 0.6384 - val_loss: 2.7477 - val_accuracy30: 0.6425 - 23s/epoch - 43ms/step
Epoch 21/50
538/538 - 23s - loss: 2.3318 - accuracy30: 0.6391 - val_loss: 2.7496 - val_accuracy30: 0.6425 - 23s/epoch - 42ms/step
Epoch 22/50
538/538 - 23s - loss: 2.3121 - accuracy30: 0.6411 - val_loss: 2.7721 - val_accuracy30: 0.6542 - 23s/epoch - 43ms/step
Epoch 23/50
538/538 - 23s - loss: 2.3090 - accuracy30: 0.6438 - val_loss: 2.7646 - val_accuracy30: 0.6275 - 23s/epoch - 43ms/step
Epoch 24/50
538/538 - 25s - loss: 2.2942 - accuracy30: 0.6416 - val_loss: 2.8124 - val_accuracy30: 0.6609 - 25s/epoch - 46ms/step
Epoch 25/50
538/538 - 24s - loss: 2.2876 - accuracy30: 0.6424 - val_loss: 2.7781 - val_accuracy30: 0.6522 - 24s/epoch - 44ms/step
Epoch 26/50
538/538 - 24s - loss: 2.2760 - accuracy30: 0.6441 - val_loss: 2.8154 - val_accuracy30: 0.6671 - 24s/epoch - 46ms/step
testing model: results/QRTEA/W7/deepVOL_L3/h30
Evaluating performance on  test set...
2006/2006 - 44s - 44s/epoch - 22ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.78298974
{'0': {'precision': 0.4192293630159246, 'recall': 0.4972235271443886, 'f1-score': 0.4549076222015285, 'support': 83019}, '1': {'precision': 0.8174268300850579, 'recall': 0.6987682099110009, 'f1-score': 0.7534543613772072, 'support': 349329}, '2': {'precision': 0.38782409717323607, 'recall': 0.5567039589044479, 'f1-score': 0.4571663252682175, 'support': 80982}, 'accuracy': 0.6437613231254748, 'macro avg': {'precision': 0.5414934300914062, 'recall': 0.5842318986532792, 'f1-score': 0.5551761029489845, 'support': 513330}, 'weighted avg': {'precision': 0.6852544574684614, 'recall': 0.6437613231254748, 'f1-score': 0.6584296219701906, 'support': 513330}}
[[ 41279  28162  13578]
 [ 47644 244100  57585]
 [  9541  26358  45083]]
Evaluating performance on  train set...
538/538 - 12s - 12s/epoch - 22ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.73844695
{'0': {'precision': 0.48592304332287656, 'recall': 0.5190888266734538, 'f1-score': 0.5019586931107328, 'support': 23574}, '1': {'precision': 0.8247789335217169, 'recall': 0.74191427820142, 'f1-score': 0.7811551905129951, 'support': 91272}, '2': {'precision': 0.4254925294195425, 'recall': 0.5672733682958001, 'f1-score': 0.4862588066411046, 'support': 22691}, 'accuracy': 0.6749092971345892, 'macro avg': {'precision': 0.5787315020880454, 'recall': 0.6094254910568914, 'f1-score': 0.5897908967549442, 'support': 137537}, 'weighted avg': {'precision': 0.7008239501279401, 'recall': 0.6749092971345892, 'f1-score': 0.6846482718205851, 'support': 137537}}
[[12237  7647  3690]
 [ 9866 67716 13690]
 [ 3080  6739 12872]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 23ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.7888982
{'0': {'precision': 0.45127169004040885, 'recall': 0.5329870859067939, 'f1-score': 0.4887372892264126, 'support': 7124}, '1': {'precision': 0.7975331201461855, 'recall': 0.704576640568246, 'f1-score': 0.748178623467901, 'support': 24778}, '2': {'precision': 0.4392865309855934, 'recall': 0.5374930050363738, 'f1-score': 0.4834528752988549, 'support': 7148}, 'accuracy': 0.6426888604353393, 'macro avg': {'precision': 0.5626971137240625, 'recall': 0.5916855771704712, 'f1-score': 0.5734562626643895, 'support': 39050}, 'weighted avg': {'precision': 0.668787587562486, 'recall': 0.6426888604353393, 'f1-score': 0.6523906666676781, 'support': 39050}}
[[ 3797  2151  1176]
 [ 3592 17458  3728]
 [ 1025  2281  3842]]
training model: results/QRTEA/W7/deepVOL_L3/h50
Epoch 1/50
538/538 - 27s - loss: 3.3117 - accuracy50: 0.3904 - val_loss: 3.3774 - val_accuracy50: 0.4605 - 27s/epoch - 51ms/step
Epoch 2/50
538/538 - 23s - loss: 3.1129 - accuracy50: 0.4118 - val_loss: 3.2370 - val_accuracy50: 0.4950 - 23s/epoch - 43ms/step
Epoch 3/50
538/538 - 24s - loss: 2.9393 - accuracy50: 0.5021 - val_loss: 3.1773 - val_accuracy50: 0.5470 - 24s/epoch - 45ms/step
Epoch 4/50
538/538 - 23s - loss: 2.8429 - accuracy50: 0.5445 - val_loss: 3.1009 - val_accuracy50: 0.5716 - 23s/epoch - 43ms/step
Epoch 5/50
538/538 - 25s - loss: 2.7931 - accuracy50: 0.5593 - val_loss: 3.0337 - val_accuracy50: 0.5773 - 25s/epoch - 46ms/step
Epoch 6/50
538/538 - 24s - loss: 2.7444 - accuracy50: 0.5709 - val_loss: 3.0741 - val_accuracy50: 0.5691 - 24s/epoch - 45ms/step
Epoch 7/50
538/538 - 24s - loss: 2.7185 - accuracy50: 0.5771 - val_loss: 3.0759 - val_accuracy50: 0.5959 - 24s/epoch - 44ms/step
Epoch 8/50
538/538 - 24s - loss: 2.6940 - accuracy50: 0.5829 - val_loss: 3.0035 - val_accuracy50: 0.5871 - 24s/epoch - 45ms/step
Epoch 9/50
538/538 - 23s - loss: 2.6786 - accuracy50: 0.5852 - val_loss: 2.9776 - val_accuracy50: 0.5865 - 23s/epoch - 43ms/step
Epoch 10/50
538/538 - 22s - loss: 2.6613 - accuracy50: 0.5879 - val_loss: 2.9790 - val_accuracy50: 0.5959 - 22s/epoch - 41ms/step
Epoch 11/50
538/538 - 22s - loss: 2.6498 - accuracy50: 0.5891 - val_loss: 2.9798 - val_accuracy50: 0.5980 - 22s/epoch - 40ms/step
Epoch 12/50
538/538 - 23s - loss: 2.6370 - accuracy50: 0.5911 - val_loss: 3.0172 - val_accuracy50: 0.5938 - 23s/epoch - 43ms/step
Epoch 13/50
538/538 - 23s - loss: 2.6241 - accuracy50: 0.5938 - val_loss: 2.9608 - val_accuracy50: 0.5871 - 23s/epoch - 43ms/step
Epoch 14/50
538/538 - 23s - loss: 2.6066 - accuracy50: 0.5973 - val_loss: 2.9785 - val_accuracy50: 0.5901 - 23s/epoch - 42ms/step
Epoch 15/50
538/538 - 22s - loss: 2.5958 - accuracy50: 0.5996 - val_loss: 2.9727 - val_accuracy50: 0.5883 - 22s/epoch - 41ms/step
Epoch 16/50
538/538 - 23s - loss: 2.5801 - accuracy50: 0.6029 - val_loss: 2.9787 - val_accuracy50: 0.5815 - 23s/epoch - 42ms/step
Epoch 17/50
538/538 - 22s - loss: 2.5690 - accuracy50: 0.6044 - val_loss: 3.0074 - val_accuracy50: 0.5858 - 22s/epoch - 41ms/step
Epoch 18/50
538/538 - 22s - loss: 2.5541 - accuracy50: 0.6064 - val_loss: 2.9916 - val_accuracy50: 0.5888 - 22s/epoch - 40ms/step
Epoch 19/50
538/538 - 23s - loss: 2.5416 - accuracy50: 0.6088 - val_loss: 3.0216 - val_accuracy50: 0.5828 - 23s/epoch - 43ms/step
Epoch 20/50
538/538 - 22s - loss: 2.5325 - accuracy50: 0.6107 - val_loss: 3.0337 - val_accuracy50: 0.5908 - 22s/epoch - 41ms/step
Epoch 21/50
538/538 - 22s - loss: 2.5277 - accuracy50: 0.6107 - val_loss: 3.0418 - val_accuracy50: 0.5793 - 22s/epoch - 41ms/step
Epoch 22/50
538/538 - 22s - loss: 2.5063 - accuracy50: 0.6140 - val_loss: 3.0768 - val_accuracy50: 0.5866 - 22s/epoch - 41ms/step
Epoch 23/50
538/538 - 23s - loss: 2.4954 - accuracy50: 0.6144 - val_loss: 3.0856 - val_accuracy50: 0.5859 - 23s/epoch - 43ms/step
testing model: results/QRTEA/W7/deepVOL_L3/h50
Evaluating performance on  test set...
2006/2006 - 43s - 43s/epoch - 21ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.885319
{'0': {'precision': 0.43714152104826165, 'recall': 0.415751447709986, 'f1-score': 0.4261782589075955, 'support': 110174}, '1': {'precision': 0.6913125805715314, 'recall': 0.7249841543835044, 'f1-score': 0.7077481071171735, 'support': 296612}, '2': {'precision': 0.4536660922369933, 'recall': 0.4151054963207689, 'f1-score': 0.4335300345043915, 'support': 106544}, 'accuracy': 0.5942980149221748, 'macro avg': {'precision': 0.5273733979522621, 'recall': 0.5186136994714198, 'f1-score': 0.5224854668430535, 'support': 513330}, 'weighted avg': {'precision': 0.5874362246892885, 'recall': 0.5942980149221748, 'f1-score': 0.5904006565783422, 'support': 513330}}
[[ 45805  48136  16233]
 [ 44545 215039  37028]
 [ 14433  47884  44227]]
Evaluating performance on  train set...
538/538 - 12s - 12s/epoch - 22ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.84848213
{'0': {'precision': 0.4903159680497632, 'recall': 0.45661905075373577, 'f1-score': 0.4728679528256868, 'support': 30382}, '1': {'precision': 0.7152970259944565, 'recall': 0.7330245531430326, 'f1-score': 0.7240522966679516, 'support': 78157}, '2': {'precision': 0.4604960719064119, 'recall': 0.462893992689151, 'f1-score': 0.46169191875763155, 'support': 28998}, 'accuracy': 0.6150126874950014, 'macro avg': {'precision': 0.5553696886502105, 'recall': 0.5508458655286398, 'f1-score': 0.5528707227504234, 'support': 137537}, 'weighted avg': {'precision': 0.6118769094503935, 'recall': 0.6150126874950014, 'f1-score': 0.6132500472859005, 'support': 137537}}
[[13873 11793  4716]
 [ 9856 57291 11010]
 [ 4565 11010 13423]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 22ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.8881738
{'0': {'precision': 0.4599758648431215, 'recall': 0.5018102029621503, 'f1-score': 0.47998321003200584, 'support': 9115}, '1': {'precision': 0.6704426550202448, 'recall': 0.7102853287063814, 'f1-score': 0.6897891361838564, 'support': 20748}, '2': {'precision': 0.5096140350877193, 'recall': 0.3952323935996517, 'f1-score': 0.4451937224129475, 'support': 9187}, 'accuracy': 0.5875032010243277, 'macro avg': {'precision': 0.5466775183170286, 'recall': 0.5357759750893943, 'f1-score': 0.5383220228762698, 'support': 39050}, 'weighted avg': {'precision': 0.5834788311077073, 'recall': 0.5875032010243277, 'f1-score': 0.5832723862942929, 'support': 39050}}
[[ 4574  3499  1042]
 [ 3559 14737  2452]
 [ 1811  3745  3631]]
training model: results/QRTEA/W7/deepVOL_L3/h100
Epoch 1/50
538/538 - 27s - loss: 3.3333 - accuracy100: 0.3672 - val_loss: 3.5296 - val_accuracy100: 0.3791 - 27s/epoch - 50ms/step
Epoch 2/50
538/538 - 24s - loss: 3.3091 - accuracy100: 0.3562 - val_loss: 3.3044 - val_accuracy100: 0.3962 - 24s/epoch - 44ms/step
Epoch 3/50
538/538 - 23s - loss: 3.2233 - accuracy100: 0.4029 - val_loss: 3.2387 - val_accuracy100: 0.4244 - 23s/epoch - 43ms/step
Epoch 4/50
538/538 - 23s - loss: 3.1132 - accuracy100: 0.4544 - val_loss: 3.2529 - val_accuracy100: 0.4344 - 23s/epoch - 42ms/step
Epoch 5/50
538/538 - 23s - loss: 3.0599 - accuracy100: 0.4719 - val_loss: 3.2888 - val_accuracy100: 0.4415 - 23s/epoch - 43ms/step
Epoch 6/50
538/538 - 22s - loss: 3.0294 - accuracy100: 0.4837 - val_loss: 3.2337 - val_accuracy100: 0.4465 - 22s/epoch - 42ms/step
Epoch 7/50
538/538 - 22s - loss: 2.9962 - accuracy100: 0.4959 - val_loss: 3.2996 - val_accuracy100: 0.4493 - 22s/epoch - 41ms/step
Epoch 8/50
538/538 - 22s - loss: 2.9791 - accuracy100: 0.5038 - val_loss: 3.2802 - val_accuracy100: 0.4524 - 22s/epoch - 41ms/step
Epoch 9/50
538/538 - 23s - loss: 2.9543 - accuracy100: 0.5109 - val_loss: 3.2526 - val_accuracy100: 0.4540 - 23s/epoch - 43ms/step
Epoch 10/50
538/538 - 22s - loss: 2.9357 - accuracy100: 0.5135 - val_loss: 3.2813 - val_accuracy100: 0.4543 - 22s/epoch - 41ms/step
Epoch 11/50
538/538 - 22s - loss: 2.9186 - accuracy100: 0.5195 - val_loss: 3.2964 - val_accuracy100: 0.4598 - 22s/epoch - 41ms/step
Epoch 12/50
538/538 - 23s - loss: 2.9002 - accuracy100: 0.5238 - val_loss: 3.2726 - val_accuracy100: 0.4608 - 23s/epoch - 42ms/step
Epoch 13/50
538/538 - 23s - loss: 2.8776 - accuracy100: 0.5292 - val_loss: 3.2785 - val_accuracy100: 0.4557 - 23s/epoch - 42ms/step
Epoch 14/50
538/538 - 22s - loss: 2.8615 - accuracy100: 0.5315 - val_loss: 3.2752 - val_accuracy100: 0.4600 - 22s/epoch - 41ms/step
Epoch 15/50
538/538 - 23s - loss: 2.8508 - accuracy100: 0.5339 - val_loss: 3.2926 - val_accuracy100: 0.4588 - 23s/epoch - 43ms/step
Epoch 16/50
538/538 - 23s - loss: 2.8347 - accuracy100: 0.5378 - val_loss: 3.2838 - val_accuracy100: 0.4588 - 23s/epoch - 42ms/step
testing model: results/QRTEA/W7/deepVOL_L3/h100
Evaluating performance on  test set...
2006/2006 - 42s - 42s/epoch - 21ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0342194
{'0': {'precision': 0.44839505060854096, 'recall': 0.2580356737914904, 'f1-score': 0.32756762981057896, 'support': 154343}, '1': {'precision': 0.49008274539397156, 'recall': 0.7046151222123781, 'f1-score': 0.5780871011878849, 'support': 211067}, '2': {'precision': 0.3979595208591491, 'recall': 0.3256692806922661, 'f1-score': 0.3582035171208685, 'support': 147920}, 'accuracy': 0.46114585159643895, 'macro avg': {'precision': 0.4454791056205539, 'recall': 0.42944002556537814, 'f1-score': 0.42128608270644413, 'support': 513330}, 'weighted avg': {'precision': 0.45100248269851506, 'recall': 0.46114585159643895, 'f1-score': 0.43940222688484276, 'support': 513330}}
[[ 39826  76906  37611]
 [ 27080 148721  35266]
 [ 21913  77834  48173]]
Evaluating performance on  train set...
538/538 - 12s - 12s/epoch - 22ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0090984
{'0': {'precision': 0.4899139149428241, 'recall': 0.2749032707697484, 'f1-score': 0.35218596059113305, 'support': 41611}, '1': {'precision': 0.507117025222552, 'recall': 0.770354979574588, 'f1-score': 0.611614382374322, 'support': 56792}, '2': {'precision': 0.4321536036681473, 'recall': 0.30827413502325346, 'f1-score': 0.35985085756897833, 'support': 39134}, 'accuracy': 0.48898114689138195, 'macro avg': {'precision': 0.47639484794450776, 'recall': 0.4511774617891966, 'f1-score': 0.44121706684481116, 'support': 137537}, 'weighted avg': {'precision': 0.48058265875418466, 'recall': 0.48898114689138195, 'f1-score': 0.4614904896141731, 'support': 137537}}
[[11439 21924  8248]
 [ 5438 43750  7604]
 [ 6472 20598 12064]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 22ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0361598
{'0': {'precision': 0.4550548680831193, 'recall': 0.3222020168622913, 'f1-score': 0.3772744870305845, 'support': 12098}, '1': {'precision': 0.45777109233287616, 'recall': 0.7045965270684372, 'f1-score': 0.554977472645355, 'support': 14685}, '2': {'precision': 0.410607790889481, 'recall': 0.2637971794244722, 'f1-score': 0.32122295016875124, 'support': 12267}, 'accuracy': 0.4476568501920615, 'macro avg': {'precision': 0.44114458376849214, 'recall': 0.4301985744517336, 'f1-score': 0.4178249699482303, 'support': 39050}, 'weighted avg': {'precision': 0.44211390667910694, 'recall': 0.4476568501920615, 'f1-score': 0.42649303097600827, 'support': 39050}}
[[ 3898  5907  2293]
 [ 1986 10347  2352]
 [ 2682  6349  3236]]
training model: results/QRTEA/W7/deepVOL_L3/h200
Epoch 1/50
538/538 - 28s - loss: 3.3273 - accuracy200: 0.3644 - val_loss: 3.4144 - val_accuracy200: 0.3265 - 28s/epoch - 51ms/step
Epoch 2/50
538/538 - 24s - loss: 3.3080 - accuracy200: 0.3611 - val_loss: 3.3501 - val_accuracy200: 0.3177 - 24s/epoch - 44ms/step
Epoch 3/50
538/538 - 24s - loss: 3.2959 - accuracy200: 0.3586 - val_loss: 3.3134 - val_accuracy200: 0.3395 - 24s/epoch - 45ms/step
Epoch 4/50
538/538 - 23s - loss: 3.2759 - accuracy200: 0.3757 - val_loss: 3.3006 - val_accuracy200: 0.3496 - 23s/epoch - 43ms/step
Epoch 5/50
538/538 - 24s - loss: 3.2565 - accuracy200: 0.3857 - val_loss: 3.2871 - val_accuracy200: 0.3549 - 24s/epoch - 45ms/step
Epoch 6/50
538/538 - 26s - loss: 3.2326 - accuracy200: 0.4026 - val_loss: 3.3095 - val_accuracy200: 0.3525 - 26s/epoch - 48ms/step
Epoch 7/50
538/538 - 23s - loss: 3.1973 - accuracy200: 0.4179 - val_loss: 3.2454 - val_accuracy200: 0.3812 - 23s/epoch - 42ms/step
Epoch 8/50
538/538 - 24s - loss: 3.1727 - accuracy200: 0.4270 - val_loss: 3.2480 - val_accuracy200: 0.3844 - 24s/epoch - 44ms/step
Epoch 9/50
538/538 - 24s - loss: 3.1532 - accuracy200: 0.4363 - val_loss: 3.2569 - val_accuracy200: 0.3794 - 24s/epoch - 45ms/step
Epoch 10/50
538/538 - 23s - loss: 3.1369 - accuracy200: 0.4406 - val_loss: 3.2522 - val_accuracy200: 0.3846 - 23s/epoch - 43ms/step
Epoch 11/50
538/538 - 23s - loss: 3.1210 - accuracy200: 0.4477 - val_loss: 3.2461 - val_accuracy200: 0.3836 - 23s/epoch - 43ms/step
Epoch 12/50
538/538 - 24s - loss: 3.1066 - accuracy200: 0.4529 - val_loss: 3.2644 - val_accuracy200: 0.3826 - 24s/epoch - 44ms/step
Epoch 13/50
538/538 - 24s - loss: 3.1000 - accuracy200: 0.4540 - val_loss: 3.2708 - val_accuracy200: 0.3820 - 24s/epoch - 44ms/step
Epoch 14/50
538/538 - 22s - loss: 3.0833 - accuracy200: 0.4617 - val_loss: 3.2776 - val_accuracy200: 0.3798 - 22s/epoch - 41ms/step
Epoch 15/50
538/538 - 23s - loss: 3.0715 - accuracy200: 0.4634 - val_loss: 3.2857 - val_accuracy200: 0.3777 - 23s/epoch - 42ms/step
Epoch 16/50
538/538 - 22s - loss: 3.0578 - accuracy200: 0.4686 - val_loss: 3.2891 - val_accuracy200: 0.3778 - 22s/epoch - 41ms/step
Epoch 17/50
538/538 - 22s - loss: 3.0452 - accuracy200: 0.4735 - val_loss: 3.2835 - val_accuracy200: 0.3896 - 22s/epoch - 41ms/step
testing model: results/QRTEA/W7/deepVOL_L3/h200
Evaluating performance on  test set...
2006/2006 - 42s - 42s/epoch - 21ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0869913
{'0': {'precision': 0.4026372023390616, 'recall': 0.35500612050340435, 'f1-score': 0.3773244397811587, 'support': 177273}, '1': {'precision': 0.36461807905106874, 'recall': 0.5503102903452544, 'f1-score': 0.4386203065932146, 'support': 166457}, '2': {'precision': 0.38334373050530257, 'recall': 0.23913325471698113, 'f1-score': 0.29453372936622635, 'support': 169600}, 'accuracy': 0.3800537665828999, 'macro avg': {'precision': 0.3835330039651443, 'recall': 0.3814832218552133, 'f1-score': 0.3701594919135332, 'support': 513330}, 'weighted avg': {'precision': 0.38393437564248245, 'recall': 0.3800537665828999, 'f1-score': 0.36984742035030893, 'support': 513330}}
[[62933 76197 38143]
 [47756 91603 27098]
 [45613 83430 40557]]
Evaluating performance on  train set...
538/538 - 11s - 11s/epoch - 21ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.07288
{'0': {'precision': 0.4491372444916379, 'recall': 0.34840715800745453, 'f1-score': 0.3924110818615115, 'support': 48561}, '1': {'precision': 0.37499831887566404, 'recall': 0.6352638293994349, 'f1-score': 0.4716060449736569, 'support': 43892}, '2': {'precision': 0.40831765443712764, 'recall': 0.23105758140360216, 'f1-score': 0.2951158705875687, 'support': 45084}, 'accuracy': 0.4014846913921345, 'macro avg': {'precision': 0.4108177392681432, 'recall': 0.4049095229368305, 'f1-score': 0.38637766580757904, 'support': 137537}, 'weighted avg': {'precision': 0.41209691264527026, 'recall': 0.4014846913921345, 'f1-score': 0.385791539599021, 'support': 137537}}
[[16919 22518  9124]
 [10038 27883  5971]
 [10713 23954 10417]]
Evaluating performance on  val set...
153/153 - 4s - 4s/epoch - 23ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0829864
{'0': {'precision': 0.4035940977660539, 'recall': 0.3665768194070081, 'f1-score': 0.3841958645584024, 'support': 13356}, '1': {'precision': 0.3520945909796159, 'recall': 0.5543295148247979, 'f1-score': 0.43065144128521415, 'support': 11872}, '2': {'precision': 0.40094798249878466, 'recall': 0.23867747069888584, 'f1-score': 0.29922902494331066, 'support': 13822}, 'accuracy': 0.3783866837387964, 'macro avg': {'precision': 0.3855455570814848, 'recall': 0.3865279349768973, 'f1-score': 0.37135877692897573, 'support': 39050}, 'weighted avg': {'precision': 0.38700058304664836, 'recall': 0.3783866837387964, 'f1-score': 0.36824474931489176, 'support': 39050}}
[[4896 5527 2933]
 [3295 6581 1996]
 [3940 6583 3299]]
training model: results/QRTEA/W7/deepVOL_L3/h300
Epoch 1/50
538/538 - 27s - loss: 3.3369 - accuracy300: 0.3481 - val_loss: 3.3306 - val_accuracy300: 0.3354 - 27s/epoch - 49ms/step
Epoch 2/50
538/538 - 24s - loss: 3.2996 - accuracy300: 0.3531 - val_loss: 3.3009 - val_accuracy300: 0.3489 - 24s/epoch - 44ms/step
Epoch 3/50
538/538 - 24s - loss: 3.2881 - accuracy300: 0.3641 - val_loss: 3.3008 - val_accuracy300: 0.3506 - 24s/epoch - 44ms/step
Epoch 4/50
538/538 - 24s - loss: 3.2761 - accuracy300: 0.3725 - val_loss: 3.2958 - val_accuracy300: 0.3576 - 24s/epoch - 44ms/step
Epoch 5/50
538/538 - 23s - loss: 3.2642 - accuracy300: 0.3848 - val_loss: 3.3057 - val_accuracy300: 0.3511 - 23s/epoch - 44ms/step
Epoch 6/50
538/538 - 23s - loss: 3.2535 - accuracy300: 0.3904 - val_loss: 3.2974 - val_accuracy300: 0.3642 - 23s/epoch - 43ms/step
Epoch 7/50
538/538 - 23s - loss: 3.2324 - accuracy300: 0.4053 - val_loss: 3.3060 - val_accuracy300: 0.3585 - 23s/epoch - 43ms/step
Epoch 8/50
538/538 - 23s - loss: 3.2141 - accuracy300: 0.4150 - val_loss: 3.3220 - val_accuracy300: 0.3597 - 23s/epoch - 43ms/step
Epoch 9/50
538/538 - 23s - loss: 3.2097 - accuracy300: 0.4183 - val_loss: 3.3276 - val_accuracy300: 0.3592 - 23s/epoch - 43ms/step
Epoch 10/50
538/538 - 23s - loss: 3.1989 - accuracy300: 0.4218 - val_loss: 3.3227 - val_accuracy300: 0.3554 - 23s/epoch - 43ms/step
Epoch 11/50
538/538 - 23s - loss: 3.1757 - accuracy300: 0.4319 - val_loss: 3.3654 - val_accuracy300: 0.3548 - 23s/epoch - 42ms/step
Epoch 12/50
538/538 - 24s - loss: 3.1501 - accuracy300: 0.4461 - val_loss: 3.3775 - val_accuracy300: 0.3633 - 24s/epoch - 44ms/step
Epoch 13/50
538/538 - 24s - loss: 3.1197 - accuracy300: 0.4554 - val_loss: 3.4277 - val_accuracy300: 0.3510 - 24s/epoch - 44ms/step
Epoch 14/50
538/538 - 23s - loss: 3.0928 - accuracy300: 0.4673 - val_loss: 3.4842 - val_accuracy300: 0.3483 - 23s/epoch - 43ms/step
testing model: results/QRTEA/W7/deepVOL_L3/h300
Evaluating performance on  test set...
2006/2006 - 45s - 45s/epoch - 22ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0976778
{'0': {'precision': 0.34775639863360436, 'recall': 0.27946216254021544, 'f1-score': 0.3098911965151863, 'support': 171576}, '1': {'precision': 0.37988950613982136, 'recall': 0.28036250028196974, 'f1-score': 0.3226246061695507, 'support': 177324}, '2': {'precision': 0.3387575537038703, 'recall': 0.5038861521620143, 'f1-score': 0.40514214741865767, 'support': 164430}, 'accuracy': 0.3516607250696433, 'macro avg': {'precision': 0.35546781949243195, 'recall': 0.35457027166139987, 'f1-score': 0.34588598336779824, 'support': 513330}, 'weighted avg': {'precision': 0.35597390215694463, 'recall': 0.3516607250696433, 'f1-score': 0.3448006173372858, 'support': 513330}}
[[47949 43751 79876]
 [45757 49715 81852]
 [44175 37401 82854]]
Evaluating performance on  train set...
538/538 - 12s - 12s/epoch - 23ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0883831
{'0': {'precision': 0.38251840325573044, 'recall': 0.2730243485689876, 'f1-score': 0.318627084423839, 'support': 46820}, '1': {'precision': 0.4101270227945015, 'recall': 0.3460796241137727, 'f1-score': 0.37539105605041917, 'support': 47674}, '2': {'precision': 0.3606354672092659, 'recall': 0.5353019073949307, 'f1-score': 0.43094273984644593, 'support': 43043}, 'accuracy': 0.3804285392294437, 'macro avg': {'precision': 0.3844269644198326, 'recall': 0.38480196002589695, 'f1-score': 0.37498696010690136, 'support': 137537}, 'weighted avg': {'precision': 0.3852398971929502, 'recall': 0.3804285392294437, 'f1-score': 0.37345282833043036, 'support': 137537}}
[[12783 13608 20429]
 [10755 16499 20420]
 [ 9880 10122 23041]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 20ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0967077
{'0': {'precision': 0.3358486961505397, 'recall': 0.2792249047013977, 'f1-score': 0.3049304019773644, 'support': 12592}, '1': {'precision': 0.37909955365806325, 'recall': 0.29360486961749455, 'f1-score': 0.3309194088002372, 'support': 13307}, '2': {'precision': 0.35545827633378935, 'recall': 0.49395483233214205, 'f1-score': 0.4134156430980717, 'support': 13151}, 'accuracy': 0.3564404609475032, 'macro avg': {'precision': 0.35680217538079745, 'recall': 0.3555948688836781, 'f1-score': 0.3497551512918911, 'support': 39050}, 'weighted avg': {'precision': 0.3571911993475316, 'recall': 0.3564404609475032, 'f1-score': 0.35032157021732313, 'support': 39050}}
[[3516 3332 5744]
 [3365 3907 6035]
 [3588 3067 6496]]
training model: results/QRTEA/W7/deepVOL_L3/h500
Epoch 1/50
538/538 - 26s - loss: 3.3057 - accuracy500: 0.3710 - val_loss: 3.3375 - val_accuracy500: 0.3277 - 26s/epoch - 48ms/step
Epoch 2/50
538/538 - 24s - loss: 3.2849 - accuracy500: 0.3620 - val_loss: 3.3691 - val_accuracy500: 0.2982 - 24s/epoch - 44ms/step
Epoch 3/50
538/538 - 23s - loss: 3.2922 - accuracy500: 0.3528 - val_loss: 3.3536 - val_accuracy500: 0.3046 - 23s/epoch - 42ms/step
Epoch 4/50
538/538 - 23s - loss: 3.2877 - accuracy500: 0.3655 - val_loss: 3.3327 - val_accuracy500: 0.3113 - 23s/epoch - 42ms/step
Epoch 5/50
538/538 - 23s - loss: 3.2819 - accuracy500: 0.3730 - val_loss: 3.3349 - val_accuracy500: 0.3109 - 23s/epoch - 42ms/step
Epoch 6/50
538/538 - 22s - loss: 3.2753 - accuracy500: 0.3777 - val_loss: 3.3464 - val_accuracy500: 0.3055 - 22s/epoch - 42ms/step
Epoch 7/50
538/538 - 22s - loss: 3.2618 - accuracy500: 0.3900 - val_loss: 3.3540 - val_accuracy500: 0.3142 - 22s/epoch - 41ms/step
Epoch 8/50
538/538 - 23s - loss: 3.2535 - accuracy500: 0.3951 - val_loss: 3.3672 - val_accuracy500: 0.3122 - 23s/epoch - 42ms/step
Epoch 9/50
538/538 - 24s - loss: 3.2392 - accuracy500: 0.4015 - val_loss: 3.3872 - val_accuracy500: 0.3132 - 24s/epoch - 44ms/step
Epoch 10/50
538/538 - 23s - loss: 3.2180 - accuracy500: 0.4144 - val_loss: 3.4198 - val_accuracy500: 0.3138 - 23s/epoch - 44ms/step
Epoch 11/50
538/538 - 24s - loss: 3.2035 - accuracy500: 0.4224 - val_loss: 3.4615 - val_accuracy500: 0.3078 - 24s/epoch - 44ms/step
Epoch 12/50
538/538 - 24s - loss: 3.1768 - accuracy500: 0.4354 - val_loss: 3.4405 - val_accuracy500: 0.3201 - 24s/epoch - 44ms/step
Epoch 13/50
538/538 - 23s - loss: 3.1553 - accuracy500: 0.4483 - val_loss: 3.5104 - val_accuracy500: 0.3210 - 23s/epoch - 43ms/step
Epoch 14/50
538/538 - 24s - loss: 3.1519 - accuracy500: 0.4508 - val_loss: 3.4854 - val_accuracy500: 0.3216 - 24s/epoch - 44ms/step
testing model: results/QRTEA/W7/deepVOL_L3/h500
Evaluating performance on  test set...
2006/2006 - 43s - 43s/epoch - 21ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.097301
{'0': {'precision': 0.3708429503646165, 'recall': 0.5224257874951389, 'f1-score': 0.4337729782091011, 'support': 185144}, '1': {'precision': 0.28869448183041724, 'recall': 0.0028583992963940193, 'f1-score': 0.005660750808207429, 'support': 150084}, '2': {'precision': 0.35721968592394293, 'recall': 0.5034755364903257, 'f1-score': 0.4179211603172976, 'support': 178102}, 'accuracy': 0.36394327235891144, 'macro avg': {'precision': 0.3389190393729922, 'recall': 0.34291990776061954, 'f1-score': 0.2857849631115354, 'support': 513330}, 'weighted avg': {'precision': 0.3420982804740985, 'recall': 0.36394327235891144, 'f1-score': 0.30310452710084385, 'support': 513330}}
[[96724   533 87887]
 [76190   429 73465]
 [87908   524 89670]]
Evaluating performance on  train set...
538/538 - 12s - 12s/epoch - 22ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0947971
{'0': {'precision': 0.3866952542665554, 'recall': 0.5528741307657491, 'f1-score': 0.45508890770533444, 'support': 48606}, '1': {'precision': 0.34096109839816935, 'recall': 0.0033426808749298935, 'f1-score': 0.006620456767084334, 'support': 44575}, '2': {'precision': 0.3458272934354939, 'recall': 0.5270989268644602, 'f1-score': 0.4176416998624533, 'support': 44356}, 'accuracy': 0.3664613885718025, 'macro avg': {'precision': 0.3578278820334062, 'recall': 0.36110524616837975, 'f1-score': 0.2931170214449574, 'support': 137537}, 'weighted avg': {'precision': 0.3586930492711296, 'recall': 0.3664613885718025, 'f1-score': 0.2976658902507489, 'support': 137537}}
[[26873   140 21593]
 [21793   149 22633]
 [20828   148 23380]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 21ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1043744
{'0': {'precision': 0.29591249280368453, 'recall': 0.5336101738904749, 'f1-score': 0.38070549023238587, 'support': 11559}, '1': {'precision': 0.38345864661654133, 'recall': 0.003291171915332989, 'f1-score': 0.006526329259709513, 'support': 15496}, '2': {'precision': 0.3235212748298567, 'recall': 0.4874531054606086, 'f1-score': 0.3889184515099109, 'support': 11995}, 'accuracy': 0.30898847631242, 'macro avg': {'precision': 0.3342974714166942, 'recall': 0.34145148375547213, 'f1-score': 0.25871675700066876, 'support': 39050}, 'weighted avg': {'precision': 0.3391335565652201, 'recall': 0.30898847631242, 'f1-score': 0.23474477812204833, 'support': 39050}}
[[6168   41 5350]
 [8569   51 6876]
 [6107   41 5847]]
training model: results/QRTEA/W7/deepVOL_L3/h1000
Epoch 1/50
538/538 - 26s - loss: 3.2791 - accuracy1000: 0.3940 - val_loss: 3.4558 - val_accuracy1000: 0.3339 - 26s/epoch - 48ms/step
Epoch 2/50
538/538 - 23s - loss: 3.2832 - accuracy1000: 0.3729 - val_loss: 3.4283 - val_accuracy1000: 0.3376 - 23s/epoch - 42ms/step
Epoch 3/50
538/538 - 22s - loss: 3.2812 - accuracy1000: 0.3712 - val_loss: 3.4084 - val_accuracy1000: 0.3344 - 22s/epoch - 41ms/step
Epoch 4/50
538/538 - 23s - loss: 3.2766 - accuracy1000: 0.3733 - val_loss: 3.4301 - val_accuracy1000: 0.3317 - 23s/epoch - 42ms/step
Epoch 5/50
538/538 - 23s - loss: 3.2725 - accuracy1000: 0.3810 - val_loss: 3.4045 - val_accuracy1000: 0.3342 - 23s/epoch - 42ms/step
Epoch 6/50
538/538 - 22s - loss: 3.2678 - accuracy1000: 0.3793 - val_loss: 3.4114 - val_accuracy1000: 0.3285 - 22s/epoch - 41ms/step
Epoch 7/50
538/538 - 22s - loss: 3.2464 - accuracy1000: 0.3920 - val_loss: 3.4377 - val_accuracy1000: 0.3270 - 22s/epoch - 41ms/step
Epoch 8/50
538/538 - 22s - loss: 3.2617 - accuracy1000: 0.3801 - val_loss: 3.4209 - val_accuracy1000: 0.3318 - 22s/epoch - 41ms/step
Epoch 9/50
538/538 - 22s - loss: 3.2656 - accuracy1000: 0.3762 - val_loss: 3.4207 - val_accuracy1000: 0.3372 - 22s/epoch - 41ms/step
Epoch 10/50
538/538 - 22s - loss: 3.2499 - accuracy1000: 0.3836 - val_loss: 3.4728 - val_accuracy1000: 0.3412 - 22s/epoch - 41ms/step
Epoch 11/50
538/538 - 23s - loss: 3.2495 - accuracy1000: 0.3790 - val_loss: 3.4355 - val_accuracy1000: 0.3299 - 23s/epoch - 43ms/step
Epoch 12/50
538/538 - 23s - loss: 3.2481 - accuracy1000: 0.3859 - val_loss: 3.4146 - val_accuracy1000: 0.3549 - 23s/epoch - 42ms/step
Epoch 13/50
538/538 - 22s - loss: 3.2238 - accuracy1000: 0.3948 - val_loss: 3.4195 - val_accuracy1000: 0.3590 - 22s/epoch - 41ms/step
Epoch 14/50
538/538 - 23s - loss: 3.2196 - accuracy1000: 0.3990 - val_loss: 3.4259 - val_accuracy1000: 0.3558 - 23s/epoch - 42ms/step
Epoch 15/50
538/538 - 23s - loss: 3.2225 - accuracy1000: 0.3967 - val_loss: 3.4334 - val_accuracy1000: 0.3546 - 23s/epoch - 42ms/step
testing model: results/QRTEA/W7/deepVOL_L3/h1000
Evaluating performance on  test set...
2006/2006 - 44s - 44s/epoch - 22ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0745263
{'0': {'precision': 0.3893498102758691, 'recall': 0.3736504374698594, 'f1-score': 0.3813386099629866, 'support': 203214}, '1': {'precision': 0.21142713314875408, 'recall': 0.00728629049746281, 'f1-score': 0.014087105267571148, 'support': 115285}, '2': {'precision': 0.3713784886920725, 'recall': 0.5991756958594885, 'f1-score': 0.45854413474531, 'support': 194831}, 'accuracy': 0.37696803225994974, 'macro avg': {'precision': 0.3240518107055652, 'recall': 0.32670414127560354, 'f1-score': 0.2846566166586226, 'support': 513330}, 'weighted avg': {'precision': 0.34257057199232416, 'recall': 0.37696803225994974, 'f1-score': 0.32816314755099796, 'support': 513330}}
[[ 75931   1568 125715]
 [ 42561    840  71884]
 [ 76528   1565 116738]]
Evaluating performance on  train set...
538/538 - 12s - 12s/epoch - 23ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1050119
{'0': {'precision': 0.4032051282051282, 'recall': 0.4005651853768234, 'f1-score': 0.40188082141181397, 'support': 50249}, '1': {'precision': 0.20227272727272727, 'recall': 0.004186462204242909, 'f1-score': 0.00820314300198166, 'support': 42518}, '2': {'precision': 0.32167356491462695, 'recall': 0.6232075050256869, 'f1-score': 0.42432722212505797, 'support': 44770}, 'accuracy': 0.350502046721973, 'macro avg': {'precision': 0.3090504734641608, 'recall': 0.3426530508689177, 'f1-score': 0.27813706217961787, 'support': 137537}, 'weighted avg': {'precision': 0.3145496252396748, 'recall': 0.350502046721973, 'f1-score': 0.28748642448082584, 'support': 137537}}
[[20128   413 29708]
 [13212   178 29128]
 [16580   289 27901]]
Evaluating performance on  val set...
153/153 - 3s - 3s/epoch - 22ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1181529
{'0': {'precision': 0.3354993983152828, 'recall': 0.43634087174270286, 'f1-score': 0.37933263036157694, 'support': 12779}, '1': {'precision': 0.29906542056074764, 'recall': 0.004923076923076923, 'f1-score': 0.00968669592856062, 'support': 13000}, '2': {'precision': 0.33079762333453366, 'recall': 0.5537638459799563, 'f1-score': 0.41417984050497364, 'support': 13271}, 'accuracy': 0.3326248399487836, 'macro avg': {'precision': 0.3217874807368547, 'recall': 0.3316759315485787, 'f1-score': 0.2677330555983704, 'support': 39050}, 'weighted avg': {'precision': 0.3217724081340157, 'recall': 0.3326248399487836, 'f1-score': 0.26811778217166155, 'support': 39050}}
[[5576   64 7139]
 [5208   64 7728]
 [5836   86 7349]]

============================================

        Job resource usage summary 

                 Memory (GB)    NCPUs
 Requested  :        96            32
 Used       :        17 (peak)  13.93 (ave)

============================================
