This machine has 1 visible gpus.
This machine has 1 physical gpus.
getting alphas...
data/ATVI_orderbooks/ATVI_orderbooks_2019-07-31.csv
data/ATVI_orderbooks/ATVI_orderbooks_2019-07-23.csv
data/ATVI_orderbooks/ATVI_orderbooks_2019-07-10.csv
data/ATVI_orderbooks/ATVI_orderbooks_2019-07-11.csv
data/ATVI_orderbooks/ATVI_orderbooks_2019-07-19.csv
data/ATVI_orderbooks/ATVI_orderbooks_2019-07-15.csv
data/ATVI_orderbooks/ATVI_orderbooks_2019-07-17.csv
data/ATVI_orderbooks/ATVI_orderbooks_2019-07-12.csv
data/ATVI_orderbooks/ATVI_orderbooks_2019-08-02.csv
data/ATVI_orderbooks/ATVI_orderbooks_2019-07-16.csv
data/ATVI_orderbooks/ATVI_orderbooks_2019-07-29.csv
data/ATVI_orderbooks/ATVI_orderbooks_2019-07-18.csv
data/ATVI_orderbooks/ATVI_orderbooks_2019-07-09.csv
data/ATVI_orderbooks/ATVI_orderbooks_2019-07-25.csv
data/ATVI_orderbooks/ATVI_orderbooks_2019-07-24.csv
training model: results/ATVI/W5/deepLOB_L1/h10
Epoch 1/50
1806/1806 - 63s - loss: 2.9833 - accuracy10: 0.4333 - val_loss: 3.4937 - val_accuracy10: 0.4267 - 63s/epoch - 35ms/step
Epoch 2/50
1806/1806 - 51s - loss: 2.8651 - accuracy10: 0.4672 - val_loss: 3.1975 - val_accuracy10: 0.5356 - 51s/epoch - 28ms/step
Epoch 3/50
1806/1806 - 49s - loss: 2.7981 - accuracy10: 0.5051 - val_loss: 3.1845 - val_accuracy10: 0.5389 - 49s/epoch - 27ms/step
Epoch 4/50
1806/1806 - 49s - loss: 2.7450 - accuracy10: 0.5295 - val_loss: 3.1207 - val_accuracy10: 0.5315 - 49s/epoch - 27ms/step
Epoch 5/50
1806/1806 - 51s - loss: 2.7098 - accuracy10: 0.5432 - val_loss: 3.1107 - val_accuracy10: 0.5474 - 51s/epoch - 28ms/step
Epoch 6/50
1806/1806 - 49s - loss: 2.6852 - accuracy10: 0.5499 - val_loss: 3.0758 - val_accuracy10: 0.5463 - 49s/epoch - 27ms/step
Epoch 7/50
1806/1806 - 50s - loss: 2.6689 - accuracy10: 0.5554 - val_loss: 3.0848 - val_accuracy10: 0.5462 - 50s/epoch - 28ms/step
Epoch 8/50
1806/1806 - 48s - loss: 2.6583 - accuracy10: 0.5589 - val_loss: 3.1120 - val_accuracy10: 0.5532 - 48s/epoch - 26ms/step
Epoch 9/50
1806/1806 - 48s - loss: 2.6470 - accuracy10: 0.5611 - val_loss: 3.1133 - val_accuracy10: 0.5660 - 48s/epoch - 27ms/step
Epoch 10/50
1806/1806 - 51s - loss: 2.6388 - accuracy10: 0.5616 - val_loss: 3.0660 - val_accuracy10: 0.5623 - 51s/epoch - 28ms/step
Epoch 11/50
1806/1806 - 52s - loss: 2.6307 - accuracy10: 0.5635 - val_loss: 3.1271 - val_accuracy10: 0.5693 - 52s/epoch - 29ms/step
Epoch 12/50
1806/1806 - 52s - loss: 2.6234 - accuracy10: 0.5651 - val_loss: 3.0919 - val_accuracy10: 0.5765 - 52s/epoch - 29ms/step
Epoch 13/50
1806/1806 - 53s - loss: 2.6174 - accuracy10: 0.5657 - val_loss: 3.1360 - val_accuracy10: 0.5596 - 53s/epoch - 29ms/step
Epoch 14/50
1806/1806 - 52s - loss: 2.6122 - accuracy10: 0.5666 - val_loss: 3.1913 - val_accuracy10: 0.5655 - 52s/epoch - 29ms/step
Epoch 15/50
1806/1806 - 51s - loss: 2.6060 - accuracy10: 0.5676 - val_loss: 3.1829 - val_accuracy10: 0.5469 - 51s/epoch - 28ms/step
Epoch 16/50
1806/1806 - 51s - loss: 2.6007 - accuracy10: 0.5684 - val_loss: 3.1867 - val_accuracy10: 0.5625 - 51s/epoch - 28ms/step
Epoch 17/50
1806/1806 - 46s - loss: 2.5969 - accuracy10: 0.5689 - val_loss: 3.2021 - val_accuracy10: 0.5747 - 46s/epoch - 25ms/step
Epoch 18/50
1806/1806 - 47s - loss: 2.5920 - accuracy10: 0.5699 - val_loss: 3.2165 - val_accuracy10: 0.5672 - 47s/epoch - 26ms/step
Epoch 19/50
1806/1806 - 47s - loss: 2.5882 - accuracy10: 0.5712 - val_loss: 3.2624 - val_accuracy10: 0.5548 - 47s/epoch - 26ms/step
Epoch 20/50
1806/1806 - 48s - loss: 2.5850 - accuracy10: 0.5717 - val_loss: 3.2548 - val_accuracy10: 0.5544 - 48s/epoch - 27ms/step
testing model: results/ATVI/W5/deepLOB_L1/h10
Evaluating performance on  test set...
8238/8238 - 128s - 128s/epoch - 16ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 1.0155147
{'0': {'precision': 0.43219818653121184, 'recall': 0.3916968948817776, 'f1-score': 0.4109520531363666, 'support': 526550}, '1': {'precision': 0.6304822421015551, 'recall': 0.5334655927706612, 'f1-score': 0.5779306820069073, 'support': 1053485}, '2': {'precision': 0.38979826489706526, 'recall': 0.5457016450435898, 'f1-score': 0.454759112489833, 'support': 528679}, 'accuracy': 0.501133392200175, 'macro avg': {'precision': 0.4841595645099441, 'recall': 0.4902880442320095, 'f1-score': 0.48121394921103566, 'support': 2108714}, 'weighted avg': {'precision': 0.5206280684938223, 'recall': 0.501133392200175, 'f1-score': 0.5053552548828399, 'support': 2108714}}
[[206248 177831 142471]
 [182330 561998 309157]
 [ 88629 151549 288501]]
Evaluating performance on  train set...
1806/1806 - 29s - 29s/epoch - 16ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.912798
{'0': {'precision': 0.4069216238371886, 'recall': 0.386641229991195, 'f1-score': 0.39652228274396983, 'support': 88586}, '1': {'precision': 0.7610720546003804, 'recall': 0.5723155127081507, 'f1-score': 0.6533334400525058, 'support': 285250}, '2': {'precision': 0.34914489136817384, 'recall': 0.6462463346428612, 'f1-score': 0.45335663085995676, 'support': 88327}, 'accuracy': 0.5508554341217277, 'macro avg': {'precision': 0.5057128566019143, 'recall': 0.5350676924474023, 'f1-score': 0.5010707845521442, 'support': 462163}, 'weighted avg': {'precision': 0.6144634757950689, 'recall': 0.5508554341217277, 'f1-score': 0.5658897788185164, 'support': 462163}}
[[ 34251  29341  24994]
 [ 40584 163253  81413]
 [  9336  21910  57081]]
Evaluating performance on  val set...
642/642 - 10s - 10s/epoch - 16ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.897356
{'0': {'precision': 0.43167751788441444, 'recall': 0.31918813705387655, 'f1-score': 0.36700664582372333, 'support': 33651}, '1': {'precision': 0.7196103593093793, 'recall': 0.6323553532619839, 'f1-score': 0.6731671650260821, 'support': 97548}, '2': {'precision': 0.3684475055845123, 'recall': 0.5975606074329016, 'f1-score': 0.455834091406331, 'support': 33123}, 'accuracy': 0.5612090894706734, 'macro avg': {'precision': 0.506578460926102, 'recall': 0.5163680325829206, 'f1-score': 0.49866930075204546, 'support': 164322}, 'weighted avg': {'precision': 0.5898602634566009, 'recall': 0.5612090894706734, 'f1-score': 0.5666608479828037, 'support': 164322}}
[[10741 13638  9272]
 [11208 61685 24655]
 [ 2933 10397 19793]]
training model: results/ATVI/W5/deepLOB_L1/h20
Epoch 1/50
1806/1806 - 54s - loss: 3.0469 - accuracy20: 0.4527 - val_loss: 3.7414 - val_accuracy20: 0.3633 - 54s/epoch - 30ms/step
Epoch 2/50
1806/1806 - 52s - loss: 2.9914 - accuracy20: 0.4549 - val_loss: 3.2586 - val_accuracy20: 0.4950 - 52s/epoch - 29ms/step
Epoch 3/50
1806/1806 - 50s - loss: 2.8943 - accuracy20: 0.5033 - val_loss: 3.2674 - val_accuracy20: 0.4944 - 50s/epoch - 27ms/step
Epoch 4/50
1806/1806 - 49s - loss: 2.8351 - accuracy20: 0.5265 - val_loss: 3.2869 - val_accuracy20: 0.4850 - 49s/epoch - 27ms/step
Epoch 5/50
1806/1806 - 48s - loss: 2.8024 - accuracy20: 0.5383 - val_loss: 3.3577 - val_accuracy20: 0.4579 - 48s/epoch - 27ms/step
Epoch 6/50
1806/1806 - 44s - loss: 2.7799 - accuracy20: 0.5445 - val_loss: 3.3210 - val_accuracy20: 0.4564 - 44s/epoch - 25ms/step
Epoch 7/50
1806/1806 - 46s - loss: 2.7641 - accuracy20: 0.5499 - val_loss: 3.3471 - val_accuracy20: 0.4622 - 46s/epoch - 26ms/step
Epoch 8/50
1806/1806 - 51s - loss: 2.7535 - accuracy20: 0.5523 - val_loss: 3.4536 - val_accuracy20: 0.4312 - 51s/epoch - 28ms/step
Epoch 9/50
1806/1806 - 51s - loss: 2.7436 - accuracy20: 0.5546 - val_loss: 3.3147 - val_accuracy20: 0.4798 - 51s/epoch - 28ms/step
Epoch 10/50
1806/1806 - 51s - loss: 2.7353 - accuracy20: 0.5567 - val_loss: 3.2974 - val_accuracy20: 0.4880 - 51s/epoch - 28ms/step
Epoch 11/50
1806/1806 - 49s - loss: 2.7280 - accuracy20: 0.5577 - val_loss: 3.2726 - val_accuracy20: 0.5029 - 49s/epoch - 27ms/step
Epoch 12/50
1806/1806 - 49s - loss: 2.7213 - accuracy20: 0.5599 - val_loss: 3.2366 - val_accuracy20: 0.5082 - 49s/epoch - 27ms/step
Epoch 13/50
1806/1806 - 51s - loss: 2.7155 - accuracy20: 0.5607 - val_loss: 3.2378 - val_accuracy20: 0.5066 - 51s/epoch - 28ms/step
Epoch 14/50
1806/1806 - 49s - loss: 2.7092 - accuracy20: 0.5622 - val_loss: 3.2322 - val_accuracy20: 0.5153 - 49s/epoch - 27ms/step
Epoch 15/50
1806/1806 - 54s - loss: 2.7034 - accuracy20: 0.5631 - val_loss: 3.1966 - val_accuracy20: 0.5265 - 54s/epoch - 30ms/step
Epoch 16/50
1806/1806 - 54s - loss: 2.6995 - accuracy20: 0.5631 - val_loss: 3.2063 - val_accuracy20: 0.5144 - 54s/epoch - 30ms/step
Epoch 17/50
1806/1806 - 55s - loss: 2.6938 - accuracy20: 0.5652 - val_loss: 3.1798 - val_accuracy20: 0.5251 - 55s/epoch - 30ms/step
Epoch 18/50
1806/1806 - 54s - loss: 2.6915 - accuracy20: 0.5649 - val_loss: 3.1648 - val_accuracy20: 0.5296 - 54s/epoch - 30ms/step
Epoch 19/50
1806/1806 - 54s - loss: 2.6852 - accuracy20: 0.5668 - val_loss: 3.1939 - val_accuracy20: 0.5291 - 54s/epoch - 30ms/step
Epoch 20/50
1806/1806 - 53s - loss: 2.6811 - accuracy20: 0.5674 - val_loss: 3.1538 - val_accuracy20: 0.5286 - 53s/epoch - 29ms/step
Epoch 21/50
1806/1806 - 52s - loss: 2.6787 - accuracy20: 0.5683 - val_loss: 3.1717 - val_accuracy20: 0.5293 - 52s/epoch - 29ms/step
Epoch 22/50
1806/1806 - 50s - loss: 2.6757 - accuracy20: 0.5686 - val_loss: 3.1085 - val_accuracy20: 0.5323 - 50s/epoch - 28ms/step
Epoch 23/50
1806/1806 - 52s - loss: 2.6723 - accuracy20: 0.5689 - val_loss: 3.1367 - val_accuracy20: 0.5330 - 52s/epoch - 29ms/step
Epoch 24/50
1806/1806 - 51s - loss: 2.6688 - accuracy20: 0.5699 - val_loss: 3.1907 - val_accuracy20: 0.5273 - 51s/epoch - 28ms/step
Epoch 25/50
1806/1806 - 49s - loss: 2.6652 - accuracy20: 0.5709 - val_loss: 3.1857 - val_accuracy20: 0.5313 - 49s/epoch - 27ms/step
Epoch 26/50
1806/1806 - 49s - loss: 2.6624 - accuracy20: 0.5713 - val_loss: 3.1633 - val_accuracy20: 0.5330 - 49s/epoch - 27ms/step
Epoch 27/50
1806/1806 - 47s - loss: 2.6608 - accuracy20: 0.5721 - val_loss: 3.1789 - val_accuracy20: 0.5311 - 47s/epoch - 26ms/step
Epoch 28/50
1806/1806 - 49s - loss: 2.6575 - accuracy20: 0.5732 - val_loss: 3.1912 - val_accuracy20: 0.5324 - 49s/epoch - 27ms/step
Epoch 29/50
1806/1806 - 49s - loss: 2.6536 - accuracy20: 0.5737 - val_loss: 3.1198 - val_accuracy20: 0.5377 - 49s/epoch - 27ms/step
Epoch 30/50
1806/1806 - 51s - loss: 2.6520 - accuracy20: 0.5733 - val_loss: 3.1938 - val_accuracy20: 0.5252 - 51s/epoch - 28ms/step
Epoch 31/50
1806/1806 - 51s - loss: 2.6489 - accuracy20: 0.5738 - val_loss: 3.1275 - val_accuracy20: 0.5286 - 51s/epoch - 28ms/step
Epoch 32/50
1806/1806 - 52s - loss: 2.6462 - accuracy20: 0.5744 - val_loss: 3.1535 - val_accuracy20: 0.5235 - 52s/epoch - 29ms/step
testing model: results/ATVI/W5/deepLOB_L1/h20
Evaluating performance on  test set...
8238/8238 - 137s - 137s/epoch - 17ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 1.064519
{'0': {'precision': 0.5092304581042171, 'recall': 0.32244865603200157, 'f1-score': 0.39486545720654287, 'support': 655968}, '1': {'precision': 0.47121726434597855, 'recall': 0.5460639851320855, 'f1-score': 0.5058871916961505, 'support': 798498}, '2': {'precision': 0.4431272061571233, 'recall': 0.5201865347696898, 'f1-score': 0.47857472812808266, 'support': 654248}, 'accuracy': 0.46847415059605046, 'macro avg': {'precision': 0.47452497620243966, 'recall': 0.46289972531125895, 'f1-score': 0.45977579234359195, 'support': 2108714}, 'weighted avg': {'precision': 0.4743270147878413, 'recall': 0.46847415059605046, 'f1-score': 0.46287717241702575, 'support': 2108714}}
[[211516 264253 180199]
 [114976 436031 247491]
 [ 88872 225045 340331]]
Evaluating performance on  train set...
1806/1806 - 30s - 30s/epoch - 16ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.94997615
{'0': {'precision': 0.5062877263581489, 'recall': 0.3162608012568735, 'f1-score': 0.3893240498984624, 'support': 114570}, '1': {'precision': 0.6369490440764739, 'recall': 0.6143377625375054, 'f1-score': 0.6254391055991692, 'support': 233300}, '2': {'precision': 0.41436914547310316, 'recall': 0.6002992309240286, 'f1-score': 0.4902990674241612, 'support': 114293}, 'accuracy': 0.5369728861895046, 'macro avg': {'precision': 0.5192019719692419, 'recall': 0.5102992649061359, 'f1-score': 0.5016874076405976, 'support': 462163}, 'weighted avg': {'precision': 0.5495141098172114, 'recall': 0.5369728861895046, 'f1-score': 0.5334861316164701, 'support': 462163}}
[[ 36234  45993  32343]
 [ 25351 143325  64624]
 [  9983  35700  68610]]
Evaluating performance on  val set...
642/642 - 9s - 9s/epoch - 14ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.9556789
{'0': {'precision': 0.5158908368598325, 'recall': 0.2787187383351997, 'f1-score': 0.3619096664748115, 'support': 42864}, '1': {'precision': 0.6018735632183908, 'recall': 0.6607902275279836, 'f1-score': 0.6299573515877359, 'support': 79243}, '2': {'precision': 0.4290672771582601, 'recall': 0.5505152197086344, 'f1-score': 0.48226273358304195, 'support': 42215}, 'accuracy': 0.5327953651975998, 'macro avg': {'precision': 0.5156105590788278, 'recall': 0.4966747285239392, 'f1-score': 0.4913765838818631, 'support': 164322}, 'weighted avg': {'precision': 0.5350500036909893, 'recall': 0.5327953651975998, 'f1-score': 0.5220927669688258, 'support': 164322}}
[[11947 19141 11776]
 [ 7732 52363 19148]
 [ 3479 15496 23240]]
training model: results/ATVI/W5/deepLOB_L1/h30
Epoch 1/50
1806/1806 - 54s - loss: 3.0814 - accuracy30: 0.4603 - val_loss: 3.4619 - val_accuracy30: 0.3939 - 54s/epoch - 30ms/step
Epoch 2/50
1806/1806 - 51s - loss: 3.0249 - accuracy30: 0.4750 - val_loss: 3.3004 - val_accuracy30: 0.4600 - 51s/epoch - 28ms/step
Epoch 3/50
1806/1806 - 49s - loss: 2.9713 - accuracy30: 0.4947 - val_loss: 3.2519 - val_accuracy30: 0.4687 - 49s/epoch - 27ms/step
Epoch 4/50
1806/1806 - 47s - loss: 2.9293 - accuracy30: 0.5091 - val_loss: 3.2474 - val_accuracy30: 0.4735 - 47s/epoch - 26ms/step
Epoch 5/50
1806/1806 - 45s - loss: 2.8991 - accuracy30: 0.5188 - val_loss: 3.2260 - val_accuracy30: 0.4819 - 45s/epoch - 25ms/step
Epoch 6/50
1806/1806 - 48s - loss: 2.8773 - accuracy30: 0.5241 - val_loss: 3.2363 - val_accuracy30: 0.4817 - 48s/epoch - 27ms/step
Epoch 7/50
1806/1806 - 49s - loss: 2.8601 - accuracy30: 0.5292 - val_loss: 3.2119 - val_accuracy30: 0.4857 - 49s/epoch - 27ms/step
Epoch 8/50
1806/1806 - 48s - loss: 2.8441 - accuracy30: 0.5330 - val_loss: 3.2515 - val_accuracy30: 0.4830 - 48s/epoch - 26ms/step
Epoch 9/50
1806/1806 - 49s - loss: 2.8330 - accuracy30: 0.5365 - val_loss: 3.2886 - val_accuracy30: 0.4792 - 49s/epoch - 27ms/step
Epoch 10/50
1806/1806 - 53s - loss: 2.8232 - accuracy30: 0.5387 - val_loss: 3.2515 - val_accuracy30: 0.4802 - 53s/epoch - 29ms/step
Epoch 11/50
1806/1806 - 53s - loss: 2.8152 - accuracy30: 0.5406 - val_loss: 3.2554 - val_accuracy30: 0.4785 - 53s/epoch - 29ms/step
Epoch 12/50
1806/1806 - 55s - loss: 2.8088 - accuracy30: 0.5422 - val_loss: 3.2753 - val_accuracy30: 0.4773 - 55s/epoch - 30ms/step
Epoch 13/50
1806/1806 - 55s - loss: 2.8030 - accuracy30: 0.5438 - val_loss: 3.2791 - val_accuracy30: 0.4704 - 55s/epoch - 30ms/step
Epoch 14/50
1806/1806 - 52s - loss: 2.7988 - accuracy30: 0.5449 - val_loss: 3.2812 - val_accuracy30: 0.4675 - 52s/epoch - 29ms/step
Epoch 15/50
1806/1806 - 51s - loss: 2.7933 - accuracy30: 0.5464 - val_loss: 3.2550 - val_accuracy30: 0.4755 - 51s/epoch - 28ms/step
Epoch 16/50
1806/1806 - 51s - loss: 2.7886 - accuracy30: 0.5480 - val_loss: 3.2809 - val_accuracy30: 0.4718 - 51s/epoch - 28ms/step
Epoch 17/50
1806/1806 - 46s - loss: 2.7848 - accuracy30: 0.5483 - val_loss: 3.2567 - val_accuracy30: 0.4728 - 46s/epoch - 25ms/step
testing model: results/ATVI/W5/deepLOB_L1/h30
Evaluating performance on  test set...
8238/8238 - 130s - 130s/epoch - 16ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.1470416
{'0': {'precision': 0.5696582801351859, 'recall': 0.09282021717197812, 'f1-score': 0.15963025363356714, 'support': 735454}, '1': {'precision': 0.34849061294028844, 'recall': 0.7172706512176403, 'f1-score': 0.4690770762519943, 'support': 641076}, '2': {'precision': 0.481173523273723, 'recall': 0.4399153764627471, 'f1-score': 0.459620415999863, 'support': 732184}, 'accuracy': 0.40317890429901826, 'macro avg': {'precision': 0.4664408054497325, 'recall': 0.4166687482841218, 'f1-score': 0.36277591529514147, 'support': 2108714}, 'weighted avg': {'precision': 0.4716969602821905, 'recall': 0.40317890429901826, 'f1-score': 0.35786810300476435, 'support': 2108714}}
[[ 68265 478080 189109]
 [ 23056 459825 158195]
 [ 28514 381571 322099]]
Evaluating performance on  train set...
1806/1806 - 29s - 29s/epoch - 16ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.0104418
{'0': {'precision': 0.5560832202623247, 'recall': 0.16793134323828024, 'f1-score': 0.25796111525550164, 'support': 131786}, '1': {'precision': 0.5179729318910349, 'recall': 0.6761337378689546, 'f1-score': 0.5865790442738578, 'support': 199076}, '2': {'precision': 0.4388499833848199, 'recall': 0.5431337156609622, 'f1-score': 0.4854545392661069, 'support': 131301}, 'accuracy': 0.4934341347100482, 'macro avg': {'precision': 0.5043020451793931, 'recall': 0.4623995989227323, 'f1-score': 0.4433315662651554, 'support': 462163}, 'weighted avg': {'precision': 0.5063611849564776, 'recall': 0.4934341347100482, 'f1-score': 0.4641439055335523, 'support': 462163}}
[[ 22131  71928  37727]
 [ 11013 134602  53461]
 [  6654  53333  71314]]
Evaluating performance on  val set...
642/642 - 9s - 9s/epoch - 15ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.0130728
{'0': {'precision': 0.5580640609566813, 'recall': 0.16260998273168326, 'f1-score': 0.2518386449743704, 'support': 48644}, '1': {'precision': 0.49164025789531196, 'recall': 0.7320749693051878, 'f1-score': 0.5882373916867742, 'support': 67601}, '2': {'precision': 0.45379594641016835, 'recall': 0.4671048526322358, 'f1-score': 0.46035422901890044, 'support': 48077}, 'accuracy': 0.4859726634291209, 'macro avg': {'precision': 0.5011667550873872, 'recall': 0.4539299348897023, 'f1-score': 0.43347675522668166, 'support': 164322}, 'weighted avg': {'precision': 0.5002311861510903, 'recall': 0.4859726634291209, 'f1-score': 0.4512379671017428, 'support': 164322}}
[[ 7910 28398 12336]
 [ 3418 49489 14694]
 [ 2846 22774 22457]]
training model: results/ATVI/W5/deepLOB_L1/h50
Epoch 1/50
1806/1806 - 53s - loss: 3.1468 - accuracy50: 0.4463 - val_loss: 3.4948 - val_accuracy50: 0.3372 - 53s/epoch - 29ms/step
Epoch 2/50
1806/1806 - 50s - loss: 3.1313 - accuracy50: 0.4504 - val_loss: 3.3444 - val_accuracy50: 0.3672 - 50s/epoch - 28ms/step
Epoch 3/50
1806/1806 - 53s - loss: 3.0884 - accuracy50: 0.4707 - val_loss: 3.3757 - val_accuracy50: 0.3593 - 53s/epoch - 29ms/step
Epoch 4/50
1806/1806 - 52s - loss: 3.0379 - accuracy50: 0.4839 - val_loss: 3.3130 - val_accuracy50: 0.3945 - 52s/epoch - 29ms/step
Epoch 5/50
1806/1806 - 52s - loss: 3.0016 - accuracy50: 0.4927 - val_loss: 3.3345 - val_accuracy50: 0.4063 - 52s/epoch - 29ms/step
Epoch 6/50
1806/1806 - 52s - loss: 2.9797 - accuracy50: 0.4976 - val_loss: 3.3674 - val_accuracy50: 0.3992 - 52s/epoch - 29ms/step
Epoch 7/50
1806/1806 - 51s - loss: 2.9650 - accuracy50: 0.5009 - val_loss: 3.3651 - val_accuracy50: 0.4023 - 51s/epoch - 28ms/step
Epoch 8/50
1806/1806 - 48s - loss: 2.9534 - accuracy50: 0.5037 - val_loss: 3.3339 - val_accuracy50: 0.4052 - 48s/epoch - 26ms/step
Epoch 9/50
1806/1806 - 48s - loss: 2.9460 - accuracy50: 0.5064 - val_loss: 3.3436 - val_accuracy50: 0.3966 - 48s/epoch - 27ms/step
Epoch 10/50
1806/1806 - 48s - loss: 2.9403 - accuracy50: 0.5070 - val_loss: 3.3401 - val_accuracy50: 0.3959 - 48s/epoch - 27ms/step
Epoch 11/50
1806/1806 - 50s - loss: 2.9343 - accuracy50: 0.5088 - val_loss: 3.3591 - val_accuracy50: 0.3975 - 50s/epoch - 28ms/step
Epoch 12/50
1806/1806 - 52s - loss: 2.9296 - accuracy50: 0.5100 - val_loss: 3.4012 - val_accuracy50: 0.3898 - 52s/epoch - 29ms/step
Epoch 13/50
1806/1806 - 51s - loss: 2.9242 - accuracy50: 0.5116 - val_loss: 3.4266 - val_accuracy50: 0.3952 - 51s/epoch - 28ms/step
Epoch 14/50
1806/1806 - 51s - loss: 2.9213 - accuracy50: 0.5116 - val_loss: 3.4070 - val_accuracy50: 0.3904 - 51s/epoch - 28ms/step
testing model: results/ATVI/W5/deepLOB_L1/h50
Evaluating performance on  test set...
8238/8238 - 142s - 142s/epoch - 17ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.1844075
{'0': {'precision': 0.5469051807925591, 'recall': 0.053582879707622356, 'f1-score': 0.09760312133258243, 'support': 829612}, '1': {'precision': 0.258207431543853, 'recall': 0.5672076879908988, 'f1-score': 0.35486929376968107, 'support': 457961}, '2': {'precision': 0.44927571703817415, 'recall': 0.5588577357603627, 'f1-score': 0.4981110571404537, 'support': 821141}, 'accuracy': 0.36188549039841345, 'macro avg': {'precision': 0.4181294431248621, 'recall': 0.3932161011529613, 'f1-score': 0.31686115741423904, 'support': 2108714}, 'weighted avg': {'precision': 0.4461898322718844, 'recall': 0.36188549039841345, 'f1-score': 0.3094342945085927, 'support': 2108714}}
[[ 44453 408788 376371]
 [ 12050 259759 186152]
 [ 24778 337462 458901]]
Evaluating performance on  train set...
1806/1806 - 31s - 31s/epoch - 17ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.1001415
{'0': {'precision': 0.5398875488917861, 'recall': 0.08566884540041506, 'f1-score': 0.1478732960981135, 'support': 154677}, '1': {'precision': 0.3851343753514, 'recall': 0.5776615895586289, 'f1-score': 0.46214845838068996, 'support': 154156}, '2': {'precision': 0.42086520898639057, 'recall': 0.5665362290484576, 'f1-score': 0.48295531939143416, 'support': 153330}, 'accuracy': 0.4093101351687608, 'macro avg': {'precision': 0.44862904440985885, 'recall': 0.40995555466916717, 'f1-score': 0.3643256912900792, 'support': 462163}, 'weighted avg': {'precision': 0.4487815417082035, 'recall': 0.4093101351687608, 'f1-score': 0.3638696622035735, 'support': 462163}}
[[13251 81303 60123]
 [ 5695 89050 59411]
 [ 5598 60865 86867]]
Evaluating performance on  val set...
642/642 - 11s - 11s/epoch - 18ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.105125
{'0': {'precision': 0.5372196204091694, 'recall': 0.07783511597592986, 'f1-score': 0.13597017951557308, 'support': 56003}, '1': {'precision': 0.3578979893619369, 'recall': 0.6151045025224747, 'f1-score': 0.4525058600290211, 'support': 52726}, '2': {'precision': 0.4265284342125324, 'recall': 0.5032288237727771, 'f1-score': 0.4617149270112144, 'support': 55593}, 'accuracy': 0.3941468579983204, 'macro avg': {'precision': 0.44054868132787955, 'recall': 0.39872281409039384, 'f1-score': 0.3500636555186028, 'support': 164322}, 'weighted avg': {'precision': 0.44223192896903346, 'recall': 0.3941468579983204, 'f1-score': 0.34774211533839194, 'support': 164322}}
[[ 4359 32582 19062]
 [ 1742 32432 18552]
 [ 2013 25604 27976]]
training model: results/ATVI/W5/deepLOB_L1/h100
Epoch 1/50
1806/1806 - 56s - loss: 3.2538 - accuracy100: 0.3973 - val_loss: 3.4121 - val_accuracy100: 0.3562 - 56s/epoch - 31ms/step
Epoch 2/50
1806/1806 - 50s - loss: 3.2269 - accuracy100: 0.4077 - val_loss: 3.3742 - val_accuracy100: 0.3444 - 50s/epoch - 28ms/step
Epoch 3/50
1806/1806 - 46s - loss: 3.2065 - accuracy100: 0.4193 - val_loss: 3.4233 - val_accuracy100: 0.3532 - 46s/epoch - 25ms/step
Epoch 4/50
1806/1806 - 47s - loss: 3.1916 - accuracy100: 0.4257 - val_loss: 3.4091 - val_accuracy100: 0.3613 - 47s/epoch - 26ms/step
Epoch 5/50
1806/1806 - 47s - loss: 3.1830 - accuracy100: 0.4297 - val_loss: 3.4063 - val_accuracy100: 0.3630 - 47s/epoch - 26ms/step
Epoch 6/50
1806/1806 - 49s - loss: 3.1752 - accuracy100: 0.4324 - val_loss: 3.4221 - val_accuracy100: 0.3625 - 49s/epoch - 27ms/step
Epoch 7/50
1806/1806 - 51s - loss: 3.1686 - accuracy100: 0.4338 - val_loss: 3.4296 - val_accuracy100: 0.3686 - 51s/epoch - 28ms/step
Epoch 8/50
1806/1806 - 50s - loss: 3.1633 - accuracy100: 0.4353 - val_loss: 3.4477 - val_accuracy100: 0.3690 - 50s/epoch - 27ms/step
Epoch 9/50
1806/1806 - 47s - loss: 3.1585 - accuracy100: 0.4377 - val_loss: 3.4559 - val_accuracy100: 0.3650 - 47s/epoch - 26ms/step
Epoch 10/50
1806/1806 - 48s - loss: 3.1550 - accuracy100: 0.4393 - val_loss: 3.4422 - val_accuracy100: 0.3661 - 48s/epoch - 27ms/step
Epoch 11/50
1806/1806 - 48s - loss: 3.1516 - accuracy100: 0.4399 - val_loss: 3.4758 - val_accuracy100: 0.3637 - 48s/epoch - 27ms/step
Epoch 12/50
1806/1806 - 47s - loss: 3.1479 - accuracy100: 0.4417 - val_loss: 3.4528 - val_accuracy100: 0.3623 - 47s/epoch - 26ms/step
testing model: results/ATVI/W5/deepLOB_L1/h100
Evaluating performance on  test set...
8238/8238 - 134s - 134s/epoch - 16ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.1715946
{'0': {'precision': 0.40845432352563277, 'recall': 0.012114045026598312, 'f1-score': 0.023530224507998233, 'support': 787268}, '1': {'precision': 0.24912987803819012, 'recall': 0.890271471936866, 'f1-score': 0.3893153597358243, 'support': 531694}, '2': {'precision': 0.42932601001381215, 'recall': 0.10075694648446601, 'f1-score': 0.1632105967002223, 'support': 789752}, 'accuracy': 0.2667322358555973, 'macro avg': {'precision': 0.36230340385921167, 'recall': 0.33438082114931006, 'f1-score': 0.19201872698134828, 'support': 2108714}, 'weighted avg': {'precision': 0.3760988710690229, 'recall': 0.2667322358555973, 'f1-score': 0.16807263992771712, 'support': 2108714}}
[[  9537 724383  53348]
 [  5919 473352  52423]
 [  7893 702286  79573]]
Evaluating performance on  train set...
1806/1806 - 28s - 28s/epoch - 16ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.1303482
{'0': {'precision': 0.3958890030832477, 'recall': 0.012444432957717357, 'f1-score': 0.024130348987991202, 'support': 154768}, '1': {'precision': 0.33335609223206275, 'recall': 0.8895569393744185, 'f1-score': 0.48497189491589765, 'support': 153681}, '2': {'precision': 0.41595695097665353, 'recall': 0.1277307206890719, 'f1-score': 0.19544486252961438, 'support': 153714}, 'accuracy': 0.3424506072532851, 'macro avg': {'precision': 0.3817340154306546, 'recall': 0.34324403100706924, 'f1-score': 0.2348490354778344, 'support': 462163}, 'weighted avg': {'precision': 0.38176975136895214, 'recall': 0.3424506072532851, 'f1-score': 0.23435061489911707, 'support': 462163}}
[[  1926 140877  11965]
 [  1370 136708  15603]
 [  1569 132511  19634]]
Evaluating performance on  val set...
642/642 - 10s - 10s/epoch - 15ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.1257309
{'0': {'precision': 0.3607242339832869, 'recall': 0.014288866821140903, 'f1-score': 0.0274888558692422, 'support': 54378}, '1': {'precision': 0.3367085873211959, 'recall': 0.9045719156344644, 'f1-score': 0.4907466622064364, 'support': 55141}, '2': {'precision': 0.42520133989024306, 'recall': 0.1088626535043702, 'f1-score': 0.1733445680913502, 'support': 54803}, 'accuracy': 0.34457954503961735, 'macro avg': {'precision': 0.37421138706490864, 'recall': 0.3425744786533252, 'f1-score': 0.2305266953890096, 'support': 164322}, 'weighted avg': {'precision': 0.37416912914294026, 'recall': 0.34457954503961735, 'f1-score': 0.2315870855411511, 'support': 164322}}
[[  777 50060  3541]
 [  738 49879  4524]
 [  639 48198  5966]]
training model: results/ATVI/W5/deepLOB_L1/h200
Epoch 1/50
1806/1806 - 51s - loss: 3.2836 - accuracy200: 0.3777 - val_loss: 3.3426 - val_accuracy200: 0.3377 - 51s/epoch - 28ms/step
Epoch 2/50
1806/1806 - 49s - loss: 3.2574 - accuracy200: 0.3884 - val_loss: 3.3580 - val_accuracy200: 0.3482 - 49s/epoch - 27ms/step
Epoch 3/50
1806/1806 - 48s - loss: 3.2449 - accuracy200: 0.3988 - val_loss: 3.4474 - val_accuracy200: 0.3429 - 48s/epoch - 27ms/step
Epoch 4/50
1806/1806 - 50s - loss: 3.2367 - accuracy200: 0.4037 - val_loss: 3.4192 - val_accuracy200: 0.3411 - 50s/epoch - 27ms/step
Epoch 5/50
1806/1806 - 48s - loss: 3.2316 - accuracy200: 0.4051 - val_loss: 3.4437 - val_accuracy200: 0.3495 - 48s/epoch - 27ms/step
Epoch 6/50
1806/1806 - 47s - loss: 3.2256 - accuracy200: 0.4090 - val_loss: 3.4788 - val_accuracy200: 0.3409 - 47s/epoch - 26ms/step
Epoch 7/50
1806/1806 - 47s - loss: 3.2217 - accuracy200: 0.4106 - val_loss: 3.4664 - val_accuracy200: 0.3403 - 47s/epoch - 26ms/step
Epoch 8/50
1806/1806 - 49s - loss: 3.2177 - accuracy200: 0.4127 - val_loss: 3.4817 - val_accuracy200: 0.3450 - 49s/epoch - 27ms/step
Epoch 9/50
1806/1806 - 48s - loss: 3.2149 - accuracy200: 0.4145 - val_loss: 3.4643 - val_accuracy200: 0.3416 - 48s/epoch - 27ms/step
Epoch 10/50
1806/1806 - 49s - loss: 3.2118 - accuracy200: 0.4161 - val_loss: 3.4658 - val_accuracy200: 0.3413 - 49s/epoch - 27ms/step
Epoch 11/50
1806/1806 - 49s - loss: 3.2098 - accuracy200: 0.4173 - val_loss: 3.4605 - val_accuracy200: 0.3409 - 49s/epoch - 27ms/step
testing model: results/ATVI/W5/deepLOB_L1/h200
Evaluating performance on  test set...
8238/8238 - 130s - 130s/epoch - 16ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1475815
{'0': {'precision': 0.3833972534949895, 'recall': 0.008252831168485316, 'f1-score': 0.016157855838452726, 'support': 751015}, '1': {'precision': 0.28146249482215674, 'recall': 0.8890419378467808, 'f1-score': 0.4275626043676072, 'support': 593855}, '2': {'precision': 0.36700235736989484, 'recall': 0.10414953838741942, 'f1-score': 0.16225394167513926, 'support': 763844}, 'accuracy': 0.2910370965432012, 'macro avg': {'precision': 0.34395403522901374, 'recall': 0.33381476913422853, 'f1-score': 0.20199146729373307, 'support': 2108714}, 'weighted avg': {'precision': 0.34875167844430366, 'recall': 0.2910370965432012, 'f1-score': 0.18493815773222258, 'support': 2108714}}
[[  6198 668434  76383]
 [  5063 527962  60830]
 [  4905 679385  79554]]
Evaluating performance on  train set...
1806/1806 - 30s - 30s/epoch - 16ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1278197
{'0': {'precision': 0.3958086200079083, 'recall': 0.012870128701287013, 'f1-score': 0.024929644111274376, 'support': 155554}, '1': {'precision': 0.33096704292102164, 'recall': 0.8685955948988036, 'f1-score': 0.47930221644842813, 'support': 152278}, '2': {'precision': 0.3564144507865794, 'recall': 0.13270826988744971, 'f1-score': 0.1934039991501216, 'support': 154331}, 'accuracy': 0.33484073800801883, 'macro avg': {'precision': 0.36106337123850313, 'recall': 0.33805799782918006, 'f1-score': 0.23254528656994136, 'support': 462163}, 'weighted avg': {'precision': 0.3612890085164348, 'recall': 0.33484073800801883, 'f1-score': 0.23089975045439884, 'support': 462163}}
[[  2002 134883  18669]
 [  1696 132268  18314]
 [  1360 132490  20481]]
Evaluating performance on  val set...
642/642 - 11s - 11s/epoch - 16ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1163019
{'0': {'precision': 0.37080536912751677, 'recall': 0.01615113368534522, 'f1-score': 0.03095400668802633, 'support': 54733}, '1': {'precision': 0.3293966041134305, 'recall': 0.8336514407486334, 'f1-score': 0.4722108511509273, 'support': 53965}, '2': {'precision': 0.3728165293166673, 'recall': 0.1699805839206098, 'f1-score': 0.2335000308699142, 'support': 55624}, 'accuracy': 0.33669867698786526, 'macro avg': {'precision': 0.3576728341858715, 'recall': 0.3399277194515295, 'f1-score': 0.24555496290295595, 'support': 164322}, 'weighted avg': {'precision': 0.3578871035901946, 'recall': 0.33669867698786526, 'f1-score': 0.24443026464821294, 'support': 164322}}
[[  884 46077  7772]
 [  843 44988  8134]
 [  657 45512  9455]]
training model: results/ATVI/W5/deepLOB_L1/h300
Epoch 1/50
1806/1806 - 55s - loss: 3.2877 - accuracy300: 0.3782 - val_loss: 3.3550 - val_accuracy300: 0.3383 - 55s/epoch - 31ms/step
Epoch 2/50
1806/1806 - 49s - loss: 3.2651 - accuracy300: 0.3858 - val_loss: 3.3533 - val_accuracy300: 0.3382 - 49s/epoch - 27ms/step
Epoch 3/50
1806/1806 - 52s - loss: 3.2543 - accuracy300: 0.3960 - val_loss: 3.3804 - val_accuracy300: 0.3330 - 52s/epoch - 29ms/step
Epoch 4/50
1806/1806 - 50s - loss: 3.2413 - accuracy300: 0.4031 - val_loss: 3.4264 - val_accuracy300: 0.3288 - 50s/epoch - 27ms/step
Epoch 5/50
1806/1806 - 52s - loss: 3.2334 - accuracy300: 0.4087 - val_loss: 3.4536 - val_accuracy300: 0.3304 - 52s/epoch - 29ms/step
Epoch 6/50
1806/1806 - 48s - loss: 3.2283 - accuracy300: 0.4110 - val_loss: 3.4657 - val_accuracy300: 0.3309 - 48s/epoch - 26ms/step
Epoch 7/50
1806/1806 - 49s - loss: 3.2244 - accuracy300: 0.4139 - val_loss: 3.4674 - val_accuracy300: 0.3310 - 49s/epoch - 27ms/step
Epoch 8/50
1806/1806 - 52s - loss: 3.2192 - accuracy300: 0.4162 - val_loss: 3.4620 - val_accuracy300: 0.3321 - 52s/epoch - 29ms/step
Epoch 9/50
1806/1806 - 53s - loss: 3.2162 - accuracy300: 0.4181 - val_loss: 3.4599 - val_accuracy300: 0.3330 - 53s/epoch - 29ms/step
Epoch 10/50
1806/1806 - 55s - loss: 3.2133 - accuracy300: 0.4196 - val_loss: 3.4737 - val_accuracy300: 0.3335 - 55s/epoch - 30ms/step
Epoch 11/50
1806/1806 - 49s - loss: 3.2088 - accuracy300: 0.4216 - val_loss: 3.4700 - val_accuracy300: 0.3332 - 49s/epoch - 27ms/step
Epoch 12/50
1806/1806 - 51s - loss: 3.2055 - accuracy300: 0.4233 - val_loss: 3.4713 - val_accuracy300: 0.3319 - 51s/epoch - 28ms/step
testing model: results/ATVI/W5/deepLOB_L1/h300
Evaluating performance on  test set...
8238/8238 - 131s - 131s/epoch - 16ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1278465
{'0': {'precision': 0.35864814236653136, 'recall': 0.006120130367434247, 'f1-score': 0.012034892019910608, 'support': 750801}, '1': {'precision': 0.26765190834734437, 'recall': 0.33358697742848753, 'f1-score': 0.2970040468801167, 'support': 592694}, '2': {'precision': 0.3587024756852343, 'recall': 0.636198264810466, 'f1-score': 0.4587510760127948, 'support': 765219}, 'accuracy': 0.3268062904689778, 'macro avg': {'precision': 0.32833417546637, 'recall': 0.3253017908687959, 'f1-score': 0.2559300049709407, 'support': 2108714}, 'weighted avg': {'precision': 0.33309164440712885, 'recall': 0.3268062904689778, 'f1-score': 0.254237115683037, 'support': 2108714}}
[[  4595 267728 478478]
 [  3088 197715 391891]
 [  5129 273259 486831]]
Evaluating performance on  train set...
1806/1806 - 31s - 31s/epoch - 17ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.12321
{'0': {'precision': 0.30928750638335667, 'recall': 0.08994001846578986, 'f1-score': 0.13935574229691877, 'support': 154881}, '1': {'precision': 0.33141580377836694, 'recall': 0.2600430439532404, 'f1-score': 0.291423062683963, 'support': 152867}, '2': {'precision': 0.3413476098499889, 'recall': 0.6569374736910274, 'f1-score': 0.44925851375021314, 'support': 154415}, 'accuracy': 0.3356456488295255, 'macro avg': {'precision': 0.32735030667057086, 'recall': 0.33564017870335255, 'f1-score': 0.29334577291036495, 'support': 462163}, 'weighted avg': {'precision': 0.3273184766572277, 'recall': 0.3356456488295255, 'f1-score': 0.29319694446924055, 'support': 462163}}
[[ 13930  40814 100137]
 [ 17515  39752  95600]
 [ 13594  39380 101441]]
Evaluating performance on  val set...
642/642 - 11s - 11s/epoch - 17ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1182817
{'0': {'precision': 0.33062890062409983, 'recall': 0.1264180035977826, 'f1-score': 0.18290221490412706, 'support': 54478}, '1': {'precision': 0.3236720621749547, 'recall': 0.20343402809659353, 'f1-score': 0.2498393116902155, 'support': 54455}, '2': {'precision': 0.3448465213332601, 'recall': 0.6802794778746682, 'f1-score': 0.4576842488840302, 'support': 55389}, 'accuracy': 0.33863390172953106, 'macro avg': {'precision': 0.33304916137743823, 'recall': 0.3367105031896815, 'f1-score': 0.29680859182612424, 'support': 164322}, 'weighted avg': {'precision': 0.3331158783611739, 'recall': 0.33863390172953106, 'f1-score': 0.29770705957251775, 'support': 164322}}
[[ 6887 11806 35785]
 [ 7576 11078 35801]
 [ 6367 11342 37680]]
training model: results/ATVI/W5/deepLOB_L1/h500
Epoch 1/50
1806/1806 - 53s - loss: 3.2530 - accuracy500: 0.4035 - val_loss: 3.5761 - val_accuracy500: 0.3290 - 53s/epoch - 29ms/step
Epoch 2/50
1806/1806 - 50s - loss: 3.2348 - accuracy500: 0.4119 - val_loss: 3.4780 - val_accuracy500: 0.3292 - 50s/epoch - 28ms/step
Epoch 3/50
1806/1806 - 49s - loss: 3.2285 - accuracy500: 0.4169 - val_loss: 3.5082 - val_accuracy500: 0.3168 - 49s/epoch - 27ms/step
Epoch 4/50
1806/1806 - 51s - loss: 3.2081 - accuracy500: 0.4233 - val_loss: 3.5280 - val_accuracy500: 0.3256 - 51s/epoch - 29ms/step
Epoch 5/50
1806/1806 - 50s - loss: 3.1944 - accuracy500: 0.4324 - val_loss: 3.6971 - val_accuracy500: 0.3146 - 50s/epoch - 28ms/step
Epoch 6/50
1806/1806 - 51s - loss: 3.1883 - accuracy500: 0.4366 - val_loss: 3.5897 - val_accuracy500: 0.3253 - 51s/epoch - 28ms/step
Epoch 7/50
1806/1806 - 51s - loss: 3.1776 - accuracy500: 0.4402 - val_loss: 3.6168 - val_accuracy500: 0.3217 - 51s/epoch - 28ms/step
Epoch 8/50
1806/1806 - 51s - loss: 3.1722 - accuracy500: 0.4415 - val_loss: 3.6529 - val_accuracy500: 0.3177 - 51s/epoch - 28ms/step
Epoch 9/50
1806/1806 - 52s - loss: 3.1626 - accuracy500: 0.4469 - val_loss: 3.7226 - val_accuracy500: 0.3238 - 52s/epoch - 29ms/step
Epoch 10/50
1806/1806 - 50s - loss: 3.1563 - accuracy500: 0.4473 - val_loss: 3.7012 - val_accuracy500: 0.3247 - 50s/epoch - 28ms/step
Epoch 11/50
1806/1806 - 48s - loss: 3.1530 - accuracy500: 0.4484 - val_loss: 3.7270 - val_accuracy500: 0.3250 - 48s/epoch - 26ms/step
Epoch 12/50
1806/1806 - 51s - loss: 3.1481 - accuracy500: 0.4499 - val_loss: 3.7345 - val_accuracy500: 0.3262 - 51s/epoch - 28ms/step
testing model: results/ATVI/W5/deepLOB_L1/h500
Evaluating performance on  test set...
8238/8238 - 143s - 143s/epoch - 17ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1852844
{'0': {'precision': 0.3768342213293737, 'recall': 0.04558319147053502, 'f1-score': 0.08132859083459888, 'support': 757187}, '1': {'precision': 0.27515069882068227, 'recall': 0.8976999520535895, 'f1-score': 0.42120071972457224, 'support': 579814}, '2': {'precision': 0.3561605612468609, 'recall': 0.05789069252429336, 'f1-score': 0.09959337812713176, 'support': 771713}, 'accuracy': 0.2843861234856884, 'macro avg': {'precision': 0.3360484937989723, 'recall': 0.3337246120161393, 'f1-score': 0.20070756289543432, 'support': 2108714}, 'weighted avg': {'precision': 0.3413094122926288, 'recall': 0.2843861234856884, 'f1-score': 0.18146440457515048, 'support': 2108714}}
[[ 34515 679136  43536]
 [ 22091 520499  37224]
 [ 34986 692052  44675]]
Evaluating performance on  train set...
1806/1806 - 30s - 30s/epoch - 17ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1593451
{'0': {'precision': 0.35378982057854264, 'recall': 0.031039379083917476, 'f1-score': 0.05707163784141386, 'support': 155641}, '1': {'precision': 0.3284598687060389, 'recall': 0.9067568728238535, 'f1-score': 0.48223640982575483, 'support': 151357}, '2': {'precision': 0.3307137965891675, 'recall': 0.06536267843908097, 'f1-score': 0.10915235266261998, 'support': 155165}, 'accuracy': 0.3293578239711963, 'macro avg': {'precision': 0.3376544952912497, 'recall': 0.3343863101156173, 'f1-score': 0.21615346677659622, 'support': 462163}, 'weighted avg': {'precision': 0.33774687298672346, 'recall': 0.3293578239711963, 'f1-score': 0.21379722709989268, 'support': 462163}}
[[  4831 140486  10324]
 [  3912 137244  10201]
 [  4912 140111  10142]]
Evaluating performance on  val set...
642/642 - 11s - 11s/epoch - 16ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1629245
{'0': {'precision': 0.3766367137355584, 'recall': 0.02690706333339447, 'f1-score': 0.05022596548890715, 'support': 54521}, '1': {'precision': 0.32715100092801275, 'recall': 0.9188635686624963, 'f1-score': 0.48250982539154913, 'support': 53712}, '2': {'precision': 0.3403365736385492, 'recall': 0.05805059815650127, 'f1-score': 0.09918362373583527, 'support': 56089}, 'accuracy': 0.3290916614938961, 'macro avg': {'precision': 0.34804142943404015, 'recall': 0.33460707671746404, 'f1-score': 0.21063980487209719, 'support': 164322}, 'weighted avg': {'precision': 0.34807075686904, 'recall': 0.3290916614938961, 'f1-score': 0.208237776302448, 'support': 164322}}
[[ 1467 50054  3000]
 [ 1047 49354  3311]
 [ 1381 51452  3256]]
training model: results/ATVI/W5/deepLOB_L1/h1000
Epoch 1/50
1806/1806 - 49s - loss: 3.2648 - accuracy1000: 0.4012 - val_loss: 3.4671 - val_accuracy1000: 0.3127 - 49s/epoch - 27ms/step
Epoch 2/50
1806/1806 - 45s - loss: 3.2071 - accuracy1000: 0.4252 - val_loss: 3.3947 - val_accuracy1000: 0.3569 - 45s/epoch - 25ms/step
Epoch 3/50
1806/1806 - 45s - loss: 3.1800 - accuracy1000: 0.4358 - val_loss: 3.4844 - val_accuracy1000: 0.3228 - 45s/epoch - 25ms/step
Epoch 4/50
1806/1806 - 46s - loss: 3.1669 - accuracy1000: 0.4396 - val_loss: 3.4590 - val_accuracy1000: 0.3350 - 46s/epoch - 25ms/step
Epoch 5/50
1806/1806 - 45s - loss: 3.1544 - accuracy1000: 0.4458 - val_loss: 3.5394 - val_accuracy1000: 0.3371 - 45s/epoch - 25ms/step
Epoch 6/50
1806/1806 - 45s - loss: 3.1414 - accuracy1000: 0.4492 - val_loss: 3.4848 - val_accuracy1000: 0.3437 - 45s/epoch - 25ms/step
Epoch 7/50
1806/1806 - 44s - loss: 3.1318 - accuracy1000: 0.4546 - val_loss: 3.5299 - val_accuracy1000: 0.3323 - 44s/epoch - 24ms/step
Epoch 8/50
1806/1806 - 44s - loss: 3.1254 - accuracy1000: 0.4574 - val_loss: 3.5477 - val_accuracy1000: 0.3284 - 44s/epoch - 25ms/step
Epoch 9/50
1806/1806 - 43s - loss: 3.1139 - accuracy1000: 0.4619 - val_loss: 3.5686 - val_accuracy1000: 0.3280 - 43s/epoch - 24ms/step
Epoch 10/50
1806/1806 - 44s - loss: 3.1040 - accuracy1000: 0.4652 - val_loss: 3.5512 - val_accuracy1000: 0.3326 - 44s/epoch - 24ms/step
Epoch 11/50
1806/1806 - 45s - loss: 3.0979 - accuracy1000: 0.4677 - val_loss: 3.5869 - val_accuracy1000: 0.3396 - 45s/epoch - 25ms/step
Epoch 12/50
1806/1806 - 45s - loss: 3.0941 - accuracy1000: 0.4692 - val_loss: 3.5929 - val_accuracy1000: 0.3337 - 45s/epoch - 25ms/step
testing model: results/ATVI/W5/deepLOB_L1/h1000
Evaluating performance on  test set...
8238/8238 - 122s - 122s/epoch - 15ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1477934
{'0': {'precision': 0.3333333333333333, 'recall': 2.583555411450576e-06, 'f1-score': 5.167070774660168e-06, 'support': 774127}, '1': {'precision': 0.24893268120630813, 'recall': 0.8848632102328781, 'f1-score': 0.38855559997574085, 'support': 532167}, '2': {'precision': 0.36541934651604224, 'recall': 0.09884474464744149, 'f1-score': 0.15560015380510694, 'support': 802420}, 'accuracy': 0.2609230080513526, 'macro avg': {'precision': 0.31589512035189454, 'recall': 0.3279035128119104, 'f1-score': 0.1813869736172075, 'support': 2108714}, 'weighted avg': {'precision': 0.3242430616595011, 'recall': 0.2609230080513526, 'f1-score': 0.1572698542133175, 'support': 2108714}}
[[     2 697659  76466]
 [     1 470895  61271]
 [     3 723102  79315]]
Evaluating performance on  train set...
1806/1806 - 27s - 27s/epoch - 15ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1359657
{'0': {'precision': 0.34171222987526334, 'recall': 0.09335635394842348, 'f1-score': 0.14664817946803596, 'support': 154644}, '1': {'precision': 0.33250583873654643, 'recall': 0.6722025951728464, 'f1-score': 0.44492766292233055, 'support': 151435}, '2': {'precision': 0.34908454851497334, 'recall': 0.2544463237743779, 'f1-score': 0.29434543992469975, 'support': 156084}, 'accuracy': 0.3374285695739382, 'macro avg': {'precision': 0.3411008723755944, 'recall': 0.34000175763188256, 'f1-score': 0.2953070941050221, 'support': 462163}, 'weighted avg': {'precision': 0.341185426865219, 'recall': 0.3374285695739382, 'f1-score': 0.2942652166995301, 'support': 462163}}
[[ 14437 103592  36615]
 [ 12201 101795  37439]
 [ 15611 100758  39715]]
Evaluating performance on  val set...
642/642 - 9s - 9s/epoch - 14ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1329906
{'0': {'precision': 0.347862923252213, 'recall': 0.2171660982326871, 'f1-score': 0.26739877383278315, 'support': 54829}, '1': {'precision': 0.3349899277451418, 'recall': 0.5380308431494111, 'f1-score': 0.4128994848234796, 'support': 51616}, '2': {'precision': 0.40839549076114595, 'recall': 0.33299929160115416, 'f1-score': 0.3668636800578667, 'support': 57877}, 'accuracy': 0.35875293630798066, 'macro avg': {'precision': 0.3637494472528336, 'recall': 0.36273207766108406, 'f1-score': 0.34905397957137646, 'support': 164322}, 'weighted avg': {'precision': 0.36513992130251377, 'recall': 0.35875293630798066, 'f1-score': 0.34813595495329624, 'support': 164322}}
[[11907 28460 14462]
 [10388 27771 13457]
 [11934 26670 19273]]
training model: results/ATVI/W5/deepOF_L1/h10
Epoch 1/50
1806/1806 - 45s - loss: 3.1707 - accuracy10: 0.4136 - val_loss: 3.4085 - val_accuracy10: 0.5741 - 45s/epoch - 25ms/step
Epoch 2/50
1806/1806 - 43s - loss: 3.1408 - accuracy10: 0.4108 - val_loss: 3.3689 - val_accuracy10: 0.5669 - 43s/epoch - 24ms/step
Epoch 3/50
1806/1806 - 43s - loss: 3.1271 - accuracy10: 0.4146 - val_loss: 3.3782 - val_accuracy10: 0.5655 - 43s/epoch - 24ms/step
Epoch 4/50
1806/1806 - 41s - loss: 3.1157 - accuracy10: 0.4220 - val_loss: 3.3965 - val_accuracy10: 0.5705 - 41s/epoch - 23ms/step
Epoch 5/50
1806/1806 - 41s - loss: 3.1015 - accuracy10: 0.4266 - val_loss: 3.4139 - val_accuracy10: 0.5763 - 41s/epoch - 23ms/step
Epoch 6/50
1806/1806 - 41s - loss: 3.0906 - accuracy10: 0.4302 - val_loss: 3.4279 - val_accuracy10: 0.5725 - 41s/epoch - 23ms/step
Epoch 7/50
1806/1806 - 41s - loss: 3.0820 - accuracy10: 0.4366 - val_loss: 3.4301 - val_accuracy10: 0.5719 - 41s/epoch - 23ms/step
Epoch 8/50
1806/1806 - 41s - loss: 3.0737 - accuracy10: 0.4390 - val_loss: 3.4373 - val_accuracy10: 0.5717 - 41s/epoch - 23ms/step
Epoch 9/50
1806/1806 - 41s - loss: 3.0658 - accuracy10: 0.4439 - val_loss: 3.4334 - val_accuracy10: 0.5705 - 41s/epoch - 23ms/step
Epoch 10/50
1806/1806 - 41s - loss: 3.0598 - accuracy10: 0.4487 - val_loss: 3.4439 - val_accuracy10: 0.5668 - 41s/epoch - 23ms/step
Epoch 11/50
1806/1806 - 41s - loss: 3.0529 - accuracy10: 0.4494 - val_loss: 3.4418 - val_accuracy10: 0.5670 - 41s/epoch - 23ms/step
Epoch 12/50
1806/1806 - 41s - loss: 3.0481 - accuracy10: 0.4518 - val_loss: 3.4332 - val_accuracy10: 0.5699 - 41s/epoch - 23ms/step
testing model: results/ATVI/W5/deepOF_L1/h10
Evaluating performance on  test set...
8238/8238 - 124s - 124s/epoch - 15ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 1.0259156
{'0': {'precision': 0.3845819301913593, 'recall': 0.18305384104073688, 'f1-score': 0.24804356273594977, 'support': 526550}, '1': {'precision': 0.5177997847304215, 'recall': 0.8100929866993708, 'f1-score': 0.631776877093628, 'support': 1053484}, '2': {'precision': 0.4040302027010933, 'recall': 0.1604237007613373, 'f1-score': 0.229659215532298, 'support': 528675}, 'accuracy': 0.4906409561489992, 'macro avg': {'precision': 0.4354706392076247, 'recall': 0.3845235095004817, 'f1-score': 0.3698265517872919, 'support': 2108709}, 'weighted avg': {'precision': 0.45601174518257576, 'recall': 0.4906409561489992, 'f1-score': 0.43514266563961906, 'support': 2108709}}
[[ 96387 397279  32884]
 [107845 853420  92219]
 [ 46396 397467  84812]]
Evaluating performance on  train set...
1806/1806 - 27s - 27s/epoch - 15ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.9637754
{'0': {'precision': 0.3435111745469656, 'recall': 0.21475607965391436, 'f1-score': 0.2642860121488442, 'support': 88533}, '1': {'precision': 0.6394213071240559, 'recall': 0.8098555012584921, 'f1-score': 0.7146169181776142, 'support': 285262}, '2': {'precision': 0.3565716043415213, 'recall': 0.18365868839472643, 'f1-score': 0.24244280282942066, 'support': 88365}, 'accuracy': 0.5761273152155097, 'macro avg': {'precision': 0.4465013620041809, 'recall': 0.402756756435711, 'f1-score': 0.407115244385293, 'support': 462160}, 'weighted avg': {'precision': 0.5286548501528204, 'recall': 0.5761273152155097, 'f1-score': 0.5380702421212955, 'support': 462160}}
[[ 19013  64592   4928]
 [ 29884 231021  24357]
 [  6452  65684  16229]]
Evaluating performance on  val set...
642/642 - 10s - 10s/epoch - 15ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.9723476
{'0': {'precision': 0.36336233862253314, 'recall': 0.18959582171048728, 'f1-score': 0.24917610811021623, 'support': 33698}, '1': {'precision': 0.6153156029986466, 'recall': 0.830400476097641, 'f1-score': 0.7068585278511692, 'support': 97459}, '2': {'precision': 0.38881220009202655, 'recall': 0.17835067088798431, 'f1-score': 0.24453263880276158, 'support': 33165}, 'accuracy': 0.5673859860517764, 'macro avg': {'precision': 0.4558300472377354, 'recall': 0.39944898956537084, 'f1-score': 0.400189091588049, 'support': 164322}, 'weighted avg': {'precision': 0.517931768452181, 'recall': 0.5673859860517764, 'f1-score': 0.5196893095436932, 'support': 164322}}
[[ 6389 25652  1657]
 [ 8888 80930  7641]
 [ 2306 24944  5915]]
training model: results/ATVI/W5/deepOF_L1/h20
Epoch 1/50
1806/1806 - 43s - loss: 3.1953 - accuracy20: 0.4147 - val_loss: 3.3718 - val_accuracy20: 0.4901 - 43s/epoch - 24ms/step
Epoch 2/50
1806/1806 - 41s - loss: 3.1697 - accuracy20: 0.4132 - val_loss: 3.3580 - val_accuracy20: 0.4912 - 41s/epoch - 23ms/step
Epoch 3/50
1806/1806 - 41s - loss: 3.1567 - accuracy20: 0.4181 - val_loss: 3.3662 - val_accuracy20: 0.4938 - 41s/epoch - 23ms/step
Epoch 4/50
1806/1806 - 41s - loss: 3.1439 - accuracy20: 0.4232 - val_loss: 3.3895 - val_accuracy20: 0.4958 - 41s/epoch - 23ms/step
Epoch 5/50
1806/1806 - 41s - loss: 3.1320 - accuracy20: 0.4281 - val_loss: 3.3955 - val_accuracy20: 0.4960 - 41s/epoch - 23ms/step
Epoch 6/50
1806/1806 - 41s - loss: 3.1222 - accuracy20: 0.4316 - val_loss: 3.4117 - val_accuracy20: 0.4976 - 41s/epoch - 23ms/step
Epoch 7/50
1806/1806 - 41s - loss: 3.1133 - accuracy20: 0.4368 - val_loss: 3.4218 - val_accuracy20: 0.4973 - 41s/epoch - 23ms/step
Epoch 8/50
1806/1806 - 43s - loss: 3.1042 - accuracy20: 0.4416 - val_loss: 3.4253 - val_accuracy20: 0.4989 - 43s/epoch - 24ms/step
Epoch 9/50
1806/1806 - 43s - loss: 3.0968 - accuracy20: 0.4441 - val_loss: 3.4289 - val_accuracy20: 0.4994 - 43s/epoch - 24ms/step
Epoch 10/50
1806/1806 - 43s - loss: 3.0900 - accuracy20: 0.4471 - val_loss: 3.4349 - val_accuracy20: 0.4996 - 43s/epoch - 24ms/step
Epoch 11/50
1806/1806 - 41s - loss: 3.0823 - accuracy20: 0.4501 - val_loss: 3.4327 - val_accuracy20: 0.5010 - 41s/epoch - 22ms/step
Epoch 12/50
1806/1806 - 41s - loss: 3.0776 - accuracy20: 0.4525 - val_loss: 3.4360 - val_accuracy20: 0.5008 - 41s/epoch - 23ms/step
testing model: results/ATVI/W5/deepOF_L1/h20
Evaluating performance on  test set...
8238/8238 - 120s - 120s/epoch - 15ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 1.0884188
{'0': {'precision': 0.45273615656371785, 'recall': 0.10608171765000016, 'f1-score': 0.1718879489963158, 'support': 655966}, '1': {'precision': 0.38580468585385086, 'recall': 0.8530176068288297, 'f1-score': 0.5313081493193592, 'support': 798497}, '2': {'precision': 0.4674289272071083, 'recall': 0.13540625391672245, 'f1-score': 0.20998376334783175, 'support': 654246}, 'accuracy': 0.3980193568671637, 'macro avg': {'precision': 0.435323256541559, 'recall': 0.3648351927985174, 'f1-score': 0.30439328722116893, 'support': 2108709}, 'weighted avg': {'precision': 0.4319500300071086, 'recall': 0.3980193568671637, 'f1-score': 0.3198078307123663, 'support': 2108709}}
[[ 69586 551765  34615]
 [ 51045 681132  66320]
 [ 33070 532587  88589]]
Evaluating performance on  train set...
1806/1806 - 27s - 27s/epoch - 15ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 1.017259
{'0': {'precision': 0.43378291226200827, 'recall': 0.13518945749440717, 'f1-score': 0.2061361137945968, 'support': 114432}, '1': {'precision': 0.5197410716842054, 'recall': 0.8555367991705298, 'f1-score': 0.6466440306929556, 'support': 233402}, '2': {'precision': 0.4361908364461677, 'recall': 0.16138061333379983, 'f1-score': 0.23559607722954334, 'support': 114326}, 'accuracy': 0.5054613120997057, 'macro avg': {'precision': 0.4632382734641271, 'recall': 0.3840356233329123, 'f1-score': 0.3627920739056986, 'support': 462160}, 'weighted avg': {'precision': 0.477789521803591, 'recall': 0.5054613120997057, 'f1-score': 0.4358908926581385, 'support': 462160}}
[[ 15470  93624   5338]
 [ 15208 199684  18510]
 [  4985  90891  18450]]
Evaluating performance on  val set...
642/642 - 9s - 9s/epoch - 14ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 1.0292324
{'0': {'precision': 0.4440236060953052, 'recall': 0.1177061199710463, 'f1-score': 0.18608342561830932, 'support': 42827}, '1': {'precision': 0.4982149051803885, 'recall': 0.8699443483967038, 'f1-score': 0.6335801039469512, 'support': 79243}, '2': {'precision': 0.4662009451407438, 'recall': 0.16110479977279182, 'f1-score': 0.2394596591208907, 'support': 42252}, 'accuracy': 0.49162619734423874, 'macro avg': {'precision': 0.4694798188054792, 'recall': 0.382918422713514, 'f1-score': 0.35304106289538373, 'support': 164322}, 'weighted avg': {'precision': 0.4758593800193515, 'recall': 0.49162619734423874, 'f1-score': 0.415609793960635, 'support': 164322}}
[[ 5041 35893  1893]
 [ 4405 68937  5901]
 [ 1907 33538  6807]]
training model: results/ATVI/W5/deepOF_L1/h30
Epoch 1/50
1806/1806 - 44s - loss: 3.2174 - accuracy30: 0.4129 - val_loss: 3.4079 - val_accuracy30: 0.4251 - 44s/epoch - 24ms/step
Epoch 2/50
1806/1806 - 42s - loss: 3.1978 - accuracy30: 0.4098 - val_loss: 3.3809 - val_accuracy30: 0.4268 - 42s/epoch - 23ms/step
Epoch 3/50
1806/1806 - 43s - loss: 3.1832 - accuracy30: 0.4150 - val_loss: 3.3862 - val_accuracy30: 0.4288 - 43s/epoch - 24ms/step
Epoch 4/50
1806/1806 - 43s - loss: 3.1692 - accuracy30: 0.4223 - val_loss: 3.4015 - val_accuracy30: 0.4303 - 43s/epoch - 24ms/step
Epoch 5/50
1806/1806 - 40s - loss: 3.1575 - accuracy30: 0.4279 - val_loss: 3.4159 - val_accuracy30: 0.4301 - 40s/epoch - 22ms/step
Epoch 6/50
1806/1806 - 40s - loss: 3.1491 - accuracy30: 0.4325 - val_loss: 3.4237 - val_accuracy30: 0.4328 - 40s/epoch - 22ms/step
Epoch 7/50
1806/1806 - 41s - loss: 3.1416 - accuracy30: 0.4363 - val_loss: 3.4263 - val_accuracy30: 0.4335 - 41s/epoch - 23ms/step
Epoch 8/50
1806/1806 - 41s - loss: 3.1349 - accuracy30: 0.4398 - val_loss: 3.4376 - val_accuracy30: 0.4367 - 41s/epoch - 23ms/step
Epoch 9/50
1806/1806 - 41s - loss: 3.1292 - accuracy30: 0.4415 - val_loss: 3.4303 - val_accuracy30: 0.4390 - 41s/epoch - 23ms/step
Epoch 10/50
1806/1806 - 41s - loss: 3.1229 - accuracy30: 0.4444 - val_loss: 3.4343 - val_accuracy30: 0.4395 - 41s/epoch - 23ms/step
Epoch 11/50
1806/1806 - 41s - loss: 3.1181 - accuracy30: 0.4464 - val_loss: 3.4400 - val_accuracy30: 0.4402 - 41s/epoch - 23ms/step
Epoch 12/50
1806/1806 - 41s - loss: 3.1129 - accuracy30: 0.4488 - val_loss: 3.4380 - val_accuracy30: 0.4415 - 41s/epoch - 23ms/step
testing model: results/ATVI/W5/deepOF_L1/h30
Evaluating performance on  test set...
8238/8238 - 119s - 119s/epoch - 14ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.1364284
{'0': {'precision': 0.48074345632292653, 'recall': 0.06632927777747562, 'f1-score': 0.11657450377812084, 'support': 735452}, '1': {'precision': 0.3069086404133059, 'recall': 0.9081230745232617, 'f1-score': 0.45877126449236105, 'support': 641075}, '2': {'precision': 0.5143152342369287, 'recall': 0.07750531971558984, 'f1-score': 0.13471031513829362, 'support': 732182}, 'accuracy': 0.32612607998543186, 'macro avg': {'precision': 0.4339891103243871, 'recall': 0.35065255733877576, 'f1-score': 0.2366853611362585, 'support': 2108709}, 'weighted avg': {'precision': 0.43955213826404305, 'recall': 0.32612607998543186, 'f1-score': 0.2269038583776391, 'support': 2108709}}
[[ 48782 663516  23154]
 [ 28465 582175  30435]
 [ 24225 651209  56748]]
Evaluating performance on  train set...
1806/1806 - 27s - 27s/epoch - 15ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.0567787
{'0': {'precision': 0.4679779427727845, 'recall': 0.08184558840280362, 'f1-score': 0.13932444835119379, 'support': 131687}, '1': {'precision': 0.4386036524540907, 'recall': 0.9118032507017076, 'f1-score': 0.5922959000619721, 'support': 199157}, '2': {'precision': 0.4909981677686609, 'recall': 0.093872795394316, 'f1-score': 0.15761210059965988, 'support': 131316}, 'accuracy': 0.4429137095378224, 'macro avg': {'precision': 0.465859920998512, 'recall': 0.36250721149960907, 'f1-score': 0.2964108163376086, 'support': 462160}, 'weighted avg': {'precision': 0.4618606421162119, 'recall': 0.4429137095378224, 'f1-score': 0.33971802795787337, 'support': 462160}}
[[ 10778 117082   3827]
 [  8613 181592   8952]
 [  3640 115349  12327]]
Evaluating performance on  val set...
642/642 - 10s - 10s/epoch - 16ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.0695801
{'0': {'precision': 0.4728747203579418, 'recall': 0.06957559299718159, 'f1-score': 0.12130341995301377, 'support': 48609}, '1': {'precision': 0.419388816208782, 'recall': 0.9245149077141505, 'f1-score': 0.577022305707732, 'support': 67616}, '2': {'precision': 0.5211337030191004, 'recall': 0.08792648190115808, 'f1-score': 0.15046609264925642, 'support': 48097}, 'accuracy': 0.42674139798687943, 'macro avg': {'precision': 0.47113241319527477, 'recall': 0.36067232753749673, 'f1-score': 0.2829306061033341, 'support': 164322}, 'weighted avg': {'precision': 0.46499147523010836, 'recall': 0.42674139798687943, 'f1-score': 0.3173607053308829, 'support': 164322}}
[[ 3382 43992  1235]
 [ 2453 62512  2651]
 [ 1317 42551  4229]]
training model: results/ATVI/W5/deepOF_L1/h50
Epoch 1/50
1806/1806 - 45s - loss: 3.2425 - accuracy50: 0.4074 - val_loss: 3.3506 - val_accuracy50: 0.3425 - 45s/epoch - 25ms/step
Epoch 2/50
1806/1806 - 41s - loss: 3.2329 - accuracy50: 0.4053 - val_loss: 3.3213 - val_accuracy50: 0.3525 - 41s/epoch - 22ms/step
Epoch 3/50
1806/1806 - 40s - loss: 3.2222 - accuracy50: 0.4100 - val_loss: 3.3507 - val_accuracy50: 0.3447 - 40s/epoch - 22ms/step
Epoch 4/50
1806/1806 - 41s - loss: 3.2109 - accuracy50: 0.4169 - val_loss: 3.3714 - val_accuracy50: 0.3420 - 41s/epoch - 23ms/step
Epoch 5/50
1806/1806 - 41s - loss: 3.2015 - accuracy50: 0.4219 - val_loss: 3.3942 - val_accuracy50: 0.3407 - 41s/epoch - 23ms/step
Epoch 6/50
1806/1806 - 41s - loss: 3.1935 - accuracy50: 0.4271 - val_loss: 3.4066 - val_accuracy50: 0.3385 - 41s/epoch - 23ms/step
Epoch 7/50
1806/1806 - 42s - loss: 3.1865 - accuracy50: 0.4308 - val_loss: 3.4128 - val_accuracy50: 0.3414 - 42s/epoch - 23ms/step
Epoch 8/50
1806/1806 - 42s - loss: 3.1792 - accuracy50: 0.4338 - val_loss: 3.4259 - val_accuracy50: 0.3432 - 42s/epoch - 23ms/step
Epoch 9/50
1806/1806 - 43s - loss: 3.1740 - accuracy50: 0.4360 - val_loss: 3.4338 - val_accuracy50: 0.3458 - 43s/epoch - 24ms/step
Epoch 10/50
1806/1806 - 43s - loss: 3.1691 - accuracy50: 0.4392 - val_loss: 3.4319 - val_accuracy50: 0.3466 - 43s/epoch - 24ms/step
Epoch 11/50
1806/1806 - 44s - loss: 3.1641 - accuracy50: 0.4408 - val_loss: 3.4251 - val_accuracy50: 0.3497 - 44s/epoch - 25ms/step
Epoch 12/50
1806/1806 - 44s - loss: 3.1598 - accuracy50: 0.4435 - val_loss: 3.4347 - val_accuracy50: 0.3514 - 44s/epoch - 24ms/step
testing model: results/ATVI/W5/deepOF_L1/h50
Evaluating performance on  test set...
8238/8238 - 124s - 124s/epoch - 15ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.1562164
{'0': {'precision': 0.49714813335341534, 'recall': 0.09151068938583042, 'f1-score': 0.15456956271664385, 'support': 829608}, '1': {'precision': 0.21848295829752032, 'recall': 0.8719934666925786, 'f1-score': 0.3494173883141667, 'support': 457961}, '2': {'precision': 0.5355908938473417, 'recall': 0.0836325108994812, 'f1-score': 0.14467415451024424, 'support': 821140}, 'accuracy': 0.2579450270283856, 'macro avg': {'precision': 0.41707399516609245, 'recall': 0.3490455556592968, 'f1-score': 0.21622036851368495, 'support': 2108709}, 'weighted avg': {'precision': 0.4515985132390278, 'recall': 0.2579450270283856, 'f1-score': 0.1930325225484007, 'support': 2108709}}
[[ 75918 721362  32328]
 [ 31403 399339  27219]
 [ 45386 707080  68674]]
Evaluating performance on  train set...
1806/1806 - 28s - 28s/epoch - 15ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0983855
{'0': {'precision': 0.4943056886733946, 'recall': 0.11343640833225514, 'f1-score': 0.18452650299388595, 'support': 154580}, '1': {'precision': 0.3398897118968698, 'recall': 0.8757733362732001, 'f1-score': 0.48971850777389964, 'support': 154202}, '2': {'precision': 0.5220856179545686, 'recall': 0.09994914524899269, 'f1-score': 0.16777844052511479, 'support': 153378}, 'accuracy': 0.3633178985632681, 'macro avg': {'precision': 0.45209367284161095, 'recall': 0.363052963284816, 'f1-score': 0.2806744837643001, 'support': 462160}, 'weighted avg': {'precision': 0.4520034070877841, 'recall': 0.3633178985632681, 'f1-score': 0.28079713047301114, 'support': 462160}}
[[ 17535 131500   5545]
 [ 10668 135046   8488]
 [  7271 130777  15330]]
Evaluating performance on  val set...
642/642 - 10s - 10s/epoch - 15ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.1074462
{'0': {'precision': 0.48763314677739666, 'recall': 0.09647634525744289, 'f1-score': 0.16108303141447122, 'support': 55993}, '1': {'precision': 0.3284548425989811, 'recall': 0.893966122270908, 'f1-score': 0.48040324964578046, 'support': 52719}, '2': {'precision': 0.5369478323255099, 'recall': 0.09420967451897141, 'f1-score': 0.1602949500512491, 'support': 55610}, 'accuracy': 0.3515658280692786, 'macro avg': {'precision': 0.4510119405672959, 'recall': 0.3615507140157741, 'f1-score': 0.2672604103705003, 'support': 164322}, 'weighted avg': {'precision': 0.453253505861078, 'recall': 0.3515658280692786, 'f1-score': 0.26326300354436016, 'support': 164322}}
[[ 5402 48654  1937]
 [ 3009 47129  2581]
 [ 2667 47704  5239]]
training model: results/ATVI/W5/deepOF_L1/h100
Epoch 1/50
1806/1806 - 45s - loss: 3.2748 - accuracy100: 0.3848 - val_loss: 3.3221 - val_accuracy100: 0.3458 - 45s/epoch - 25ms/step
Epoch 2/50
1806/1806 - 43s - loss: 3.2513 - accuracy100: 0.3955 - val_loss: 3.3086 - val_accuracy100: 0.3525 - 43s/epoch - 24ms/step
Epoch 3/50
1806/1806 - 42s - loss: 3.2430 - accuracy100: 0.4010 - val_loss: 3.3128 - val_accuracy100: 0.3519 - 42s/epoch - 23ms/step
Epoch 4/50
1806/1806 - 43s - loss: 3.2368 - accuracy100: 0.4047 - val_loss: 3.3213 - val_accuracy100: 0.3497 - 43s/epoch - 24ms/step
Epoch 5/50
1806/1806 - 45s - loss: 3.2318 - accuracy100: 0.4080 - val_loss: 3.3341 - val_accuracy100: 0.3494 - 45s/epoch - 25ms/step
Epoch 6/50
1806/1806 - 45s - loss: 3.2280 - accuracy100: 0.4105 - val_loss: 3.3433 - val_accuracy100: 0.3496 - 45s/epoch - 25ms/step
Epoch 7/50
1806/1806 - 44s - loss: 3.2257 - accuracy100: 0.4120 - val_loss: 3.3462 - val_accuracy100: 0.3518 - 44s/epoch - 25ms/step
Epoch 8/50
1806/1806 - 41s - loss: 3.2229 - accuracy100: 0.4132 - val_loss: 3.3531 - val_accuracy100: 0.3511 - 41s/epoch - 23ms/step
Epoch 9/50
1806/1806 - 43s - loss: 3.2212 - accuracy100: 0.4140 - val_loss: 3.3574 - val_accuracy100: 0.3503 - 43s/epoch - 24ms/step
Epoch 10/50
1806/1806 - 42s - loss: 3.2191 - accuracy100: 0.4152 - val_loss: 3.3584 - val_accuracy100: 0.3507 - 42s/epoch - 23ms/step
Epoch 11/50
1806/1806 - 42s - loss: 3.2171 - accuracy100: 0.4166 - val_loss: 3.3579 - val_accuracy100: 0.3515 - 42s/epoch - 23ms/step
Epoch 12/50
1806/1806 - 43s - loss: 3.2147 - accuracy100: 0.4173 - val_loss: 3.3635 - val_accuracy100: 0.3518 - 43s/epoch - 24ms/step
testing model: results/ATVI/W5/deepOF_L1/h100
Evaluating performance on  test set...
8238/8238 - 125s - 125s/epoch - 15ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.1368327
{'0': {'precision': 0.43997401472498915, 'recall': 0.03871250468393743, 'f1-score': 0.07116346675850957, 'support': 787265}, '1': {'precision': 0.25030799223764405, 'recall': 0.8410737023056538, 'f1-score': 0.385799891643057, 'support': 531693}, '2': {'precision': 0.457329515794802, 'recall': 0.14643096368349012, 'f1-score': 0.22183367078482172, 'support': 789751}, 'accuracy': 0.2813636210591409, 'macro avg': {'precision': 0.3825371742524784, 'recall': 0.3420723902243605, 'f1-score': 0.22626567639546277, 'support': 2108709}, 'weighted avg': {'precision': 0.3986513039246946, 'recall': 0.2813636210591409, 'f1-score': 0.2069251716481476, 'support': 2108709}}
[[ 30477 684457  72331]
 [ 19607 447193  64893]
 [ 19186 654921 115644]]
Evaluating performance on  train set...
1806/1806 - 28s - 28s/epoch - 15ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.1018814
{'0': {'precision': 0.4544528957297718, 'recall': 0.04903994674628872, 'f1-score': 0.0885269617565392, 'support': 154731}, '1': {'precision': 0.3330687851072191, 'recall': 0.8437469500888134, 'f1-score': 0.47760369478266634, 'support': 153693}, '2': {'precision': 0.44290805416963647, 'recall': 0.16167976271010043, 'f1-score': 0.23688624580664835, 'support': 153736}, 'accuracy': 0.3507919335295136, 'macro avg': {'precision': 0.4101432450022091, 'recall': 0.35148888651506754, 'f1-score': 0.2676723007819513, 'support': 462160}, 'weighted avg': {'precision': 0.41024581187136566, 'recall': 0.3507919335295136, 'f1-score': 0.26726708037717306, 'support': 462160}}
[[  7588 134201  12942]
 [  5693 129678  18322]
 [  3416 125464  24856]]
Evaluating performance on  val set...
642/642 - 10s - 10s/epoch - 16ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.1035312
{'0': {'precision': 0.423728813559322, 'recall': 0.04006705474909734, 'f1-score': 0.07321137048319504, 'support': 54284}, '1': {'precision': 0.33652556428931996, 'recall': 0.8454444987952244, 'f1-score': 0.48142283111617756, 'support': 55197}, '2': {'precision': 0.439300160826551, 'recall': 0.16436607647562954, 'f1-score': 0.23922505307855627, 'support': 54841}, 'accuracy': 0.3520831051228685, 'macro avg': {'precision': 0.399851512891731, 'recall': 0.3499592100066504, 'f1-score': 0.2646197515593096, 'support': 164322}, 'weighted avg': {'precision': 0.39963338206217497, 'recall': 0.3520831051228685, 'f1-score': 0.2657382649937958, 'support': 164322}}
[[ 2175 47346  4763]
 [ 1789 46666  6742]
 [ 1169 44658  9014]]
training model: results/ATVI/W5/deepOF_L1/h200
Epoch 1/50
1806/1806 - 47s - loss: 3.2919 - accuracy200: 0.3657 - val_loss: 3.3194 - val_accuracy200: 0.3398 - 47s/epoch - 26ms/step
Epoch 2/50
1806/1806 - 45s - loss: 3.2746 - accuracy200: 0.3741 - val_loss: 3.3067 - val_accuracy200: 0.3463 - 45s/epoch - 25ms/step
Epoch 3/50
1806/1806 - 43s - loss: 3.2688 - accuracy200: 0.3776 - val_loss: 3.2999 - val_accuracy200: 0.3501 - 43s/epoch - 24ms/step
Epoch 4/50
1806/1806 - 43s - loss: 3.2654 - accuracy200: 0.3817 - val_loss: 3.3018 - val_accuracy200: 0.3489 - 43s/epoch - 24ms/step
Epoch 5/50
1806/1806 - 44s - loss: 3.2628 - accuracy200: 0.3848 - val_loss: 3.3050 - val_accuracy200: 0.3486 - 44s/epoch - 24ms/step
Epoch 6/50
1806/1806 - 44s - loss: 3.2609 - accuracy200: 0.3864 - val_loss: 3.3097 - val_accuracy200: 0.3475 - 44s/epoch - 24ms/step
Epoch 7/50
1806/1806 - 44s - loss: 3.2585 - accuracy200: 0.3882 - val_loss: 3.3169 - val_accuracy200: 0.3451 - 44s/epoch - 24ms/step
Epoch 8/50
1806/1806 - 43s - loss: 3.2567 - accuracy200: 0.3890 - val_loss: 3.3135 - val_accuracy200: 0.3473 - 43s/epoch - 24ms/step
Epoch 9/50
1806/1806 - 44s - loss: 3.2557 - accuracy200: 0.3902 - val_loss: 3.3188 - val_accuracy200: 0.3447 - 44s/epoch - 24ms/step
Epoch 10/50
1806/1806 - 44s - loss: 3.2545 - accuracy200: 0.3906 - val_loss: 3.3207 - val_accuracy200: 0.3449 - 44s/epoch - 24ms/step
Epoch 11/50
1806/1806 - 43s - loss: 3.2532 - accuracy200: 0.3917 - val_loss: 3.3179 - val_accuracy200: 0.3475 - 43s/epoch - 24ms/step
Epoch 12/50
1806/1806 - 43s - loss: 3.2521 - accuracy200: 0.3923 - val_loss: 3.3259 - val_accuracy200: 0.3440 - 43s/epoch - 24ms/step
Epoch 13/50
1806/1806 - 43s - loss: 3.2514 - accuracy200: 0.3928 - val_loss: 3.3256 - val_accuracy200: 0.3444 - 43s/epoch - 24ms/step
testing model: results/ATVI/W5/deepOF_L1/h200
Evaluating performance on  test set...
8238/8238 - 127s - 127s/epoch - 15ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1108359
{'0': {'precision': 0.4186660984444918, 'recall': 0.013081033433598177, 'f1-score': 0.025369411059864993, 'support': 751011}, '1': {'precision': 0.2876063516205214, 'recall': 0.555336833632509, 'f1-score': 0.37895412985299815, 'support': 593854}, '2': {'precision': 0.39146110703874804, 'recall': 0.48100921130492613, 'f1-score': 0.4316396658873838, 'support': 763844}, 'accuracy': 0.3352899807417714, 'macro avg': {'precision': 0.36591118570125375, 'recall': 0.34980902612367776, 'f1-score': 0.278654402266749, 'support': 2108709}, 'weighted avg': {'precision': 0.37190254579415877, 'recall': 0.3352899807417714, 'f1-score': 0.27211032985076905, 'support': 2108709}}
[[  9824 427589 313598]
 [  6503 329789 257562]
 [  7138 389290 367416]]
Evaluating performance on  train set...
1806/1806 - 28s - 28s/epoch - 16ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0991125
{'0': {'precision': 0.4097155022256629, 'recall': 0.013614147909967846, 'f1-score': 0.02635264242190369, 'support': 155500}, '1': {'precision': 0.3389716350671716, 'recall': 0.5518588556645524, 'f1-score': 0.4199777636197829, 'support': 152298}, '2': {'precision': 0.3698755297877022, 'recall': 0.500906958966585, 'f1-score': 0.42553273455730195, 'support': 154362}, 'accuracy': 0.3537411286134672, 'macro avg': {'precision': 0.37285422236017896, 'recall': 0.3554599875137017, 'f1-score': 0.2906210468663295, 'support': 462160}, 'weighted avg': {'precision': 0.37309630691241125, 'recall': 0.3537411286134672, 'f1-score': 0.2893926201144754, 'support': 462160}}
[[ 2117 88169 65214]
 [ 1740 84047 66511]
 [ 1310 75731 77321]]
Evaluating performance on  val set...
642/642 - 10s - 10s/epoch - 15ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.100942
{'0': {'precision': 0.41741204531902204, 'recall': 0.012795671407158263, 'f1-score': 0.024830179309366297, 'support': 54706}, '1': {'precision': 0.3353327151291773, 'recall': 0.52929188127617, 'f1-score': 0.4105571004620348, 'support': 53974}, '2': {'precision': 0.3674921241543149, 'recall': 0.5115380467991805, 'f1-score': 0.42771274437615525, 'support': 55642}, 'accuracy': 0.3513284891858668, 'macro avg': {'precision': 0.37341229486750477, 'recall': 0.3512085331608363, 'f1-score': 0.28770000804918544, 'support': 164322}, 'weighted avg': {'precision': 0.37354820468226424, 'recall': 0.3513284891858668, 'f1-score': 0.2879502516535466, 'support': 164322}}
[[  700 29863 24143]
 [  560 28568 24846]
 [  417 26762 28463]]
training model: results/ATVI/W5/deepOF_L1/h300
Epoch 1/50
1806/1806 - 46s - loss: 3.2977 - accuracy300: 0.3658 - val_loss: 3.3214 - val_accuracy300: 0.3442 - 46s/epoch - 25ms/step
Epoch 2/50
1806/1806 - 42s - loss: 3.2811 - accuracy300: 0.3725 - val_loss: 3.3083 - val_accuracy300: 0.3505 - 42s/epoch - 23ms/step
Epoch 3/50
1806/1806 - 43s - loss: 3.2773 - accuracy300: 0.3744 - val_loss: 3.3011 - val_accuracy300: 0.3504 - 43s/epoch - 24ms/step
Epoch 4/50
1806/1806 - 44s - loss: 3.2747 - accuracy300: 0.3771 - val_loss: 3.2954 - val_accuracy300: 0.3507 - 44s/epoch - 24ms/step
Epoch 5/50
1806/1806 - 44s - loss: 3.2724 - accuracy300: 0.3791 - val_loss: 3.2947 - val_accuracy300: 0.3513 - 44s/epoch - 24ms/step
Epoch 6/50
1806/1806 - 44s - loss: 3.2711 - accuracy300: 0.3799 - val_loss: 3.2957 - val_accuracy300: 0.3489 - 44s/epoch - 24ms/step
Epoch 7/50
1806/1806 - 42s - loss: 3.2702 - accuracy300: 0.3809 - val_loss: 3.2978 - val_accuracy300: 0.3505 - 42s/epoch - 23ms/step
Epoch 8/50
1806/1806 - 43s - loss: 3.2683 - accuracy300: 0.3821 - val_loss: 3.2959 - val_accuracy300: 0.3506 - 43s/epoch - 24ms/step
Epoch 9/50
1806/1806 - 44s - loss: 3.2668 - accuracy300: 0.3831 - val_loss: 3.3024 - val_accuracy300: 0.3489 - 44s/epoch - 24ms/step
Epoch 10/50
1806/1806 - 43s - loss: 3.2658 - accuracy300: 0.3842 - val_loss: 3.3024 - val_accuracy300: 0.3467 - 43s/epoch - 24ms/step
Epoch 11/50
1806/1806 - 43s - loss: 3.2648 - accuracy300: 0.3847 - val_loss: 3.3066 - val_accuracy300: 0.3477 - 43s/epoch - 24ms/step
Epoch 12/50
1806/1806 - 44s - loss: 3.2639 - accuracy300: 0.3853 - val_loss: 3.3048 - val_accuracy300: 0.3456 - 44s/epoch - 24ms/step
Epoch 13/50
1806/1806 - 44s - loss: 3.2633 - accuracy300: 0.3866 - val_loss: 3.3074 - val_accuracy300: 0.3462 - 44s/epoch - 25ms/step
Epoch 14/50
1806/1806 - 44s - loss: 3.2628 - accuracy300: 0.3864 - val_loss: 3.3048 - val_accuracy300: 0.3462 - 44s/epoch - 24ms/step
Epoch 15/50
1806/1806 - 42s - loss: 3.2613 - accuracy300: 0.3881 - val_loss: 3.3088 - val_accuracy300: 0.3463 - 42s/epoch - 23ms/step
testing model: results/ATVI/W5/deepOF_L1/h300
Evaluating performance on  test set...
8238/8238 - 128s - 128s/epoch - 16ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1085252
{'0': {'precision': 0.398393036491463, 'recall': 0.00792491179373386, 'f1-score': 0.015540685252803856, 'support': 750797}, '1': {'precision': 0.2828891210795686, 'recall': 0.5390277934782425, 'f1-score': 0.371047477022798, 'support': 592693}, '2': {'precision': 0.38803277362681116, 'recall': 0.48905215369717686, 'f1-score': 0.4327249454081252, 'support': 765219}, 'accuracy': 0.3317954255423579, 'macro avg': {'precision': 0.3564383103992809, 'recall': 0.3453349529897178, 'f1-score': 0.273104369227909, 'support': 2108709}, 'weighted avg': {'precision': 0.3621688670464386, 'recall': 0.3317954255423579, 'f1-score': 0.2668526061040583, 'support': 2108709}}
[[  5950 423466 321381]
 [  4394 319478 268821]
 [  4591 386396 374232]]
Evaluating performance on  train set...
1806/1806 - 27s - 27s/epoch - 15ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0993586
{'0': {'precision': 0.4010312231452306, 'recall': 0.009037213956040409, 'f1-score': 0.017676098127596178, 'support': 154915}, '1': {'precision': 0.33668951929069746, 'recall': 0.5479011941763455, 'f1-score': 0.417080095636581, 'support': 152825}, '2': {'precision': 0.3673216683970396, 'recall': 0.4994689807019816, 'f1-score': 0.42332200859509217, 'support': 154420}, 'accuracy': 0.35109269517050373, 'macro avg': {'precision': 0.3683474702776559, 'recall': 0.35213579627812247, 'f1-score': 0.2860260674530898, 'support': 462160}, 'weighted avg': {'precision': 0.36849173392984047, 'recall': 0.35109269517050373, 'f1-score': 0.2852863573748295, 'support': 462160}}
[[ 1400 88565 64950]
 [ 1196 83733 67896]
 [  895 76397 77128]]
Evaluating performance on  val set...
642/642 - 10s - 10s/epoch - 16ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0986246
{'0': {'precision': 0.37702265372168287, 'recall': 0.008556738890929122, 'f1-score': 0.016733697213444414, 'support': 54460}, '1': {'precision': 0.33613503114694027, 'recall': 0.5381118240146654, 'f1-score': 0.41379213126770886, 'support': 54550}, '2': {'precision': 0.3671823437788748, 'recall': 0.5029107607752387, 'f1-score': 0.42446021210040435, 'support': 55312}, 'accuracy': 0.3507564416207203, 'macro avg': {'precision': 0.36011334288249935, 'recall': 0.3498597745602778, 'f1-score': 0.28499534686051925, 'support': 164322}, 'weighted avg': {'precision': 0.3601368621964531, 'recall': 0.3507564416207203, 'f1-score': 0.28578900672213864, 'support': 164322}}
[[  466 30793 23201]
 [  456 29354 24740]
 [  314 27181 27817]]
training model: results/ATVI/W5/deepOF_L1/h500
Epoch 1/50
1806/1806 - 46s - loss: 3.2954 - accuracy500: 0.3737 - val_loss: 3.3184 - val_accuracy500: 0.3292 - 46s/epoch - 25ms/step
Epoch 2/50
1806/1806 - 43s - loss: 3.2864 - accuracy500: 0.3701 - val_loss: 3.3018 - val_accuracy500: 0.3440 - 43s/epoch - 24ms/step
Epoch 3/50
1806/1806 - 43s - loss: 3.2838 - accuracy500: 0.3688 - val_loss: 3.2980 - val_accuracy500: 0.3425 - 43s/epoch - 24ms/step
Epoch 4/50
1806/1806 - 43s - loss: 3.2807 - accuracy500: 0.3707 - val_loss: 3.2981 - val_accuracy500: 0.3431 - 43s/epoch - 24ms/step
Epoch 5/50
1806/1806 - 41s - loss: 3.2765 - accuracy500: 0.3747 - val_loss: 3.3035 - val_accuracy500: 0.3397 - 41s/epoch - 23ms/step
Epoch 6/50
1806/1806 - 44s - loss: 3.2731 - accuracy500: 0.3772 - val_loss: 3.3098 - val_accuracy500: 0.3349 - 44s/epoch - 24ms/step
Epoch 7/50
1806/1806 - 44s - loss: 3.2708 - accuracy500: 0.3786 - val_loss: 3.3254 - val_accuracy500: 0.3269 - 44s/epoch - 24ms/step
Epoch 8/50
1806/1806 - 44s - loss: 3.2691 - accuracy500: 0.3801 - val_loss: 3.3361 - val_accuracy500: 0.3267 - 44s/epoch - 24ms/step
Epoch 9/50
1806/1806 - 42s - loss: 3.2677 - accuracy500: 0.3817 - val_loss: 3.3488 - val_accuracy500: 0.3267 - 42s/epoch - 23ms/step
Epoch 10/50
1806/1806 - 44s - loss: 3.2671 - accuracy500: 0.3818 - val_loss: 3.3505 - val_accuracy500: 0.3267 - 44s/epoch - 24ms/step
Epoch 11/50
1806/1806 - 43s - loss: 3.2665 - accuracy500: 0.3831 - val_loss: 3.3563 - val_accuracy500: 0.3268 - 43s/epoch - 24ms/step
Epoch 12/50
1806/1806 - 43s - loss: 3.2659 - accuracy500: 0.3829 - val_loss: 3.3573 - val_accuracy500: 0.3267 - 43s/epoch - 24ms/step
Epoch 13/50
1806/1806 - 42s - loss: 3.2649 - accuracy500: 0.3832 - val_loss: 3.3626 - val_accuracy500: 0.3267 - 42s/epoch - 23ms/step
testing model: results/ATVI/W5/deepOF_L1/h500
Evaluating performance on  test set...
8238/8238 - 126s - 126s/epoch - 15ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1058353
{'0': {'precision': 0.392835641180012, 'recall': 0.005170466926840865, 'f1-score': 0.010206595572449231, 'support': 757185}, '1': {'precision': 0.27659398037443067, 'recall': 0.5292620206859798, 'f1-score': 0.3633172397299684, 'support': 579813}, '2': {'precision': 0.38282696770958846, 'recall': 0.49075366296450357, 'f1-score': 0.43012340266771454, 'support': 771711}, 'accuracy': 0.32698110550104353, 'macro avg': {'precision': 0.35075219642134375, 'recall': 0.3417287168591081, 'f1-score': 0.2678824126567107, 'support': 2108709}, 'weighted avg': {'precision': 0.3572108918716909, 'recall': 0.32698110550104353, 'f1-score': 0.2609726145163613, 'support': 2108709}}
[[  3915 412824 340446]
 [  2834 306873 270106]
 [  3217 389774 378720]]
Evaluating performance on  train set...
1806/1806 - 29s - 29s/epoch - 16ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1004525
{'0': {'precision': 0.37197869725522326, 'recall': 0.005833563549222299, 'f1-score': 0.011486982263492145, 'support': 155651}, '1': {'precision': 0.3297559625108909, 'recall': 0.5352215056037217, 'f1-score': 0.4080857345835454, 'support': 151328}, '2': {'precision': 0.3563598488563809, 'recall': 0.4916645723381084, 'f1-score': 0.41321808265769794, 'support': 155181}, 'accuracy': 0.3423035312445906, 'macro avg': {'precision': 0.3526981695408317, 'recall': 0.3442398804970175, 'f1-score': 0.27759693316824513, 'support': 462160}, 'weighted avg': {'precision': 0.35290904493401176, 'recall': 0.3423035312445906, 'f1-score': 0.27623843172117407, 'support': 462160}}
[[  908 86399 68344]
 [  874 80994 69460]
 [  659 78225 76297]]
Evaluating performance on  val set...
642/642 - 11s - 11s/epoch - 16ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0998577
{'0': {'precision': 0.34657039711191334, 'recall': 0.005280431235217543, 'f1-score': 0.010402369428592068, 'support': 54541}, '1': {'precision': 0.32703364129225654, 'recall': 0.5203062707254369, 'f1-score': 0.401627851796461, 'support': 53678}, '2': {'precision': 0.3596107055961071, 'recall': 0.5005436429424451, 'f1-score': 0.4185315180374536, 'support': 56103}, 'accuracy': 0.3426138922359757, 'macro avg': {'precision': 0.344404914666759, 'recall': 0.3420434483010332, 'f1-score': 0.27685391308750223, 'support': 164322}, 'weighted avg': {'precision': 0.34464068866143915, 'recall': 0.3426138922359757, 'f1-score': 0.2775453634704454, 'support': 164322}}
[[  288 29701 24552]
 [  293 27929 25456]
 [  250 27771 28082]]
training model: results/ATVI/W5/deepOF_L1/h1000
Epoch 1/50
1806/1806 - 45s - loss: 3.3100 - accuracy1000: 0.3602 - val_loss: 3.3870 - val_accuracy1000: 0.3152 - 45s/epoch - 25ms/step
Epoch 2/50
1806/1806 - 42s - loss: 3.2965 - accuracy1000: 0.3564 - val_loss: 3.3335 - val_accuracy1000: 0.3155 - 42s/epoch - 23ms/step
Epoch 3/50
1806/1806 - 42s - loss: 3.2913 - accuracy1000: 0.3568 - val_loss: 3.3390 - val_accuracy1000: 0.3145 - 42s/epoch - 23ms/step
Epoch 4/50
1806/1806 - 42s - loss: 3.2859 - accuracy1000: 0.3613 - val_loss: 3.3615 - val_accuracy1000: 0.3139 - 42s/epoch - 23ms/step
Epoch 5/50
1806/1806 - 42s - loss: 3.2809 - accuracy1000: 0.3651 - val_loss: 3.3778 - val_accuracy1000: 0.3138 - 42s/epoch - 23ms/step
Epoch 6/50
1806/1806 - 43s - loss: 3.2768 - accuracy1000: 0.3691 - val_loss: 3.3947 - val_accuracy1000: 0.3138 - 43s/epoch - 24ms/step
Epoch 7/50
1806/1806 - 43s - loss: 3.2740 - accuracy1000: 0.3716 - val_loss: 3.4022 - val_accuracy1000: 0.3140 - 43s/epoch - 24ms/step
Epoch 8/50
1806/1806 - 43s - loss: 3.2714 - accuracy1000: 0.3745 - val_loss: 3.4019 - val_accuracy1000: 0.3139 - 43s/epoch - 24ms/step
Epoch 9/50
1806/1806 - 43s - loss: 3.2699 - accuracy1000: 0.3761 - val_loss: 3.4026 - val_accuracy1000: 0.3139 - 43s/epoch - 24ms/step
Epoch 10/50
1806/1806 - 44s - loss: 3.2683 - accuracy1000: 0.3780 - val_loss: 3.4027 - val_accuracy1000: 0.3140 - 44s/epoch - 24ms/step
Epoch 11/50
1806/1806 - 44s - loss: 3.2675 - accuracy1000: 0.3795 - val_loss: 3.3972 - val_accuracy1000: 0.3139 - 44s/epoch - 24ms/step
Epoch 12/50
1806/1806 - 45s - loss: 3.2664 - accuracy1000: 0.3804 - val_loss: 3.3977 - val_accuracy1000: 0.3139 - 45s/epoch - 25ms/step
testing model: results/ATVI/W5/deepOF_L1/h1000
Evaluating performance on  test set...
8238/8238 - 126s - 126s/epoch - 15ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1281544
{'0': {'precision': 0.431266846361186, 'recall': 0.0002066852338901778, 'f1-score': 0.00041317245430893683, 'support': 774124}, '1': {'precision': 0.25168543811410576, 'recall': 0.9477476055448759, 'f1-score': 0.39774503893187046, 'support': 532167}, '2': {'precision': 0.39481648915791895, 'recall': 0.05137222744255488, 'f1-score': 0.09091490539530185, 'support': 802418}, 'accuracy': 0.258803846334416, 'macro avg': {'precision': 0.3592562578777369, 'recall': 0.333108839407107, 'f1-score': 0.16302437226049374, 'support': 2108709}, 'weighted avg': {'precision': 0.3720762600787947, 'recall': 0.258803846334416, 'f1-score': 0.13512456550608143, 'support': 2108709}}
[[   160 738501  35463]
 [    84 504360  27723]
 [   127 761069  41222]]
Evaluating performance on  train set...
1806/1806 - 28s - 28s/epoch - 15ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1107374
{'0': {'precision': 0.2112676056338028, 'recall': 9.701202949165696e-05, 'f1-score': 0.00019393500591501767, 'support': 154620}, '1': {'precision': 0.3273378615398159, 'recall': 0.9571177759590253, 'f1-score': 0.4878344987207931, 'support': 151508}, '2': {'precision': 0.35975481978206203, 'recall': 0.044010203035274816, 'f1-score': 0.07842622201918684, 'support': 156032}, 'accuracy': 0.3286589060065778, 'macro avg': {'precision': 0.2994534289852269, 'recall': 0.3337416636745973, 'f1-score': 0.18881821858196499, 'support': 462160}, 'weighted avg': {'precision': 0.29944990035811775, 'recall': 0.3286589060065778, 'f1-score': 0.18646749120846084, 'support': 462160}}
[[    15 148848   5757]
 [    33 145011   6464]
 [    23 149142   6867]]
Evaluating performance on  val set...
642/642 - 10s - 10s/epoch - 15ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1126856
{'0': {'precision': 0.25806451612903225, 'recall': 0.00014589222212090818, 'f1-score': 0.00029161958225494837, 'support': 54835}, '1': {'precision': 0.3129033072775259, 'recall': 0.9606117583205722, 'f1-score': 0.4720456071668404, 'support': 51589}, '2': {'precision': 0.37409098596313206, 'recall': 0.038205119347818575, 'f1-score': 0.06932973938662612, 'support': 57898}, 'accuracy': 0.3150947529849929, 'macro avg': {'precision': 0.3150196031232301, 'recall': 0.3329875899635039, 'f1-score': 0.1805556553785738, 'support': 164322}, 'weighted avg': {'precision': 0.31616251242298166, 'recall': 0.3150947529849929, 'f1-score': 0.17272431590979884, 'support': 164322}}
[[    8 53145  1682]
 [   13 49557  2019]
 [   10 55676  2212]]
training model: results/ATVI/W5/deepLOB_L2/h10
Epoch 1/50
1806/1806 - 89s - loss: 2.9970 - accuracy10: 0.4454 - val_loss: 3.1304 - val_accuracy10: 0.4786 - 89s/epoch - 50ms/step
Epoch 2/50
1806/1806 - 87s - loss: 2.8255 - accuracy10: 0.4911 - val_loss: 3.0782 - val_accuracy10: 0.5657 - 87s/epoch - 48ms/step
Epoch 3/50
1806/1806 - 87s - loss: 2.7448 - accuracy10: 0.5283 - val_loss: 3.0108 - val_accuracy10: 0.5438 - 87s/epoch - 48ms/step
Epoch 4/50
1806/1806 - 89s - loss: 2.6867 - accuracy10: 0.5490 - val_loss: 2.9112 - val_accuracy10: 0.5704 - 89s/epoch - 49ms/step
Epoch 5/50
1806/1806 - 89s - loss: 2.6435 - accuracy10: 0.5631 - val_loss: 2.9084 - val_accuracy10: 0.5612 - 89s/epoch - 49ms/step
Epoch 6/50
1806/1806 - 88s - loss: 2.6131 - accuracy10: 0.5710 - val_loss: 2.8873 - val_accuracy10: 0.5374 - 88s/epoch - 49ms/step
Epoch 7/50
1806/1806 - 87s - loss: 2.5922 - accuracy10: 0.5757 - val_loss: 2.9041 - val_accuracy10: 0.5528 - 87s/epoch - 48ms/step
Epoch 8/50
1806/1806 - 87s - loss: 2.5749 - accuracy10: 0.5797 - val_loss: 2.8992 - val_accuracy10: 0.5507 - 87s/epoch - 48ms/step
Epoch 9/50
1806/1806 - 87s - loss: 2.5606 - accuracy10: 0.5825 - val_loss: 2.8747 - val_accuracy10: 0.5613 - 87s/epoch - 48ms/step
Epoch 10/50
1806/1806 - 86s - loss: 2.5471 - accuracy10: 0.5849 - val_loss: 2.8558 - val_accuracy10: 0.5616 - 86s/epoch - 48ms/step
Epoch 11/50
1806/1806 - 87s - loss: 2.5364 - accuracy10: 0.5866 - val_loss: 2.8482 - val_accuracy10: 0.5673 - 87s/epoch - 48ms/step
Epoch 12/50
1806/1806 - 87s - loss: 2.5258 - accuracy10: 0.5883 - val_loss: 2.8472 - val_accuracy10: 0.5616 - 87s/epoch - 48ms/step
Epoch 13/50
1806/1806 - 86s - loss: 2.5167 - accuracy10: 0.5894 - val_loss: 2.8288 - val_accuracy10: 0.5671 - 86s/epoch - 48ms/step
Epoch 14/50
1806/1806 - 86s - loss: 2.5082 - accuracy10: 0.5908 - val_loss: 2.8483 - val_accuracy10: 0.5664 - 86s/epoch - 48ms/step
Epoch 15/50
1806/1806 - 86s - loss: 2.5007 - accuracy10: 0.5910 - val_loss: 2.8434 - val_accuracy10: 0.5642 - 86s/epoch - 48ms/step
Epoch 16/50
1806/1806 - 86s - loss: 2.4936 - accuracy10: 0.5919 - val_loss: 2.8394 - val_accuracy10: 0.5726 - 86s/epoch - 48ms/step
Epoch 17/50
1806/1806 - 85s - loss: 2.4876 - accuracy10: 0.5935 - val_loss: 2.8630 - val_accuracy10: 0.5681 - 85s/epoch - 47ms/step
Epoch 18/50
1806/1806 - 86s - loss: 2.4817 - accuracy10: 0.5934 - val_loss: 2.8624 - val_accuracy10: 0.5693 - 86s/epoch - 48ms/step
Epoch 19/50
1806/1806 - 87s - loss: 2.4763 - accuracy10: 0.5947 - val_loss: 2.9064 - val_accuracy10: 0.5662 - 87s/epoch - 48ms/step
Epoch 20/50
1806/1806 - 86s - loss: 2.4715 - accuracy10: 0.5941 - val_loss: 2.8518 - val_accuracy10: 0.5732 - 86s/epoch - 48ms/step
Epoch 21/50
1806/1806 - 87s - loss: 2.4649 - accuracy10: 0.5959 - val_loss: 2.8506 - val_accuracy10: 0.5753 - 87s/epoch - 48ms/step
Epoch 22/50
1806/1806 - 87s - loss: 2.4598 - accuracy10: 0.5967 - val_loss: 2.8849 - val_accuracy10: 0.5717 - 87s/epoch - 48ms/step
Epoch 23/50
1806/1806 - 89s - loss: 2.4538 - accuracy10: 0.5974 - val_loss: 2.8538 - val_accuracy10: 0.5733 - 89s/epoch - 49ms/step
testing model: results/ATVI/W5/deepLOB_L2/h10
Evaluating performance on  test set...
8238/8238 - 170s - 170s/epoch - 21ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.98897994
{'0': {'precision': 0.49248812114720664, 'recall': 0.32833539075111573, 'f1-score': 0.3939976800206018, 'support': 526550}, '1': {'precision': 0.6775162840723565, 'recall': 0.5333630758862252, 'f1-score': 0.5968590780970914, 'support': 1053485}, '2': {'precision': 0.39037542603292785, 'recall': 0.6854783337337023, 'f1-score': 0.4974540343209489, 'support': 528679}, 'accuracy': 0.5203043181768604, 'macro avg': {'precision': 0.520126610417497, 'recall': 0.5157256001236811, 'f1-score': 0.49610359747954735, 'support': 2108714}, 'weighted avg': {'precision': 0.5593248551371548, 'recall': 0.5203043181768604, 'f1-score': 0.521282196502099, 'support': 2108714}}
[[172885 160906 192759]
 [118420 561890 373175]
 [ 59739 106542 362398]]
Evaluating performance on  train set...
1806/1806 - 39s - 39s/epoch - 21ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.9001636
{'0': {'precision': 0.4809617285497501, 'recall': 0.38998261576321314, 'f1-score': 0.43072031917214726, 'support': 88586}, '1': {'precision': 0.8130225817886111, 'recall': 0.5467730061349694, 'f1-score': 0.6538318039095676, 'support': 285250}, '2': {'precision': 0.34242662394583323, 'recall': 0.7695381933044256, 'f1-score': 0.47395450187396493, 'support': 88327}, 'accuracy': 0.559294015314943, 'macro avg': {'precision': 0.5454703114280649, 'recall': 0.568764605067536, 'f1-score': 0.51950220831856, 'support': 462163}, 'weighted avg': {'precision': 0.6594354882449982, 'recall': 0.559294015314943, 'f1-score': 0.5766889420970732, 'support': 462163}}
[[ 34547  22696  31343]
 [ 30099 155967  99184]
 [  7183  13173  67971]]
Evaluating performance on  val set...
642/642 - 13s - 13s/epoch - 21ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.8984102
{'0': {'precision': 0.4862462506401346, 'recall': 0.395025407863065, 'f1-score': 0.43591467313777893, 'support': 33651}, '1': {'precision': 0.8060147090948809, 'recall': 0.5673617091073113, 'f1-score': 0.6659527233128576, 'support': 97548}, '2': {'precision': 0.3571334475036227, 'recall': 0.7366180599583371, 'f1-score': 0.4810433548234459, 'support': 33123}, 'accuracy': 0.5661871204099268, 'macro avg': {'precision': 0.5497981357462128, 'recall': 0.5663350589762378, 'f1-score': 0.5276369170913607, 'support': 164322}, 'weighted avg': {'precision': 0.6500476296828246, 'recall': 0.5661871204099268, 'f1-score': 0.5815710614604194, 'support': 164322}}
[[13293  8145 12213]
 [10496 55345 31707]
 [ 3549  5175 24399]]
training model: results/ATVI/W5/deepLOB_L2/h20
Epoch 1/50
1806/1806 - 91s - loss: 3.0684 - accuracy20: 0.4579 - val_loss: 3.3728 - val_accuracy20: 0.4826 - 91s/epoch - 51ms/step
Epoch 2/50
1806/1806 - 91s - loss: 2.9057 - accuracy20: 0.5013 - val_loss: 3.1445 - val_accuracy20: 0.5165 - 91s/epoch - 50ms/step
Epoch 3/50
1806/1806 - 88s - loss: 2.8333 - accuracy20: 0.5258 - val_loss: 3.1469 - val_accuracy20: 0.4792 - 88s/epoch - 49ms/step
Epoch 4/50
1806/1806 - 89s - loss: 2.7856 - accuracy20: 0.5423 - val_loss: 3.1672 - val_accuracy20: 0.4989 - 89s/epoch - 49ms/step
Epoch 5/50
1806/1806 - 87s - loss: 2.7494 - accuracy20: 0.5539 - val_loss: 3.1019 - val_accuracy20: 0.4991 - 87s/epoch - 48ms/step
Epoch 6/50
1806/1806 - 87s - loss: 2.7212 - accuracy20: 0.5620 - val_loss: 3.1141 - val_accuracy20: 0.5157 - 87s/epoch - 48ms/step
Epoch 7/50
1806/1806 - 88s - loss: 2.6973 - accuracy20: 0.5675 - val_loss: 3.0495 - val_accuracy20: 0.5233 - 88s/epoch - 49ms/step
Epoch 8/50
1806/1806 - 88s - loss: 2.6793 - accuracy20: 0.5719 - val_loss: 2.9711 - val_accuracy20: 0.5520 - 88s/epoch - 49ms/step
Epoch 9/50
1806/1806 - 88s - loss: 2.6644 - accuracy20: 0.5751 - val_loss: 2.9547 - val_accuracy20: 0.5500 - 88s/epoch - 48ms/step
Epoch 10/50
1806/1806 - 87s - loss: 2.6542 - accuracy20: 0.5775 - val_loss: 2.9516 - val_accuracy20: 0.5473 - 87s/epoch - 48ms/step
Epoch 11/50
1806/1806 - 87s - loss: 2.6441 - accuracy20: 0.5799 - val_loss: 2.9456 - val_accuracy20: 0.5597 - 87s/epoch - 48ms/step
Epoch 12/50
1806/1806 - 86s - loss: 2.6352 - accuracy20: 0.5809 - val_loss: 2.9440 - val_accuracy20: 0.5504 - 86s/epoch - 48ms/step
Epoch 13/50
1806/1806 - 87s - loss: 2.6284 - accuracy20: 0.5823 - val_loss: 2.9801 - val_accuracy20: 0.5511 - 87s/epoch - 48ms/step
Epoch 14/50
1806/1806 - 88s - loss: 2.6213 - accuracy20: 0.5827 - val_loss: 2.9789 - val_accuracy20: 0.5415 - 88s/epoch - 49ms/step
Epoch 15/50
1806/1806 - 88s - loss: 2.6146 - accuracy20: 0.5845 - val_loss: 2.9551 - val_accuracy20: 0.5514 - 88s/epoch - 48ms/step
Epoch 16/50
1806/1806 - 88s - loss: 2.6083 - accuracy20: 0.5855 - val_loss: 2.9529 - val_accuracy20: 0.5387 - 88s/epoch - 49ms/step
Epoch 17/50
1806/1806 - 89s - loss: 2.6028 - accuracy20: 0.5861 - val_loss: 2.9690 - val_accuracy20: 0.5325 - 89s/epoch - 49ms/step
Epoch 18/50
1806/1806 - 86s - loss: 2.5976 - accuracy20: 0.5870 - val_loss: 2.9789 - val_accuracy20: 0.5349 - 86s/epoch - 48ms/step
Epoch 19/50
1806/1806 - 86s - loss: 2.5918 - accuracy20: 0.5886 - val_loss: 2.9702 - val_accuracy20: 0.5340 - 86s/epoch - 48ms/step
Epoch 20/50
1806/1806 - 86s - loss: 2.5867 - accuracy20: 0.5900 - val_loss: 2.9916 - val_accuracy20: 0.5118 - 86s/epoch - 48ms/step
Epoch 21/50
1806/1806 - 87s - loss: 2.5816 - accuracy20: 0.5905 - val_loss: 2.9641 - val_accuracy20: 0.5165 - 87s/epoch - 48ms/step
Epoch 22/50
1806/1806 - 87s - loss: 2.5771 - accuracy20: 0.5911 - val_loss: 2.9670 - val_accuracy20: 0.5141 - 87s/epoch - 48ms/step
testing model: results/ATVI/W5/deepLOB_L2/h20
Evaluating performance on  test set...
8238/8238 - 158s - 158s/epoch - 19ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 1.0538763
{'0': {'precision': 0.5589992320439756, 'recall': 0.21083650421971803, 'f1-score': 0.3061885500864533, 'support': 655968}, '1': {'precision': 0.5000295476258483, 'recall': 0.6357999644332234, 'f1-score': 0.5598001552534777, 'support': 798498}, '2': {'precision': 0.43810239788934674, 'recall': 0.5665007764639709, 'f1-score': 0.4940962857992244, 'support': 654248}, 'accuracy': 0.4821037845815032, 'macro avg': {'precision': 0.4990437258530569, 'recall': 0.4710457483723041, 'f1-score': 0.45336166371305175, 'support': 2108714}, 'weighted avg': {'precision': 0.49916006607812935, 'recall': 0.4821037845815032, 'f1-score': 0.4605227176299266, 'support': 2108714}}
[[138302 284260 233406]
 [ 48857 507685 241956]
 [ 60251 223365 370632]]
Evaluating performance on  train set...
1806/1806 - 35s - 35s/epoch - 20ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.9355934
{'0': {'precision': 0.5217365779199812, 'recall': 0.3102731954263769, 'f1-score': 0.3891321481740958, 'support': 114570}, '1': {'precision': 0.6678196581235635, 'recall': 0.626459494213459, 'f1-score': 0.6464787206043998, 'support': 233300}, '2': {'precision': 0.4077224308988572, 'recall': 0.6249201613397146, 'f1-score': 0.49347948499158806, 'support': 114293}, 'accuracy': 0.5476963755211905, 'macro avg': {'precision': 0.532426222314134, 'recall': 0.5205509503265168, 'f1-score': 0.5096967845900279, 'support': 462163}, 'weighted avg': {'precision': 0.5672836331927106, 'recall': 0.5476963755211905, 'f1-score': 0.544845880157988, 'support': 462163}}
[[ 35548  42491  36531]
 [ 19924 146153  67223]
 [ 12662  30207  71424]]
Evaluating performance on  val set...
642/642 - 12s - 12s/epoch - 19ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.92968225
{'0': {'precision': 0.5047950131862863, 'recall': 0.39296379245987306, 'f1-score': 0.4419141567845524, 'support': 42864}, '1': {'precision': 0.6694506385566592, 'recall': 0.6251151521270017, 'f1-score': 0.6465237082185881, 'support': 79243}, '2': {'precision': 0.42061833950736494, 'recall': 0.5675233921591851, 'f1-score': 0.48315082582128377, 'support': 42215}, 'accuracy': 0.5497620525553486, 'macro avg': {'precision': 0.5316213304167702, 'recall': 0.5285341122486866, 'f1-score': 0.5238628969414748, 'support': 164322}, 'weighted avg': {'precision': 0.5625735665258804, 'recall': 0.5497620525553486, 'f1-score': 0.5511793840071574, 'support': 164322}}
[[16844 13606 12414]
 [ 9120 49536 20587]
 [ 7404 10853 23958]]
training model: results/ATVI/W5/deepLOB_L2/h30
Epoch 1/50
1806/1806 - 89s - loss: 3.0871 - accuracy30: 0.4603 - val_loss: 3.2923 - val_accuracy30: 0.4452 - 89s/epoch - 49ms/step
Epoch 2/50
1806/1806 - 87s - loss: 2.9785 - accuracy30: 0.4921 - val_loss: 3.1978 - val_accuracy30: 0.4835 - 87s/epoch - 48ms/step
Epoch 3/50
1806/1806 - 88s - loss: 2.9335 - accuracy30: 0.5088 - val_loss: 3.1598 - val_accuracy30: 0.4994 - 88s/epoch - 48ms/step
Epoch 4/50
1806/1806 - 87s - loss: 2.9023 - accuracy30: 0.5180 - val_loss: 3.1512 - val_accuracy30: 0.5032 - 87s/epoch - 48ms/step
Epoch 5/50
1806/1806 - 89s - loss: 2.8737 - accuracy30: 0.5258 - val_loss: 3.1999 - val_accuracy30: 0.4835 - 89s/epoch - 49ms/step
Epoch 6/50
1806/1806 - 88s - loss: 2.8387 - accuracy30: 0.5363 - val_loss: 3.1275 - val_accuracy30: 0.4924 - 88s/epoch - 49ms/step
Epoch 7/50
1806/1806 - 87s - loss: 2.8147 - accuracy30: 0.5433 - val_loss: 3.2514 - val_accuracy30: 0.4629 - 87s/epoch - 48ms/step
Epoch 8/50
1806/1806 - 87s - loss: 2.7989 - accuracy30: 0.5473 - val_loss: 3.1355 - val_accuracy30: 0.4892 - 87s/epoch - 48ms/step
Epoch 9/50
1806/1806 - 87s - loss: 2.7844 - accuracy30: 0.5512 - val_loss: 3.1712 - val_accuracy30: 0.4746 - 87s/epoch - 48ms/step
Epoch 10/50
1806/1806 - 87s - loss: 2.7728 - accuracy30: 0.5539 - val_loss: 3.1539 - val_accuracy30: 0.4782 - 87s/epoch - 48ms/step
Epoch 11/50
1806/1806 - 88s - loss: 2.7635 - accuracy30: 0.5560 - val_loss: 3.2409 - val_accuracy30: 0.4585 - 88s/epoch - 49ms/step
Epoch 12/50
1806/1806 - 88s - loss: 2.7550 - accuracy30: 0.5581 - val_loss: 3.1236 - val_accuracy30: 0.4894 - 88s/epoch - 49ms/step
Epoch 13/50
1806/1806 - 89s - loss: 2.7464 - accuracy30: 0.5596 - val_loss: 3.1988 - val_accuracy30: 0.4800 - 89s/epoch - 49ms/step
Epoch 14/50
1806/1806 - 88s - loss: 2.7397 - accuracy30: 0.5620 - val_loss: 3.1237 - val_accuracy30: 0.4910 - 88s/epoch - 49ms/step
Epoch 15/50
1806/1806 - 87s - loss: 2.7325 - accuracy30: 0.5635 - val_loss: 3.1076 - val_accuracy30: 0.5010 - 87s/epoch - 48ms/step
Epoch 16/50
1806/1806 - 87s - loss: 2.7254 - accuracy30: 0.5652 - val_loss: 3.1482 - val_accuracy30: 0.4952 - 87s/epoch - 48ms/step
Epoch 17/50
1806/1806 - 86s - loss: 2.7198 - accuracy30: 0.5671 - val_loss: 3.1950 - val_accuracy30: 0.4735 - 86s/epoch - 48ms/step
Epoch 18/50
1806/1806 - 87s - loss: 2.7138 - accuracy30: 0.5676 - val_loss: 3.1453 - val_accuracy30: 0.4932 - 87s/epoch - 48ms/step
Epoch 19/50
1806/1806 - 87s - loss: 2.7082 - accuracy30: 0.5688 - val_loss: 3.1454 - val_accuracy30: 0.4975 - 87s/epoch - 48ms/step
Epoch 20/50
1806/1806 - 88s - loss: 2.7018 - accuracy30: 0.5707 - val_loss: 3.1525 - val_accuracy30: 0.4937 - 88s/epoch - 49ms/step
Epoch 21/50
1806/1806 - 88s - loss: 2.6965 - accuracy30: 0.5714 - val_loss: 3.1477 - val_accuracy30: 0.4942 - 88s/epoch - 49ms/step
Epoch 22/50
1806/1806 - 87s - loss: 2.6921 - accuracy30: 0.5727 - val_loss: 3.1439 - val_accuracy30: 0.4952 - 87s/epoch - 48ms/step
Epoch 23/50
1806/1806 - 87s - loss: 2.6874 - accuracy30: 0.5738 - val_loss: 3.0930 - val_accuracy30: 0.5059 - 87s/epoch - 48ms/step
Epoch 24/50
1806/1806 - 87s - loss: 2.6819 - accuracy30: 0.5749 - val_loss: 3.2147 - val_accuracy30: 0.4839 - 87s/epoch - 48ms/step
Epoch 25/50
1806/1806 - 88s - loss: 2.6760 - accuracy30: 0.5759 - val_loss: 3.1725 - val_accuracy30: 0.4934 - 88s/epoch - 49ms/step
Epoch 26/50
1806/1806 - 87s - loss: 2.6725 - accuracy30: 0.5764 - val_loss: 3.2168 - val_accuracy30: 0.4901 - 87s/epoch - 48ms/step
Epoch 27/50
1806/1806 - 88s - loss: 2.6672 - accuracy30: 0.5782 - val_loss: 3.1862 - val_accuracy30: 0.4934 - 88s/epoch - 49ms/step
Epoch 28/50
1806/1806 - 88s - loss: 2.6637 - accuracy30: 0.5783 - val_loss: 3.1689 - val_accuracy30: 0.4948 - 88s/epoch - 49ms/step
Epoch 29/50
1806/1806 - 87s - loss: 2.6581 - accuracy30: 0.5794 - val_loss: 3.1216 - val_accuracy30: 0.5030 - 87s/epoch - 48ms/step
Epoch 30/50
1806/1806 - 86s - loss: 2.6537 - accuracy30: 0.5804 - val_loss: 3.1233 - val_accuracy30: 0.5086 - 86s/epoch - 48ms/step
Epoch 31/50
1806/1806 - 91s - loss: 2.6491 - accuracy30: 0.5815 - val_loss: 3.1355 - val_accuracy30: 0.5046 - 91s/epoch - 50ms/step
Epoch 32/50
1806/1806 - 88s - loss: 2.6457 - accuracy30: 0.5825 - val_loss: 3.1165 - val_accuracy30: 0.5031 - 88s/epoch - 49ms/step
Epoch 33/50
1806/1806 - 88s - loss: 2.6404 - accuracy30: 0.5838 - val_loss: 3.0583 - val_accuracy30: 0.5163 - 88s/epoch - 49ms/step
Epoch 34/50
1806/1806 - 90s - loss: 2.6366 - accuracy30: 0.5844 - val_loss: 3.1122 - val_accuracy30: 0.5038 - 90s/epoch - 50ms/step
Epoch 35/50
1806/1806 - 88s - loss: 2.6323 - accuracy30: 0.5851 - val_loss: 3.1172 - val_accuracy30: 0.5059 - 88s/epoch - 49ms/step
Epoch 36/50
1806/1806 - 86s - loss: 2.6295 - accuracy30: 0.5861 - val_loss: 3.0926 - val_accuracy30: 0.5054 - 86s/epoch - 48ms/step
Epoch 37/50
1806/1806 - 86s - loss: 2.6261 - accuracy30: 0.5867 - val_loss: 3.1159 - val_accuracy30: 0.5042 - 86s/epoch - 48ms/step
Epoch 38/50
1806/1806 - 87s - loss: 2.6211 - accuracy30: 0.5878 - val_loss: 3.0824 - val_accuracy30: 0.5116 - 87s/epoch - 48ms/step
Epoch 39/50
1806/1806 - 87s - loss: 2.6187 - accuracy30: 0.5888 - val_loss: 3.0939 - val_accuracy30: 0.5062 - 87s/epoch - 48ms/step
Epoch 40/50
1806/1806 - 89s - loss: 2.6130 - accuracy30: 0.5893 - val_loss: 3.1567 - val_accuracy30: 0.4910 - 89s/epoch - 49ms/step
Epoch 41/50
1806/1806 - 92s - loss: 2.6105 - accuracy30: 0.5894 - val_loss: 3.1651 - val_accuracy30: 0.4841 - 92s/epoch - 51ms/step
Epoch 42/50
1806/1806 - 88s - loss: 2.6061 - accuracy30: 0.5908 - val_loss: 3.1823 - val_accuracy30: 0.4831 - 88s/epoch - 49ms/step
Epoch 43/50
1806/1806 - 86s - loss: 2.6029 - accuracy30: 0.5911 - val_loss: 3.1908 - val_accuracy30: 0.4778 - 86s/epoch - 47ms/step
testing model: results/ATVI/W5/deepLOB_L2/h30
Evaluating performance on  test set...
8238/8238 - 156s - 156s/epoch - 19ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.1591437
{'0': {'precision': 0.5662203185019993, 'recall': 0.156733119950398, 'f1-score': 0.24550814029766824, 'support': 735454}, '1': {'precision': 0.3842258200836658, 'recall': 0.6183588217309648, 'f1-score': 0.473953849832616, 'support': 641076}, '2': {'precision': 0.46181298173141655, 'recall': 0.5508902133889841, 'f1-score': 0.5024339871300127, 'support': 732184}, 'accuracy': 0.4339317707379948, 'macro avg': {'precision': 0.47075304010569385, 'recall': 0.4419940516901157, 'f1-score': 0.4072986590867657, 'support': 2108714}, 'weighted avg': {'precision': 0.4746395320444408, 'recall': 0.4339317707379948, 'f1-score': 0.40416789971640377, 'support': 2108714}}
[[115270 355609 264575]
 [ 39177 396415 205484]
 [ 49131 279700 403353]]
Evaluating performance on  train set...
1806/1806 - 36s - 36s/epoch - 20ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.0030539
{'0': {'precision': 0.5075629648259261, 'recall': 0.32158954668932965, 'f1-score': 0.3937199526209443, 'support': 131786}, '1': {'precision': 0.5754191229596086, 'recall': 0.6280917840422753, 'f1-score': 0.6006028219753827, 'support': 199076}, '2': {'precision': 0.44197316642394574, 'recall': 0.5431717961020861, 'f1-score': 0.4873746865027028, 'support': 131301}, 'accuracy': 0.5165666658732958, 'macro avg': {'precision': 0.5083184180698268, 'recall': 0.4976177089445637, 'f1-score': 0.49389915369967663, 'support': 462163}, 'weighted avg': {'precision': 0.5181577688596599, 'recall': 0.5165666658732958, 'f1-score': 0.509441839299482, 'support': 462163}}
[[ 42381  52212  37193]
 [ 21185 125038  52853]
 [ 19933  40049  71319]]
Evaluating performance on  val set...
642/642 - 12s - 12s/epoch - 19ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.98735696
{'0': {'precision': 0.49649853085210577, 'recall': 0.4168448318394869, 'f1-score': 0.45319833713289526, 'support': 48644}, '1': {'precision': 0.5742084209098922, 'recall': 0.626396059229893, 'f1-score': 0.5991679990944208, 'support': 67601}, '2': {'precision': 0.4516356032732171, 'recall': 0.4672296524325561, 'f1-score': 0.4593003046598646, 'support': 48077}, 'accuracy': 0.5177943306434927, 'macro avg': {'precision': 0.5074475183450717, 'recall': 0.503490181167312, 'f1-score': 0.5038888802957269, 'support': 164322}, 'weighted avg': {'precision': 0.5153419681799511, 'recall': 0.5177943306434927, 'f1-score': 0.5150346062329256, 'support': 164322}}
[[20277 17281 11086]
 [ 9068 42345 16188]
 [11495 14119 22463]]
training model: results/ATVI/W5/deepLOB_L2/h50
Epoch 1/50
1806/1806 - 89s - loss: 3.1422 - accuracy50: 0.4441 - val_loss: 3.2586 - val_accuracy50: 0.3968 - 89s/epoch - 49ms/step
Epoch 2/50
1806/1806 - 86s - loss: 3.0488 - accuracy50: 0.4761 - val_loss: 3.1588 - val_accuracy50: 0.4432 - 86s/epoch - 48ms/step
Epoch 3/50
1806/1806 - 87s - loss: 3.0122 - accuracy50: 0.4882 - val_loss: 3.1639 - val_accuracy50: 0.4399 - 87s/epoch - 48ms/step
Epoch 4/50
1806/1806 - 88s - loss: 2.9848 - accuracy50: 0.4955 - val_loss: 3.2222 - val_accuracy50: 0.4276 - 88s/epoch - 49ms/step
Epoch 5/50
1806/1806 - 87s - loss: 2.9629 - accuracy50: 0.5011 - val_loss: 3.1715 - val_accuracy50: 0.4340 - 87s/epoch - 48ms/step
Epoch 6/50
1806/1806 - 88s - loss: 2.9448 - accuracy50: 0.5048 - val_loss: 3.1265 - val_accuracy50: 0.4523 - 88s/epoch - 49ms/step
Epoch 7/50
1806/1806 - 87s - loss: 2.9282 - accuracy50: 0.5096 - val_loss: 3.1046 - val_accuracy50: 0.4593 - 87s/epoch - 48ms/step
Epoch 8/50
1806/1806 - 86s - loss: 2.9142 - accuracy50: 0.5127 - val_loss: 3.1401 - val_accuracy50: 0.4519 - 86s/epoch - 48ms/step
Epoch 9/50
1806/1806 - 87s - loss: 2.9021 - accuracy50: 0.5161 - val_loss: 3.1397 - val_accuracy50: 0.4540 - 87s/epoch - 48ms/step
Epoch 10/50
1806/1806 - 87s - loss: 2.8912 - accuracy50: 0.5189 - val_loss: 3.1442 - val_accuracy50: 0.4515 - 87s/epoch - 48ms/step
Epoch 11/50
1806/1806 - 88s - loss: 2.8832 - accuracy50: 0.5212 - val_loss: 3.1560 - val_accuracy50: 0.4529 - 88s/epoch - 49ms/step
Epoch 12/50
1806/1806 - 89s - loss: 2.8734 - accuracy50: 0.5240 - val_loss: 3.2165 - val_accuracy50: 0.4384 - 89s/epoch - 49ms/step
Epoch 13/50
1806/1806 - 88s - loss: 2.8701 - accuracy50: 0.5247 - val_loss: 3.1708 - val_accuracy50: 0.4489 - 88s/epoch - 49ms/step
Epoch 14/50
1806/1806 - 88s - loss: 2.8603 - accuracy50: 0.5275 - val_loss: 3.1902 - val_accuracy50: 0.4478 - 88s/epoch - 49ms/step
Epoch 15/50
1806/1806 - 90s - loss: 2.8542 - accuracy50: 0.5285 - val_loss: 3.1428 - val_accuracy50: 0.4590 - 90s/epoch - 50ms/step
Epoch 16/50
1806/1806 - 88s - loss: 2.8484 - accuracy50: 0.5299 - val_loss: 3.1175 - val_accuracy50: 0.4624 - 88s/epoch - 49ms/step
Epoch 17/50
1806/1806 - 88s - loss: 2.8426 - accuracy50: 0.5308 - val_loss: 3.1512 - val_accuracy50: 0.4609 - 88s/epoch - 49ms/step
testing model: results/ATVI/W5/deepLOB_L2/h50
Evaluating performance on  test set...
8238/8238 - 157s - 157s/epoch - 19ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.1325293
{'0': {'precision': 0.5693555531173934, 'recall': 0.16888738349975652, 'f1-score': 0.26050224086849577, 'support': 829612}, '1': {'precision': 0.29519085967199865, 'recall': 0.5615652861269846, 'f1-score': 0.3869687784245439, 'support': 457961}, '2': {'precision': 0.48503193932687855, 'recall': 0.5856071003640057, 'f1-score': 0.5305955360177252, 'support': 821141}, 'accuracy': 0.41643959304106676, 'macro avg': {'precision': 0.4498594507054235, 'recall': 0.4386865899969156, 'f1-score': 0.392688851770255, 'support': 2108714}, 'weighted avg': {'precision': 0.4769777751320888, 'recall': 0.41643959304106676, 'f1-score': 0.39314299749923787, 'support': 2108714}}
[[140111 343498 346003]
 [ 36244 257175 164542]
 [ 69732 270543 480866]]
Evaluating performance on  train set...
1806/1806 - 36s - 36s/epoch - 20ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0396225
{'0': {'precision': 0.5683869996990671, 'recall': 0.19537487797151484, 'f1-score': 0.2907936202458563, 'support': 154677}, '1': {'precision': 0.44579414773485415, 'recall': 0.5851604867796258, 'f1-score': 0.5060574185495295, 'support': 154156}, '2': {'precision': 0.4542551029296478, 'recall': 0.612208961064371, 'f1-score': 0.5215347689845989, 'support': 153330}, 'accuracy': 0.46368056291827775, 'macro avg': {'precision': 0.4894787501211897, 'recall': 0.4642481086051706, 'f1-score': 0.4394619359266616, 'support': 462163}, 'weighted avg': {'precision': 0.48963065741495904, 'recall': 0.46368056291827775, 'f1-score': 0.4391476564352796, 'support': 462163}}
[[30220 64121 60336]
 [11510 90206 52440]
 [11438 48022 93870]]
Evaluating performance on  val set...
642/642 - 13s - 13s/epoch - 20ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0352857
{'0': {'precision': 0.5642718026401212, 'recall': 0.18624002285591842, 'f1-score': 0.28004886758763275, 'support': 56003}, '1': {'precision': 0.43745026594630815, 'recall': 0.5942988279027425, 'f1-score': 0.5039523307895817, 'support': 52726}, '2': {'precision': 0.4556712978559974, 'recall': 0.6082420448617631, 'f1-score': 0.5210169491525424, 'support': 55593}, 'accuracy': 0.459944499214956, 'macro avg': {'precision': 0.48579778881414226, 'recall': 0.46292696520680804, 'f1-score': 0.43500604917658564, 'support': 164322}, 'weighted avg': {'precision': 0.48683713043444105, 'recall': 0.459944499214956, 'f1-score': 0.4334164784931961, 'support': 164322}}
[[10430 23003 22570]
 [ 3568 31335 17823]
 [ 4486 17293 33814]]
training model: results/ATVI/W5/deepLOB_L2/h100
Epoch 1/50
1806/1806 - 90s - loss: 3.2664 - accuracy100: 0.3881 - val_loss: 3.3177 - val_accuracy100: 0.3591 - 90s/epoch - 50ms/step
Epoch 2/50
1806/1806 - 88s - loss: 3.2043 - accuracy100: 0.4163 - val_loss: 3.2839 - val_accuracy100: 0.3609 - 88s/epoch - 49ms/step
Epoch 3/50
1806/1806 - 87s - loss: 3.1892 - accuracy100: 0.4243 - val_loss: 3.2771 - val_accuracy100: 0.3721 - 87s/epoch - 48ms/step
Epoch 4/50
1806/1806 - 87s - loss: 3.1786 - accuracy100: 0.4298 - val_loss: 3.2347 - val_accuracy100: 0.3974 - 87s/epoch - 48ms/step
Epoch 5/50
1806/1806 - 87s - loss: 3.1660 - accuracy100: 0.4352 - val_loss: 3.2638 - val_accuracy100: 0.3936 - 87s/epoch - 48ms/step
Epoch 6/50
1806/1806 - 87s - loss: 3.1573 - accuracy100: 0.4380 - val_loss: 3.2706 - val_accuracy100: 0.3926 - 87s/epoch - 48ms/step
Epoch 7/50
1806/1806 - 88s - loss: 3.1492 - accuracy100: 0.4419 - val_loss: 3.2826 - val_accuracy100: 0.3891 - 88s/epoch - 49ms/step
Epoch 8/50
1806/1806 - 94s - loss: 3.1408 - accuracy100: 0.4446 - val_loss: 3.2787 - val_accuracy100: 0.3888 - 94s/epoch - 52ms/step
Epoch 9/50
1806/1806 - 90s - loss: 3.1360 - accuracy100: 0.4470 - val_loss: 3.2827 - val_accuracy100: 0.3896 - 90s/epoch - 50ms/step
Epoch 10/50
1806/1806 - 90s - loss: 3.1291 - accuracy100: 0.4497 - val_loss: 3.2901 - val_accuracy100: 0.3915 - 90s/epoch - 50ms/step
Epoch 11/50
1806/1806 - 87s - loss: 3.1224 - accuracy100: 0.4519 - val_loss: 3.2951 - val_accuracy100: 0.3892 - 87s/epoch - 48ms/step
Epoch 12/50
1806/1806 - 89s - loss: 3.1153 - accuracy100: 0.4553 - val_loss: 3.3384 - val_accuracy100: 0.3825 - 89s/epoch - 49ms/step
Epoch 13/50
1806/1806 - 88s - loss: 3.1099 - accuracy100: 0.4577 - val_loss: 3.3121 - val_accuracy100: 0.3888 - 88s/epoch - 49ms/step
Epoch 14/50
1806/1806 - 87s - loss: 3.1034 - accuracy100: 0.4600 - val_loss: 3.3334 - val_accuracy100: 0.3863 - 87s/epoch - 48ms/step
testing model: results/ATVI/W5/deepLOB_L2/h100
Evaluating performance on  test set...
8238/8238 - 156s - 156s/epoch - 19ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.1452101
{'0': {'precision': 0.4398494503658896, 'recall': 0.15720186772484085, 'f1-score': 0.23162215045894916, 'support': 787268}, '1': {'precision': 0.26259349110091257, 'recall': 0.725968320123981, 'f1-score': 0.38568059871504085, 'support': 531694}, '2': {'precision': 0.4650955880912878, 'recall': 0.2104888623264012, 'f1-score': 0.2898155549608559, 'support': 789752}, 'accuracy': 0.32056836536391375, 'macro avg': {'precision': 0.38917950985269667, 'recall': 0.36455301672507434, 'f1-score': 0.3023727680449486, 'support': 2108714}, 'weighted avg': {'precision': 0.40461103385017244, 'recall': 0.32056836536391375, 'f1-score': 0.292261151375747, 'support': 2108714}}
[[123760 555079 108429]
 [ 62945 385993  82756]
 [ 94664 528854 166234]]
Evaluating performance on  train set...
1806/1806 - 36s - 36s/epoch - 20ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0916065
{'0': {'precision': 0.4415083050799168, 'recall': 0.20025457458906235, 'f1-score': 0.27553496972875896, 'support': 154768}, '1': {'precision': 0.3572159432889721, 'recall': 0.6951347271295736, 'f1-score': 0.47192103211328335, 'support': 153681}, '2': {'precision': 0.4387492599967709, 'recall': 0.2651807902988667, 'f1-score': 0.3305665824612053, 'support': 153714}, 'accuracy': 0.38640912405363476, 'macro avg': {'precision': 0.41249116945521996, 'recall': 0.38685669733916755, 'f1-score': 0.35934086143441585, 'support': 462163}, 'weighted avg': {'precision': 0.41256129221150273, 'recall': 0.38640912405363476, 'f1-score': 0.3591416967338878, 'support': 462163}}
[[ 30993  98756  25019]
 [ 19728 106829  27124]
 [ 19477  93475  40762]]
Evaluating performance on  val set...
642/642 - 13s - 13s/epoch - 20ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0785068
{'0': {'precision': 0.41973791973791974, 'recall': 0.24504395159807274, 'f1-score': 0.3094375551530351, 'support': 54378}, '1': {'precision': 0.37634078396104326, 'recall': 0.6222955695399068, 'f1-score': 0.46902999610440205, 'support': 55141}, '2': {'precision': 0.42625247596502247, 'recall': 0.3219896720982428, 'f1-score': 0.3668568933794867, 'support': 54803}, 'accuracy': 0.3972992052190212, 'macro avg': {'precision': 0.4074437265546618, 'recall': 0.39644306441207416, 'f1-score': 0.3817748148789746, 'support': 164322}, 'weighted avg': {'precision': 0.4073479522414261, 'recall': 0.3972992052190212, 'f1-score': 0.38214138531164776, 'support': 164322}}
[[13325 28958 12095]
 [ 9170 34314 11657]
 [ 9251 27906 17646]]
training model: results/ATVI/W5/deepLOB_L2/h200
Epoch 1/50
1806/1806 - 90s - loss: 3.2891 - accuracy200: 0.3718 - val_loss: 3.3573 - val_accuracy200: 0.3536 - 90s/epoch - 50ms/step
Epoch 2/50
1806/1806 - 88s - loss: 3.2549 - accuracy200: 0.3896 - val_loss: 3.3082 - val_accuracy200: 0.3668 - 88s/epoch - 48ms/step
Epoch 3/50
1806/1806 - 87s - loss: 3.2379 - accuracy200: 0.4005 - val_loss: 3.3347 - val_accuracy200: 0.3614 - 87s/epoch - 48ms/step
Epoch 4/50
1806/1806 - 88s - loss: 3.2269 - accuracy200: 0.4071 - val_loss: 3.3683 - val_accuracy200: 0.3639 - 88s/epoch - 49ms/step
Epoch 5/50
1806/1806 - 91s - loss: 3.2185 - accuracy200: 0.4118 - val_loss: 3.3963 - val_accuracy200: 0.3551 - 91s/epoch - 50ms/step
Epoch 6/50
1806/1806 - 87s - loss: 3.2126 - accuracy200: 0.4152 - val_loss: 3.3907 - val_accuracy200: 0.3573 - 87s/epoch - 48ms/step
Epoch 7/50
1806/1806 - 90s - loss: 3.2049 - accuracy200: 0.4189 - val_loss: 3.3983 - val_accuracy200: 0.3538 - 90s/epoch - 50ms/step
Epoch 8/50
1806/1806 - 87s - loss: 3.1980 - accuracy200: 0.4216 - val_loss: 3.3604 - val_accuracy200: 0.3594 - 87s/epoch - 48ms/step
Epoch 9/50
1806/1806 - 88s - loss: 3.1924 - accuracy200: 0.4245 - val_loss: 3.3838 - val_accuracy200: 0.3617 - 88s/epoch - 49ms/step
Epoch 10/50
1806/1806 - 89s - loss: 3.1864 - accuracy200: 0.4288 - val_loss: 3.3959 - val_accuracy200: 0.3631 - 89s/epoch - 49ms/step
Epoch 11/50
1806/1806 - 89s - loss: 3.1793 - accuracy200: 0.4315 - val_loss: 3.4127 - val_accuracy200: 0.3609 - 89s/epoch - 50ms/step
Epoch 12/50
1806/1806 - 88s - loss: 3.1723 - accuracy200: 0.4349 - val_loss: 3.4577 - val_accuracy200: 0.3617 - 88s/epoch - 49ms/step
testing model: results/ATVI/W5/deepLOB_L2/h200
Evaluating performance on  test set...
8238/8238 - 155s - 155s/epoch - 19ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.11646
{'0': {'precision': 0.43694407052551004, 'recall': 0.044085670725618, 'f1-score': 0.08009056724267014, 'support': 751015}, '1': {'precision': 0.3587019382687343, 'recall': 0.10131092606781117, 'f1-score': 0.1579974316619878, 'support': 593855}, '2': {'precision': 0.36650398640798665, 'recall': 0.8949576091453229, 'f1-score': 0.5200404555701912, 'support': 763844}, 'accuracy': 0.36841458822770656, 'macro avg': {'precision': 0.38738333173407696, 'recall': 0.34678473531291737, 'f1-score': 0.2527094848249497, 'support': 2108714}, 'weighted avg': {'precision': 0.38939389678738673, 'recall': 0.36841458822770656, 'f1-score': 0.26139465279878676, 'support': 2108714}}
[[ 33109  54264 663642]
 [ 15728  60164 517963]
 [ 26937  53299 683608]]
Evaluating performance on  train set...
1806/1806 - 35s - 35s/epoch - 19ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1162539
{'0': {'precision': 0.383999436434509, 'recall': 0.10512747984622703, 'f1-score': 0.16506510548097306, 'support': 155554}, '1': {'precision': 0.38950377195959174, 'recall': 0.1959770945244881, 'f1-score': 0.26075597651335103, 'support': 152278}, '2': {'precision': 0.34223915978294783, 'recall': 0.7605341765426259, 'f1-score': 0.4720545355828592, 'support': 154331}, 'accuracy': 0.35392275019852304, 'macro avg': {'precision': 0.3719141227256828, 'recall': 0.3538795836377804, 'f1-score': 0.2992918725257278, 'support': 462163}, 'weighted avg': {'precision': 0.3718679675570274, 'recall': 0.35392275019852304, 'f1-score': 0.2991078570558993, 'support': 462163}}
[[ 16353  24436 114765]
 [ 11615  29843 110820]
 [ 14618  22339 117374]]
Evaluating performance on  val set...
642/642 - 13s - 13s/epoch - 20ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.102668
{'0': {'precision': 0.39374646826144283, 'recall': 0.1909634041620229, 'f1-score': 0.2571913678978321, 'support': 54733}, '1': {'precision': 0.40093113247475665, 'recall': 0.24575187621606598, 'f1-score': 0.30472295302321845, 'support': 53965}, '2': {'precision': 0.351206792806044, 'recall': 0.6610635696821516, 'f1-score': 0.45871147620740627, 'support': 55624}, 'accuracy': 0.3680882657221796, 'macro avg': {'precision': 0.3819614645140812, 'recall': 0.36592628335341354, 'f1-score': 0.34020859904281897, 'support': 164322}, 'weighted avg': {'precision': 0.3817060445612711, 'recall': 0.3680882657221796, 'f1-score': 0.34101700594936035, 'support': 164322}}
[[10452 10022 34259]
 [ 7034 13262 33669]
 [ 9059  9794 36771]]
training model: results/ATVI/W5/deepLOB_L2/h300
Epoch 1/50
1806/1806 - 92s - loss: 3.2915 - accuracy300: 0.3753 - val_loss: 3.3606 - val_accuracy300: 0.3353 - 92s/epoch - 51ms/step
Epoch 2/50
1806/1806 - 88s - loss: 3.2675 - accuracy300: 0.3849 - val_loss: 3.3823 - val_accuracy300: 0.3393 - 88s/epoch - 49ms/step
Epoch 3/50
1806/1806 - 86s - loss: 3.2511 - accuracy300: 0.3982 - val_loss: 3.3854 - val_accuracy300: 0.3487 - 86s/epoch - 48ms/step
Epoch 4/50
1806/1806 - 86s - loss: 3.2325 - accuracy300: 0.4103 - val_loss: 3.4061 - val_accuracy300: 0.3448 - 86s/epoch - 48ms/step
Epoch 5/50
1806/1806 - 86s - loss: 3.2198 - accuracy300: 0.4153 - val_loss: 3.4204 - val_accuracy300: 0.3480 - 86s/epoch - 48ms/step
Epoch 6/50
1806/1806 - 86s - loss: 3.2087 - accuracy300: 0.4216 - val_loss: 3.3966 - val_accuracy300: 0.3517 - 86s/epoch - 48ms/step
Epoch 7/50
1806/1806 - 86s - loss: 3.2019 - accuracy300: 0.4251 - val_loss: 3.4001 - val_accuracy300: 0.3454 - 86s/epoch - 48ms/step
Epoch 8/50
1806/1806 - 87s - loss: 3.1924 - accuracy300: 0.4303 - val_loss: 3.4110 - val_accuracy300: 0.3519 - 87s/epoch - 48ms/step
Epoch 9/50
1806/1806 - 91s - loss: 3.1824 - accuracy300: 0.4342 - val_loss: 3.4526 - val_accuracy300: 0.3510 - 91s/epoch - 51ms/step
Epoch 10/50
1806/1806 - 85s - loss: 3.1772 - accuracy300: 0.4374 - val_loss: 3.4318 - val_accuracy300: 0.3441 - 85s/epoch - 47ms/step
Epoch 11/50
1806/1806 - 88s - loss: 3.1693 - accuracy300: 0.4399 - val_loss: 3.4188 - val_accuracy300: 0.3490 - 88s/epoch - 49ms/step
testing model: results/ATVI/W5/deepLOB_L2/h300
Evaluating performance on  test set...
8238/8238 - 157s - 157s/epoch - 19ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1217514
{'0': {'precision': 0.3749611294234716, 'recall': 0.08833099582978712, 'f1-score': 0.14297972339301693, 'support': 750801}, '1': {'precision': 0.2886618490991709, 'recall': 0.6718120986546178, 'f1-score': 0.403814227545396, 'support': 592694}, '2': {'precision': 0.3714641532521554, 'recall': 0.2681781293982507, 'f1-score': 0.3114821032308594, 'support': 765219}, 'accuracy': 0.31759309228278465, 'macro avg': {'precision': 0.34502904392493267, 'recall': 0.3427737412942185, 'f1-score': 0.2860920180564241, 'support': 2108714}, 'weighted avg': {'precision': 0.34943608512568186, 'recall': 0.31759309228278465, 'f1-score': 0.2774390517804721, 'support': 2108714}}
[[ 66319 487974 196508]
 [ 43789 398179 150726]
 [ 66761 493243 205215]]
Evaluating performance on  train set...
1806/1806 - 35s - 35s/epoch - 20ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1232635
{'0': {'precision': 0.3268673832338821, 'recall': 0.10858013571709893, 'f1-score': 0.16301071099694664, 'support': 154881}, '1': {'precision': 0.3261689888541468, 'recall': 0.6598677281558479, 'f1-score': 0.43655248523142837, 'support': 152867}, '2': {'precision': 0.3327024869148653, 'recall': 0.21858627723990545, 'f1-score': 0.26383341280201356, 'support': 154415}, 'accuracy': 0.3276809264263907, 'macro avg': {'precision': 0.3285796196676314, 'recall': 0.32901138037095073, 'f1-score': 0.2877988696767962, 'support': 462163}, 'weighted avg': {'precision': 0.3285859675455904, 'recall': 0.3276809264263907, 'f1-score': 0.28717480007619345, 'support': 462163}}
[[ 16817 104439  33625]
 [ 17922 100872  34073]
 [ 16710 103952  33753]]
Evaluating performance on  val set...
642/642 - 12s - 12s/epoch - 19ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1207309
{'0': {'precision': 0.34100230069020704, 'recall': 0.12515143727743308, 'f1-score': 0.18310237404662152, 'support': 54478}, '1': {'precision': 0.33500893368555135, 'recall': 0.7196217059957764, 'f1-score': 0.45718319061063534, 'support': 54455}, '2': {'precision': 0.33957229025772256, 'recall': 0.16770477892722382, 'f1-score': 0.2245238325437494, 'support': 55389}, 'accuracy': 0.3364978517788245, 'macro avg': {'precision': 0.33852784154449367, 'recall': 0.33749264073347773, 'f1-score': 0.28826979906700206, 'support': 164322}, 'weighted avg': {'precision': 0.33853412449904935, 'recall': 0.3364978517788245, 'f1-score': 0.28789274922882957, 'support': 164322}}
[[ 6818 38358  9302]
 [ 6504 39187  8764]
 [ 6672 39428  9289]]
training model: results/ATVI/W5/deepLOB_L2/h500
Epoch 1/50
1806/1806 - 90s - loss: 3.2566 - accuracy500: 0.3975 - val_loss: 3.5994 - val_accuracy500: 0.3277 - 90s/epoch - 50ms/step
Epoch 2/50
1806/1806 - 86s - loss: 3.2300 - accuracy500: 0.4069 - val_loss: 3.5408 - val_accuracy500: 0.3344 - 86s/epoch - 48ms/step
Epoch 3/50
1806/1806 - 87s - loss: 3.2147 - accuracy500: 0.4204 - val_loss: 3.4175 - val_accuracy500: 0.3330 - 87s/epoch - 48ms/step
Epoch 4/50
1806/1806 - 87s - loss: 3.1924 - accuracy500: 0.4339 - val_loss: 3.5108 - val_accuracy500: 0.3360 - 87s/epoch - 48ms/step
Epoch 5/50
1806/1806 - 86s - loss: 3.1730 - accuracy500: 0.4414 - val_loss: 3.5742 - val_accuracy500: 0.3330 - 86s/epoch - 48ms/step
Epoch 6/50
1806/1806 - 86s - loss: 3.1602 - accuracy500: 0.4467 - val_loss: 3.6275 - val_accuracy500: 0.3503 - 86s/epoch - 48ms/step
Epoch 7/50
1806/1806 - 86s - loss: 3.1437 - accuracy500: 0.4537 - val_loss: 3.6302 - val_accuracy500: 0.3459 - 86s/epoch - 48ms/step
Epoch 8/50
1806/1806 - 90s - loss: 3.1357 - accuracy500: 0.4566 - val_loss: 3.5363 - val_accuracy500: 0.3556 - 90s/epoch - 50ms/step
Epoch 9/50
1806/1806 - 88s - loss: 3.1253 - accuracy500: 0.4614 - val_loss: 3.5445 - val_accuracy500: 0.3567 - 88s/epoch - 49ms/step
Epoch 10/50
1806/1806 - 89s - loss: 3.1148 - accuracy500: 0.4651 - val_loss: 3.4571 - val_accuracy500: 0.3774 - 89s/epoch - 49ms/step
Epoch 11/50
1806/1806 - 87s - loss: 3.1041 - accuracy500: 0.4693 - val_loss: 3.4195 - val_accuracy500: 0.3753 - 87s/epoch - 48ms/step
Epoch 12/50
1806/1806 - 87s - loss: 3.0944 - accuracy500: 0.4724 - val_loss: 3.4730 - val_accuracy500: 0.3731 - 87s/epoch - 48ms/step
Epoch 13/50
1806/1806 - 87s - loss: 3.0823 - accuracy500: 0.4767 - val_loss: 3.5067 - val_accuracy500: 0.3543 - 87s/epoch - 48ms/step
testing model: results/ATVI/W5/deepLOB_L2/h500
Evaluating performance on  test set...
8238/8238 - 159s - 159s/epoch - 19ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1738425
{'0': {'precision': 0.620253164556962, 'recall': 6.471320822993528e-05, 'f1-score': 0.0001294129143524204, 'support': 757187}, '1': {'precision': 0.279123134580036, 'recall': 0.9635210602020648, 'f1-score': 0.4328528144850651, 'support': 579814}, '2': {'precision': 0.3934311474491796, 'recall': 0.05462263820876414, 'f1-score': 0.09592708694835896, 'support': 771713}, 'accuracy': 0.28494380935489594, 'macro avg': {'precision': 0.4309358155287259, 'recall': 0.3394028038730197, 'f1-score': 0.17630310478259215, 'support': 2108714}, 'weighted avg': {'precision': 0.44344707966857055, 'recall': 0.28494380935489594, 'f1-score': 0.15416993086990566, 'support': 2108714}}
[[    49 713292  43846]
 [     8 558663  21143]
 [    22 729538  42153]]
Evaluating performance on  train set...
1806/1806 - 35s - 35s/epoch - 20ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1487455
{'0': {'precision': 0.33419881305637983, 'recall': 0.005788963062432135, 'f1-score': 0.011380789076463492, 'support': 155641}, '1': {'precision': 0.3312095503935514, 'recall': 0.9572071328052221, 'f1-score': 0.4921329383950651, 'support': 151357}, '2': {'precision': 0.365562613430127, 'recall': 0.05192536976766668, 'f1-score': 0.09093422871815131, 'support': 155165}, 'accuracy': 0.3328652445132994, 'macro avg': {'precision': 0.3436569922933528, 'recall': 0.3383071552117736, 'f1-score': 0.19814931872989328, 'support': 462163}, 'weighted avg': {'precision': 0.34374981185146886, 'recall': 0.3328652445132994, 'f1-score': 0.19553467531663868, 'support': 462163}}
[[   901 146386   8354]
 [   848 144880   5629]
 [   947 146161   8057]]
Evaluating performance on  val set...
642/642 - 13s - 13s/epoch - 20ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1422459
{'0': {'precision': 0.3852526926263463, 'recall': 0.008528823755983933, 'f1-score': 0.01668819982773471, 'support': 54521}, '1': {'precision': 0.33093627075433435, 'recall': 0.9570300863866548, 'f1-score': 0.4918078271726599, 'support': 53712}, '2': {'precision': 0.3828666837914205, 'recall': 0.05314767601490488, 'f1-score': 0.0933385518590998, 'support': 56089}, 'accuracy': 0.33379583987536665, 'macro avg': {'precision': 0.3663518823907004, 'recall': 0.3395688620525145, 'f1-score': 0.20061152628649814, 'support': 164322}, 'weighted avg': {'precision': 0.3666838308724018, 'recall': 0.33379583987536665, 'f1-score': 0.19815426656887625, 'support': 164322}}
[[  465 51200  2856]
 [  359 51404  1949]
 [  383 52725  2981]]
training model: results/ATVI/W5/deepLOB_L2/h1000
Epoch 1/50
1806/1806 - 90s - loss: 3.2443 - accuracy1000: 0.4063 - val_loss: 3.6206 - val_accuracy1000: 0.3138 - 90s/epoch - 50ms/step
Epoch 2/50
1806/1806 - 88s - loss: 3.1866 - accuracy1000: 0.4318 - val_loss: 3.6101 - val_accuracy1000: 0.3177 - 88s/epoch - 48ms/step
Epoch 3/50
1806/1806 - 87s - loss: 3.1474 - accuracy1000: 0.4496 - val_loss: 3.6657 - val_accuracy1000: 0.3168 - 87s/epoch - 48ms/step
Epoch 4/50
1806/1806 - 87s - loss: 3.1227 - accuracy1000: 0.4595 - val_loss: 3.6081 - val_accuracy1000: 0.3239 - 87s/epoch - 48ms/step
Epoch 5/50
1806/1806 - 87s - loss: 3.1038 - accuracy1000: 0.4658 - val_loss: 3.5461 - val_accuracy1000: 0.3201 - 87s/epoch - 48ms/step
Epoch 6/50
1806/1806 - 88s - loss: 3.0857 - accuracy1000: 0.4726 - val_loss: 3.5471 - val_accuracy1000: 0.3213 - 88s/epoch - 49ms/step
Epoch 7/50
1806/1806 - 89s - loss: 3.0733 - accuracy1000: 0.4766 - val_loss: 3.5848 - val_accuracy1000: 0.3274 - 89s/epoch - 49ms/step
Epoch 8/50
1806/1806 - 89s - loss: 3.0587 - accuracy1000: 0.4827 - val_loss: 3.5928 - val_accuracy1000: 0.3343 - 89s/epoch - 49ms/step
Epoch 9/50
1806/1806 - 88s - loss: 3.0402 - accuracy1000: 0.4893 - val_loss: 3.6004 - val_accuracy1000: 0.3291 - 88s/epoch - 49ms/step
Epoch 10/50
1806/1806 - 87s - loss: 3.0281 - accuracy1000: 0.4939 - val_loss: 3.7164 - val_accuracy1000: 0.3178 - 87s/epoch - 48ms/step
Epoch 11/50
1806/1806 - 88s - loss: 3.0133 - accuracy1000: 0.4972 - val_loss: 3.7484 - val_accuracy1000: 0.3160 - 88s/epoch - 49ms/step
Epoch 12/50
1806/1806 - 88s - loss: 3.0009 - accuracy1000: 0.5010 - val_loss: 3.7909 - val_accuracy1000: 0.3215 - 88s/epoch - 49ms/step
Epoch 13/50
1806/1806 - 88s - loss: 2.9928 - accuracy1000: 0.5038 - val_loss: 3.8138 - val_accuracy1000: 0.3208 - 88s/epoch - 49ms/step
Epoch 14/50
1806/1806 - 87s - loss: 2.9840 - accuracy1000: 0.5059 - val_loss: 3.8749 - val_accuracy1000: 0.3236 - 87s/epoch - 48ms/step
Epoch 15/50
1806/1806 - 88s - loss: 2.9749 - accuracy1000: 0.5090 - val_loss: 3.8910 - val_accuracy1000: 0.3212 - 88s/epoch - 49ms/step
testing model: results/ATVI/W5/deepLOB_L2/h1000
Evaluating performance on  test set...
8238/8238 - 155s - 155s/epoch - 19ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1822126
{'0': {'precision': 0.3634374524485395, 'recall': 0.08947498278706208, 'f1-score': 0.143597557815302, 'support': 774127}, '1': {'precision': 0.25122175497550564, 'recall': 0.7962519284359985, 'f1-score': 0.3819395370637439, 'support': 532167}, '2': {'precision': 0.3792660899325031, 'recall': 0.1093803743675382, 'f1-score': 0.1697925593758403, 'support': 802420}, 'accuracy': 0.27541572731057884, 'macro avg': {'precision': 0.3313084324521827, 'recall': 0.3317024285301996, 'f1-score': 0.23177655141829537, 'support': 2108714}, 'weighted avg': {'precision': 0.3411412682399413, 'recall': 0.27541572731057884, 'f1-score': 0.213714761581632, 'support': 2108714}}
[[ 69265 620129  84733]
 [ 49512 423739  58916]
 [ 71806 642845  87769]]
Evaluating performance on  train set...
1806/1806 - 35s - 35s/epoch - 19ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1636738
{'0': {'precision': 0.33191026512576477, 'recall': 0.07892967072760664, 'f1-score': 0.12753174972181444, 'support': 154644}, '1': {'precision': 0.32718775388723986, 'recall': 0.805791263578433, 'f1-score': 0.46540144092328933, 'support': 151435}, '2': {'precision': 0.33823445277189773, 'recall': 0.113631121703698, 'f1-score': 0.17011236278360453, 'support': 156084}, 'accuracy': 0.3288168892793235, 'macro avg': {'precision': 0.3324441572616341, 'recall': 0.33278401866991253, 'f1-score': 0.2543485178095694, 'support': 462163}, 'weighted avg': {'precision': 0.3324986960801099, 'recall': 0.3288168892793235, 'f1-score': 0.2526206233361708, 'support': 462163}}
[[ 12206 124585  17853]
 [ 12562 122025  16848]
 [ 12007 126341  17736]]
Evaluating performance on  val set...
642/642 - 12s - 12s/epoch - 19ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1860636
{'0': {'precision': 0.31237300823441344, 'recall': 0.053274726878111946, 'f1-score': 0.09102524150825801, 'support': 54829}, '1': {'precision': 0.31429884859324386, 'recall': 0.8477410105393677, 'f1-score': 0.45857983514727235, 'support': 51616}, '2': {'precision': 0.38292063492063494, 'recall': 0.10420374241926846, 'f1-score': 0.1638257704374754, 'support': 57877}, 'accuracy': 0.3207665437372963, 'macro avg': {'precision': 0.33653083058276406, 'recall': 0.33507315994558273, 'f1-score': 0.23781028236433524, 'support': 164322}, 'weighted avg': {'precision': 0.3378260161437612, 'recall': 0.3207665437372963, 'f1-score': 0.23212122450571224, 'support': 164322}}
[[ 2921 46551  5357]
 [ 3497 43757  4362]
 [ 2933 48913  6031]]
training model: results/ATVI/W5/deepOF_L2/h10
Epoch 1/50
1806/1806 - 61s - loss: 2.9253 - accuracy10: 0.4863 - val_loss: 2.9690 - val_accuracy10: 0.6111 - 61s/epoch - 34ms/step
Epoch 2/50
1806/1806 - 56s - loss: 2.6975 - accuracy10: 0.5630 - val_loss: 2.8342 - val_accuracy10: 0.6031 - 56s/epoch - 31ms/step
Epoch 3/50
1806/1806 - 56s - loss: 2.6344 - accuracy10: 0.5743 - val_loss: 2.7821 - val_accuracy10: 0.6000 - 56s/epoch - 31ms/step
Epoch 4/50
1806/1806 - 57s - loss: 2.6078 - accuracy10: 0.5797 - val_loss: 2.7665 - val_accuracy10: 0.5916 - 57s/epoch - 32ms/step
Epoch 5/50
1806/1806 - 54s - loss: 2.5894 - accuracy10: 0.5823 - val_loss: 2.7629 - val_accuracy10: 0.5948 - 54s/epoch - 30ms/step
Epoch 6/50
1806/1806 - 54s - loss: 2.5751 - accuracy10: 0.5833 - val_loss: 2.7579 - val_accuracy10: 0.5849 - 54s/epoch - 30ms/step
Epoch 7/50
1806/1806 - 55s - loss: 2.5632 - accuracy10: 0.5851 - val_loss: 2.7728 - val_accuracy10: 0.5840 - 55s/epoch - 31ms/step
Epoch 8/50
1806/1806 - 55s - loss: 2.5559 - accuracy10: 0.5871 - val_loss: 2.7573 - val_accuracy10: 0.5859 - 55s/epoch - 31ms/step
Epoch 9/50
1806/1806 - 54s - loss: 2.5458 - accuracy10: 0.5873 - val_loss: 2.7438 - val_accuracy10: 0.5891 - 54s/epoch - 30ms/step
Epoch 10/50
1806/1806 - 54s - loss: 2.5407 - accuracy10: 0.5882 - val_loss: 2.7312 - val_accuracy10: 0.5952 - 54s/epoch - 30ms/step
Epoch 11/50
1806/1806 - 54s - loss: 2.5329 - accuracy10: 0.5889 - val_loss: 2.7364 - val_accuracy10: 0.5918 - 54s/epoch - 30ms/step
Epoch 12/50
1806/1806 - 54s - loss: 2.5272 - accuracy10: 0.5899 - val_loss: 2.7484 - val_accuracy10: 0.5833 - 54s/epoch - 30ms/step
Epoch 13/50
1806/1806 - 54s - loss: 2.5202 - accuracy10: 0.5903 - val_loss: 2.7322 - val_accuracy10: 0.5921 - 54s/epoch - 30ms/step
Epoch 14/50
1806/1806 - 56s - loss: 2.5159 - accuracy10: 0.5910 - val_loss: 2.7228 - val_accuracy10: 0.5765 - 56s/epoch - 31ms/step
Epoch 15/50
1806/1806 - 55s - loss: 2.5083 - accuracy10: 0.5923 - val_loss: 2.7341 - val_accuracy10: 0.5817 - 55s/epoch - 30ms/step
Epoch 16/50
1806/1806 - 54s - loss: 2.5040 - accuracy10: 0.5929 - val_loss: 2.7273 - val_accuracy10: 0.5831 - 54s/epoch - 30ms/step
Epoch 17/50
1806/1806 - 56s - loss: 2.4990 - accuracy10: 0.5935 - val_loss: 2.7212 - val_accuracy10: 0.5832 - 56s/epoch - 31ms/step
Epoch 18/50
1806/1806 - 56s - loss: 2.4940 - accuracy10: 0.5937 - val_loss: 2.7301 - val_accuracy10: 0.5901 - 56s/epoch - 31ms/step
Epoch 19/50
1806/1806 - 57s - loss: 2.4888 - accuracy10: 0.5948 - val_loss: 2.7230 - val_accuracy10: 0.5857 - 57s/epoch - 32ms/step
Epoch 20/50
1806/1806 - 55s - loss: 2.4842 - accuracy10: 0.5946 - val_loss: 2.7189 - val_accuracy10: 0.5883 - 55s/epoch - 30ms/step
Epoch 21/50
1806/1806 - 54s - loss: 2.4809 - accuracy10: 0.5950 - val_loss: 2.7220 - val_accuracy10: 0.5862 - 54s/epoch - 30ms/step
Epoch 22/50
1806/1806 - 55s - loss: 2.4755 - accuracy10: 0.5954 - val_loss: 2.7113 - val_accuracy10: 0.5834 - 55s/epoch - 31ms/step
Epoch 23/50
1806/1806 - 57s - loss: 2.4714 - accuracy10: 0.5962 - val_loss: 2.7310 - val_accuracy10: 0.5814 - 57s/epoch - 32ms/step
Epoch 24/50
1806/1806 - 56s - loss: 2.4668 - accuracy10: 0.5961 - val_loss: 2.7272 - val_accuracy10: 0.5878 - 56s/epoch - 31ms/step
Epoch 25/50
1806/1806 - 57s - loss: 2.4633 - accuracy10: 0.5973 - val_loss: 2.7210 - val_accuracy10: 0.5857 - 57s/epoch - 32ms/step
Epoch 26/50
1806/1806 - 57s - loss: 2.4580 - accuracy10: 0.5973 - val_loss: 2.7312 - val_accuracy10: 0.5860 - 57s/epoch - 31ms/step
Epoch 27/50
1806/1806 - 56s - loss: 2.4553 - accuracy10: 0.5977 - val_loss: 2.7231 - val_accuracy10: 0.5852 - 56s/epoch - 31ms/step
Epoch 28/50
1806/1806 - 54s - loss: 2.4514 - accuracy10: 0.5978 - val_loss: 2.7297 - val_accuracy10: 0.5987 - 54s/epoch - 30ms/step
Epoch 29/50
1806/1806 - 55s - loss: 2.4463 - accuracy10: 0.5981 - val_loss: 2.7323 - val_accuracy10: 0.5822 - 55s/epoch - 30ms/step
Epoch 30/50
1806/1806 - 56s - loss: 2.4440 - accuracy10: 0.5995 - val_loss: 2.7246 - val_accuracy10: 0.5889 - 56s/epoch - 31ms/step
Epoch 31/50
1806/1806 - 55s - loss: 2.4406 - accuracy10: 0.5989 - val_loss: 2.7293 - val_accuracy10: 0.5857 - 55s/epoch - 31ms/step
Epoch 32/50
1806/1806 - 55s - loss: 2.4352 - accuracy10: 0.5998 - val_loss: 2.7399 - val_accuracy10: 0.5787 - 55s/epoch - 30ms/step
testing model: results/ATVI/W5/deepOF_L2/h10
Evaluating performance on  test set...
8238/8238 - 122s - 122s/epoch - 15ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 1.0069491
{'0': {'precision': 0.4312570059789225, 'recall': 0.5604064191434811, 'f1-score': 0.4874218173799355, 'support': 526550}, '1': {'precision': 0.7349033620269612, 'recall': 0.42950818427237625, 'f1-score': 0.5421571258770753, 'support': 1053484}, '2': {'precision': 0.3989084686413476, 'recall': 0.6102539367286139, 'f1-score': 0.4824505195346059, 'support': 528675}, 'accuracy': 0.507508622574286, 'macro avg': {'precision': 0.5216896122157437, 'recall': 0.5333895133814904, 'f1-score': 0.5040098209305389, 'support': 2108709}, 'weighted avg': {'precision': 0.5748447247101318, 'recall': 0.507508622574286, 'f1-score': 0.5135205208276, 'support': 2108709}}
[[295082  77779 153689]
 [268547 452480 332457]
 [120608  85441 322626]]
Evaluating performance on  train set...
1806/1806 - 27s - 27s/epoch - 15ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.8531892
{'0': {'precision': 0.44551323553894817, 'recall': 0.5440683135102166, 'f1-score': 0.4898830923819355, 'support': 88533}, '1': {'precision': 0.8132967413804408, 'recall': 0.6087736887492902, 'f1-score': 0.696327898826756, 'support': 285262}, '2': {'precision': 0.3993637735204532, 'recall': 0.6350591297459401, 'f1-score': 0.49035961919075854, 'support': 88365}, 'accuracy': 0.6014042755755582, 'macro avg': {'precision': 0.5527245834799474, 'recall': 0.5959670440018155, 'f1-score': 0.55885687013315, 'support': 462160}, 'weighted avg': {'precision': 0.6636988449211785, 'recall': 0.6014042755755582, 'f1-score': 0.6173994647800748, 'support': 462160}}
[[ 48168  20388  19977]
 [ 47180 173660  64422]
 [ 12770  19478  56117]]
Evaluating performance on  val set...
642/642 - 10s - 10s/epoch - 16ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.8844226
{'0': {'precision': 0.43676110768105003, 'recall': 0.5667992165707164, 'f1-score': 0.4933552028309806, 'support': 33698}, '1': {'precision': 0.8174086824600303, 'recall': 0.5749597266542854, 'f1-score': 0.675075747992603, 'support': 97459}, '2': {'precision': 0.3975479928515152, 'recall': 0.6237901402080507, 'f1-score': 0.48561100417820763, 'support': 33165}, 'accuracy': 0.5831416365428853, 'macro avg': {'precision': 0.5505725943308651, 'recall': 0.5885163611443508, 'f1-score': 0.5513473183339304, 'support': 164322}, 'weighted avg': {'precision': 0.6546079512994524, 'recall': 0.5831416365428853, 'f1-score': 0.5995702334573565, 'support': 164322}}
[[19100  6284  8314]
 [18387 56035 23037]
 [ 6244  6233 20688]]
training model: results/ATVI/W5/deepOF_L2/h20
Epoch 1/50
1806/1806 - 58s - loss: 2.9842 - accuracy20: 0.4849 - val_loss: 3.0162 - val_accuracy20: 0.5691 - 58s/epoch - 32ms/step
Epoch 2/50
1806/1806 - 54s - loss: 2.7808 - accuracy20: 0.5547 - val_loss: 2.8563 - val_accuracy20: 0.5845 - 54s/epoch - 30ms/step
Epoch 3/50
1806/1806 - 55s - loss: 2.7222 - accuracy20: 0.5678 - val_loss: 2.8157 - val_accuracy20: 0.5856 - 55s/epoch - 30ms/step
Epoch 4/50
1806/1806 - 55s - loss: 2.6977 - accuracy20: 0.5727 - val_loss: 2.8055 - val_accuracy20: 0.5800 - 55s/epoch - 30ms/step
Epoch 5/50
1806/1806 - 56s - loss: 2.6814 - accuracy20: 0.5748 - val_loss: 2.7868 - val_accuracy20: 0.5851 - 56s/epoch - 31ms/step
Epoch 6/50
1806/1806 - 55s - loss: 2.6693 - accuracy20: 0.5775 - val_loss: 2.7826 - val_accuracy20: 0.5786 - 55s/epoch - 31ms/step
Epoch 7/50
1806/1806 - 55s - loss: 2.6597 - accuracy20: 0.5791 - val_loss: 2.7853 - val_accuracy20: 0.5811 - 55s/epoch - 30ms/step
Epoch 8/50
1806/1806 - 57s - loss: 2.6514 - accuracy20: 0.5806 - val_loss: 2.7684 - val_accuracy20: 0.5796 - 57s/epoch - 31ms/step
Epoch 9/50
1806/1806 - 56s - loss: 2.6435 - accuracy20: 0.5814 - val_loss: 2.7749 - val_accuracy20: 0.5823 - 56s/epoch - 31ms/step
Epoch 10/50
1806/1806 - 57s - loss: 2.6374 - accuracy20: 0.5825 - val_loss: 2.7601 - val_accuracy20: 0.5833 - 57s/epoch - 31ms/step
Epoch 11/50
1806/1806 - 56s - loss: 2.6310 - accuracy20: 0.5834 - val_loss: 2.7645 - val_accuracy20: 0.5858 - 56s/epoch - 31ms/step
Epoch 12/50
1806/1806 - 56s - loss: 2.6260 - accuracy20: 0.5843 - val_loss: 2.7572 - val_accuracy20: 0.5829 - 56s/epoch - 31ms/step
Epoch 13/50
1806/1806 - 54s - loss: 2.6200 - accuracy20: 0.5854 - val_loss: 2.7582 - val_accuracy20: 0.5879 - 54s/epoch - 30ms/step
Epoch 14/50
1806/1806 - 56s - loss: 2.6146 - accuracy20: 0.5862 - val_loss: 2.7528 - val_accuracy20: 0.5846 - 56s/epoch - 31ms/step
Epoch 15/50
1806/1806 - 55s - loss: 2.6088 - accuracy20: 0.5870 - val_loss: 2.7605 - val_accuracy20: 0.5850 - 55s/epoch - 31ms/step
Epoch 16/50
1806/1806 - 55s - loss: 2.6041 - accuracy20: 0.5879 - val_loss: 2.7455 - val_accuracy20: 0.5855 - 55s/epoch - 31ms/step
Epoch 17/50
1806/1806 - 56s - loss: 2.6004 - accuracy20: 0.5882 - val_loss: 2.7546 - val_accuracy20: 0.5859 - 56s/epoch - 31ms/step
Epoch 18/50
1806/1806 - 57s - loss: 2.5949 - accuracy20: 0.5892 - val_loss: 2.7556 - val_accuracy20: 0.5844 - 57s/epoch - 31ms/step
Epoch 19/50
1806/1806 - 56s - loss: 2.5903 - accuracy20: 0.5898 - val_loss: 2.7521 - val_accuracy20: 0.5854 - 56s/epoch - 31ms/step
Epoch 20/50
1806/1806 - 56s - loss: 2.5862 - accuracy20: 0.5899 - val_loss: 2.7485 - val_accuracy20: 0.5880 - 56s/epoch - 31ms/step
Epoch 21/50
1806/1806 - 58s - loss: 2.5818 - accuracy20: 0.5909 - val_loss: 2.7558 - val_accuracy20: 0.5853 - 58s/epoch - 32ms/step
Epoch 22/50
1806/1806 - 56s - loss: 2.5779 - accuracy20: 0.5915 - val_loss: 2.7582 - val_accuracy20: 0.5816 - 56s/epoch - 31ms/step
Epoch 23/50
1806/1806 - 55s - loss: 2.5745 - accuracy20: 0.5926 - val_loss: 2.7499 - val_accuracy20: 0.5827 - 55s/epoch - 30ms/step
Epoch 24/50
1806/1806 - 55s - loss: 2.5703 - accuracy20: 0.5925 - val_loss: 2.7552 - val_accuracy20: 0.5862 - 55s/epoch - 30ms/step
Epoch 25/50
1806/1806 - 55s - loss: 2.5657 - accuracy20: 0.5931 - val_loss: 2.7560 - val_accuracy20: 0.5873 - 55s/epoch - 30ms/step
Epoch 26/50
1806/1806 - 55s - loss: 2.5620 - accuracy20: 0.5937 - val_loss: 2.7578 - val_accuracy20: 0.5880 - 55s/epoch - 31ms/step
testing model: results/ATVI/W5/deepOF_L2/h20
Evaluating performance on  test set...
8238/8238 - 129s - 129s/epoch - 16ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 1.0046909
{'0': {'precision': 0.47015471127425573, 'recall': 0.6056838311741767, 'f1-score': 0.5293826081395101, 'support': 655966}, '1': {'precision': 0.6016089357512373, 'recall': 0.45759971546543066, 'f1-score': 0.5198146323767386, 'support': 798497}, '2': {'precision': 0.4827752238710454, 'recall': 0.4842857273869462, 'f1-score': 0.4835292959614327, 'support': 654246}, 'accuracy': 0.5119445120213363, 'macro avg': {'precision': 0.5181796236321795, 'recall': 0.5158564246755178, 'f1-score': 0.5109088454925604, 'support': 2108709}, 'weighted avg': {'precision': 0.5238476218496816, 'recall': 0.5119445120213363, 'f1-score': 0.5115331343515649, 'support': 2108709}}
[[397308 112672 145986]
 [239640 365392 193465]
 [208110 129294 316842]]
Evaluating performance on  train set...
1806/1806 - 29s - 29s/epoch - 16ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.881814
{'0': {'precision': 0.49101862251509987, 'recall': 0.5463157158836689, 'f1-score': 0.5171933104723455, 'support': 114432}, '1': {'precision': 0.7029867408471583, 'recall': 0.6583019854157205, 'f1-score': 0.6799109671481166, 'support': 233402}, '2': {'precision': 0.5015953558374543, 'recall': 0.5101464233857566, 'f1-score': 0.5058347535353273, 'support': 114326}, 'accuracy': 0.5939241821014367, 'macro avg': {'precision': 0.5652002397332375, 'recall': 0.5715880415617153, 'f1-score': 0.5676463437185965, 'support': 462160}, 'weighted avg': {'precision': 0.600684059525552, 'recall': 0.5939241821014367, 'f1-score': 0.596559867775134, 'support': 462160}}
[[ 62516  31625  20291]
 [ 42092 153649  37661]
 [ 22711  33292  58323]]
Evaluating performance on  val set...
642/642 - 11s - 11s/epoch - 17ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.8934381
{'0': {'precision': 0.4809669615181069, 'recall': 0.5941812408060336, 'f1-score': 0.5316133075677653, 'support': 42827}, '1': {'precision': 0.7138985675571041, 'recall': 0.6282952437439269, 'f1-score': 0.6683670729742791, 'support': 79243}, '2': {'precision': 0.500059990881386, 'recall': 0.4932074221338635, 'f1-score': 0.4966100685135537, 'support': 42252}, 'accuracy': 0.5846691252540743, 'macro avg': {'precision': 0.5649751733188656, 'recall': 0.5718946355612746, 'f1-score': 0.5655301496851993, 'support': 164322}, 'weighted avg': {'precision': 0.5982057848893264, 'recall': 0.5846691252540743, 'f1-score': 0.5885613837571363, 'support': 164322}}
[[25447  9588  7792]
 [16413 49788 13042]
 [11048 10365 20839]]
training model: results/ATVI/W5/deepOF_L2/h30
Epoch 1/50
1806/1806 - 60s - loss: 3.0390 - accuracy30: 0.4733 - val_loss: 3.0716 - val_accuracy30: 0.5171 - 60s/epoch - 33ms/step
Epoch 2/50
1806/1806 - 57s - loss: 2.8639 - accuracy30: 0.5314 - val_loss: 2.9365 - val_accuracy30: 0.5500 - 57s/epoch - 32ms/step
Epoch 3/50
1806/1806 - 57s - loss: 2.8022 - accuracy30: 0.5487 - val_loss: 2.8793 - val_accuracy30: 0.5566 - 57s/epoch - 32ms/step
Epoch 4/50
1806/1806 - 56s - loss: 2.7782 - accuracy30: 0.5546 - val_loss: 2.8711 - val_accuracy30: 0.5547 - 56s/epoch - 31ms/step
Epoch 5/50
1806/1806 - 55s - loss: 2.7624 - accuracy30: 0.5570 - val_loss: 2.8552 - val_accuracy30: 0.5579 - 55s/epoch - 31ms/step
Epoch 6/50
1806/1806 - 55s - loss: 2.7519 - accuracy30: 0.5594 - val_loss: 2.8495 - val_accuracy30: 0.5580 - 55s/epoch - 31ms/step
Epoch 7/50
1806/1806 - 57s - loss: 2.7426 - accuracy30: 0.5615 - val_loss: 2.8470 - val_accuracy30: 0.5561 - 57s/epoch - 31ms/step
Epoch 8/50
1806/1806 - 56s - loss: 2.7365 - accuracy30: 0.5630 - val_loss: 2.8323 - val_accuracy30: 0.5601 - 56s/epoch - 31ms/step
Epoch 9/50
1806/1806 - 55s - loss: 2.7292 - accuracy30: 0.5646 - val_loss: 2.8399 - val_accuracy30: 0.5621 - 55s/epoch - 31ms/step
Epoch 10/50
1806/1806 - 56s - loss: 2.7223 - accuracy30: 0.5656 - val_loss: 2.8298 - val_accuracy30: 0.5614 - 56s/epoch - 31ms/step
Epoch 11/50
1806/1806 - 55s - loss: 2.7181 - accuracy30: 0.5662 - val_loss: 2.8276 - val_accuracy30: 0.5624 - 55s/epoch - 31ms/step
Epoch 12/50
1806/1806 - 55s - loss: 2.7123 - accuracy30: 0.5672 - val_loss: 2.8351 - val_accuracy30: 0.5610 - 55s/epoch - 30ms/step
Epoch 13/50
1806/1806 - 56s - loss: 2.7066 - accuracy30: 0.5683 - val_loss: 2.8301 - val_accuracy30: 0.5608 - 56s/epoch - 31ms/step
Epoch 14/50
1806/1806 - 56s - loss: 2.7026 - accuracy30: 0.5691 - val_loss: 2.8243 - val_accuracy30: 0.5630 - 56s/epoch - 31ms/step
Epoch 15/50
1806/1806 - 57s - loss: 2.6970 - accuracy30: 0.5704 - val_loss: 2.8344 - val_accuracy30: 0.5620 - 57s/epoch - 32ms/step
Epoch 16/50
1806/1806 - 57s - loss: 2.6936 - accuracy30: 0.5707 - val_loss: 2.8263 - val_accuracy30: 0.5619 - 57s/epoch - 32ms/step
Epoch 17/50
1806/1806 - 57s - loss: 2.6890 - accuracy30: 0.5722 - val_loss: 2.8246 - val_accuracy30: 0.5656 - 57s/epoch - 31ms/step
Epoch 18/50
1806/1806 - 58s - loss: 2.6835 - accuracy30: 0.5732 - val_loss: 2.8155 - val_accuracy30: 0.5646 - 58s/epoch - 32ms/step
Epoch 19/50
1806/1806 - 57s - loss: 2.6798 - accuracy30: 0.5729 - val_loss: 2.8221 - val_accuracy30: 0.5629 - 57s/epoch - 32ms/step
Epoch 20/50
1806/1806 - 58s - loss: 2.6756 - accuracy30: 0.5739 - val_loss: 2.8150 - val_accuracy30: 0.5599 - 58s/epoch - 32ms/step
Epoch 21/50
1806/1806 - 58s - loss: 2.6713 - accuracy30: 0.5753 - val_loss: 2.8304 - val_accuracy30: 0.5612 - 58s/epoch - 32ms/step
Epoch 22/50
1806/1806 - 58s - loss: 2.6672 - accuracy30: 0.5758 - val_loss: 2.8337 - val_accuracy30: 0.5583 - 58s/epoch - 32ms/step
Epoch 23/50
1806/1806 - 58s - loss: 2.6628 - accuracy30: 0.5763 - val_loss: 2.8306 - val_accuracy30: 0.5611 - 58s/epoch - 32ms/step
Epoch 24/50
1806/1806 - 55s - loss: 2.6597 - accuracy30: 0.5772 - val_loss: 2.8376 - val_accuracy30: 0.5597 - 55s/epoch - 31ms/step
Epoch 25/50
1806/1806 - 56s - loss: 2.6542 - accuracy30: 0.5784 - val_loss: 2.8523 - val_accuracy30: 0.5550 - 56s/epoch - 31ms/step
Epoch 26/50
1806/1806 - 56s - loss: 2.6501 - accuracy30: 0.5786 - val_loss: 2.8397 - val_accuracy30: 0.5548 - 56s/epoch - 31ms/step
Epoch 27/50
1806/1806 - 55s - loss: 2.6461 - accuracy30: 0.5798 - val_loss: 2.8479 - val_accuracy30: 0.5511 - 55s/epoch - 31ms/step
Epoch 28/50
1806/1806 - 55s - loss: 2.6424 - accuracy30: 0.5807 - val_loss: 2.8570 - val_accuracy30: 0.5551 - 55s/epoch - 31ms/step
Epoch 29/50
1806/1806 - 57s - loss: 2.6375 - accuracy30: 0.5816 - val_loss: 2.8696 - val_accuracy30: 0.5473 - 57s/epoch - 32ms/step
Epoch 30/50
1806/1806 - 55s - loss: 2.6339 - accuracy30: 0.5815 - val_loss: 2.8676 - val_accuracy30: 0.5505 - 55s/epoch - 31ms/step
testing model: results/ATVI/W5/deepOF_L2/h30
Evaluating performance on  test set...
8238/8238 - 129s - 129s/epoch - 16ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.0109738
{'0': {'precision': 0.5080018972420239, 'recall': 0.49513904374452716, 'f1-score': 0.5014880030186976, 'support': 735452}, '1': {'precision': 0.48557431007735413, 'recall': 0.4975221307959287, 'f1-score': 0.4914756179868775, 'support': 641075}, '2': {'precision': 0.49518250955743304, 'recall': 0.49710864238672897, 'f1-score': 0.49614370656728546, 'support': 732182}, 'accuracy': 0.49654741360709326, 'macro avg': {'precision': 0.4962529056256037, 'recall': 0.4965899389757283, 'f1-score': 0.4963691091909535, 'support': 2108709}, 'weighted avg': {'precision': 0.4967324947994537, 'recall': 0.49654741360709326, 'f1-score': 0.4965884709359579, 'support': 2108709}}
[[364151 168290 203011]
 [154081 318949 168045]
 [198598 169610 363974]]
Evaluating performance on  train set...
1806/1806 - 28s - 28s/epoch - 15ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.91860694
{'0': {'precision': 0.550194824657808, 'recall': 0.4181809897711999, 'f1-score': 0.475189514058772, 'support': 131687}, '1': {'precision': 0.6035704886772021, 'recall': 0.7024658937421231, 'f1-score': 0.6492739229509034, 'support': 199157}, '2': {'precision': 0.5113869251847929, 'recall': 0.5073563008315818, 'f1-score': 0.5093636394912785, 'support': 131316}, 'accuracy': 0.5660247533321794, 'macro avg': {'precision': 0.5550507461732677, 'recall': 0.5426677281149682, 'f1-score': 0.5446090255003179, 'support': 462160}, 'weighted avg': {'precision': 0.5621691170931379, 'recall': 0.5660247533321794, 'f1-score': 0.559917179968901, 'support': 462160}}
[[ 55069  48017  28601]
 [ 24200 139901  35056]
 [ 20821  43871  66624]]
Evaluating performance on  val set...
642/642 - 11s - 11s/epoch - 16ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.92168903
{'0': {'precision': 0.5245935951998884, 'recall': 0.4640498673085231, 'f1-score': 0.49246790673303636, 'support': 48609}, '1': {'precision': 0.6174897510384709, 'recall': 0.6727401798390913, 'f1-score': 0.643931994167693, 'support': 67616}, '2': {'precision': 0.5028432339425478, 'recall': 0.4982431336673805, 'f1-score': 0.5005326148254904, 'support': 48097}, 'accuracy': 0.5599311108676867, 'macro avg': {'precision': 0.5483088600603024, 'recall': 0.545011060271665, 'f1-score': 0.5456441719087399, 'support': 164322}, 'weighted avg': {'precision': 0.5564526241052528, 'recall': 0.5599311108676867, 'f1-score': 0.5571536092019967, 'support': 164322}}
[[22557 14696 11356]
 [ 9791 45488 12337]
 [10651 13482 23964]]
training model: results/ATVI/W5/deepOF_L2/h50
Epoch 1/50
1806/1806 - 59s - loss: 3.1049 - accuracy50: 0.4543 - val_loss: 3.1527 - val_accuracy50: 0.4355 - 59s/epoch - 33ms/step
Epoch 2/50
1806/1806 - 59s - loss: 2.9686 - accuracy50: 0.4990 - val_loss: 3.0050 - val_accuracy50: 0.4867 - 59s/epoch - 33ms/step
Epoch 3/50
1806/1806 - 57s - loss: 2.9195 - accuracy50: 0.5114 - val_loss: 2.9504 - val_accuracy50: 0.5015 - 57s/epoch - 31ms/step
Epoch 4/50
1806/1806 - 58s - loss: 2.8974 - accuracy50: 0.5162 - val_loss: 2.9260 - val_accuracy50: 0.5067 - 58s/epoch - 32ms/step
Epoch 5/50
1806/1806 - 59s - loss: 2.8849 - accuracy50: 0.5197 - val_loss: 2.9203 - val_accuracy50: 0.5084 - 59s/epoch - 33ms/step
Epoch 6/50
1806/1806 - 61s - loss: 2.8753 - accuracy50: 0.5225 - val_loss: 2.9177 - val_accuracy50: 0.5088 - 61s/epoch - 34ms/step
Epoch 7/50
1806/1806 - 59s - loss: 2.8668 - accuracy50: 0.5249 - val_loss: 2.9034 - val_accuracy50: 0.5114 - 59s/epoch - 33ms/step
Epoch 8/50
1806/1806 - 57s - loss: 2.8601 - accuracy50: 0.5265 - val_loss: 2.9029 - val_accuracy50: 0.5101 - 57s/epoch - 32ms/step
Epoch 9/50
1806/1806 - 57s - loss: 2.8544 - accuracy50: 0.5279 - val_loss: 2.8960 - val_accuracy50: 0.5131 - 57s/epoch - 32ms/step
Epoch 10/50
1806/1806 - 55s - loss: 2.8477 - accuracy50: 0.5292 - val_loss: 2.8920 - val_accuracy50: 0.5129 - 55s/epoch - 31ms/step
Epoch 11/50
1806/1806 - 56s - loss: 2.8438 - accuracy50: 0.5301 - val_loss: 2.8905 - val_accuracy50: 0.5139 - 56s/epoch - 31ms/step
Epoch 12/50
1806/1806 - 56s - loss: 2.8395 - accuracy50: 0.5313 - val_loss: 2.9024 - val_accuracy50: 0.5090 - 56s/epoch - 31ms/step
Epoch 13/50
1806/1806 - 55s - loss: 2.8347 - accuracy50: 0.5323 - val_loss: 2.8945 - val_accuracy50: 0.5124 - 55s/epoch - 31ms/step
Epoch 14/50
1806/1806 - 55s - loss: 2.8298 - accuracy50: 0.5340 - val_loss: 2.8969 - val_accuracy50: 0.5110 - 55s/epoch - 31ms/step
Epoch 15/50
1806/1806 - 56s - loss: 2.8260 - accuracy50: 0.5346 - val_loss: 2.8945 - val_accuracy50: 0.5132 - 56s/epoch - 31ms/step
Epoch 16/50
1806/1806 - 56s - loss: 2.8212 - accuracy50: 0.5355 - val_loss: 2.9035 - val_accuracy50: 0.5087 - 56s/epoch - 31ms/step
Epoch 17/50
1806/1806 - 56s - loss: 2.8180 - accuracy50: 0.5369 - val_loss: 2.8964 - val_accuracy50: 0.5117 - 56s/epoch - 31ms/step
Epoch 18/50
1806/1806 - 55s - loss: 2.8151 - accuracy50: 0.5380 - val_loss: 2.9000 - val_accuracy50: 0.5108 - 55s/epoch - 30ms/step
Epoch 19/50
1806/1806 - 56s - loss: 2.8099 - accuracy50: 0.5390 - val_loss: 2.9149 - val_accuracy50: 0.5060 - 56s/epoch - 31ms/step
Epoch 20/50
1806/1806 - 56s - loss: 2.8054 - accuracy50: 0.5397 - val_loss: 2.9143 - val_accuracy50: 0.5069 - 56s/epoch - 31ms/step
Epoch 21/50
1806/1806 - 56s - loss: 2.8023 - accuracy50: 0.5407 - val_loss: 2.9086 - val_accuracy50: 0.5096 - 56s/epoch - 31ms/step
testing model: results/ATVI/W5/deepOF_L2/h50
Evaluating performance on  test set...
8238/8238 - 125s - 125s/epoch - 15ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0178148
{'0': {'precision': 0.5240160246223843, 'recall': 0.45313810860068854, 'f1-score': 0.4860065003063987, 'support': 829608}, '1': {'precision': 0.35325134333157715, 'recall': 0.5373186799749323, 'f1-score': 0.4262630462084795, 'support': 457961}, '2': {'precision': 0.5160956005550406, 'recall': 0.4366417419684828, 'f1-score': 0.4730556303203981, 'support': 821140}, 'accuracy': 0.46499635559007907, 'macro avg': {'precision': 0.46445432283633403, 'recall': 0.4756995101813679, 'f1-score': 0.46177505894509213, 'support': 2108709}, 'weighted avg': {'precision': 0.4838457871798173, 'recall': 0.46499635559007907, 'f1-score': 0.46798853321732115, 'support': 2108709}}
[[375927 226901 226780]
 [102490 246071 109400]
 [238979 223617 358544]]
Evaluating performance on  train set...
1806/1806 - 29s - 29s/epoch - 16ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.98112184
{'0': {'precision': 0.564312416837392, 'recall': 0.3456915513002976, 'f1-score': 0.42874106405000123, 'support': 154580}, '1': {'precision': 0.46701889908184047, 'recall': 0.7629602728888082, 'f1-score': 0.5793868299685561, 'support': 154202}, '2': {'precision': 0.5411730088533869, 'recall': 0.4076986269217228, 'f1-score': 0.4650481357394386, 'support': 153378}, 'accuracy': 0.5054937683918989, 'macro avg': {'precision': 0.5241681082575398, 'recall': 0.5054501503702763, 'f1-score': 0.4910586765859987, 'support': 462160}, 'weighted avg': {'precision': 0.5241706236430171, 'recall': 0.5054937683918989, 'f1-score': 0.4910540821341183, 'support': 462160}}
[[ 53437  69625  31518]
 [ 15053 117650  21499]
 [ 26204  64642  62532]]
Evaluating performance on  val set...
642/642 - 11s - 11s/epoch - 17ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.9641693
{'0': {'precision': 0.5361437160034355, 'recall': 0.4013537406461522, 'f1-score': 0.4590589220602804, 'support': 55993}, '1': {'precision': 0.48900381602731474, 'recall': 0.7389366262637759, 'f1-score': 0.588534781656255, 'support': 52719}, '2': {'precision': 0.5347667399747321, 'recall': 0.41102319726667863, 'f1-score': 0.46479990239141045, 'support': 55610}, 'accuracy': 0.5129319263397476, 'macro avg': {'precision': 0.5199714240018274, 'recall': 0.5171045213922022, 'f1-score': 0.5041312020359819, 'support': 164322}, 'weighted avg': {'precision': 0.5205539469901731, 'recall': 0.5129319263397476, 'f1-score': 0.5025411932002029, 'support': 164322}}
[[22473 21264 12256]
 [ 6134 38956  7629]
 [13309 19444 22857]]
training model: results/ATVI/W5/deepOF_L2/h100
Epoch 1/50
1806/1806 - 59s - loss: 3.2342 - accuracy100: 0.4047 - val_loss: 3.2681 - val_accuracy100: 0.3759 - 59s/epoch - 33ms/step
Epoch 2/50
1806/1806 - 57s - loss: 3.1843 - accuracy100: 0.4289 - val_loss: 3.2678 - val_accuracy100: 0.3846 - 57s/epoch - 32ms/step
Epoch 3/50
1806/1806 - 57s - loss: 3.1672 - accuracy100: 0.4363 - val_loss: 3.2597 - val_accuracy100: 0.3898 - 57s/epoch - 32ms/step
Epoch 4/50
1806/1806 - 58s - loss: 3.1555 - accuracy100: 0.4411 - val_loss: 3.2521 - val_accuracy100: 0.3969 - 58s/epoch - 32ms/step
Epoch 5/50
1806/1806 - 57s - loss: 3.1463 - accuracy100: 0.4450 - val_loss: 3.2511 - val_accuracy100: 0.3967 - 57s/epoch - 32ms/step
Epoch 6/50
1806/1806 - 58s - loss: 3.1387 - accuracy100: 0.4467 - val_loss: 3.2381 - val_accuracy100: 0.4015 - 58s/epoch - 32ms/step
Epoch 7/50
1806/1806 - 56s - loss: 3.1311 - accuracy100: 0.4500 - val_loss: 3.2287 - val_accuracy100: 0.4047 - 56s/epoch - 31ms/step
Epoch 8/50
1806/1806 - 56s - loss: 3.1249 - accuracy100: 0.4522 - val_loss: 3.2317 - val_accuracy100: 0.4085 - 56s/epoch - 31ms/step
Epoch 9/50
1806/1806 - 54s - loss: 3.1191 - accuracy100: 0.4539 - val_loss: 3.2281 - val_accuracy100: 0.4096 - 54s/epoch - 30ms/step
Epoch 10/50
1806/1806 - 53s - loss: 3.1136 - accuracy100: 0.4563 - val_loss: 3.2237 - val_accuracy100: 0.4149 - 53s/epoch - 29ms/step
Epoch 11/50
1806/1806 - 54s - loss: 3.1089 - accuracy100: 0.4579 - val_loss: 3.2125 - val_accuracy100: 0.4175 - 54s/epoch - 30ms/step
Epoch 12/50
1806/1806 - 56s - loss: 3.1038 - accuracy100: 0.4600 - val_loss: 3.2137 - val_accuracy100: 0.4188 - 56s/epoch - 31ms/step
Epoch 13/50
1806/1806 - 56s - loss: 3.0999 - accuracy100: 0.4612 - val_loss: 3.2120 - val_accuracy100: 0.4210 - 56s/epoch - 31ms/step
Epoch 14/50
1806/1806 - 56s - loss: 3.0953 - accuracy100: 0.4625 - val_loss: 3.2150 - val_accuracy100: 0.4222 - 56s/epoch - 31ms/step
Epoch 15/50
1806/1806 - 56s - loss: 3.0913 - accuracy100: 0.4639 - val_loss: 3.2178 - val_accuracy100: 0.4220 - 56s/epoch - 31ms/step
Epoch 16/50
1806/1806 - 58s - loss: 3.0863 - accuracy100: 0.4658 - val_loss: 3.2239 - val_accuracy100: 0.4207 - 58s/epoch - 32ms/step
Epoch 17/50
1806/1806 - 57s - loss: 3.0826 - accuracy100: 0.4672 - val_loss: 3.2246 - val_accuracy100: 0.4221 - 57s/epoch - 31ms/step
Epoch 18/50
1806/1806 - 57s - loss: 3.0766 - accuracy100: 0.4690 - val_loss: 3.2223 - val_accuracy100: 0.4224 - 57s/epoch - 31ms/step
Epoch 19/50
1806/1806 - 55s - loss: 3.0712 - accuracy100: 0.4709 - val_loss: 3.2272 - val_accuracy100: 0.4214 - 55s/epoch - 30ms/step
Epoch 20/50
1806/1806 - 56s - loss: 3.0665 - accuracy100: 0.4726 - val_loss: 3.2357 - val_accuracy100: 0.4196 - 56s/epoch - 31ms/step
Epoch 21/50
1806/1806 - 55s - loss: 3.0617 - accuracy100: 0.4745 - val_loss: 3.2472 - val_accuracy100: 0.4176 - 55s/epoch - 31ms/step
Epoch 22/50
1806/1806 - 55s - loss: 3.0565 - accuracy100: 0.4753 - val_loss: 3.2473 - val_accuracy100: 0.4197 - 55s/epoch - 31ms/step
Epoch 23/50
1806/1806 - 56s - loss: 3.0516 - accuracy100: 0.4776 - val_loss: 3.2481 - val_accuracy100: 0.4188 - 56s/epoch - 31ms/step
testing model: results/ATVI/W5/deepOF_L2/h100
Evaluating performance on  test set...
8238/8238 - 129s - 129s/epoch - 16ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0913508
{'0': {'precision': 0.46880387370620114, 'recall': 0.2690796618673509, 'f1-score': 0.3419119189884532, 'support': 787265}, '1': {'precision': 0.30438279247048733, 'recall': 0.4698124669687207, 'f1-score': 0.3694231626708036, 'support': 531693}, '2': {'precision': 0.4390859362480237, 'recall': 0.4648984300114846, 'f1-score': 0.45162365638351976, 'support': 789751}, 'accuracy': 0.39303052246658976, 'macro avg': {'precision': 0.404090867474904, 'recall': 0.40126351961585205, 'f1-score': 0.38765291268092544, 'support': 2108709}, 'weighted avg': {'precision': 0.4162165756148128, 'recall': 0.39303052246658976, 'f1-score': 0.3899377442714539, 'support': 2108709}}
[[211837 289187 286241]
 [ 99114 249796 182783]
 [140916 281681 367154]]
Evaluating performance on  train set...
1806/1806 - 29s - 29s/epoch - 16ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.071587
{'0': {'precision': 0.5034333328022688, 'recall': 0.20421893479651781, 'f1-score': 0.2905681891327736, 'support': 154731}, '1': {'precision': 0.3859810163665482, 'recall': 0.6429375443253759, 'f1-score': 0.48237381713094607, 'support': 153693}, '2': {'precision': 0.4426605664548796, 'recall': 0.4128506010303377, 'f1-score': 0.42723622521615917, 'support': 153736}, 'accuracy': 0.41951705037216547, 'macro avg': {'precision': 0.44402497187456547, 'recall': 0.4200023600507438, 'f1-score': 0.4000594104932929, 'support': 462160}, 'weighted avg': {'precision': 0.44415827464678714, 'recall': 0.41951705037216547, 'f1-score': 0.3998160244695368, 'support': 462160}}
[[31599 82149 40983]
 [15948 98815 38930]
 [15220 75046 63470]]
Evaluating performance on  val set...
642/642 - 10s - 10s/epoch - 16ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.07062
{'0': {'precision': 0.46479389760891887, 'recall': 0.23347579397244123, 'f1-score': 0.3108200902491662, 'support': 54284}, '1': {'precision': 0.4002734862297284, 'recall': 0.6045618421291012, 'f1-score': 0.48165121062317323, 'support': 55197}, '2': {'precision': 0.435420780091644, 'recall': 0.42625043307014826, 'f1-score': 0.4307868088125535, 'support': 54841}, 'accuracy': 0.42246321247307117, 'macro avg': {'precision': 0.4334960546434304, 'recall': 0.42142935639056356, 'f1-score': 0.40775270322829765, 'support': 164322}, 'weighted avg': {'precision': 0.4333179888160485, 'recall': 0.42246321247307117, 'f1-score': 0.40824137385098935, 'support': 164322}}
[[12674 25900 15710]
 [ 7227 33370 14600]
 [ 7367 24098 23376]]
training model: results/ATVI/W5/deepOF_L2/h200
Epoch 1/50
1806/1806 - 60s - loss: 3.2746 - accuracy200: 0.3762 - val_loss: 3.3044 - val_accuracy200: 0.3464 - 60s/epoch - 33ms/step
Epoch 2/50
1806/1806 - 58s - loss: 3.2451 - accuracy200: 0.3942 - val_loss: 3.2971 - val_accuracy200: 0.3533 - 58s/epoch - 32ms/step
Epoch 3/50
1806/1806 - 58s - loss: 3.2342 - accuracy200: 0.4006 - val_loss: 3.3026 - val_accuracy200: 0.3507 - 58s/epoch - 32ms/step
Epoch 4/50
1806/1806 - 59s - loss: 3.2285 - accuracy200: 0.4038 - val_loss: 3.3055 - val_accuracy200: 0.3501 - 59s/epoch - 32ms/step
Epoch 5/50
1806/1806 - 58s - loss: 3.2225 - accuracy200: 0.4079 - val_loss: 3.3107 - val_accuracy200: 0.3502 - 58s/epoch - 32ms/step
Epoch 6/50
1806/1806 - 56s - loss: 3.2185 - accuracy200: 0.4099 - val_loss: 3.3205 - val_accuracy200: 0.3481 - 56s/epoch - 31ms/step
Epoch 7/50
1806/1806 - 57s - loss: 3.2147 - accuracy200: 0.4120 - val_loss: 3.3267 - val_accuracy200: 0.3436 - 57s/epoch - 32ms/step
Epoch 8/50
1806/1806 - 56s - loss: 3.2107 - accuracy200: 0.4151 - val_loss: 3.3266 - val_accuracy200: 0.3451 - 56s/epoch - 31ms/step
Epoch 9/50
1806/1806 - 56s - loss: 3.2076 - accuracy200: 0.4166 - val_loss: 3.3473 - val_accuracy200: 0.3427 - 56s/epoch - 31ms/step
Epoch 10/50
1806/1806 - 56s - loss: 3.2046 - accuracy200: 0.4182 - val_loss: 3.3464 - val_accuracy200: 0.3435 - 56s/epoch - 31ms/step
Epoch 11/50
1806/1806 - 57s - loss: 3.2003 - accuracy200: 0.4209 - val_loss: 3.3461 - val_accuracy200: 0.3459 - 57s/epoch - 31ms/step
Epoch 12/50
1806/1806 - 58s - loss: 3.1977 - accuracy200: 0.4223 - val_loss: 3.3442 - val_accuracy200: 0.3524 - 58s/epoch - 32ms/step
testing model: results/ATVI/W5/deepOF_L2/h200
Evaluating performance on  test set...
8238/8238 - 126s - 126s/epoch - 15ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1172776
{'0': {'precision': 0.4128628928663184, 'recall': 0.03851608032372362, 'f1-score': 0.07045902130504839, 'support': 751011}, '1': {'precision': 0.2873203324213836, 'recall': 0.7234758038170999, 'f1-score': 0.4112981856561291, 'support': 593854}, '2': {'precision': 0.415520617835661, 'recall': 0.29555642251559217, 'f1-score': 0.34541907647112824, 'support': 763844}, 'accuracy': 0.3245227293097341, 'macro avg': {'precision': 0.371901281041121, 'recall': 0.35251610221880525, 'f1-score': 0.2757254278107686, 'support': 2108709}, 'weighted avg': {'precision': 0.37847035012145236, 'recall': 0.3245227293097341, 'f1-score': 0.26604565250206313, 'support': 2108709}}
[[ 28926 550363 171722]
 [ 18380 429639 145835]
 [ 22756 515329 225759]]
Evaluating performance on  train set...
1806/1806 - 29s - 29s/epoch - 16ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0991441
{'0': {'precision': 0.42884990253411304, 'recall': 0.032540192926045014, 'f1-score': 0.06049049904661712, 'support': 155500}, '1': {'precision': 0.33680835248637, 'recall': 0.711073027879552, 'f1-score': 0.4571039041345965, 'support': 152298}, '2': {'precision': 0.39826745738504055, 'recall': 0.33238750469675177, 'f1-score': 0.3623574278752781, 'support': 154362}, 'accuracy': 0.35629002942703825, 'macro avg': {'precision': 0.38797523746850787, 'recall': 0.3586669085007829, 'f1-score': 0.2933172770188306, 'support': 462160}, 'weighted avg': {'precision': 0.38830439581074383, 'recall': 0.35629002942703825, 'f1-score': 0.2920125070869903, 'support': 462160}}
[[  5060 113343  37097]
 [  3580 108295  40423]
 [  3159  99895  51308]]
Evaluating performance on  val set...
642/642 - 11s - 11s/epoch - 17ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1003563
{'0': {'precision': 0.4070121951219512, 'recall': 0.03416444265711256, 'f1-score': 0.06303753920874228, 'support': 54706}, '1': {'precision': 0.33446989415235123, 'recall': 0.7142513061844592, 'f1-score': 0.4555940295685264, 'support': 53974}, '2': {'precision': 0.39399595232741175, 'recall': 0.3148880342187556, 'f1-score': 0.3500279686750839, 'support': 55642}, 'accuracy': 0.3526064677888536, 'macro avg': {'precision': 0.37849268053390467, 'recall': 0.35443459435344243, 'f1-score': 0.2895531791507842, 'support': 164322}, 'weighted avg': {'precision': 0.37877709614490035, 'recall': 0.3526064677888536, 'f1-score': 0.28915799469884806, 'support': 164322}}
[[ 1869 39967 12870]
 [ 1344 38551 14079]
 [ 1379 36742 17521]]
training model: results/ATVI/W5/deepOF_L2/h300
Epoch 1/50
1806/1806 - 60s - loss: 3.2872 - accuracy300: 0.3728 - val_loss: 3.3060 - val_accuracy300: 0.3487 - 60s/epoch - 33ms/step
Epoch 2/50
1806/1806 - 58s - loss: 3.2642 - accuracy300: 0.3848 - val_loss: 3.2954 - val_accuracy300: 0.3551 - 58s/epoch - 32ms/step
Epoch 3/50
1806/1806 - 58s - loss: 3.2553 - accuracy300: 0.3899 - val_loss: 3.2944 - val_accuracy300: 0.3559 - 58s/epoch - 32ms/step
Epoch 4/50
1806/1806 - 56s - loss: 3.2508 - accuracy300: 0.3933 - val_loss: 3.2859 - val_accuracy300: 0.3605 - 56s/epoch - 31ms/step
Epoch 5/50
1806/1806 - 58s - loss: 3.2475 - accuracy300: 0.3956 - val_loss: 3.2918 - val_accuracy300: 0.3567 - 58s/epoch - 32ms/step
Epoch 6/50
1806/1806 - 59s - loss: 3.2443 - accuracy300: 0.3976 - val_loss: 3.2905 - val_accuracy300: 0.3570 - 59s/epoch - 32ms/step
Epoch 7/50
1806/1806 - 58s - loss: 3.2426 - accuracy300: 0.3982 - val_loss: 3.2902 - val_accuracy300: 0.3599 - 58s/epoch - 32ms/step
Epoch 8/50
1806/1806 - 59s - loss: 3.2400 - accuracy300: 0.4000 - val_loss: 3.2865 - val_accuracy300: 0.3621 - 59s/epoch - 33ms/step
Epoch 9/50
1806/1806 - 60s - loss: 3.2379 - accuracy300: 0.4019 - val_loss: 3.2872 - val_accuracy300: 0.3595 - 60s/epoch - 33ms/step
Epoch 10/50
1806/1806 - 57s - loss: 3.2358 - accuracy300: 0.4033 - val_loss: 3.2854 - val_accuracy300: 0.3597 - 57s/epoch - 32ms/step
Epoch 11/50
1806/1806 - 57s - loss: 3.2329 - accuracy300: 0.4052 - val_loss: 3.2815 - val_accuracy300: 0.3636 - 57s/epoch - 32ms/step
Epoch 12/50
1806/1806 - 58s - loss: 3.2306 - accuracy300: 0.4076 - val_loss: 3.2820 - val_accuracy300: 0.3672 - 58s/epoch - 32ms/step
Epoch 13/50
1806/1806 - 57s - loss: 3.2283 - accuracy300: 0.4087 - val_loss: 3.2879 - val_accuracy300: 0.3655 - 57s/epoch - 32ms/step
Epoch 14/50
1806/1806 - 55s - loss: 3.2254 - accuracy300: 0.4099 - val_loss: 3.2828 - val_accuracy300: 0.3684 - 55s/epoch - 31ms/step
Epoch 15/50
1806/1806 - 58s - loss: 3.2238 - accuracy300: 0.4114 - val_loss: 3.2826 - val_accuracy300: 0.3720 - 58s/epoch - 32ms/step
Epoch 16/50
1806/1806 - 57s - loss: 3.2203 - accuracy300: 0.4140 - val_loss: 3.2833 - val_accuracy300: 0.3728 - 57s/epoch - 31ms/step
Epoch 17/50
1806/1806 - 56s - loss: 3.2181 - accuracy300: 0.4150 - val_loss: 3.2811 - val_accuracy300: 0.3725 - 56s/epoch - 31ms/step
Epoch 18/50
1806/1806 - 57s - loss: 3.2150 - accuracy300: 0.4161 - val_loss: 3.2833 - val_accuracy300: 0.3723 - 57s/epoch - 32ms/step
Epoch 19/50
1806/1806 - 56s - loss: 3.2117 - accuracy300: 0.4184 - val_loss: 3.2864 - val_accuracy300: 0.3720 - 56s/epoch - 31ms/step
Epoch 20/50
1806/1806 - 57s - loss: 3.2082 - accuracy300: 0.4207 - val_loss: 3.3033 - val_accuracy300: 0.3698 - 57s/epoch - 32ms/step
Epoch 21/50
1806/1806 - 57s - loss: 3.2040 - accuracy300: 0.4224 - val_loss: 3.2957 - val_accuracy300: 0.3720 - 57s/epoch - 31ms/step
Epoch 22/50
1806/1806 - 58s - loss: 3.2010 - accuracy300: 0.4242 - val_loss: 3.2970 - val_accuracy300: 0.3720 - 58s/epoch - 32ms/step
Epoch 23/50
1806/1806 - 56s - loss: 3.1962 - accuracy300: 0.4264 - val_loss: 3.3017 - val_accuracy300: 0.3736 - 56s/epoch - 31ms/step
Epoch 24/50
1806/1806 - 57s - loss: 3.1927 - accuracy300: 0.4285 - val_loss: 3.3244 - val_accuracy300: 0.3655 - 57s/epoch - 31ms/step
Epoch 25/50
1806/1806 - 57s - loss: 3.1884 - accuracy300: 0.4298 - val_loss: 3.3277 - val_accuracy300: 0.3676 - 57s/epoch - 32ms/step
Epoch 26/50
1806/1806 - 58s - loss: 3.1837 - accuracy300: 0.4321 - val_loss: 3.3299 - val_accuracy300: 0.3669 - 58s/epoch - 32ms/step
Epoch 27/50
1806/1806 - 58s - loss: 3.1786 - accuracy300: 0.4343 - val_loss: 3.3324 - val_accuracy300: 0.3652 - 58s/epoch - 32ms/step
testing model: results/ATVI/W5/deepOF_L2/h300
Evaluating performance on  test set...
8238/8238 - 138s - 138s/epoch - 17ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1011804
{'0': {'precision': 0.39550320704247793, 'recall': 0.43306246561986794, 'f1-score': 0.4134315471989848, 'support': 750797}, '1': {'precision': 0.31316837103153694, 'recall': 0.411185892190392, 'f1-score': 0.35554540805942997, 'support': 592693}, '2': {'precision': 0.3972667943841043, 'recall': 0.26394535420578946, 'f1-score': 0.3171651488301575, 'support': 765219}, 'accuracy': 0.3655435624355945, 'macro avg': {'precision': 0.36864612415270637, 'recall': 0.36939790400534983, 'f1-score': 0.36204736802952403, 'support': 2108709}, 'weighted avg': {'precision': 0.3730014059794291, 'recall': 0.3655435624355945, 'f1-score': 0.3622279024293955, 'support': 2108709}}
[[325142 263492 162163]
 [204711 243707 144275]
 [292244 270999 201976]]
Evaluating performance on  train set...
1806/1806 - 29s - 29s/epoch - 16ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0903978
{'0': {'precision': 0.4017674418604651, 'recall': 0.36243746570700064, 'f1-score': 0.3810903907827533, 'support': 154915}, '1': {'precision': 0.3603683595095656, 'recall': 0.4860003271716015, 'f1-score': 0.4138601613694112, 'support': 152825}, '2': {'precision': 0.4014633684988866, 'recall': 0.3023766351508872, 'f1-score': 0.3449452769764375, 'support': 154420}, 'accuracy': 0.38322875194737754, 'macro avg': {'precision': 0.38786638995630573, 'recall': 0.38360480934316316, 'f1-score': 0.37996527637620064, 'support': 462160}, 'weighted avg': {'precision': 0.38797617959464553, 'recall': 0.38322875194737754, 'f1-score': 0.37984950389495403, 'support': 462160}}
[[56147 66064 32704]
 [41642 74273 36910]
 [41961 65766 46693]]
Evaluating performance on  val set...
642/642 - 10s - 10s/epoch - 15ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0939832
{'0': {'precision': 0.376461525293161, 'recall': 0.40380095482923245, 'f1-score': 0.38965227021040977, 'support': 54460}, '1': {'precision': 0.36041762628588975, 'recall': 0.43032080659945005, 'f1-score': 0.3922794117647059, 'support': 54550}, '2': {'precision': 0.38632072001373324, 'recall': 0.28480257448654905, 'f1-score': 0.3278835246490233, 'support': 55312}, 'accuracy': 0.37254901960784315, 'macro avg': {'precision': 0.37439995719759467, 'recall': 0.3729747786384105, 'f1-score': 0.3699384022080463, 'support': 164322}, 'weighted avg': {'precision': 0.37445410746437147, 'recall': 0.37254901960784315, 'f1-score': 0.36973258640237094, 'support': 164322}}
[[21991 20553 11916]
 [17968 23474 13108]
 [18456 21103 15753]]
training model: results/ATVI/W5/deepOF_L2/h500
Epoch 1/50
1806/1806 - 61s - loss: 3.2795 - accuracy500: 0.3815 - val_loss: 3.3624 - val_accuracy500: 0.3322 - 61s/epoch - 34ms/step
Epoch 2/50
1806/1806 - 58s - loss: 3.2594 - accuracy500: 0.3885 - val_loss: 3.3538 - val_accuracy500: 0.3362 - 58s/epoch - 32ms/step
Epoch 3/50
1806/1806 - 58s - loss: 3.2477 - accuracy500: 0.3955 - val_loss: 3.3951 - val_accuracy500: 0.3365 - 58s/epoch - 32ms/step
Epoch 4/50
1806/1806 - 57s - loss: 3.2461 - accuracy500: 0.3966 - val_loss: 3.3814 - val_accuracy500: 0.3369 - 57s/epoch - 32ms/step
Epoch 5/50
1806/1806 - 58s - loss: 3.2431 - accuracy500: 0.3990 - val_loss: 3.4032 - val_accuracy500: 0.3373 - 58s/epoch - 32ms/step
Epoch 6/50
1806/1806 - 58s - loss: 3.2421 - accuracy500: 0.3991 - val_loss: 3.4024 - val_accuracy500: 0.3345 - 58s/epoch - 32ms/step
Epoch 7/50
1806/1806 - 57s - loss: 3.2404 - accuracy500: 0.3999 - val_loss: 3.4106 - val_accuracy500: 0.3348 - 57s/epoch - 31ms/step
Epoch 8/50
1806/1806 - 56s - loss: 3.2388 - accuracy500: 0.4014 - val_loss: 3.4096 - val_accuracy500: 0.3338 - 56s/epoch - 31ms/step
Epoch 9/50
1806/1806 - 57s - loss: 3.2376 - accuracy500: 0.4011 - val_loss: 3.4035 - val_accuracy500: 0.3348 - 57s/epoch - 32ms/step
Epoch 10/50
1806/1806 - 57s - loss: 3.2361 - accuracy500: 0.4029 - val_loss: 3.4013 - val_accuracy500: 0.3339 - 57s/epoch - 32ms/step
Epoch 11/50
1806/1806 - 57s - loss: 3.2349 - accuracy500: 0.4035 - val_loss: 3.4012 - val_accuracy500: 0.3345 - 57s/epoch - 32ms/step
Epoch 12/50
1806/1806 - 58s - loss: 3.2332 - accuracy500: 0.4049 - val_loss: 3.3944 - val_accuracy500: 0.3337 - 58s/epoch - 32ms/step
testing model: results/ATVI/W5/deepOF_L2/h500
Evaluating performance on  test set...
8238/8238 - 133s - 133s/epoch - 16ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1393592
{'0': {'precision': 0.3925639877621073, 'recall': 0.027791094646618726, 'f1-score': 0.05190746297742076, 'support': 757185}, '1': {'precision': 0.28174676913411467, 'recall': 0.8786453563476501, 'f1-score': 0.4266755779006422, 'support': 579813}, '2': {'precision': 0.3869415724057492, 'recall': 0.12380800584674832, 'f1-score': 0.187592771481752, 'support': 771711}, 'accuracy': 0.2968816465429796, 'macro avg': {'precision': 0.3537507764339904, 'recall': 0.3434148189470057, 'f1-score': 0.2220586041199383, 'support': 2108709}, 'weighted avg': {'precision': 0.3600359605371926, 'recall': 0.2968816465429796, 'f1-score': 0.20461002655028157, 'support': 2108709}}
[[ 21043 642046  94096]
 [ 13082 509450  57281]
 [ 19479 656688  95544]]
Evaluating performance on  train set...
1806/1806 - 30s - 30s/epoch - 17ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1222208
{'0': {'precision': 0.39877394636015323, 'recall': 0.016716885853608393, 'f1-score': 0.03208859510655091, 'support': 155651}, '1': {'precision': 0.33281395999639524, 'recall': 0.9273564707126243, 'f1-score': 0.4898340285170771, 'support': 151328}, '2': {'precision': 0.35878491743443325, 'recall': 0.07854698706671565, 'f1-score': 0.12887911437241611, 'support': 155181}, 'accuracy': 0.33565431885061453, 'macro avg': {'precision': 0.3634576079303273, 'recall': 0.34087344787764945, 'f1-score': 0.216933912665348, 'support': 462160}, 'weighted avg': {'precision': 0.3637489976104195, 'recall': 0.33565431885061453, 'f1-score': 0.2144707798852949, 'support': 462160}}
[[  2602 140480  12569]
 [  1778 140335   9215]
 [  2145 140847  12189]]
Evaluating performance on  val set...
642/642 - 10s - 10s/epoch - 16ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1205229
{'0': {'precision': 0.37549407114624506, 'recall': 0.01915989805834143, 'f1-score': 0.03645942362710208, 'support': 54541}, '1': {'precision': 0.3320206693910635, 'recall': 0.915719661686352, 'f1-score': 0.4873415525249971, 'support': 53678}, '2': {'precision': 0.3749814732473692, 'recall': 0.09019125536958808, 'f1-score': 0.14540856646119804, 'support': 56103}, 'accuracy': 0.33628485534499336, 'macro avg': {'precision': 0.3608320712615593, 'recall': 0.3416902717047605, 'f1-score': 0.22306984753776574, 'support': 164322}, 'weighted avg': {'precision': 0.3611178857338519, 'recall': 0.33628485534499336, 'f1-score': 0.22094369642929837, 'support': 164322}}
[[ 1045 48792  4704]
 [  794 49154  3730]
 [  944 50099  5060]]
training model: results/ATVI/W5/deepOF_L2/h1000
Epoch 1/50
1806/1806 - 60s - loss: 3.2908 - accuracy1000: 0.3739 - val_loss: 3.4174 - val_accuracy1000: 0.3293 - 60s/epoch - 33ms/step
Epoch 2/50
1806/1806 - 58s - loss: 3.2616 - accuracy1000: 0.3865 - val_loss: 3.3834 - val_accuracy1000: 0.3325 - 58s/epoch - 32ms/step
Epoch 3/50
1806/1806 - 59s - loss: 3.2522 - accuracy1000: 0.3907 - val_loss: 3.3798 - val_accuracy1000: 0.3307 - 59s/epoch - 32ms/step
Epoch 4/50
1806/1806 - 58s - loss: 3.2488 - accuracy1000: 0.3932 - val_loss: 3.3868 - val_accuracy1000: 0.3274 - 58s/epoch - 32ms/step
Epoch 5/50
1806/1806 - 58s - loss: 3.2459 - accuracy1000: 0.3950 - val_loss: 3.3879 - val_accuracy1000: 0.3273 - 58s/epoch - 32ms/step
Epoch 6/50
1806/1806 - 59s - loss: 3.2442 - accuracy1000: 0.3964 - val_loss: 3.3939 - val_accuracy1000: 0.3251 - 59s/epoch - 32ms/step
Epoch 7/50
1806/1806 - 59s - loss: 3.2420 - accuracy1000: 0.3973 - val_loss: 3.3947 - val_accuracy1000: 0.3273 - 59s/epoch - 32ms/step
Epoch 8/50
1806/1806 - 57s - loss: 3.2402 - accuracy1000: 0.3986 - val_loss: 3.3988 - val_accuracy1000: 0.3258 - 57s/epoch - 32ms/step
Epoch 9/50
1806/1806 - 57s - loss: 3.2391 - accuracy1000: 0.3987 - val_loss: 3.4047 - val_accuracy1000: 0.3248 - 57s/epoch - 32ms/step
Epoch 10/50
1806/1806 - 58s - loss: 3.2377 - accuracy1000: 0.3998 - val_loss: 3.4004 - val_accuracy1000: 0.3260 - 58s/epoch - 32ms/step
Epoch 11/50
1806/1806 - 58s - loss: 3.2357 - accuracy1000: 0.4011 - val_loss: 3.4115 - val_accuracy1000: 0.3262 - 58s/epoch - 32ms/step
Epoch 12/50
1806/1806 - 58s - loss: 3.2341 - accuracy1000: 0.4022 - val_loss: 3.4162 - val_accuracy1000: 0.3252 - 58s/epoch - 32ms/step
Epoch 13/50
1806/1806 - 58s - loss: 3.2327 - accuracy1000: 0.4027 - val_loss: 3.4192 - val_accuracy1000: 0.3240 - 58s/epoch - 32ms/step
testing model: results/ATVI/W5/deepOF_L2/h1000
Evaluating performance on  test set...
8238/8238 - 131s - 131s/epoch - 16ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1528531
{'0': {'precision': 0.4049111807732497, 'recall': 0.007007921211588841, 'f1-score': 0.013777392885532088, 'support': 774124}, '1': {'precision': 0.26183419249859846, 'recall': 0.8995634828916487, 'f1-score': 0.40560866124519807, 'support': 532167}, '2': {'precision': 0.40908886608286577, 'recall': 0.1361148428873729, 'f1-score': 0.20426517948315137, 'support': 802418}, 'accuracy': 0.2813873322492577, 'macro avg': {'precision': 0.358611413118238, 'recall': 0.34756208233020347, 'f1-score': 0.20788374453796052, 'support': 2108709}, 'weighted avg': {'precision': 0.3703930932948993, 'recall': 0.2813873322492577, 'f1-score': 0.18514788513232708, 'support': 2108709}}
[[  5425 661645 107054]
 [  2738 478718  50711]
 [  5235 687962 109221]]
Evaluating performance on  train set...
1806/1806 - 29s - 29s/epoch - 16ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1275481
{'0': {'precision': 0.42533185840707965, 'recall': 0.004973483378605614, 'f1-score': 0.009831999386299129, 'support': 154620}, '1': {'precision': 0.3364058558664749, 'recall': 0.9418644560023233, 'f1-score': 0.4957460335106254, 'support': 151508}, '2': {'precision': 0.3762513135335435, 'recall': 0.08720006152584085, 'f1-score': 0.1415861057056932, 'support': 156032}, 'accuracy': 0.339871473082915, 'macro avg': {'precision': 0.3793296759356994, 'recall': 0.34467933363558995, 'f1-score': 0.2157213795342059, 'support': 462160}, 'weighted avg': {'precision': 0.3796093026458075, 'recall': 0.339871473082915, 'f1-score': 0.21360930637811174, 'support': 462160}}
[[   769 139673  14178]
 [   430 142700   8378]
 [   609 141817  13606]]
Evaluating performance on  val set...
642/642 - 10s - 10s/epoch - 16ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1291221
{'0': {'precision': 0.413751507840772, 'recall': 0.006255129023433938, 'f1-score': 0.01232394366197183, 'support': 54835}, '1': {'precision': 0.3240779336031518, 'recall': 0.9343852371629611, 'f1-score': 0.48124354193809243, 'support': 51589}, '2': {'precision': 0.39061758524845774, 'recall': 0.09951984524508618, 'f1-score': 0.15862572093215324, 'support': 57898}, 'accuracy': 0.3305035235695768, 'macro avg': {'precision': 0.37614900889746056, 'recall': 0.3467200704771604, 'f1-score': 0.21739773551073915, 'support': 164322}, 'weighted avg': {'precision': 0.3774473132010135, 'recall': 0.3305035235695768, 'f1-score': 0.21109022849209652, 'support': 164322}}
[[  343 48723  5769]
 [  165 48204  3220]
 [  321 51815  5762]]
training model: results/ATVI/W5/deepVOL_L2/h10
Epoch 1/50
1806/1806 - 62s - loss: 2.9306 - accuracy10: 0.4866 - val_loss: 2.9194 - val_accuracy10: 0.5436 - 62s/epoch - 34ms/step
Epoch 2/50
1806/1806 - 58s - loss: 2.7664 - accuracy10: 0.5272 - val_loss: 2.8527 - val_accuracy10: 0.5514 - 58s/epoch - 32ms/step
Epoch 3/50
1806/1806 - 58s - loss: 2.6967 - accuracy10: 0.5477 - val_loss: 2.8214 - val_accuracy10: 0.5750 - 58s/epoch - 32ms/step
Epoch 4/50
1806/1806 - 59s - loss: 2.6544 - accuracy10: 0.5622 - val_loss: 2.8083 - val_accuracy10: 0.5603 - 59s/epoch - 33ms/step
Epoch 5/50
1806/1806 - 56s - loss: 2.6304 - accuracy10: 0.5691 - val_loss: 2.7966 - val_accuracy10: 0.5664 - 56s/epoch - 31ms/step
Epoch 6/50
1806/1806 - 57s - loss: 2.6130 - accuracy10: 0.5746 - val_loss: 2.7878 - val_accuracy10: 0.5759 - 57s/epoch - 32ms/step
Epoch 7/50
1806/1806 - 57s - loss: 2.5986 - accuracy10: 0.5769 - val_loss: 2.7878 - val_accuracy10: 0.5759 - 57s/epoch - 32ms/step
Epoch 8/50
1806/1806 - 59s - loss: 2.5868 - accuracy10: 0.5795 - val_loss: 2.7989 - val_accuracy10: 0.5771 - 59s/epoch - 33ms/step
Epoch 9/50
1806/1806 - 57s - loss: 2.5767 - accuracy10: 0.5807 - val_loss: 2.7814 - val_accuracy10: 0.5738 - 57s/epoch - 32ms/step
Epoch 10/50
1806/1806 - 58s - loss: 2.5675 - accuracy10: 0.5826 - val_loss: 2.7862 - val_accuracy10: 0.5696 - 58s/epoch - 32ms/step
Epoch 11/50
1806/1806 - 57s - loss: 2.5583 - accuracy10: 0.5836 - val_loss: 2.7619 - val_accuracy10: 0.5791 - 57s/epoch - 32ms/step
Epoch 12/50
1806/1806 - 57s - loss: 2.5500 - accuracy10: 0.5846 - val_loss: 2.7857 - val_accuracy10: 0.5821 - 57s/epoch - 32ms/step
Epoch 13/50
1806/1806 - 57s - loss: 2.5425 - accuracy10: 0.5858 - val_loss: 2.7481 - val_accuracy10: 0.5837 - 57s/epoch - 32ms/step
Epoch 14/50
1806/1806 - 57s - loss: 2.5368 - accuracy10: 0.5871 - val_loss: 2.7655 - val_accuracy10: 0.5810 - 57s/epoch - 32ms/step
Epoch 15/50
1806/1806 - 55s - loss: 2.5303 - accuracy10: 0.5882 - val_loss: 2.7621 - val_accuracy10: 0.5842 - 55s/epoch - 30ms/step
Epoch 16/50
1806/1806 - 56s - loss: 2.5259 - accuracy10: 0.5883 - val_loss: 2.7498 - val_accuracy10: 0.5820 - 56s/epoch - 31ms/step
Epoch 17/50
1806/1806 - 56s - loss: 2.5190 - accuracy10: 0.5902 - val_loss: 2.7508 - val_accuracy10: 0.5834 - 56s/epoch - 31ms/step
Epoch 18/50
1806/1806 - 56s - loss: 2.5159 - accuracy10: 0.5899 - val_loss: 2.7567 - val_accuracy10: 0.5825 - 56s/epoch - 31ms/step
Epoch 19/50
1806/1806 - 58s - loss: 2.5103 - accuracy10: 0.5910 - val_loss: 2.7430 - val_accuracy10: 0.5870 - 58s/epoch - 32ms/step
Epoch 20/50
1806/1806 - 57s - loss: 2.5063 - accuracy10: 0.5918 - val_loss: 2.7455 - val_accuracy10: 0.5892 - 57s/epoch - 31ms/step
Epoch 21/50
1806/1806 - 57s - loss: 2.5022 - accuracy10: 0.5917 - val_loss: 2.7376 - val_accuracy10: 0.5925 - 57s/epoch - 31ms/step
Epoch 22/50
1806/1806 - 56s - loss: 2.4987 - accuracy10: 0.5931 - val_loss: 2.7457 - val_accuracy10: 0.5927 - 56s/epoch - 31ms/step
Epoch 23/50
1806/1806 - 57s - loss: 2.4946 - accuracy10: 0.5935 - val_loss: 2.7443 - val_accuracy10: 0.5907 - 57s/epoch - 32ms/step
Epoch 24/50
1806/1806 - 57s - loss: 2.4910 - accuracy10: 0.5941 - val_loss: 2.7532 - val_accuracy10: 0.5869 - 57s/epoch - 31ms/step
Epoch 25/50
1806/1806 - 57s - loss: 2.4854 - accuracy10: 0.5949 - val_loss: 2.7665 - val_accuracy10: 0.5829 - 57s/epoch - 31ms/step
Epoch 26/50
1806/1806 - 57s - loss: 2.4839 - accuracy10: 0.5946 - val_loss: 2.7485 - val_accuracy10: 0.5874 - 57s/epoch - 32ms/step
Epoch 27/50
1806/1806 - 59s - loss: 2.4796 - accuracy10: 0.5963 - val_loss: 2.7563 - val_accuracy10: 0.5837 - 59s/epoch - 32ms/step
Epoch 28/50
1806/1806 - 57s - loss: 2.4769 - accuracy10: 0.5965 - val_loss: 2.7519 - val_accuracy10: 0.5821 - 57s/epoch - 32ms/step
Epoch 29/50
1806/1806 - 57s - loss: 2.4733 - accuracy10: 0.5974 - val_loss: 2.7582 - val_accuracy10: 0.5829 - 57s/epoch - 31ms/step
Epoch 30/50
1806/1806 - 58s - loss: 2.4703 - accuracy10: 0.5971 - val_loss: 2.7584 - val_accuracy10: 0.5791 - 58s/epoch - 32ms/step
Epoch 31/50
1806/1806 - 59s - loss: 2.4666 - accuracy10: 0.5976 - val_loss: 2.7520 - val_accuracy10: 0.5858 - 59s/epoch - 33ms/step
testing model: results/ATVI/W5/deepVOL_L2/h10
Evaluating performance on  test set...
8238/8238 - 133s - 133s/epoch - 16ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 1.0350792
{'0': {'precision': 0.4376430530596803, 'recall': 0.4833273193428924, 'f1-score': 0.45935211382003766, 'support': 526550}, '1': {'precision': 0.7535428309665598, 'recall': 0.3903672097846671, 'f1-score': 0.5143034013137532, 'support': 1053485}, '2': {'precision': 0.38430422772859313, 'recall': 0.7134291318550576, 'f1-score': 0.4995271923969359, 'support': 528679}, 'accuracy': 0.4945748925648523, 'macro avg': {'precision': 0.5251633705849444, 'recall': 0.5290412203275391, 'f1-score': 0.4910609025102423, 'support': 2108714}, 'weighted avg': {'precision': 0.5820896497489493, 'recall': 0.4945748925648523, 'f1-score': 0.49687739106117745, 'support': 2108714}}
[[254496  74947 197107]
 [235072 411246 407167]
 [ 91947  59557 377175]]
Evaluating performance on  train set...
1806/1806 - 29s - 29s/epoch - 16ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.8702319
{'0': {'precision': 0.44671817137019537, 'recall': 0.47387849095793916, 'f1-score': 0.45989767635491186, 'support': 88586}, '1': {'precision': 0.8218024798571911, 'recall': 0.5971428571428572, 'f1-score': 0.6916876472021442, 'support': 285250}, '2': {'precision': 0.3829767401395716, 'recall': 0.6977368188662584, 'f1-score': 0.4945195147002184, 'support': 88327}, 'accuracy': 0.5927410891828208, 'macro avg': {'precision': 0.5504991304556527, 'recall': 0.589586055655685, 'f1-score': 0.5487016127524248, 'support': 462163}, 'weighted avg': {'precision': 0.6660405957088124, 'recall': 0.5927410891828209, 'f1-score': 0.6095767555968652, 'support': 462163}}
[[ 41979  20650  25957]
 [ 41580 170335  73335]
 [ 10413  16285  61629]]
Evaluating performance on  val set...
642/642 - 11s - 11s/epoch - 17ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.8759686
{'0': {'precision': 0.4552578660988881, 'recall': 0.4574901191643636, 'f1-score': 0.4563712629878311, 'support': 33651}, '1': {'precision': 0.8180018550050528, 'recall': 0.6057530651576659, 'f1-score': 0.6960567776894308, 'support': 97548}, '2': {'precision': 0.3922154147145137, 'recall': 0.6899737342632007, 'f1-score': 0.5001313025210083, 'support': 33123}, 'accuracy': 0.5923674249339711, 'macro avg': {'precision': 0.5551583786061515, 'recall': 0.5844056395284101, 'f1-score': 0.5508531143994234, 'support': 164322}, 'weighted avg': {'precision': 0.6578892575900696, 'recall': 0.5923674249339711, 'f1-score': 0.6074788832551665, 'support': 164322}}
[[15395  7361 10895]
 [13938 59090 24520]
 [ 4483  5786 22854]]
training model: results/ATVI/W5/deepVOL_L2/h20
Epoch 1/50
1806/1806 - 61s - loss: 3.0107 - accuracy20: 0.4814 - val_loss: 3.0001 - val_accuracy20: 0.5532 - 61s/epoch - 34ms/step
Epoch 2/50
1806/1806 - 56s - loss: 2.8614 - accuracy20: 0.5250 - val_loss: 2.9257 - val_accuracy20: 0.5438 - 56s/epoch - 31ms/step
Epoch 3/50
1806/1806 - 57s - loss: 2.8016 - accuracy20: 0.5431 - val_loss: 2.8838 - val_accuracy20: 0.5537 - 57s/epoch - 32ms/step
Epoch 4/50
1806/1806 - 59s - loss: 2.7638 - accuracy20: 0.5539 - val_loss: 2.8537 - val_accuracy20: 0.5589 - 59s/epoch - 32ms/step
Epoch 5/50
1806/1806 - 58s - loss: 2.7428 - accuracy20: 0.5601 - val_loss: 2.8385 - val_accuracy20: 0.5608 - 58s/epoch - 32ms/step
Epoch 6/50
1806/1806 - 59s - loss: 2.7251 - accuracy20: 0.5643 - val_loss: 2.8515 - val_accuracy20: 0.5585 - 59s/epoch - 33ms/step
Epoch 7/50
1806/1806 - 58s - loss: 2.7119 - accuracy20: 0.5677 - val_loss: 2.8357 - val_accuracy20: 0.5631 - 58s/epoch - 32ms/step
Epoch 8/50
1806/1806 - 58s - loss: 2.6995 - accuracy20: 0.5702 - val_loss: 2.8178 - val_accuracy20: 0.5703 - 58s/epoch - 32ms/step
Epoch 9/50
1806/1806 - 59s - loss: 2.6923 - accuracy20: 0.5723 - val_loss: 2.8198 - val_accuracy20: 0.5701 - 59s/epoch - 33ms/step
Epoch 10/50
1806/1806 - 58s - loss: 2.6850 - accuracy20: 0.5732 - val_loss: 2.8009 - val_accuracy20: 0.5775 - 58s/epoch - 32ms/step
Epoch 11/50
1806/1806 - 56s - loss: 2.6757 - accuracy20: 0.5751 - val_loss: 2.8533 - val_accuracy20: 0.5611 - 56s/epoch - 31ms/step
Epoch 12/50
1806/1806 - 57s - loss: 2.6681 - accuracy20: 0.5759 - val_loss: 2.8248 - val_accuracy20: 0.5637 - 57s/epoch - 32ms/step
Epoch 13/50
1806/1806 - 57s - loss: 2.6631 - accuracy20: 0.5775 - val_loss: 2.8047 - val_accuracy20: 0.5682 - 57s/epoch - 32ms/step
Epoch 14/50
1806/1806 - 57s - loss: 2.6567 - accuracy20: 0.5778 - val_loss: 2.7985 - val_accuracy20: 0.5659 - 57s/epoch - 31ms/step
Epoch 15/50
1806/1806 - 57s - loss: 2.6511 - accuracy20: 0.5800 - val_loss: 2.7869 - val_accuracy20: 0.5679 - 57s/epoch - 32ms/step
Epoch 16/50
1806/1806 - 57s - loss: 2.6445 - accuracy20: 0.5812 - val_loss: 2.7903 - val_accuracy20: 0.5715 - 57s/epoch - 31ms/step
Epoch 17/50
1806/1806 - 57s - loss: 2.6406 - accuracy20: 0.5815 - val_loss: 2.7948 - val_accuracy20: 0.5691 - 57s/epoch - 32ms/step
Epoch 18/50
1806/1806 - 58s - loss: 2.6361 - accuracy20: 0.5822 - val_loss: 2.8140 - val_accuracy20: 0.5678 - 58s/epoch - 32ms/step
Epoch 19/50
1806/1806 - 58s - loss: 2.6321 - accuracy20: 0.5827 - val_loss: 2.8055 - val_accuracy20: 0.5664 - 58s/epoch - 32ms/step
Epoch 20/50
1806/1806 - 56s - loss: 2.6275 - accuracy20: 0.5837 - val_loss: 2.8243 - val_accuracy20: 0.5632 - 56s/epoch - 31ms/step
Epoch 21/50
1806/1806 - 57s - loss: 2.6229 - accuracy20: 0.5849 - val_loss: 2.8044 - val_accuracy20: 0.5729 - 57s/epoch - 32ms/step
Epoch 22/50
1806/1806 - 58s - loss: 2.6210 - accuracy20: 0.5856 - val_loss: 2.7862 - val_accuracy20: 0.5752 - 58s/epoch - 32ms/step
Epoch 23/50
1806/1806 - 59s - loss: 2.6168 - accuracy20: 0.5863 - val_loss: 2.8002 - val_accuracy20: 0.5743 - 59s/epoch - 33ms/step
Epoch 24/50
1806/1806 - 58s - loss: 2.6136 - accuracy20: 0.5860 - val_loss: 2.8023 - val_accuracy20: 0.5716 - 58s/epoch - 32ms/step
Epoch 25/50
1806/1806 - 57s - loss: 2.6104 - accuracy20: 0.5874 - val_loss: 2.7989 - val_accuracy20: 0.5748 - 57s/epoch - 32ms/step
Epoch 26/50
1806/1806 - 58s - loss: 2.6071 - accuracy20: 0.5881 - val_loss: 2.7878 - val_accuracy20: 0.5807 - 58s/epoch - 32ms/step
Epoch 27/50
1806/1806 - 58s - loss: 2.6024 - accuracy20: 0.5886 - val_loss: 2.7963 - val_accuracy20: 0.5755 - 58s/epoch - 32ms/step
Epoch 28/50
1806/1806 - 58s - loss: 2.5989 - accuracy20: 0.5887 - val_loss: 2.8121 - val_accuracy20: 0.5710 - 58s/epoch - 32ms/step
Epoch 29/50
1806/1806 - 57s - loss: 2.5961 - accuracy20: 0.5896 - val_loss: 2.8062 - val_accuracy20: 0.5728 - 57s/epoch - 32ms/step
Epoch 30/50
1806/1806 - 57s - loss: 2.5942 - accuracy20: 0.5904 - val_loss: 2.8156 - val_accuracy20: 0.5700 - 57s/epoch - 32ms/step
Epoch 31/50
1806/1806 - 57s - loss: 2.5916 - accuracy20: 0.5905 - val_loss: 2.8082 - val_accuracy20: 0.5694 - 57s/epoch - 32ms/step
Epoch 32/50
1806/1806 - 58s - loss: 2.5887 - accuracy20: 0.5913 - val_loss: 2.8180 - val_accuracy20: 0.5749 - 58s/epoch - 32ms/step
testing model: results/ATVI/W5/deepVOL_L2/h20
Evaluating performance on  test set...
8238/8238 - 135s - 135s/epoch - 16ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 1.0247264
{'0': {'precision': 0.5071505936914422, 'recall': 0.42043056978389187, 'f1-score': 0.459736832673623, 'support': 655968}, '1': {'precision': 0.618164043962719, 'recall': 0.4078344591971426, 'f1-score': 0.49144048025062853, 'support': 798498}, '2': {'precision': 0.43558490824128243, 'recall': 0.6911476993433683, 'f1-score': 0.5343832337381548, 'support': 654248}, 'accuracy': 0.4996533432224569, 'macro avg': {'precision': 0.5202998486318146, 'recall': 0.5064709094414676, 'f1-score': 0.49518684888746883, 'support': 2108714}, 'weighted avg': {'precision': 0.526983682218534, 'recall': 0.4996533432224569, 'f1-score': 0.4949016572001408, 'support': 2108714}}
[[275789 114490 265689]
 [152611 325655 320232]
 [115401  86665 452182]]
Evaluating performance on  train set...
1806/1806 - 28s - 28s/epoch - 15ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.9017467
{'0': {'precision': 0.5328557427544687, 'recall': 0.3986209304355416, 'f1-score': 0.4560660681652503, 'support': 114570}, '1': {'precision': 0.7140083326015475, 'recall': 0.627329618516931, 'f1-score': 0.6678683392732467, 'support': 233300}, '2': {'precision': 0.44000069980230583, 'recall': 0.6601454157297473, 'f1-score': 0.5280470308289883, 'support': 114293}, 'accuracy': 0.5787481905734557, 'macro avg': {'precision': 0.5622882583861073, 'recall': 0.5620319882274066, 'f1-score': 0.5506604794224951, 'support': 462163}, 'weighted avg': {'precision': 0.601338545980153, 'recall': 0.5787481905734557, 'f1-score': 0.5807848146144947, 'support': 462163}}
[[ 45670  33341  35559]
 [ 26476 146356  60468]
 [ 13562  25281  75450]]
Evaluating performance on  val set...
642/642 - 11s - 11s/epoch - 18ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.903177
{'0': {'precision': 0.5348228091766859, 'recall': 0.3953900709219858, 'f1-score': 0.4546564189234504, 'support': 42864}, '1': {'precision': 0.7171566161144254, 'recall': 0.6295698042729326, 'f1-score': 0.6705150260738669, 'support': 79243}, '2': {'precision': 0.4431248810807383, 'recall': 0.6620158711358521, 'f1-score': 0.5308929266833202, 'support': 42215}, 'accuracy': 0.5768186852642981, 'macro avg': {'precision': 0.5650347687906164, 'recall': 0.5623252487769236, 'f1-score': 0.5520214572268792, 'support': 164322}, 'weighted avg': {'precision': 0.599194286085419, 'recall': 0.5768186852642981, 'f1-score': 0.5783380183532489, 'support': 164322}}
[[16948 11181 14735]
 [ 8968 49889 20386]
 [ 5773  8495 27947]]
training model: results/ATVI/W5/deepVOL_L2/h30
Epoch 1/50
1806/1806 - 62s - loss: 3.0160 - accuracy30: 0.4870 - val_loss: 2.9818 - val_accuracy30: 0.5219 - 62s/epoch - 34ms/step
Epoch 2/50
1806/1806 - 59s - loss: 2.9078 - accuracy30: 0.5196 - val_loss: 2.9469 - val_accuracy30: 0.5329 - 59s/epoch - 33ms/step
Epoch 3/50
1806/1806 - 60s - loss: 2.8585 - accuracy30: 0.5343 - val_loss: 2.9560 - val_accuracy30: 0.5355 - 60s/epoch - 33ms/step
Epoch 4/50
1806/1806 - 60s - loss: 2.8227 - accuracy30: 0.5441 - val_loss: 2.9249 - val_accuracy30: 0.5442 - 60s/epoch - 33ms/step
Epoch 5/50
1806/1806 - 57s - loss: 2.8010 - accuracy30: 0.5494 - val_loss: 2.8948 - val_accuracy30: 0.5480 - 57s/epoch - 32ms/step
Epoch 6/50
1806/1806 - 56s - loss: 2.7861 - accuracy30: 0.5529 - val_loss: 2.8936 - val_accuracy30: 0.5511 - 56s/epoch - 31ms/step
Epoch 7/50
1806/1806 - 57s - loss: 2.7766 - accuracy30: 0.5545 - val_loss: 2.8908 - val_accuracy30: 0.5548 - 57s/epoch - 31ms/step
Epoch 8/50
1806/1806 - 57s - loss: 2.7693 - accuracy30: 0.5558 - val_loss: 2.9208 - val_accuracy30: 0.5481 - 57s/epoch - 32ms/step
Epoch 9/50
1806/1806 - 57s - loss: 2.7622 - accuracy30: 0.5576 - val_loss: 2.9035 - val_accuracy30: 0.5501 - 57s/epoch - 32ms/step
Epoch 10/50
1806/1806 - 57s - loss: 2.7556 - accuracy30: 0.5589 - val_loss: 2.9079 - val_accuracy30: 0.5470 - 57s/epoch - 31ms/step
Epoch 11/50
1806/1806 - 57s - loss: 2.7483 - accuracy30: 0.5604 - val_loss: 2.9160 - val_accuracy30: 0.5467 - 57s/epoch - 31ms/step
Epoch 12/50
1806/1806 - 55s - loss: 2.7442 - accuracy30: 0.5610 - val_loss: 2.9401 - val_accuracy30: 0.5432 - 55s/epoch - 31ms/step
Epoch 13/50
1806/1806 - 57s - loss: 2.7393 - accuracy30: 0.5622 - val_loss: 2.9124 - val_accuracy30: 0.5477 - 57s/epoch - 32ms/step
Epoch 14/50
1806/1806 - 58s - loss: 2.7346 - accuracy30: 0.5633 - val_loss: 2.9072 - val_accuracy30: 0.5455 - 58s/epoch - 32ms/step
Epoch 15/50
1806/1806 - 59s - loss: 2.7311 - accuracy30: 0.5640 - val_loss: 2.9019 - val_accuracy30: 0.5483 - 59s/epoch - 33ms/step
Epoch 16/50
1806/1806 - 57s - loss: 2.7263 - accuracy30: 0.5648 - val_loss: 2.9024 - val_accuracy30: 0.5503 - 57s/epoch - 32ms/step
Epoch 17/50
1806/1806 - 59s - loss: 2.7241 - accuracy30: 0.5651 - val_loss: 2.8618 - val_accuracy30: 0.5558 - 59s/epoch - 32ms/step
Epoch 18/50
1806/1806 - 57s - loss: 2.7198 - accuracy30: 0.5661 - val_loss: 2.8903 - val_accuracy30: 0.5514 - 57s/epoch - 32ms/step
Epoch 19/50
1806/1806 - 58s - loss: 2.7164 - accuracy30: 0.5672 - val_loss: 2.8723 - val_accuracy30: 0.5528 - 58s/epoch - 32ms/step
Epoch 20/50
1806/1806 - 58s - loss: 2.7137 - accuracy30: 0.5679 - val_loss: 2.8723 - val_accuracy30: 0.5533 - 58s/epoch - 32ms/step
Epoch 21/50
1806/1806 - 58s - loss: 2.7108 - accuracy30: 0.5684 - val_loss: 2.8794 - val_accuracy30: 0.5505 - 58s/epoch - 32ms/step
Epoch 22/50
1806/1806 - 59s - loss: 2.7073 - accuracy30: 0.5687 - val_loss: 2.8747 - val_accuracy30: 0.5565 - 59s/epoch - 32ms/step
Epoch 23/50
1806/1806 - 60s - loss: 2.7038 - accuracy30: 0.5697 - val_loss: 2.8752 - val_accuracy30: 0.5532 - 60s/epoch - 33ms/step
Epoch 24/50
1806/1806 - 58s - loss: 2.7015 - accuracy30: 0.5702 - val_loss: 2.8788 - val_accuracy30: 0.5551 - 58s/epoch - 32ms/step
Epoch 25/50
1806/1806 - 58s - loss: 2.6981 - accuracy30: 0.5704 - val_loss: 2.8672 - val_accuracy30: 0.5559 - 58s/epoch - 32ms/step
Epoch 26/50
1806/1806 - 59s - loss: 2.6948 - accuracy30: 0.5711 - val_loss: 2.8706 - val_accuracy30: 0.5542 - 59s/epoch - 33ms/step
Epoch 27/50
1806/1806 - 57s - loss: 2.6929 - accuracy30: 0.5713 - val_loss: 2.8728 - val_accuracy30: 0.5543 - 57s/epoch - 32ms/step
testing model: results/ATVI/W5/deepVOL_L2/h30
Evaluating performance on  test set...
8238/8238 - 135s - 135s/epoch - 16ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.0295854
{'0': {'precision': 0.5424084723837296, 'recall': 0.3722924887212524, 'f1-score': 0.4415314046314968, 'support': 735454}, '1': {'precision': 0.485772317910531, 'recall': 0.5028935726809302, 'f1-score': 0.49418469634342904, 'support': 641076}, '2': {'precision': 0.4751278915182132, 'recall': 0.6101458103427554, 'f1-score': 0.5342381224012428, 'support': 732184}, 'accuracy': 0.4945839027957324, 'macro avg': {'precision': 0.5011028939374912, 'recall': 0.49511062391497934, 'f1-score': 0.48998474112538953, 'support': 2108714}, 'weighted avg': {'precision': 0.5018293117268091, 'recall': 0.4945839027957324, 'f1-score': 0.48972814306119483, 'support': 2108714}}
[[273804 188608 273042]
 [ 98214 322393 220469]
 [132775 152670 446739]]
Evaluating performance on  train set...
1806/1806 - 32s - 32s/epoch - 18ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.9391816
{'0': {'precision': 0.5727954385690853, 'recall': 0.3338822029654136, 'f1-score': 0.4218615175164426, 'support': 131786}, '1': {'precision': 0.6015692732635395, 'recall': 0.6936044525708774, 'f1-score': 0.6443168482229725, 'support': 199076}, '2': {'precision': 0.4822093291915899, 'recall': 0.5722271726795684, 'f1-score': 0.523375813704012, 'support': 131301}, 'accuracy': 0.5565460670802292, 'macro avg': {'precision': 0.5521913470080716, 'recall': 0.5332379427386198, 'f1-score': 0.5298513931478089, 'support': 462163}, 'weighted avg': {'precision': 0.5594541134700589, 'recall': 0.5565460670802292, 'f1-score': 0.5465241279362668, 'support': 462163}}
[[ 44001  50707  37078]
 [ 17396 138080  43600]
 [ 15421  40746  75134]]
Evaluating performance on  val set...
642/642 - 11s - 11s/epoch - 17ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.93336654
{'0': {'precision': 0.5726498783803119, 'recall': 0.3291053367321766, 'f1-score': 0.4179895561357702, 'support': 48644}, '1': {'precision': 0.6021559795536211, 'recall': 0.7040132542418012, 'f1-score': 0.6491131160621125, 'support': 67601}, '2': {'precision': 0.48386534100819817, 'recall': 0.5769910768142771, 'f1-score': 0.5263407553578036, 'support': 48077}, 'accuracy': 0.5558659217877095, 'macro avg': {'precision': 0.552890399647377, 'recall': 0.5367032225960849, 'f1-score': 0.5311478091852287, 'support': 164322}, 'weighted avg': {'precision': 0.5588120948953115, 'recall': 0.5558659217877095, 'f1-score': 0.5447734583495843, 'support': 164322}}
[[16009 17445 15190]
 [ 5609 47592 14400]
 [ 6338 13999 27740]]
training model: results/ATVI/W5/deepVOL_L2/h50
Epoch 1/50
1806/1806 - 61s - loss: 3.1250 - accuracy50: 0.4498 - val_loss: 3.0298 - val_accuracy50: 0.4814 - 61s/epoch - 34ms/step
Epoch 2/50
1806/1806 - 56s - loss: 2.9854 - accuracy50: 0.4912 - val_loss: 3.0155 - val_accuracy50: 0.4803 - 56s/epoch - 31ms/step
Epoch 3/50
1806/1806 - 57s - loss: 2.9501 - accuracy50: 0.5016 - val_loss: 3.0176 - val_accuracy50: 0.4846 - 57s/epoch - 32ms/step
Epoch 4/50
1806/1806 - 56s - loss: 2.9320 - accuracy50: 0.5057 - val_loss: 2.9706 - val_accuracy50: 0.4958 - 56s/epoch - 31ms/step
Epoch 5/50
1806/1806 - 56s - loss: 2.9171 - accuracy50: 0.5098 - val_loss: 2.9601 - val_accuracy50: 0.4986 - 56s/epoch - 31ms/step
Epoch 6/50
1806/1806 - 57s - loss: 2.9066 - accuracy50: 0.5126 - val_loss: 2.9711 - val_accuracy50: 0.4960 - 57s/epoch - 32ms/step
Epoch 7/50
1806/1806 - 57s - loss: 2.8973 - accuracy50: 0.5145 - val_loss: 2.9660 - val_accuracy50: 0.5000 - 57s/epoch - 32ms/step
Epoch 8/50
1806/1806 - 56s - loss: 2.8908 - accuracy50: 0.5171 - val_loss: 2.9731 - val_accuracy50: 0.5010 - 56s/epoch - 31ms/step
Epoch 9/50
1806/1806 - 57s - loss: 2.8850 - accuracy50: 0.5187 - val_loss: 2.9791 - val_accuracy50: 0.4977 - 57s/epoch - 31ms/step
Epoch 10/50
1806/1806 - 57s - loss: 2.8811 - accuracy50: 0.5200 - val_loss: 2.9670 - val_accuracy50: 0.4998 - 57s/epoch - 32ms/step
Epoch 11/50
1806/1806 - 57s - loss: 2.8759 - accuracy50: 0.5208 - val_loss: 2.9637 - val_accuracy50: 0.5005 - 57s/epoch - 32ms/step
Epoch 12/50
1806/1806 - 57s - loss: 2.8721 - accuracy50: 0.5213 - val_loss: 2.9660 - val_accuracy50: 0.5004 - 57s/epoch - 32ms/step
Epoch 13/50
1806/1806 - 59s - loss: 2.8696 - accuracy50: 0.5226 - val_loss: 2.9646 - val_accuracy50: 0.4995 - 59s/epoch - 32ms/step
Epoch 14/50
1806/1806 - 59s - loss: 2.8656 - accuracy50: 0.5237 - val_loss: 2.9622 - val_accuracy50: 0.5009 - 59s/epoch - 32ms/step
Epoch 15/50
1806/1806 - 58s - loss: 2.8623 - accuracy50: 0.5247 - val_loss: 2.9842 - val_accuracy50: 0.4958 - 58s/epoch - 32ms/step
testing model: results/ATVI/W5/deepVOL_L2/h50
Evaluating performance on  test set...
8238/8238 - 132s - 132s/epoch - 16ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0406061
{'0': {'precision': 0.5033311445203138, 'recall': 0.4240934316282792, 'f1-score': 0.46032731461886234, 'support': 829612}, '1': {'precision': 0.35303351081844714, 'recall': 0.49847257735920747, 'f1-score': 0.4133323918058136, 'support': 457961}, '2': {'precision': 0.49601613465464867, 'recall': 0.46094276135280055, 'f1-score': 0.47783671323219834, 'support': 821141}, 'accuracy': 0.4545960239273794, 'macro avg': {'precision': 0.45079359666446983, 'recall': 0.4611695901134291, 'f1-score': 0.4504988065522914, 'support': 2108714}, 'weighted avg': {'precision': 0.4678416902160114, 'recall': 0.4545960239273794, 'f1-score': 0.4569393934689893, 'support': 2108714}}
[[351833 227075 250704]
 [ 95805 228281 133875]
 [251371 191271 378499]]
Evaluating performance on  train set...
1806/1806 - 30s - 30s/epoch - 16ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0050731
{'0': {'precision': 0.5204235256829303, 'recall': 0.33969497727522513, 'f1-score': 0.4110718630568888, 'support': 154677}, '1': {'precision': 0.4688420432550703, 'recall': 0.7228067671709177, 'f1-score': 0.5687618678155053, 'support': 154156}, '2': {'precision': 0.5099602561093078, 'recall': 0.4108850192395487, 'f1-score': 0.4550928049524869, 'support': 153330}, 'accuracy': 0.49110162431869275, 'macro avg': {'precision': 0.4997419416824361, 'recall': 0.4911289212285639, 'f1-score': 0.47830884527496037, 'support': 462163}, 'weighted avg': {'precision': 0.49974699353112945, 'recall': 0.49110162431869275, 'f1-score': 0.4782745413206644, 'support': 462163}}
[[ 52543  68510  33624]
 [ 15815 111425  26916]
 [ 32604  57725  63001]]
Evaluating performance on  val set...
642/642 - 11s - 11s/epoch - 17ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.98713046
{'0': {'precision': 0.5231112527892892, 'recall': 0.3516240201417781, 'f1-score': 0.42055805311435496, 'support': 56003}, '1': {'precision': 0.48102538638197506, 'recall': 0.734912566855062, 'f1-score': 0.5814632243155439, 'support': 52726}, '2': {'precision': 0.5113067233267568, 'recall': 0.42420808375155145, 'f1-score': 0.46370285894057967, 'support': 55593}, 'accuracy': 0.49916627110186096, 'macro avg': {'precision': 0.5051477874993403, 'recall': 0.5035815569161305, 'f1-score': 0.48857471212349285, 'support': 164322}, 'weighted avg': {'precision': 0.5056134825661747, 'recall': 0.49916627110186096, 'f1-score': 0.48678433594350257, 'support': 164322}}
[[19692 22684 13627]
 [ 5064 38749  8913]
 [12888 19122 23583]]
training model: results/ATVI/W5/deepVOL_L2/h100
Epoch 1/50
1806/1806 - 59s - loss: 3.2477 - accuracy100: 0.3988 - val_loss: 3.2482 - val_accuracy100: 0.3960 - 59s/epoch - 33ms/step
Epoch 2/50
1806/1806 - 58s - loss: 3.1993 - accuracy100: 0.4170 - val_loss: 3.2556 - val_accuracy100: 0.4007 - 58s/epoch - 32ms/step
Epoch 3/50
1806/1806 - 57s - loss: 3.1848 - accuracy100: 0.4247 - val_loss: 3.2595 - val_accuracy100: 0.4051 - 57s/epoch - 32ms/step
Epoch 4/50
1806/1806 - 56s - loss: 3.1738 - accuracy100: 0.4296 - val_loss: 3.2397 - val_accuracy100: 0.4117 - 56s/epoch - 31ms/step
Epoch 5/50
1806/1806 - 56s - loss: 3.1670 - accuracy100: 0.4317 - val_loss: 3.2409 - val_accuracy100: 0.4112 - 56s/epoch - 31ms/step
Epoch 6/50
1806/1806 - 56s - loss: 3.1596 - accuracy100: 0.4354 - val_loss: 3.2232 - val_accuracy100: 0.4130 - 56s/epoch - 31ms/step
Epoch 7/50
1806/1806 - 57s - loss: 3.1524 - accuracy100: 0.4390 - val_loss: 3.2321 - val_accuracy100: 0.4165 - 57s/epoch - 32ms/step
Epoch 8/50
1806/1806 - 57s - loss: 3.1451 - accuracy100: 0.4417 - val_loss: 3.2232 - val_accuracy100: 0.4231 - 57s/epoch - 32ms/step
Epoch 9/50
1806/1806 - 58s - loss: 3.1384 - accuracy100: 0.4455 - val_loss: 3.2241 - val_accuracy100: 0.4248 - 58s/epoch - 32ms/step
Epoch 10/50
1806/1806 - 59s - loss: 3.1322 - accuracy100: 0.4480 - val_loss: 3.2273 - val_accuracy100: 0.4241 - 59s/epoch - 33ms/step
Epoch 11/50
1806/1806 - 59s - loss: 3.1287 - accuracy100: 0.4497 - val_loss: 3.2284 - val_accuracy100: 0.4253 - 59s/epoch - 33ms/step
Epoch 12/50
1806/1806 - 62s - loss: 3.1249 - accuracy100: 0.4509 - val_loss: 3.2327 - val_accuracy100: 0.4234 - 62s/epoch - 34ms/step
Epoch 13/50
1806/1806 - 60s - loss: 3.1209 - accuracy100: 0.4524 - val_loss: 3.2263 - val_accuracy100: 0.4258 - 60s/epoch - 33ms/step
Epoch 14/50
1806/1806 - 60s - loss: 3.1188 - accuracy100: 0.4530 - val_loss: 3.2312 - val_accuracy100: 0.4258 - 60s/epoch - 33ms/step
Epoch 15/50
1806/1806 - 60s - loss: 3.1155 - accuracy100: 0.4542 - val_loss: 3.2243 - val_accuracy100: 0.4284 - 60s/epoch - 33ms/step
Epoch 16/50
1806/1806 - 58s - loss: 3.1120 - accuracy100: 0.4555 - val_loss: 3.2218 - val_accuracy100: 0.4291 - 58s/epoch - 32ms/step
Epoch 17/50
1806/1806 - 57s - loss: 3.1090 - accuracy100: 0.4559 - val_loss: 3.2172 - val_accuracy100: 0.4294 - 57s/epoch - 32ms/step
Epoch 18/50
1806/1806 - 59s - loss: 3.1068 - accuracy100: 0.4571 - val_loss: 3.2302 - val_accuracy100: 0.4278 - 59s/epoch - 33ms/step
Epoch 19/50
1806/1806 - 58s - loss: 3.1051 - accuracy100: 0.4573 - val_loss: 3.2248 - val_accuracy100: 0.4280 - 58s/epoch - 32ms/step
Epoch 20/50
1806/1806 - 59s - loss: 3.1017 - accuracy100: 0.4592 - val_loss: 3.2236 - val_accuracy100: 0.4282 - 59s/epoch - 32ms/step
Epoch 21/50
1806/1806 - 59s - loss: 3.1004 - accuracy100: 0.4597 - val_loss: 3.2175 - val_accuracy100: 0.4312 - 59s/epoch - 33ms/step
Epoch 22/50
1806/1806 - 59s - loss: 3.0989 - accuracy100: 0.4605 - val_loss: 3.2185 - val_accuracy100: 0.4306 - 59s/epoch - 33ms/step
Epoch 23/50
1806/1806 - 60s - loss: 3.0977 - accuracy100: 0.4613 - val_loss: 3.2238 - val_accuracy100: 0.4308 - 60s/epoch - 33ms/step
Epoch 24/50
1806/1806 - 59s - loss: 3.0963 - accuracy100: 0.4618 - val_loss: 3.2272 - val_accuracy100: 0.4327 - 59s/epoch - 33ms/step
Epoch 25/50
1806/1806 - 59s - loss: 3.0953 - accuracy100: 0.4621 - val_loss: 3.2194 - val_accuracy100: 0.4318 - 59s/epoch - 33ms/step
Epoch 26/50
1806/1806 - 60s - loss: 3.0921 - accuracy100: 0.4642 - val_loss: 3.2200 - val_accuracy100: 0.4323 - 60s/epoch - 33ms/step
Epoch 27/50
1806/1806 - 60s - loss: 3.0890 - accuracy100: 0.4648 - val_loss: 3.2283 - val_accuracy100: 0.4303 - 60s/epoch - 33ms/step
testing model: results/ATVI/W5/deepVOL_L2/h100
Evaluating performance on  test set...
8238/8238 - 140s - 140s/epoch - 17ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0838503
{'0': {'precision': 0.45358322021281255, 'recall': 0.3289375409644492, 'f1-score': 0.38133313895742355, 'support': 787268}, '1': {'precision': 0.32702343754305335, 'recall': 0.33482792734166644, 'f1-score': 0.3308796675330855, 'support': 531694}, '2': {'precision': 0.43529433081741, 'recall': 0.5475440391414014, 'f1-score': 0.4850091803418429, 'support': 789752}, 'accuracy': 0.4122948868362424, 'macro avg': {'precision': 0.4053003295244253, 'recall': 0.403769835815839, 'f1-score': 0.39907399561078405, 'support': 2108714}, 'weighted avg': {'precision': 0.4148227415207695, 'recall': 0.4122948868362424, 'f1-score': 0.40744030806614856, 'support': 2108714}}
[[258962 198481 329825]
 [122511 178026 231157]
 [189452 167876 432424]]
Evaluating performance on  train set...
1806/1806 - 31s - 31s/epoch - 17ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0777377
{'0': {'precision': 0.46929277420593035, 'recall': 0.2527912746821048, 'f1-score': 0.32858534618873253, 'support': 154768}, '1': {'precision': 0.4019551962141424, 'recall': 0.5460596950826713, 'f1-score': 0.4630550298241452, 'support': 153681}, '2': {'precision': 0.43308355585879144, 'recall': 0.47901947773137127, 'f1-score': 0.45489478951725504, 'support': 153714}, 'accuracy': 0.4255533220963167, 'macro avg': {'precision': 0.4347771754262881, 'recall': 0.4259568158320491, 'f1-score': 0.41551172184337765, 'support': 462163}, 'weighted avg': {'precision': 0.43485823463359746, 'recall': 0.4255533220963167, 'f1-score': 0.41531008447928014, 'support': 462163}}
[[39124 68471 47173]
 [20549 83919 49213]
 [23695 56387 73632]]
Evaluating performance on  val set...
642/642 - 12s - 12s/epoch - 18ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0723957
{'0': {'precision': 0.45566658234252466, 'recall': 0.26499687373570197, 'f1-score': 0.33510848584916636, 'support': 54378}, '1': {'precision': 0.42049246103813825, 'recall': 0.5416659110280916, 'f1-score': 0.4734489427131217, 'support': 55141}, '2': {'precision': 0.4297274068788817, 'recall': 0.48355017061109795, 'f1-score': 0.45505280329698633, 'support': 54803}, 'accuracy': 0.43072747410571927, 'macro avg': {'precision': 0.4352954834198482, 'recall': 0.43007098512496383, 'f1-score': 0.42120341061975813, 'support': 164322}, 'weighted avg': {'precision': 0.4352123470254083, 'recall': 0.43072747410571927, 'f1-score': 0.42153355103233264, 'support': 164322}}
[[14410 22305 17663]
 [ 7769 29868 17504]
 [ 9445 18858 26500]]
training model: results/ATVI/W5/deepVOL_L2/h200
Epoch 1/50
1806/1806 - 62s - loss: 3.2940 - accuracy200: 0.3659 - val_loss: 3.3346 - val_accuracy200: 0.3466 - 62s/epoch - 34ms/step
Epoch 2/50
1806/1806 - 59s - loss: 3.2613 - accuracy200: 0.3855 - val_loss: 3.3767 - val_accuracy200: 0.3432 - 59s/epoch - 33ms/step
Epoch 3/50
1806/1806 - 59s - loss: 3.2478 - accuracy200: 0.3930 - val_loss: 3.4283 - val_accuracy200: 0.3468 - 59s/epoch - 33ms/step
Epoch 4/50
1806/1806 - 59s - loss: 3.2399 - accuracy200: 0.3974 - val_loss: 3.4086 - val_accuracy200: 0.3510 - 59s/epoch - 33ms/step
Epoch 5/50
1806/1806 - 58s - loss: 3.2337 - accuracy200: 0.4024 - val_loss: 3.4184 - val_accuracy200: 0.3516 - 58s/epoch - 32ms/step
Epoch 6/50
1806/1806 - 59s - loss: 3.2280 - accuracy200: 0.4052 - val_loss: 3.4223 - val_accuracy200: 0.3553 - 59s/epoch - 33ms/step
Epoch 7/50
1806/1806 - 60s - loss: 3.2249 - accuracy200: 0.4070 - val_loss: 3.4538 - val_accuracy200: 0.3527 - 60s/epoch - 33ms/step
Epoch 8/50
1806/1806 - 59s - loss: 3.2204 - accuracy200: 0.4107 - val_loss: 3.4304 - val_accuracy200: 0.3563 - 59s/epoch - 33ms/step
Epoch 9/50
1806/1806 - 61s - loss: 3.2177 - accuracy200: 0.4114 - val_loss: 3.4267 - val_accuracy200: 0.3599 - 61s/epoch - 34ms/step
Epoch 10/50
1806/1806 - 59s - loss: 3.2142 - accuracy200: 0.4137 - val_loss: 3.4063 - val_accuracy200: 0.3644 - 59s/epoch - 33ms/step
Epoch 11/50
1806/1806 - 59s - loss: 3.2111 - accuracy200: 0.4157 - val_loss: 3.4333 - val_accuracy200: 0.3607 - 59s/epoch - 33ms/step
testing model: results/ATVI/W5/deepVOL_L2/h200
Evaluating performance on  test set...
8238/8238 - 143s - 143s/epoch - 17ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1281049
{'0': {'precision': 0.40803212851405624, 'recall': 0.001352835828844963, 'f1-score': 0.002696730612271982, 'support': 751015}, '1': {'precision': 0.28398550539624456, 'recall': 0.7679231462225627, 'f1-score': 0.4146349446786689, 'support': 593855}, '2': {'precision': 0.39637279294942895, 'recall': 0.25965904032760617, 'f1-score': 0.313770685532447, 'support': 763844}, 'accuracy': 0.3108008008672584, 'macro avg': {'precision': 0.36279680895324323, 'recall': 0.34297834079300465, 'f1-score': 0.24370078694112932, 'support': 2108714}, 'weighted avg': {'precision': 0.3688747933388475, 'recall': 0.3108008008672584, 'f1-score': 0.23138755456300514, 'support': 2108714}}
[[  1016 585255 164744]
 [   518 456035 137302]
 [   956 564549 198339]]
Evaluating performance on  train set...
1806/1806 - 31s - 31s/epoch - 17ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1154755
{'0': {'precision': 0.3684210526315789, 'recall': 0.0008550085500855009, 'f1-score': 0.0017060577878972515, 'support': 155554}, '1': {'precision': 0.33343112444238504, 'recall': 0.798605182626512, 'f1-score': 0.47044396432502067, 'support': 152278}, '2': {'precision': 0.38732372603755705, 'recall': 0.24363867272291373, 'f1-score': 0.29912095779801917, 'support': 154331}, 'accuracy': 0.34477879016710555, 'macro avg': {'precision': 0.36305863437050706, 'recall': 0.34769962129983706, 'f1-score': 0.257090326636979, 'support': 462163}, 'weighted avg': {'precision': 0.36320443469510183, 'recall': 0.34477879016710555, 'f1-score': 0.25546676529828255, 'support': 462163}}
[[   133 126500  28921]
 [   111 121610  30557]
 [   117 116613  37601]]
Evaluating performance on  val set...
642/642 - 11s - 11s/epoch - 17ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1129681
{'0': {'precision': 0.4411764705882353, 'recall': 0.0013702884914037236, 'f1-score': 0.002732091142560516, 'support': 54733}, '1': {'precision': 0.33392065697453294, 'recall': 0.7971833595849162, 'f1-score': 0.47068348669022636, 'support': 53965}, '2': {'precision': 0.38964863104844416, 'recall': 0.24741118941464116, 'f1-score': 0.30265111113554644, 'support': 55624}, 'accuracy': 0.34600966395248356, 'macro avg': {'precision': 0.3882485862037375, 'recall': 0.34865494583032036, 'f1-score': 0.25868889632277775, 'support': 164322}, 'weighted avg': {'precision': 0.38851009281639226, 'recall': 0.34600966395248356, 'f1-score': 0.25793646200476783, 'support': 164322}}
[[   75 44005 10653]
 [   41 43020 10904]
 [   54 41808 13762]]
training model: results/ATVI/W5/deepVOL_L2/h300
Epoch 1/50
1806/1806 - 60s - loss: 3.2923 - accuracy300: 0.3694 - val_loss: 3.3434 - val_accuracy300: 0.3324 - 60s/epoch - 33ms/step
Epoch 2/50
1806/1806 - 58s - loss: 3.2735 - accuracy300: 0.3745 - val_loss: 3.3599 - val_accuracy300: 0.3400 - 58s/epoch - 32ms/step
Epoch 3/50
1806/1806 - 57s - loss: 3.2679 - accuracy300: 0.3788 - val_loss: 3.4140 - val_accuracy300: 0.3329 - 57s/epoch - 31ms/step
Epoch 4/50
1806/1806 - 56s - loss: 3.2659 - accuracy300: 0.3805 - val_loss: 3.3727 - val_accuracy300: 0.3355 - 56s/epoch - 31ms/step
Epoch 5/50
1806/1806 - 57s - loss: 3.2608 - accuracy300: 0.3845 - val_loss: 3.3858 - val_accuracy300: 0.3326 - 57s/epoch - 32ms/step
Epoch 6/50
1806/1806 - 58s - loss: 3.2567 - accuracy300: 0.3858 - val_loss: 3.3830 - val_accuracy300: 0.3340 - 58s/epoch - 32ms/step
Epoch 7/50
1806/1806 - 60s - loss: 3.2535 - accuracy300: 0.3906 - val_loss: 3.3576 - val_accuracy300: 0.3365 - 60s/epoch - 33ms/step
Epoch 8/50
1806/1806 - 59s - loss: 3.2509 - accuracy300: 0.3930 - val_loss: 3.3603 - val_accuracy300: 0.3373 - 59s/epoch - 32ms/step
Epoch 9/50
1806/1806 - 58s - loss: 3.2466 - accuracy300: 0.3954 - val_loss: 3.3787 - val_accuracy300: 0.3377 - 58s/epoch - 32ms/step
Epoch 10/50
1806/1806 - 58s - loss: 3.2427 - accuracy300: 0.3968 - val_loss: 3.3878 - val_accuracy300: 0.3388 - 58s/epoch - 32ms/step
Epoch 11/50
1806/1806 - 61s - loss: 3.2404 - accuracy300: 0.4002 - val_loss: 3.3884 - val_accuracy300: 0.3378 - 61s/epoch - 34ms/step
testing model: results/ATVI/W5/deepVOL_L2/h300
Evaluating performance on  test set...
8238/8238 - 144s - 144s/epoch - 17ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1305346
{'0': {'precision': 0.3893805309734513, 'recall': 0.0006446448526307237, 'f1-score': 0.001287158730074304, 'support': 750801}, '1': {'precision': 0.2829223788662785, 'recall': 0.8842404343556709, 'f1-score': 0.42868296409660345, 'support': 592694}, '2': {'precision': 0.3703523655694773, 'recall': 0.12345224046972174, 'f1-score': 0.18517781621981877, 'support': 765219}, 'accuracy': 0.29356090963497183, 'macro avg': {'precision': 0.3475517584697357, 'recall': 0.3361124398926745, 'f1-score': 0.2050493130154988, 'support': 2108714}, 'weighted avg': {'precision': 0.35255343080374024, 'recall': 0.29356090963497183, 'f1-score': 0.18814585768097725, 'support': 2108714}}
[[   484 657999  92318]
 [   320 524084  68290]
 [   439 670312  94468]]
Evaluating performance on  train set...
1806/1806 - 32s - 32s/epoch - 18ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1164755
{'0': {'precision': 0.35172413793103446, 'recall': 0.0006585701280337808, 'f1-score': 0.0013146786448498754, 'support': 154881}, '1': {'precision': 0.3314709291095229, 'recall': 0.8980486305088737, 'f1-score': 0.4842168009636226, 'support': 152867}, '2': {'precision': 0.3444134722193113, 'recall': 0.1064210083217304, 'f1-score': 0.16259993667379086, 'support': 154415}, 'accuracy': 0.3328198059991821, 'macro avg': {'precision': 0.34253617975328954, 'recall': 0.335042736319546, 'f1-score': 0.2160438054274211, 'support': 462163}, 'weighted avg': {'precision': 0.34258250669098766, 'recall': 0.3328198059991821, 'f1-score': 0.21492905679940302, 'support': 462163}}
[[   102 138994  15785]
 [    90 137282  15495]
 [    98 137884  16433]]
Evaluating performance on  val set...
642/642 - 12s - 12s/epoch - 18ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1154288
{'0': {'precision': 0.41414141414141414, 'recall': 0.0007525973787583978, 'f1-score': 0.0015024644080839915, 'support': 54478}, '1': {'precision': 0.33121866366520003, 'recall': 0.8916536589844826, 'f1-score': 0.48301417557821424, 'support': 54455}, '2': {'precision': 0.34184252325845244, 'recall': 0.10879416490638935, 'f1-score': 0.16505745237410463, 'support': 55389}, 'accuracy': 0.3324083202492667, 'macro avg': {'precision': 0.3624008670216889, 'recall': 0.33373347375654344, 'f1-score': 0.2165246974534676, 'support': 164322}, 'weighted avg': {'precision': 0.36229125625446895, 'recall': 0.3324083202492667, 'f1-score': 0.2162020631241376, 'support': 164322}}
[[   41 48711  5726]
 [   24 48555  5876]
 [   34 49329  6026]]
training model: results/ATVI/W5/deepVOL_L2/h500
Epoch 1/50
1806/1806 - 62s - loss: 3.2635 - accuracy500: 0.3903 - val_loss: 3.9646 - val_accuracy500: 0.3270 - 62s/epoch - 34ms/step
Epoch 2/50
1806/1806 - 58s - loss: 3.2593 - accuracy500: 0.3833 - val_loss: 3.4238 - val_accuracy500: 0.3269 - 58s/epoch - 32ms/step
Epoch 3/50
1806/1806 - 57s - loss: 3.2609 - accuracy500: 0.3818 - val_loss: 3.4134 - val_accuracy500: 0.3270 - 57s/epoch - 32ms/step
Epoch 4/50
1806/1806 - 58s - loss: 3.2618 - accuracy500: 0.3801 - val_loss: 3.3777 - val_accuracy500: 0.3269 - 58s/epoch - 32ms/step
Epoch 5/50
1806/1806 - 57s - loss: 3.2603 - accuracy500: 0.3806 - val_loss: 3.3981 - val_accuracy500: 0.3269 - 57s/epoch - 32ms/step
Epoch 6/50
1806/1806 - 57s - loss: 3.2616 - accuracy500: 0.3806 - val_loss: 3.3682 - val_accuracy500: 0.3269 - 57s/epoch - 32ms/step
Epoch 7/50
1806/1806 - 57s - loss: 3.2608 - accuracy500: 0.3806 - val_loss: 3.3877 - val_accuracy500: 0.3269 - 57s/epoch - 32ms/step
Epoch 8/50
1806/1806 - 57s - loss: 3.2574 - accuracy500: 0.3832 - val_loss: 3.3820 - val_accuracy500: 0.3269 - 57s/epoch - 32ms/step
Epoch 9/50
1806/1806 - 59s - loss: 3.2560 - accuracy500: 0.3845 - val_loss: 3.4038 - val_accuracy500: 0.3269 - 59s/epoch - 32ms/step
Epoch 10/50
1806/1806 - 58s - loss: 3.2511 - accuracy500: 0.3859 - val_loss: 3.4238 - val_accuracy500: 0.3269 - 58s/epoch - 32ms/step
Epoch 11/50
1806/1806 - 61s - loss: 3.2471 - accuracy500: 0.3916 - val_loss: 3.4328 - val_accuracy500: 0.3269 - 61s/epoch - 34ms/step
Epoch 12/50
1806/1806 - 60s - loss: 3.2519 - accuracy500: 0.3883 - val_loss: 3.4597 - val_accuracy500: 0.3269 - 60s/epoch - 33ms/step
Epoch 13/50
1806/1806 - 58s - loss: 3.2418 - accuracy500: 0.3971 - val_loss: 3.4501 - val_accuracy500: 0.3269 - 58s/epoch - 32ms/step
Epoch 14/50
1806/1806 - 59s - loss: 3.2340 - accuracy500: 0.4016 - val_loss: 3.4811 - val_accuracy500: 0.3271 - 59s/epoch - 33ms/step
Epoch 15/50
1806/1806 - 60s - loss: 3.2295 - accuracy500: 0.4036 - val_loss: 3.5382 - val_accuracy500: 0.3271 - 60s/epoch - 33ms/step
Epoch 16/50
1806/1806 - 58s - loss: 3.2260 - accuracy500: 0.4051 - val_loss: 3.5519 - val_accuracy500: 0.3276 - 58s/epoch - 32ms/step
testing model: results/ATVI/W5/deepVOL_L2/h500
Evaluating performance on  test set...
8238/8238 - 141s - 141s/epoch - 17ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1451905
{'0': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 757187}, '1': {'precision': 0.27496138555779553, 'recall': 0.9999793037077408, 'f1-score': 0.4313231151717271, 'support': 579814}, '2': {'precision': 0.425531914893617, 'recall': 2.5916370464149236e-05, 'f1-score': 5.1829584326733695e-05, 'support': 771713}, 'accuracy': 0.27496474154389833, 'macro avg': {'precision': 0.23349776681713752, 'recall': 0.33333507335940166, 'f1-score': 0.14379164825201796, 'support': 2108714}, 'weighted avg': {'precision': 0.23133292207672806, 'recall': 0.27496474154389833, 'f1-score': 0.11861598029139528, 'support': 2108714}}
[[     0 757172     15]
 [     0 579802     12]
 [     0 771693     20]]
Evaluating performance on  train set...
1806/1806 - 30s - 30s/epoch - 17ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1257106
{'0': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 155641}, '1': {'precision': 0.3274990966273366, 'recall': 0.9999933931037217, 'f1-score': 0.49340683342189423, 'support': 151357}, '2': {'precision': 0.3333333333333333, 'recall': 1.2889504720781104e-05, 'f1-score': 2.5778012644115202e-05, 'support': 155165}, 'accuracy': 0.32749917236992143, 'macro avg': {'precision': 0.22027747665355665, 'recall': 0.33333542753614753, 'f1-score': 0.16447753714484611, 'support': 462163}, 'weighted avg': {'precision': 0.21916714976077803, 'recall': 0.32749917236992143, 'f1-score': 0.16159791660424908, 'support': 462163}}
[[     0 155638      3]
 [     0 151356      1]
 [     0 155163      2]]
Evaluating performance on  val set...
642/642 - 11s - 11s/epoch - 17ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1256155
{'0': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 54521}, '1': {'precision': 0.3268622200584226, 'recall': 0.9999627643729521, 'f1-score': 0.4926799735818595, 'support': 53712}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 56089}, 'accuracy': 0.3268582417448668, 'macro avg': {'precision': 0.10895407335280753, 'recall': 0.3333209214576507, 'f1-score': 0.16422665786061982, 'support': 164322}, 'weighted avg': {'precision': 0.10684158885467554, 'recall': 0.3268582417448668, 'f1-score': 0.1610425064265822, 'support': 164322}}
[[    0 54521     0]
 [    0 53710     2]
 [    0 56089     0]]
training model: results/ATVI/W5/deepVOL_L2/h1000
Epoch 1/50
1806/1806 - 62s - loss: 3.2687 - accuracy1000: 0.3894 - val_loss: 3.4397 - val_accuracy1000: 0.3362 - 62s/epoch - 34ms/step
Epoch 2/50
1806/1806 - 59s - loss: 3.2499 - accuracy1000: 0.3951 - val_loss: 3.4283 - val_accuracy1000: 0.3230 - 59s/epoch - 33ms/step
Epoch 3/50
1806/1806 - 61s - loss: 3.2410 - accuracy1000: 0.3986 - val_loss: 3.4243 - val_accuracy1000: 0.3234 - 61s/epoch - 34ms/step
Epoch 4/50
1806/1806 - 58s - loss: 3.2340 - accuracy1000: 0.4022 - val_loss: 3.4253 - val_accuracy1000: 0.3303 - 58s/epoch - 32ms/step
Epoch 5/50
1806/1806 - 57s - loss: 3.2263 - accuracy1000: 0.4055 - val_loss: 3.4258 - val_accuracy1000: 0.3373 - 57s/epoch - 32ms/step
Epoch 6/50
1806/1806 - 58s - loss: 3.2202 - accuracy1000: 0.4083 - val_loss: 3.4110 - val_accuracy1000: 0.3356 - 58s/epoch - 32ms/step
Epoch 7/50
1806/1806 - 59s - loss: 3.2114 - accuracy1000: 0.4144 - val_loss: 3.4380 - val_accuracy1000: 0.3286 - 59s/epoch - 33ms/step
Epoch 8/50
1806/1806 - 57s - loss: 3.2074 - accuracy1000: 0.4169 - val_loss: 3.4497 - val_accuracy1000: 0.3309 - 57s/epoch - 31ms/step
Epoch 9/50
1806/1806 - 58s - loss: 3.2029 - accuracy1000: 0.4198 - val_loss: 3.4388 - val_accuracy1000: 0.3331 - 58s/epoch - 32ms/step
Epoch 10/50
1806/1806 - 59s - loss: 3.1998 - accuracy1000: 0.4229 - val_loss: 3.4260 - val_accuracy1000: 0.3339 - 59s/epoch - 32ms/step
Epoch 11/50
1806/1806 - 58s - loss: 3.1949 - accuracy1000: 0.4264 - val_loss: 3.4474 - val_accuracy1000: 0.3247 - 58s/epoch - 32ms/step
Epoch 12/50
1806/1806 - 59s - loss: 3.1876 - accuracy1000: 0.4296 - val_loss: 3.4570 - val_accuracy1000: 0.3314 - 59s/epoch - 33ms/step
Epoch 13/50
1806/1806 - 59s - loss: 3.1818 - accuracy1000: 0.4326 - val_loss: 3.5040 - val_accuracy1000: 0.3324 - 59s/epoch - 32ms/step
Epoch 14/50
1806/1806 - 57s - loss: 3.1770 - accuracy1000: 0.4341 - val_loss: 3.4946 - val_accuracy1000: 0.3262 - 57s/epoch - 32ms/step
Epoch 15/50
1806/1806 - 57s - loss: 3.1723 - accuracy1000: 0.4364 - val_loss: 3.5112 - val_accuracy1000: 0.3347 - 57s/epoch - 32ms/step
Epoch 16/50
1806/1806 - 60s - loss: 3.1670 - accuracy1000: 0.4383 - val_loss: 3.5117 - val_accuracy1000: 0.3401 - 60s/epoch - 33ms/step
testing model: results/ATVI/W5/deepVOL_L2/h1000
Evaluating performance on  test set...
8238/8238 - 140s - 140s/epoch - 17ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1624095
{'0': {'precision': 0.4053616220735786, 'recall': 0.010020319663311059, 'f1-score': 0.01955719603712766, 'support': 774127}, '1': {'precision': 0.2622155225203233, 'recall': 0.8295910870084015, 'f1-score': 0.398480204203944, 'support': 532167}, '2': {'precision': 0.40652737848004905, 'recall': 0.2056504075172603, 'f1-score': 0.2731315084069812, 'support': 802420}, 'accuracy': 0.29129412523462167, 'macro avg': {'precision': 0.35803484102465033, 'recall': 0.34842060472965763, 'f1-score': 0.2303896362160176, 'support': 2108714}, 'weighted avg': {'precision': 0.369680062551862, 'recall': 0.29129412523462167, 'f1-score': 0.21167590925235175, 'support': 2108714}}
[[  7757 612458 153912]
 [  3695 441481  86991]
 [  7684 629718 165018]]
Evaluating performance on  train set...
1806/1806 - 31s - 31s/epoch - 17ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1355883
{'0': {'precision': 0.40495449949443885, 'recall': 0.005179638395282067, 'f1-score': 0.010228448110737953, 'support': 154644}, '1': {'precision': 0.3390360736657541, 'recall': 0.9053059068247102, 'f1-score': 0.4933231618454053, 'support': 151435}, '2': {'precision': 0.3746103407502956, 'recall': 0.133966325824556, 'f1-score': 0.19735538126114904, 'support': 156084}, 'accuracy': 0.34361469871019534, 'macro avg': {'precision': 0.3728669713034962, 'recall': 0.3481506236815161, 'f1-score': 0.23363566373909742, 'support': 462163}, 'weighted avg': {'precision': 0.3731073059960677, 'recall': 0.34361469871019534, 'f1-score': 0.23171949825594237, 'support': 462163}}
[[   801 132798  21045]
 [   477 137095  13863]
 [   700 134474  20910]]
Evaluating performance on  val set...
642/642 - 10s - 10s/epoch - 16ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1397295
{'0': {'precision': 0.3940520446096654, 'recall': 0.005799850444108045, 'f1-score': 0.011431447264361207, 'support': 54829}, '1': {'precision': 0.3272174688182156, 'recall': 0.9031889336639801, 'f1-score': 0.4803928135320758, 'support': 51616}, '2': {'precision': 0.3894221630868656, 'recall': 0.1415933790624946, 'f1-score': 0.20767603046084063, 'support': 57877}, 'accuracy': 0.3355119825708061, 'macro avg': {'precision': 0.37023055883824885, 'recall': 0.35019405439019424, 'f1-score': 0.23316676375242587, 'support': 164322}, 'weighted avg': {'precision': 0.3714275809532679, 'recall': 0.3355119825708061, 'f1-score': 0.2278599085959966, 'support': 164322}}
[[  318 46473  8038]
 [  186 46619  4811]
 [  303 49379  8195]]
training model: results/ATVI/W5/deepVOL_L3/h10
Epoch 1/50
1806/1806 - 82s - loss: 3.2130 - accuracy10: 0.4219 - val_loss: 3.1507 - val_accuracy10: 0.4870 - 82s/epoch - 45ms/step
Epoch 2/50
1806/1806 - 82s - loss: 2.8518 - accuracy10: 0.4892 - val_loss: 2.8882 - val_accuracy10: 0.5296 - 82s/epoch - 45ms/step
Epoch 3/50
1806/1806 - 82s - loss: 2.7427 - accuracy10: 0.5356 - val_loss: 2.9004 - val_accuracy10: 0.5856 - 82s/epoch - 46ms/step
Epoch 4/50
1806/1806 - 84s - loss: 2.6788 - accuracy10: 0.5555 - val_loss: 2.8828 - val_accuracy10: 0.5838 - 84s/epoch - 47ms/step
Epoch 5/50
1806/1806 - 85s - loss: 2.6408 - accuracy10: 0.5643 - val_loss: 2.8338 - val_accuracy10: 0.5751 - 85s/epoch - 47ms/step
Epoch 6/50
1806/1806 - 80s - loss: 2.6173 - accuracy10: 0.5698 - val_loss: 2.8192 - val_accuracy10: 0.5668 - 80s/epoch - 44ms/step
Epoch 7/50
1806/1806 - 80s - loss: 2.6011 - accuracy10: 0.5743 - val_loss: 2.8200 - val_accuracy10: 0.5673 - 80s/epoch - 44ms/step
Epoch 8/50
1806/1806 - 82s - loss: 2.5872 - accuracy10: 0.5772 - val_loss: 2.8066 - val_accuracy10: 0.5709 - 82s/epoch - 46ms/step
Epoch 9/50
1806/1806 - 82s - loss: 2.5772 - accuracy10: 0.5791 - val_loss: 2.8046 - val_accuracy10: 0.5719 - 82s/epoch - 45ms/step
Epoch 10/50
1806/1806 - 81s - loss: 2.5661 - accuracy10: 0.5808 - val_loss: 2.8086 - val_accuracy10: 0.5793 - 81s/epoch - 45ms/step
Epoch 11/50
1806/1806 - 81s - loss: 2.5585 - accuracy10: 0.5827 - val_loss: 2.7940 - val_accuracy10: 0.5884 - 81s/epoch - 45ms/step
Epoch 12/50
1806/1806 - 83s - loss: 2.5505 - accuracy10: 0.5833 - val_loss: 2.8035 - val_accuracy10: 0.5806 - 83s/epoch - 46ms/step
Epoch 13/50
1806/1806 - 84s - loss: 2.5427 - accuracy10: 0.5849 - val_loss: 2.7879 - val_accuracy10: 0.5794 - 84s/epoch - 47ms/step
Epoch 14/50
1806/1806 - 82s - loss: 2.5352 - accuracy10: 0.5856 - val_loss: 2.8053 - val_accuracy10: 0.5841 - 82s/epoch - 45ms/step
Epoch 15/50
1806/1806 - 81s - loss: 2.5294 - accuracy10: 0.5869 - val_loss: 2.7653 - val_accuracy10: 0.5869 - 81s/epoch - 45ms/step
Epoch 16/50
1806/1806 - 82s - loss: 2.5224 - accuracy10: 0.5874 - val_loss: 2.7875 - val_accuracy10: 0.5866 - 82s/epoch - 45ms/step
Epoch 17/50
1806/1806 - 79s - loss: 2.5192 - accuracy10: 0.5871 - val_loss: 2.7519 - val_accuracy10: 0.5936 - 79s/epoch - 43ms/step
Epoch 18/50
1806/1806 - 79s - loss: 2.5122 - accuracy10: 0.5889 - val_loss: 2.7660 - val_accuracy10: 0.5944 - 79s/epoch - 44ms/step
Epoch 19/50
1806/1806 - 80s - loss: 2.5076 - accuracy10: 0.5899 - val_loss: 2.7742 - val_accuracy10: 0.5867 - 80s/epoch - 45ms/step
Epoch 20/50
1806/1806 - 81s - loss: 2.5035 - accuracy10: 0.5904 - val_loss: 2.7624 - val_accuracy10: 0.5921 - 81s/epoch - 45ms/step
Epoch 21/50
1806/1806 - 81s - loss: 2.5002 - accuracy10: 0.5912 - val_loss: 2.7466 - val_accuracy10: 0.5927 - 81s/epoch - 45ms/step
Epoch 22/50
1806/1806 - 80s - loss: 2.4935 - accuracy10: 0.5921 - val_loss: 2.7650 - val_accuracy10: 0.5943 - 80s/epoch - 45ms/step
Epoch 23/50
1806/1806 - 85s - loss: 2.4906 - accuracy10: 0.5927 - val_loss: 2.7451 - val_accuracy10: 0.5872 - 85s/epoch - 47ms/step
Epoch 24/50
1806/1806 - 81s - loss: 2.4873 - accuracy10: 0.5922 - val_loss: 2.7390 - val_accuracy10: 0.5923 - 81s/epoch - 45ms/step
Epoch 25/50
1806/1806 - 84s - loss: 2.4838 - accuracy10: 0.5938 - val_loss: 2.7392 - val_accuracy10: 0.5851 - 84s/epoch - 47ms/step
Epoch 26/50
1806/1806 - 86s - loss: 2.4792 - accuracy10: 0.5942 - val_loss: 2.7111 - val_accuracy10: 0.5826 - 86s/epoch - 48ms/step
Epoch 27/50
1806/1806 - 85s - loss: 2.4763 - accuracy10: 0.5942 - val_loss: 2.7302 - val_accuracy10: 0.5947 - 85s/epoch - 47ms/step
Epoch 28/50
1806/1806 - 78s - loss: 2.4725 - accuracy10: 0.5952 - val_loss: 2.7195 - val_accuracy10: 0.5902 - 78s/epoch - 43ms/step
Epoch 29/50
1806/1806 - 79s - loss: 2.4692 - accuracy10: 0.5955 - val_loss: 2.7384 - val_accuracy10: 0.5863 - 79s/epoch - 44ms/step
Epoch 30/50
1806/1806 - 78s - loss: 2.4650 - accuracy10: 0.5965 - val_loss: 2.7147 - val_accuracy10: 0.5889 - 78s/epoch - 43ms/step
Epoch 31/50
1806/1806 - 79s - loss: 2.4622 - accuracy10: 0.5963 - val_loss: 2.7437 - val_accuracy10: 0.5929 - 79s/epoch - 44ms/step
Epoch 32/50
1806/1806 - 87s - loss: 2.4588 - accuracy10: 0.5978 - val_loss: 2.7227 - val_accuracy10: 0.5997 - 87s/epoch - 48ms/step
Epoch 33/50
1806/1806 - 84s - loss: 2.4550 - accuracy10: 0.5980 - val_loss: 2.7240 - val_accuracy10: 0.5896 - 84s/epoch - 47ms/step
Epoch 34/50
1806/1806 - 81s - loss: 2.4506 - accuracy10: 0.5980 - val_loss: 2.7134 - val_accuracy10: 0.5869 - 81s/epoch - 45ms/step
Epoch 35/50
1806/1806 - 80s - loss: 2.4492 - accuracy10: 0.5984 - val_loss: 2.7062 - val_accuracy10: 0.5925 - 80s/epoch - 44ms/step
Epoch 36/50
1806/1806 - 78s - loss: 2.4446 - accuracy10: 0.5987 - val_loss: 2.7109 - val_accuracy10: 0.5830 - 78s/epoch - 43ms/step
Epoch 37/50
1806/1806 - 79s - loss: 2.4410 - accuracy10: 0.5997 - val_loss: 2.7305 - val_accuracy10: 0.5841 - 79s/epoch - 44ms/step
Epoch 38/50
1806/1806 - 83s - loss: 2.4385 - accuracy10: 0.6002 - val_loss: 2.7263 - val_accuracy10: 0.5903 - 83s/epoch - 46ms/step
Epoch 39/50
1806/1806 - 83s - loss: 2.4349 - accuracy10: 0.6010 - val_loss: 2.7127 - val_accuracy10: 0.5962 - 83s/epoch - 46ms/step
Epoch 40/50
1806/1806 - 82s - loss: 2.4328 - accuracy10: 0.6010 - val_loss: 2.7171 - val_accuracy10: 0.5815 - 82s/epoch - 46ms/step
Epoch 41/50
1806/1806 - 80s - loss: 2.4286 - accuracy10: 0.6004 - val_loss: 2.7115 - val_accuracy10: 0.5923 - 80s/epoch - 44ms/step
Epoch 42/50
1806/1806 - 84s - loss: 2.4262 - accuracy10: 0.6012 - val_loss: 2.7198 - val_accuracy10: 0.5952 - 84s/epoch - 47ms/step
Epoch 43/50
1806/1806 - 79s - loss: 2.4227 - accuracy10: 0.6021 - val_loss: 2.7192 - val_accuracy10: 0.5829 - 79s/epoch - 44ms/step
Epoch 44/50
1806/1806 - 79s - loss: 2.4195 - accuracy10: 0.6022 - val_loss: 2.7262 - val_accuracy10: 0.5981 - 79s/epoch - 44ms/step
Epoch 45/50
1806/1806 - 79s - loss: 2.4156 - accuracy10: 0.6028 - val_loss: 2.7181 - val_accuracy10: 0.5888 - 79s/epoch - 44ms/step
testing model: results/ATVI/W5/deepVOL_L3/h10
Evaluating performance on  test set...
8238/8238 - 173s - 173s/epoch - 21ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 1.0154316
{'0': {'precision': 0.43298498742935165, 'recall': 0.5010768208147375, 'f1-score': 0.4645490031745585, 'support': 526550}, '1': {'precision': 0.7613056220996036, 'recall': 0.3888408472830652, 'f1-score': 0.514763521027823, 'support': 1053485}, '2': {'precision': 0.3819252354920757, 'recall': 0.6944459681583721, 'f1-score': 0.4928159338077967, 'support': 528679}, 'accuracy': 0.4934851288510438, 'macro avg': {'precision': 0.5254052816736771, 'recall': 0.5281212120853916, 'f1-score': 0.4907094860033927, 'support': 2108714}, 'weighted avg': {'precision': 0.5842082662718799, 'recall': 0.4934851288510438, 'f1-score': 0.4967223438745757, 'support': 2108714}}
[[263842  70359 192349]
 [242050 409638 401797]
 [103464  58076 367139]]
Evaluating performance on  train set...
1806/1806 - 39s - 39s/epoch - 21ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.8450955
{'0': {'precision': 0.4580994573731882, 'recall': 0.498419614837559, 'f1-score': 0.4774097281166033, 'support': 88586}, '1': {'precision': 0.8275755058389909, 'recall': 0.6076739702015775, 'f1-score': 0.7007786474336167, 'support': 285250}, '2': {'precision': 0.39069636528792395, 'recall': 0.6914759926183387, 'f1-score': 0.4992867448999195, 'support': 88327}, 'accuracy': 0.6027483809824672, 'macro avg': {'precision': 0.5587904428333678, 'recall': 0.5991898592191583, 'f1-score': 0.5591583734833798, 'support': 462163}, 'weighted avg': {'precision': 0.6732606232611001, 'recall': 0.6027483809824672, 'f1-score': 0.6194555333770807, 'support': 462163}}
[[ 44153  20110  24323]
 [ 40984 173339  70927]
 [ 11246  16005  61076]]
Evaluating performance on  val set...
642/642 - 15s - 15s/epoch - 23ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.8636528
{'0': {'precision': 0.45186875573984914, 'recall': 0.48251166384357075, 'f1-score': 0.46668774430903653, 'support': 33651}, '1': {'precision': 0.8260722823794122, 'recall': 0.6021855906835609, 'f1-score': 0.6965812472577643, 'support': 97548}, '2': {'precision': 0.3926046194940554, 'recall': 0.6789240105062947, 'f1-score': 0.4975111170106855, 'support': 33123}, 'accuracy': 0.5931463833205536, 'macro avg': {'precision': 0.5568485525377722, 'recall': 0.5878737550111421, 'f1-score': 0.5535933695258288, 'support': 164322}, 'weighted avg': {'precision': 0.6620645885058005, 'recall': 0.5931463833205536, 'f1-score': 0.6093747490901323, 'support': 164322}}
[[16237  6930 10484]
 [14499 58742 24307]
 [ 5197  5438 22488]]
training model: results/ATVI/W5/deepVOL_L3/h20
Epoch 1/50
1806/1806 - 82s - loss: 3.1815 - accuracy20: 0.4359 - val_loss: 3.2990 - val_accuracy20: 0.5146 - 82s/epoch - 45ms/step
Epoch 2/50
1806/1806 - 81s - loss: 2.9848 - accuracy20: 0.4864 - val_loss: 3.1083 - val_accuracy20: 0.5450 - 81s/epoch - 45ms/step
Epoch 3/50
1806/1806 - 80s - loss: 2.8267 - accuracy20: 0.5417 - val_loss: 2.9810 - val_accuracy20: 0.5559 - 80s/epoch - 44ms/step
Epoch 4/50
1806/1806 - 81s - loss: 2.7713 - accuracy20: 0.5571 - val_loss: 2.8621 - val_accuracy20: 0.5698 - 81s/epoch - 45ms/step
Epoch 5/50
1806/1806 - 80s - loss: 2.7361 - accuracy20: 0.5637 - val_loss: 2.8368 - val_accuracy20: 0.5723 - 80s/epoch - 44ms/step
Epoch 6/50
1806/1806 - 78s - loss: 2.7144 - accuracy20: 0.5688 - val_loss: 2.8335 - val_accuracy20: 0.5746 - 78s/epoch - 43ms/step
Epoch 7/50
1806/1806 - 77s - loss: 2.7008 - accuracy20: 0.5712 - val_loss: 2.8517 - val_accuracy20: 0.5800 - 77s/epoch - 43ms/step
Epoch 8/50
1806/1806 - 76s - loss: 2.6860 - accuracy20: 0.5738 - val_loss: 2.8394 - val_accuracy20: 0.5747 - 76s/epoch - 42ms/step
Epoch 9/50
1806/1806 - 77s - loss: 2.6763 - accuracy20: 0.5758 - val_loss: 2.8510 - val_accuracy20: 0.5795 - 77s/epoch - 43ms/step
Epoch 10/50
1806/1806 - 80s - loss: 2.6656 - accuracy20: 0.5766 - val_loss: 2.8112 - val_accuracy20: 0.5775 - 80s/epoch - 44ms/step
Epoch 11/50
1806/1806 - 82s - loss: 2.6573 - accuracy20: 0.5782 - val_loss: 2.8038 - val_accuracy20: 0.5807 - 82s/epoch - 45ms/step
Epoch 12/50
1806/1806 - 78s - loss: 2.6510 - accuracy20: 0.5793 - val_loss: 2.8084 - val_accuracy20: 0.5749 - 78s/epoch - 43ms/step
Epoch 13/50
1806/1806 - 78s - loss: 2.6412 - accuracy20: 0.5810 - val_loss: 2.7954 - val_accuracy20: 0.5805 - 78s/epoch - 43ms/step
Epoch 14/50
1806/1806 - 76s - loss: 2.6361 - accuracy20: 0.5813 - val_loss: 2.8030 - val_accuracy20: 0.5799 - 76s/epoch - 42ms/step
Epoch 15/50
1806/1806 - 74s - loss: 2.6318 - accuracy20: 0.5822 - val_loss: 2.7923 - val_accuracy20: 0.5838 - 74s/epoch - 41ms/step
Epoch 16/50
1806/1806 - 76s - loss: 2.6260 - accuracy20: 0.5836 - val_loss: 2.8023 - val_accuracy20: 0.5827 - 76s/epoch - 42ms/step
Epoch 17/50
1806/1806 - 74s - loss: 2.6215 - accuracy20: 0.5839 - val_loss: 2.7845 - val_accuracy20: 0.5865 - 74s/epoch - 41ms/step
Epoch 18/50
1806/1806 - 74s - loss: 2.6156 - accuracy20: 0.5851 - val_loss: 2.7963 - val_accuracy20: 0.5860 - 74s/epoch - 41ms/step
Epoch 19/50
1806/1806 - 74s - loss: 2.6130 - accuracy20: 0.5857 - val_loss: 2.7514 - val_accuracy20: 0.5931 - 74s/epoch - 41ms/step
Epoch 20/50
1806/1806 - 73s - loss: 2.6082 - accuracy20: 0.5869 - val_loss: 2.7707 - val_accuracy20: 0.5872 - 73s/epoch - 41ms/step
Epoch 21/50
1806/1806 - 75s - loss: 2.6044 - accuracy20: 0.5876 - val_loss: 2.7728 - val_accuracy20: 0.5913 - 75s/epoch - 41ms/step
Epoch 22/50
1806/1806 - 74s - loss: 2.6006 - accuracy20: 0.5877 - val_loss: 2.8027 - val_accuracy20: 0.5862 - 74s/epoch - 41ms/step
Epoch 23/50
1806/1806 - 74s - loss: 2.5979 - accuracy20: 0.5881 - val_loss: 2.7767 - val_accuracy20: 0.5883 - 74s/epoch - 41ms/step
Epoch 24/50
1806/1806 - 74s - loss: 2.5940 - accuracy20: 0.5893 - val_loss: 2.7586 - val_accuracy20: 0.5883 - 74s/epoch - 41ms/step
Epoch 25/50
1806/1806 - 76s - loss: 2.5923 - accuracy20: 0.5900 - val_loss: 2.7565 - val_accuracy20: 0.5923 - 76s/epoch - 42ms/step
Epoch 26/50
1806/1806 - 75s - loss: 2.5873 - accuracy20: 0.5903 - val_loss: 2.7481 - val_accuracy20: 0.5921 - 75s/epoch - 41ms/step
Epoch 27/50
1806/1806 - 76s - loss: 2.5842 - accuracy20: 0.5910 - val_loss: 2.7804 - val_accuracy20: 0.5863 - 76s/epoch - 42ms/step
Epoch 28/50
1806/1806 - 74s - loss: 2.5813 - accuracy20: 0.5917 - val_loss: 2.7603 - val_accuracy20: 0.5895 - 74s/epoch - 41ms/step
Epoch 29/50
1806/1806 - 75s - loss: 2.5778 - accuracy20: 0.5921 - val_loss: 2.7811 - val_accuracy20: 0.5892 - 75s/epoch - 41ms/step
Epoch 30/50
1806/1806 - 76s - loss: 2.5752 - accuracy20: 0.5929 - val_loss: 2.7791 - val_accuracy20: 0.5897 - 76s/epoch - 42ms/step
Epoch 31/50
1806/1806 - 76s - loss: 2.5723 - accuracy20: 0.5937 - val_loss: 2.7757 - val_accuracy20: 0.5872 - 76s/epoch - 42ms/step
Epoch 32/50
1806/1806 - 77s - loss: 2.5685 - accuracy20: 0.5936 - val_loss: 2.7756 - val_accuracy20: 0.5875 - 77s/epoch - 43ms/step
Epoch 33/50
1806/1806 - 77s - loss: 2.5655 - accuracy20: 0.5940 - val_loss: 2.7886 - val_accuracy20: 0.5896 - 77s/epoch - 42ms/step
Epoch 34/50
1806/1806 - 76s - loss: 2.5631 - accuracy20: 0.5946 - val_loss: 2.7645 - val_accuracy20: 0.5898 - 76s/epoch - 42ms/step
Epoch 35/50
1806/1806 - 75s - loss: 2.5612 - accuracy20: 0.5946 - val_loss: 2.7685 - val_accuracy20: 0.5865 - 75s/epoch - 41ms/step
Epoch 36/50
1806/1806 - 77s - loss: 2.5574 - accuracy20: 0.5956 - val_loss: 2.7779 - val_accuracy20: 0.5885 - 77s/epoch - 43ms/step
testing model: results/ATVI/W5/deepVOL_L3/h20
Evaluating performance on  test set...
8238/8238 - 165s - 165s/epoch - 20ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 1.0002347
{'0': {'precision': 0.5072968067762138, 'recall': 0.4273867017903312, 'f1-score': 0.46392582535100324, 'support': 655968}, '1': {'precision': 0.6018913548101074, 'recall': 0.4828703390615881, 'f1-score': 0.5358513011979039, 'support': 798498}, '2': {'precision': 0.45318610209333726, 'recall': 0.6341341509641604, 'f1-score': 0.5286037545453851, 'support': 654248}, 'accuracy': 0.5125417671623558, 'macro avg': {'precision': 0.5207914212265529, 'recall': 0.5147970639386932, 'f1-score': 0.5094602936980974, 'support': 2108714}, 'weighted avg': {'precision': 0.5263281866117938, 'recall': 0.5125417671623558, 'f1-score': 0.5112284725721838, 'support': 2108714}}
[[280352 137408 238208]
 [150540 385571 262387]
 [121747 117620 414881]]
Evaluating performance on  train set...
1806/1806 - 36s - 36s/epoch - 20ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.87155175
{'0': {'precision': 0.5384658751367137, 'recall': 0.4168281400017457, 'f1-score': 0.46990293172750036, 'support': 114570}, '1': {'precision': 0.702046600735709, 'recall': 0.6879725675096442, 'f1-score': 0.6949383338781571, 'support': 233300}, '2': {'precision': 0.47218175918702665, 'recall': 0.5984268502882941, 'f1-score': 0.5278609576142994, 'support': 114293}, 'accuracy': 0.5986113124590242, 'macro avg': {'precision': 0.5708980783531498, 'recall': 0.5677425192665614, 'f1-score': 0.5642340744066523, 'support': 462163}, 'weighted avg': {'precision': 0.6046493922464954, 'recall': 0.5986113124590242, 'f1-score': 0.5978338910955764, 'support': 462163}}
[[ 47756  36522  30292]
 [ 26633 160504  46163]
 [ 14300  31597  68396]]
Evaluating performance on  val set...
642/642 - 13s - 13s/epoch - 20ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.8782634
{'0': {'precision': 0.5317705308841957, 'recall': 0.40591172079134, 'f1-score': 0.460394533162219, 'support': 42864}, '1': {'precision': 0.7031901395686061, 'recall': 0.6853980793256187, 'f1-score': 0.6941801241045238, 'support': 79243}, '2': {'precision': 0.4701186425089672, 'recall': 0.6054246121047021, 'f1-score': 0.5292607165044523, 'support': 42215}, 'accuracy': 0.591947517678704, 'macro avg': {'precision': 0.5683597709872563, 'recall': 0.5655781374072203, 'f1-score': 0.5612784579237317, 'support': 164322}, 'weighted avg': {'precision': 0.5985976726133522, 'recall': 0.591947517678704, 'f1-score': 0.5908278136288239, 'support': 164322}}
[[17399 12422 13043]
 [ 9166 54313 15764]
 [ 6154 10503 25558]]
training model: results/ATVI/W5/deepVOL_L3/h30
Epoch 1/50
1806/1806 - 79s - loss: 3.2299 - accuracy30: 0.4011 - val_loss: 3.4566 - val_accuracy30: 0.4139 - 79s/epoch - 44ms/step
Epoch 2/50
1806/1806 - 82s - loss: 3.0836 - accuracy30: 0.4451 - val_loss: 3.0483 - val_accuracy30: 0.5160 - 82s/epoch - 46ms/step
Epoch 3/50
1806/1806 - 80s - loss: 2.9166 - accuracy30: 0.5168 - val_loss: 2.9542 - val_accuracy30: 0.5361 - 80s/epoch - 44ms/step
Epoch 4/50
1806/1806 - 74s - loss: 2.8527 - accuracy30: 0.5382 - val_loss: 2.9188 - val_accuracy30: 0.5375 - 74s/epoch - 41ms/step
Epoch 5/50
1806/1806 - 74s - loss: 2.8134 - accuracy30: 0.5476 - val_loss: 2.8832 - val_accuracy30: 0.5450 - 74s/epoch - 41ms/step
Epoch 6/50
1806/1806 - 78s - loss: 2.7887 - accuracy30: 0.5524 - val_loss: 2.8626 - val_accuracy30: 0.5472 - 78s/epoch - 43ms/step
Epoch 7/50
1806/1806 - 76s - loss: 2.7747 - accuracy30: 0.5549 - val_loss: 2.8573 - val_accuracy30: 0.5459 - 76s/epoch - 42ms/step
Epoch 8/50
1806/1806 - 81s - loss: 2.7632 - accuracy30: 0.5566 - val_loss: 2.8939 - val_accuracy30: 0.5449 - 81s/epoch - 45ms/step
Epoch 9/50
1806/1806 - 79s - loss: 2.7520 - accuracy30: 0.5584 - val_loss: 2.8706 - val_accuracy30: 0.5476 - 79s/epoch - 44ms/step
Epoch 10/50
1806/1806 - 85s - loss: 2.7433 - accuracy30: 0.5605 - val_loss: 2.8753 - val_accuracy30: 0.5486 - 85s/epoch - 47ms/step
Epoch 11/50
1806/1806 - 84s - loss: 2.7366 - accuracy30: 0.5617 - val_loss: 2.9106 - val_accuracy30: 0.5478 - 84s/epoch - 47ms/step
Epoch 12/50
1806/1806 - 84s - loss: 2.7295 - accuracy30: 0.5633 - val_loss: 2.8799 - val_accuracy30: 0.5515 - 84s/epoch - 47ms/step
Epoch 13/50
1806/1806 - 83s - loss: 2.7243 - accuracy30: 0.5638 - val_loss: 2.9042 - val_accuracy30: 0.5476 - 83s/epoch - 46ms/step
Epoch 14/50
1806/1806 - 84s - loss: 2.7193 - accuracy30: 0.5653 - val_loss: 2.8594 - val_accuracy30: 0.5522 - 84s/epoch - 47ms/step
Epoch 15/50
1806/1806 - 81s - loss: 2.7136 - accuracy30: 0.5664 - val_loss: 2.8957 - val_accuracy30: 0.5504 - 81s/epoch - 45ms/step
Epoch 16/50
1806/1806 - 81s - loss: 2.7104 - accuracy30: 0.5672 - val_loss: 2.8605 - val_accuracy30: 0.5558 - 81s/epoch - 45ms/step
Epoch 17/50
1806/1806 - 80s - loss: 2.7056 - accuracy30: 0.5684 - val_loss: 2.8708 - val_accuracy30: 0.5493 - 80s/epoch - 44ms/step
testing model: results/ATVI/W5/deepVOL_L3/h30
Evaluating performance on  test set...
8238/8238 - 162s - 162s/epoch - 20ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.0250769
{'0': {'precision': 0.5327702920508026, 'recall': 0.28090811933853105, 'f1-score': 0.36785909195720556, 'support': 735454}, '1': {'precision': 0.5097310747405258, 'recall': 0.4387373727919935, 'f1-score': 0.4715772530839617, 'support': 641076}, '2': {'precision': 0.4458632339733995, 'recall': 0.7119535526588945, 'f1-score': 0.5483318554236132, 'support': 732184}, 'accuracy': 0.47855707317350765, 'macro avg': {'precision': 0.4961215335882427, 'recall': 0.477199681596473, 'f1-score': 0.46258940015492683, 'support': 2108714}, 'weighted avg': {'precision': 0.49559035836242743, 'recall': 0.47855707317350765, 'f1-score': 0.462054176595703, 'support': 2108714}}
[[206595 152218 376641]
 [ 88584 281264 271228]
 [ 92596 118307 521281]]
Evaluating performance on  train set...
1806/1806 - 35s - 35s/epoch - 20ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.94116294
{'0': {'precision': 0.5590171713277381, 'recall': 0.2860622524395611, 'f1-score': 0.378458418664418, 'support': 131786}, '1': {'precision': 0.6123194600674916, 'recall': 0.683598223793928, 'f1-score': 0.6459985854184171, 'support': 199076}, '2': {'precision': 0.46122626467604, 'recall': 0.6058598182801349, 'f1-score': 0.5237411777098915, 'support': 131301}, 'accuracy': 0.5481550881398987, 'macro avg': {'precision': 0.5441876320237565, 'recall': 0.5251734315045413, 'f1-score': 0.5160660605975755, 'support': 462163}, 'weighted avg': {'precision': 0.5541945494365018, 'recall': 0.5481550881398987, 'f1-score': 0.5349759195940659, 'support': 462163}}
[[ 37699  48111  45976]
 [ 16039 136088  46949]
 [ 13700  38051  79550]]
Evaluating performance on  val set...
642/642 - 12s - 12s/epoch - 19ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.9331813
{'0': {'precision': 0.5481842731046713, 'recall': 0.27960282871474385, 'f1-score': 0.37032196582941934, 'support': 48644}, '1': {'precision': 0.62456207314912, 'recall': 0.677741453528794, 'f1-score': 0.6500659770995616, 'support': 67601}, '2': {'precision': 0.4594280013302295, 'recall': 0.6321733885225783, 'f1-score': 0.5321322583186701, 'support': 48077}, 'accuracy': 0.546548849210696, 'macro avg': {'precision': 0.5440581158613403, 'recall': 0.5298392235887054, 'f1-score': 0.5175067337492171, 'support': 164322}, 'weighted avg': {'precision': 0.553637470988734, 'recall': 0.546548849210696, 'f1-score': 0.5327489587937125, 'support': 164322}}
[[13601 15364 19679]
 [ 5703 45816 16082]
 [ 5507 12177 30393]]
training model: results/ATVI/W5/deepVOL_L3/h50
Epoch 1/50
1806/1806 - 82s - loss: 3.2613 - accuracy50: 0.3874 - val_loss: 3.3210 - val_accuracy50: 0.3289 - 82s/epoch - 46ms/step
Epoch 2/50
1806/1806 - 76s - loss: 3.2018 - accuracy50: 0.4117 - val_loss: 3.1058 - val_accuracy50: 0.4435 - 76s/epoch - 42ms/step
Epoch 3/50
1806/1806 - 78s - loss: 3.0761 - accuracy50: 0.4598 - val_loss: 3.0720 - val_accuracy50: 0.4542 - 78s/epoch - 43ms/step
Epoch 4/50
1806/1806 - 78s - loss: 2.9940 - accuracy50: 0.4900 - val_loss: 2.9892 - val_accuracy50: 0.4829 - 78s/epoch - 43ms/step
Epoch 5/50
1806/1806 - 78s - loss: 2.9517 - accuracy50: 0.4992 - val_loss: 2.9751 - val_accuracy50: 0.4848 - 78s/epoch - 43ms/step
Epoch 6/50
1806/1806 - 76s - loss: 2.9346 - accuracy50: 0.5043 - val_loss: 2.9589 - val_accuracy50: 0.4880 - 76s/epoch - 42ms/step
Epoch 7/50
1806/1806 - 74s - loss: 2.9165 - accuracy50: 0.5089 - val_loss: 2.9424 - val_accuracy50: 0.4965 - 74s/epoch - 41ms/step
Epoch 8/50
1806/1806 - 75s - loss: 2.9086 - accuracy50: 0.5116 - val_loss: 2.9484 - val_accuracy50: 0.4949 - 75s/epoch - 41ms/step
Epoch 9/50
1806/1806 - 74s - loss: 2.8985 - accuracy50: 0.5147 - val_loss: 2.9378 - val_accuracy50: 0.4989 - 74s/epoch - 41ms/step
Epoch 10/50
1806/1806 - 77s - loss: 2.8914 - accuracy50: 0.5167 - val_loss: 2.9505 - val_accuracy50: 0.4966 - 77s/epoch - 43ms/step
Epoch 11/50
1806/1806 - 78s - loss: 2.8842 - accuracy50: 0.5182 - val_loss: 2.9462 - val_accuracy50: 0.4965 - 78s/epoch - 43ms/step
Epoch 12/50
1806/1806 - 77s - loss: 2.8795 - accuracy50: 0.5196 - val_loss: 2.9336 - val_accuracy50: 0.5014 - 77s/epoch - 43ms/step
Epoch 13/50
1806/1806 - 79s - loss: 2.8740 - accuracy50: 0.5215 - val_loss: 2.9268 - val_accuracy50: 0.5000 - 79s/epoch - 44ms/step
Epoch 14/50
1806/1806 - 76s - loss: 2.8693 - accuracy50: 0.5225 - val_loss: 2.9322 - val_accuracy50: 0.5019 - 76s/epoch - 42ms/step
Epoch 15/50
1806/1806 - 77s - loss: 2.8649 - accuracy50: 0.5240 - val_loss: 2.9311 - val_accuracy50: 0.5008 - 77s/epoch - 42ms/step
Epoch 16/50
1806/1806 - 75s - loss: 2.8609 - accuracy50: 0.5242 - val_loss: 2.9326 - val_accuracy50: 0.4992 - 75s/epoch - 42ms/step
Epoch 17/50
1806/1806 - 77s - loss: 2.8581 - accuracy50: 0.5253 - val_loss: 2.9124 - val_accuracy50: 0.5032 - 77s/epoch - 43ms/step
Epoch 18/50
1806/1806 - 77s - loss: 2.8541 - accuracy50: 0.5262 - val_loss: 2.9204 - val_accuracy50: 0.4999 - 77s/epoch - 43ms/step
Epoch 19/50
1806/1806 - 75s - loss: 2.8507 - accuracy50: 0.5269 - val_loss: 2.9266 - val_accuracy50: 0.5011 - 75s/epoch - 42ms/step
Epoch 20/50
1806/1806 - 79s - loss: 2.8476 - accuracy50: 0.5280 - val_loss: 2.9193 - val_accuracy50: 0.5020 - 79s/epoch - 44ms/step
Epoch 21/50
1806/1806 - 78s - loss: 2.8442 - accuracy50: 0.5286 - val_loss: 2.9151 - val_accuracy50: 0.5028 - 78s/epoch - 43ms/step
Epoch 22/50
1806/1806 - 75s - loss: 2.8411 - accuracy50: 0.5293 - val_loss: 2.9113 - val_accuracy50: 0.5043 - 75s/epoch - 42ms/step
Epoch 23/50
1806/1806 - 75s - loss: 2.8370 - accuracy50: 0.5305 - val_loss: 2.9152 - val_accuracy50: 0.5045 - 75s/epoch - 41ms/step
Epoch 24/50
1806/1806 - 75s - loss: 2.8352 - accuracy50: 0.5312 - val_loss: 2.9102 - val_accuracy50: 0.5053 - 75s/epoch - 41ms/step
Epoch 25/50
1806/1806 - 74s - loss: 2.8327 - accuracy50: 0.5313 - val_loss: 2.9057 - val_accuracy50: 0.5059 - 74s/epoch - 41ms/step
Epoch 26/50
1806/1806 - 75s - loss: 2.8298 - accuracy50: 0.5324 - val_loss: 2.9243 - val_accuracy50: 0.5030 - 75s/epoch - 41ms/step
Epoch 27/50
1806/1806 - 74s - loss: 2.8263 - accuracy50: 0.5331 - val_loss: 2.9167 - val_accuracy50: 0.5029 - 74s/epoch - 41ms/step
Epoch 28/50
1806/1806 - 74s - loss: 2.8230 - accuracy50: 0.5336 - val_loss: 2.9069 - val_accuracy50: 0.5067 - 74s/epoch - 41ms/step
Epoch 29/50
1806/1806 - 75s - loss: 2.8232 - accuracy50: 0.5337 - val_loss: 2.9135 - val_accuracy50: 0.5048 - 75s/epoch - 41ms/step
Epoch 30/50
1806/1806 - 75s - loss: 2.8183 - accuracy50: 0.5355 - val_loss: 2.9267 - val_accuracy50: 0.5034 - 75s/epoch - 41ms/step
Epoch 31/50
1806/1806 - 75s - loss: 2.8169 - accuracy50: 0.5356 - val_loss: 2.9216 - val_accuracy50: 0.5069 - 75s/epoch - 42ms/step
Epoch 32/50
1806/1806 - 76s - loss: 2.8115 - accuracy50: 0.5375 - val_loss: 2.9141 - val_accuracy50: 0.5043 - 76s/epoch - 42ms/step
Epoch 33/50
1806/1806 - 77s - loss: 2.8113 - accuracy50: 0.5373 - val_loss: 2.9178 - val_accuracy50: 0.5037 - 77s/epoch - 42ms/step
Epoch 34/50
1806/1806 - 75s - loss: 2.8094 - accuracy50: 0.5380 - val_loss: 2.9176 - val_accuracy50: 0.5027 - 75s/epoch - 41ms/step
Epoch 35/50
1806/1806 - 75s - loss: 2.8053 - accuracy50: 0.5394 - val_loss: 2.9309 - val_accuracy50: 0.5025 - 75s/epoch - 42ms/step
testing model: results/ATVI/W5/deepVOL_L3/h50
Evaluating performance on  test set...
8238/8238 - 154s - 154s/epoch - 19ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0186751
{'0': {'precision': 0.5401675643894852, 'recall': 0.2746428450890296, 'f1-score': 0.3641415352159946, 'support': 829612}, '1': {'precision': 0.39235839376706494, 'recall': 0.344848142090702, 'f1-score': 0.36707233737919365, 'support': 457961}, '2': {'precision': 0.4562896732245976, 'recall': 0.7137117742263509, 'f1-score': 0.5566818963306325, 'support': 821141}, 'accuracy': 0.4608647735065068, 'macro avg': {'precision': 0.4629385437937159, 'recall': 0.4444009204686942, 'f1-score': 0.4292985896419402, 'support': 2108714}, 'weighted avg': {'precision': 0.4754046752464145, 'recall': 0.4608647735065068, 'f1-score': 0.43975395954451696, 'support': 2108714}}
[[227847 136231 465534]
 [ 67227 157927 232807]
 [126734 108349 586058]]
Evaluating performance on  train set...
1806/1806 - 41s - 41s/epoch - 23ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.9857483
{'0': {'precision': 0.5891930014105219, 'recall': 0.25385157457152646, 'f1-score': 0.3548271951346247, 'support': 154677}, '1': {'precision': 0.49581275397074637, 'recall': 0.6759451464749994, 'f1-score': 0.5720332237221329, 'support': 154156}, '2': {'precision': 0.47880599269525626, 'recall': 0.578823452683754, 'f1-score': 0.5240855179825741, 'support': 153330}, 'accuracy': 0.5024569253704861, 'macro avg': {'precision': 0.5212705826921749, 'recall': 0.5028733912434267, 'f1-score': 0.4836486456131106, 'support': 462163}, 'weighted avg': {'precision': 0.5214230469342057, 'recall': 0.5024569253704861, 'f1-score': 0.48343115344632853, 'support': 462163}}
[[ 39265  58110  57302]
 [ 10649 104201  39306]
 [ 16728  47851  88751]]
Evaluating performance on  val set...
642/642 - 15s - 15s/epoch - 24ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.96885514
{'0': {'precision': 0.5657991053273689, 'recall': 0.24843311965430423, 'f1-score': 0.34526571786631594, 'support': 56003}, '1': {'precision': 0.5165047125009132, 'recall': 0.6703903197663392, 'f1-score': 0.5834715791385016, 'support': 52726}, '2': {'precision': 0.47340000280516714, 'recall': 0.6071267965391326, 'f1-score': 0.5319883363543226, 'support': 55593}, 'accuracy': 0.5051788561482942, 'macro avg': {'precision': 0.5185679402111497, 'recall': 0.5086500786532587, 'f1-score': 0.48690854445304677, 'support': 164322}, 'weighted avg': {'precision': 0.5187217848061698, 'recall': 0.5051788561482942, 'f1-score': 0.48487035249248295, 'support': 164322}}
[[13913 18140 23950]
 [ 3784 35347 13595]
 [ 6893 14948 33752]]
training model: results/ATVI/W5/deepVOL_L3/h100
Epoch 1/50
1806/1806 - 79s - loss: 3.2993 - accuracy100: 0.3617 - val_loss: 3.3171 - val_accuracy100: 0.3366 - 79s/epoch - 44ms/step
Epoch 2/50
1806/1806 - 75s - loss: 3.2728 - accuracy100: 0.3749 - val_loss: 3.3011 - val_accuracy100: 0.3698 - 75s/epoch - 42ms/step
Epoch 3/50
1806/1806 - 74s - loss: 3.2452 - accuracy100: 0.3936 - val_loss: 3.3112 - val_accuracy100: 0.3567 - 74s/epoch - 41ms/step
Epoch 4/50
1806/1806 - 74s - loss: 3.2224 - accuracy100: 0.4064 - val_loss: 3.2878 - val_accuracy100: 0.3604 - 74s/epoch - 41ms/step
Epoch 5/50
1806/1806 - 74s - loss: 3.1978 - accuracy100: 0.4192 - val_loss: 3.2159 - val_accuracy100: 0.4068 - 74s/epoch - 41ms/step
Epoch 6/50
1806/1806 - 73s - loss: 3.1842 - accuracy100: 0.4268 - val_loss: 3.2138 - val_accuracy100: 0.4100 - 73s/epoch - 40ms/step
Epoch 7/50
1806/1806 - 72s - loss: 3.1762 - accuracy100: 0.4310 - val_loss: 3.2199 - val_accuracy100: 0.4102 - 72s/epoch - 40ms/step
Epoch 8/50
1806/1806 - 73s - loss: 3.1686 - accuracy100: 0.4351 - val_loss: 3.2188 - val_accuracy100: 0.4120 - 73s/epoch - 40ms/step
Epoch 9/50
1806/1806 - 75s - loss: 3.1616 - accuracy100: 0.4381 - val_loss: 3.2205 - val_accuracy100: 0.4122 - 75s/epoch - 41ms/step
Epoch 10/50
1806/1806 - 73s - loss: 3.1538 - accuracy100: 0.4405 - val_loss: 3.2102 - val_accuracy100: 0.4177 - 73s/epoch - 40ms/step
Epoch 11/50
1806/1806 - 73s - loss: 3.1488 - accuracy100: 0.4430 - val_loss: 3.2230 - val_accuracy100: 0.4162 - 73s/epoch - 40ms/step
Epoch 12/50
1806/1806 - 75s - loss: 3.1441 - accuracy100: 0.4450 - val_loss: 3.2214 - val_accuracy100: 0.4162 - 75s/epoch - 41ms/step
Epoch 13/50
1806/1806 - 76s - loss: 3.1390 - accuracy100: 0.4470 - val_loss: 3.2282 - val_accuracy100: 0.4167 - 76s/epoch - 42ms/step
Epoch 14/50
1806/1806 - 74s - loss: 3.1328 - accuracy100: 0.4496 - val_loss: 3.2220 - val_accuracy100: 0.4194 - 74s/epoch - 41ms/step
Epoch 15/50
1806/1806 - 75s - loss: 3.1283 - accuracy100: 0.4501 - val_loss: 3.2489 - val_accuracy100: 0.4153 - 75s/epoch - 41ms/step
Epoch 16/50
1806/1806 - 76s - loss: 3.1216 - accuracy100: 0.4529 - val_loss: 3.2653 - val_accuracy100: 0.4159 - 76s/epoch - 42ms/step
Epoch 17/50
1806/1806 - 75s - loss: 3.1168 - accuracy100: 0.4548 - val_loss: 3.2742 - val_accuracy100: 0.4145 - 75s/epoch - 41ms/step
Epoch 18/50
1806/1806 - 73s - loss: 3.1122 - accuracy100: 0.4566 - val_loss: 3.2739 - val_accuracy100: 0.4156 - 73s/epoch - 40ms/step
Epoch 19/50
1806/1806 - 75s - loss: 3.1075 - accuracy100: 0.4584 - val_loss: 3.2744 - val_accuracy100: 0.4164 - 75s/epoch - 41ms/step
Epoch 20/50
1806/1806 - 73s - loss: 3.1026 - accuracy100: 0.4600 - val_loss: 3.2830 - val_accuracy100: 0.4195 - 73s/epoch - 40ms/step
testing model: results/ATVI/W5/deepVOL_L3/h100
Evaluating performance on  test set...
8238/8238 - 154s - 154s/epoch - 19ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0734111
{'0': {'precision': 0.45729362742732116, 'recall': 0.21662762871093452, 'f1-score': 0.2939881573163479, 'support': 787268}, '1': {'precision': 0.3620330823408776, 'recall': 0.15671231949203865, 'f1-score': 0.21873945818517365, 'support': 531694}, '2': {'precision': 0.40493843395972023, 'recall': 0.7719929800747577, 'f1-score': 0.5312282851007528, 'support': 789752}, 'accuracy': 0.4095149934984071, 'macro avg': {'precision': 0.4080883812426397, 'recall': 0.38177764275924364, 'f1-score': 0.3479853002007582, 'support': 2108714}, 'weighted avg': {'precision': 0.4136665262601566, 'recall': 0.4095149934984071, 'f1-score': 0.3638656198656262, 'support': 2108714}}
[[170544  79458 537266]
 [ 89701  83323 358670]
 [112697  67372 609683]]
Evaluating performance on  train set...
1806/1806 - 34s - 34s/epoch - 19ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0716244
{'0': {'precision': 0.4825011201274456, 'recall': 0.18786829318722217, 'f1-score': 0.27043794092889795, 'support': 154768}, '1': {'precision': 0.4305621128231541, 'recall': 0.39165544211711273, 'f1-score': 0.4101882613510521, 'support': 153681}, '2': {'precision': 0.39192622888275064, 'recall': 0.6682995693300545, 'f1-score': 0.4940912217246803, 'support': 153714}, 'accuracy': 0.4154226971869232, 'macro avg': {'precision': 0.4349964872777834, 'recall': 0.41594110154479647, 'f1-score': 0.3915724746682101, 'support': 462163}, 'weighted avg': {'precision': 0.4351051420540865, 'recall': 0.4154226971869232, 'f1-score': 0.39129488836311477, 'support': 462163}}
[[ 29076  43031  82661]
 [ 16771  60190  76720]
 [ 14414  36573 102727]]
Evaluating performance on  val set...
642/642 - 12s - 12s/epoch - 19ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0707037
{'0': {'precision': 0.45914342068188224, 'recall': 0.17979697671852587, 'f1-score': 0.2584046939422772, 'support': 54378}, '1': {'precision': 0.45285288959582365, 'recall': 0.4027311800656499, 'f1-score': 0.4263239232474875, 'support': 55141}, '2': {'precision': 0.3892541759761677, 'recall': 0.6675911902633067, 'f1-score': 0.491770446190345, 'support': 54803}, 'accuracy': 0.41729044193717213, 'macro avg': {'precision': 0.4337501620846245, 'recall': 0.4167064490158275, 'f1-score': 0.3921663544600366, 'support': 164322}, 'weighted avg': {'precision': 0.4337237784415028, 'recall': 0.41729044193717213, 'f1-score': 0.3925825736149289, 'support': 164322}}
[[ 9777 14179 30422]
 [ 5952 22207 26982]
 [ 5565 12652 36586]]
training model: results/ATVI/W5/deepVOL_L3/h200
Epoch 1/50
1806/1806 - 76s - loss: 3.2987 - accuracy200: 0.3607 - val_loss: 3.3429 - val_accuracy200: 0.3288 - 76s/epoch - 42ms/step
Epoch 2/50
1806/1806 - 78s - loss: 3.2868 - accuracy200: 0.3597 - val_loss: 3.3281 - val_accuracy200: 0.3282 - 78s/epoch - 43ms/step
Epoch 3/50
1806/1806 - 74s - loss: 3.2714 - accuracy200: 0.3753 - val_loss: 3.3301 - val_accuracy200: 0.3358 - 74s/epoch - 41ms/step
Epoch 4/50
1806/1806 - 73s - loss: 3.2573 - accuracy200: 0.3863 - val_loss: 3.3516 - val_accuracy200: 0.3329 - 73s/epoch - 40ms/step
Epoch 5/50
1806/1806 - 73s - loss: 3.2471 - accuracy200: 0.3940 - val_loss: 3.3277 - val_accuracy200: 0.3428 - 73s/epoch - 40ms/step
Epoch 6/50
1806/1806 - 75s - loss: 3.2414 - accuracy200: 0.3971 - val_loss: 3.3453 - val_accuracy200: 0.3435 - 75s/epoch - 42ms/step
Epoch 7/50
1806/1806 - 75s - loss: 3.2341 - accuracy200: 0.4011 - val_loss: 3.3323 - val_accuracy200: 0.3479 - 75s/epoch - 41ms/step
Epoch 8/50
1806/1806 - 75s - loss: 3.2286 - accuracy200: 0.4059 - val_loss: 3.3328 - val_accuracy200: 0.3491 - 75s/epoch - 41ms/step
Epoch 9/50
1806/1806 - 74s - loss: 3.2236 - accuracy200: 0.4083 - val_loss: 3.3389 - val_accuracy200: 0.3449 - 74s/epoch - 41ms/step
Epoch 10/50
1806/1806 - 74s - loss: 3.2163 - accuracy200: 0.4130 - val_loss: 3.3340 - val_accuracy200: 0.3543 - 74s/epoch - 41ms/step
Epoch 11/50
1806/1806 - 71s - loss: 3.2101 - accuracy200: 0.4155 - val_loss: 3.3349 - val_accuracy200: 0.3587 - 71s/epoch - 40ms/step
Epoch 12/50
1806/1806 - 71s - loss: 3.2046 - accuracy200: 0.4192 - val_loss: 3.3419 - val_accuracy200: 0.3584 - 71s/epoch - 39ms/step
Epoch 13/50
1806/1806 - 71s - loss: 3.2013 - accuracy200: 0.4212 - val_loss: 3.3458 - val_accuracy200: 0.3575 - 71s/epoch - 40ms/step
Epoch 14/50
1806/1806 - 71s - loss: 3.1968 - accuracy200: 0.4234 - val_loss: 3.3665 - val_accuracy200: 0.3574 - 71s/epoch - 39ms/step
Epoch 15/50
1806/1806 - 72s - loss: 3.1910 - accuracy200: 0.4262 - val_loss: 3.3780 - val_accuracy200: 0.3529 - 72s/epoch - 40ms/step
testing model: results/ATVI/W5/deepVOL_L3/h200
Evaluating performance on  test set...
8238/8238 - 150s - 150s/epoch - 18ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1219839
{'0': {'precision': 0.3792208201726956, 'recall': 0.09607930600587206, 'f1-score': 0.15331480560761168, 'support': 751015}, '1': {'precision': 0.2847792494710994, 'recall': 0.6911165183420195, 'f1-score': 0.4033538209343054, 'support': 593855}, '2': {'precision': 0.36708783840415726, 'recall': 0.22935180481878498, 'f1-score': 0.28231610430881393, 'support': 763844}, 'accuracy': 0.31192897661797664, 'macro avg': {'precision': 0.3436959693493174, 'recall': 0.33884920972222554, 'f1-score': 0.2796615769502437, 'support': 2108714}, 'weighted avg': {'precision': 0.34822927542314497, 'recall': 0.31192897661797664, 'f1-score': 0.27045908759746656, 'support': 2108714}}
[[ 72157 508249 170609]
 [ 51990 410423 131442]
 [ 66130 522525 175189]]
Evaluating performance on  train set...
1806/1806 - 35s - 35s/epoch - 19ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1127784
{'0': {'precision': 0.40936258305786505, 'recall': 0.07881507386502437, 'f1-score': 0.13218115070915298, 'support': 155554}, '1': {'precision': 0.33683011959836123, 'recall': 0.8023023680374053, 'f1-score': 0.47446562276695564, 'support': 152278}, '2': {'precision': 0.36051798561151077, 'recall': 0.1623523465797539, 'f1-score': 0.22388319759103964, 'support': 154331}, 'accuracy': 0.34509253228839176, 'macro avg': {'precision': 0.36890356275591235, 'recall': 0.3478232628273945, 'f1-score': 0.27684332368904946, 'support': 462163}, 'weighted avg': {'precision': 0.3691531027680547, 'recall': 0.34509253228839176, 'f1-score': 0.2755826420300647, 'support': 462163}}
[[ 12260 120422  22872]
 [  8533 122173  21572]
 [  9156 120119  25056]]
Evaluating performance on  val set...
642/642 - 12s - 12s/epoch - 19ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1105034
{'0': {'precision': 0.38842697572856305, 'recall': 0.08450112363656295, 'f1-score': 0.13880552220888356, 'support': 54733}, '1': {'precision': 0.3355374515542197, 'recall': 0.7861021032150468, 'f1-score': 0.4703234568585603, 'support': 53965}, '2': {'precision': 0.3592457186838561, 'recall': 0.1678232417661441, 'f1-score': 0.2287737872048426, 'support': 55624}, 'accuracy': 0.34311899806477525, 'macro avg': {'precision': 0.36107004865554626, 'recall': 0.34614215620591793, 'f1-score': 0.2793009220907621, 'support': 164322}, 'weighted avg': {'precision': 0.36117948961031215, 'recall': 0.34311899806477525, 'f1-score': 0.2781341581523667, 'support': 164322}}
[[ 4625 41476  8632]
 [ 3525 42422  8018]
 [ 3757 42532  9335]]
training model: results/ATVI/W5/deepVOL_L3/h300
Epoch 1/50
1806/1806 - 77s - loss: 3.2939 - accuracy300: 0.3652 - val_loss: 3.3210 - val_accuracy300: 0.3365 - 77s/epoch - 43ms/step
Epoch 2/50
1806/1806 - 77s - loss: 3.2883 - accuracy300: 0.3610 - val_loss: 3.3230 - val_accuracy300: 0.3361 - 77s/epoch - 43ms/step
Epoch 3/50
1806/1806 - 75s - loss: 3.2832 - accuracy300: 0.3653 - val_loss: 3.3657 - val_accuracy300: 0.3288 - 75s/epoch - 41ms/step
Epoch 4/50
1806/1806 - 73s - loss: 3.2737 - accuracy300: 0.3736 - val_loss: 3.3665 - val_accuracy300: 0.3291 - 73s/epoch - 40ms/step
Epoch 5/50
1806/1806 - 73s - loss: 3.2624 - accuracy300: 0.3828 - val_loss: 3.3441 - val_accuracy300: 0.3335 - 73s/epoch - 41ms/step
Epoch 6/50
1806/1806 - 73s - loss: 3.2520 - accuracy300: 0.3920 - val_loss: 3.3458 - val_accuracy300: 0.3334 - 73s/epoch - 41ms/step
Epoch 7/50
1806/1806 - 73s - loss: 3.2449 - accuracy300: 0.3968 - val_loss: 3.3548 - val_accuracy300: 0.3327 - 73s/epoch - 40ms/step
Epoch 8/50
1806/1806 - 74s - loss: 3.2386 - accuracy300: 0.3999 - val_loss: 3.3676 - val_accuracy300: 0.3334 - 74s/epoch - 41ms/step
Epoch 9/50
1806/1806 - 73s - loss: 3.2338 - accuracy300: 0.4039 - val_loss: 3.3709 - val_accuracy300: 0.3365 - 73s/epoch - 40ms/step
Epoch 10/50
1806/1806 - 73s - loss: 3.2327 - accuracy300: 0.4063 - val_loss: 3.3645 - val_accuracy300: 0.3330 - 73s/epoch - 40ms/step
Epoch 11/50
1806/1806 - 73s - loss: 3.2323 - accuracy300: 0.4060 - val_loss: 3.3649 - val_accuracy300: 0.3350 - 73s/epoch - 40ms/step
testing model: results/ATVI/W5/deepVOL_L3/h300
Evaluating performance on  test set...
8238/8238 - 151s - 151s/epoch - 18ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1111375
{'0': {'precision': 0.3493486719675182, 'recall': 0.0027503959105009182, 'f1-score': 0.005457822791233653, 'support': 750801}, '1': {'precision': 0.27360014647438313, 'recall': 0.0857221432982281, 'f1-score': 0.1305434793779998, 'support': 592694}, '2': {'precision': 0.3636368378362166, 'recall': 0.9110202438778964, 'f1-score': 0.5197955206007925, 'support': 765219}, 'accuracy': 0.355667956868499, 'macro avg': {'precision': 0.3288618854260393, 'recall': 0.33316426102887514, 'f1-score': 0.21859894092334198, 'support': 2108714}, 'weighted avg': {'precision': 0.3332430642033792, 'recall': 0.355667956868499, 'f1-score': 0.22726054090529255, 'support': 2108714}}
[[  2065  68878 679858]
 [  1770  50807 540117]
 [  2076  66013 697130]]
Evaluating performance on  train set...
1806/1806 - 39s - 39s/epoch - 22ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1082268
{'0': {'precision': 0.34277620396600567, 'recall': 0.0023437348674143375, 'f1-score': 0.004655636783378222, 'support': 154881}, '1': {'precision': 0.3312201772324472, 'recall': 0.09535740218621416, 'f1-score': 0.14808230519562976, 'support': 152867}, '2': {'precision': 0.33475907109668324, 'recall': 0.9042256257487938, 'f1-score': 0.48862222642163117, 'support': 154415}, 'accuracy': 0.334440446336033, 'macro avg': {'precision': 0.336251817431712, 'recall': 0.3339755876008075, 'f1-score': 0.21378672280021305, 'support': 462163}, 'weighted avg': {'precision': 0.3362752493013196, 'recall': 0.334440446336033, 'f1-score': 0.21379593027110114, 'support': 462163}}
[[   363  14992 139526]
 [   348  14577 137942]
 [   348  14441 139626]]
Evaluating performance on  val set...
642/642 - 14s - 14s/epoch - 22ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1076353
{'0': {'precision': 0.3008595988538682, 'recall': 0.0019273835309666287, 'f1-score': 0.003830229631385996, 'support': 54478}, '1': {'precision': 0.33042550520898706, 'recall': 0.09668533651638968, 'f1-score': 0.14959723820483314, 'support': 54455}, '2': {'precision': 0.33831625450050323, 'recall': 0.9042228601346838, 'f1-score': 0.4924002595512909, 'support': 55389}, 'accuracy': 0.33747154976205257, 'macro avg': {'precision': 0.3232004528544528, 'recall': 0.3342785267273467, 'f1-score': 0.21527590912917002, 'support': 164322}, 'weighted avg': {'precision': 0.3232832434673677, 'recall': 0.33747154976205257, 'f1-score': 0.2168214775415908, 'support': 164322}}
[[  105  5485 48888]
 [  123  5265 49067]
 [  121  5184 50084]]
training model: results/ATVI/W5/deepVOL_L3/h500
Epoch 1/50
1806/1806 - 78s - loss: 3.2717 - accuracy500: 0.3886 - val_loss: 3.3466 - val_accuracy500: 0.3275 - 78s/epoch - 43ms/step
Epoch 2/50
1806/1806 - 81s - loss: 3.2745 - accuracy500: 0.3745 - val_loss: 3.4130 - val_accuracy500: 0.3286 - 81s/epoch - 45ms/step
Epoch 3/50
1806/1806 - 79s - loss: 3.2567 - accuracy500: 0.3848 - val_loss: 3.5337 - val_accuracy500: 0.3269 - 79s/epoch - 44ms/step
Epoch 4/50
1806/1806 - 74s - loss: 3.2486 - accuracy500: 0.3902 - val_loss: 3.4723 - val_accuracy500: 0.3280 - 74s/epoch - 41ms/step
Epoch 5/50
1806/1806 - 73s - loss: 3.2410 - accuracy500: 0.3953 - val_loss: 3.8061 - val_accuracy500: 0.3280 - 73s/epoch - 40ms/step
Epoch 6/50
1806/1806 - 77s - loss: 3.2346 - accuracy500: 0.4006 - val_loss: 3.5610 - val_accuracy500: 0.3269 - 77s/epoch - 42ms/step
Epoch 7/50
1806/1806 - 73s - loss: 3.2289 - accuracy500: 0.4053 - val_loss: 3.5263 - val_accuracy500: 0.3276 - 73s/epoch - 40ms/step
Epoch 8/50
1806/1806 - 72s - loss: 3.2213 - accuracy500: 0.4088 - val_loss: 3.6934 - val_accuracy500: 0.3269 - 72s/epoch - 40ms/step
Epoch 9/50
1806/1806 - 72s - loss: 3.2173 - accuracy500: 0.4123 - val_loss: 3.8050 - val_accuracy500: 0.3269 - 72s/epoch - 40ms/step
Epoch 10/50
1806/1806 - 76s - loss: 3.2137 - accuracy500: 0.4146 - val_loss: 3.7409 - val_accuracy500: 0.3269 - 76s/epoch - 42ms/step
Epoch 11/50
1806/1806 - 72s - loss: 3.2049 - accuracy500: 0.4191 - val_loss: 3.7780 - val_accuracy500: 0.3272 - 72s/epoch - 40ms/step
testing model: results/ATVI/W5/deepVOL_L3/h500
Evaluating performance on  test set...
8238/8238 - 151s - 151s/epoch - 18ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1343926
{'0': {'precision': 0.3788659793814433, 'recall': 0.00019413962468980582, 'f1-score': 0.0003880803880803881, 'support': 757187}, '1': {'precision': 0.27508818852207606, 'recall': 0.9884152504078895, 'f1-score': 0.4303927514001356, 'support': 579814}, '2': {'precision': 0.37144571085782846, 'recall': 0.012035562443550906, 'f1-score': 0.023315652464234525, 'support': 771713}, 'accuracy': 0.2762498850010006, 'macro avg': {'precision': 0.34179995958711595, 'recall': 0.33354831749204344, 'f1-score': 0.15136549475081684, 'support': 2108714}, 'weighted avg': {'precision': 0.34761558994385355, 'recall': 0.2762498850010006, 'f1-score': 0.12701323379806814, 'support': 2108714}}
[[   147 747954   9086]
 [    86 573097   6631]
 [   155 762270   9288]]
Evaluating performance on  train set...
1806/1806 - 38s - 38s/epoch - 21ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1181401
{'0': {'precision': 0.3, 'recall': 0.00011565076040374966, 'f1-score': 0.00023121238784593547, 'support': 155641}, '1': {'precision': 0.3276790015327348, 'recall': 0.98872863494916, 'f1-score': 0.4922268800457852, 'support': 151357}, '2': {'precision': 0.3529520636683324, 'recall': 0.012290142751264783, 'f1-score': 0.023753176224403368, 'support': 155165}, 'accuracy': 0.3279708674212345, 'macro avg': {'precision': 0.3268770217336891, 'recall': 0.3337114761536095, 'f1-score': 0.1720704228860115, 'support': 462163}, 'weighted avg': {'precision': 0.32684273209687265, 'recall': 0.3279708674212345, 'f1-score': 0.1692555042251461, 'support': 462163}}
[[    18 153815   1808]
 [    18 149651   1688]
 [    24 153234   1907]]
Evaluating performance on  val set...
642/642 - 14s - 14s/epoch - 22ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1173767
{'0': {'precision': 0.4166666666666667, 'recall': 0.00018341556464481577, 'f1-score': 0.0003666697222476854, 'support': 54521}, '1': {'precision': 0.32719517142189825, 'recall': 0.9911006851355377, 'f1-score': 0.49197356868906245, 'support': 53712}, '2': {'precision': 0.351875, 'recall': 0.010037618784431886, 'f1-score': 0.019518452391270435, 'support': 56089}, 'accuracy': 0.3274485461471988, 'macro avg': {'precision': 0.36524561269618827, 'recall': 0.3337739064948715, 'f1-score': 0.1706195636008602, 'support': 164322}, 'weighted avg': {'precision': 0.3653053593295258, 'recall': 0.3274485461471988, 'f1-score': 0.16759561104129425, 'support': 164322}}
[[   10 53942   569]
 [   10 53234   468]
 [    4 55522   563]]
training model: results/ATVI/W5/deepVOL_L3/h1000
Epoch 1/50
1806/1806 - 76s - loss: 3.2750 - accuracy1000: 0.3864 - val_loss: 3.4254 - val_accuracy1000: 0.3160 - 76s/epoch - 42ms/step
Epoch 2/50
1806/1806 - 75s - loss: 3.2841 - accuracy1000: 0.3688 - val_loss: 3.3102 - val_accuracy1000: 0.3163 - 75s/epoch - 41ms/step
Epoch 3/50
1806/1806 - 74s - loss: 3.2812 - accuracy1000: 0.3668 - val_loss: 3.4437 - val_accuracy1000: 0.3199 - 74s/epoch - 41ms/step
Epoch 4/50
1806/1806 - 72s - loss: 3.2746 - accuracy1000: 0.3762 - val_loss: 3.3504 - val_accuracy1000: 0.3143 - 72s/epoch - 40ms/step
Epoch 5/50
1806/1806 - 74s - loss: 3.2509 - accuracy1000: 0.3965 - val_loss: 3.3889 - val_accuracy1000: 0.3222 - 74s/epoch - 41ms/step
Epoch 6/50
1806/1806 - 73s - loss: 3.2338 - accuracy1000: 0.4040 - val_loss: 3.4284 - val_accuracy1000: 0.3146 - 73s/epoch - 40ms/step
Epoch 7/50
1806/1806 - 74s - loss: 3.2171 - accuracy1000: 0.4123 - val_loss: 3.4469 - val_accuracy1000: 0.3168 - 74s/epoch - 41ms/step
Epoch 8/50
1806/1806 - 75s - loss: 3.2016 - accuracy1000: 0.4197 - val_loss: 3.4765 - val_accuracy1000: 0.3137 - 75s/epoch - 42ms/step
Epoch 9/50
1806/1806 - 74s - loss: 3.1909 - accuracy1000: 0.4252 - val_loss: 3.4567 - val_accuracy1000: 0.3168 - 74s/epoch - 41ms/step
Epoch 10/50
1806/1806 - 76s - loss: 3.1810 - accuracy1000: 0.4302 - val_loss: 3.4851 - val_accuracy1000: 0.3190 - 76s/epoch - 42ms/step
Epoch 11/50
1806/1806 - 74s - loss: 3.1741 - accuracy1000: 0.4334 - val_loss: 3.4892 - val_accuracy1000: 0.3182 - 74s/epoch - 41ms/step
Epoch 12/50
1806/1806 - 73s - loss: 3.1678 - accuracy1000: 0.4362 - val_loss: 3.4895 - val_accuracy1000: 0.3169 - 73s/epoch - 40ms/step
testing model: results/ATVI/W5/deepVOL_L3/h1000
Evaluating performance on  test set...
8238/8238 - 146s - 146s/epoch - 18ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1131786
{'0': {'precision': 0.4, 'recall': 1.291777705725288e-05, 'f1-score': 2.5834719796629087e-05, 'support': 774127}, '1': {'precision': 0.2524195044381801, 'recall': 0.9384027946114659, 'f1-score': 0.39782790189311745, 'support': 532167}, '2': {'precision': 0.3780240697531622, 'recall': 0.061379327534209015, 'f1-score': 0.10561075920866982, 'support': 802420}, 'accuracy': 0.26018179800579877, 'macro avg': {'precision': 0.34348119139711414, 'recall': 0.3332650133075774, 'f1-score': 0.16782149860719464, 'support': 2108714}, 'weighted avg': {'precision': 0.35439334327447225, 'recall': 0.26018179800579877, 'f1-score': 0.14059519964542727, 'support': 2108714}}
[[    10 725853  48264]
 [     8 499387  32772]
 [     7 753161  49252]]
Evaluating performance on  train set...
1806/1806 - 38s - 38s/epoch - 21ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1038944
{'0': {'precision': 0.3333333333333333, 'recall': 6.466464912961382e-06, 'f1-score': 1.2932678939778978e-05, 'support': 154644}, '1': {'precision': 0.32717557779338774, 'recall': 0.9380790438141777, 'f1-score': 0.4851459112408858, 'support': 151435}, '2': {'precision': 0.3344895404970499, 'recall': 0.059929268855231796, 'f1-score': 0.10164684404696575, 'support': 156084}, 'accuracy': 0.32761817800213344, 'macro avg': {'precision': 0.331666150541257, 'recall': 0.33267159304477417, 'f1-score': 0.19560189598893044, 'support': 462163}, 'weighted avg': {'precision': 0.33170612762614743, 'recall': 0.32761817800213344, 'f1-score': 0.19329872152507255, 'support': 462163}}
[[     1 145408   9235]
 [     1 142058   9376]
 [     1 146729   9354]]
Evaluating performance on  val set...
642/642 - 13s - 13s/epoch - 21ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1042908
{'0': {'precision': 1.0, 'recall': 1.8238523409144796e-05, 'f1-score': 3.647638154295094e-05, 'support': 54829}, '1': {'precision': 0.3138961434524234, 'recall': 0.938410570365778, 'f1-score': 0.47043341022216834, 'support': 51616}, '2': {'precision': 0.3496803835397523, 'recall': 0.06049035022547817, 'f1-score': 0.10313894739943143, 'support': 57877}, 'accuracy': 0.3160806221930113, 'macro avg': {'precision': 0.5545255089973918, 'recall': 0.3329730530382218, 'f1-score': 0.19120294466771426, 'support': 164322}, 'weighted avg': {'precision': 0.55543089116838, 'recall': 0.3160806221930113, 'f1-score': 0.18410963671442626, 'support': 164322}}
[[    1 51496  3332]
 [    0 48437  3179]
 [    0 54376  3501]]

============================================

        Job resource usage summary 

                 Memory (GB)    NCPUs
 Requested  :        96            32
 Used       :        28 (peak)  15.35 (ave)

============================================
