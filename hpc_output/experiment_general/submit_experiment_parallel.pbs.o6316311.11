This machine has 1 visible gpus.
This machine has 1 physical gpus.
getting alphas...
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-03-13.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-03-05.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-02-20.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-02-21.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-03-01.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-02-25.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-02-27.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-02-22.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-03-15.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-02-26.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-03-11.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-02-28.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-02-19.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-03-07.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-03-06.csv
training model: results/QRTEA/W1/deepLOB_L1/h10
Epoch 1/50
653/653 - 36s - loss: 3.0454 - accuracy10: 0.4211 - val_loss: 3.0255 - val_accuracy10: 0.6106 - 36s/epoch - 55ms/step
Epoch 2/50
653/653 - 10s - loss: 2.9466 - accuracy10: 0.4386 - val_loss: 2.8703 - val_accuracy10: 0.5189 - 10s/epoch - 15ms/step
Epoch 3/50
653/653 - 10s - loss: 2.8787 - accuracy10: 0.4670 - val_loss: 2.9158 - val_accuracy10: 0.5335 - 10s/epoch - 15ms/step
Epoch 4/50
653/653 - 10s - loss: 2.8096 - accuracy10: 0.4978 - val_loss: 2.8858 - val_accuracy10: 0.3412 - 10s/epoch - 15ms/step
Epoch 5/50
653/653 - 10s - loss: 2.7613 - accuracy10: 0.5261 - val_loss: 2.8434 - val_accuracy10: 0.3950 - 10s/epoch - 15ms/step
Epoch 6/50
653/653 - 10s - loss: 2.7201 - accuracy10: 0.5360 - val_loss: 2.8963 - val_accuracy10: 0.3712 - 10s/epoch - 15ms/step
Epoch 7/50
653/653 - 10s - loss: 2.6811 - accuracy10: 0.5521 - val_loss: 2.9340 - val_accuracy10: 0.3787 - 10s/epoch - 15ms/step
Epoch 8/50
653/653 - 10s - loss: 2.6421 - accuracy10: 0.5643 - val_loss: 2.8945 - val_accuracy10: 0.4020 - 10s/epoch - 15ms/step
Epoch 9/50
653/653 - 10s - loss: 2.6216 - accuracy10: 0.5726 - val_loss: 2.9296 - val_accuracy10: 0.4354 - 10s/epoch - 15ms/step
Epoch 10/50
653/653 - 10s - loss: 2.5950 - accuracy10: 0.5815 - val_loss: 2.9221 - val_accuracy10: 0.4161 - 10s/epoch - 15ms/step
Epoch 11/50
653/653 - 10s - loss: 2.5789 - accuracy10: 0.5888 - val_loss: 2.8885 - val_accuracy10: 0.4461 - 10s/epoch - 15ms/step
Epoch 12/50
653/653 - 10s - loss: 2.5583 - accuracy10: 0.5921 - val_loss: 2.9423 - val_accuracy10: 0.4289 - 10s/epoch - 15ms/step
Epoch 13/50
653/653 - 10s - loss: 2.5456 - accuracy10: 0.5935 - val_loss: 2.9289 - val_accuracy10: 0.4434 - 10s/epoch - 15ms/step
Epoch 14/50
653/653 - 10s - loss: 2.5262 - accuracy10: 0.6003 - val_loss: 2.9584 - val_accuracy10: 0.4253 - 10s/epoch - 15ms/step
Epoch 15/50
653/653 - 10s - loss: 2.5119 - accuracy10: 0.6044 - val_loss: 2.9661 - val_accuracy10: 0.4519 - 10s/epoch - 15ms/step
testing model: results/QRTEA/W1/deepLOB_L1/h10
Evaluating performance on  test set...
1645/1645 - 10s - 10s/epoch - 6ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 1.3617773
{'0': {'precision': 0.12517700509874757, 'recall': 0.7324120970811254, 'f1-score': 0.2138113755822401, 'support': 34157}, '1': {'precision': 0.903419783580334, 'recall': 0.17416653911781546, 'f1-score': 0.2920332111914301, 'support': 352806}, '2': {'precision': 0.13832350578878289, 'recall': 0.622169354128117, 'f1-score': 0.22632861080838515, 'support': 34047}, 'accuracy': 0.25568751336072776, 'macro avg': {'precision': 0.38897343148928815, 'recall': 0.5095826634423526, 'f1-score': 0.24405773252735177, 'support': 421010}, 'weighted avg': {'precision': 0.7784069060843969, 'recall': 0.25568751336072776, 'f1-score': 0.28037346969325994, 'support': 421010}}
[[ 25017   2258   6882]
 [166283  61447 125076]
 [  8553   4311  21183]]
Evaluating performance on  train set...
653/653 - 4s - 4s/epoch - 6ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 1.1313884
{'0': {'precision': 0.20609865470852018, 'recall': 0.5819596647941799, 'f1-score': 0.30439651746685453, 'support': 21718}, '1': {'precision': 0.8258839982612969, 'recall': 0.3520020620715764, 'f1-score': 0.49361798260476675, 'support': 124147}, '2': {'precision': 0.21247152619589976, 'recall': 0.5316581959815703, 'f1-score': 0.3036089674908114, 'support': 21053}, 'accuracy': 0.40458189050911225, 'macro avg': {'precision': 0.4148180597219056, 'recall': 0.48853997428244217, 'f1-score': 0.36720782252081086, 'support': 166918}, 'weighted avg': {'precision': 0.6678742517649812, 'recall': 0.40458189050911225, 'f1-score': 0.44503261988139786, 'support': 166918}}
[[12639  3859  5220]
 [44180 43700 36267]
 [ 4506  5354 11193]]
Evaluating performance on  val set...
181/181 - 1s - 1s/epoch - 6ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 1.1502713
{'0': {'precision': 0.1940099640829568, 'recall': 0.6549970663015842, 'f1-score': 0.29935195530726255, 'support': 5113}, '1': {'precision': 0.8570229434806939, 'recall': 0.3377346528103206, 'f1-score': 0.4845273169477785, 'support': 36277}, '2': {'precision': 0.18490361118653273, 'recall': 0.5559183673469388, 'f1-score': 0.2775061124694377, 'support': 4900}, 'accuracy': 0.39587383884208255, 'macro avg': {'precision': 0.4119788395833945, 'recall': 0.5162166954862811, 'f1-score': 0.3537951282414929, 'support': 46290}, 'weighted avg': {'precision': 0.7126425137571679, 'recall': 0.39587383884208255, 'f1-score': 0.44215951556493494, 'support': 46290}}
[[ 3349   863   901]
 [12918 12252 11107]
 [  995  1181  2724]]
training model: results/QRTEA/W1/deepLOB_L1/h20
Epoch 1/50
653/653 - 12s - loss: 3.0444 - accuracy20: 0.4309 - val_loss: 3.1882 - val_accuracy20: 0.5318 - 12s/epoch - 18ms/step
Epoch 2/50
653/653 - 10s - loss: 2.9699 - accuracy20: 0.4503 - val_loss: 3.0148 - val_accuracy20: 0.4641 - 10s/epoch - 15ms/step
Epoch 3/50
653/653 - 10s - loss: 2.9173 - accuracy20: 0.4655 - val_loss: 3.0557 - val_accuracy20: 0.4067 - 10s/epoch - 15ms/step
Epoch 4/50
653/653 - 10s - loss: 2.8694 - accuracy20: 0.4897 - val_loss: 3.0993 - val_accuracy20: 0.4069 - 10s/epoch - 15ms/step
Epoch 5/50
653/653 - 10s - loss: 2.8304 - accuracy20: 0.5040 - val_loss: 3.1065 - val_accuracy20: 0.3495 - 10s/epoch - 15ms/step
Epoch 6/50
653/653 - 10s - loss: 2.7857 - accuracy20: 0.5290 - val_loss: 2.9806 - val_accuracy20: 0.4156 - 10s/epoch - 15ms/step
Epoch 7/50
653/653 - 10s - loss: 2.7566 - accuracy20: 0.5404 - val_loss: 2.9964 - val_accuracy20: 0.4306 - 10s/epoch - 15ms/step
Epoch 8/50
653/653 - 10s - loss: 2.7319 - accuracy20: 0.5469 - val_loss: 2.9918 - val_accuracy20: 0.4374 - 10s/epoch - 15ms/step
Epoch 9/50
653/653 - 10s - loss: 2.7178 - accuracy20: 0.5524 - val_loss: 2.9898 - val_accuracy20: 0.4292 - 10s/epoch - 15ms/step
Epoch 10/50
653/653 - 10s - loss: 2.6979 - accuracy20: 0.5583 - val_loss: 3.0065 - val_accuracy20: 0.4527 - 10s/epoch - 15ms/step
Epoch 11/50
653/653 - 10s - loss: 2.6777 - accuracy20: 0.5661 - val_loss: 3.0423 - val_accuracy20: 0.4779 - 10s/epoch - 15ms/step
Epoch 12/50
653/653 - 10s - loss: 2.6646 - accuracy20: 0.5703 - val_loss: 3.0143 - val_accuracy20: 0.4740 - 10s/epoch - 15ms/step
Epoch 13/50
653/653 - 10s - loss: 2.6490 - accuracy20: 0.5713 - val_loss: 2.9982 - val_accuracy20: 0.5035 - 10s/epoch - 15ms/step
Epoch 14/50
653/653 - 10s - loss: 2.6318 - accuracy20: 0.5784 - val_loss: 3.0232 - val_accuracy20: 0.4796 - 10s/epoch - 15ms/step
Epoch 15/50
653/653 - 10s - loss: 2.6157 - accuracy20: 0.5818 - val_loss: 3.0840 - val_accuracy20: 0.4716 - 10s/epoch - 15ms/step
Epoch 16/50
653/653 - 10s - loss: 2.6040 - accuracy20: 0.5854 - val_loss: 3.0434 - val_accuracy20: 0.4877 - 10s/epoch - 15ms/step
testing model: results/QRTEA/W1/deepLOB_L1/h20
Evaluating performance on  test set...
1645/1645 - 9s - 9s/epoch - 5ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 1.2560796
{'0': {'precision': 0.16454568517436888, 'recall': 0.595952904976602, 'f1-score': 0.25788733957169807, 'support': 46799}, '1': {'precision': 0.8347466416134897, 'recall': 0.2085753221690736, 'f1-score': 0.3337561284972071, 'support': 328011}, '2': {'precision': 0.17546622315014684, 'recall': 0.643961038961039, 'f1-score': 0.2757863121888818, 'support': 46200}, 'accuracy': 0.29941331559820433, 'macro avg': {'precision': 0.3915861833126684, 'recall': 0.4828297553689049, 'f1-score': 0.28914326008592894, 'support': 421010}, 'weighted avg': {'precision': 0.6879009849939298, 'recall': 0.29941331559820433, 'f1-score': 0.3189612567213122, 'support': 421010}}
[[ 27890   5635  13274]
 [133067  68415 126529]
 [  8540   7909  29751]]
Evaluating performance on  train set...
653/653 - 4s - 4s/epoch - 6ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 1.032387
{'0': {'precision': 0.26728273137697517, 'recall': 0.5343393033422649, 'f1-score': 0.3563267033432078, 'support': 28364}, '1': {'precision': 0.7415299941919961, 'recall': 0.4837307064310393, 'f1-score': 0.5855093985270272, 'support': 110853}, '2': {'precision': 0.27820580474934037, 'recall': 0.38063607811992345, 'f1-score': 0.32145851435191536, 'support': 27701}, 'accuracy': 0.4752213661798009, 'macro avg': {'precision': 0.4290061767727705, 'recall': 0.46623536263107584, 'f1-score': 0.42109820540738346, 'support': 166918}, 'weighted avg': {'precision': 0.5840509162361359, 'recall': 0.4752213661798009, 'f1-score': 0.5027441394852904, 'support': 166918}}
[[15156  7999  5209]
 [35083 53623 22147]
 [ 6465 10692 10544]]
Evaluating performance on  val set...
181/181 - 1s - 1s/epoch - 6ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 1.1225388
{'0': {'precision': 0.2350385824521292, 'recall': 0.5933621933621933, 'f1-score': 0.3367041965199591, 'support': 6930}, '1': {'precision': 0.784335129972027, 'recall': 0.351237396883593, 'f1-score': 0.4851963618713993, 'support': 32730}, '2': {'precision': 0.24932805205828265, 'recall': 0.5316742081447964, 'f1-score': 0.33946456086286597, 'support': 6630}, 'accuracy': 0.4133290127457334, 'macro avg': {'precision': 0.42290058816081294, 'recall': 0.4920912661301942, 'f1-score': 0.38712170641807475, 'support': 46290}, 'weighted avg': {'precision': 0.6254731295209357, 'recall': 0.4133290127457334, 'f1-score': 0.44209304481432316, 'support': 46290}}
[[ 4112  1342  1476]
 [12097 11496  9137]
 [ 1286  1819  3525]]
training model: results/QRTEA/W1/deepLOB_L1/h30
Epoch 1/50
653/653 - 12s - loss: 3.0738 - accuracy30: 0.4363 - val_loss: 3.1262 - val_accuracy30: 0.4394 - 12s/epoch - 18ms/step
Epoch 2/50
653/653 - 10s - loss: 2.9868 - accuracy30: 0.4657 - val_loss: 3.1751 - val_accuracy30: 0.5014 - 10s/epoch - 15ms/step
Epoch 3/50
653/653 - 10s - loss: 2.9275 - accuracy30: 0.4796 - val_loss: 3.1158 - val_accuracy30: 0.4649 - 10s/epoch - 15ms/step
Epoch 4/50
653/653 - 10s - loss: 2.8790 - accuracy30: 0.4962 - val_loss: 3.1271 - val_accuracy30: 0.4526 - 10s/epoch - 15ms/step
Epoch 5/50
653/653 - 10s - loss: 2.8571 - accuracy30: 0.5081 - val_loss: 3.1790 - val_accuracy30: 0.4680 - 10s/epoch - 15ms/step
Epoch 6/50
653/653 - 10s - loss: 2.8138 - accuracy30: 0.5252 - val_loss: 3.1413 - val_accuracy30: 0.4412 - 10s/epoch - 15ms/step
Epoch 7/50
653/653 - 10s - loss: 2.7961 - accuracy30: 0.5339 - val_loss: 3.1361 - val_accuracy30: 0.4675 - 10s/epoch - 15ms/step
Epoch 8/50
653/653 - 10s - loss: 2.7676 - accuracy30: 0.5445 - val_loss: 3.1698 - val_accuracy30: 0.4688 - 10s/epoch - 15ms/step
Epoch 9/50
653/653 - 10s - loss: 2.7503 - accuracy30: 0.5504 - val_loss: 3.1446 - val_accuracy30: 0.4861 - 10s/epoch - 15ms/step
Epoch 10/50
653/653 - 10s - loss: 2.7286 - accuracy30: 0.5565 - val_loss: 3.1669 - val_accuracy30: 0.4608 - 10s/epoch - 15ms/step
Epoch 11/50
653/653 - 10s - loss: 2.7100 - accuracy30: 0.5594 - val_loss: 3.0702 - val_accuracy30: 0.4809 - 10s/epoch - 15ms/step
Epoch 12/50
653/653 - 10s - loss: 2.6910 - accuracy30: 0.5645 - val_loss: 3.1370 - val_accuracy30: 0.4937 - 10s/epoch - 15ms/step
Epoch 13/50
653/653 - 10s - loss: 2.6736 - accuracy30: 0.5684 - val_loss: 3.1142 - val_accuracy30: 0.5048 - 10s/epoch - 15ms/step
Epoch 14/50
653/653 - 10s - loss: 2.6556 - accuracy30: 0.5731 - val_loss: 3.1634 - val_accuracy30: 0.5469 - 10s/epoch - 15ms/step
Epoch 15/50
653/653 - 10s - loss: 2.6397 - accuracy30: 0.5758 - val_loss: 3.1417 - val_accuracy30: 0.5074 - 10s/epoch - 15ms/step
Epoch 16/50
653/653 - 10s - loss: 2.6248 - accuracy30: 0.5802 - val_loss: 3.0432 - val_accuracy30: 0.5010 - 10s/epoch - 15ms/step
Epoch 17/50
653/653 - 10s - loss: 2.6154 - accuracy30: 0.5820 - val_loss: 3.1068 - val_accuracy30: 0.4785 - 10s/epoch - 15ms/step
Epoch 18/50
653/653 - 10s - loss: 2.6023 - accuracy30: 0.5848 - val_loss: 3.0728 - val_accuracy30: 0.4848 - 10s/epoch - 15ms/step
Epoch 19/50
653/653 - 10s - loss: 2.5940 - accuracy30: 0.5869 - val_loss: 3.1012 - val_accuracy30: 0.4896 - 10s/epoch - 15ms/step
Epoch 20/50
653/653 - 10s - loss: 2.5845 - accuracy30: 0.5896 - val_loss: 3.1469 - val_accuracy30: 0.4741 - 10s/epoch - 15ms/step
Epoch 21/50
653/653 - 10s - loss: 2.5744 - accuracy30: 0.5911 - val_loss: 3.1303 - val_accuracy30: 0.4678 - 10s/epoch - 15ms/step
Epoch 22/50
653/653 - 10s - loss: 2.5697 - accuracy30: 0.5918 - val_loss: 3.1855 - val_accuracy30: 0.4834 - 10s/epoch - 15ms/step
Epoch 23/50
653/653 - 10s - loss: 2.5540 - accuracy30: 0.5952 - val_loss: 3.1358 - val_accuracy30: 0.4874 - 10s/epoch - 15ms/step
Epoch 24/50
653/653 - 10s - loss: 2.5485 - accuracy30: 0.5947 - val_loss: 3.1373 - val_accuracy30: 0.4924 - 10s/epoch - 15ms/step
Epoch 25/50
653/653 - 10s - loss: 2.5463 - accuracy30: 0.5957 - val_loss: 3.1194 - val_accuracy30: 0.4808 - 10s/epoch - 15ms/step
Epoch 26/50
653/653 - 10s - loss: 2.5313 - accuracy30: 0.5999 - val_loss: 3.1446 - val_accuracy30: 0.4885 - 10s/epoch - 15ms/step
testing model: results/QRTEA/W1/deepLOB_L1/h30
Evaluating performance on  test set...
1645/1645 - 9s - 9s/epoch - 5ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.1054128
{'0': {'precision': 0.21494330907498937, 'recall': 0.5990098134559279, 'f1-score': 0.3163650286696177, 'support': 56555}, '1': {'precision': 0.8076471209441085, 'recall': 0.3961134814220139, 'f1-score': 0.5315341143559604, 'support': 308914}, '2': {'precision': 0.2287989418462281, 'recall': 0.46093876595668065, 'f1-score': 0.30580407802477394, 'support': 55541}, 'accuracy': 0.4319208569867699, 'macro avg': {'precision': 0.4171297906217753, 'recall': 0.48535402027820745, 'f1-score': 0.3845677403501173, 'support': 421010}, 'weighted avg': {'precision': 0.6516646720817694, 'recall': 0.4319208569867699, 'f1-score': 0.4728510436715075, 'support': 421010}}
[[ 33877  11979  10699]
 [110956 122365  75593]
 [ 12776  17164  25601]]
Evaluating performance on  train set...
653/653 - 4s - 4s/epoch - 6ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.0374163
{'0': {'precision': 0.312120161334477, 'recall': 0.5168484995013448, 'f1-score': 0.3892037049680253, 'support': 33089}, '1': {'precision': 0.7019875776397515, 'recall': 0.5012467353274528, 'f1-score': 0.5848719201908978, 'support': 101465}, '2': {'precision': 0.3371140516698173, 'recall': 0.4132678284513657, 'f1-score': 0.37132664251308317, 'support': 32364}, 'accuracy': 0.4872811799805893, 'macro avg': {'precision': 0.45040726354801525, 'recall': 0.4771210210933878, 'f1-score': 0.44846742255733546, 'support': 166918}, 'weighted avg': {'precision': 0.5539562704552885, 'recall': 0.4872811799805893, 'f1-score': 0.504678981500796, 'support': 166918}}
[[17102  9529  6458]
 [30764 50859 19842]
 [ 6927 12062 13375]]
Evaluating performance on  val set...
181/181 - 1s - 1s/epoch - 6ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.0176888
{'0': {'precision': 0.28799884742832443, 'recall': 0.4867299732164597, 'f1-score': 0.361875452570601, 'support': 8214}, '1': {'precision': 0.7135778899040865, 'recall': 0.5196636652542372, 'f1-score': 0.6013752945007375, 'support': 30208}, '2': {'precision': 0.3328850033624748, 'recall': 0.4403914590747331, 'f1-score': 0.3791650708540789, 'support': 7868}, 'accuracy': 0.5003456470079931, 'macro avg': {'precision': 0.44482058023162857, 'recall': 0.48226169918181, 'f1-score': 0.4474719393084725, 'support': 46290}, 'weighted avg': {'precision': 0.5733532650130666, 'recall': 0.5003456470079931, 'f1-score': 0.5211073804530802, 'support': 46290}}
[[ 3998  3035  1181]
 [ 8747 15698  5763]
 [ 1137  3266  3465]]
training model: results/QRTEA/W1/deepLOB_L1/h50
Epoch 1/50
653/653 - 12s - loss: 3.1066 - accuracy50: 0.4411 - val_loss: 3.1322 - val_accuracy50: 0.4310 - 12s/epoch - 18ms/step
Epoch 2/50
653/653 - 10s - loss: 3.0594 - accuracy50: 0.4568 - val_loss: 3.3361 - val_accuracy50: 0.4834 - 10s/epoch - 15ms/step
Epoch 3/50
653/653 - 10s - loss: 3.0233 - accuracy50: 0.4619 - val_loss: 3.2309 - val_accuracy50: 0.4822 - 10s/epoch - 15ms/step
Epoch 4/50
653/653 - 10s - loss: 2.9779 - accuracy50: 0.4819 - val_loss: 3.3189 - val_accuracy50: 0.4725 - 10s/epoch - 15ms/step
Epoch 5/50
653/653 - 9s - loss: 2.9472 - accuracy50: 0.4896 - val_loss: 3.2859 - val_accuracy50: 0.4690 - 9s/epoch - 14ms/step
Epoch 6/50
653/653 - 9s - loss: 2.9146 - accuracy50: 0.5026 - val_loss: 3.3583 - val_accuracy50: 0.4723 - 9s/epoch - 15ms/step
Epoch 7/50
653/653 - 10s - loss: 2.8904 - accuracy50: 0.5125 - val_loss: 3.3481 - val_accuracy50: 0.4479 - 10s/epoch - 15ms/step
Epoch 8/50
653/653 - 10s - loss: 2.8679 - accuracy50: 0.5190 - val_loss: 3.3237 - val_accuracy50: 0.4630 - 10s/epoch - 15ms/step
Epoch 9/50
653/653 - 10s - loss: 2.8539 - accuracy50: 0.5236 - val_loss: 3.2951 - val_accuracy50: 0.4663 - 10s/epoch - 15ms/step
Epoch 10/50
653/653 - 10s - loss: 2.8378 - accuracy50: 0.5287 - val_loss: 3.3914 - val_accuracy50: 0.4359 - 10s/epoch - 15ms/step
Epoch 11/50
653/653 - 10s - loss: 2.8238 - accuracy50: 0.5336 - val_loss: 3.3929 - val_accuracy50: 0.4544 - 10s/epoch - 15ms/step
testing model: results/QRTEA/W1/deepLOB_L1/h50
Evaluating performance on  test set...
1645/1645 - 10s - 10s/epoch - 6ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0672123
{'0': {'precision': 0.24701465167310047, 'recall': 0.5397802138093103, 'f1-score': 0.33892855010533673, 'support': 73617}, '1': {'precision': 0.7069797476618271, 'recall': 0.36054485776013373, 'f1-score': 0.477549484602793, 'support': 276329}, '2': {'precision': 0.2685561865138946, 'recall': 0.45053754362265, 'f1-score': 0.33651981522258956, 'support': 71064}, 'accuracy': 0.4070758414289447, 'macro avg': {'precision': 0.4075168619496074, 'recall': 0.45028753839736463, 'f1-score': 0.38433261664357304, 'support': 421010}, 'weighted avg': {'precision': 0.5525478281805352, 'recall': 0.4070758414289447, 'f1-score': 0.4295055194719552, 'support': 421010}}
[[ 39737  18663  15217]
 [104715  99629  71985]
 [ 16417  22630  32017]]
Evaluating performance on  train set...
653/653 - 4s - 4s/epoch - 6ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.071455
{'0': {'precision': 0.3079994227716581, 'recall': 0.47862161758110333, 'f1-score': 0.3748060994526883, 'support': 40134}, '1': {'precision': 0.5514719899779406, 'recall': 0.46357153486029556, 'f1-score': 0.50371577291186, 'support': 87363}, '2': {'precision': 0.364060039211905, 'recall': 0.2873341619948758, 'f1-score': 0.3211784387671194, 'support': 39421}, 'accuracy': 0.42556824308942115, 'macro avg': {'precision': 0.40784381732050123, 'recall': 0.4098424381454249, 'f1-score': 0.39990010371055584, 'support': 166918}, 'weighted avg': {'precision': 0.44867004816576433, 'recall': 0.42556824308942115, 'f1-score': 0.42961073280875417, 'support': 166918}}
[[19209 15708  5217]
 [32295 40499 14569]
 [10863 17231 11327]]
Evaluating performance on  val set...
181/181 - 1s - 1s/epoch - 6ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0594903
{'0': {'precision': 0.31330128205128205, 'recall': 0.4902112064808564, 'f1-score': 0.3822810514045049, 'support': 10369}, '1': {'precision': 0.5966260230499415, 'recall': 0.4095390965374914, 'f1-score': 0.48568903392480794, 'support': 26166}, '2': {'precision': 0.33672036348616274, 'recall': 0.41783700666324963, 'f1-score': 0.37291857273559015, 'support': 9755}, 'accuracy': 0.42935839274141285, 'macro avg': {'precision': 0.41554922286246204, 'recall': 0.4391957698938658, 'f1-score': 0.413629552688301, 'support': 46290}, 'weighted avg': {'precision': 0.47838938558051486, 'recall': 0.42935839274141285, 'f1-score': 0.4387606861249842, 'support': 46290}}
[[ 5083  3506  1780]
 [ 9201 10716  6249]
 [ 1940  3739  4076]]
training model: results/QRTEA/W1/deepLOB_L1/h100
Epoch 1/50
653/653 - 12s - loss: 3.2028 - accuracy100: 0.4228 - val_loss: 3.3430 - val_accuracy100: 0.4106 - 12s/epoch - 18ms/step
Epoch 2/50
653/653 - 10s - loss: 3.1575 - accuracy100: 0.4413 - val_loss: 3.2303 - val_accuracy100: 0.4261 - 10s/epoch - 15ms/step
Epoch 3/50
653/653 - 10s - loss: 3.1439 - accuracy100: 0.4399 - val_loss: 3.2683 - val_accuracy100: 0.4171 - 10s/epoch - 15ms/step
Epoch 4/50
653/653 - 10s - loss: 3.1273 - accuracy100: 0.4469 - val_loss: 3.3570 - val_accuracy100: 0.4056 - 10s/epoch - 15ms/step
Epoch 5/50
653/653 - 10s - loss: 3.0983 - accuracy100: 0.4632 - val_loss: 3.3605 - val_accuracy100: 0.4022 - 10s/epoch - 15ms/step
Epoch 6/50
653/653 - 10s - loss: 3.0785 - accuracy100: 0.4690 - val_loss: 3.4139 - val_accuracy100: 0.3900 - 10s/epoch - 15ms/step
Epoch 7/50
653/653 - 10s - loss: 3.0588 - accuracy100: 0.4750 - val_loss: 3.3755 - val_accuracy100: 0.4096 - 10s/epoch - 15ms/step
Epoch 8/50
653/653 - 10s - loss: 3.0474 - accuracy100: 0.4760 - val_loss: 3.5382 - val_accuracy100: 0.3955 - 10s/epoch - 15ms/step
Epoch 9/50
653/653 - 10s - loss: 3.0286 - accuracy100: 0.4847 - val_loss: 3.4499 - val_accuracy100: 0.4105 - 10s/epoch - 15ms/step
Epoch 10/50
653/653 - 10s - loss: 3.0128 - accuracy100: 0.4899 - val_loss: 3.5103 - val_accuracy100: 0.4121 - 10s/epoch - 15ms/step
Epoch 11/50
653/653 - 10s - loss: 2.9999 - accuracy100: 0.4939 - val_loss: 3.5453 - val_accuracy100: 0.4070 - 10s/epoch - 15ms/step
Epoch 12/50
653/653 - 10s - loss: 2.9914 - accuracy100: 0.4972 - val_loss: 3.5173 - val_accuracy100: 0.4118 - 10s/epoch - 15ms/step
testing model: results/QRTEA/W1/deepLOB_L1/h100
Evaluating performance on  test set...
1645/1645 - 9s - 9s/epoch - 5ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0893154
{'0': {'precision': 0.33295654187151863, 'recall': 0.4637021442051457, 'f1-score': 0.3876005247700168, 'support': 105447}, '1': {'precision': 0.5651682902888746, 'recall': 0.24765974765974766, 'f1-score': 0.3444011023819554, 'support': 216216}, '2': {'precision': 0.281936803616318, 'recall': 0.5091447149888774, 'f1-score': 0.362912367805536, 'support': 99347}, 'accuracy': 0.3634735516971093, 'macro avg': {'precision': 0.393353878592237, 'recall': 0.40683553561792357, 'f1-score': 0.36497133165250273, 'support': 421010}, 'weighted avg': {'precision': 0.4401730865126616, 'recall': 0.3634735516971093, 'f1-score': 0.3595890745882934, 'support': 421010}}
[[48896 17694 38857]
 [72698 53548 89970]
 [25260 23505 50582]]
Evaluating performance on  train set...
653/653 - 4s - 4s/epoch - 6ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.1124983
{'0': {'precision': 0.37080560177481975, 'recall': 0.41551429459291483, 'f1-score': 0.3918889214536928, 'support': 51488}, '1': {'precision': 0.4716947867632799, 'recall': 0.4148383595627568, 'f1-score': 0.441443373812038, 'support': 64495}, '2': {'precision': 0.3697072436715491, 'recall': 0.3810739177382939, 'f1-score': 0.3753045361382884, 'support': 50935}, 'accuracy': 0.4047436465809559, 'macro avg': {'precision': 0.4040692107365496, 'recall': 0.4038088572979885, 'f1-score': 0.40287894380133976, 'support': 166918}, 'weighted avg': {'precision': 0.4094527405845386, 'recall': 0.4047436465809559, 'f1-score': 0.40597541145963195, 'support': 166918}}
[[21394 13499 16595]
 [21244 26755 16496]
 [15058 16467 19410]]
Evaluating performance on  val set...
181/181 - 1s - 1s/epoch - 6ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0703844
{'0': {'precision': 0.4349217963962316, 'recall': 0.33528416302355096, 'f1-score': 0.37865817240692806, 'support': 14182}, '1': {'precision': 0.47106555626734997, 'recall': 0.463396702027098, 'f1-score': 0.4671996611425848, 'support': 19042}, '2': {'precision': 0.3608421052631579, 'recall': 0.4591305678861166, 'f1-score': 0.4040955171600822, 'support': 13066}, 'accuracy': 0.4229423201555412, 'macro avg': {'precision': 0.4222764859755798, 'recall': 0.4192704776455885, 'f1-score': 0.41665111690319834, 'support': 46290}, 'weighted avg': {'precision': 0.4288799781011591, 'recall': 0.4229423201555412, 'f1-score': 0.42226092408221627, 'support': 46290}}
[[4755 4658 4769]
 [4361 8824 5857]
 [1817 5250 5999]]
training model: results/QRTEA/W1/deepLOB_L1/h200
Epoch 1/50
653/653 - 12s - loss: 3.2805 - accuracy200: 0.3908 - val_loss: 3.4481 - val_accuracy200: 0.3267 - 12s/epoch - 18ms/step
Epoch 2/50
653/653 - 10s - loss: 3.2477 - accuracy200: 0.4028 - val_loss: 3.3040 - val_accuracy200: 0.3830 - 10s/epoch - 15ms/step
Epoch 3/50
653/653 - 9s - loss: 3.2214 - accuracy200: 0.4156 - val_loss: 3.3417 - val_accuracy200: 0.3586 - 9s/epoch - 15ms/step
Epoch 4/50
653/653 - 10s - loss: 3.2146 - accuracy200: 0.4172 - val_loss: 3.3172 - val_accuracy200: 0.3741 - 10s/epoch - 15ms/step
Epoch 5/50
653/653 - 10s - loss: 3.1992 - accuracy200: 0.4257 - val_loss: 3.4347 - val_accuracy200: 0.3443 - 10s/epoch - 15ms/step
Epoch 6/50
653/653 - 10s - loss: 3.1836 - accuracy200: 0.4301 - val_loss: 3.3808 - val_accuracy200: 0.3543 - 10s/epoch - 15ms/step
Epoch 7/50
653/653 - 10s - loss: 3.1735 - accuracy200: 0.4352 - val_loss: 3.4305 - val_accuracy200: 0.3533 - 10s/epoch - 15ms/step
Epoch 8/50
653/653 - 10s - loss: 3.1618 - accuracy200: 0.4401 - val_loss: 3.5167 - val_accuracy200: 0.3484 - 10s/epoch - 15ms/step
Epoch 9/50
653/653 - 10s - loss: 3.1554 - accuracy200: 0.4432 - val_loss: 3.4895 - val_accuracy200: 0.3538 - 10s/epoch - 15ms/step
Epoch 10/50
653/653 - 10s - loss: 3.1490 - accuracy200: 0.4429 - val_loss: 3.4996 - val_accuracy200: 0.3483 - 10s/epoch - 15ms/step
Epoch 11/50
653/653 - 10s - loss: 3.1398 - accuracy200: 0.4481 - val_loss: 3.6103 - val_accuracy200: 0.3434 - 10s/epoch - 15ms/step
Epoch 12/50
653/653 - 10s - loss: 3.1316 - accuracy200: 0.4525 - val_loss: 3.5585 - val_accuracy200: 0.3555 - 10s/epoch - 15ms/step
testing model: results/QRTEA/W1/deepLOB_L1/h200
Evaluating performance on  test set...
1645/1645 - 10s - 10s/epoch - 6ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1011208
{'0': {'precision': 0.35995223494730866, 'recall': 0.688868441099052, 'f1-score': 0.47283532947306567, 'support': 132587}, '1': {'precision': 0.40362233603413383, 'recall': 0.33517163554293616, 'f1-score': 0.36622594042406503, 'support': 164826}, '2': {'precision': 0.37775949991774965, 'recall': 0.09289869495214285, 'f1-score': 0.14912462985090136, 'support': 123597}, 'accuracy': 0.37543526282036055, 'macro avg': {'precision': 0.3804446902997307, 'recall': 0.3723129238647103, 'f1-score': 0.3293952999160107, 'support': 421010}, 'weighted avg': {'precision': 0.3822768652655639, 'recall': 0.37543526282036055, 'f1-score': 0.33606501403972383, 'support': 421010}}
[[91335 34397  6855]
 [97523 55245 12058]
 [64884 47231 11482]]
Evaluating performance on  train set...
653/653 - 4s - 4s/epoch - 6ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1254903
{'0': {'precision': 0.39156852137001125, 'recall': 0.6459452501501759, 'f1-score': 0.48757295263018113, 'support': 58265}, '1': {'precision': 0.3336866057791216, 'recall': 0.4086891786130147, 'f1-score': 0.3673991196835666, 'support': 52387}, '2': {'precision': 0.40376506024096387, 'recall': 0.04764866882309032, 'f1-score': 0.08523829205481195, 'support': 56266}, 'accuracy': 0.3698043350627254, 'macro avg': {'precision': 0.37634006246336554, 'recall': 0.367427699195427, 'f1-score': 0.31340345478951986, 'support': 166918}, 'weighted avg': {'precision': 0.37751365936623144, 'recall': 0.3698043350627254, 'f1-score': 0.31423449543258697, 'support': 166918}}
[[37636 18557  2072]
 [29090 21410  1887]
 [29390 24195  2681]]
Evaluating performance on  val set...
181/181 - 1s - 1s/epoch - 6ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1031208
{'0': {'precision': 0.43261851510766125, 'recall': 0.5882879122189755, 'f1-score': 0.4985848579803901, 'support': 16769}, '1': {'precision': 0.32454102318800965, 'recall': 0.5001755248192095, 'f1-score': 0.39365640713930483, 'support': 14243}, '2': {'precision': 0.484375, 'recall': 0.04869747349129467, 'f1-score': 0.0884976805043416, 'support': 15278}, 'accuracy': 0.3830848995463383, 'macro avg': {'precision': 0.41384484609855693, 'recall': 0.37905363684315985, 'f1-score': 0.3269129818746788, 'support': 46290}, 'weighted avg': {'precision': 0.4164462934350225, 'recall': 0.3830848995463383, 'f1-score': 0.33095021069569264, 'support': 46290}}
[[9865 6555  349]
 [6676 7124  443]
 [6262 8272  744]]
training model: results/QRTEA/W1/deepLOB_L1/h300
Epoch 1/50
653/653 - 12s - loss: 3.2857 - accuracy300: 0.3869 - val_loss: 3.3737 - val_accuracy300: 0.3467 - 12s/epoch - 18ms/step
Epoch 2/50
653/653 - 10s - loss: 3.2585 - accuracy300: 0.3935 - val_loss: 3.3791 - val_accuracy300: 0.3466 - 10s/epoch - 15ms/step
Epoch 3/50
653/653 - 10s - loss: 3.2487 - accuracy300: 0.3958 - val_loss: 3.3886 - val_accuracy300: 0.3370 - 10s/epoch - 15ms/step
Epoch 4/50
653/653 - 10s - loss: 3.2370 - accuracy300: 0.4017 - val_loss: 3.3509 - val_accuracy300: 0.3458 - 10s/epoch - 15ms/step
Epoch 5/50
653/653 - 10s - loss: 3.2289 - accuracy300: 0.4058 - val_loss: 3.3819 - val_accuracy300: 0.3486 - 10s/epoch - 15ms/step
Epoch 6/50
653/653 - 10s - loss: 3.2217 - accuracy300: 0.4110 - val_loss: 3.3611 - val_accuracy300: 0.3507 - 10s/epoch - 15ms/step
Epoch 7/50
653/653 - 10s - loss: 3.2128 - accuracy300: 0.4140 - val_loss: 3.4012 - val_accuracy300: 0.3391 - 10s/epoch - 15ms/step
Epoch 8/50
653/653 - 10s - loss: 3.2092 - accuracy300: 0.4179 - val_loss: 3.4647 - val_accuracy300: 0.3557 - 10s/epoch - 15ms/step
Epoch 9/50
653/653 - 10s - loss: 3.2012 - accuracy300: 0.4210 - val_loss: 3.4915 - val_accuracy300: 0.3545 - 10s/epoch - 15ms/step
Epoch 10/50
653/653 - 10s - loss: 3.1904 - accuracy300: 0.4251 - val_loss: 3.5278 - val_accuracy300: 0.3579 - 10s/epoch - 15ms/step
Epoch 11/50
653/653 - 10s - loss: 3.1854 - accuracy300: 0.4264 - val_loss: 3.5214 - val_accuracy300: 0.3532 - 10s/epoch - 15ms/step
Epoch 12/50
653/653 - 10s - loss: 3.1789 - accuracy300: 0.4285 - val_loss: 3.5472 - val_accuracy300: 0.3516 - 10s/epoch - 15ms/step
Epoch 13/50
653/653 - 10s - loss: 3.1705 - accuracy300: 0.4328 - val_loss: 3.5781 - val_accuracy300: 0.3489 - 10s/epoch - 15ms/step
Epoch 14/50
653/653 - 10s - loss: 3.1658 - accuracy300: 0.4354 - val_loss: 3.5136 - val_accuracy300: 0.3561 - 10s/epoch - 15ms/step
testing model: results/QRTEA/W1/deepLOB_L1/h300
Evaluating performance on  test set...
1645/1645 - 9s - 9s/epoch - 6ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1116707
{'0': {'precision': 0.3547477982385909, 'recall': 0.24619567633243936, 'f1-score': 0.2906675180295032, 'support': 134978}, '1': {'precision': 0.3821249065796455, 'recall': 0.4116576935368882, 'f1-score': 0.39634191442967415, 'support': 162708}, '2': {'precision': 0.29257753926288377, 'recall': 0.36073270409652625, 'f1-score': 0.32310005229213873, 'support': 123324}, 'accuracy': 0.34369254887057316, 'macro avg': {'precision': 0.3431500813603734, 'recall': 0.3395286913219513, 'f1-score': 0.33670316158377206, 'support': 421010}, 'weighted avg': {'precision': 0.34711707575227513, 'recall': 0.34369254887057316, 'f1-score': 0.3410078414063452, 'support': 421010}}
[[33231 55444 46303]
 [34466 66980 61262]
 [25978 52859 44487]]
Evaluating performance on  train set...
653/653 - 4s - 4s/epoch - 6ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1321955
{'0': {'precision': 0.3469263010827803, 'recall': 0.2805196639130128, 'f1-score': 0.31020886199492487, 'support': 56652}, '1': {'precision': 0.34688608848389113, 'recall': 0.5219689578713969, 'f1-score': 0.4167870598566613, 'support': 56375}, '2': {'precision': 0.33549240649375706, 'recall': 0.22586331669480988, 'f1-score': 0.2699729406024043, 'support': 53891}, 'accuracy': 0.3444206137145185, 'macro avg': {'precision': 0.3431015986868095, 'recall': 0.34278397949307315, 'f1-score': 0.3323229541513302, 'support': 166918}, 'weighted avg': {'precision': 0.34322118241038174, 'recall': 0.3444206137145185, 'f1-score': 0.3332141212521114, 'support': 166918}}
[[15892 27621 13139]
 [15979 29426 10970]
 [13937 27782 12172]]
Evaluating performance on  val set...
181/181 - 1s - 1s/epoch - 6ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.116008
{'0': {'precision': 0.38852756157372853, 'recall': 0.22486886763344646, 'f1-score': 0.28486554096310196, 'support': 16205}, '1': {'precision': 0.3420275031253552, 'recall': 0.3960650128314799, 'f1-score': 0.36706815063271847, 'support': 15197}, '2': {'precision': 0.33091699891264953, 'recall': 0.4292718968296615, 'f1-score': 0.3737317622291746, 'support': 14888}, 'accuracy': 0.34681356664506374, 'macro avg': {'precision': 0.35382402120391104, 'recall': 0.35006859243152927, 'f1-score': 0.34188848460833166, 'support': 46290}, 'weighted avg': {'precision': 0.35473262864786825, 'recall': 0.34681356664506374, 'f1-score': 0.3404342029064688, 'support': 46290}}
[[3644 5668 6893]
 [3149 6019 6029]
 [2586 5911 6391]]
training model: results/QRTEA/W1/deepLOB_L1/h500
Epoch 1/50
653/653 - 12s - loss: 3.2305 - accuracy500: 0.4200 - val_loss: 3.3974 - val_accuracy500: 0.3115 - 12s/epoch - 19ms/step
Epoch 2/50
653/653 - 10s - loss: 3.2056 - accuracy500: 0.4258 - val_loss: 3.3988 - val_accuracy500: 0.3325 - 10s/epoch - 15ms/step
Epoch 3/50
653/653 - 10s - loss: 3.1773 - accuracy500: 0.4398 - val_loss: 3.3942 - val_accuracy500: 0.3469 - 10s/epoch - 15ms/step
Epoch 4/50
653/653 - 10s - loss: 3.1641 - accuracy500: 0.4457 - val_loss: 3.4199 - val_accuracy500: 0.3339 - 10s/epoch - 15ms/step
Epoch 5/50
653/653 - 10s - loss: 3.1589 - accuracy500: 0.4513 - val_loss: 3.4292 - val_accuracy500: 0.3516 - 10s/epoch - 15ms/step
Epoch 6/50
653/653 - 10s - loss: 3.1512 - accuracy500: 0.4553 - val_loss: 3.3662 - val_accuracy500: 0.3458 - 10s/epoch - 15ms/step
Epoch 7/50
653/653 - 10s - loss: 3.1463 - accuracy500: 0.4554 - val_loss: 3.3774 - val_accuracy500: 0.3515 - 10s/epoch - 15ms/step
Epoch 8/50
653/653 - 10s - loss: 3.1442 - accuracy500: 0.4553 - val_loss: 3.3739 - val_accuracy500: 0.3496 - 10s/epoch - 15ms/step
Epoch 9/50
653/653 - 10s - loss: 3.1370 - accuracy500: 0.4601 - val_loss: 3.4519 - val_accuracy500: 0.3288 - 10s/epoch - 15ms/step
Epoch 10/50
653/653 - 10s - loss: 3.1377 - accuracy500: 0.4578 - val_loss: 3.4747 - val_accuracy500: 0.3087 - 10s/epoch - 15ms/step
Epoch 11/50
653/653 - 10s - loss: 3.1185 - accuracy500: 0.4654 - val_loss: 3.5203 - val_accuracy500: 0.3045 - 10s/epoch - 15ms/step
Epoch 12/50
653/653 - 10s - loss: 3.1151 - accuracy500: 0.4670 - val_loss: 3.5124 - val_accuracy500: 0.3275 - 10s/epoch - 15ms/step
Epoch 13/50
653/653 - 10s - loss: 3.1171 - accuracy500: 0.4625 - val_loss: 3.4810 - val_accuracy500: 0.3344 - 10s/epoch - 15ms/step
Epoch 14/50
653/653 - 10s - loss: 3.1216 - accuracy500: 0.4603 - val_loss: 3.5127 - val_accuracy500: 0.3442 - 10s/epoch - 15ms/step
Epoch 15/50
653/653 - 10s - loss: 3.1102 - accuracy500: 0.4659 - val_loss: 3.4902 - val_accuracy500: 0.3538 - 10s/epoch - 15ms/step
Epoch 16/50
653/653 - 10s - loss: 3.1079 - accuracy500: 0.4645 - val_loss: 3.5326 - val_accuracy500: 0.3526 - 10s/epoch - 15ms/step
testing model: results/QRTEA/W1/deepLOB_L1/h500
Evaluating performance on  test set...
1645/1645 - 8s - 8s/epoch - 5ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1174749
{'0': {'precision': 0.3748161437876804, 'recall': 0.2982956007203499, 'f1-score': 0.33220637637974626, 'support': 155480}, '1': {'precision': 0.3077975836577185, 'recall': 0.43022116296755075, 'f1-score': 0.35885547624730657, 'support': 127553}, '2': {'precision': 0.3298959541458659, 'recall': 0.2844894438928227, 'f1-score': 0.305514801741885, 'support': 137977}, 'accuracy': 0.33374029120448445, 'macro avg': {'precision': 0.3375032271970883, 'recall': 0.3376687358602411, 'f1-score': 0.3321922181229793, 'support': 421010}, 'weighted avg': {'precision': 0.33978996529675226, 'recall': 0.33374029120448445, 'f1-score': 0.3315326376124931, 'support': 421010}}
[[46379 65274 43827]
 [36771 54876 35906]
 [40588 58136 39253]]
Evaluating performance on  train set...
653/653 - 4s - 4s/epoch - 6ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1051109
{'0': {'precision': 0.3678497714875424, 'recall': 0.34387058985667035, 'f1-score': 0.3554562290761451, 'support': 58048}, '1': {'precision': 0.37099992787247854, 'recall': 0.5505369438795533, 'f1-score': 0.44327942317083685, 'support': 56058}, '2': {'precision': 0.36144292113479026, 'recall': 0.20167764901916233, 'f1-score': 0.2588964511424405, 'support': 52812}, 'accuracy': 0.3682886207598941, 'macro avg': {'precision': 0.3667642068316037, 'recall': 0.36536172758512864, 'f1-score': 0.3525440344631408, 'support': 166918}, 'weighted avg': {'precision': 0.3668806302672857, 'recall': 0.3682886207598941, 'f1-score': 0.35439988777278314, 'support': 166918}}
[[19961 27549 10538]
 [16917 30862  8279]
 [17386 24775 10651]]
Evaluating performance on  val set...
181/181 - 1s - 1s/epoch - 6ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1190777
{'0': {'precision': 0.3833094702393127, 'recall': 0.31209059620295326, 'f1-score': 0.3440531195495854, 'support': 18014}, '1': {'precision': 0.28827566886118505, 'recall': 0.17120039930122286, 'f1-score': 0.2148225469728601, 'support': 12021}, '2': {'precision': 0.347533082829603, 'recall': 0.5234697016302676, 'f1-score': 0.41773239402047174, 'support': 16255}, 'accuracy': 0.3497299632750054, 'macro avg': {'precision': 0.3397060739767002, 'recall': 0.3355868990448146, 'f1-score': 0.32553602018097244, 'support': 46290}, 'weighted avg': {'precision': 0.3460671608050655, 'recall': 0.3497299632750054, 'f1-score': 0.33636627343983044, 'support': 46290}}
[[5622 2613 9779]
 [3767 2058 6196]
 [5278 2468 8509]]
training model: results/QRTEA/W1/deepLOB_L1/h1000
Epoch 1/50
653/653 - 12s - loss: 3.2030 - accuracy1000: 0.4338 - val_loss: 3.3537 - val_accuracy1000: 0.3502 - 12s/epoch - 18ms/step
Epoch 2/50
653/653 - 10s - loss: 3.1675 - accuracy1000: 0.4425 - val_loss: 3.4416 - val_accuracy1000: 0.3788 - 10s/epoch - 15ms/step
Epoch 3/50
653/653 - 10s - loss: 3.1581 - accuracy1000: 0.4470 - val_loss: 3.4549 - val_accuracy1000: 0.3923 - 10s/epoch - 15ms/step
Epoch 4/50
653/653 - 10s - loss: 3.1334 - accuracy1000: 0.4583 - val_loss: 3.3607 - val_accuracy1000: 0.3988 - 10s/epoch - 15ms/step
Epoch 5/50
653/653 - 10s - loss: 3.1538 - accuracy1000: 0.4493 - val_loss: 3.4137 - val_accuracy1000: 0.3950 - 10s/epoch - 15ms/step
Epoch 6/50
653/653 - 10s - loss: 3.1323 - accuracy1000: 0.4600 - val_loss: 3.4391 - val_accuracy1000: 0.3836 - 10s/epoch - 15ms/step
Epoch 7/50
653/653 - 10s - loss: 3.1180 - accuracy1000: 0.4650 - val_loss: 3.5165 - val_accuracy1000: 0.3755 - 10s/epoch - 15ms/step
Epoch 8/50
653/653 - 10s - loss: 3.0986 - accuracy1000: 0.4723 - val_loss: 3.6744 - val_accuracy1000: 0.3658 - 10s/epoch - 15ms/step
Epoch 9/50
653/653 - 10s - loss: 3.1137 - accuracy1000: 0.4604 - val_loss: 3.5555 - val_accuracy1000: 0.3786 - 10s/epoch - 15ms/step
Epoch 10/50
653/653 - 10s - loss: 3.0937 - accuracy1000: 0.4715 - val_loss: 3.6023 - val_accuracy1000: 0.3841 - 10s/epoch - 15ms/step
Epoch 11/50
653/653 - 10s - loss: 3.0888 - accuracy1000: 0.4717 - val_loss: 3.5887 - val_accuracy1000: 0.3755 - 10s/epoch - 15ms/step
testing model: results/QRTEA/W1/deepLOB_L1/h1000
Evaluating performance on  test set...
1645/1645 - 10s - 10s/epoch - 6ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1153423
{'0': {'precision': 0.4249718933932941, 'recall': 0.2929214078552259, 'f1-score': 0.3468018578670957, 'support': 175501}, '1': {'precision': 0.20406334545329222, 'recall': 0.13882441208881385, 'f1-score': 0.165237593575799, 'support': 85302}, '2': {'precision': 0.40088673655329715, 'recall': 0.6055852740516956, 'f1-score': 0.4824199812042226, 'support': 160207}, 'accuracy': 0.3806774185886321, 'macro avg': {'precision': 0.3433073251332945, 'recall': 0.3457770313319118, 'f1-score': 0.3314864775490391, 'support': 421010}, 'weighted avg': {'precision': 0.37104787335043665, 'recall': 0.3806774185886321, 'f1-score': 0.3616214056519343, 'support': 421010}}
[[51408 25377 98716]
 [27184 11842 46276]
 [42376 20812 97019]]
Evaluating performance on  train set...
653/653 - 4s - 4s/epoch - 6ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1432424
{'0': {'precision': 0.31915500570536304, 'recall': 0.355515788065293, 'f1-score': 0.3363555808728124, 'support': 59792}, '1': {'precision': 0.321875, 'recall': 0.16912340933686607, 'f1-score': 0.22173838588937544, 'support': 53594}, '2': {'precision': 0.3448180281065499, 'recall': 0.4647687364566988, 'f1-score': 0.39590726095189605, 'support': 53532}, 'accuracy': 0.3307072934015505, 'macro avg': {'precision': 0.3286160112706376, 'recall': 0.3298026446196193, 'f1-score': 0.31800040923802797, 'support': 166918}, 'weighted avg': {'precision': 0.3282586870902773, 'recall': 0.3307072934015505, 'f1-score': 0.31865303585101246, 'support': 166918}}
[[21257  9658 28877]
 [26133  9064 18397]
 [19214  9438 24880]]
Evaluating performance on  val set...
181/181 - 1s - 1s/epoch - 6ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1262925
{'0': {'precision': 0.44551197683600946, 'recall': 0.3395526131006119, 'f1-score': 0.3853816815620197, 'support': 19938}, '1': {'precision': 0.19203640500568828, 'recall': 0.28158362989323843, 'f1-score': 0.22834468142670333, 'support': 8992}, '2': {'precision': 0.39041822547322574, 'recall': 0.40276497695852537, 'f1-score': 0.3964955059684142, 'support': 17360}, 'accuracy': 0.35199827176496, 'macro avg': {'precision': 0.34265553577164115, 'recall': 0.34130040665079187, 'f1-score': 0.33674062298571245, 'support': 46290}, 'weighted avg': {'precision': 0.3756117853139491, 'recall': 0.35199827176496, 'f1-score': 0.35904466031506016, 'support': 46290}}
[[6770 5444 7724]
 [3267 2532 3193]
 [5159 5209 6992]]
training model: results/QRTEA/W1/deepOF_L1/h10
Epoch 1/50
653/653 - 11s - loss: 3.1469 - accuracy10: 0.4251 - val_loss: 2.7893 - val_accuracy10: 0.5948 - 11s/epoch - 17ms/step
Epoch 2/50
653/653 - 9s - loss: 3.0703 - accuracy10: 0.4488 - val_loss: 2.7445 - val_accuracy10: 0.5837 - 9s/epoch - 14ms/step
Epoch 3/50
653/653 - 9s - loss: 3.0392 - accuracy10: 0.4632 - val_loss: 2.7227 - val_accuracy10: 0.5755 - 9s/epoch - 13ms/step
Epoch 4/50
653/653 - 9s - loss: 3.0219 - accuracy10: 0.4706 - val_loss: 2.7066 - val_accuracy10: 0.5890 - 9s/epoch - 13ms/step
Epoch 5/50
653/653 - 9s - loss: 3.0031 - accuracy10: 0.4775 - val_loss: 2.7008 - val_accuracy10: 0.5971 - 9s/epoch - 13ms/step
Epoch 6/50
653/653 - 9s - loss: 2.9909 - accuracy10: 0.4862 - val_loss: 2.6960 - val_accuracy10: 0.6192 - 9s/epoch - 13ms/step
Epoch 7/50
653/653 - 9s - loss: 2.9760 - accuracy10: 0.4918 - val_loss: 2.6800 - val_accuracy10: 0.6238 - 9s/epoch - 13ms/step
Epoch 8/50
653/653 - 9s - loss: 2.9599 - accuracy10: 0.4966 - val_loss: 2.6845 - val_accuracy10: 0.6334 - 9s/epoch - 13ms/step
Epoch 9/50
653/653 - 9s - loss: 2.9484 - accuracy10: 0.4978 - val_loss: 2.6801 - val_accuracy10: 0.6447 - 9s/epoch - 13ms/step
Epoch 10/50
653/653 - 9s - loss: 2.9366 - accuracy10: 0.5019 - val_loss: 2.6773 - val_accuracy10: 0.6388 - 9s/epoch - 13ms/step
Epoch 11/50
653/653 - 9s - loss: 2.9225 - accuracy10: 0.5058 - val_loss: 2.6879 - val_accuracy10: 0.6551 - 9s/epoch - 13ms/step
Epoch 12/50
653/653 - 9s - loss: 2.9129 - accuracy10: 0.5078 - val_loss: 2.6823 - val_accuracy10: 0.6689 - 9s/epoch - 13ms/step
Epoch 13/50
653/653 - 9s - loss: 2.9012 - accuracy10: 0.5070 - val_loss: 2.6724 - val_accuracy10: 0.6594 - 9s/epoch - 13ms/step
Epoch 14/50
653/653 - 9s - loss: 2.8890 - accuracy10: 0.5089 - val_loss: 2.6835 - val_accuracy10: 0.6693 - 9s/epoch - 13ms/step
Epoch 15/50
653/653 - 9s - loss: 2.8767 - accuracy10: 0.5117 - val_loss: 2.6815 - val_accuracy10: 0.6787 - 9s/epoch - 13ms/step
Epoch 16/50
653/653 - 9s - loss: 2.8652 - accuracy10: 0.5137 - val_loss: 2.6809 - val_accuracy10: 0.6779 - 9s/epoch - 13ms/step
Epoch 17/50
653/653 - 9s - loss: 2.8541 - accuracy10: 0.5132 - val_loss: 2.7121 - val_accuracy10: 0.6816 - 9s/epoch - 13ms/step
Epoch 18/50
653/653 - 9s - loss: 2.8443 - accuracy10: 0.5125 - val_loss: 2.6968 - val_accuracy10: 0.6862 - 9s/epoch - 13ms/step
Epoch 19/50
653/653 - 9s - loss: 2.8280 - accuracy10: 0.5165 - val_loss: 2.7233 - val_accuracy10: 0.6858 - 9s/epoch - 13ms/step
Epoch 20/50
653/653 - 9s - loss: 2.8248 - accuracy10: 0.5159 - val_loss: 2.7085 - val_accuracy10: 0.6970 - 9s/epoch - 13ms/step
Epoch 21/50
653/653 - 9s - loss: 2.8092 - accuracy10: 0.5189 - val_loss: 2.7437 - val_accuracy10: 0.7006 - 9s/epoch - 13ms/step
Epoch 22/50
653/653 - 9s - loss: 2.8011 - accuracy10: 0.5190 - val_loss: 2.7447 - val_accuracy10: 0.7029 - 9s/epoch - 13ms/step
Epoch 23/50
653/653 - 9s - loss: 2.7895 - accuracy10: 0.5183 - val_loss: 2.7278 - val_accuracy10: 0.6983 - 9s/epoch - 13ms/step
testing model: results/QRTEA/W1/deepOF_L1/h10
Evaluating performance on  test set...
1645/1645 - 9s - 9s/epoch - 6ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.79544514
{'0': {'precision': 0.1918780193236715, 'recall': 0.4837793523452597, 'f1-score': 0.2747742504115877, 'support': 34154}, '1': {'precision': 0.8894212844695453, 'recall': 0.7302710271367266, 'f1-score': 0.8020271385034912, 'support': 352806}, '2': {'precision': 0.2652763341221222, 'recall': 0.35232780143927156, 'f1-score': 0.30266710403472036, 'support': 34045}, 'accuracy': 0.6797116423795442, 'macro avg': {'precision': 0.4488585459717797, 'recall': 0.522126060307086, 'f1-score': 0.45982283098326643, 'support': 421005}, 'weighted avg': {'precision': 0.7823610179350143, 'recall': 0.6797116423795442, 'f1-score': 0.7188725262937071, 'support': 421005}}
[[ 16523  15544   2087]
 [ 64027 257644  31135]
 [  5562  16488  11995]]
Evaluating performance on  train set...
653/653 - 3s - 3s/epoch - 5ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.8502325
{'0': {'precision': 0.275083335835911, 'recall': 0.42356422824378065, 'f1-score': 0.3335457441966318, 'support': 21626}, '1': {'precision': 0.8005650715168638, 'recall': 0.729872011591403, 'f1-score': 0.7635858351930607, 'support': 124230}, '2': {'precision': 0.3105260572719682, 'recall': 0.30016142816446684, 'f1-score': 0.3052557881267956, 'support': 21062}, 'accuracy': 0.6359649648330318, 'macro avg': {'precision': 0.4620581548749143, 'recall': 0.4845325559998835, 'f1-score': 0.4674624558388294, 'support': 166918}, 'weighted avg': {'precision': 0.6706493659976133, 'recall': 0.6359649648330318, 'f1-score': 0.6500367005329375, 'support': 166918}}
[[ 9160 10768  1698]
 [21219 90672 12339]
 [ 2920 11820  6322]]
Evaluating performance on  val set...
181/181 - 1s - 1s/epoch - 6ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.82364804
{'0': {'precision': 0.2558477895914941, 'recall': 0.4506209343583678, 'f1-score': 0.3263849229011993, 'support': 5073}, '1': {'precision': 0.845259705104933, 'recall': 0.7310033325070919, 'f1-score': 0.783990547924974, 'support': 36309}, '2': {'precision': 0.2961034598589184, 'recall': 0.35920945395273024, 'f1-score': 0.32461793408212114, 'support': 4908}, 'accuracy': 0.6608554763447829, 'macro avg': {'precision': 0.4657369848517819, 'recall': 0.51361124027273, 'f1-score': 0.47833113496943147, 'support': 46290}, 'weighted avg': {'precision': 0.7224395387824634, 'recall': 0.6608554763447829, 'f1-score': 0.6851347664497887, 'support': 46290}}
[[ 2286  2364   423]
 [ 5999 26542  3768]
 [  650  2495  1763]]
training model: results/QRTEA/W1/deepOF_L1/h20
Epoch 1/50
653/653 - 11s - loss: 3.1533 - accuracy20: 0.4221 - val_loss: 2.8845 - val_accuracy20: 0.5884 - 11s/epoch - 17ms/step
Epoch 2/50
653/653 - 9s - loss: 3.0800 - accuracy20: 0.4465 - val_loss: 2.8387 - val_accuracy20: 0.5774 - 9s/epoch - 14ms/step
Epoch 3/50
653/653 - 9s - loss: 3.0493 - accuracy20: 0.4583 - val_loss: 2.8039 - val_accuracy20: 0.5841 - 9s/epoch - 13ms/step
Epoch 4/50
653/653 - 9s - loss: 3.0276 - accuracy20: 0.4654 - val_loss: 2.7869 - val_accuracy20: 0.5781 - 9s/epoch - 14ms/step
Epoch 5/50
653/653 - 9s - loss: 3.0089 - accuracy20: 0.4703 - val_loss: 2.7751 - val_accuracy20: 0.5782 - 9s/epoch - 13ms/step
Epoch 6/50
653/653 - 9s - loss: 2.9915 - accuracy20: 0.4738 - val_loss: 2.7642 - val_accuracy20: 0.5891 - 9s/epoch - 14ms/step
Epoch 7/50
653/653 - 9s - loss: 2.9753 - accuracy20: 0.4801 - val_loss: 2.7583 - val_accuracy20: 0.6070 - 9s/epoch - 14ms/step
Epoch 8/50
653/653 - 9s - loss: 2.9610 - accuracy20: 0.4817 - val_loss: 2.7588 - val_accuracy20: 0.6149 - 9s/epoch - 13ms/step
Epoch 9/50
653/653 - 9s - loss: 2.9493 - accuracy20: 0.4859 - val_loss: 2.7556 - val_accuracy20: 0.6184 - 9s/epoch - 13ms/step
Epoch 10/50
653/653 - 9s - loss: 2.9369 - accuracy20: 0.4881 - val_loss: 2.7583 - val_accuracy20: 0.6298 - 9s/epoch - 13ms/step
Epoch 11/50
653/653 - 9s - loss: 2.9276 - accuracy20: 0.4928 - val_loss: 2.7624 - val_accuracy20: 0.6378 - 9s/epoch - 13ms/step
Epoch 12/50
653/653 - 9s - loss: 2.9159 - accuracy20: 0.4956 - val_loss: 2.7605 - val_accuracy20: 0.6450 - 9s/epoch - 13ms/step
Epoch 13/50
653/653 - 9s - loss: 2.9057 - accuracy20: 0.4979 - val_loss: 2.7725 - val_accuracy20: 0.6538 - 9s/epoch - 13ms/step
Epoch 14/50
653/653 - 9s - loss: 2.8951 - accuracy20: 0.5015 - val_loss: 2.7828 - val_accuracy20: 0.6535 - 9s/epoch - 13ms/step
Epoch 15/50
653/653 - 8s - loss: 2.8830 - accuracy20: 0.5058 - val_loss: 2.7803 - val_accuracy20: 0.6628 - 8s/epoch - 13ms/step
Epoch 16/50
653/653 - 9s - loss: 2.8738 - accuracy20: 0.5060 - val_loss: 2.7979 - val_accuracy20: 0.6664 - 9s/epoch - 13ms/step
Epoch 17/50
653/653 - 9s - loss: 2.8616 - accuracy20: 0.5093 - val_loss: 2.7945 - val_accuracy20: 0.6677 - 9s/epoch - 13ms/step
Epoch 18/50
653/653 - 9s - loss: 2.8501 - accuracy20: 0.5101 - val_loss: 2.8067 - val_accuracy20: 0.6667 - 9s/epoch - 13ms/step
Epoch 19/50
653/653 - 9s - loss: 2.8395 - accuracy20: 0.5111 - val_loss: 2.7966 - val_accuracy20: 0.6659 - 9s/epoch - 13ms/step
testing model: results/QRTEA/W1/deepOF_L1/h20
Evaluating performance on  test set...
1645/1645 - 10s - 10s/epoch - 6ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.8706507
{'0': {'precision': 0.22893893944786212, 'recall': 0.48113086588597315, 'f1-score': 0.31025003272679674, 'support': 46796}, '1': {'precision': 0.83446563225058, 'recall': 0.7017417098816808, 'f1-score': 0.762370187347541, 'support': 328011}, '2': {'precision': 0.3344297308842375, 'recall': 0.3389324213169401, 'f1-score': 0.3366660216302221, 'support': 46198}, 'accuracy': 0.6374081067920808, 'macro avg': {'precision': 0.46594476752755987, 'recall': 0.5072683323615313, 'f1-score': 0.4697620805681866, 'support': 421005}, 'weighted avg': {'precision': 0.7122892075342031, 'recall': 0.6374081067920808, 'f1-score': 0.665401990287076, 'support': 421005}}
[[ 22515  21847   2434]
 [ 69104 230179  28728]
 [  6726  23814  15658]]
Evaluating performance on  train set...
653/653 - 4s - 4s/epoch - 6ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.91664004
{'0': {'precision': 0.32596217431556673, 'recall': 0.4353647765412471, 'f1-score': 0.37280290425049156, 'support': 28305}, '1': {'precision': 0.7230599586492075, 'recall': 0.7095822962882805, 'f1-score': 0.7162577315364764, 'support': 110892}, '2': {'precision': 0.3801754731861199, 'recall': 0.2782367158471917, 'f1-score': 0.3213147534837218, 'support': 27721}, 'accuracy': 0.5914460992822823, 'macro avg': {'precision': 0.47639920205029807, 'recall': 0.4743945962255731, 'f1-score': 0.4701251297568965, 'support': 166918}, 'weighted avg': {'precision': 0.5987776547210155, 'recall': 0.5914460992822823, 'f1-score': 0.5924262503245626, 'support': 166918}}
[[12323 14010  1972]
 [21602 78687 10603]
 [ 3880 16128  7713]]
Evaluating performance on  val set...
181/181 - 1s - 1s/epoch - 6ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.89066625
{'0': {'precision': 0.3025322503583373, 'recall': 0.45804398148148145, 'f1-score': 0.3643897105369166, 'support': 6912}, '1': {'precision': 0.77229071815493, 'recall': 0.7099563132007454, 'f1-score': 0.7398128103909333, 'support': 32733}, '2': {'precision': 0.38576909661667247, 'recall': 0.3328818660647103, 'f1-score': 0.35737943291057434, 'support': 6645}, 'accuracy': 0.6182112767336357, 'macro avg': {'precision': 0.48686402170997994, 'recall': 0.5002940535823124, 'f1-score': 0.4871939846128081, 'support': 46290}, 'weighted avg': {'precision': 0.6466608476746585, 'recall': 0.6182112767336357, 'f1-score': 0.6288559242481822, 'support': 46290}}
[[ 3166  3268   478]
 [ 6450 23239  3044]
 [  849  3584  2212]]
training model: results/QRTEA/W1/deepOF_L1/h30
Epoch 1/50
653/653 - 11s - loss: 3.1690 - accuracy30: 0.4234 - val_loss: 2.9399 - val_accuracy30: 0.5572 - 11s/epoch - 17ms/step
Epoch 2/50
653/653 - 9s - loss: 3.0960 - accuracy30: 0.4428 - val_loss: 2.8907 - val_accuracy30: 0.5493 - 9s/epoch - 14ms/step
Epoch 3/50
653/653 - 9s - loss: 3.0691 - accuracy30: 0.4526 - val_loss: 2.8670 - val_accuracy30: 0.5478 - 9s/epoch - 13ms/step
Epoch 4/50
653/653 - 9s - loss: 3.0503 - accuracy30: 0.4579 - val_loss: 2.8602 - val_accuracy30: 0.5556 - 9s/epoch - 13ms/step
Epoch 5/50
653/653 - 9s - loss: 3.0302 - accuracy30: 0.4617 - val_loss: 2.8409 - val_accuracy30: 0.5630 - 9s/epoch - 13ms/step
Epoch 6/50
653/653 - 9s - loss: 3.0112 - accuracy30: 0.4684 - val_loss: 2.8408 - val_accuracy30: 0.5728 - 9s/epoch - 13ms/step
Epoch 7/50
653/653 - 9s - loss: 2.9977 - accuracy30: 0.4722 - val_loss: 2.8406 - val_accuracy30: 0.5753 - 9s/epoch - 13ms/step
Epoch 8/50
653/653 - 9s - loss: 2.9872 - accuracy30: 0.4759 - val_loss: 2.8239 - val_accuracy30: 0.5831 - 9s/epoch - 13ms/step
Epoch 9/50
653/653 - 9s - loss: 2.9727 - accuracy30: 0.4825 - val_loss: 2.8283 - val_accuracy30: 0.5960 - 9s/epoch - 13ms/step
Epoch 10/50
653/653 - 9s - loss: 2.9634 - accuracy30: 0.4847 - val_loss: 2.8181 - val_accuracy30: 0.5944 - 9s/epoch - 13ms/step
Epoch 11/50
653/653 - 9s - loss: 2.9493 - accuracy30: 0.4907 - val_loss: 2.8267 - val_accuracy30: 0.6019 - 9s/epoch - 13ms/step
Epoch 12/50
653/653 - 9s - loss: 2.9424 - accuracy30: 0.4931 - val_loss: 2.8160 - val_accuracy30: 0.6026 - 9s/epoch - 13ms/step
Epoch 13/50
653/653 - 9s - loss: 2.9315 - accuracy30: 0.4970 - val_loss: 2.8225 - val_accuracy30: 0.6093 - 9s/epoch - 13ms/step
Epoch 14/50
653/653 - 9s - loss: 2.9207 - accuracy30: 0.4991 - val_loss: 2.8242 - val_accuracy30: 0.6148 - 9s/epoch - 13ms/step
Epoch 15/50
653/653 - 9s - loss: 2.9120 - accuracy30: 0.5006 - val_loss: 2.8348 - val_accuracy30: 0.6183 - 9s/epoch - 13ms/step
Epoch 16/50
653/653 - 9s - loss: 2.8990 - accuracy30: 0.5051 - val_loss: 2.8395 - val_accuracy30: 0.6118 - 9s/epoch - 13ms/step
Epoch 17/50
653/653 - 9s - loss: 2.8900 - accuracy30: 0.5053 - val_loss: 2.8430 - val_accuracy30: 0.6119 - 9s/epoch - 13ms/step
Epoch 18/50
653/653 - 9s - loss: 2.8783 - accuracy30: 0.5093 - val_loss: 2.8374 - val_accuracy30: 0.6223 - 9s/epoch - 13ms/step
Epoch 19/50
653/653 - 9s - loss: 2.8722 - accuracy30: 0.5090 - val_loss: 2.8513 - val_accuracy30: 0.6197 - 9s/epoch - 13ms/step
Epoch 20/50
653/653 - 9s - loss: 2.8634 - accuracy30: 0.5119 - val_loss: 2.8551 - val_accuracy30: 0.6182 - 9s/epoch - 13ms/step
Epoch 21/50
653/653 - 9s - loss: 2.8538 - accuracy30: 0.5118 - val_loss: 2.8647 - val_accuracy30: 0.6256 - 9s/epoch - 13ms/step
Epoch 22/50
653/653 - 9s - loss: 2.8445 - accuracy30: 0.5136 - val_loss: 2.8542 - val_accuracy30: 0.6213 - 9s/epoch - 13ms/step
testing model: results/QRTEA/W1/deepOF_L1/h30
Evaluating performance on  test set...
1645/1645 - 9s - 9s/epoch - 6ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.87978506
{'0': {'precision': 0.27149630609769543, 'recall': 0.43538690055170465, 'f1-score': 0.3344426182746771, 'support': 56552}, '1': {'precision': 0.7878374399448462, 'recall': 0.7102559288345623, 'f1-score': 0.7470378340097512, 'support': 308914}, '2': {'precision': 0.35213523475039077, 'recall': 0.328561911449612, 'f1-score': 0.3399403874813711, 'support': 55539}, 'accuracy': 0.6229807246944811, 'macro avg': {'precision': 0.47048966026431077, 'recall': 0.4914015802786264, 'f1-score': 0.47380694658859984, 'support': 421005}, 'weighted avg': {'precision': 0.6610014437556823, 'recall': 0.6229807246944811, 'f1-score': 0.6379111734641767, 'support': 421005}}
[[ 24622  28859   3071]
 [ 59004 219408  30502]
 [  7064  30227  18248]]
Evaluating performance on  train set...
653/653 - 4s - 4s/epoch - 6ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.9320209
{'0': {'precision': 0.38124560168895144, 'recall': 0.3933206280061712, 'f1-score': 0.38718899361236436, 'support': 33057}, '1': {'precision': 0.6661601497842781, 'recall': 0.7255371339066702, 'f1-score': 0.6945819776488894, 'support': 101511}, '2': {'precision': 0.4001797348910357, 'recall': 0.2753013910355487, 'f1-score': 0.32619723468546835, 'support': 32350}, 'accuracy': 0.5724846930828311, 'macro avg': {'precision': 0.48252849545475507, 'recall': 0.46471971764946335, 'f1-score': 0.46932273531557406, 'support': 166918}, 'weighted avg': {'precision': 0.5581856554925684, 'recall': 0.5724846930828311, 'f1-score': 0.5623090274088788, 'support': 166918}}
[[13002 17355  2700]
 [17212 73650 10649]
 [ 3890 19554  8906]]
Evaluating performance on  val set...
181/181 - 1s - 1s/epoch - 6ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.90297717
{'0': {'precision': 0.35999581764951905, 'recall': 0.4203907203907204, 'f1-score': 0.3878562577447336, 'support': 8190}, '1': {'precision': 0.7176781875310071, 'recall': 0.7187003179650239, 'f1-score': 0.7181888890727656, 'support': 30192}, '2': {'precision': 0.4087197658296102, 'recall': 0.3354830551340415, 'f1-score': 0.3684978123480797, 'support': 7908}, 'accuracy': 0.600453661697991, 'macro avg': {'precision': 0.49546459033671214, 'recall': 0.4915246978299286, 'f1-score': 0.49151431972185966, 'support': 46290}, 'weighted avg': {'precision': 0.6016129075970249, 'recall': 0.600453661697991, 'f1-score': 0.6000039401569004, 'support': 46290}}
[[ 3443  4174   573]
 [ 5228 21699  3265]
 [  893  4362  2653]]
training model: results/QRTEA/W1/deepOF_L1/h50
Epoch 1/50
653/653 - 11s - loss: 3.1972 - accuracy50: 0.4196 - val_loss: 3.0484 - val_accuracy50: 0.5173 - 11s/epoch - 16ms/step
Epoch 2/50
653/653 - 9s - loss: 3.1317 - accuracy50: 0.4393 - val_loss: 3.0188 - val_accuracy50: 0.5213 - 9s/epoch - 14ms/step
Epoch 3/50
653/653 - 9s - loss: 3.1079 - accuracy50: 0.4454 - val_loss: 2.9964 - val_accuracy50: 0.5212 - 9s/epoch - 13ms/step
Epoch 4/50
653/653 - 9s - loss: 3.0901 - accuracy50: 0.4499 - val_loss: 2.9843 - val_accuracy50: 0.5233 - 9s/epoch - 13ms/step
Epoch 5/50
653/653 - 9s - loss: 3.0760 - accuracy50: 0.4530 - val_loss: 2.9839 - val_accuracy50: 0.5281 - 9s/epoch - 13ms/step
Epoch 6/50
653/653 - 9s - loss: 3.0606 - accuracy50: 0.4570 - val_loss: 2.9872 - val_accuracy50: 0.5367 - 9s/epoch - 13ms/step
Epoch 7/50
653/653 - 9s - loss: 3.0490 - accuracy50: 0.4618 - val_loss: 2.9623 - val_accuracy50: 0.5414 - 9s/epoch - 13ms/step
Epoch 8/50
653/653 - 9s - loss: 3.0377 - accuracy50: 0.4652 - val_loss: 2.9665 - val_accuracy50: 0.5464 - 9s/epoch - 13ms/step
Epoch 9/50
653/653 - 9s - loss: 3.0257 - accuracy50: 0.4701 - val_loss: 2.9716 - val_accuracy50: 0.5545 - 9s/epoch - 13ms/step
Epoch 10/50
653/653 - 9s - loss: 3.0169 - accuracy50: 0.4727 - val_loss: 2.9644 - val_accuracy50: 0.5590 - 9s/epoch - 13ms/step
Epoch 11/50
653/653 - 9s - loss: 3.0064 - accuracy50: 0.4764 - val_loss: 2.9516 - val_accuracy50: 0.5613 - 9s/epoch - 13ms/step
Epoch 12/50
653/653 - 9s - loss: 2.9993 - accuracy50: 0.4771 - val_loss: 2.9473 - val_accuracy50: 0.5672 - 9s/epoch - 13ms/step
Epoch 13/50
653/653 - 9s - loss: 2.9896 - accuracy50: 0.4778 - val_loss: 2.9451 - val_accuracy50: 0.5641 - 9s/epoch - 13ms/step
Epoch 14/50
653/653 - 9s - loss: 2.9828 - accuracy50: 0.4823 - val_loss: 2.9494 - val_accuracy50: 0.5651 - 9s/epoch - 13ms/step
Epoch 15/50
653/653 - 9s - loss: 2.9740 - accuracy50: 0.4853 - val_loss: 2.9565 - val_accuracy50: 0.5696 - 9s/epoch - 13ms/step
Epoch 16/50
653/653 - 8s - loss: 2.9642 - accuracy50: 0.4868 - val_loss: 2.9623 - val_accuracy50: 0.5701 - 8s/epoch - 13ms/step
Epoch 17/50
653/653 - 9s - loss: 2.9592 - accuracy50: 0.4885 - val_loss: 2.9597 - val_accuracy50: 0.5658 - 9s/epoch - 13ms/step
Epoch 18/50
653/653 - 9s - loss: 2.9510 - accuracy50: 0.4902 - val_loss: 2.9813 - val_accuracy50: 0.5739 - 9s/epoch - 13ms/step
Epoch 19/50
653/653 - 9s - loss: 2.9457 - accuracy50: 0.4912 - val_loss: 2.9900 - val_accuracy50: 0.5720 - 9s/epoch - 13ms/step
Epoch 20/50
653/653 - 9s - loss: 2.9363 - accuracy50: 0.4930 - val_loss: 2.9993 - val_accuracy50: 0.5686 - 9s/epoch - 13ms/step
Epoch 21/50
653/653 - 9s - loss: 2.9282 - accuracy50: 0.4954 - val_loss: 3.0059 - val_accuracy50: 0.5779 - 9s/epoch - 13ms/step
Epoch 22/50
653/653 - 9s - loss: 2.9168 - accuracy50: 0.4971 - val_loss: 3.0237 - val_accuracy50: 0.5756 - 9s/epoch - 13ms/step
Epoch 23/50
653/653 - 9s - loss: 2.9114 - accuracy50: 0.4982 - val_loss: 3.0035 - val_accuracy50: 0.5734 - 9s/epoch - 13ms/step
testing model: results/QRTEA/W1/deepOF_L1/h50
Evaluating performance on  test set...
1645/1645 - 9s - 9s/epoch - 5ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.9182871
{'0': {'precision': 0.32229434806939006, 'recall': 0.39118917597196184, 'f1-score': 0.3534154782651383, 'support': 73614}, '1': {'precision': 0.7008832846846598, 'recall': 0.7333975080429488, 'f1-score': 0.7167718580950242, 'support': 276329}, '2': {'precision': 0.41955442632978096, 'recall': 0.2509639469758802, 'f1-score': 0.314064577481531, 'support': 71062}, 'accuracy': 0.5921307347893731, 'macro avg': {'precision': 0.48091068636127693, 'recall': 0.4585168769969303, 'f1-score': 0.46141730461389785, 'support': 421005}, 'weighted avg': {'precision': 0.5871999856444801, 'recall': 0.5921307347893731, 'f1-score': 0.5852643906783587, 'support': 421005}}
[[ 28797  41922   2895]
 [ 51892 202659  21778]
 [  8661  44567  17834]]
Evaluating performance on  train set...
653/653 - 4s - 4s/epoch - 5ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.97473425
{'0': {'precision': 0.4357233283461848, 'recall': 0.3777877563239036, 'f1-score': 0.4046925523102001, 'support': 40086}, '1': {'precision': 0.5708399588849745, 'recall': 0.743350379242887, 'f1-score': 0.6457726671900932, 'support': 87411}, '2': {'precision': 0.46206708481047176, 'recall': 0.2149108343268816, 'f1-score': 0.29337211718263034, 'support': 39421}, 'accuracy': 0.5307576175127907, 'macro avg': {'precision': 0.4895434573472104, 'recall': 0.44534965663122406, 'f1-score': 0.4479457788943078, 'support': 166918}, 'weighted avg': {'precision': 0.5127023061412985, 'recall': 0.5307576175127907, 'f1-score': 0.5046499628267557, 'support': 166918}}
[[15144 22523  2419]
 [14990 64977  7444]
 [ 4622 26327  8472]]
Evaluating performance on  val set...
181/181 - 1s - 1s/epoch - 6ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.9435085
{'0': {'precision': 0.42221289103506193, 'recall': 0.38848642905438036, 'f1-score': 0.40464812113285376, 'support': 10353}, '1': {'precision': 0.6208608211106129, 'recall': 0.7416035498431642, 'f1-score': 0.6758820248222005, 'support': 26142}, '2': {'precision': 0.4758035391838209, 'recall': 0.26901480347115875, 'f1-score': 0.3437031239809561, 'support': 9795}, 'accuracy': 0.5626269172607474, 'macro avg': {'precision': 0.5062924171098319, 'recall': 0.46636826078956783, 'f1-score': 0.47474442331200345, 'support': 46290}, 'weighted avg': {'precision': 0.5457379415136134, 'recall': 0.5626269172607474, 'f1-score': 0.5449298334496407, 'support': 46290}}
[[ 4022  5780   551]
 [ 4403 19387  2352]
 [ 1101  6059  2635]]
training model: results/QRTEA/W1/deepOF_L1/h100
Epoch 1/50
653/653 - 11s - loss: 3.2555 - accuracy100: 0.4046 - val_loss: 3.2289 - val_accuracy100: 0.4407 - 11s/epoch - 16ms/step
Epoch 2/50
653/653 - 9s - loss: 3.2053 - accuracy100: 0.4262 - val_loss: 3.1828 - val_accuracy100: 0.4461 - 9s/epoch - 13ms/step
Epoch 3/50
653/653 - 9s - loss: 3.1901 - accuracy100: 0.4299 - val_loss: 3.1560 - val_accuracy100: 0.4469 - 9s/epoch - 13ms/step
Epoch 4/50
653/653 - 9s - loss: 3.1800 - accuracy100: 0.4320 - val_loss: 3.1594 - val_accuracy100: 0.4422 - 9s/epoch - 13ms/step
Epoch 5/50
653/653 - 9s - loss: 3.1721 - accuracy100: 0.4355 - val_loss: 3.1484 - val_accuracy100: 0.4464 - 9s/epoch - 13ms/step
Epoch 6/50
653/653 - 9s - loss: 3.1633 - accuracy100: 0.4375 - val_loss: 3.1343 - val_accuracy100: 0.4495 - 9s/epoch - 13ms/step
Epoch 7/50
653/653 - 9s - loss: 3.1547 - accuracy100: 0.4401 - val_loss: 3.1378 - val_accuracy100: 0.4524 - 9s/epoch - 13ms/step
Epoch 8/50
653/653 - 9s - loss: 3.1487 - accuracy100: 0.4423 - val_loss: 3.1370 - val_accuracy100: 0.4575 - 9s/epoch - 13ms/step
Epoch 9/50
653/653 - 9s - loss: 3.1418 - accuracy100: 0.4452 - val_loss: 3.1338 - val_accuracy100: 0.4593 - 9s/epoch - 13ms/step
Epoch 10/50
653/653 - 9s - loss: 3.1340 - accuracy100: 0.4479 - val_loss: 3.1379 - val_accuracy100: 0.4603 - 9s/epoch - 13ms/step
Epoch 11/50
653/653 - 9s - loss: 3.1270 - accuracy100: 0.4509 - val_loss: 3.1492 - val_accuracy100: 0.4618 - 9s/epoch - 13ms/step
Epoch 12/50
653/653 - 9s - loss: 3.1207 - accuracy100: 0.4519 - val_loss: 3.1588 - val_accuracy100: 0.4630 - 9s/epoch - 13ms/step
Epoch 13/50
653/653 - 9s - loss: 3.1142 - accuracy100: 0.4546 - val_loss: 3.1724 - val_accuracy100: 0.4622 - 9s/epoch - 13ms/step
Epoch 14/50
653/653 - 9s - loss: 3.1086 - accuracy100: 0.4566 - val_loss: 3.1696 - val_accuracy100: 0.4632 - 9s/epoch - 13ms/step
Epoch 15/50
653/653 - 9s - loss: 3.1033 - accuracy100: 0.4590 - val_loss: 3.1963 - val_accuracy100: 0.4638 - 9s/epoch - 13ms/step
Epoch 16/50
653/653 - 9s - loss: 3.1005 - accuracy100: 0.4600 - val_loss: 3.1808 - val_accuracy100: 0.4636 - 9s/epoch - 13ms/step
Epoch 17/50
653/653 - 9s - loss: 3.0899 - accuracy100: 0.4644 - val_loss: 3.1727 - val_accuracy100: 0.4661 - 9s/epoch - 13ms/step
Epoch 18/50
653/653 - 9s - loss: 3.0861 - accuracy100: 0.4651 - val_loss: 3.1851 - val_accuracy100: 0.4649 - 9s/epoch - 13ms/step
Epoch 19/50
653/653 - 9s - loss: 3.0817 - accuracy100: 0.4663 - val_loss: 3.1905 - val_accuracy100: 0.4652 - 9s/epoch - 13ms/step
testing model: results/QRTEA/W1/deepOF_L1/h100
Evaluating performance on  test set...
1645/1645 - 9s - 9s/epoch - 5ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0239019
{'0': {'precision': 0.36763061499903604, 'recall': 0.3616896172375858, 'f1-score': 0.3646359186171026, 'support': 105444}, '1': {'precision': 0.5416909826530732, 'recall': 0.6396566396566397, 'f1-score': 0.586611810364024, 'support': 216216}, '2': {'precision': 0.41620120750330936, 'recall': 0.2595198550505813, 'f1-score': 0.3196954572790794, 'support': 99345}, 'accuracy': 0.4803363380482417, 'macro avg': {'precision': 0.4418409350518062, 'recall': 0.4202887039816023, 'f1-score': 0.42364772875340195, 'support': 421005}, 'weighted avg': {'precision': 0.46848424373271463, 'recall': 0.4803363380482417, 'f1-score': 0.468031672297763, 'support': 421005}}
[[ 38138  59109   8197]
 [ 49945 138304  27967]
 [ 15657  57906  25782]]
Evaluating performance on  train set...
653/653 - 4s - 4s/epoch - 5ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0574578
{'0': {'precision': 0.46765230947172565, 'recall': 0.3617145413174119, 'f1-score': 0.40791753481741416, 'support': 51419}, '1': {'precision': 0.420698671790656, 'recall': 0.6579660754395477, 'f1-score': 0.5132372309960246, 'support': 64555}, '2': {'precision': 0.4687213565536205, 'recall': 0.2409115891959799, 'f1-score': 0.3182501815164402, 'support': 50944}, 'accuracy': 0.4394193556117375, 'macro avg': {'precision': 0.4523574459386674, 'recall': 0.4201974019843131, 'f1-score': 0.413134982443293, 'support': 166918}, 'weighted avg': {'precision': 0.4498194181960011, 'recall': 0.4394193556117375, 'f1-score': 0.4212827760750699, 'support': 166918}}
[[18599 27566  5254]
 [13423 42475  8657]
 [ 7749 30922 12273]]
Evaluating performance on  val set...
181/181 - 1s - 1s/epoch - 6ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0384635
{'0': {'precision': 0.4670592565329407, 'recall': 0.35806997742663654, 'f1-score': 0.4053665548634403, 'support': 14176}, '1': {'precision': 0.44812931347620777, 'recall': 0.6486671223513328, 'f1-score': 0.5300650926980172, 'support': 19019}, '2': {'precision': 0.48035985808413584, 'recall': 0.28949980908743794, 'f1-score': 0.36127126316291036, 'support': 13095}, 'accuracy': 0.4580686973428386, 'macro avg': {'precision': 0.4651828093644281, 'recall': 0.4320789696218024, 'f1-score': 0.43223430357478926, 'support': 46290}, 'weighted avg': {'precision': 0.46304419475538394, 'recall': 0.4580686973428386, 'f1-score': 0.44412684102151717, 'support': 46290}}
[[ 5076  7818  1282]
 [ 3863 12337  2819]
 [ 1929  7375  3791]]
training model: results/QRTEA/W1/deepOF_L1/h200
Epoch 1/50
653/653 - 11s - loss: 3.2890 - accuracy200: 0.3819 - val_loss: 3.2880 - val_accuracy200: 0.3687 - 11s/epoch - 17ms/step
Epoch 2/50
653/653 - 9s - loss: 3.2568 - accuracy200: 0.3983 - val_loss: 3.2600 - val_accuracy200: 0.3804 - 9s/epoch - 13ms/step
Epoch 3/50
653/653 - 9s - loss: 3.2440 - accuracy200: 0.4038 - val_loss: 3.2399 - val_accuracy200: 0.3932 - 9s/epoch - 13ms/step
Epoch 4/50
653/653 - 9s - loss: 3.2365 - accuracy200: 0.4057 - val_loss: 3.2396 - val_accuracy200: 0.3951 - 9s/epoch - 13ms/step
Epoch 5/50
653/653 - 9s - loss: 3.2323 - accuracy200: 0.4081 - val_loss: 3.2282 - val_accuracy200: 0.4012 - 9s/epoch - 13ms/step
Epoch 6/50
653/653 - 9s - loss: 3.2275 - accuracy200: 0.4101 - val_loss: 3.2259 - val_accuracy200: 0.4027 - 9s/epoch - 13ms/step
Epoch 7/50
653/653 - 9s - loss: 3.2235 - accuracy200: 0.4106 - val_loss: 3.2266 - val_accuracy200: 0.4041 - 9s/epoch - 13ms/step
Epoch 8/50
653/653 - 9s - loss: 3.2205 - accuracy200: 0.4116 - val_loss: 3.2237 - val_accuracy200: 0.4038 - 9s/epoch - 13ms/step
Epoch 9/50
653/653 - 9s - loss: 3.2180 - accuracy200: 0.4122 - val_loss: 3.2227 - val_accuracy200: 0.4032 - 9s/epoch - 13ms/step
Epoch 10/50
653/653 - 9s - loss: 3.2139 - accuracy200: 0.4138 - val_loss: 3.2259 - val_accuracy200: 0.4017 - 9s/epoch - 13ms/step
Epoch 11/50
653/653 - 9s - loss: 3.2108 - accuracy200: 0.4164 - val_loss: 3.2236 - val_accuracy200: 0.4015 - 9s/epoch - 13ms/step
Epoch 12/50
653/653 - 8s - loss: 3.2076 - accuracy200: 0.4190 - val_loss: 3.2264 - val_accuracy200: 0.3992 - 8s/epoch - 13ms/step
Epoch 13/50
653/653 - 9s - loss: 3.2050 - accuracy200: 0.4188 - val_loss: 3.2243 - val_accuracy200: 0.4006 - 9s/epoch - 13ms/step
Epoch 14/50
653/653 - 9s - loss: 3.2012 - accuracy200: 0.4218 - val_loss: 3.2271 - val_accuracy200: 0.4008 - 9s/epoch - 13ms/step
Epoch 15/50
653/653 - 9s - loss: 3.1980 - accuracy200: 0.4229 - val_loss: 3.2256 - val_accuracy200: 0.4006 - 9s/epoch - 13ms/step
Epoch 16/50
653/653 - 9s - loss: 3.1940 - accuracy200: 0.4246 - val_loss: 3.2293 - val_accuracy200: 0.3988 - 9s/epoch - 13ms/step
Epoch 17/50
653/653 - 9s - loss: 3.1909 - accuracy200: 0.4275 - val_loss: 3.2280 - val_accuracy200: 0.3994 - 9s/epoch - 13ms/step
Epoch 18/50
653/653 - 9s - loss: 3.1889 - accuracy200: 0.4283 - val_loss: 3.2335 - val_accuracy200: 0.3939 - 9s/epoch - 13ms/step
Epoch 19/50
653/653 - 9s - loss: 3.1862 - accuracy200: 0.4291 - val_loss: 3.2308 - val_accuracy200: 0.3992 - 9s/epoch - 13ms/step
testing model: results/QRTEA/W1/deepOF_L1/h200
Evaluating performance on  test set...
1645/1645 - 11s - 11s/epoch - 7ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0773853
{'0': {'precision': 0.38954715870558276, 'recall': 0.4592368554037848, 'f1-score': 0.42153105907194904, 'support': 132583}, '1': {'precision': 0.4055180186931576, 'recall': 0.4103721500248747, 'f1-score': 0.40793064455333583, 'support': 164826}, '2': {'precision': 0.4149575093969603, 'recall': 0.328699957927441, 'f1-score': 0.36682618510158016, 'support': 123596}, 'accuracy': 0.40178382679540625, 'macro avg': {'precision': 0.4033408955985669, 'recall': 0.3994363211187002, 'f1-score': 0.3987626295756217, 'support': 421005}, 'weighted avg': {'precision': 0.40325965777890377, 'recall': 0.40178382679540625, 'f1-score': 0.40014650181802885, 'support': 421005}}
[[60887 50190 21506]
 [61414 67640 35772]
 [34001 48969 40626]]
Evaluating performance on  train set...
653/653 - 4s - 4s/epoch - 5ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0752727
{'0': {'precision': 0.44479164935259213, 'recall': 0.4590602645257578, 'f1-score': 0.45181333153238334, 'support': 58293}, '1': {'precision': 0.33768018665899574, 'recall': 0.4035908700219654, 'f1-score': 0.3677052789113278, 'support': 52355}, '2': {'precision': 0.44238473551979357, 'recall': 0.34734316687400035, 'f1-score': 0.38914495624732454, 'support': 56270}, 'accuracy': 0.40400076684359987, 'macro avg': {'precision': 0.40828552384379385, 'recall': 0.4033314338072412, 'f1-score': 0.40288785556367857, 'support': 166918}, 'weighted avg': {'precision': 0.4103839900786085, 'recall': 0.40400076684359987, 'f1-score': 0.404306013134933, 'support': 166918}}
[[26760 20076 11457]
 [18046 21130 13179]
 [15357 21368 19545]]
Evaluating performance on  val set...
181/181 - 1s - 1s/epoch - 6ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0743289
{'0': {'precision': 0.46023091725465043, 'recall': 0.42871653919694075, 'f1-score': 0.443915114768298, 'support': 16736}, '1': {'precision': 0.32619909998902424, 'recall': 0.4159552134359692, 'f1-score': 0.36564960629921256, 'support': 14290}, '2': {'precision': 0.4491905754127264, 'recall': 0.3672038784067086, 'f1-score': 0.4040804556268474, 'support': 15264}, 'accuracy': 0.4044934111039101, 'macro avg': {'precision': 0.411873530885467, 'recall': 0.4039585436798729, 'f1-score': 0.4045483922314526, 'support': 46290}, 'weighted avg': {'precision': 0.4152139709033666, 'recall': 0.4044934111039101, 'f1-score': 0.40661871482968637, 'support': 46290}}
[[7175 6465 3096]
 [4569 5944 3777]
 [3846 5813 5605]]
training model: results/QRTEA/W1/deepOF_L1/h300
Epoch 1/50
653/653 - 11s - loss: 3.3047 - accuracy300: 0.3645 - val_loss: 3.2976 - val_accuracy300: 0.3520 - 11s/epoch - 17ms/step
Epoch 2/50
653/653 - 9s - loss: 3.2766 - accuracy300: 0.3747 - val_loss: 3.2782 - val_accuracy300: 0.3608 - 9s/epoch - 14ms/step
Epoch 3/50
653/653 - 9s - loss: 3.2675 - accuracy300: 0.3779 - val_loss: 3.2674 - val_accuracy300: 0.3744 - 9s/epoch - 14ms/step
Epoch 4/50
653/653 - 9s - loss: 3.2619 - accuracy300: 0.3795 - val_loss: 3.2602 - val_accuracy300: 0.3850 - 9s/epoch - 14ms/step
Epoch 5/50
653/653 - 9s - loss: 3.2574 - accuracy300: 0.3817 - val_loss: 3.2576 - val_accuracy300: 0.3864 - 9s/epoch - 13ms/step
Epoch 6/50
653/653 - 9s - loss: 3.2545 - accuracy300: 0.3837 - val_loss: 3.2528 - val_accuracy300: 0.3905 - 9s/epoch - 13ms/step
Epoch 7/50
653/653 - 9s - loss: 3.2522 - accuracy300: 0.3842 - val_loss: 3.2534 - val_accuracy300: 0.3924 - 9s/epoch - 13ms/step
Epoch 8/50
653/653 - 9s - loss: 3.2496 - accuracy300: 0.3855 - val_loss: 3.2500 - val_accuracy300: 0.3946 - 9s/epoch - 13ms/step
Epoch 9/50
653/653 - 9s - loss: 3.2486 - accuracy300: 0.3861 - val_loss: 3.2503 - val_accuracy300: 0.3928 - 9s/epoch - 13ms/step
Epoch 10/50
653/653 - 9s - loss: 3.2462 - accuracy300: 0.3860 - val_loss: 3.2500 - val_accuracy300: 0.3935 - 9s/epoch - 13ms/step
Epoch 11/50
653/653 - 9s - loss: 3.2435 - accuracy300: 0.3893 - val_loss: 3.2496 - val_accuracy300: 0.3955 - 9s/epoch - 13ms/step
Epoch 12/50
653/653 - 9s - loss: 3.2426 - accuracy300: 0.3902 - val_loss: 3.2482 - val_accuracy300: 0.3955 - 9s/epoch - 13ms/step
Epoch 13/50
653/653 - 9s - loss: 3.2401 - accuracy300: 0.3917 - val_loss: 3.2484 - val_accuracy300: 0.3929 - 9s/epoch - 13ms/step
Epoch 14/50
653/653 - 9s - loss: 3.2385 - accuracy300: 0.3919 - val_loss: 3.2463 - val_accuracy300: 0.3968 - 9s/epoch - 13ms/step
Epoch 15/50
653/653 - 9s - loss: 3.2367 - accuracy300: 0.3940 - val_loss: 3.2481 - val_accuracy300: 0.3927 - 9s/epoch - 13ms/step
Epoch 16/50
653/653 - 9s - loss: 3.2350 - accuracy300: 0.3940 - val_loss: 3.2458 - val_accuracy300: 0.3957 - 9s/epoch - 13ms/step
Epoch 17/50
653/653 - 9s - loss: 3.2330 - accuracy300: 0.3948 - val_loss: 3.2454 - val_accuracy300: 0.3965 - 9s/epoch - 13ms/step
Epoch 18/50
653/653 - 9s - loss: 3.2311 - accuracy300: 0.3977 - val_loss: 3.2473 - val_accuracy300: 0.3922 - 9s/epoch - 13ms/step
Epoch 19/50
653/653 - 9s - loss: 3.2297 - accuracy300: 0.3976 - val_loss: 3.2462 - val_accuracy300: 0.3941 - 9s/epoch - 13ms/step
Epoch 20/50
653/653 - 9s - loss: 3.2274 - accuracy300: 0.3985 - val_loss: 3.2487 - val_accuracy300: 0.3933 - 9s/epoch - 13ms/step
Epoch 21/50
653/653 - 9s - loss: 3.2261 - accuracy300: 0.4003 - val_loss: 3.2483 - val_accuracy300: 0.3957 - 9s/epoch - 13ms/step
Epoch 22/50
653/653 - 9s - loss: 3.2239 - accuracy300: 0.4020 - val_loss: 3.2472 - val_accuracy300: 0.3913 - 9s/epoch - 13ms/step
Epoch 23/50
653/653 - 9s - loss: 3.2216 - accuracy300: 0.4029 - val_loss: 3.2491 - val_accuracy300: 0.3909 - 9s/epoch - 13ms/step
Epoch 24/50
653/653 - 9s - loss: 3.2180 - accuracy300: 0.4046 - val_loss: 3.2509 - val_accuracy300: 0.3927 - 9s/epoch - 13ms/step
Epoch 25/50
653/653 - 9s - loss: 3.2165 - accuracy300: 0.4051 - val_loss: 3.2525 - val_accuracy300: 0.3902 - 9s/epoch - 14ms/step
Epoch 26/50
653/653 - 9s - loss: 3.2139 - accuracy300: 0.4067 - val_loss: 3.2596 - val_accuracy300: 0.3845 - 9s/epoch - 13ms/step
Epoch 27/50
653/653 - 9s - loss: 3.2100 - accuracy300: 0.4092 - val_loss: 3.2623 - val_accuracy300: 0.3845 - 9s/epoch - 13ms/step
testing model: results/QRTEA/W1/deepOF_L1/h300
Evaluating performance on  test set...
1645/1645 - 9s - 9s/epoch - 6ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0878386
{'0': {'precision': 0.36802348048506706, 'recall': 0.5926875347286534, 'f1-score': 0.4540864545462286, 'support': 134975}, '1': {'precision': 0.39184230334964243, 'recall': 0.0511901762063095, 'f1-score': 0.09055081728391035, 'support': 162707}, '2': {'precision': 0.35083371258437196, 'recall': 0.5188326589525069, 'f1-score': 0.41860647693817465, 'support': 123323}, 'accuracy': 0.36177955131174216, 'macro avg': {'precision': 0.37023316547302715, 'recall': 0.38757012329582324, 'f1-score': 0.32108124958943784, 'support': 421005}, 'weighted avg': {'precision': 0.37219349144695363, 'recall': 0.36177955131174216, 'f1-score': 0.3031968209062527, 'support': 421005}}
[[79998  6769 48208]
 [84193  8329 70185]
 [53181  6158 63984]]
Evaluating performance on  train set...
653/653 - 4s - 4s/epoch - 6ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.081516
{'0': {'precision': 0.39899574623079626, 'recall': 0.5413533834586466, 'f1-score': 0.4593989410698639, 'support': 56658}, '1': {'precision': 0.3575479930191972, 'recall': 0.05818659471740983, 'f1-score': 0.10008549096238398, 'support': 56336}, '2': {'precision': 0.3829642543615614, 'recall': 0.5743824642088866, 'f1-score': 0.45953665032158514, 'support': 53924}, 'accuracy': 0.38895146119651564, 'macro avg': {'precision': 0.3798359978705183, 'recall': 0.391307480794981, 'f1-score': 0.33967369411794435, 'support': 166918}, 'weighted avg': {'precision': 0.37982775480695186, 'recall': 0.38895146119651564, 'f1-score': 0.3381726102273833, 'support': 166918}}
[[30672  3149 22837]
 [25991  3278 27067]
 [20210  2741 30973]]
Evaluating performance on  val set...
181/181 - 1s - 1s/epoch - 6ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0823758
{'0': {'precision': 0.41222498389026974, 'recall': 0.553317681947362, 'f1-score': 0.47246254484068373, 'support': 16186}, '1': {'precision': 0.34514767932489454, 'recall': 0.05387604557729039, 'f1-score': 0.09320344100723522, 'support': 15183}, '2': {'precision': 0.37861584211949173, 'recall': 0.5631660076402386, 'f1-score': 0.45280883739727873, 'support': 14921}, 'accuracy': 0.39267660401814647, 'macro avg': {'precision': 0.378662835111552, 'recall': 0.39011991172163035, 'f1-score': 0.3394916077483992, 'support': 46290}, 'weighted avg': {'precision': 0.3793903172327224, 'recall': 0.39267660401814647, 'f1-score': 0.341731416254244, 'support': 46290}}
[[8956  819 6411]
 [6985  818 7380]
 [5785  733 8403]]
training model: results/QRTEA/W1/deepOF_L1/h500
Epoch 1/50
653/653 - 11s - loss: 3.2871 - accuracy500: 0.3901 - val_loss: 3.3319 - val_accuracy500: 0.3152 - 11s/epoch - 17ms/step
Epoch 2/50
653/653 - 9s - loss: 3.2737 - accuracy500: 0.3907 - val_loss: 3.3112 - val_accuracy500: 0.3391 - 9s/epoch - 14ms/step
Epoch 3/50
653/653 - 9s - loss: 3.2703 - accuracy500: 0.3891 - val_loss: 3.2689 - val_accuracy500: 0.4074 - 9s/epoch - 13ms/step
Epoch 4/50
653/653 - 9s - loss: 3.2767 - accuracy500: 0.3821 - val_loss: 3.2414 - val_accuracy500: 0.4035 - 9s/epoch - 13ms/step
Epoch 5/50
653/653 - 9s - loss: 3.2760 - accuracy500: 0.3775 - val_loss: 3.2393 - val_accuracy500: 0.4025 - 9s/epoch - 14ms/step
Epoch 6/50
653/653 - 9s - loss: 3.2717 - accuracy500: 0.3784 - val_loss: 3.2409 - val_accuracy500: 0.4102 - 9s/epoch - 13ms/step
Epoch 7/50
653/653 - 9s - loss: 3.2721 - accuracy500: 0.3778 - val_loss: 3.2370 - val_accuracy500: 0.4122 - 9s/epoch - 13ms/step
Epoch 8/50
653/653 - 9s - loss: 3.2699 - accuracy500: 0.3767 - val_loss: 3.2366 - val_accuracy500: 0.4131 - 9s/epoch - 13ms/step
Epoch 9/50
653/653 - 9s - loss: 3.2684 - accuracy500: 0.3786 - val_loss: 3.2360 - val_accuracy500: 0.4143 - 9s/epoch - 13ms/step
Epoch 10/50
653/653 - 9s - loss: 3.2673 - accuracy500: 0.3784 - val_loss: 3.2372 - val_accuracy500: 0.4148 - 9s/epoch - 13ms/step
Epoch 11/50
653/653 - 9s - loss: 3.2656 - accuracy500: 0.3791 - val_loss: 3.2356 - val_accuracy500: 0.4171 - 9s/epoch - 13ms/step
Epoch 12/50
653/653 - 9s - loss: 3.2632 - accuracy500: 0.3808 - val_loss: 3.2377 - val_accuracy500: 0.4168 - 9s/epoch - 13ms/step
Epoch 13/50
653/653 - 9s - loss: 3.2617 - accuracy500: 0.3815 - val_loss: 3.2373 - val_accuracy500: 0.4178 - 9s/epoch - 13ms/step
Epoch 14/50
653/653 - 9s - loss: 3.2599 - accuracy500: 0.3829 - val_loss: 3.2384 - val_accuracy500: 0.4153 - 9s/epoch - 14ms/step
Epoch 15/50
653/653 - 9s - loss: 3.2589 - accuracy500: 0.3838 - val_loss: 3.2415 - val_accuracy500: 0.4146 - 9s/epoch - 13ms/step
Epoch 16/50
653/653 - 9s - loss: 3.2576 - accuracy500: 0.3847 - val_loss: 3.2403 - val_accuracy500: 0.4185 - 9s/epoch - 13ms/step
Epoch 17/50
653/653 - 9s - loss: 3.2571 - accuracy500: 0.3852 - val_loss: 3.2366 - val_accuracy500: 0.4162 - 9s/epoch - 13ms/step
Epoch 18/50
653/653 - 9s - loss: 3.2550 - accuracy500: 0.3868 - val_loss: 3.2381 - val_accuracy500: 0.4161 - 9s/epoch - 13ms/step
Epoch 19/50
653/653 - 9s - loss: 3.2547 - accuracy500: 0.3879 - val_loss: 3.2366 - val_accuracy500: 0.4178 - 9s/epoch - 13ms/step
Epoch 20/50
653/653 - 9s - loss: 3.2534 - accuracy500: 0.3883 - val_loss: 3.2380 - val_accuracy500: 0.4169 - 9s/epoch - 13ms/step
Epoch 21/50
653/653 - 8s - loss: 3.2511 - accuracy500: 0.3904 - val_loss: 3.2392 - val_accuracy500: 0.4159 - 8s/epoch - 13ms/step
testing model: results/QRTEA/W1/deepOF_L1/h500
Evaluating performance on  test set...
1645/1645 - 9s - 9s/epoch - 6ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0917203
{'0': {'precision': 0.3988863325664366, 'recall': 0.6924858019410981, 'f1-score': 0.5061941993145243, 'support': 155479}, '1': {'precision': 0.35600762873490144, 'recall': 0.004390400702464112, 'f1-score': 0.008673832904804684, 'support': 127551}, '2': {'precision': 0.37392066241731486, 'recall': 0.40518934589599565, 'f1-score': 0.3889275378450579, 'support': 137975}, 'accuracy': 0.38985997791000104, 'macro avg': {'precision': 0.376271541239551, 'recall': 0.3673551828465193, 'f1-score': 0.3012651900214623, 'support': 421005}, 'weighted avg': {'precision': 0.3777135201503341, 'recall': 0.38985997791000104, 'f1-score': 0.31702996641426, 'support': 421005}}
[[107667    556  47256]
 [ 80640    560  46351]
 [ 81612    457  55906]]
Evaluating performance on  train set...
653/653 - 4s - 4s/epoch - 6ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1007562
{'0': {'precision': 0.37508386021264917, 'recall': 0.6356698651139554, 'f1-score': 0.4717855613161411, 'support': 58049}, '1': {'precision': 0.3427362482369535, 'recall': 0.0043355695118469885, 'f1-score': 0.008562820445055236, 'support': 56048}, '2': {'precision': 0.35464610576285177, 'recall': 0.4554249256924329, 'f1-score': 0.3987667009249743, 'support': 52821}, 'accuracy': 0.36664110521333826, 'macro avg': {'precision': 0.3574887380708181, 'recall': 0.3651434534394118, 'f1-score': 0.2930383608953902, 'support': 166918}, 'weighted avg': {'precision': 0.3577546231992262, 'recall': 0.36664110521333826, 'f1-score': 0.29313713870704894, 'support': 166918}}
[[36900   295 20854]
 [32884   243 22921]
 [28594   171 24056]]
Evaluating performance on  val set...
181/181 - 1s - 1s/epoch - 6ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.078568
{'0': {'precision': 0.42492643364673793, 'recall': 0.6573950699533644, 'f1-score': 0.5161951262042809, 'support': 18012}, '1': {'precision': 0.2830188679245283, 'recall': 0.0049987503124218945, 'f1-score': 0.009823986901350798, 'support': 12003}, '2': {'precision': 0.40896112453327477, 'recall': 0.45763440860215054, 'f1-score': 0.43193087250268214, 'support': 16275}, 'accuracy': 0.4179952473536401, 'macro avg': {'precision': 0.37230214203484696, 'recall': 0.37334274295597897, 'f1-score': 0.3193166618694379, 'support': 46290}, 'weighted avg': {'precision': 0.382516584496051, 'recall': 0.4179952473536401, 'f1-score': 0.35526677204470886, 'support': 46290}}
[[11841    78  6093]
 [ 7272    60  4671]
 [ 8753    74  7448]]
training model: results/QRTEA/W1/deepOF_L1/h1000
Epoch 1/50
653/653 - 11s - loss: 3.2921 - accuracy1000: 0.3917 - val_loss: 3.1916 - val_accuracy1000: 0.3899 - 11s/epoch - 17ms/step
Epoch 2/50
653/653 - 9s - loss: 3.2625 - accuracy1000: 0.3986 - val_loss: 3.2530 - val_accuracy1000: 0.3730 - 9s/epoch - 14ms/step
Epoch 3/50
653/653 - 9s - loss: 3.2777 - accuracy1000: 0.3864 - val_loss: 3.2053 - val_accuracy1000: 0.3817 - 9s/epoch - 14ms/step
Epoch 4/50
653/653 - 9s - loss: 3.2792 - accuracy1000: 0.3784 - val_loss: 3.1893 - val_accuracy1000: 0.3793 - 9s/epoch - 14ms/step
Epoch 5/50
653/653 - 9s - loss: 3.2879 - accuracy1000: 0.3749 - val_loss: 3.1787 - val_accuracy1000: 0.3846 - 9s/epoch - 14ms/step
Epoch 6/50
653/653 - 9s - loss: 3.2855 - accuracy1000: 0.3733 - val_loss: 3.1781 - val_accuracy1000: 0.3884 - 9s/epoch - 13ms/step
Epoch 7/50
653/653 - 9s - loss: 3.2825 - accuracy1000: 0.3732 - val_loss: 3.1748 - val_accuracy1000: 0.3911 - 9s/epoch - 13ms/step
Epoch 8/50
653/653 - 9s - loss: 3.2766 - accuracy1000: 0.3731 - val_loss: 3.1723 - val_accuracy1000: 0.3903 - 9s/epoch - 13ms/step
Epoch 9/50
653/653 - 9s - loss: 3.2665 - accuracy1000: 0.3820 - val_loss: 3.1722 - val_accuracy1000: 0.3872 - 9s/epoch - 13ms/step
Epoch 10/50
653/653 - 9s - loss: 3.2584 - accuracy1000: 0.3865 - val_loss: 3.1701 - val_accuracy1000: 0.3869 - 9s/epoch - 13ms/step
Epoch 11/50
653/653 - 9s - loss: 3.2518 - accuracy1000: 0.3906 - val_loss: 3.1654 - val_accuracy1000: 0.3886 - 9s/epoch - 13ms/step
Epoch 12/50
653/653 - 9s - loss: 3.2381 - accuracy1000: 0.4004 - val_loss: 3.1686 - val_accuracy1000: 0.3863 - 9s/epoch - 13ms/step
Epoch 13/50
653/653 - 9s - loss: 3.2229 - accuracy1000: 0.4121 - val_loss: 3.1684 - val_accuracy1000: 0.3877 - 9s/epoch - 13ms/step
Epoch 14/50
653/653 - 9s - loss: 3.2190 - accuracy1000: 0.4120 - val_loss: 3.1738 - val_accuracy1000: 0.3882 - 9s/epoch - 13ms/step
Epoch 15/50
653/653 - 9s - loss: 3.2094 - accuracy1000: 0.4221 - val_loss: 3.1682 - val_accuracy1000: 0.3878 - 9s/epoch - 13ms/step
Epoch 16/50
653/653 - 9s - loss: 3.1889 - accuracy1000: 0.4321 - val_loss: 3.1700 - val_accuracy1000: 0.3871 - 9s/epoch - 13ms/step
Epoch 17/50
653/653 - 9s - loss: 3.1838 - accuracy1000: 0.4342 - val_loss: 3.1670 - val_accuracy1000: 0.3934 - 9s/epoch - 13ms/step
Epoch 18/50
653/653 - 9s - loss: 3.1811 - accuracy1000: 0.4343 - val_loss: 3.1675 - val_accuracy1000: 0.3947 - 9s/epoch - 13ms/step
Epoch 19/50
653/653 - 9s - loss: 3.1794 - accuracy1000: 0.4357 - val_loss: 3.1659 - val_accuracy1000: 0.3989 - 9s/epoch - 13ms/step
Epoch 20/50
653/653 - 9s - loss: 3.1766 - accuracy1000: 0.4362 - val_loss: 3.1688 - val_accuracy1000: 0.3976 - 9s/epoch - 13ms/step
Epoch 21/50
653/653 - 9s - loss: 3.1753 - accuracy1000: 0.4371 - val_loss: 3.1644 - val_accuracy1000: 0.4016 - 9s/epoch - 13ms/step
Epoch 22/50
653/653 - 9s - loss: 3.1742 - accuracy1000: 0.4366 - val_loss: 3.1665 - val_accuracy1000: 0.4001 - 9s/epoch - 13ms/step
Epoch 23/50
653/653 - 9s - loss: 3.1779 - accuracy1000: 0.4357 - val_loss: 3.1670 - val_accuracy1000: 0.4008 - 9s/epoch - 13ms/step
Epoch 24/50
653/653 - 9s - loss: 3.1747 - accuracy1000: 0.4366 - val_loss: 3.1672 - val_accuracy1000: 0.4014 - 9s/epoch - 13ms/step
Epoch 25/50
653/653 - 9s - loss: 3.1743 - accuracy1000: 0.4376 - val_loss: 3.1679 - val_accuracy1000: 0.4013 - 9s/epoch - 13ms/step
Epoch 26/50
653/653 - 9s - loss: 3.1722 - accuracy1000: 0.4394 - val_loss: 3.1675 - val_accuracy1000: 0.4037 - 9s/epoch - 13ms/step
Epoch 27/50
653/653 - 9s - loss: 3.1690 - accuracy1000: 0.4396 - val_loss: 3.1662 - val_accuracy1000: 0.4016 - 9s/epoch - 13ms/step
Epoch 28/50
653/653 - 9s - loss: 3.1688 - accuracy1000: 0.4392 - val_loss: 3.1632 - val_accuracy1000: 0.4040 - 9s/epoch - 13ms/step
Epoch 29/50
653/653 - 9s - loss: 3.1650 - accuracy1000: 0.4410 - val_loss: 3.1654 - val_accuracy1000: 0.4010 - 9s/epoch - 13ms/step
Epoch 30/50
653/653 - 9s - loss: 3.1634 - accuracy1000: 0.4396 - val_loss: 3.1625 - val_accuracy1000: 0.4018 - 9s/epoch - 13ms/step
Epoch 31/50
653/653 - 9s - loss: 3.1608 - accuracy1000: 0.4424 - val_loss: 3.1642 - val_accuracy1000: 0.4040 - 9s/epoch - 13ms/step
Epoch 32/50
653/653 - 9s - loss: 3.1608 - accuracy1000: 0.4429 - val_loss: 3.1629 - val_accuracy1000: 0.4088 - 9s/epoch - 13ms/step
Epoch 33/50
653/653 - 9s - loss: 3.1562 - accuracy1000: 0.4430 - val_loss: 3.1652 - val_accuracy1000: 0.4135 - 9s/epoch - 13ms/step
Epoch 34/50
653/653 - 9s - loss: 3.1554 - accuracy1000: 0.4436 - val_loss: 3.1656 - val_accuracy1000: 0.4126 - 9s/epoch - 13ms/step
Epoch 35/50
653/653 - 9s - loss: 3.1536 - accuracy1000: 0.4452 - val_loss: 3.1691 - val_accuracy1000: 0.4033 - 9s/epoch - 13ms/step
Epoch 36/50
653/653 - 9s - loss: 3.1541 - accuracy1000: 0.4442 - val_loss: 3.1668 - val_accuracy1000: 0.4077 - 9s/epoch - 13ms/step
Epoch 37/50
653/653 - 9s - loss: 3.1489 - accuracy1000: 0.4462 - val_loss: 3.1746 - val_accuracy1000: 0.3962 - 9s/epoch - 13ms/step
Epoch 38/50
653/653 - 9s - loss: 3.1494 - accuracy1000: 0.4455 - val_loss: 3.1768 - val_accuracy1000: 0.3970 - 9s/epoch - 13ms/step
Epoch 39/50
653/653 - 9s - loss: 3.1471 - accuracy1000: 0.4461 - val_loss: 3.2062 - val_accuracy1000: 0.3783 - 9s/epoch - 13ms/step
Epoch 40/50
653/653 - 9s - loss: 3.1472 - accuracy1000: 0.4463 - val_loss: 3.1906 - val_accuracy1000: 0.3880 - 9s/epoch - 13ms/step
testing model: results/QRTEA/W1/deepOF_L1/h1000
Evaluating performance on  test set...
1645/1645 - 10s - 10s/epoch - 6ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0582467
{'0': {'precision': 0.4671938509454314, 'recall': 0.3726652155580121, 'f1-score': 0.41460979374744444, 'support': 175498}, '1': {'precision': 0.2207329842931937, 'recall': 0.012356099505287097, 'f1-score': 0.02340220033970936, 'support': 85302}, '2': {'precision': 0.40836443540242034, 'recall': 0.7041415686152117, 'f1-score': 0.5169345119442038, 'support': 160205}, 'accuracy': 0.4257977933753756, 'macro avg': {'precision': 0.36543042354701516, 'recall': 0.3630542945595036, 'f1-score': 0.3183155020104525, 'support': 421005}, 'weighted avg': {'precision': 0.3948707874088053, 'recall': 0.4257977933753756, 'f1-score': 0.37428281745463365, 'support': 421005}}
[[ 65402   2154 107942]
 [ 28756   1054  55492]
 [ 45831   1567 112807]]
Evaluating performance on  train set...
653/653 - 4s - 4s/epoch - 6ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1125991
{'0': {'precision': 0.3844153531035711, 'recall': 0.3611129701512515, 'f1-score': 0.37239998964740795, 'support': 59768}, '1': {'precision': 0.3784090909090909, 'recall': 0.018629370629370628, 'f1-score': 0.035510530525193276, 'support': 53625}, '2': {'precision': 0.3362248342319181, 'recall': 0.6792526856609061, 'f1-score': 0.4498014326541217, 'support': 53525}, 'accuracy': 0.3531015229034616, 'macro avg': {'precision': 0.3663497594148601, 'recall': 0.35299834214717607, 'f1-score': 0.28590398427557434, 'support': 166918}, 'weighted avg': {'precision': 0.36703266619871827, 'recall': 0.3531015229034616, 'f1-score': 0.2889890632734135, 'support': 166918}}
[[21583  1006 37179]
 [18029   999 34597]
 [16533   635 36357]]
Evaluating performance on  val set...
181/181 - 1s - 1s/epoch - 6ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.059375
{'0': {'precision': 0.4513878796686528, 'recall': 0.3118004316618983, 'f1-score': 0.36882885557369743, 'support': 19923}, '1': {'precision': 0.19318181818181818, 'recall': 0.013201686265808742, 'f1-score': 0.02471443406022845, 'support': 9014}, '2': {'precision': 0.3846202055653046, 'recall': 0.7073128565665879, 'f1-score': 0.4982847863594844, 'support': 17353}, 'accuracy': 0.40192266148196154, 'macro avg': {'precision': 0.3430633011385918, 'recall': 0.3441049914980983, 'f1-score': 0.2972760253311368, 'support': 46290}, 'weighted avg': {'precision': 0.37607811758272214, 'recall': 0.40192266148196154, 'f1-score': 0.3503497320352086, 'support': 46290}}
[[ 6212   241 13470]
 [ 2727   119  6168]
 [ 4823   256 12274]]
training model: results/QRTEA/W1/deepLOB_L2/h10
Epoch 1/50
653/653 - 28s - loss: 3.1492 - accuracy10: 0.4013 - val_loss: 2.8879 - val_accuracy10: 0.5609 - 28s/epoch - 43ms/step
Epoch 2/50
653/653 - 26s - loss: 2.9663 - accuracy10: 0.4509 - val_loss: 2.7329 - val_accuracy10: 0.4122 - 26s/epoch - 39ms/step
Epoch 3/50
653/653 - 25s - loss: 2.8528 - accuracy10: 0.4950 - val_loss: 2.7624 - val_accuracy10: 0.4059 - 25s/epoch - 39ms/step
Epoch 4/50
653/653 - 26s - loss: 2.7648 - accuracy10: 0.5228 - val_loss: 2.7926 - val_accuracy10: 0.3859 - 26s/epoch - 39ms/step
Epoch 5/50
653/653 - 26s - loss: 2.7070 - accuracy10: 0.5386 - val_loss: 2.8547 - val_accuracy10: 0.3597 - 26s/epoch - 39ms/step
Epoch 6/50
653/653 - 26s - loss: 2.6488 - accuracy10: 0.5637 - val_loss: 2.8202 - val_accuracy10: 0.4160 - 26s/epoch - 39ms/step
Epoch 7/50
653/653 - 26s - loss: 2.6011 - accuracy10: 0.5782 - val_loss: 2.8025 - val_accuracy10: 0.3962 - 26s/epoch - 39ms/step
Epoch 8/50
653/653 - 26s - loss: 2.5597 - accuracy10: 0.5926 - val_loss: 2.7616 - val_accuracy10: 0.4291 - 26s/epoch - 39ms/step
Epoch 9/50
653/653 - 26s - loss: 2.5192 - accuracy10: 0.6057 - val_loss: 2.6864 - val_accuracy10: 0.4355 - 26s/epoch - 39ms/step
Epoch 10/50
653/653 - 25s - loss: 2.4853 - accuracy10: 0.6143 - val_loss: 2.6276 - val_accuracy10: 0.4767 - 25s/epoch - 39ms/step
Epoch 11/50
653/653 - 25s - loss: 2.4598 - accuracy10: 0.6201 - val_loss: 2.5662 - val_accuracy10: 0.5077 - 25s/epoch - 39ms/step
Epoch 12/50
653/653 - 25s - loss: 2.4302 - accuracy10: 0.6263 - val_loss: 2.5800 - val_accuracy10: 0.5153 - 25s/epoch - 39ms/step
Epoch 13/50
653/653 - 25s - loss: 2.4108 - accuracy10: 0.6310 - val_loss: 2.5559 - val_accuracy10: 0.5213 - 25s/epoch - 39ms/step
Epoch 14/50
653/653 - 25s - loss: 2.3924 - accuracy10: 0.6353 - val_loss: 2.5644 - val_accuracy10: 0.5149 - 25s/epoch - 39ms/step
Epoch 15/50
653/653 - 25s - loss: 2.3734 - accuracy10: 0.6368 - val_loss: 2.5442 - val_accuracy10: 0.5356 - 25s/epoch - 39ms/step
Epoch 16/50
653/653 - 25s - loss: 2.3579 - accuracy10: 0.6389 - val_loss: 2.5453 - val_accuracy10: 0.5326 - 25s/epoch - 39ms/step
Epoch 17/50
653/653 - 25s - loss: 2.3387 - accuracy10: 0.6402 - val_loss: 2.5110 - val_accuracy10: 0.5409 - 25s/epoch - 39ms/step
Epoch 18/50
653/653 - 26s - loss: 2.3259 - accuracy10: 0.6439 - val_loss: 2.5442 - val_accuracy10: 0.5441 - 26s/epoch - 39ms/step
Epoch 19/50
653/653 - 25s - loss: 2.3182 - accuracy10: 0.6425 - val_loss: 2.5809 - val_accuracy10: 0.5442 - 25s/epoch - 39ms/step
Epoch 20/50
653/653 - 26s - loss: 2.3065 - accuracy10: 0.6439 - val_loss: 2.5727 - val_accuracy10: 0.5079 - 26s/epoch - 39ms/step
Epoch 21/50
653/653 - 25s - loss: 2.2879 - accuracy10: 0.6463 - val_loss: 2.6040 - val_accuracy10: 0.4998 - 25s/epoch - 39ms/step
Epoch 22/50
653/653 - 25s - loss: 2.2747 - accuracy10: 0.6480 - val_loss: 2.6237 - val_accuracy10: 0.5110 - 25s/epoch - 39ms/step
Epoch 23/50
653/653 - 25s - loss: 2.2598 - accuracy10: 0.6507 - val_loss: 2.6580 - val_accuracy10: 0.4823 - 25s/epoch - 38ms/step
Epoch 24/50
653/653 - 25s - loss: 2.2443 - accuracy10: 0.6512 - val_loss: 2.6491 - val_accuracy10: 0.4782 - 25s/epoch - 39ms/step
Epoch 25/50
653/653 - 26s - loss: 2.2285 - accuracy10: 0.6531 - val_loss: 2.6773 - val_accuracy10: 0.5040 - 26s/epoch - 39ms/step
Epoch 26/50
653/653 - 26s - loss: 2.2204 - accuracy10: 0.6514 - val_loss: 2.6680 - val_accuracy10: 0.5070 - 26s/epoch - 39ms/step
Epoch 27/50
653/653 - 26s - loss: 2.2187 - accuracy10: 0.6526 - val_loss: 2.6481 - val_accuracy10: 0.5319 - 26s/epoch - 39ms/step
testing model: results/QRTEA/W1/deepLOB_L2/h10
Evaluating performance on  test set...
1645/1645 - 21s - 21s/epoch - 13ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 1.2897303
{'0': {'precision': 0.14688700334704263, 'recall': 0.6963726322569312, 'f1-score': 0.2426016492342841, 'support': 34157}, '1': {'precision': 0.94828039808036, 'recall': 0.29627614042845074, 'f1-score': 0.4514907080458281, 'support': 352806}, '2': {'precision': 0.15438671924862443, 'recall': 0.6749493347431492, 'f1-score': 0.2512930987347863, 'support': 34047}, 'accuracy': 0.35935963516306024, 'macro avg': {'precision': 0.41651804022534233, 'recall': 0.5558660358095104, 'f1-score': 0.31512848533829946, 'support': 421010}, 'weighted avg': {'precision': 0.819060445425815, 'recall': 0.35935963516306024, 'f1-score': 0.4183533678732931, 'support': 421010}}
[[ 23786   2326   8045]
 [130456 104528 117822]
 [  7692   3375  22980]]
Evaluating performance on  train set...
653/653 - 9s - 9s/epoch - 14ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 1.0323437
{'0': {'precision': 0.24691906887414863, 'recall': 0.6393314301501059, 'f1-score': 0.35624943874998394, 'support': 21718}, '1': {'precision': 0.9087625603902018, 'recall': 0.4742442427122685, 'f1-score': 0.6232440958218214, 'support': 124147}, '2': {'precision': 0.27140616148851804, 'recall': 0.5916971452999572, 'f1-score': 0.37212289584920316, 'support': 21053}, 'accuracy': 0.5105381085323333, 'macro avg': {'precision': 0.4756959302509561, 'recall': 0.5684242727207772, 'f1-score': 0.4505388101403362, 'support': 166918}, 'weighted avg': {'precision': 0.7422605581206875, 'recall': 0.5105381085323333, 'f1-score': 0.556831578386256, 'support': 166918}}
[[13885  2260  5573]
 [37403 58876 27868]
 [ 4945  3651 12457]]
Evaluating performance on  val set...
181/181 - 3s - 3s/epoch - 14ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.95241785
{'0': {'precision': 0.2470881195276729, 'recall': 0.6016037551339722, 'f1-score': 0.3503017879512583, 'support': 5113}, '1': {'precision': 0.9166341463414635, 'recall': 0.5179866030818425, 'f1-score': 0.6619229617626857, 'support': 36277}, '2': {'precision': 0.2408365190015741, 'recall': 0.6557142857142857, 'f1-score': 0.35228331780055916, 'support': 4900}, 'accuracy': 0.5418016850291639, 'macro avg': {'precision': 0.46818626162357013, 'recall': 0.5917682146433668, 'f1-score': 0.4548360225048344, 'support': 46290}, 'weighted avg': {'precision': 0.7711427397943825, 'recall': 0.5418016850291639, 'f1-score': 0.5947258713087594, 'support': 46290}}
[[ 3076   787  1250]
 [ 8608 18791  8878]
 [  765   922  3213]]
training model: results/QRTEA/W1/deepLOB_L2/h20
Epoch 1/50
653/653 - 28s - loss: 3.1486 - accuracy20: 0.4309 - val_loss: 3.1061 - val_accuracy20: 0.5949 - 28s/epoch - 43ms/step
Epoch 2/50
653/653 - 26s - loss: 2.9449 - accuracy20: 0.4633 - val_loss: 2.8550 - val_accuracy20: 0.5108 - 26s/epoch - 40ms/step
Epoch 3/50
653/653 - 26s - loss: 2.8520 - accuracy20: 0.5004 - val_loss: 2.8656 - val_accuracy20: 0.4560 - 26s/epoch - 39ms/step
Epoch 4/50
653/653 - 26s - loss: 2.8040 - accuracy20: 0.5147 - val_loss: 2.8723 - val_accuracy20: 0.4000 - 26s/epoch - 40ms/step
Epoch 5/50
653/653 - 26s - loss: 2.7572 - accuracy20: 0.5303 - val_loss: 2.8693 - val_accuracy20: 0.4267 - 26s/epoch - 39ms/step
Epoch 6/50
653/653 - 26s - loss: 2.7229 - accuracy20: 0.5419 - val_loss: 2.7960 - val_accuracy20: 0.4422 - 26s/epoch - 39ms/step
Epoch 7/50
653/653 - 26s - loss: 2.6848 - accuracy20: 0.5557 - val_loss: 2.8704 - val_accuracy20: 0.4536 - 26s/epoch - 39ms/step
Epoch 8/50
653/653 - 26s - loss: 2.6392 - accuracy20: 0.5701 - val_loss: 2.8737 - val_accuracy20: 0.4210 - 26s/epoch - 39ms/step
Epoch 9/50
653/653 - 26s - loss: 2.6027 - accuracy20: 0.5839 - val_loss: 2.8704 - val_accuracy20: 0.4310 - 26s/epoch - 39ms/step
Epoch 10/50
653/653 - 26s - loss: 2.5675 - accuracy20: 0.5943 - val_loss: 2.8171 - val_accuracy20: 0.4909 - 26s/epoch - 39ms/step
Epoch 11/50
653/653 - 26s - loss: 2.5352 - accuracy20: 0.6016 - val_loss: 2.7596 - val_accuracy20: 0.4981 - 26s/epoch - 40ms/step
Epoch 12/50
653/653 - 26s - loss: 2.5108 - accuracy20: 0.6065 - val_loss: 2.7313 - val_accuracy20: 0.4953 - 26s/epoch - 39ms/step
Epoch 13/50
653/653 - 26s - loss: 2.4814 - accuracy20: 0.6153 - val_loss: 2.7396 - val_accuracy20: 0.4978 - 26s/epoch - 39ms/step
Epoch 14/50
653/653 - 26s - loss: 2.4599 - accuracy20: 0.6214 - val_loss: 2.7273 - val_accuracy20: 0.5208 - 26s/epoch - 39ms/step
Epoch 15/50
653/653 - 26s - loss: 2.4423 - accuracy20: 0.6241 - val_loss: 2.7386 - val_accuracy20: 0.5236 - 26s/epoch - 39ms/step
Epoch 16/50
653/653 - 26s - loss: 2.4181 - accuracy20: 0.6289 - val_loss: 2.7540 - val_accuracy20: 0.5136 - 26s/epoch - 39ms/step
Epoch 17/50
653/653 - 26s - loss: 2.4048 - accuracy20: 0.6294 - val_loss: 2.7531 - val_accuracy20: 0.5209 - 26s/epoch - 39ms/step
Epoch 18/50
653/653 - 26s - loss: 2.3859 - accuracy20: 0.6335 - val_loss: 2.7421 - val_accuracy20: 0.5168 - 26s/epoch - 39ms/step
Epoch 19/50
653/653 - 26s - loss: 2.3686 - accuracy20: 0.6357 - val_loss: 2.8366 - val_accuracy20: 0.5035 - 26s/epoch - 39ms/step
Epoch 20/50
653/653 - 26s - loss: 2.3522 - accuracy20: 0.6404 - val_loss: 2.7918 - val_accuracy20: 0.5223 - 26s/epoch - 39ms/step
Epoch 21/50
653/653 - 26s - loss: 2.3419 - accuracy20: 0.6402 - val_loss: 2.7786 - val_accuracy20: 0.5314 - 26s/epoch - 39ms/step
Epoch 22/50
653/653 - 26s - loss: 2.3245 - accuracy20: 0.6425 - val_loss: 2.7856 - val_accuracy20: 0.5256 - 26s/epoch - 39ms/step
Epoch 23/50
653/653 - 26s - loss: 2.3100 - accuracy20: 0.6440 - val_loss: 2.8203 - val_accuracy20: 0.4973 - 26s/epoch - 39ms/step
Epoch 24/50
653/653 - 25s - loss: 2.2985 - accuracy20: 0.6456 - val_loss: 2.7767 - val_accuracy20: 0.5277 - 25s/epoch - 39ms/step
testing model: results/QRTEA/W1/deepLOB_L2/h20
Evaluating performance on  test set...
1645/1645 - 22s - 22s/epoch - 13ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 1.2513546
{'0': {'precision': 0.1892667074526521, 'recall': 0.6147780935490075, 'f1-score': 0.2894292095044565, 'support': 46799}, '1': {'precision': 0.9115511159854166, 'recall': 0.28126800625588777, 'f1-score': 0.42988942784852596, 'support': 328011}, '2': {'precision': 0.1974896594471529, 'recall': 0.7172294372294372, 'f1-score': 0.3097025039021244, 'support': 46200}, 'accuracy': 0.36618132585924323, 'macro avg': {'precision': 0.43276916096174056, 'recall': 0.5377585123447775, 'f1-score': 0.34300704708503565, 'support': 421010}, 'weighted avg': {'precision': 0.7529044631102056, 'recall': 0.36618132585924323, 'f1-score': 0.4010871817151613, 'support': 421010}}
[[ 28771   4100  13928]
 [115030  92259 120722]
 [  8212   4852  33136]]
Evaluating performance on  train set...
653/653 - 10s - 10s/epoch - 15ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 1.0249252
{'0': {'precision': 0.3103484182685299, 'recall': 0.5253842899450007, 'f1-score': 0.3902017517445438, 'support': 28364}, '1': {'precision': 0.8429128954579423, 'recall': 0.45786762649635104, 'f1-score': 0.5934014543924053, 'support': 110853}, '2': {'precision': 0.3069897420168354, 'recall': 0.6503736327208404, 'f1-score': 0.4170997951080603, 'support': 27701}, 'accuracy': 0.5012880576091254, 'macro avg': {'precision': 0.4867503519144359, 'recall': 0.5445418497207307, 'f1-score': 0.46690100041500315, 'support': 166918}, 'weighted avg': {'precision': 0.6634758898355853, 'recall': 0.5012880576091254, 'f1-score': 0.529613914224541, 'support': 166918}}
[[14902  4431  9031]
 [28458 50756 31639]
 [ 4657  5028 18016]]
Evaluating performance on  val set...
181/181 - 3s - 3s/epoch - 14ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.97413933
{'0': {'precision': 0.30302786924745, 'recall': 0.5444444444444444, 'f1-score': 0.38935039471647487, 'support': 6930}, '1': {'precision': 0.8495781822040643, 'recall': 0.48921478765658416, 'f1-score': 0.6208969114140024, 'support': 32730}, '2': {'precision': 0.28508537886873, 'recall': 0.6446455505279035, 'f1-score': 0.39533808158357225, 'support': 6630}, 'accuracy': 0.5197450853316051, 'macro avg': {'precision': 0.4792304767734148, 'recall': 0.5594349275429774, 'f1-score': 0.4685284625713499, 'support': 46290}, 'weighted avg': {'precision': 0.686904149909776, 'recall': 0.5197450853316051, 'f1-score': 0.5539262395088476, 'support': 46290}}
[[ 3773  1393  1764]
 [ 7764 16012  8954]
 [  914  1442  4274]]
training model: results/QRTEA/W1/deepLOB_L2/h30
Epoch 1/50
653/653 - 28s - loss: 3.1383 - accuracy30: 0.4264 - val_loss: 2.9844 - val_accuracy30: 0.5688 - 28s/epoch - 44ms/step
Epoch 2/50
653/653 - 27s - loss: 2.9593 - accuracy30: 0.4640 - val_loss: 2.8862 - val_accuracy30: 0.4808 - 27s/epoch - 41ms/step
Epoch 3/50
653/653 - 27s - loss: 2.8879 - accuracy30: 0.4898 - val_loss: 2.9231 - val_accuracy30: 0.5116 - 27s/epoch - 41ms/step
Epoch 4/50
653/653 - 26s - loss: 2.8543 - accuracy30: 0.5041 - val_loss: 2.9543 - val_accuracy30: 0.4635 - 26s/epoch - 40ms/step
Epoch 5/50
653/653 - 26s - loss: 2.8182 - accuracy30: 0.5177 - val_loss: 2.9803 - val_accuracy30: 0.4560 - 26s/epoch - 39ms/step
Epoch 6/50
653/653 - 25s - loss: 2.7856 - accuracy30: 0.5289 - val_loss: 3.0708 - val_accuracy30: 0.4499 - 25s/epoch - 39ms/step
Epoch 7/50
653/653 - 25s - loss: 2.7627 - accuracy30: 0.5368 - val_loss: 3.0453 - val_accuracy30: 0.4499 - 25s/epoch - 39ms/step
Epoch 8/50
653/653 - 26s - loss: 2.7345 - accuracy30: 0.5484 - val_loss: 2.9666 - val_accuracy30: 0.4772 - 26s/epoch - 39ms/step
Epoch 9/50
653/653 - 26s - loss: 2.6990 - accuracy30: 0.5600 - val_loss: 3.0061 - val_accuracy30: 0.4586 - 26s/epoch - 39ms/step
Epoch 10/50
653/653 - 26s - loss: 2.6787 - accuracy30: 0.5666 - val_loss: 3.0291 - val_accuracy30: 0.4545 - 26s/epoch - 39ms/step
Epoch 11/50
653/653 - 26s - loss: 2.6503 - accuracy30: 0.5734 - val_loss: 3.0936 - val_accuracy30: 0.4505 - 26s/epoch - 39ms/step
Epoch 12/50
653/653 - 26s - loss: 2.6281 - accuracy30: 0.5793 - val_loss: 3.0636 - val_accuracy30: 0.4632 - 26s/epoch - 40ms/step
testing model: results/QRTEA/W1/deepLOB_L2/h30
Evaluating performance on  test set...
1645/1645 - 22s - 22s/epoch - 14ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.0455098
{'0': {'precision': 0.1930361902048424, 'recall': 0.5750331535673239, 'f1-score': 0.28904215512874065, 'support': 56555}, '1': {'precision': 0.7852456945555603, 'recall': 0.30184452630829295, 'f1-score': 0.43606705342340507, 'support': 308914}, '2': {'precision': 0.23397162802517302, 'recall': 0.5636196683531085, 'f1-score': 0.33067314548287424, 'support': 55541}, 'accuracy': 0.37307664901071236, 'macro avg': {'precision': 0.4040845042618586, 'recall': 0.48016578274290844, 'f1-score': 0.35192745134500664, 'support': 421010}, 'weighted avg': {'precision': 0.632967312931088, 'recall': 0.37307664901071236, 'f1-score': 0.4024130400651006, 'support': 421010}}
[[ 32521  11206  12828]
 [126008  93244  89662]
 [  9942  14295  31304]]
Evaluating performance on  train set...
653/653 - 9s - 9s/epoch - 14ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.9773375
{'0': {'precision': 0.3037996155150967, 'recall': 0.4871407416361933, 'f1-score': 0.37422080861782764, 'support': 33089}, '1': {'precision': 0.6697861128717547, 'recall': 0.5311486719558468, 'f1-score': 0.5924651510487665, 'support': 101465}, '2': {'precision': 0.35655897236278705, 'recall': 0.367939686070943, 'f1-score': 0.36215994282325387, 'support': 32364}, 'accuracy': 0.4907799039049114, 'macro avg': {'precision': 0.4433815669165462, 'recall': 0.4620763665543277, 'f1-score': 0.4429486341632827, 'support': 166918}, 'weighted avg': {'precision': 0.5365026420269885, 'recall': 0.4907799039049114, 'f1-score': 0.5045472224508452, 'support': 166918}}
[[16119 11728  5242]
 [31325 53893 16247]
 [ 5614 14842 11908]]
Evaluating performance on  val set...
181/181 - 3s - 3s/epoch - 14ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.96226186
{'0': {'precision': 0.2919165757906216, 'recall': 0.5214268322376431, 'f1-score': 0.37428995892685485, 'support': 8214}, '1': {'precision': 0.7383132270573028, 'recall': 0.4538201800847458, 'f1-score': 0.5621207151057898, 'support': 30208}, '2': {'precision': 0.315632183908046, 'recall': 0.523512963904423, 'f1-score': 0.39382350129075444, 'support': 7868}, 'accuracy': 0.47766256210844676, 'macro avg': {'precision': 0.44862066225199015, 'recall': 0.49958665874227065, 'f1-score': 0.44341139177446637, 'support': 46290}, 'weighted avg': {'precision': 0.5872577822311444, 'recall': 0.47766256210844676, 'f1-score': 0.5001849987620769, 'support': 46290}}
[[ 4283  2233  1698]
 [ 9266 13709  7233]
 [ 1123  2626  4119]]
training model: results/QRTEA/W1/deepLOB_L2/h50
Epoch 1/50
653/653 - 28s - loss: 3.2268 - accuracy50: 0.4179 - val_loss: 3.2005 - val_accuracy50: 0.5345 - 28s/epoch - 43ms/step
Epoch 2/50
653/653 - 25s - loss: 3.0585 - accuracy50: 0.4540 - val_loss: 3.0785 - val_accuracy50: 0.4565 - 25s/epoch - 39ms/step
Epoch 3/50
653/653 - 25s - loss: 2.9823 - accuracy50: 0.4777 - val_loss: 3.0166 - val_accuracy50: 0.4573 - 25s/epoch - 39ms/step
Epoch 4/50
653/653 - 26s - loss: 2.9309 - accuracy50: 0.4963 - val_loss: 3.1042 - val_accuracy50: 0.4530 - 26s/epoch - 39ms/step
Epoch 5/50
653/653 - 25s - loss: 2.8907 - accuracy50: 0.5128 - val_loss: 3.0179 - val_accuracy50: 0.4666 - 25s/epoch - 39ms/step
Epoch 6/50
653/653 - 26s - loss: 2.8638 - accuracy50: 0.5224 - val_loss: 3.0387 - val_accuracy50: 0.4506 - 26s/epoch - 39ms/step
Epoch 7/50
653/653 - 26s - loss: 2.8374 - accuracy50: 0.5298 - val_loss: 3.0436 - val_accuracy50: 0.4435 - 26s/epoch - 39ms/step
Epoch 8/50
653/653 - 25s - loss: 2.8146 - accuracy50: 0.5359 - val_loss: 3.0622 - val_accuracy50: 0.4490 - 25s/epoch - 39ms/step
Epoch 9/50
653/653 - 26s - loss: 2.7805 - accuracy50: 0.5472 - val_loss: 3.1288 - val_accuracy50: 0.4400 - 26s/epoch - 39ms/step
Epoch 10/50
653/653 - 26s - loss: 2.7529 - accuracy50: 0.5543 - val_loss: 3.1395 - val_accuracy50: 0.4434 - 26s/epoch - 39ms/step
Epoch 11/50
653/653 - 26s - loss: 2.7293 - accuracy50: 0.5597 - val_loss: 3.1812 - val_accuracy50: 0.4513 - 26s/epoch - 39ms/step
Epoch 12/50
653/653 - 25s - loss: 2.7050 - accuracy50: 0.5658 - val_loss: 3.1833 - val_accuracy50: 0.4436 - 25s/epoch - 39ms/step
Epoch 13/50
653/653 - 26s - loss: 2.6867 - accuracy50: 0.5712 - val_loss: 3.1992 - val_accuracy50: 0.4601 - 26s/epoch - 39ms/step
testing model: results/QRTEA/W1/deepLOB_L2/h50
Evaluating performance on  test set...
1645/1645 - 22s - 22s/epoch - 13ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.1660287
{'0': {'precision': 0.2268011426805131, 'recall': 0.6179550918945352, 'f1-score': 0.3318186128272271, 'support': 73617}, '1': {'precision': 0.7632172836108435, 'recall': 0.20071364207158857, 'f1-score': 0.31784045226490615, 'support': 276329}, '2': {'precision': 0.28015890741003935, 'recall': 0.5825171676235505, 'f1-score': 0.3783514530008271, 'support': 71064}, 'accuracy': 0.3381178594332676, 'macro avg': {'precision': 0.423392444567132, 'recall': 0.4670619671965581, 'f1-score': 0.3426701726976535, 'support': 421010}, 'weighted avg': {'precision': 0.587883188237332, 'recall': 0.3381178594332676, 'f1-score': 0.3304985459026199, 'support': 421010}}
[[ 45492   6701  21424]
 [135927  55463  84939]
 [ 19162  10506  41396]]
Evaluating performance on  train set...
653/653 - 9s - 9s/epoch - 14ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0856665
{'0': {'precision': 0.32170870718356753, 'recall': 0.568196541585688, 'f1-score': 0.41081626402925653, 'support': 40134}, '1': {'precision': 0.6267020857929949, 'recall': 0.3645593672378467, 'f1-score': 0.4609684259279362, 'support': 87363}, '2': {'precision': 0.3828681381872871, 'recall': 0.4391314274117856, 'f1-score': 0.40907426005789566, 'support': 39421}, 'accuracy': 0.4311338501539678, 'macro avg': {'precision': 0.4437596437212832, 'recall': 0.4572957787451068, 'f1-score': 0.4269529833383628, 'support': 166918}, 'weighted avg': {'precision': 0.4957828182144512, 'recall': 0.4311338501539678, 'f1-score': 0.4366539315150839, 'support': 166918}}
[[22804  7748  9582]
 [37193 31849 18321]
 [10887 11223 17311]]
Evaluating performance on  val set...
181/181 - 3s - 3s/epoch - 14ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.029805
{'0': {'precision': 0.3291953761175332, 'recall': 0.5575272446716173, 'f1-score': 0.4139634801288936, 'support': 10369}, '1': {'precision': 0.6765036186673322, 'recall': 0.4143927233814874, 'f1-score': 0.5139593307105276, 'support': 26166}, '2': {'precision': 0.35965671994331155, 'recall': 0.4682726806765761, 'f1-score': 0.4068400427502672, 'support': 9755}, 'accuracy': 0.4578094620868438, 'macro avg': {'precision': 0.455118571576059, 'recall': 0.4800642162432269, 'f1-score': 0.4449209511965628, 'support': 46290}, 'weighted avg': {'precision': 0.5319350149937161, 'recall': 0.4578094620868438, 'f1-score': 0.46898621278585045, 'support': 46290}}
[[ 5781  2201  2387]
 [ 9577 10843  5746]
 [ 2203  2984  4568]]
training model: results/QRTEA/W1/deepLOB_L2/h100
Epoch 1/50
653/653 - 29s - loss: 3.2570 - accuracy100: 0.4046 - val_loss: 3.5191 - val_accuracy100: 0.4135 - 29s/epoch - 45ms/step
Epoch 2/50
653/653 - 26s - loss: 3.1934 - accuracy100: 0.4316 - val_loss: 3.3281 - val_accuracy100: 0.4270 - 26s/epoch - 40ms/step
Epoch 3/50
653/653 - 26s - loss: 3.1197 - accuracy100: 0.4506 - val_loss: 3.2096 - val_accuracy100: 0.4252 - 26s/epoch - 40ms/step
Epoch 4/50
653/653 - 26s - loss: 3.0757 - accuracy100: 0.4682 - val_loss: 3.2835 - val_accuracy100: 0.4262 - 26s/epoch - 39ms/step
Epoch 5/50
653/653 - 26s - loss: 3.0315 - accuracy100: 0.4828 - val_loss: 3.1972 - val_accuracy100: 0.4419 - 26s/epoch - 39ms/step
Epoch 6/50
653/653 - 26s - loss: 3.0020 - accuracy100: 0.4918 - val_loss: 3.1853 - val_accuracy100: 0.4456 - 26s/epoch - 39ms/step
Epoch 7/50
653/653 - 25s - loss: 2.9788 - accuracy100: 0.4986 - val_loss: 3.2198 - val_accuracy100: 0.4450 - 25s/epoch - 39ms/step
Epoch 8/50
653/653 - 26s - loss: 2.9478 - accuracy100: 0.5083 - val_loss: 3.2610 - val_accuracy100: 0.4400 - 26s/epoch - 39ms/step
Epoch 9/50
653/653 - 26s - loss: 2.9223 - accuracy100: 0.5140 - val_loss: 3.3026 - val_accuracy100: 0.4433 - 26s/epoch - 39ms/step
Epoch 10/50
653/653 - 26s - loss: 2.9012 - accuracy100: 0.5197 - val_loss: 3.3368 - val_accuracy100: 0.4369 - 26s/epoch - 39ms/step
Epoch 11/50
653/653 - 26s - loss: 2.8802 - accuracy100: 0.5270 - val_loss: 3.3584 - val_accuracy100: 0.4446 - 26s/epoch - 39ms/step
Epoch 12/50
653/653 - 25s - loss: 2.8578 - accuracy100: 0.5326 - val_loss: 3.4230 - val_accuracy100: 0.4355 - 25s/epoch - 39ms/step
Epoch 13/50
653/653 - 26s - loss: 2.8334 - accuracy100: 0.5385 - val_loss: 3.4886 - val_accuracy100: 0.4269 - 26s/epoch - 39ms/step
Epoch 14/50
653/653 - 25s - loss: 2.8103 - accuracy100: 0.5439 - val_loss: 3.5177 - val_accuracy100: 0.4267 - 25s/epoch - 39ms/step
Epoch 15/50
653/653 - 25s - loss: 2.7837 - accuracy100: 0.5504 - val_loss: 3.5546 - val_accuracy100: 0.4260 - 25s/epoch - 39ms/step
Epoch 16/50
653/653 - 26s - loss: 2.7669 - accuracy100: 0.5547 - val_loss: 3.5553 - val_accuracy100: 0.4271 - 26s/epoch - 39ms/step
testing model: results/QRTEA/W1/deepLOB_L2/h100
Evaluating performance on  test set...
1645/1645 - 22s - 22s/epoch - 13ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.1863749
{'0': {'precision': 0.31014888576259847, 'recall': 0.641848511574535, 'f1-score': 0.4182124893409296, 'support': 105447}, '1': {'precision': 0.6533196065975949, 'recall': 0.13794538794538794, 'f1-score': 0.22779328595595508, 'support': 216216}, '2': {'precision': 0.3135054984217493, 'recall': 0.4958680181585755, 'f1-score': 0.38414241879578764, 'support': 99347}, 'accuracy': 0.3486140471722762, 'macro avg': {'precision': 0.4256579969273142, 'recall': 0.42522063922616615, 'f1-score': 0.3433827313642241, 'support': 421010}, 'weighted avg': {'precision': 0.48718142649537977, 'recall': 0.3486140471722762, 'f1-score': 0.31238023410344384, 'support': 421010}}
[[ 67681   6459  31307]
 [109824  29826  76566]
 [ 40716   9368  49263]]
Evaluating performance on  train set...
653/653 - 9s - 9s/epoch - 14ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.1386375
{'0': {'precision': 0.3563348138695983, 'recall': 0.5640537600994406, 'f1-score': 0.4367546432062561, 'support': 51488}, '1': {'precision': 0.4842952262193257, 'recall': 0.3191565237615319, 'f1-score': 0.3847548552309389, 'support': 64495}, '2': {'precision': 0.4021392118938317, 'recall': 0.3388043584961225, 'f1-score': 0.367764896428267, 'support': 50935}, 'accuracy': 0.4006937538192406, 'macro avg': {'precision': 0.41425641732758517, 'recall': 0.40733821411903165, 'f1-score': 0.39642479828848737, 'support': 166918}, 'weighted avg': {'precision': 0.41975430013147536, 'recall': 0.4006937538192406, 'f1-score': 0.39561037429813983, 'support': 166918}}
[[29042 10136 12310]
 [30565 20584 13346]
 [21895 11783 17257]]
Evaluating performance on  val set...
181/181 - 3s - 3s/epoch - 14ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0668232
{'0': {'precision': 0.422790585975024, 'recall': 0.49654491609081935, 'f1-score': 0.4567092548154874, 'support': 14182}, '1': {'precision': 0.5191983122362869, 'recall': 0.38772187795399643, 'f1-score': 0.44393001022187484, 'support': 19042}, '2': {'precision': 0.3994420656545997, 'recall': 0.4712230215827338, 'f1-score': 0.43237359550561794, 'support': 13066}, 'accuracy': 0.44463166990710734, 'macro avg': {'precision': 0.4471436546219702, 'recall': 0.4518299385425166, 'f1-score': 0.4443376201809934, 'support': 46290}, 'weighted avg': {'precision': 0.45585872503227837, 'recall': 0.44463166990710734, 'f1-score': 0.4445832643187424, 'support': 46290}}
[[7042 3052 4088]
 [6490 7383 5169]
 [3124 3785 6157]]
training model: results/QRTEA/W1/deepLOB_L2/h200
Epoch 1/50
653/653 - 28s - loss: 3.2909 - accuracy200: 0.3835 - val_loss: 3.3212 - val_accuracy200: 0.3538 - 28s/epoch - 43ms/step
Epoch 2/50
653/653 - 27s - loss: 3.2619 - accuracy200: 0.3966 - val_loss: 3.2905 - val_accuracy200: 0.3889 - 27s/epoch - 41ms/step
Epoch 3/50
653/653 - 27s - loss: 3.2225 - accuracy200: 0.4163 - val_loss: 3.2414 - val_accuracy200: 0.4051 - 27s/epoch - 41ms/step
Epoch 4/50
653/653 - 27s - loss: 3.1925 - accuracy200: 0.4259 - val_loss: 3.2526 - val_accuracy200: 0.4069 - 27s/epoch - 41ms/step
Epoch 5/50
653/653 - 27s - loss: 3.1637 - accuracy200: 0.4378 - val_loss: 3.2607 - val_accuracy200: 0.4110 - 27s/epoch - 41ms/step
Epoch 6/50
653/653 - 26s - loss: 3.1375 - accuracy200: 0.4487 - val_loss: 3.2908 - val_accuracy200: 0.4063 - 26s/epoch - 40ms/step
Epoch 7/50
653/653 - 26s - loss: 3.1079 - accuracy200: 0.4587 - val_loss: 3.3310 - val_accuracy200: 0.4052 - 26s/epoch - 40ms/step
Epoch 8/50
653/653 - 26s - loss: 3.0859 - accuracy200: 0.4676 - val_loss: 3.3219 - val_accuracy200: 0.4037 - 26s/epoch - 40ms/step
Epoch 9/50
653/653 - 26s - loss: 3.0584 - accuracy200: 0.4774 - val_loss: 3.3750 - val_accuracy200: 0.3960 - 26s/epoch - 40ms/step
Epoch 10/50
653/653 - 26s - loss: 3.0403 - accuracy200: 0.4817 - val_loss: 3.4391 - val_accuracy200: 0.3967 - 26s/epoch - 40ms/step
Epoch 11/50
653/653 - 26s - loss: 3.0165 - accuracy200: 0.4885 - val_loss: 3.4450 - val_accuracy200: 0.4043 - 26s/epoch - 39ms/step
Epoch 12/50
653/653 - 26s - loss: 2.9952 - accuracy200: 0.4965 - val_loss: 3.4735 - val_accuracy200: 0.4046 - 26s/epoch - 39ms/step
Epoch 13/50
653/653 - 26s - loss: 2.9659 - accuracy200: 0.5050 - val_loss: 3.4632 - val_accuracy200: 0.4021 - 26s/epoch - 39ms/step
testing model: results/QRTEA/W1/deepLOB_L2/h200
Evaluating performance on  test set...
1645/1645 - 22s - 22s/epoch - 13ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.104023
{'0': {'precision': 0.34394508455103057, 'recall': 0.7134862392240566, 'f1-score': 0.46414377815066676, 'support': 132587}, '1': {'precision': 0.50970856617387, 'recall': 0.349738512127941, 'f1-score': 0.4148358172436871, 'support': 164826}, '2': {'precision': 0.3477626015270891, 'recall': 0.09249415438886058, 'f1-score': 0.14612385760848726, 'support': 123597}, 'accuracy': 0.38877223818911666, 'macro avg': {'precision': 0.40047208408399654, 'recall': 0.38523963524695276, 'f1-score': 0.34170115100094706, 'support': 421010}, 'weighted avg': {'precision': 0.4099624363185801, 'recall': 0.38877223818911666, 'f1-score': 0.35147770826228986, 'support': 421010}}
[[94599 27827 10161]
 [95900 57646 11280]
 [84542 27623 11432]]
Evaluating performance on  train set...
653/653 - 9s - 9s/epoch - 14ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1150392
{'0': {'precision': 0.36780253656921774, 'recall': 0.6102119625847421, 'f1-score': 0.4589656040430901, 'support': 58265}, '1': {'precision': 0.35041404990829766, 'recall': 0.36106285910626684, 'f1-score': 0.35565876313859696, 'support': 52387}, '2': {'precision': 0.40004916118724265, 'recall': 0.11570042299079374, 'f1-score': 0.17948965384138188, 'support': 56266}, 'accuracy': 0.36532309277609365, 'macro avg': {'precision': 0.37275524922158604, 'recall': 0.3623250815606009, 'f1-score': 0.331371340341023, 'support': 166918}, 'weighted avg': {'precision': 0.37321512197074524, 'recall': 0.36532309277609365, 'f1-score': 0.3323349872820877, 'support': 166918}}
[[35554 16939  5772]
 [29481 18915  3991]
 [31631 18125  6510]]
Evaluating performance on  val set...
181/181 - 2s - 2s/epoch - 14ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0778587
{'0': {'precision': 0.4115949535683895, 'recall': 0.663426560915976, 'f1-score': 0.5080140645691584, 'support': 16769}, '1': {'precision': 0.3906633906633907, 'recall': 0.35722811205504457, 'f1-score': 0.3731983716580482, 'support': 14243}, '2': {'precision': 0.3995510662177329, 'recall': 0.16311035475847624, 'f1-score': 0.23165233557982806, 'support': 15278}, 'accuracy': 0.40408295528191834, 'macro avg': {'precision': 0.40060313681650433, 'recall': 0.39458834257649894, 'f1-score': 0.37095492393567825, 'support': 46290}, 'weighted avg': {'precision': 0.40117942621044544, 'recall': 0.40408295528191834, 'f1-score': 0.37531943485146707, 'support': 46290}}
[[11125  3558  2086]
 [ 7496  5088  1659]
 [ 8408  4378  2492]]
training model: results/QRTEA/W1/deepLOB_L2/h300
Epoch 1/50
653/653 - 29s - loss: 3.2975 - accuracy300: 0.3816 - val_loss: 3.4326 - val_accuracy300: 0.3310 - 29s/epoch - 44ms/step
Epoch 2/50
653/653 - 26s - loss: 3.2744 - accuracy300: 0.3811 - val_loss: 3.3487 - val_accuracy300: 0.3377 - 26s/epoch - 40ms/step
Epoch 3/50
653/653 - 26s - loss: 3.2492 - accuracy300: 0.3964 - val_loss: 3.3675 - val_accuracy300: 0.3454 - 26s/epoch - 40ms/step
Epoch 4/50
653/653 - 26s - loss: 3.2260 - accuracy300: 0.4090 - val_loss: 3.3904 - val_accuracy300: 0.3582 - 26s/epoch - 39ms/step
Epoch 5/50
653/653 - 26s - loss: 3.1974 - accuracy300: 0.4227 - val_loss: 3.4370 - val_accuracy300: 0.3586 - 26s/epoch - 39ms/step
Epoch 6/50
653/653 - 26s - loss: 3.1777 - accuracy300: 0.4308 - val_loss: 3.3801 - val_accuracy300: 0.3684 - 26s/epoch - 39ms/step
Epoch 7/50
653/653 - 26s - loss: 3.1523 - accuracy300: 0.4409 - val_loss: 3.4767 - val_accuracy300: 0.3573 - 26s/epoch - 39ms/step
Epoch 8/50
653/653 - 26s - loss: 3.1314 - accuracy300: 0.4508 - val_loss: 3.6107 - val_accuracy300: 0.3518 - 26s/epoch - 39ms/step
Epoch 9/50
653/653 - 26s - loss: 3.0971 - accuracy300: 0.4632 - val_loss: 3.6130 - val_accuracy300: 0.3575 - 26s/epoch - 39ms/step
Epoch 10/50
653/653 - 25s - loss: 3.0724 - accuracy300: 0.4687 - val_loss: 3.6867 - val_accuracy300: 0.3568 - 25s/epoch - 39ms/step
Epoch 11/50
653/653 - 25s - loss: 3.0406 - accuracy300: 0.4788 - val_loss: 3.8037 - val_accuracy300: 0.3507 - 25s/epoch - 39ms/step
Epoch 12/50
653/653 - 26s - loss: 3.0100 - accuracy300: 0.4883 - val_loss: 3.9347 - val_accuracy300: 0.3484 - 26s/epoch - 39ms/step
testing model: results/QRTEA/W1/deepLOB_L2/h300
Evaluating performance on  test set...
1645/1645 - 22s - 22s/epoch - 13ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1165844
{'0': {'precision': 0.36630230709867656, 'recall': 0.23560876587295707, 'f1-score': 0.28676672813428494, 'support': 134978}, '1': {'precision': 0.39761790134195335, 'recall': 0.6040391375961845, 'f1-score': 0.47955890066726037, 'support': 162708}, '2': {'precision': 0.29374583400372356, 'recall': 0.20725892770263696, 'f1-score': 0.24303739695157317, 'support': 123324}, 'accuracy': 0.36969193130804495, 'macro avg': {'precision': 0.3525553474814512, 'recall': 0.34896894372392623, 'f1-score': 0.3364543419177062, 'support': 421010}, 'weighted avg': {'precision': 0.3571513207092158, 'recall': 0.36969193130804495, 'f1-score': 0.3484658629997718, 'support': 421010}}
[[31802 76061 27115]
 [30087 98282 34339]
 [24930 72834 25560]]
Evaluating performance on  train set...
653/653 - 9s - 9s/epoch - 14ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1372764
{'0': {'precision': 0.33620268977767365, 'recall': 0.30403163171644426, 'f1-score': 0.31930888091729, 'support': 56652}, '1': {'precision': 0.33668501378596394, 'recall': 0.5826696230598669, 'f1-score': 0.42676921877639046, 'support': 56375}, '2': {'precision': 0.3568748620613551, 'recall': 0.12002004045202352, 'f1-score': 0.17962924390751925, 'support': 53891}, 'accuracy': 0.3387291963718712, 'macro avg': {'precision': 0.34325418854166423, 'recall': 0.33557376507611153, 'f1-score': 0.3085691145337332, 'support': 166918}, 'weighted avg': {'precision': 0.34303978974596494, 'recall': 0.3387291963718712, 'f1-score': 0.3105057633907993, 'support': 166918}}
[[17224 33249  6179]
 [18050 32848  5477]
 [15957 31466  6468]]
Evaluating performance on  val set...
181/181 - 3s - 3s/epoch - 14ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1145473
{'0': {'precision': 0.36203522504892366, 'recall': 0.1027460660290034, 'f1-score': 0.16006537204383772, 'support': 16205}, '1': {'precision': 0.3308064721620589, 'recall': 0.6834243600710667, 'f1-score': 0.4458180413366815, 'support': 15197}, '2': {'precision': 0.35726080621661, 'recall': 0.24704459967759268, 'f1-score': 0.29210181471627683, 'support': 14888}, 'accuracy': 0.33979261179520415, 'macro avg': {'precision': 0.35003416780919755, 'recall': 0.34440500859255424, 'f1-score': 0.2993284093655987, 'support': 46290}, 'weighted avg': {'precision': 0.3502472599334091, 'recall': 0.33979261179520415, 'f1-score': 0.2963440904225506, 'support': 46290}}
[[ 1665 11202  3338]
 [ 1532 10386  3279]
 [ 1402  9808  3678]]
training model: results/QRTEA/W1/deepLOB_L2/h500
Epoch 1/50
653/653 - 28s - loss: 3.2144 - accuracy500: 0.4254 - val_loss: 3.4538 - val_accuracy500: 0.2820 - 28s/epoch - 44ms/step
Epoch 2/50
653/653 - 26s - loss: 3.1816 - accuracy500: 0.4358 - val_loss: 3.4212 - val_accuracy500: 0.2932 - 26s/epoch - 39ms/step
Epoch 3/50
653/653 - 25s - loss: 3.2159 - accuracy500: 0.4173 - val_loss: 3.4053 - val_accuracy500: 0.3264 - 25s/epoch - 39ms/step
Epoch 4/50
653/653 - 25s - loss: 3.1601 - accuracy500: 0.4416 - val_loss: 3.4397 - val_accuracy500: 0.3167 - 25s/epoch - 39ms/step
Epoch 5/50
653/653 - 25s - loss: 3.1335 - accuracy500: 0.4575 - val_loss: 3.4550 - val_accuracy500: 0.3506 - 25s/epoch - 39ms/step
Epoch 6/50
653/653 - 26s - loss: 3.1154 - accuracy500: 0.4665 - val_loss: 3.4473 - val_accuracy500: 0.3626 - 26s/epoch - 39ms/step
Epoch 7/50
653/653 - 26s - loss: 3.0973 - accuracy500: 0.4695 - val_loss: 3.5185 - val_accuracy500: 0.3591 - 26s/epoch - 39ms/step
Epoch 8/50
653/653 - 26s - loss: 3.0822 - accuracy500: 0.4746 - val_loss: 3.4852 - val_accuracy500: 0.3583 - 26s/epoch - 39ms/step
Epoch 9/50
653/653 - 26s - loss: 3.0608 - accuracy500: 0.4830 - val_loss: 3.6010 - val_accuracy500: 0.3571 - 26s/epoch - 39ms/step
Epoch 10/50
653/653 - 26s - loss: 3.0449 - accuracy500: 0.4879 - val_loss: 3.6290 - val_accuracy500: 0.3609 - 26s/epoch - 39ms/step
Epoch 11/50
653/653 - 26s - loss: 3.0086 - accuracy500: 0.4992 - val_loss: 3.6598 - val_accuracy500: 0.3611 - 26s/epoch - 39ms/step
Epoch 12/50
653/653 - 26s - loss: 2.9909 - accuracy500: 0.5046 - val_loss: 3.6253 - val_accuracy500: 0.3464 - 26s/epoch - 39ms/step
Epoch 13/50
653/653 - 26s - loss: 2.9630 - accuracy500: 0.5122 - val_loss: 3.6544 - val_accuracy500: 0.3488 - 26s/epoch - 39ms/step
testing model: results/QRTEA/W1/deepLOB_L2/h500
Evaluating performance on  test set...
1645/1645 - 22s - 22s/epoch - 14ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1244615
{'0': {'precision': 0.36125392691644714, 'recall': 0.311371237458194, 'f1-score': 0.33446290212821816, 'support': 155480}, '1': {'precision': 0.29090938244089376, 'recall': 0.28447782490415746, 'f1-score': 0.2876576583718478, 'support': 127553}, '2': {'precision': 0.3310243673967436, 'recall': 0.3892967668524464, 'f1-score': 0.3578035124882179, 'support': 137977}, 'accuracy': 0.328761787130947, 'macro avg': {'precision': 0.32772922558469486, 'recall': 0.3283819430715993, 'f1-score': 0.3266413576627613, 'support': 421010}, 'weighted avg': {'precision': 0.33003461712489734, 'recall': 0.328761787130947, 'f1-score': 0.3279317464283188, 'support': 421010}}
[[48412 48892 58176]
 [40891 36286 50376]
 [44708 39555 53714]]
Evaluating performance on  train set...
653/653 - 9s - 9s/epoch - 14ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1048743
{'0': {'precision': 0.3416178462442272, 'recall': 0.36063257993384784, 'f1-score': 0.3508677834857157, 'support': 58048}, '1': {'precision': 0.39992974310413293, 'recall': 0.4671054978771986, 'f1-score': 0.4309153144850739, 'support': 56058}, '2': {'precision': 0.35735092742437446, 'recall': 0.2717753540861925, 'f1-score': 0.3087430224679222, 'support': 52812}, 'accuracy': 0.3682766388286464, 'macro avg': {'precision': 0.3662995055909115, 'recall': 0.3665044772990797, 'f1-score': 0.3635087068129039, 'support': 166918}, 'weighted avg': {'precision': 0.36617927040134945, 'recall': 0.3682766388286464, 'f1-score': 0.364423011884632, 'support': 166918}}
[[20934 20788 16326]
 [20387 26185  9486]
 [19958 18501 14353]]
Evaluating performance on  val set...
181/181 - 3s - 3s/epoch - 14ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1325165
{'0': {'precision': 0.37753628172501547, 'recall': 0.30470744976129677, 'f1-score': 0.33723466347187664, 'support': 18014}, '1': {'precision': 0.2603509648410666, 'recall': 0.34680974960485816, 'f1-score': 0.2974245558964115, 'support': 12021}, '2': {'precision': 0.3529037997204219, 'recall': 0.3416794832359274, 'f1-score': 0.34720095020785796, 'support': 16255}, 'accuracy': 0.3286238928494275, 'macro avg': {'precision': 0.33026368209550133, 'recall': 0.3310655608673608, 'f1-score': 0.32728672319204866, 'support': 46290}, 'weighted avg': {'precision': 0.3384547157443152, 'recall': 0.3286238928494275, 'f1-score': 0.3303961386874461, 'support': 46290}}
[[5489 6249 6276]
 [3944 4169 3908]
 [5106 5595 5554]]
training model: results/QRTEA/W1/deepLOB_L2/h1000
Epoch 1/50
653/653 - 29s - loss: 3.2078 - accuracy1000: 0.4297 - val_loss: 3.4563 - val_accuracy1000: 0.2769 - 29s/epoch - 44ms/step
Epoch 2/50
653/653 - 26s - loss: 3.1997 - accuracy1000: 0.4233 - val_loss: 3.3957 - val_accuracy1000: 0.3355 - 26s/epoch - 40ms/step
Epoch 3/50
653/653 - 26s - loss: 3.1895 - accuracy1000: 0.4313 - val_loss: 3.4034 - val_accuracy1000: 0.2949 - 26s/epoch - 40ms/step
Epoch 4/50
653/653 - 26s - loss: 3.1580 - accuracy1000: 0.4465 - val_loss: 3.3731 - val_accuracy1000: 0.3728 - 26s/epoch - 40ms/step
Epoch 5/50
653/653 - 26s - loss: 3.1346 - accuracy1000: 0.4555 - val_loss: 3.4168 - val_accuracy1000: 0.3898 - 26s/epoch - 40ms/step
Epoch 6/50
653/653 - 26s - loss: 3.1258 - accuracy1000: 0.4603 - val_loss: 3.3688 - val_accuracy1000: 0.3908 - 26s/epoch - 39ms/step
Epoch 7/50
653/653 - 25s - loss: 3.1184 - accuracy1000: 0.4626 - val_loss: 3.4177 - val_accuracy1000: 0.3787 - 25s/epoch - 39ms/step
Epoch 8/50
653/653 - 26s - loss: 3.0896 - accuracy1000: 0.4742 - val_loss: 3.4875 - val_accuracy1000: 0.3720 - 26s/epoch - 39ms/step
Epoch 9/50
653/653 - 26s - loss: 3.0818 - accuracy1000: 0.4719 - val_loss: 3.4859 - val_accuracy1000: 0.3665 - 26s/epoch - 39ms/step
Epoch 10/50
653/653 - 26s - loss: 3.0453 - accuracy1000: 0.4870 - val_loss: 3.5102 - val_accuracy1000: 0.2985 - 26s/epoch - 39ms/step
Epoch 11/50
653/653 - 26s - loss: 3.0292 - accuracy1000: 0.4918 - val_loss: 3.5873 - val_accuracy1000: 0.3031 - 26s/epoch - 39ms/step
Epoch 12/50
653/653 - 25s - loss: 3.0189 - accuracy1000: 0.4974 - val_loss: 3.7220 - val_accuracy1000: 0.2413 - 25s/epoch - 39ms/step
Epoch 13/50
653/653 - 26s - loss: 2.9902 - accuracy1000: 0.5026 - val_loss: 3.6207 - val_accuracy1000: 0.2802 - 26s/epoch - 39ms/step
Epoch 14/50
653/653 - 26s - loss: 2.9658 - accuracy1000: 0.5146 - val_loss: 3.6783 - val_accuracy1000: 0.2567 - 26s/epoch - 39ms/step
Epoch 15/50
653/653 - 26s - loss: 2.9301 - accuracy1000: 0.5241 - val_loss: 3.6373 - val_accuracy1000: 0.2820 - 26s/epoch - 40ms/step
Epoch 16/50
653/653 - 26s - loss: 2.9139 - accuracy1000: 0.5297 - val_loss: 3.6680 - val_accuracy1000: 0.2830 - 26s/epoch - 39ms/step
testing model: results/QRTEA/W1/deepLOB_L2/h1000
Evaluating performance on  test set...
1645/1645 - 22s - 22s/epoch - 13ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0989176
{'0': {'precision': 0.4333228055683778, 'recall': 0.3048871516401616, 'f1-score': 0.35793219704064433, 'support': 175501}, '1': {'precision': 0.23830516776879745, 'recall': 0.011406532086000329, 'f1-score': 0.021770990658387872, 'support': 85302}, '2': {'precision': 0.39626300077697957, 'recall': 0.7258172239664934, 'f1-score': 0.5126451831914842, 'support': 160207}, 'accuracy': 0.4056008170827296, 'macro avg': {'precision': 0.35596365803805163, 'recall': 0.34737030256421847, 'f1-score': 0.2974494569635055, 'support': 421010}, 'weighted avg': {'precision': 0.37970736962672474, 'recall': 0.4056008170827296, 'f1-score': 0.3486946020795944, 'support': 421010}}
[[ 53508   1681 120312]
 [ 27478    973  56851]
 [ 42497   1429 116281]]
Evaluating performance on  train set...
653/653 - 9s - 9s/epoch - 14ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1318507
{'0': {'precision': 0.32820983946385873, 'recall': 0.46604896976184107, 'f1-score': 0.385168803344967, 'support': 59792}, '1': {'precision': 0.4105793450881612, 'recall': 0.018248311378139342, 'f1-score': 0.03494354723452908, 'support': 53594}, '2': {'precision': 0.36099355794708227, 'recall': 0.5370059030112829, 'f1-score': 0.4317500844816581, 'support': 53532}, 'accuracy': 0.3450257012425263, 'macro avg': {'precision': 0.36659424749970076, 'recall': 0.34043439471708775, 'f1-score': 0.2839541450203847, 'support': 166918}, 'weighted avg': {'precision': 0.36517103779041904, 'recall': 0.3450257012425263, 'f1-score': 0.2876575509086003, 'support': 166918}}
[[27866   758 31168]
 [32898   978 19718]
 [24139   646 28747]]
Evaluating performance on  val set...
181/181 - 3s - 3s/epoch - 14ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1368848
{'0': {'precision': 0.422026868074042, 'recall': 0.34190992075433846, 'f1-score': 0.37776731040979744, 'support': 19938}, '1': {'precision': 0.23029045643153526, 'recall': 0.012344306049822064, 'f1-score': 0.023432552248258392, 'support': 8992}, '2': {'precision': 0.3755859045692126, 'recall': 0.6415898617511521, 'f1-score': 0.4738062320535999, 'support': 17360}, 'accuracy': 0.39027867790019444, 'macro avg': {'precision': 0.3426344096915966, 'recall': 0.33194802951843755, 'f1-score': 0.2916686982372186, 'support': 46290}, 'weighted avg': {'precision': 0.3673647609249114, 'recall': 0.39027867790019444, 'f1-score': 0.3449536904994032, 'support': 46290}}
[[ 6817   249 12872]
 [ 3236   111  5645]
 [ 6100   122 11138]]
training model: results/QRTEA/W1/deepOF_L2/h10
Epoch 1/50
653/653 - 16s - loss: 2.9784 - accuracy10: 0.4947 - val_loss: 2.6296 - val_accuracy10: 0.6832 - 16s/epoch - 25ms/step
Epoch 2/50
653/653 - 14s - loss: 2.6841 - accuracy10: 0.5837 - val_loss: 2.6359 - val_accuracy10: 0.7524 - 14s/epoch - 21ms/step
Epoch 3/50
653/653 - 14s - loss: 2.5358 - accuracy10: 0.6229 - val_loss: 2.4883 - val_accuracy10: 0.7662 - 14s/epoch - 22ms/step
Epoch 4/50
653/653 - 14s - loss: 2.4502 - accuracy10: 0.6389 - val_loss: 2.4138 - val_accuracy10: 0.7710 - 14s/epoch - 21ms/step
Epoch 5/50
653/653 - 14s - loss: 2.4026 - accuracy10: 0.6395 - val_loss: 2.3827 - val_accuracy10: 0.7774 - 14s/epoch - 22ms/step
Epoch 6/50
653/653 - 14s - loss: 2.3719 - accuracy10: 0.6431 - val_loss: 2.3661 - val_accuracy10: 0.7782 - 14s/epoch - 22ms/step
Epoch 7/50
653/653 - 14s - loss: 2.3443 - accuracy10: 0.6473 - val_loss: 2.3746 - val_accuracy10: 0.7782 - 14s/epoch - 21ms/step
Epoch 8/50
653/653 - 14s - loss: 2.3225 - accuracy10: 0.6503 - val_loss: 2.3314 - val_accuracy10: 0.7728 - 14s/epoch - 21ms/step
Epoch 9/50
653/653 - 14s - loss: 2.3042 - accuracy10: 0.6530 - val_loss: 2.3272 - val_accuracy10: 0.7679 - 14s/epoch - 21ms/step
Epoch 10/50
653/653 - 14s - loss: 2.2912 - accuracy10: 0.6537 - val_loss: 2.3265 - val_accuracy10: 0.7691 - 14s/epoch - 21ms/step
Epoch 11/50
653/653 - 14s - loss: 2.2766 - accuracy10: 0.6553 - val_loss: 2.3180 - val_accuracy10: 0.7593 - 14s/epoch - 21ms/step
Epoch 12/50
653/653 - 14s - loss: 2.2617 - accuracy10: 0.6568 - val_loss: 2.2987 - val_accuracy10: 0.7607 - 14s/epoch - 21ms/step
Epoch 13/50
653/653 - 14s - loss: 2.2442 - accuracy10: 0.6598 - val_loss: 2.3022 - val_accuracy10: 0.7651 - 14s/epoch - 21ms/step
Epoch 14/50
653/653 - 14s - loss: 2.2412 - accuracy10: 0.6604 - val_loss: 2.3129 - val_accuracy10: 0.7713 - 14s/epoch - 21ms/step
Epoch 15/50
653/653 - 14s - loss: 2.2260 - accuracy10: 0.6598 - val_loss: 2.3012 - val_accuracy10: 0.7598 - 14s/epoch - 21ms/step
Epoch 16/50
653/653 - 14s - loss: 2.2080 - accuracy10: 0.6612 - val_loss: 2.3228 - val_accuracy10: 0.7487 - 14s/epoch - 21ms/step
Epoch 17/50
653/653 - 14s - loss: 2.2002 - accuracy10: 0.6629 - val_loss: 2.3233 - val_accuracy10: 0.7665 - 14s/epoch - 21ms/step
Epoch 18/50
653/653 - 14s - loss: 2.1819 - accuracy10: 0.6640 - val_loss: 2.3339 - val_accuracy10: 0.7630 - 14s/epoch - 21ms/step
Epoch 19/50
653/653 - 14s - loss: 2.1766 - accuracy10: 0.6633 - val_loss: 2.3527 - val_accuracy10: 0.7528 - 14s/epoch - 21ms/step
Epoch 20/50
653/653 - 14s - loss: 2.1637 - accuracy10: 0.6655 - val_loss: 2.3808 - val_accuracy10: 0.7563 - 14s/epoch - 21ms/step
Epoch 21/50
653/653 - 14s - loss: 2.1515 - accuracy10: 0.6664 - val_loss: 2.4229 - val_accuracy10: 0.7642 - 14s/epoch - 21ms/step
Epoch 22/50
653/653 - 14s - loss: 2.1422 - accuracy10: 0.6681 - val_loss: 2.4244 - val_accuracy10: 0.7675 - 14s/epoch - 21ms/step
testing model: results/QRTEA/W1/deepOF_L2/h10
Evaluating performance on  test set...
1645/1645 - 14s - 14s/epoch - 8ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.5646954
{'0': {'precision': 0.27169351563557603, 'recall': 0.5876324881419454, 'f1-score': 0.3715840924239058, 'support': 34154}, '1': {'precision': 0.9217465704040531, 'recall': 0.8153007601911532, 'f1-score': 0.8652621794669326, 'support': 352806}, '2': {'precision': 0.40548015510948904, 'recall': 0.4177118519606403, 'f1-score': 0.41150512898418623, 'support': 34045}, 'accuracy': 0.7646797543972161, 'macro avg': {'precision': 0.5329734137163727, 'recall': 0.606881700097913, 'f1-score': 0.5494504669583415, 'support': 421005}, 'weighted avg': {'precision': 0.8272626518252573, 'recall': 0.7646797543972161, 'f1-score': 0.788519052500382, 'support': 421005}}
[[ 20070  10564   3520]
 [ 47832 287643  17331]
 [  5968  13856  14221]]
Evaluating performance on  train set...
653/653 - 5s - 5s/epoch - 8ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.6559117
{'0': {'precision': 0.3733325796970382, 'recall': 0.6108388051419588, 'f1-score': 0.4634274688651113, 'support': 21626}, '1': {'precision': 0.8832203922272585, 'recall': 0.7921114062625775, 'f1-score': 0.8351885251119269, 'support': 124230}, '2': {'precision': 0.4500223669168448, 'recall': 0.42987370620074067, 'f1-score': 0.4397173453777227, 'support': 21062}, 'accuracy': 0.7229178398974346, 'macro avg': {'precision': 0.5688584462803805, 'recall': 0.6109413058684257, 'f1-score': 0.579444446451587, 'support': 166918}, 'weighted avg': {'precision': 0.7624973387347264, 'recall': 0.7229178398974346, 'f1-score': 0.7371216983469558, 'support': 166918}}
[[13210  5387  3029]
 [17790 98404  8036]
 [ 4384  7624  9054]]
Evaluating performance on  val set...
181/181 - 2s - 2s/epoch - 8ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.59629697
{'0': {'precision': 0.38101694915254236, 'recall': 0.5539128720678099, 'f1-score': 0.451478149100257, 'support': 5073}, '1': {'precision': 0.8968537718984626, 'recall': 0.8290506485995208, 'f1-score': 0.8616203683826371, 'support': 36309}, '2': {'precision': 0.4208559147822837, 'recall': 0.4588427057864711, 'f1-score': 0.43902914514085195, 'support': 4908}, 'accuracy': 0.7596457118168071, 'macro avg': {'precision': 0.5662422119444296, 'recall': 0.613935408817934, 'f1-score': 0.5840425542079154, 'support': 46290}, 'weighted avg': {'precision': 0.7898536058903343, 'recall': 0.7596457118168071, 'f1-score': 0.7718660110248883, 'support': 46290}}
[[ 2810  1574   689]
 [ 3797 30102  2410]
 [  768  1888  2252]]
training model: results/QRTEA/W1/deepOF_L2/h20
Epoch 1/50
653/653 - 16s - loss: 3.0021 - accuracy20: 0.4841 - val_loss: 2.7147 - val_accuracy20: 0.6715 - 16s/epoch - 25ms/step
Epoch 2/50
653/653 - 14s - loss: 2.7181 - accuracy20: 0.5719 - val_loss: 2.6798 - val_accuracy20: 0.7207 - 14s/epoch - 21ms/step
Epoch 3/50
653/653 - 14s - loss: 2.5893 - accuracy20: 0.6079 - val_loss: 2.6230 - val_accuracy20: 0.7367 - 14s/epoch - 21ms/step
Epoch 4/50
653/653 - 14s - loss: 2.5104 - accuracy20: 0.6203 - val_loss: 2.5451 - val_accuracy20: 0.7339 - 14s/epoch - 21ms/step
Epoch 5/50
653/653 - 14s - loss: 2.4660 - accuracy20: 0.6289 - val_loss: 2.5224 - val_accuracy20: 0.7395 - 14s/epoch - 22ms/step
Epoch 6/50
653/653 - 14s - loss: 2.4345 - accuracy20: 0.6344 - val_loss: 2.5253 - val_accuracy20: 0.7378 - 14s/epoch - 21ms/step
Epoch 7/50
653/653 - 14s - loss: 2.4117 - accuracy20: 0.6380 - val_loss: 2.4987 - val_accuracy20: 0.7426 - 14s/epoch - 21ms/step
Epoch 8/50
653/653 - 14s - loss: 2.3848 - accuracy20: 0.6395 - val_loss: 2.5067 - val_accuracy20: 0.7452 - 14s/epoch - 21ms/step
Epoch 9/50
653/653 - 14s - loss: 2.3720 - accuracy20: 0.6398 - val_loss: 2.5132 - val_accuracy20: 0.7448 - 14s/epoch - 21ms/step
Epoch 10/50
653/653 - 14s - loss: 2.3555 - accuracy20: 0.6430 - val_loss: 2.4805 - val_accuracy20: 0.7412 - 14s/epoch - 22ms/step
Epoch 11/50
653/653 - 14s - loss: 2.3372 - accuracy20: 0.6435 - val_loss: 2.5158 - val_accuracy20: 0.7385 - 14s/epoch - 21ms/step
Epoch 12/50
653/653 - 14s - loss: 2.3249 - accuracy20: 0.6453 - val_loss: 2.4733 - val_accuracy20: 0.7394 - 14s/epoch - 21ms/step
Epoch 13/50
653/653 - 14s - loss: 2.3103 - accuracy20: 0.6470 - val_loss: 2.4662 - val_accuracy20: 0.7444 - 14s/epoch - 21ms/step
Epoch 14/50
653/653 - 14s - loss: 2.3010 - accuracy20: 0.6488 - val_loss: 2.4774 - val_accuracy20: 0.7328 - 14s/epoch - 21ms/step
Epoch 15/50
653/653 - 14s - loss: 2.2852 - accuracy20: 0.6504 - val_loss: 2.5079 - val_accuracy20: 0.7366 - 14s/epoch - 21ms/step
Epoch 16/50
653/653 - 14s - loss: 2.2661 - accuracy20: 0.6516 - val_loss: 2.5206 - val_accuracy20: 0.7284 - 14s/epoch - 21ms/step
Epoch 17/50
653/653 - 14s - loss: 2.2544 - accuracy20: 0.6532 - val_loss: 2.4789 - val_accuracy20: 0.7250 - 14s/epoch - 21ms/step
Epoch 18/50
653/653 - 14s - loss: 2.2410 - accuracy20: 0.6542 - val_loss: 2.5129 - val_accuracy20: 0.7291 - 14s/epoch - 21ms/step
Epoch 19/50
653/653 - 14s - loss: 2.2318 - accuracy20: 0.6555 - val_loss: 2.4798 - val_accuracy20: 0.7201 - 14s/epoch - 22ms/step
Epoch 20/50
653/653 - 14s - loss: 2.2216 - accuracy20: 0.6558 - val_loss: 2.5422 - val_accuracy20: 0.7292 - 14s/epoch - 21ms/step
Epoch 21/50
653/653 - 14s - loss: 2.2029 - accuracy20: 0.6589 - val_loss: 2.5590 - val_accuracy20: 0.7256 - 14s/epoch - 21ms/step
Epoch 22/50
653/653 - 14s - loss: 2.1890 - accuracy20: 0.6599 - val_loss: 2.5792 - val_accuracy20: 0.7209 - 14s/epoch - 21ms/step
Epoch 23/50
653/653 - 14s - loss: 2.1846 - accuracy20: 0.6599 - val_loss: 2.5504 - val_accuracy20: 0.7178 - 14s/epoch - 21ms/step
testing model: results/QRTEA/W1/deepOF_L2/h20
Evaluating performance on  test set...
1645/1645 - 12s - 12s/epoch - 8ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.61080426
{'0': {'precision': 0.34107795246500555, 'recall': 0.532673732797675, 'f1-score': 0.4158693349127037, 'support': 46796}, '1': {'precision': 0.8729093796646096, 'recall': 0.8361579337278323, 'f1-score': 0.8541385087790325, 'support': 328011}, '2': {'precision': 0.504255508436879, 'recall': 0.36806788172648164, 'f1-score': 0.4255308499856104, 'support': 46198}, 'accuracy': 0.7510599636583889, 'macro avg': {'precision': 0.5727476135221647, 'recall': 0.5789665160839963, 'f1-score': 0.5651795645591156, 'support': 421005}, 'weighted avg': {'precision': 0.7733413103775194, 'recall': 0.7510599636583889, 'f1-score': 0.7583912827812719, 'support': 421005}}
[[ 24927  17641   4228]
 [ 41253 274269  12489]
 [  6903  22291  17004]]
Evaluating performance on  train set...
653/653 - 5s - 5s/epoch - 8ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.70496356
{'0': {'precision': 0.4493628249031606, 'recall': 0.565589118530295, 'f1-score': 0.5008211978539362, 'support': 28305}, '1': {'precision': 0.8172631730362938, 'recall': 0.8197615698156765, 'f1-score': 0.8185104649225878, 'support': 110892}, '2': {'precision': 0.5322267085389562, 'recall': 0.38515926553876123, 'f1-score': 0.446904692143485, 'support': 27721}, 'accuracy': 0.7044836386728813, 'macro avg': {'precision': 0.5996175688261368, 'recall': 0.5901699846282443, 'f1-score': 0.5887454516400029, 'support': 166918}, 'weighted avg': {'precision': 0.7075391457520043, 'recall': 0.7044836386728813, 'f1-score': 0.7029238994737584, 'support': 166918}}
[[16009  8589  3707]
 [14310 90905  5677]
 [ 5307 11737 10677]]
Evaluating performance on  val set...
181/181 - 2s - 2s/epoch - 8ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.64601254
{'0': {'precision': 0.48175388967468175, 'recall': 0.4927662037037037, 'f1-score': 0.4871978257759977, 'support': 6912}, '1': {'precision': 0.8352499482661779, 'recall': 0.8631656126844469, 'f1-score': 0.8489783653846154, 'support': 32733}, '2': {'precision': 0.5151121824587428, 'recall': 0.41805869074492097, 'f1-score': 0.4615384615384615, 'support': 6645}, 'accuracy': 0.7439619788291207, 'macro avg': {'precision': 0.6107053401332009, 'recall': 0.5913301690443572, 'f1-score': 0.5992382175663582, 'support': 46290}, 'weighted avg': {'precision': 0.7365098270569572, 'recall': 0.7439619788291207, 'f1-score': 0.7393398851333202, 'support': 46290}}
[[ 3406  2600   906]
 [ 2770 28254  1709]
 [  894  2973  2778]]
training model: results/QRTEA/W1/deepOF_L2/h30
Epoch 1/50
653/653 - 17s - loss: 3.0343 - accuracy30: 0.4690 - val_loss: 2.8272 - val_accuracy30: 0.6236 - 17s/epoch - 25ms/step
Epoch 2/50
653/653 - 14s - loss: 2.7851 - accuracy30: 0.5484 - val_loss: 2.8168 - val_accuracy30: 0.6775 - 14s/epoch - 21ms/step
Epoch 3/50
653/653 - 14s - loss: 2.6707 - accuracy30: 0.5795 - val_loss: 2.7499 - val_accuracy30: 0.6911 - 14s/epoch - 21ms/step
Epoch 4/50
653/653 - 14s - loss: 2.5970 - accuracy30: 0.5974 - val_loss: 2.6828 - val_accuracy30: 0.6977 - 14s/epoch - 21ms/step
Epoch 5/50
653/653 - 14s - loss: 2.5481 - accuracy30: 0.6074 - val_loss: 2.6267 - val_accuracy30: 0.7004 - 14s/epoch - 21ms/step
Epoch 6/50
653/653 - 14s - loss: 2.5168 - accuracy30: 0.6141 - val_loss: 2.6276 - val_accuracy30: 0.7021 - 14s/epoch - 21ms/step
Epoch 7/50
653/653 - 14s - loss: 2.4903 - accuracy30: 0.6170 - val_loss: 2.6331 - val_accuracy30: 0.7038 - 14s/epoch - 21ms/step
Epoch 8/50
653/653 - 14s - loss: 2.4716 - accuracy30: 0.6213 - val_loss: 2.6023 - val_accuracy30: 0.7054 - 14s/epoch - 22ms/step
Epoch 9/50
653/653 - 14s - loss: 2.4529 - accuracy30: 0.6216 - val_loss: 2.5889 - val_accuracy30: 0.6974 - 14s/epoch - 21ms/step
Epoch 10/50
653/653 - 14s - loss: 2.4407 - accuracy30: 0.6232 - val_loss: 2.6140 - val_accuracy30: 0.7059 - 14s/epoch - 21ms/step
Epoch 11/50
653/653 - 14s - loss: 2.4225 - accuracy30: 0.6251 - val_loss: 2.5792 - val_accuracy30: 0.7009 - 14s/epoch - 22ms/step
Epoch 12/50
653/653 - 14s - loss: 2.4076 - accuracy30: 0.6286 - val_loss: 2.6276 - val_accuracy30: 0.7055 - 14s/epoch - 21ms/step
Epoch 13/50
653/653 - 14s - loss: 2.3954 - accuracy30: 0.6299 - val_loss: 2.6258 - val_accuracy30: 0.7097 - 14s/epoch - 21ms/step
Epoch 14/50
653/653 - 14s - loss: 2.3839 - accuracy30: 0.6323 - val_loss: 2.6211 - val_accuracy30: 0.7035 - 14s/epoch - 21ms/step
Epoch 15/50
653/653 - 14s - loss: 2.3656 - accuracy30: 0.6341 - val_loss: 2.6385 - val_accuracy30: 0.7044 - 14s/epoch - 21ms/step
Epoch 16/50
653/653 - 14s - loss: 2.3525 - accuracy30: 0.6366 - val_loss: 2.6433 - val_accuracy30: 0.7040 - 14s/epoch - 21ms/step
Epoch 17/50
653/653 - 14s - loss: 2.3410 - accuracy30: 0.6368 - val_loss: 2.6361 - val_accuracy30: 0.6963 - 14s/epoch - 21ms/step
Epoch 18/50
653/653 - 14s - loss: 2.3313 - accuracy30: 0.6393 - val_loss: 2.6449 - val_accuracy30: 0.6937 - 14s/epoch - 21ms/step
Epoch 19/50
653/653 - 14s - loss: 2.3169 - accuracy30: 0.6412 - val_loss: 2.6677 - val_accuracy30: 0.7001 - 14s/epoch - 21ms/step
Epoch 20/50
653/653 - 14s - loss: 2.3017 - accuracy30: 0.6438 - val_loss: 2.6641 - val_accuracy30: 0.6886 - 14s/epoch - 21ms/step
Epoch 21/50
653/653 - 14s - loss: 2.2913 - accuracy30: 0.6428 - val_loss: 2.6649 - val_accuracy30: 0.6860 - 14s/epoch - 21ms/step
testing model: results/QRTEA/W1/deepOF_L2/h30
Evaluating performance on  test set...
1645/1645 - 12s - 12s/epoch - 8ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.69816464
{'0': {'precision': 0.35583778966131907, 'recall': 0.53655043146131, 'f1-score': 0.42789654783393505, 'support': 56552}, '1': {'precision': 0.828487135958334, 'recall': 0.8136050810257871, 'f1-score': 0.8209786714879981, 'support': 308914}, '2': {'precision': 0.541337123084528, 'recall': 0.3154900160247754, 'f1-score': 0.39864857178609214, 'support': 55539}, 'accuracy': 0.7106780204510635, 'macro avg': {'precision': 0.5752206829013936, 'recall': 0.5552151761706242, 'f1-score': 0.5491745970360083, 'support': 421005}, 'weighted avg': {'precision': 0.7271171037810745, 'recall': 0.7106780204510635, 'f1-score': 0.712463638022294, 'support': 421005}}
[[ 30343  22425   3784]
 [ 46518 251334  11062]
 [  8411  29606  17522]]
Evaluating performance on  train set...
653/653 - 5s - 5s/epoch - 8ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.7764745
{'0': {'precision': 0.45914006732399076, 'recall': 0.5817829809117585, 'f1-score': 0.5132365499573015, 'support': 33057}, '1': {'precision': 0.7603461178671655, 'recall': 0.8007112529676587, 'f1-score': 0.7800068134599422, 'support': 101511}, '2': {'precision': 0.5697975842479731, 'recall': 0.31935085007727976, 'f1-score': 0.40930250985519306, 'support': 32350}, 'accuracy': 0.6640625936088379, 'macro avg': {'precision': 0.5964279231463765, 'recall': 0.5672816946522322, 'f1-score': 0.5675152910908122, 'support': 166918}, 'weighted avg': {'precision': 0.6637644821215503, 'recall': 0.6640625936088379, 'f1-score': 0.6553293741051666, 'support': 166918}}
[[19232 10574  3251]
 [15681 81281  4549]
 [ 6974 15045 10331]]
Evaluating performance on  val set...
181/181 - 2s - 2s/epoch - 8ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.7307801
{'0': {'precision': 0.4944796805261922, 'recall': 0.514041514041514, 'f1-score': 0.5040708812260536, 'support': 8190}, '1': {'precision': 0.7804788663571952, 'recall': 0.8464493905670376, 'f1-score': 0.812126604804881, 'support': 30192}, '2': {'precision': 0.5482909379968204, 'recall': 0.3488872028325746, 'f1-score': 0.4264296754250387, 'support': 7908}, 'accuracy': 0.7026355584359473, 'macro avg': {'precision': 0.6077498282934025, 'recall': 0.5697927024803754, 'f1-score': 0.5808757204853244, 'support': 46290}, 'weighted avg': {'precision': 0.6902115198583886, 'recall': 0.7026355584359473, 'f1-score': 0.6917319689516429, 'support': 46290}}
[[ 4210  3217   763]
 [ 3126 25556  1510]
 [ 1178  3971  2759]]
training model: results/QRTEA/W1/deepOF_L2/h50
Epoch 1/50
653/653 - 16s - loss: 3.0936 - accuracy50: 0.4537 - val_loss: 2.9680 - val_accuracy50: 0.5713 - 16s/epoch - 25ms/step
Epoch 2/50
653/653 - 14s - loss: 2.8932 - accuracy50: 0.5180 - val_loss: 2.9903 - val_accuracy50: 0.6094 - 14s/epoch - 22ms/step
Epoch 3/50
653/653 - 14s - loss: 2.8109 - accuracy50: 0.5407 - val_loss: 2.9283 - val_accuracy50: 0.6277 - 14s/epoch - 22ms/step
Epoch 4/50
653/653 - 14s - loss: 2.7551 - accuracy50: 0.5535 - val_loss: 2.9547 - val_accuracy50: 0.6308 - 14s/epoch - 21ms/step
Epoch 5/50
653/653 - 14s - loss: 2.7216 - accuracy50: 0.5618 - val_loss: 2.8615 - val_accuracy50: 0.6342 - 14s/epoch - 22ms/step
Epoch 6/50
653/653 - 14s - loss: 2.6786 - accuracy50: 0.5737 - val_loss: 2.8310 - val_accuracy50: 0.6349 - 14s/epoch - 22ms/step
Epoch 7/50
653/653 - 14s - loss: 2.6554 - accuracy50: 0.5804 - val_loss: 2.8238 - val_accuracy50: 0.6330 - 14s/epoch - 22ms/step
Epoch 8/50
653/653 - 14s - loss: 2.6326 - accuracy50: 0.5856 - val_loss: 2.8223 - val_accuracy50: 0.6363 - 14s/epoch - 21ms/step
Epoch 9/50
653/653 - 14s - loss: 2.6168 - accuracy50: 0.5889 - val_loss: 2.8226 - val_accuracy50: 0.6339 - 14s/epoch - 21ms/step
Epoch 10/50
653/653 - 14s - loss: 2.5997 - accuracy50: 0.5915 - val_loss: 2.8290 - val_accuracy50: 0.6374 - 14s/epoch - 21ms/step
Epoch 11/50
653/653 - 14s - loss: 2.5837 - accuracy50: 0.5941 - val_loss: 2.8257 - val_accuracy50: 0.6345 - 14s/epoch - 21ms/step
Epoch 12/50
653/653 - 14s - loss: 2.5694 - accuracy50: 0.5973 - val_loss: 2.8106 - val_accuracy50: 0.6380 - 14s/epoch - 21ms/step
Epoch 13/50
653/653 - 14s - loss: 2.5530 - accuracy50: 0.5992 - val_loss: 2.8357 - val_accuracy50: 0.6334 - 14s/epoch - 21ms/step
Epoch 14/50
653/653 - 14s - loss: 2.5422 - accuracy50: 0.6014 - val_loss: 2.8691 - val_accuracy50: 0.6297 - 14s/epoch - 21ms/step
Epoch 15/50
653/653 - 14s - loss: 2.5247 - accuracy50: 0.6032 - val_loss: 2.8534 - val_accuracy50: 0.6278 - 14s/epoch - 21ms/step
Epoch 16/50
653/653 - 14s - loss: 2.5106 - accuracy50: 0.6055 - val_loss: 2.8539 - val_accuracy50: 0.6247 - 14s/epoch - 21ms/step
Epoch 17/50
653/653 - 14s - loss: 2.4966 - accuracy50: 0.6091 - val_loss: 2.8862 - val_accuracy50: 0.6317 - 14s/epoch - 21ms/step
Epoch 18/50
653/653 - 14s - loss: 2.4836 - accuracy50: 0.6107 - val_loss: 2.8938 - val_accuracy50: 0.6310 - 14s/epoch - 21ms/step
Epoch 19/50
653/653 - 14s - loss: 2.4678 - accuracy50: 0.6142 - val_loss: 2.9112 - val_accuracy50: 0.6211 - 14s/epoch - 21ms/step
Epoch 20/50
653/653 - 14s - loss: 2.4541 - accuracy50: 0.6148 - val_loss: 2.9564 - val_accuracy50: 0.6188 - 14s/epoch - 21ms/step
Epoch 21/50
653/653 - 14s - loss: 2.4361 - accuracy50: 0.6182 - val_loss: 2.9384 - val_accuracy50: 0.6097 - 14s/epoch - 21ms/step
Epoch 22/50
653/653 - 14s - loss: 2.4232 - accuracy50: 0.6209 - val_loss: 2.9683 - val_accuracy50: 0.6087 - 14s/epoch - 21ms/step
testing model: results/QRTEA/W1/deepOF_L2/h50
Evaluating performance on  test set...
1645/1645 - 12s - 12s/epoch - 8ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.7969034
{'0': {'precision': 0.39993581220485075, 'recall': 0.4739859265900508, 'f1-score': 0.4338236208332815, 'support': 73614}, '1': {'precision': 0.7465934904192445, 'recall': 0.8004733487979908, 'f1-score': 0.7725951798812435, 'support': 276329}, '2': {'precision': 0.5319018404907976, 'recall': 0.28061411162083816, 'f1-score': 0.3673999557815609, 'support': 71062}, 'accuracy': 0.655638294082018, 'macro avg': {'precision': 0.5594770477049643, 'recall': 0.5183577956696266, 'f1-score': 0.5246062521653619, 'support': 421005}, 'weighted avg': {'precision': 0.6497412526755367, 'recall': 0.655638294082018, 'f1-score': 0.6449664995503013, 'support': 421005}}
[[ 34892  33701   5021]
 [ 42607 221194  12528]
 [  9745  41376  19941]]
Evaluating performance on  train set...
653/653 - 5s - 5s/epoch - 8ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.8625869
{'0': {'precision': 0.4915014498220137, 'recall': 0.5201067704435464, 'f1-score': 0.5053996727471063, 'support': 40086}, '1': {'precision': 0.6644197399031311, 'recall': 0.797233757765041, 'f1-score': 0.7247926363139967, 'support': 87411}, '2': {'precision': 0.5855722661228652, 'recall': 0.2913675452170163, 'f1-score': 0.3891185039636832, 'support': 39421}, 'accuracy': 0.611210294875328, 'macro avg': {'precision': 0.5804978186160032, 'recall': 0.5362360244752012, 'f1-score': 0.539770271008262, 'support': 166918}, 'weighted avg': {'precision': 0.6042713506336482, 'recall': 0.611210294875328, 'f1-score': 0.5928284604376738, 'support': 166918}}
[[20849 15231  4006]
 [13601 69687  4123]
 [ 7969 19966 11486]]
Evaluating performance on  val set...
181/181 - 1s - 1s/epoch - 8ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.8371175
{'0': {'precision': 0.5280859916782247, 'recall': 0.44132135612865836, 'f1-score': 0.4808208366219416, 'support': 10353}, '1': {'precision': 0.6794415379376528, 'recall': 0.8395685104429653, 'f1-score': 0.7510651039438789, 'support': 26142}, '2': {'precision': 0.5625117150890346, 'recall': 0.3063808065339459, 'f1-score': 0.39669530733641767, 'support': 9795}, 'accuracy': 0.6376755238712465, 'macro avg': {'precision': 0.5900130815683041, 'recall': 0.5290902243685233, 'f1-score': 0.5428604159674127, 'support': 46290}, 'weighted avg': {'precision': 0.6208476389265041, 'recall': 0.6376755238712465, 'f1-score': 0.6156386391058124, 'support': 46290}}
[[ 4569  4913   871]
 [ 2731 21948  1463]
 [ 1352  5442  3001]]
training model: results/QRTEA/W1/deepOF_L2/h100
Epoch 1/50
653/653 - 16s - loss: 3.1941 - accuracy100: 0.4208 - val_loss: 3.1719 - val_accuracy100: 0.4666 - 16s/epoch - 25ms/step
Epoch 2/50
653/653 - 15s - loss: 3.0656 - accuracy100: 0.4652 - val_loss: 3.2541 - val_accuracy100: 0.4804 - 15s/epoch - 22ms/step
Epoch 3/50
653/653 - 15s - loss: 3.0148 - accuracy100: 0.4823 - val_loss: 3.2172 - val_accuracy100: 0.4895 - 15s/epoch - 22ms/step
Epoch 4/50
653/653 - 14s - loss: 2.9823 - accuracy100: 0.4908 - val_loss: 3.2303 - val_accuracy100: 0.4965 - 14s/epoch - 22ms/step
Epoch 5/50
653/653 - 14s - loss: 2.9574 - accuracy100: 0.4982 - val_loss: 3.2482 - val_accuracy100: 0.4996 - 14s/epoch - 21ms/step
Epoch 6/50
653/653 - 14s - loss: 2.9394 - accuracy100: 0.5011 - val_loss: 3.2006 - val_accuracy100: 0.5027 - 14s/epoch - 22ms/step
Epoch 7/50
653/653 - 14s - loss: 2.9174 - accuracy100: 0.5076 - val_loss: 3.2037 - val_accuracy100: 0.5063 - 14s/epoch - 22ms/step
Epoch 8/50
653/653 - 14s - loss: 2.8967 - accuracy100: 0.5150 - val_loss: 3.1674 - val_accuracy100: 0.5064 - 14s/epoch - 22ms/step
Epoch 9/50
653/653 - 14s - loss: 2.8814 - accuracy100: 0.5191 - val_loss: 3.1337 - val_accuracy100: 0.5103 - 14s/epoch - 22ms/step
Epoch 10/50
653/653 - 14s - loss: 2.8650 - accuracy100: 0.5242 - val_loss: 3.1410 - val_accuracy100: 0.5118 - 14s/epoch - 22ms/step
Epoch 11/50
653/653 - 14s - loss: 2.8509 - accuracy100: 0.5280 - val_loss: 3.1321 - val_accuracy100: 0.5134 - 14s/epoch - 21ms/step
Epoch 12/50
653/653 - 14s - loss: 2.8374 - accuracy100: 0.5313 - val_loss: 3.1328 - val_accuracy100: 0.5125 - 14s/epoch - 21ms/step
Epoch 13/50
653/653 - 14s - loss: 2.8279 - accuracy100: 0.5339 - val_loss: 3.1253 - val_accuracy100: 0.5126 - 14s/epoch - 21ms/step
Epoch 14/50
653/653 - 14s - loss: 2.8148 - accuracy100: 0.5388 - val_loss: 3.1255 - val_accuracy100: 0.5139 - 14s/epoch - 21ms/step
Epoch 15/50
653/653 - 14s - loss: 2.7994 - accuracy100: 0.5432 - val_loss: 3.1149 - val_accuracy100: 0.5114 - 14s/epoch - 21ms/step
Epoch 16/50
653/653 - 14s - loss: 2.7888 - accuracy100: 0.5462 - val_loss: 3.1282 - val_accuracy100: 0.5136 - 14s/epoch - 21ms/step
Epoch 17/50
653/653 - 14s - loss: 2.7760 - accuracy100: 0.5492 - val_loss: 3.1163 - val_accuracy100: 0.5070 - 14s/epoch - 21ms/step
Epoch 18/50
653/653 - 14s - loss: 2.7597 - accuracy100: 0.5554 - val_loss: 3.1483 - val_accuracy100: 0.5035 - 14s/epoch - 21ms/step
Epoch 19/50
653/653 - 14s - loss: 2.7456 - accuracy100: 0.5582 - val_loss: 3.1501 - val_accuracy100: 0.5054 - 14s/epoch - 21ms/step
Epoch 20/50
653/653 - 14s - loss: 2.7285 - accuracy100: 0.5638 - val_loss: 3.2001 - val_accuracy100: 0.4862 - 14s/epoch - 21ms/step
Epoch 21/50
653/653 - 14s - loss: 2.7196 - accuracy100: 0.5656 - val_loss: 3.2133 - val_accuracy100: 0.4960 - 14s/epoch - 22ms/step
Epoch 22/50
653/653 - 14s - loss: 2.7034 - accuracy100: 0.5703 - val_loss: 3.2306 - val_accuracy100: 0.4921 - 14s/epoch - 21ms/step
Epoch 23/50
653/653 - 14s - loss: 2.6785 - accuracy100: 0.5760 - val_loss: 3.2602 - val_accuracy100: 0.4941 - 14s/epoch - 22ms/step
Epoch 24/50
653/653 - 14s - loss: 2.6538 - accuracy100: 0.5824 - val_loss: 3.2876 - val_accuracy100: 0.4964 - 14s/epoch - 21ms/step
Epoch 25/50
653/653 - 14s - loss: 2.6317 - accuracy100: 0.5882 - val_loss: 3.3620 - val_accuracy100: 0.4940 - 14s/epoch - 21ms/step
testing model: results/QRTEA/W1/deepOF_L2/h100
Evaluating performance on  test set...
1645/1645 - 12s - 12s/epoch - 8ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 0.97135484
{'0': {'precision': 0.4406824478909187, 'recall': 0.3635199726869239, 'f1-score': 0.3983993763804079, 'support': 105444}, '1': {'precision': 0.5861168375057612, 'recall': 0.7587320087320087, 'f1-score': 0.6613465992352487, 'support': 216216}, '2': {'precision': 0.47386894755315806, 'recall': 0.2582012179777543, 'f1-score': 0.334267246996273, 'support': 99345}, 'accuracy': 0.5416372727164761, 'macro avg': {'precision': 0.5002227443166126, 'recall': 0.4601510664655623, 'f1-score': 0.4646710742039766, 'support': 421005}, 'weighted avg': {'precision': 0.5232044008223754, 'recall': 0.5416372727164761, 'f1-score': 0.5183081431245449, 'support': 421005}}
[[ 38331  57630   9483]
 [ 33169 164050  18997]
 [ 15481  58213  25651]]
Evaluating performance on  train set...
653/653 - 5s - 5s/epoch - 8ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 0.9968944
{'0': {'precision': 0.5256608922913245, 'recall': 0.4420155973472841, 'f1-score': 0.4802231237322515, 'support': 51419}, '1': {'precision': 0.506952420016407, 'recall': 0.7658275888777012, 'f1-score': 0.6100632423260836, 'support': 64555}, '2': {'precision': 0.5590764879018386, 'recall': 0.2870995603015075, 'f1-score': 0.3793787692108164, 'support': 50944}, 'accuracy': 0.5199678884242562, 'macro avg': {'precision': 0.5305632667365233, 'recall': 0.4983142488421642, 'f1-score': 0.4898883784230505, 'support': 166918}, 'weighted avg': {'precision': 0.5286240159512936, 'recall': 0.5199678884242562, 'f1-score': 0.49966029682972957, 'support': 166918}}
[[22728 22719  5972]
 [ 9554 49438  5563]
 [10955 25363 14626]]
Evaluating performance on  val set...
181/181 - 2s - 2s/epoch - 8ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0137143
{'0': {'precision': 0.5456340500219394, 'recall': 0.3508747178329571, 'f1-score': 0.4270994332818135, 'support': 14176}, '1': {'precision': 0.5008175500749421, 'recall': 0.7730164572269835, 'f1-score': 0.6078346253229975, 'support': 19019}, '2': {'precision': 0.5089536965975953, 'recall': 0.303856433753341, 'f1-score': 0.38052885764835265, 'support': 13095}, 'accuracy': 0.5110174983797796, 'macro avg': {'precision': 0.5184684322314923, 'recall': 0.4759158696044272, 'f1-score': 0.47182097208438795, 'support': 46290}, 'weighted avg': {'precision': 0.5168439389702278, 'recall': 0.5110174983797796, 'f1-score': 0.4881830567320427, 'support': 46290}}
[[ 4974  7600  1602]
 [ 2080 14702  2237]
 [ 2062  7054  3979]]
training model: results/QRTEA/W1/deepOF_L2/h200
Epoch 1/50
653/653 - 17s - loss: 3.2614 - accuracy200: 0.3902 - val_loss: 3.2658 - val_accuracy200: 0.3757 - 17s/epoch - 26ms/step
Epoch 2/50
653/653 - 14s - loss: 3.1963 - accuracy200: 0.4185 - val_loss: 3.2627 - val_accuracy200: 0.3804 - 14s/epoch - 22ms/step
Epoch 3/50
653/653 - 14s - loss: 3.1685 - accuracy200: 0.4290 - val_loss: 3.2648 - val_accuracy200: 0.3808 - 14s/epoch - 21ms/step
Epoch 4/50
653/653 - 14s - loss: 3.1510 - accuracy200: 0.4344 - val_loss: 3.2790 - val_accuracy200: 0.3834 - 14s/epoch - 21ms/step
Epoch 5/50
653/653 - 14s - loss: 3.1379 - accuracy200: 0.4387 - val_loss: 3.2856 - val_accuracy200: 0.3856 - 14s/epoch - 21ms/step
Epoch 6/50
653/653 - 14s - loss: 3.1261 - accuracy200: 0.4427 - val_loss: 3.2869 - val_accuracy200: 0.3876 - 14s/epoch - 21ms/step
Epoch 7/50
653/653 - 14s - loss: 3.1167 - accuracy200: 0.4463 - val_loss: 3.2807 - val_accuracy200: 0.3913 - 14s/epoch - 21ms/step
Epoch 8/50
653/653 - 14s - loss: 3.1102 - accuracy200: 0.4482 - val_loss: 3.2892 - val_accuracy200: 0.3902 - 14s/epoch - 21ms/step
Epoch 9/50
653/653 - 14s - loss: 3.0979 - accuracy200: 0.4526 - val_loss: 3.2999 - val_accuracy200: 0.3900 - 14s/epoch - 21ms/step
Epoch 10/50
653/653 - 14s - loss: 3.0902 - accuracy200: 0.4533 - val_loss: 3.2910 - val_accuracy200: 0.3929 - 14s/epoch - 21ms/step
Epoch 11/50
653/653 - 14s - loss: 3.0823 - accuracy200: 0.4566 - val_loss: 3.2747 - val_accuracy200: 0.3946 - 14s/epoch - 21ms/step
Epoch 12/50
653/653 - 14s - loss: 3.0752 - accuracy200: 0.4595 - val_loss: 3.2639 - val_accuracy200: 0.3982 - 14s/epoch - 21ms/step
testing model: results/QRTEA/W1/deepOF_L2/h200
Evaluating performance on  test set...
1645/1645 - 13s - 13s/epoch - 8ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0661347
{'0': {'precision': 0.4339649701511267, 'recall': 0.18257996877427723, 'f1-score': 0.25702363508950754, 'support': 132583}, '1': {'precision': 0.42015114959975713, 'recall': 0.7976896848798126, 'f1-score': 0.5504007233742394, 'support': 164826}, '2': {'precision': 0.4418520147640995, 'recall': 0.18693161590989998, 'f1-score': 0.26271711629758077, 'support': 123596}, 'accuracy': 0.42467666654790326, 'macro avg': {'precision': 0.4319893781716611, 'recall': 0.38906708985466326, 'f1-score': 0.3567138249204425, 'support': 421005}, 'weighted avg': {'precision': 0.4308722049340508, 'recall': 0.42467666654790326, 'f1-score': 0.3735539932966838, 'support': 421005}}
[[ 24207  94779  13597]
 [ 17758 131480  15588]
 [ 13816  86676  23104]]
Evaluating performance on  train set...
653/653 - 5s - 5s/epoch - 8ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0847657
{'0': {'precision': 0.48484536436343667, 'recall': 0.24231039747482544, 'f1-score': 0.3231304188685288, 'support': 58293}, '1': {'precision': 0.35591128567310465, 'recall': 0.7546366154140006, 'f1-score': 0.48369581851459637, 'support': 52355}, '2': {'precision': 0.4468760503417112, 'recall': 0.2126532788341923, 'f1-score': 0.2881741664358737, 'support': 56270}, 'accuracy': 0.3930073449238548, 'macro avg': {'precision': 0.4292109001260842, 'recall': 0.40320009724100614, 'f1-score': 0.36500013460633296, 'support': 166918}, 'weighted avg': {'precision': 0.4316043898140482, 'recall': 0.3930073449238548, 'f1-score': 0.3617087218321658, 'support': 166918}}
[[14125 35226  8942]
 [ 6977 39509  5869]
 [ 8031 36273 11966]]
Evaluating performance on  val set...
181/181 - 1s - 1s/epoch - 8ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0949703
{'0': {'precision': 0.4961876832844575, 'recall': 0.20219885277246655, 'f1-score': 0.2873153336729496, 'support': 16736}, '1': {'precision': 0.33590029071565536, 'recall': 0.7600419874037788, 'f1-score': 0.4658973919011668, 'support': 14290}, '2': {'precision': 0.45992152466367714, 'recall': 0.21501572327044025, 'f1-score': 0.2930357142857143, 'support': 15264}, 'accuracy': 0.3786346943184273, 'macro avg': {'precision': 0.43066983288793, 'recall': 0.3924188544822285, 'f1-score': 0.3487494799532769, 'support': 46290}, 'weighted avg': {'precision': 0.43474734012187866, 'recall': 0.3786346943184273, 'f1-score': 0.3443309634364939, 'support': 46290}}
[[ 3384 11295  2057]
 [ 1632 10861  1797]
 [ 1804 10178  3282]]
training model: results/QRTEA/W1/deepOF_L2/h300
Epoch 1/50
653/653 - 17s - loss: 3.2917 - accuracy300: 0.3725 - val_loss: 3.2875 - val_accuracy300: 0.3541 - 17s/epoch - 26ms/step
Epoch 2/50
653/653 - 15s - loss: 3.2526 - accuracy300: 0.3910 - val_loss: 3.2764 - val_accuracy300: 0.3590 - 15s/epoch - 22ms/step
Epoch 3/50
653/653 - 14s - loss: 3.2387 - accuracy300: 0.3982 - val_loss: 3.2789 - val_accuracy300: 0.3620 - 14s/epoch - 22ms/step
Epoch 4/50
653/653 - 15s - loss: 3.2299 - accuracy300: 0.4034 - val_loss: 3.2726 - val_accuracy300: 0.3633 - 15s/epoch - 22ms/step
Epoch 5/50
653/653 - 14s - loss: 3.2227 - accuracy300: 0.4071 - val_loss: 3.2852 - val_accuracy300: 0.3573 - 14s/epoch - 22ms/step
Epoch 6/50
653/653 - 14s - loss: 3.2170 - accuracy300: 0.4100 - val_loss: 3.2777 - val_accuracy300: 0.3620 - 14s/epoch - 22ms/step
Epoch 7/50
653/653 - 14s - loss: 3.2116 - accuracy300: 0.4127 - val_loss: 3.2806 - val_accuracy300: 0.3630 - 14s/epoch - 22ms/step
Epoch 8/50
653/653 - 14s - loss: 3.2063 - accuracy300: 0.4164 - val_loss: 3.2801 - val_accuracy300: 0.3638 - 14s/epoch - 21ms/step
Epoch 9/50
653/653 - 14s - loss: 3.1989 - accuracy300: 0.4194 - val_loss: 3.2809 - val_accuracy300: 0.3650 - 14s/epoch - 21ms/step
Epoch 10/50
653/653 - 14s - loss: 3.1947 - accuracy300: 0.4202 - val_loss: 3.2905 - val_accuracy300: 0.3636 - 14s/epoch - 21ms/step
Epoch 11/50
653/653 - 14s - loss: 3.1885 - accuracy300: 0.4225 - val_loss: 3.3051 - val_accuracy300: 0.3610 - 14s/epoch - 21ms/step
Epoch 12/50
653/653 - 14s - loss: 3.1820 - accuracy300: 0.4257 - val_loss: 3.2948 - val_accuracy300: 0.3631 - 14s/epoch - 21ms/step
Epoch 13/50
653/653 - 14s - loss: 3.1774 - accuracy300: 0.4278 - val_loss: 3.3118 - val_accuracy300: 0.3632 - 14s/epoch - 21ms/step
Epoch 14/50
653/653 - 14s - loss: 3.1713 - accuracy300: 0.4310 - val_loss: 3.3136 - val_accuracy300: 0.3624 - 14s/epoch - 21ms/step
testing model: results/QRTEA/W1/deepOF_L2/h300
Evaluating performance on  test set...
1645/1645 - 12s - 12s/epoch - 8ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0779858
{'0': {'precision': 0.38463010097985395, 'recall': 0.34258936840155585, 'f1-score': 0.3623945422555908, 'support': 134975}, '1': {'precision': 0.3893124130201855, 'recall': 0.5828452371440688, 'f1-score': 0.46681499785871455, 'support': 162707}, '2': {'precision': 0.38017554902783607, 'recall': 0.17630936646043316, 'f1-score': 0.2408996482286791, 'support': 123323}, 'accuracy': 0.3867341242978112, 'macro avg': {'precision': 0.38470602100929185, 'recall': 0.3672479906686859, 'f1-score': 0.35670306278099484, 'support': 421005}, 'weighted avg': {'precision': 0.3851348366356479, 'recall': 0.3867341242978112, 'f1-score': 0.3671612890964517, 'support': 421005}}
[[46241 75202 13532]
 [45957 94833 21917]
 [28024 73556 21743]]
Evaluating performance on  train set...
653/653 - 5s - 5s/epoch - 8ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0854025
{'0': {'precision': 0.409900688213259, 'recall': 0.332186099050443, 'f1-score': 0.3669740870006044, 'support': 56658}, '1': {'precision': 0.35089353950522933, 'recall': 0.5949481681340528, 'f1-score': 0.44143426294820715, 'support': 56336}, '2': {'precision': 0.41635600204057605, 'recall': 0.19675840071211334, 'f1-score': 0.26723084866573477, 'support': 53924}, 'accuracy': 0.3771193040894331, 'macro avg': {'precision': 0.3923834099196881, 'recall': 0.3746308892988697, 'f1-score': 0.3585463995381821, 'support': 166918}, 'weighted avg': {'precision': 0.3920707933739288, 'recall': 0.3771193040894331, 'f1-score': 0.3598821861164256, 'support': 166918}}
[[18821 30785  7052]
 [14998 33517  7821]
 [12097 31217 10610]]
Evaluating performance on  val set...
181/181 - 2s - 2s/epoch - 8ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0893393
{'0': {'precision': 0.4210432773482627, 'recall': 0.29272210552329175, 'f1-score': 0.3453478625314334, 'support': 16186}, '1': {'precision': 0.33407885718408425, 'recall': 0.6099585062240664, 'f1-score': 0.4317079992541488, 'support': 15183}, '2': {'precision': 0.41566429743028976, 'recall': 0.2038067153676027, 'f1-score': 0.2735081171021271, 'support': 14921}, 'accuracy': 0.3681140635126377, 'macro avg': {'precision': 0.39026214398754555, 'recall': 0.3688291090383203, 'f1-score': 0.3501879929625698, 'support': 46290}, 'weighted avg': {'precision': 0.3907853263716199, 'recall': 0.3681140635126377, 'f1-score': 0.35051712402009855, 'support': 46290}}
[[4738 9529 1919]
 [3566 9261 2356]
 [2949 8931 3041]]
training model: results/QRTEA/W1/deepOF_L2/h500
Epoch 1/50
653/653 - 17s - loss: 3.2898 - accuracy500: 0.3874 - val_loss: 3.2621 - val_accuracy500: 0.4036 - 17s/epoch - 25ms/step
Epoch 2/50
653/653 - 15s - loss: 3.2660 - accuracy500: 0.3965 - val_loss: 3.2766 - val_accuracy500: 0.3985 - 15s/epoch - 22ms/step
Epoch 3/50
653/653 - 14s - loss: 3.2666 - accuracy500: 0.3906 - val_loss: 3.2450 - val_accuracy500: 0.4114 - 14s/epoch - 22ms/step
Epoch 4/50
653/653 - 14s - loss: 3.2607 - accuracy500: 0.3907 - val_loss: 3.2409 - val_accuracy500: 0.4124 - 14s/epoch - 21ms/step
Epoch 5/50
653/653 - 14s - loss: 3.2582 - accuracy500: 0.3900 - val_loss: 3.2448 - val_accuracy500: 0.4110 - 14s/epoch - 21ms/step
Epoch 6/50
653/653 - 14s - loss: 3.2519 - accuracy500: 0.3921 - val_loss: 3.2511 - val_accuracy500: 0.4121 - 14s/epoch - 21ms/step
Epoch 7/50
653/653 - 14s - loss: 3.2469 - accuracy500: 0.3948 - val_loss: 3.2589 - val_accuracy500: 0.4136 - 14s/epoch - 21ms/step
Epoch 8/50
653/653 - 14s - loss: 3.2419 - accuracy500: 0.3995 - val_loss: 3.2642 - val_accuracy500: 0.4099 - 14s/epoch - 21ms/step
Epoch 9/50
653/653 - 14s - loss: 3.2362 - accuracy500: 0.4036 - val_loss: 3.2689 - val_accuracy500: 0.4033 - 14s/epoch - 21ms/step
Epoch 10/50
653/653 - 14s - loss: 3.2320 - accuracy500: 0.4054 - val_loss: 3.2703 - val_accuracy500: 0.4005 - 14s/epoch - 21ms/step
Epoch 11/50
653/653 - 14s - loss: 3.2286 - accuracy500: 0.4079 - val_loss: 3.2718 - val_accuracy500: 0.3939 - 14s/epoch - 21ms/step
Epoch 12/50
653/653 - 14s - loss: 3.2240 - accuracy500: 0.4094 - val_loss: 3.2764 - val_accuracy500: 0.3880 - 14s/epoch - 21ms/step
Epoch 13/50
653/653 - 14s - loss: 3.2201 - accuracy500: 0.4124 - val_loss: 3.2763 - val_accuracy500: 0.3872 - 14s/epoch - 21ms/step
Epoch 14/50
653/653 - 14s - loss: 3.2158 - accuracy500: 0.4141 - val_loss: 3.2800 - val_accuracy500: 0.3808 - 14s/epoch - 21ms/step
testing model: results/QRTEA/W1/deepOF_L2/h500
Evaluating performance on  test set...
1645/1645 - 12s - 12s/epoch - 8ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0877326
{'0': {'precision': 0.4059189473893427, 'recall': 0.6567767994391526, 'f1-score': 0.5017393696995903, 'support': 155479}, '1': {'precision': 0.3824344758064516, 'recall': 0.023794403807104608, 'f1-score': 0.04480134625462221, 'support': 127551}, '2': {'precision': 0.37683896374083614, 'recall': 0.44110164884942926, 'f1-score': 0.4064458609785661, 'support': 137975}, 'accuracy': 0.39432073253286776, 'macro avg': {'precision': 0.3883974623122102, 'recall': 0.37389095069856215, 'f1-score': 0.3176621923109262, 'support': 421005}, 'weighted avg': {'precision': 0.38927359025873376, 'recall': 0.39432073253286776, 'f1-score': 0.3320714947474818, 'support': 421005}}
[[102115   2583  50781]
 [ 74654   3035  49862]
 [ 74796   2318  60861]]
Evaluating performance on  train set...
653/653 - 5s - 5s/epoch - 8ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.096379
{'0': {'precision': 0.3766414319695011, 'recall': 0.5973746317766025, 'f1-score': 0.4619965627040062, 'support': 58049}, '1': {'precision': 0.3720083246618106, 'recall': 0.02551384527547816, 'f1-score': 0.04775262138515995, 'support': 56048}, '2': {'precision': 0.36100274628547285, 'recall': 0.48528047556842924, 'f1-score': 0.41401644242727703, 'support': 52821}, 'accuracy': 0.36988221761583534, 'macro avg': {'precision': 0.3698841676389282, 'recall': 0.36938965087350334, 'f1-score': 0.30792187550548106, 'support': 166918}, 'weighted avg': {'precision': 0.3701368763499904, 'recall': 0.36988221761583534, 'f1-score': 0.307717800939692, 'support': 166918}}
[[34677  1294 22078]
 [31324  1430 23294]
 [26068  1120 25633]]
Evaluating performance on  val set...
181/181 - 2s - 2s/epoch - 8ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.080335
{'0': {'precision': 0.4255837723091438, 'recall': 0.6010437486120365, 'f1-score': 0.498319907940161, 'support': 18012}, '1': {'precision': 0.323189926547744, 'recall': 0.025660251603765727, 'f1-score': 0.047545538746526714, 'support': 12003}, '2': {'precision': 0.39931654857027993, 'recall': 0.4882334869431644, 'f1-score': 0.43932105932437665, 'support': 16275}, 'accuracy': 0.4121840570317563, 'macro avg': {'precision': 0.3826967491423892, 'recall': 0.3716458290529889, 'f1-score': 0.3283955020036881, 'support': 46290}, 'weighted avg': {'precision': 0.3897978056419567, 'recall': 0.4121840570317563, 'f1-score': 0.360690808466126, 'support': 46290}}
[[10826   347  6839]
 [ 6581   308  5114]
 [ 8031   298  7946]]
training model: results/QRTEA/W1/deepOF_L2/h1000
Epoch 1/50
653/653 - 17s - loss: 3.2893 - accuracy1000: 0.3928 - val_loss: 3.2567 - val_accuracy1000: 0.3616 - 17s/epoch - 26ms/step
Epoch 2/50
653/653 - 15s - loss: 3.2757 - accuracy1000: 0.3910 - val_loss: 3.2140 - val_accuracy1000: 0.4042 - 15s/epoch - 23ms/step
Epoch 3/50
653/653 - 15s - loss: 3.2808 - accuracy1000: 0.3861 - val_loss: 3.1763 - val_accuracy1000: 0.3873 - 15s/epoch - 22ms/step
Epoch 4/50
653/653 - 14s - loss: 3.2806 - accuracy1000: 0.3851 - val_loss: 3.1759 - val_accuracy1000: 0.3965 - 14s/epoch - 22ms/step
Epoch 5/50
653/653 - 14s - loss: 3.2775 - accuracy1000: 0.3845 - val_loss: 3.1774 - val_accuracy1000: 0.3969 - 14s/epoch - 22ms/step
Epoch 6/50
653/653 - 14s - loss: 3.2738 - accuracy1000: 0.3849 - val_loss: 3.1787 - val_accuracy1000: 0.3974 - 14s/epoch - 22ms/step
Epoch 7/50
653/653 - 15s - loss: 3.2699 - accuracy1000: 0.3867 - val_loss: 3.1779 - val_accuracy1000: 0.3977 - 15s/epoch - 23ms/step
Epoch 8/50
653/653 - 14s - loss: 3.2647 - accuracy1000: 0.3906 - val_loss: 3.1766 - val_accuracy1000: 0.4017 - 14s/epoch - 22ms/step
Epoch 9/50
653/653 - 14s - loss: 3.2611 - accuracy1000: 0.3931 - val_loss: 3.1782 - val_accuracy1000: 0.4008 - 14s/epoch - 22ms/step
Epoch 10/50
653/653 - 14s - loss: 3.2547 - accuracy1000: 0.3964 - val_loss: 3.1787 - val_accuracy1000: 0.4045 - 14s/epoch - 22ms/step
Epoch 11/50
653/653 - 14s - loss: 3.2489 - accuracy1000: 0.3988 - val_loss: 3.1814 - val_accuracy1000: 0.4024 - 14s/epoch - 21ms/step
Epoch 12/50
653/653 - 14s - loss: 3.2438 - accuracy1000: 0.4039 - val_loss: 3.1827 - val_accuracy1000: 0.4045 - 14s/epoch - 22ms/step
Epoch 13/50
653/653 - 14s - loss: 3.2375 - accuracy1000: 0.4091 - val_loss: 3.1842 - val_accuracy1000: 0.4024 - 14s/epoch - 22ms/step
Epoch 14/50
653/653 - 14s - loss: 3.2321 - accuracy1000: 0.4122 - val_loss: 3.1843 - val_accuracy1000: 0.4030 - 14s/epoch - 22ms/step
testing model: results/QRTEA/W1/deepOF_L2/h1000
Evaluating performance on  test set...
1645/1645 - 13s - 13s/epoch - 8ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0644987
{'0': {'precision': 0.4626769817509954, 'recall': 0.26682925161540305, 'f1-score': 0.33846387360006364, 'support': 175498}, '1': {'precision': 0.23392612859097128, 'recall': 0.008018569318421608, 'f1-score': 0.015505633260036726, 'support': 85302}, '2': {'precision': 0.39671474106100296, 'recall': 0.784663400018726, 'f1-score': 0.5269905151181681, 'support': 160205}, 'accuracy': 0.41144166933884396, 'macro avg': {'precision': 0.36443928380098994, 'recall': 0.3531704069841835, 'f1-score': 0.29365334065942283, 'support': 421005}, 'weighted avg': {'precision': 0.39122798222368194, 'recall': 0.41144166933884396, 'f1-score': 0.3447676628351628, 'support': 421005}}
[[ 46828   1213 127457]
 [ 20912    684  63706]
 [ 33471   1027 125707]]
Evaluating performance on  train set...
653/653 - 5s - 5s/epoch - 8ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1098655
{'0': {'precision': 0.397113133312414, 'recall': 0.27526435550796413, 'f1-score': 0.32514797869502055, 'support': 59768}, '1': {'precision': 0.3088967971530249, 'recall': 0.008093240093240093, 'f1-score': 0.01577321461021261, 'support': 53625}, '2': {'precision': 0.33505528512942845, 'recall': 0.7767398411957029, 'f1-score': 0.4681632124498196, 'support': 53525}, 'accuracy': 0.3502378413352664, 'macro avg': {'precision': 0.3470217385316225, 'recall': 0.35336581226563574, 'f1-score': 0.26969480191835093, 'support': 166918}, 'weighted avg': {'precision': 0.3488723962406689, 'recall': 0.3502378413352664, 'f1-score': 0.27161671581550967, 'support': 166918}}
[[16452   512 42804]
 [13486   434 39705]
 [11491   459 41575]]
Evaluating performance on  val set...
181/181 - 2s - 2s/epoch - 8ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0661775
{'0': {'precision': 0.4464972334239895, 'recall': 0.23897003463333835, 'f1-score': 0.3113189040737593, 'support': 19923}, '1': {'precision': 0.1903323262839879, 'recall': 0.006989128023075216, 'f1-score': 0.01348314606741573, 'support': 9014}, '2': {'precision': 0.3822529465095195, 'recall': 0.7775024491442402, 'f1-score': 0.5125263537768999, 'support': 17353}, 'accuracy': 0.3956794124000864, 'macro avg': {'precision': 0.33969416873916564, 'recall': 0.3411538706002179, 'f1-score': 0.27910946797269165, 'support': 46290}, 'weighted avg': {'precision': 0.3725308997928214, 'recall': 0.3956794124000864, 'f1-score': 0.32874947983589836, 'support': 46290}}
[[ 4761   132 15030]
 [ 2177    63  6774]
 [ 3725   136 13492]]
training model: results/QRTEA/W1/deepVOL_L2/h10
Epoch 1/50
653/653 - 16s - loss: 2.7596 - accuracy10: 0.5758 - val_loss: 2.3820 - val_accuracy10: 0.7153 - 16s/epoch - 25ms/step
Epoch 2/50
653/653 - 13s - loss: 2.5264 - accuracy10: 0.6237 - val_loss: 2.2844 - val_accuracy10: 0.6955 - 13s/epoch - 21ms/step
Epoch 3/50
653/653 - 13s - loss: 2.4620 - accuracy10: 0.6351 - val_loss: 2.2935 - val_accuracy10: 0.7212 - 13s/epoch - 20ms/step
Epoch 4/50
653/653 - 13s - loss: 2.4300 - accuracy10: 0.6427 - val_loss: 2.3081 - val_accuracy10: 0.7343 - 13s/epoch - 21ms/step
Epoch 5/50
653/653 - 13s - loss: 2.4086 - accuracy10: 0.6480 - val_loss: 2.3091 - val_accuracy10: 0.7265 - 13s/epoch - 20ms/step
Epoch 6/50
653/653 - 13s - loss: 2.3923 - accuracy10: 0.6545 - val_loss: 2.2819 - val_accuracy10: 0.7239 - 13s/epoch - 21ms/step
Epoch 7/50
653/653 - 13s - loss: 2.3818 - accuracy10: 0.6546 - val_loss: 2.3059 - val_accuracy10: 0.7382 - 13s/epoch - 20ms/step
Epoch 8/50
653/653 - 14s - loss: 2.3683 - accuracy10: 0.6576 - val_loss: 2.2912 - val_accuracy10: 0.7326 - 14s/epoch - 21ms/step
Epoch 9/50
653/653 - 13s - loss: 2.3568 - accuracy10: 0.6602 - val_loss: 2.2957 - val_accuracy10: 0.7208 - 13s/epoch - 20ms/step
Epoch 10/50
653/653 - 13s - loss: 2.3477 - accuracy10: 0.6606 - val_loss: 2.2912 - val_accuracy10: 0.7341 - 13s/epoch - 20ms/step
Epoch 11/50
653/653 - 13s - loss: 2.3345 - accuracy10: 0.6628 - val_loss: 2.3128 - val_accuracy10: 0.7384 - 13s/epoch - 20ms/step
Epoch 12/50
653/653 - 13s - loss: 2.3242 - accuracy10: 0.6646 - val_loss: 2.3158 - val_accuracy10: 0.7515 - 13s/epoch - 20ms/step
Epoch 13/50
653/653 - 13s - loss: 2.3131 - accuracy10: 0.6662 - val_loss: 2.2848 - val_accuracy10: 0.7380 - 13s/epoch - 20ms/step
Epoch 14/50
653/653 - 14s - loss: 2.3070 - accuracy10: 0.6651 - val_loss: 2.3176 - val_accuracy10: 0.7324 - 14s/epoch - 22ms/step
Epoch 15/50
653/653 - 13s - loss: 2.2958 - accuracy10: 0.6664 - val_loss: 2.3040 - val_accuracy10: 0.7331 - 13s/epoch - 20ms/step
Epoch 16/50
653/653 - 13s - loss: 2.2921 - accuracy10: 0.6668 - val_loss: 2.2994 - val_accuracy10: 0.7251 - 13s/epoch - 20ms/step
testing model: results/QRTEA/W1/deepVOL_L2/h10
Evaluating performance on  test set...
1645/1645 - 12s - 12s/epoch - 8ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.5932422
{'0': {'precision': 0.27090838408708046, 'recall': 0.6120560939192552, 'f1-score': 0.3755782514574182, 'support': 34157}, '1': {'precision': 0.9273547776358532, 'recall': 0.8107855308583187, 'f1-score': 0.8651612669070143, 'support': 352806}, '2': {'precision': 0.4143632355434967, 'recall': 0.43061062648691517, 'f1-score': 0.422330726353541, 'support': 34047}, 'accuracy': 0.763917721669319, 'macro avg': {'precision': 0.5375421324221434, 'recall': 0.6178174170881631, 'f1-score': 0.5543567482393245, 'support': 421010}, 'weighted avg': {'precision': 0.8326110363991513, 'recall': 0.763917721669319, 'f1-score': 0.7896292404161093, 'support': 421010}}
[[ 20906   9798   3453]
 [ 49488 286050  17268]
 [  6776  12610  14661]]
Evaluating performance on  train set...
653/653 - 5s - 5s/epoch - 7ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.74415874
{'0': {'precision': 0.3281031650690137, 'recall': 0.616216962887927, 'f1-score': 0.4282080406994417, 'support': 21718}, '1': {'precision': 0.8912689777706797, 'recall': 0.7192280119535712, 'f1-score': 0.7960593768109483, 'support': 124147}, '2': {'precision': 0.3915825175364218, 'recall': 0.4825915546477937, 'f1-score': 0.43234962446009495, 'support': 21053}, 'accuracy': 0.6759786242346542, 'macro avg': {'precision': 0.5369848867920384, 'recall': 0.6060121764964307, 'f1-score': 0.5522056806568284, 'support': 166918}, 'weighted avg': {'precision': 0.7549701114556829, 'recall': 0.6759786242346542, 'f1-score': 0.7023236698535668, 'support': 166918}}
[[13383  4826  3509]
 [22580 89290 12277]
 [ 4826  6067 10160]]
Evaluating performance on  val set...
181/181 - 1s - 1s/epoch - 8ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.6760783
{'0': {'precision': 0.325438781983506, 'recall': 0.6019949149227459, 'f1-score': 0.42248301420630013, 'support': 5113}, '1': {'precision': 0.9042789529604945, 'recall': 0.7742095542630316, 'f1-score': 0.8342045859569918, 'support': 36277}, '2': {'precision': 0.3999653559674346, 'recall': 0.47122448979591836, 'f1-score': 0.4326805958961867, 'support': 4900}, 'accuracy': 0.7231151436595377, 'macro avg': {'precision': 0.5432276969704783, 'recall': 0.6158096529938987, 'f1-score': 0.5631227320198261, 'support': 46290}, 'weighted avg': {'precision': 0.7869588747692797, 'recall': 0.7231151436595377, 'f1-score': 0.7462244617906658, 'support': 46290}}
[[ 3078  1270   765]
 [ 5492 28086  2699]
 [  888  1703  2309]]
training model: results/QRTEA/W1/deepVOL_L2/h20
Epoch 1/50
653/653 - 16s - loss: 2.8220 - accuracy20: 0.5531 - val_loss: 2.5383 - val_accuracy20: 0.6970 - 16s/epoch - 25ms/step
Epoch 2/50
653/653 - 14s - loss: 2.5958 - accuracy20: 0.6134 - val_loss: 2.4958 - val_accuracy20: 0.7087 - 14s/epoch - 21ms/step
Epoch 3/50
653/653 - 13s - loss: 2.5368 - accuracy20: 0.6247 - val_loss: 2.4465 - val_accuracy20: 0.7051 - 13s/epoch - 20ms/step
Epoch 4/50
653/653 - 13s - loss: 2.5024 - accuracy20: 0.6329 - val_loss: 2.4516 - val_accuracy20: 0.7151 - 13s/epoch - 20ms/step
Epoch 5/50
653/653 - 13s - loss: 2.4861 - accuracy20: 0.6363 - val_loss: 2.4759 - val_accuracy20: 0.7067 - 13s/epoch - 20ms/step
Epoch 6/50
653/653 - 13s - loss: 2.4683 - accuracy20: 0.6400 - val_loss: 2.4718 - val_accuracy20: 0.7113 - 13s/epoch - 20ms/step
Epoch 7/50
653/653 - 13s - loss: 2.4558 - accuracy20: 0.6426 - val_loss: 2.4634 - val_accuracy20: 0.7124 - 13s/epoch - 21ms/step
Epoch 8/50
653/653 - 13s - loss: 2.4469 - accuracy20: 0.6428 - val_loss: 2.4782 - val_accuracy20: 0.7194 - 13s/epoch - 20ms/step
Epoch 9/50
653/653 - 13s - loss: 2.4341 - accuracy20: 0.6457 - val_loss: 2.4743 - val_accuracy20: 0.7181 - 13s/epoch - 20ms/step
Epoch 10/50
653/653 - 13s - loss: 2.4227 - accuracy20: 0.6466 - val_loss: 2.4748 - val_accuracy20: 0.7192 - 13s/epoch - 20ms/step
Epoch 11/50
653/653 - 14s - loss: 2.4099 - accuracy20: 0.6486 - val_loss: 2.4775 - val_accuracy20: 0.7286 - 14s/epoch - 21ms/step
Epoch 12/50
653/653 - 13s - loss: 2.3956 - accuracy20: 0.6484 - val_loss: 2.4667 - val_accuracy20: 0.7356 - 13s/epoch - 20ms/step
Epoch 13/50
653/653 - 14s - loss: 2.3864 - accuracy20: 0.6516 - val_loss: 2.4684 - val_accuracy20: 0.7252 - 14s/epoch - 21ms/step
testing model: results/QRTEA/W1/deepVOL_L2/h20
Evaluating performance on  test set...
1645/1645 - 15s - 15s/epoch - 9ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.6303922
{'0': {'precision': 0.34369206684884857, 'recall': 0.5347977520887198, 'f1-score': 0.41845845176391905, 'support': 46799}, '1': {'precision': 0.878704734294515, 'recall': 0.8279478432125752, 'f1-score': 0.85257151826708, 'support': 328011}, '2': {'precision': 0.457073482428115, 'recall': 0.3870779220779221, 'f1-score': 0.41917374743627306, 'support': 46200}, 'accuracy': 0.7469822569535165, 'macro avg': {'precision': 0.5598234278571596, 'recall': 0.5832745057930724, 'f1-score': 0.5634012391557573, 'support': 421010}, 'weighted avg': {'precision': 0.772965151719238, 'recall': 0.7469822569535165, 'f1-score': 0.7567566102799426, 'support': 421010}}
[[ 25028  17649   4122]
 [ 39315 271576  17120]
 [  8478  19839  17883]]
Evaluating performance on  train set...
653/653 - 5s - 5s/epoch - 7ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.77788025
{'0': {'precision': 0.3981677237491191, 'recall': 0.5577492596248766, 'f1-score': 0.46463815789473684, 'support': 28364}, '1': {'precision': 0.8242492219392911, 'recall': 0.7358483757769299, 'f1-score': 0.7775442409337662, 'support': 110853}, '2': {'precision': 0.43692863723336406, 'recall': 0.4451463846070539, 'f1-score': 0.44099923108559985, 'support': 27701}, 'accuracy': 0.6573407301788903, 'macro avg': {'precision': 0.5531151943072581, 'recall': 0.5795813400029535, 'f1-score': 0.561060543304701, 'support': 166918}, 'weighted avg': {'precision': 0.687568078314248, 'recall': 0.6573407301788903, 'f1-score': 0.6685212388781276, 'support': 166918}}
[[15820  8332  4212]
 [17603 81571 11679]
 [ 6309  9061 12331]]
Evaluating performance on  val set...
181/181 - 1s - 1s/epoch - 8ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.7137916
{'0': {'precision': 0.41002886774297015, 'recall': 0.5533910533910534, 'f1-score': 0.471043419517288, 'support': 6930}, '1': {'precision': 0.843191241254211, 'recall': 0.7953253895508707, 'f1-score': 0.8185591648061383, 'support': 32730}, '2': {'precision': 0.46347897774113767, 'recall': 0.4239819004524887, 'f1-score': 0.4428515163450177, 'support': 6630}, 'accuracy': 0.7059192050118817, 'macro avg': {'precision': 0.572233028912773, 'recall': 0.5908994477981376, 'f1-score': 0.5774847002228147, 'support': 46290}, 'weighted avg': {'precision': 0.7239579823316667, 'recall': 0.7059192050118817, 'f1-score': 0.7127214930811661, 'support': 46290}}
[[ 3835  2225   870]
 [ 4315 26031  2384]
 [ 1203  2616  2811]]
training model: results/QRTEA/W1/deepVOL_L2/h30
Epoch 1/50
653/653 - 15s - loss: 2.8877 - accuracy30: 0.5350 - val_loss: 2.6828 - val_accuracy30: 0.6607 - 15s/epoch - 24ms/step
Epoch 2/50
653/653 - 14s - loss: 2.6631 - accuracy30: 0.5954 - val_loss: 2.6122 - val_accuracy30: 0.6730 - 14s/epoch - 21ms/step
Epoch 3/50
653/653 - 14s - loss: 2.6127 - accuracy30: 0.6081 - val_loss: 2.6266 - val_accuracy30: 0.6720 - 14s/epoch - 21ms/step
Epoch 4/50
653/653 - 14s - loss: 2.5847 - accuracy30: 0.6129 - val_loss: 2.6027 - val_accuracy30: 0.6736 - 14s/epoch - 21ms/step
Epoch 5/50
653/653 - 13s - loss: 2.5651 - accuracy30: 0.6163 - val_loss: 2.6099 - val_accuracy30: 0.6808 - 13s/epoch - 21ms/step
Epoch 6/50
653/653 - 13s - loss: 2.5497 - accuracy30: 0.6192 - val_loss: 2.6148 - val_accuracy30: 0.6795 - 13s/epoch - 20ms/step
Epoch 7/50
653/653 - 14s - loss: 2.5375 - accuracy30: 0.6219 - val_loss: 2.6277 - val_accuracy30: 0.6820 - 14s/epoch - 22ms/step
Epoch 8/50
653/653 - 13s - loss: 2.5257 - accuracy30: 0.6246 - val_loss: 2.6169 - val_accuracy30: 0.6686 - 13s/epoch - 21ms/step
Epoch 9/50
653/653 - 13s - loss: 2.5137 - accuracy30: 0.6249 - val_loss: 2.6175 - val_accuracy30: 0.6751 - 13s/epoch - 20ms/step
Epoch 10/50
653/653 - 13s - loss: 2.5041 - accuracy30: 0.6274 - val_loss: 2.6043 - val_accuracy30: 0.6748 - 13s/epoch - 20ms/step
Epoch 11/50
653/653 - 14s - loss: 2.4893 - accuracy30: 0.6299 - val_loss: 2.5852 - val_accuracy30: 0.6820 - 14s/epoch - 21ms/step
Epoch 12/50
653/653 - 13s - loss: 2.4791 - accuracy30: 0.6287 - val_loss: 2.6236 - val_accuracy30: 0.6792 - 13s/epoch - 20ms/step
Epoch 13/50
653/653 - 13s - loss: 2.4692 - accuracy30: 0.6313 - val_loss: 2.6216 - val_accuracy30: 0.6829 - 13s/epoch - 20ms/step
Epoch 14/50
653/653 - 13s - loss: 2.4633 - accuracy30: 0.6325 - val_loss: 2.6132 - val_accuracy30: 0.6757 - 13s/epoch - 20ms/step
Epoch 15/50
653/653 - 14s - loss: 2.4540 - accuracy30: 0.6327 - val_loss: 2.5991 - val_accuracy30: 0.6732 - 14s/epoch - 21ms/step
Epoch 16/50
653/653 - 13s - loss: 2.4433 - accuracy30: 0.6327 - val_loss: 2.6146 - val_accuracy30: 0.6761 - 13s/epoch - 20ms/step
Epoch 17/50
653/653 - 13s - loss: 2.4330 - accuracy30: 0.6330 - val_loss: 2.6214 - val_accuracy30: 0.6776 - 13s/epoch - 20ms/step
Epoch 18/50
653/653 - 13s - loss: 2.4285 - accuracy30: 0.6334 - val_loss: 2.6386 - val_accuracy30: 0.6799 - 13s/epoch - 20ms/step
Epoch 19/50
653/653 - 13s - loss: 2.4215 - accuracy30: 0.6340 - val_loss: 2.6154 - val_accuracy30: 0.6748 - 13s/epoch - 20ms/step
Epoch 20/50
653/653 - 14s - loss: 2.4074 - accuracy30: 0.6344 - val_loss: 2.6502 - val_accuracy30: 0.6765 - 14s/epoch - 22ms/step
Epoch 21/50
653/653 - 13s - loss: 2.4053 - accuracy30: 0.6357 - val_loss: 2.6550 - val_accuracy30: 0.6824 - 13s/epoch - 20ms/step
testing model: results/QRTEA/W1/deepVOL_L2/h30
Evaluating performance on  test set...
1645/1645 - 15s - 15s/epoch - 9ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.68880755
{'0': {'precision': 0.36478486097896184, 'recall': 0.4880912386172752, 'f1-score': 0.4175244087818676, 'support': 56555}, '1': {'precision': 0.8340712913497723, 'recall': 0.8207818357212687, 'f1-score': 0.8273732024160312, 'support': 308914}, '2': {'precision': 0.509988874377207, 'recall': 0.37964746763652074, 'f1-score': 0.43526995365735344, 'support': 55541}, 'accuracy': 0.7178950618750148, 'macro avg': {'precision': 0.5696150089019804, 'recall': 0.5628401806583548, 'f1-score': 0.5600558549517508, 'support': 421010}, 'weighted avg': {'precision': 0.7282772351736851, 'recall': 0.7178950618750148, 'f1-score': 0.720589978589315, 'support': 421010}}
[[ 27604  23716   5235]
 [ 40338 253551  15025]
 [  7730  26725  21086]]
Evaluating performance on  train set...
653/653 - 5s - 5s/epoch - 7ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.80720156
{'0': {'precision': 0.4407479486640017, 'recall': 0.5064825168484995, 'f1-score': 0.47133435518119055, 'support': 33089}, '1': {'precision': 0.7698940526617634, 'recall': 0.7541418223032573, 'f1-score': 0.7619365310125763, 'support': 101465}, '2': {'precision': 0.4964582274190815, 'recall': 0.4526016561611667, 'f1-score': 0.47351662383423043, 'support': 32364}, 'accuracy': 0.646580955918475, 'macro avg': {'precision': 0.5690334095816155, 'recall': 0.5710753317709746, 'f1-score': 0.5689291700093325, 'support': 166918}, 'weighted avg': {'precision': 0.6516288416998773, 'recall': 0.646580955918475, 'f1-score': 0.6484067902296488, 'support': 166918}}
[[16759 10751  5579]
 [15668 76519  9278]
 [ 5597 12119 14648]]
Evaluating performance on  val set...
181/181 - 1s - 1s/epoch - 8ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.7624291
{'0': {'precision': 0.4571164723536881, 'recall': 0.4821037253469686, 'f1-score': 0.46927771523375006, 'support': 8214}, '1': {'precision': 0.7903362716291218, 'recall': 0.8013771186440678, 'f1-score': 0.7958184029718268, 'support': 30208}, '2': {'precision': 0.4874946405602401, 'recall': 0.4335282155566853, 'f1-score': 0.4589303733602422, 'support': 7868}, 'accuracy': 0.682199179088356, 'macro avg': {'precision': 0.5783157948476833, 'recall': 0.5723363531825739, 'f1-score': 0.5746754971886063, 'support': 46290}, 'weighted avg': {'precision': 0.6797330012791893, 'recall': 0.682199179088356, 'f1-score': 0.6806133862065533, 'support': 46290}}
[[ 3960  3046  1208]
 [ 3622 24208  2378]
 [ 1081  3376  3411]]
training model: results/QRTEA/W1/deepVOL_L2/h50
Epoch 1/50
653/653 - 16s - loss: 2.9944 - accuracy50: 0.5040 - val_loss: 2.8458 - val_accuracy50: 0.5980 - 16s/epoch - 24ms/step
Epoch 2/50
653/653 - 13s - loss: 2.8068 - accuracy50: 0.5591 - val_loss: 2.8008 - val_accuracy50: 0.6001 - 13s/epoch - 21ms/step
Epoch 3/50
653/653 - 13s - loss: 2.7545 - accuracy50: 0.5704 - val_loss: 2.7896 - val_accuracy50: 0.6003 - 13s/epoch - 20ms/step
Epoch 4/50
653/653 - 14s - loss: 2.7273 - accuracy50: 0.5759 - val_loss: 2.7756 - val_accuracy50: 0.6068 - 14s/epoch - 21ms/step
Epoch 5/50
653/653 - 13s - loss: 2.7055 - accuracy50: 0.5790 - val_loss: 2.7951 - val_accuracy50: 0.6046 - 13s/epoch - 20ms/step
Epoch 6/50
653/653 - 14s - loss: 2.6887 - accuracy50: 0.5834 - val_loss: 2.8329 - val_accuracy50: 0.6146 - 14s/epoch - 21ms/step
Epoch 7/50
653/653 - 13s - loss: 2.6724 - accuracy50: 0.5870 - val_loss: 2.8479 - val_accuracy50: 0.6121 - 13s/epoch - 20ms/step
Epoch 8/50
653/653 - 13s - loss: 2.6630 - accuracy50: 0.5879 - val_loss: 2.8165 - val_accuracy50: 0.6104 - 13s/epoch - 20ms/step
Epoch 9/50
653/653 - 14s - loss: 2.6528 - accuracy50: 0.5904 - val_loss: 2.8628 - val_accuracy50: 0.6112 - 14s/epoch - 21ms/step
Epoch 10/50
653/653 - 14s - loss: 2.6462 - accuracy50: 0.5912 - val_loss: 2.8425 - val_accuracy50: 0.6131 - 14s/epoch - 22ms/step
Epoch 11/50
653/653 - 14s - loss: 2.6348 - accuracy50: 0.5943 - val_loss: 2.8911 - val_accuracy50: 0.6176 - 14s/epoch - 21ms/step
Epoch 12/50
653/653 - 13s - loss: 2.6234 - accuracy50: 0.5956 - val_loss: 2.9101 - val_accuracy50: 0.6153 - 13s/epoch - 20ms/step
Epoch 13/50
653/653 - 13s - loss: 2.6145 - accuracy50: 0.5954 - val_loss: 2.8964 - val_accuracy50: 0.6081 - 13s/epoch - 20ms/step
Epoch 14/50
653/653 - 14s - loss: 2.6056 - accuracy50: 0.5972 - val_loss: 2.8881 - val_accuracy50: 0.6033 - 14s/epoch - 21ms/step
testing model: results/QRTEA/W1/deepVOL_L2/h50
Evaluating performance on  test set...
1645/1645 - 16s - 16s/epoch - 10ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.80194604
{'0': {'precision': 0.40287691681367893, 'recall': 0.4032764171319125, 'f1-score': 0.4030765679838704, 'support': 73617}, '1': {'precision': 0.7557247983767313, 'recall': 0.7979184233287132, 'f1-score': 0.7762486665751311, 'support': 276329}, '2': {'precision': 0.4823713622374602, 'recall': 0.3771529888551165, 'f1-score': 0.4233220403231538, 'support': 71064}, 'accuracy': 0.6578893612978314, 'macro avg': {'precision': 0.5469910258092902, 'recall': 0.5261159431052475, 'f1-score': 0.5342157582940518, 'support': 421010}, 'weighted avg': {'precision': 0.6478860508818302, 'recall': 0.6578893612978314, 'f1-score': 0.6514245812803321, 'support': 421010}}
[[ 29688  34967   8962]
 [ 36042 220488  19799]
 [  7960  36302  26802]]
Evaluating performance on  train set...
653/653 - 5s - 5s/epoch - 7ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.8940778
{'0': {'precision': 0.48324595395486664, 'recall': 0.4225843424527832, 'f1-score': 0.45088395586866936, 'support': 40134}, '1': {'precision': 0.6772481109660295, 'recall': 0.7243112072616554, 'f1-score': 0.6999894909760671, 'support': 87363}, '2': {'precision': 0.4791862040220902, 'recall': 0.4666294614545547, 'f1-score': 0.47282448045855874, 'support': 39421}, 'accuracy': 0.5909069123761368, 'macro avg': {'precision': 0.5465600896476621, 'recall': 0.5378416703896645, 'f1-score': 0.5412326424344318, 'support': 166918}, 'weighted avg': {'precision': 0.5838257059340795, 'recall': 0.5909069123761368, 'f1-score': 0.5864446760033799, 'support': 166918}}
[[16960 14663  8511]
 [12603 63278 11482]
 [ 5533 15493 18395]]
Evaluating performance on  val set...
181/181 - 1s - 1s/epoch - 8ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.8682275
{'0': {'precision': 0.47572597824868257, 'recall': 0.4092005014948404, 'f1-score': 0.43996267109083365, 'support': 10369}, '1': {'precision': 0.6921222707423581, 'recall': 0.7571657876633799, 'f1-score': 0.7231844646018506, 'support': 26166}, '2': {'precision': 0.45883832609192776, 'recall': 0.4113787801127627, 'f1-score': 0.4338143884114372, 'support': 9755}, 'accuracy': 0.606351263771873, 'macro avg': {'precision': 0.5422288583609894, 'recall': 0.5259150230903277, 'f1-score': 0.5323205080347071, 'support': 46290}, 'weighted avg': {'precision': 0.5944878348613499, 'recall': 0.606351263771873, 'f1-score': 0.598761654704395, 'support': 46290}}
[[ 4243  4236  1890]
 [ 3511 19812  2843]
 [ 1165  4577  4013]]
training model: results/QRTEA/W1/deepVOL_L2/h100
Epoch 1/50
653/653 - 16s - loss: 3.1560 - accuracy100: 0.4420 - val_loss: 3.1914 - val_accuracy100: 0.4662 - 16s/epoch - 25ms/step
Epoch 2/50
653/653 - 14s - loss: 3.0257 - accuracy100: 0.4878 - val_loss: 3.1307 - val_accuracy100: 0.4798 - 14s/epoch - 21ms/step
Epoch 3/50
653/653 - 14s - loss: 2.9712 - accuracy100: 0.5011 - val_loss: 3.1356 - val_accuracy100: 0.4966 - 14s/epoch - 21ms/step
Epoch 4/50
653/653 - 14s - loss: 2.9387 - accuracy100: 0.5085 - val_loss: 3.1174 - val_accuracy100: 0.4954 - 14s/epoch - 21ms/step
Epoch 5/50
653/653 - 13s - loss: 2.9195 - accuracy100: 0.5147 - val_loss: 3.1494 - val_accuracy100: 0.4981 - 13s/epoch - 21ms/step
Epoch 6/50
653/653 - 13s - loss: 2.9097 - accuracy100: 0.5143 - val_loss: 3.1914 - val_accuracy100: 0.4910 - 13s/epoch - 20ms/step
Epoch 7/50
653/653 - 13s - loss: 2.8920 - accuracy100: 0.5177 - val_loss: 3.1790 - val_accuracy100: 0.4958 - 13s/epoch - 20ms/step
Epoch 8/50
653/653 - 13s - loss: 2.8792 - accuracy100: 0.5214 - val_loss: 3.1807 - val_accuracy100: 0.4932 - 13s/epoch - 20ms/step
Epoch 9/50
653/653 - 13s - loss: 2.8706 - accuracy100: 0.5242 - val_loss: 3.1446 - val_accuracy100: 0.4975 - 13s/epoch - 20ms/step
Epoch 10/50
653/653 - 14s - loss: 2.8597 - accuracy100: 0.5272 - val_loss: 3.1703 - val_accuracy100: 0.4949 - 14s/epoch - 21ms/step
Epoch 11/50
653/653 - 13s - loss: 2.8514 - accuracy100: 0.5305 - val_loss: 3.1543 - val_accuracy100: 0.4959 - 13s/epoch - 20ms/step
Epoch 12/50
653/653 - 14s - loss: 2.8433 - accuracy100: 0.5320 - val_loss: 3.1832 - val_accuracy100: 0.4975 - 14s/epoch - 21ms/step
Epoch 13/50
653/653 - 14s - loss: 2.8356 - accuracy100: 0.5333 - val_loss: 3.1771 - val_accuracy100: 0.4997 - 14s/epoch - 22ms/step
Epoch 14/50
653/653 - 14s - loss: 2.8300 - accuracy100: 0.5358 - val_loss: 3.1912 - val_accuracy100: 0.4938 - 14s/epoch - 21ms/step
testing model: results/QRTEA/W1/deepVOL_L2/h100
Evaluating performance on  test set...
1645/1645 - 16s - 16s/epoch - 10ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 0.9769781
{'0': {'precision': 0.42030862496555527, 'recall': 0.4339526017809895, 'f1-score': 0.42702165483839355, 'support': 105447}, '1': {'precision': 0.5866540784153054, 'recall': 0.7615763865763866, 'f1-score': 0.6627678350415878, 'support': 216216}, '2': {'precision': 0.5446828803051978, 'recall': 0.17245613858495978, 'f1-score': 0.2619684714301005, 'support': 99347}, 'accuracy': 0.5405026008883399, 'macro avg': {'precision': 0.5172151945620195, 'recall': 0.4559950423141119, 'f1-score': 0.4505859871033606, 'support': 421010}, 'weighted avg': {'precision': 0.5350867958126103, 'recall': 0.5405026008883399, 'f1-score': 0.5091445438119336, 'support': 421010}}
[[ 45759  53127   6561]
 [ 43790 164665   7761]
 [ 19321  62893  17133]]
Evaluating performance on  train set...
653/653 - 5s - 5s/epoch - 8ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0293682
{'0': {'precision': 0.4741832283082889, 'recall': 0.4749844623990056, 'f1-score': 0.47458350717522285, 'support': 51488}, '1': {'precision': 0.48738997341355167, 'recall': 0.7134506550895419, 'f1-score': 0.5791421235462921, 'support': 64495}, '2': {'precision': 0.5193465176268272, 'recall': 0.2134485128104447, 'f1-score': 0.30255047377868066, 'support': 50935}, 'accuracy': 0.4873171257743323, 'macro avg': {'precision': 0.49363990644955597, 'recall': 0.46729454343299737, 'f1-score': 0.45209203483339855, 'support': 166918}, 'weighted avg': {'precision': 0.49306771750060885, 'recall': 0.4873171257743323, 'f1-score': 0.46248777997263985, 'support': 166918}}
[[24456 21101  5931]
 [14350 46014  4131]
 [12769 27294 10872]]
Evaluating performance on  val set...
181/181 - 1s - 1s/epoch - 8ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0236255
{'0': {'precision': 0.48440748440748443, 'recall': 0.4435904667888873, 'f1-score': 0.46310132872023263, 'support': 14182}, '1': {'precision': 0.49719460227272727, 'recall': 0.7352694044743199, 'f1-score': 0.5932375746790389, 'support': 19042}, '2': {'precision': 0.5069025860392767, 'recall': 0.19952548599418338, 'f1-score': 0.28634191883134713, 'support': 13066}, 'accuracy': 0.49468567725210627, 'macro avg': {'precision': 0.4961682242398295, 'recall': 0.4594617857524635, 'f1-score': 0.44756027407687293, 'support': 46290}, 'weighted avg': {'precision': 0.49601719052783344, 'recall': 0.49468567725210627, 'f1-score': 0.4667417682523003, 'support': 46290}}
[[ 6291  6503  1388]
 [ 3893 14001  1148]
 [ 2803  7656  2607]]
training model: results/QRTEA/W1/deepVOL_L2/h200
Epoch 1/50
653/653 - 16s - loss: 3.2610 - accuracy200: 0.4022 - val_loss: 3.4094 - val_accuracy200: 0.3224 - 16s/epoch - 24ms/step
Epoch 2/50
653/653 - 14s - loss: 3.2080 - accuracy200: 0.4170 - val_loss: 3.3014 - val_accuracy200: 0.3686 - 14s/epoch - 21ms/step
Epoch 3/50
653/653 - 14s - loss: 3.1563 - accuracy200: 0.4352 - val_loss: 3.2662 - val_accuracy200: 0.3833 - 14s/epoch - 21ms/step
Epoch 4/50
653/653 - 14s - loss: 3.1328 - accuracy200: 0.4420 - val_loss: 3.2382 - val_accuracy200: 0.3932 - 14s/epoch - 21ms/step
Epoch 5/50
653/653 - 14s - loss: 3.1153 - accuracy200: 0.4480 - val_loss: 3.2655 - val_accuracy200: 0.3866 - 14s/epoch - 21ms/step
Epoch 6/50
653/653 - 13s - loss: 3.1027 - accuracy200: 0.4523 - val_loss: 3.2646 - val_accuracy200: 0.3938 - 13s/epoch - 21ms/step
Epoch 7/50
653/653 - 13s - loss: 3.0912 - accuracy200: 0.4567 - val_loss: 3.2548 - val_accuracy200: 0.3967 - 13s/epoch - 20ms/step
Epoch 8/50
653/653 - 13s - loss: 3.0875 - accuracy200: 0.4550 - val_loss: 3.2891 - val_accuracy200: 0.3939 - 13s/epoch - 20ms/step
Epoch 9/50
653/653 - 13s - loss: 3.0786 - accuracy200: 0.4600 - val_loss: 3.3138 - val_accuracy200: 0.3994 - 13s/epoch - 20ms/step
Epoch 10/50
653/653 - 13s - loss: 3.0652 - accuracy200: 0.4633 - val_loss: 3.3265 - val_accuracy200: 0.4067 - 13s/epoch - 20ms/step
Epoch 11/50
653/653 - 13s - loss: 3.0556 - accuracy200: 0.4682 - val_loss: 3.3483 - val_accuracy200: 0.4084 - 13s/epoch - 20ms/step
Epoch 12/50
653/653 - 13s - loss: 3.0446 - accuracy200: 0.4714 - val_loss: 3.3499 - val_accuracy200: 0.4135 - 13s/epoch - 21ms/step
Epoch 13/50
653/653 - 13s - loss: 3.0338 - accuracy200: 0.4763 - val_loss: 3.3532 - val_accuracy200: 0.4132 - 13s/epoch - 20ms/step
Epoch 14/50
653/653 - 13s - loss: 3.0236 - accuracy200: 0.4791 - val_loss: 3.3843 - val_accuracy200: 0.4159 - 13s/epoch - 20ms/step
testing model: results/QRTEA/W1/deepVOL_L2/h200
Evaluating performance on  test set...
1645/1645 - 14s - 14s/epoch - 9ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0630877
{'0': {'precision': 0.4338219186266505, 'recall': 0.32859179255884813, 'f1-score': 0.37394480136301406, 'support': 132587}, '1': {'precision': 0.42376899041051613, 'recall': 0.7874303811291908, 'f1-score': 0.5510052027280891, 'support': 164826}, '2': {'precision': 0.6017049821815387, 'recall': 0.06966997580847431, 'f1-score': 0.12488035501928821, 'support': 123597}, 'accuracy': 0.4322153868079143, 'macro avg': {'precision': 0.48643196373956843, 'recall': 0.39523071649883773, 'f1-score': 0.34994345303679714, 'support': 421010}, 'weighted avg': {'precision': 0.4791720505951096, 'recall': 0.4322153868079143, 'f1-score': 0.37014569763781596, 'support': 421010}}
[[ 43567  85080   3940]
 [ 33277 129789   1760]
 [ 23582  91404   8611]]
Evaluating performance on  train set...
653/653 - 5s - 5s/epoch - 7ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0810052
{'0': {'precision': 0.4671644776318421, 'recall': 0.36078263108212477, 'f1-score': 0.40713912184540296, 'support': 58265}, '1': {'precision': 0.35448416163325563, 'recall': 0.751713211292878, 'f1-score': 0.48177736453834774, 'support': 52387}, '2': {'precision': 0.5003693444136658, 'recall': 0.09631038282444104, 'f1-score': 0.16152974842017406, 'support': 56266}, 'accuracy': 0.39432535736109947, 'macro avg': {'precision': 0.44067266122625454, 'recall': 0.4029354083998147, 'f1-score': 0.3501487449346416, 'support': 166918}, 'weighted avg': {'precision': 0.44299285635749264, 'recall': 0.39432535736109947, 'f1-score': 0.3477723466312941, 'support': 166918}}
[[21021 33317  3927]
 [11523 39380  1484]
 [12453 38394  5419]]
Evaluating performance on  val set...
181/181 - 1s - 1s/epoch - 8ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0865954
{'0': {'precision': 0.49991392666551904, 'recall': 0.3463533901842686, 'f1-score': 0.40920139500475566, 'support': 16769}, '1': {'precision': 0.34617180932216585, 'recall': 0.7805939759882047, 'f1-score': 0.4796376186367558, 'support': 14243}, '2': {'precision': 0.5228962818003914, 'recall': 0.08744600078544312, 'f1-score': 0.14983457634722147, 'support': 15278}, 'accuracy': 0.39451285374810974, 'macro avg': {'precision': 0.4563273392626921, 'recall': 0.40479778898597213, 'f1-score': 0.3462245299962443, 'support': 46290}, 'weighted avg': {'precision': 0.4601942343870399, 'recall': 0.39451285374810974, 'f1-score': 0.3452700248976217, 'support': 46290}}
[[ 5808 10116   845]
 [ 2751 11118   374]
 [ 3059 10883  1336]]
training model: results/QRTEA/W1/deepVOL_L2/h300
Epoch 1/50
653/653 - 16s - loss: 3.3037 - accuracy300: 0.3820 - val_loss: 3.3568 - val_accuracy300: 0.3412 - 16s/epoch - 24ms/step
Epoch 2/50
653/653 - 14s - loss: 3.2695 - accuracy300: 0.3868 - val_loss: 3.3349 - val_accuracy300: 0.3523 - 14s/epoch - 21ms/step
Epoch 3/50
653/653 - 14s - loss: 3.2465 - accuracy300: 0.3975 - val_loss: 3.3618 - val_accuracy300: 0.3619 - 14s/epoch - 22ms/step
Epoch 4/50
653/653 - 14s - loss: 3.2390 - accuracy300: 0.4001 - val_loss: 3.3669 - val_accuracy300: 0.3568 - 14s/epoch - 21ms/step
Epoch 5/50
653/653 - 13s - loss: 3.2271 - accuracy300: 0.4077 - val_loss: 3.4060 - val_accuracy300: 0.3580 - 13s/epoch - 20ms/step
Epoch 6/50
653/653 - 13s - loss: 3.2157 - accuracy300: 0.4127 - val_loss: 3.3882 - val_accuracy300: 0.3570 - 13s/epoch - 20ms/step
Epoch 7/50
653/653 - 13s - loss: 3.2002 - accuracy300: 0.4206 - val_loss: 3.4079 - val_accuracy300: 0.3634 - 13s/epoch - 20ms/step
Epoch 8/50
653/653 - 13s - loss: 3.1872 - accuracy300: 0.4241 - val_loss: 3.4351 - val_accuracy300: 0.3592 - 13s/epoch - 20ms/step
Epoch 9/50
653/653 - 13s - loss: 3.1791 - accuracy300: 0.4281 - val_loss: 3.4461 - val_accuracy300: 0.3620 - 13s/epoch - 20ms/step
Epoch 10/50
653/653 - 13s - loss: 3.1643 - accuracy300: 0.4348 - val_loss: 3.4482 - val_accuracy300: 0.3683 - 13s/epoch - 20ms/step
Epoch 11/50
653/653 - 13s - loss: 3.1491 - accuracy300: 0.4431 - val_loss: 3.4649 - val_accuracy300: 0.3580 - 13s/epoch - 20ms/step
Epoch 12/50
653/653 - 13s - loss: 3.1327 - accuracy300: 0.4482 - val_loss: 3.5118 - val_accuracy300: 0.3587 - 13s/epoch - 20ms/step
testing model: results/QRTEA/W1/deepVOL_L2/h300
Evaluating performance on  test set...
1645/1645 - 12s - 12s/epoch - 8ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0930912
{'0': {'precision': 0.3869138843705633, 'recall': 0.30487190505119355, 'f1-score': 0.3410280315743676, 'support': 134978}, '1': {'precision': 0.39192298100867906, 'recall': 0.6857929542493301, 'f1-score': 0.4987919547089181, 'support': 162708}, '2': {'precision': 0.35275848250066794, 'recall': 0.08565242775128928, 'f1-score': 0.1378369914137328, 'support': 123324}, 'accuracy': 0.38787202204223176, 'macro avg': {'precision': 0.37719844929330343, 'recall': 0.35877242901727097, 'f1-score': 0.32588565923233953, 'support': 421010}, 'weighted avg': {'precision': 0.37884481075138937, 'recall': 0.38787202204223176, 'f1-score': 0.3424795898950876, 'support': 421010}}
[[ 41151  85556   8271]
 [ 40014 111584  11110]
 [ 25192  87569  10563]]
Evaluating performance on  train set...
653/653 - 5s - 5s/epoch - 7ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1061839
{'0': {'precision': 0.40893205879329836, 'recall': 0.28090799971757396, 'f1-score': 0.33304034823371836, 'support': 56652}, '1': {'precision': 0.3373843735774837, 'recall': 0.6967982261640798, 'f1-score': 0.4546369917711191, 'support': 56375}, '2': {'precision': 0.4053236539624924, 'recall': 0.08702751850958416, 'f1-score': 0.14328923650362044, 'support': 53891}, 'accuracy': 0.35877496734923736, 'macro avg': {'precision': 0.3838800287777582, 'recall': 0.35491124813041264, 'f1-score': 0.310322192169486, 'support': 166918}, 'weighted avg': {'precision': 0.38360248799339347, 'recall': 0.35877496734923736, 'f1-score': 0.31284560361165403, 'support': 166918}}
[[15914 37440  3298]
 [13510 39282  3583]
 [ 9492 39709  4690]]
Evaluating performance on  val set...
181/181 - 1s - 1s/epoch - 8ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.109031
{'0': {'precision': 0.4242738589211618, 'recall': 0.27763036099969146, 'f1-score': 0.3356335558954083, 'support': 16205}, '1': {'precision': 0.3250957079274176, 'recall': 0.6873067052707771, 'f1-score': 0.4414064150783925, 'support': 15197}, '2': {'precision': 0.35732358729266234, 'recall': 0.08537076840408382, 'f1-score': 0.13781512605042015, 'support': 14888}, 'accuracy': 0.35029163966299415, 'macro avg': {'precision': 0.36889771804708055, 'recall': 0.3501026115581842, 'f1-score': 0.3049516990080736, 'support': 46290}, 'weighted avg': {'precision': 0.3701808365695301, 'recall': 0.35029163966299415, 'f1-score': 0.30673550788226567, 'support': 46290}}
[[ 4499 10701  1005]
 [ 3471 10445  1281]
 [ 2634 10983  1271]]
training model: results/QRTEA/W1/deepVOL_L2/h500
Epoch 1/50
653/653 - 16s - loss: 3.2511 - accuracy500: 0.4134 - val_loss: 3.3577 - val_accuracy500: 0.3011 - 16s/epoch - 25ms/step
Epoch 2/50
653/653 - 14s - loss: 3.2590 - accuracy500: 0.3942 - val_loss: 3.2704 - val_accuracy500: 0.3781 - 14s/epoch - 21ms/step
Epoch 3/50
653/653 - 14s - loss: 3.2659 - accuracy500: 0.3910 - val_loss: 3.2528 - val_accuracy500: 0.3925 - 14s/epoch - 22ms/step
Epoch 4/50
653/653 - 14s - loss: 3.2552 - accuracy500: 0.3942 - val_loss: 3.3077 - val_accuracy500: 0.3245 - 14s/epoch - 22ms/step
Epoch 5/50
653/653 - 13s - loss: 3.2439 - accuracy500: 0.4017 - val_loss: 3.3235 - val_accuracy500: 0.3136 - 13s/epoch - 20ms/step
Epoch 6/50
653/653 - 14s - loss: 3.2591 - accuracy500: 0.3934 - val_loss: 3.2753 - val_accuracy500: 0.3720 - 14s/epoch - 21ms/step
Epoch 7/50
653/653 - 14s - loss: 3.2423 - accuracy500: 0.4018 - val_loss: 3.3053 - val_accuracy500: 0.3502 - 14s/epoch - 21ms/step
Epoch 8/50
653/653 - 13s - loss: 3.2362 - accuracy500: 0.4051 - val_loss: 3.3057 - val_accuracy500: 0.3570 - 13s/epoch - 20ms/step
Epoch 9/50
653/653 - 13s - loss: 3.2296 - accuracy500: 0.4098 - val_loss: 3.3022 - val_accuracy500: 0.3650 - 13s/epoch - 20ms/step
Epoch 10/50
653/653 - 13s - loss: 3.2110 - accuracy500: 0.4192 - val_loss: 3.3443 - val_accuracy500: 0.3355 - 13s/epoch - 20ms/step
Epoch 11/50
653/653 - 13s - loss: 3.1966 - accuracy500: 0.4257 - val_loss: 3.3510 - val_accuracy500: 0.3452 - 13s/epoch - 20ms/step
Epoch 12/50
653/653 - 13s - loss: 3.1796 - accuracy500: 0.4338 - val_loss: 3.3939 - val_accuracy500: 0.3432 - 13s/epoch - 20ms/step
Epoch 13/50
653/653 - 13s - loss: 3.1660 - accuracy500: 0.4374 - val_loss: 3.4055 - val_accuracy500: 0.3365 - 13s/epoch - 20ms/step
testing model: results/QRTEA/W1/deepVOL_L2/h500
Evaluating performance on  test set...
1645/1645 - 14s - 14s/epoch - 9ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.099341
{'0': {'precision': 0.3868810683207728, 'recall': 0.5038461538461538, 'f1-score': 0.4376840258572043, 'support': 155480}, '1': {'precision': 0.14285714285714285, 'recall': 2.3519634975265184e-05, 'f1-score': 4.703152680013169e-05, 'support': 127553}, '2': {'precision': 0.33659492089353465, 'recall': 0.5330381150481602, 'f1-score': 0.412629039497307, 'support': 137977}, 'accuracy': 0.3607705280159616, 'macro avg': {'precision': 0.2887777106904834, 'recall': 0.3456359295097631, 'f1-score': 0.2834533656271038, 'support': 421010}, 'weighted avg': {'precision': 0.29646916473598756, 'recall': 0.3607705280159616, 'f1-score': 0.2968823266319945, 'support': 421010}}
[[78338     9 77133]
 [59727     3 67823]
 [64421     9 73547]]
Evaluating performance on  train set...
653/653 - 5s - 5s/epoch - 8ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0995035
{'0': {'precision': 0.366614644951796, 'recall': 0.5018088478500551, 'f1-score': 0.42368838271443326, 'support': 58048}, '1': {'precision': 0.3076923076923077, 'recall': 7.135466837917871e-05, 'f1-score': 0.00014267624975477524, 'support': 56058}, '2': {'precision': 0.3535236875507427, 'recall': 0.5853972581988942, 'f1-score': 0.4408290140664323, 'support': 52812}, 'accuracy': 0.35975149474592316, 'macro avg': {'precision': 0.34261021339828207, 'recall': 0.3624258202391095, 'f1-score': 0.28822002434354016, 'support': 166918}, 'weighted avg': {'precision': 0.3426841639709741, 'recall': 0.35975149474592316, 'f1-score': 0.28686734370105443, 'support': 166918}}
[[29129     3 28916]
 [28435     4 27619]
 [21890     6 30916]]
Evaluating performance on  val set...
181/181 - 1s - 1s/epoch - 8ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0838817
{'0': {'precision': 0.41188748161851907, 'recall': 0.48201398911957366, 'f1-score': 0.4442000255787185, 'support': 18014}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12021}, '2': {'precision': 0.3729667539474728, 'recall': 0.5783451245770532, 'f1-score': 0.45348640891440145, 'support': 16255}, 'accuracy': 0.39066753078418665, 'macro avg': {'precision': 0.2616180785219973, 'recall': 0.3534530378988756, 'f1-score': 0.29922881149770664, 'support': 46290}, 'weighted avg': {'precision': 0.2912576297103515, 'recall': 0.39066753078418665, 'f1-score': 0.33210716866879736, 'support': 46290}}
[[8683    3 9328]
 [5544    0 6477]
 [6854    0 9401]]
training model: results/QRTEA/W1/deepVOL_L2/h1000
Epoch 1/50
653/653 - 16s - loss: 3.2388 - accuracy1000: 0.4211 - val_loss: 3.3224 - val_accuracy1000: 0.3222 - 16s/epoch - 25ms/step
Epoch 2/50
653/653 - 14s - loss: 3.2676 - accuracy1000: 0.3932 - val_loss: 3.1882 - val_accuracy1000: 0.3936 - 14s/epoch - 21ms/step
Epoch 3/50
653/653 - 14s - loss: 3.2732 - accuracy1000: 0.3859 - val_loss: 3.2079 - val_accuracy1000: 0.3955 - 14s/epoch - 21ms/step
Epoch 4/50
653/653 - 14s - loss: 3.2576 - accuracy1000: 0.3875 - val_loss: 3.2145 - val_accuracy1000: 0.3980 - 14s/epoch - 21ms/step
Epoch 5/50
653/653 - 13s - loss: 3.2445 - accuracy1000: 0.4024 - val_loss: 3.3173 - val_accuracy1000: 0.3889 - 13s/epoch - 20ms/step
Epoch 6/50
653/653 - 14s - loss: 3.2404 - accuracy1000: 0.3997 - val_loss: 3.2691 - val_accuracy1000: 0.3917 - 14s/epoch - 21ms/step
Epoch 7/50
653/653 - 13s - loss: 3.2595 - accuracy1000: 0.3890 - val_loss: 3.2291 - val_accuracy1000: 0.3981 - 13s/epoch - 20ms/step
Epoch 8/50
653/653 - 13s - loss: 3.2584 - accuracy1000: 0.3892 - val_loss: 3.2356 - val_accuracy1000: 0.3981 - 13s/epoch - 20ms/step
Epoch 9/50
653/653 - 13s - loss: 3.2465 - accuracy1000: 0.3922 - val_loss: 3.2379 - val_accuracy1000: 0.3899 - 13s/epoch - 20ms/step
Epoch 10/50
653/653 - 13s - loss: 3.2281 - accuracy1000: 0.3995 - val_loss: 3.2603 - val_accuracy1000: 0.4032 - 13s/epoch - 20ms/step
Epoch 11/50
653/653 - 13s - loss: 3.2116 - accuracy1000: 0.4088 - val_loss: 3.2523 - val_accuracy1000: 0.4078 - 13s/epoch - 20ms/step
Epoch 12/50
653/653 - 13s - loss: 3.2030 - accuracy1000: 0.4155 - val_loss: 3.2672 - val_accuracy1000: 0.4075 - 13s/epoch - 20ms/step
testing model: results/QRTEA/W1/deepVOL_L2/h1000
Evaluating performance on  test set...
1645/1645 - 13s - 13s/epoch - 8ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0730125
{'0': {'precision': 0.40930334766156784, 'recall': 0.43513712172580216, 'f1-score': 0.4218250713242139, 'support': 175501}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 85302}, '2': {'precision': 0.36159739284739284, 'recall': 0.5291279407266849, 'f1-score': 0.42960781879135107, 'support': 160207}, 'accuracy': 0.38273912733664284, 'macro avg': {'precision': 0.2569669135029869, 'recall': 0.3214216874841624, 'f1-score': 0.283810963371855, 'support': 421010}, 'weighted avg': {'precision': 0.30821971053859787, 'recall': 0.38273912733664284, 'f1-score': 0.3393194975596229, 'support': 421010}}
[[76367     0 99134]
 [34774     0 50528]
 [75437     0 84770]]
Evaluating performance on  train set...
653/653 - 5s - 5s/epoch - 8ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1074994
{'0': {'precision': 0.3831970709045813, 'recall': 0.4883596467754884, 'f1-score': 0.42943386791967236, 'support': 59792}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 53594}, '2': {'precision': 0.3450951861282891, 'recall': 0.5848090861540761, 'f1-score': 0.43405500211439946, 'support': 53532}, 'accuracy': 0.36248936603601767, 'macro avg': {'precision': 0.2427640856776235, 'recall': 0.3577229109765215, 'f1-score': 0.2878296233446906, 'support': 166918}, 'weighted avg': {'precision': 0.24794063412781303, 'recall': 0.36248936603601767, 'f1-score': 0.2930333589177984, 'support': 166918}}
[[29200     0 30592]
 [24775     0 28819]
 [22226     0 31306]]
Evaluating performance on  val set...
181/181 - 1s - 1s/epoch - 8ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0686854
{'0': {'precision': 0.4223695563325916, 'recall': 0.4664961380278865, 'f1-score': 0.44333754379275014, 'support': 19938}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 8992}, '2': {'precision': 0.3690716551979892, 'recall': 0.5159562211981567, 'f1-score': 0.43032501381248645, 'support': 17360}, 'accuracy': 0.3944264419961115, 'macro avg': {'precision': 0.26381373717686024, 'recall': 0.32748411974201436, 'f1-score': 0.29122085253507884, 'support': 46290}, 'weighted avg': {'precision': 0.3203345895095334, 'recall': 0.3944264419961115, 'f1-score': 0.3523375715689051, 'support': 46290}}
[[ 9301     0 10637]
 [ 4317     0  4675]
 [ 8403     0  8957]]
training model: results/QRTEA/W1/deepVOL_L3/h10
Epoch 1/50
653/653 - 24s - loss: 3.1639 - accuracy10: 0.4363 - val_loss: 2.6606 - val_accuracy10: 0.6221 - 24s/epoch - 37ms/step
Epoch 2/50
653/653 - 21s - loss: 2.7065 - accuracy10: 0.5670 - val_loss: 2.3909 - val_accuracy10: 0.6624 - 21s/epoch - 32ms/step
Epoch 3/50
653/653 - 21s - loss: 2.5256 - accuracy10: 0.6171 - val_loss: 2.3061 - val_accuracy10: 0.6793 - 21s/epoch - 33ms/step
Epoch 4/50
653/653 - 21s - loss: 2.4418 - accuracy10: 0.6383 - val_loss: 2.2974 - val_accuracy10: 0.6903 - 21s/epoch - 32ms/step
Epoch 5/50
653/653 - 20s - loss: 2.4001 - accuracy10: 0.6415 - val_loss: 2.2586 - val_accuracy10: 0.7045 - 20s/epoch - 31ms/step
Epoch 6/50
653/653 - 21s - loss: 2.3688 - accuracy10: 0.6507 - val_loss: 2.2487 - val_accuracy10: 0.7014 - 21s/epoch - 32ms/step
Epoch 7/50
653/653 - 21s - loss: 2.3545 - accuracy10: 0.6530 - val_loss: 2.2475 - val_accuracy10: 0.7249 - 21s/epoch - 31ms/step
Epoch 8/50
653/653 - 21s - loss: 2.3325 - accuracy10: 0.6584 - val_loss: 2.2431 - val_accuracy10: 0.7177 - 21s/epoch - 31ms/step
Epoch 9/50
653/653 - 21s - loss: 2.3183 - accuracy10: 0.6593 - val_loss: 2.2647 - val_accuracy10: 0.7244 - 21s/epoch - 31ms/step
Epoch 10/50
653/653 - 21s - loss: 2.3040 - accuracy10: 0.6620 - val_loss: 2.2637 - val_accuracy10: 0.7260 - 21s/epoch - 31ms/step
Epoch 11/50
653/653 - 21s - loss: 2.2902 - accuracy10: 0.6648 - val_loss: 2.2581 - val_accuracy10: 0.7210 - 21s/epoch - 32ms/step
Epoch 12/50
653/653 - 21s - loss: 2.2825 - accuracy10: 0.6651 - val_loss: 2.2422 - val_accuracy10: 0.7399 - 21s/epoch - 32ms/step
Epoch 13/50
653/653 - 21s - loss: 2.2717 - accuracy10: 0.6658 - val_loss: 2.2807 - val_accuracy10: 0.7314 - 21s/epoch - 31ms/step
Epoch 14/50
653/653 - 21s - loss: 2.2670 - accuracy10: 0.6665 - val_loss: 2.3028 - val_accuracy10: 0.7301 - 21s/epoch - 32ms/step
Epoch 15/50
653/653 - 21s - loss: 2.2592 - accuracy10: 0.6662 - val_loss: 2.2478 - val_accuracy10: 0.7206 - 21s/epoch - 33ms/step
Epoch 16/50
653/653 - 22s - loss: 2.2511 - accuracy10: 0.6670 - val_loss: 2.2679 - val_accuracy10: 0.7264 - 22s/epoch - 33ms/step
Epoch 17/50
653/653 - 21s - loss: 2.2487 - accuracy10: 0.6686 - val_loss: 2.2555 - val_accuracy10: 0.7382 - 21s/epoch - 32ms/step
Epoch 18/50
653/653 - 21s - loss: 2.2377 - accuracy10: 0.6691 - val_loss: 2.2819 - val_accuracy10: 0.7384 - 21s/epoch - 33ms/step
Epoch 19/50
653/653 - 22s - loss: 2.2318 - accuracy10: 0.6699 - val_loss: 2.2698 - val_accuracy10: 0.7382 - 22s/epoch - 33ms/step
Epoch 20/50
653/653 - 21s - loss: 2.2223 - accuracy10: 0.6699 - val_loss: 2.2465 - val_accuracy10: 0.7422 - 21s/epoch - 33ms/step
Epoch 21/50
653/653 - 21s - loss: 2.2133 - accuracy10: 0.6722 - val_loss: 2.2541 - val_accuracy10: 0.7367 - 21s/epoch - 33ms/step
Epoch 22/50
653/653 - 21s - loss: 2.2024 - accuracy10: 0.6728 - val_loss: 2.2639 - val_accuracy10: 0.7373 - 21s/epoch - 32ms/step
testing model: results/QRTEA/W1/deepVOL_L3/h10
Evaluating performance on  test set...
1645/1645 - 22s - 22s/epoch - 13ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.57032454
{'0': {'precision': 0.27135432972262225, 'recall': 0.634394121263577, 'f1-score': 0.38011788232817595, 'support': 34157}, '1': {'precision': 0.9276976945113911, 'recall': 0.8095497242110395, 'f1-score': 0.8646061633468549, 'support': 352806}, '2': {'precision': 0.4246266638622638, 'recall': 0.4150732810526625, 'f1-score': 0.4197956273764259, 'support': 34047}, 'accuracy': 0.7634379230897128, 'macro avg': {'precision': 0.5412262293654256, 'recall': 0.619672375509093, 'f1-score': 0.5548398910171523, 'support': 421010}, 'weighted avg': {'precision': 0.833764582016199, 'recall': 0.7634379230897128, 'f1-score': 0.7893273563519136, 'support': 421010}}
[[ 21669   9493   2995]
 [ 51038 285614  16154]
 [  7148  12767  14132]]
Evaluating performance on  train set...
653/653 - 9s - 9s/epoch - 14ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.6887912
{'0': {'precision': 0.34915028665028663, 'recall': 0.6281425545630352, 'f1-score': 0.4488238197071886, 'support': 21718}, '1': {'precision': 0.8914608462569404, 'recall': 0.7500946458633716, 'f1-score': 0.8146907137576714, 'support': 124147}, '2': {'precision': 0.42166253313948515, 'recall': 0.46838930318719424, 'f1-score': 0.4437993654222642, 'support': 21053}, 'accuracy': 0.6986963658802526, 'macro avg': {'precision': 0.5540912220155708, 'recall': 0.6155421678712004, 'f1-score': 0.5691046329623748, 'support': 166918}, 'weighted avg': {'precision': 0.7616452205029829, 'recall': 0.6986963658802526, 'f1-score': 0.7203074072149755, 'support': 166918}}
[[13642  4935  3141]
 [20641 93122 10384]
 [ 4789  6403  9861]]
Evaluating performance on  val set...
181/181 - 3s - 3s/epoch - 14ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.6235498
{'0': {'precision': 0.36030461684911946, 'recall': 0.5922159202034031, 'f1-score': 0.448028408670563, 'support': 5113}, '1': {'precision': 0.9039180569956327, 'recall': 0.7930369104391212, 'f1-score': 0.8448549277575471, 'support': 36277}, '2': {'precision': 0.394124442977389, 'recall': 0.4873469387755102, 'f1-score': 0.43580618669586646, 'support': 4900}, 'accuracy': 0.73849643551523, 'macro avg': {'precision': 0.5527823722740471, 'recall': 0.6241999231393448, 'f1-score': 0.5762298410413255, 'support': 46290}, 'weighted avg': {'precision': 0.7899088924210266, 'recall': 0.73849643551523, 'f1-score': 0.7577235209030647, 'support': 46290}}
[[ 3028  1405   680]
 [ 4517 28769  2991]
 [  859  1653  2388]]
training model: results/QRTEA/W1/deepVOL_L3/h20
Epoch 1/50
653/653 - 24s - loss: 3.1161 - accuracy20: 0.4198 - val_loss: 2.7522 - val_accuracy20: 0.6630 - 24s/epoch - 37ms/step
Epoch 2/50
653/653 - 24s - loss: 2.6886 - accuracy20: 0.5859 - val_loss: 2.5306 - val_accuracy20: 0.6919 - 24s/epoch - 36ms/step
Epoch 3/50
653/653 - 23s - loss: 2.5554 - accuracy20: 0.6179 - val_loss: 2.4152 - val_accuracy20: 0.6860 - 23s/epoch - 36ms/step
Epoch 4/50
653/653 - 23s - loss: 2.4973 - accuracy20: 0.6286 - val_loss: 2.4156 - val_accuracy20: 0.6752 - 23s/epoch - 36ms/step
Epoch 5/50
653/653 - 23s - loss: 2.4626 - accuracy20: 0.6345 - val_loss: 2.3870 - val_accuracy20: 0.6867 - 23s/epoch - 35ms/step
Epoch 6/50
653/653 - 23s - loss: 2.4390 - accuracy20: 0.6399 - val_loss: 2.3825 - val_accuracy20: 0.7042 - 23s/epoch - 36ms/step
Epoch 7/50
653/653 - 23s - loss: 2.4239 - accuracy20: 0.6427 - val_loss: 2.3719 - val_accuracy20: 0.7054 - 23s/epoch - 35ms/step
Epoch 8/50
653/653 - 23s - loss: 2.4097 - accuracy20: 0.6472 - val_loss: 2.3775 - val_accuracy20: 0.7150 - 23s/epoch - 35ms/step
Epoch 9/50
653/653 - 23s - loss: 2.3974 - accuracy20: 0.6468 - val_loss: 2.3614 - val_accuracy20: 0.6987 - 23s/epoch - 35ms/step
Epoch 10/50
653/653 - 23s - loss: 2.3876 - accuracy20: 0.6500 - val_loss: 2.3626 - val_accuracy20: 0.6993 - 23s/epoch - 35ms/step
Epoch 11/50
653/653 - 23s - loss: 2.3736 - accuracy20: 0.6505 - val_loss: 2.4029 - val_accuracy20: 0.7021 - 23s/epoch - 35ms/step
Epoch 12/50
653/653 - 23s - loss: 2.3614 - accuracy20: 0.6523 - val_loss: 2.4092 - val_accuracy20: 0.7021 - 23s/epoch - 35ms/step
Epoch 13/50
653/653 - 23s - loss: 2.3527 - accuracy20: 0.6532 - val_loss: 2.3809 - val_accuracy20: 0.7036 - 23s/epoch - 35ms/step
Epoch 14/50
653/653 - 23s - loss: 2.3432 - accuracy20: 0.6535 - val_loss: 2.3634 - val_accuracy20: 0.7021 - 23s/epoch - 35ms/step
Epoch 15/50
653/653 - 23s - loss: 2.3344 - accuracy20: 0.6545 - val_loss: 2.3763 - val_accuracy20: 0.6967 - 23s/epoch - 35ms/step
Epoch 16/50
653/653 - 23s - loss: 2.3260 - accuracy20: 0.6546 - val_loss: 2.3768 - val_accuracy20: 0.7068 - 23s/epoch - 35ms/step
Epoch 17/50
653/653 - 23s - loss: 2.3156 - accuracy20: 0.6566 - val_loss: 2.3862 - val_accuracy20: 0.6967 - 23s/epoch - 35ms/step
Epoch 18/50
653/653 - 23s - loss: 2.3077 - accuracy20: 0.6565 - val_loss: 2.3955 - val_accuracy20: 0.7016 - 23s/epoch - 35ms/step
Epoch 19/50
653/653 - 23s - loss: 2.3006 - accuracy20: 0.6567 - val_loss: 2.4017 - val_accuracy20: 0.6976 - 23s/epoch - 35ms/step
testing model: results/QRTEA/W1/deepVOL_L3/h20
Evaluating performance on  test set...
1645/1645 - 22s - 22s/epoch - 14ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.6692184
{'0': {'precision': 0.3061482964118918, 'recall': 0.5784952669928844, 'f1-score': 0.40039931967758635, 'support': 46799}, '1': {'precision': 0.8844393672376203, 'recall': 0.7741874510306057, 'f1-score': 0.8256490872705577, 'support': 328011}, '2': {'precision': 0.45176760454935433, 'recall': 0.4445021645021645, 'f1-score': 0.44810543657331137, 'support': 46200}, 'accuracy': 0.7162561459347759, 'macro avg': {'precision': 0.5474517560662888, 'recall': 0.5990616275085515, 'f1-score': 0.5580512811738184, 'support': 421010}, 'weighted avg': {'precision': 0.7726774631028701, 'recall': 0.7162561459347759, 'f1-score': 0.7369486275764977, 'support': 421010}}
[[ 27073  14723   5003]
 [ 54151 253942  19918]
 [  7207  18457  20536]]
Evaluating performance on  train set...
653/653 - 9s - 9s/epoch - 14ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.77466744
{'0': {'precision': 0.39772262211415776, 'recall': 0.5824636863629954, 'f1-score': 0.4726835758121969, 'support': 28364}, '1': {'precision': 0.8358944281524927, 'recall': 0.7071166319359873, 'f1-score': 0.7661317121801514, 'support': 110853}, '2': {'precision': 0.4435198076192887, 'recall': 0.5060106133352587, 'f1-score': 0.47270887783492116, 'support': 27701}, 'accuracy': 0.6525599396110665, 'macro avg': {'precision': 0.5590456192953132, 'recall': 0.5985303105447471, 'f1-score': 0.5705080552757565, 'support': 166918}, 'weighted avg': {'precision': 0.6963200594812792, 'recall': 0.6525599396110665, 'f1-score': 0.6675715276935299, 'support': 166918}}
[[16521  6987  4856]
 [19736 78386 12731]
 [ 5282  8402 14017]]
Evaluating performance on  val set...
181/181 - 3s - 3s/epoch - 14ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.712517
{'0': {'precision': 0.42349338291589195, 'recall': 0.5587301587301587, 'f1-score': 0.48180177938157154, 'support': 6930}, '1': {'precision': 0.8531192598135927, 'recall': 0.766269477543538, 'f1-score': 0.8073654390934843, 'support': 32730}, '2': {'precision': 0.4323138469479933, 'recall': 0.5052790346907994, 'f1-score': 0.46595729883858406, 'support': 6630}, 'accuracy': 0.6978181032620436, 'macro avg': {'precision': 0.569642163225826, 'recall': 0.6100928903214987, 'f1-score': 0.5850415057712133, 'support': 46290}, 'weighted avg': {'precision': 0.7285297758170493, 'recall': 0.6978181032620436, 'f1-score': 0.7097268101953736, 'support': 46290}}
[[ 3872  2021  1037]
 [ 4288 25080  3362]
 [  983  2297  3350]]
training model: results/QRTEA/W1/deepVOL_L3/h30
Epoch 1/50
653/653 - 24s - loss: 3.1085 - accuracy30: 0.4427 - val_loss: 2.8108 - val_accuracy30: 0.6371 - 24s/epoch - 37ms/step
Epoch 2/50
653/653 - 21s - loss: 2.7467 - accuracy30: 0.5692 - val_loss: 2.6477 - val_accuracy30: 0.6435 - 21s/epoch - 33ms/step
Epoch 3/50
653/653 - 24s - loss: 2.6400 - accuracy30: 0.5990 - val_loss: 2.5766 - val_accuracy30: 0.6558 - 24s/epoch - 36ms/step
Epoch 4/50
653/653 - 23s - loss: 2.5915 - accuracy30: 0.6082 - val_loss: 2.5911 - val_accuracy30: 0.6674 - 23s/epoch - 35ms/step
Epoch 5/50
653/653 - 23s - loss: 2.5573 - accuracy30: 0.6147 - val_loss: 2.5917 - val_accuracy30: 0.6867 - 23s/epoch - 35ms/step
Epoch 6/50
653/653 - 23s - loss: 2.5302 - accuracy30: 0.6196 - val_loss: 2.5783 - val_accuracy30: 0.6805 - 23s/epoch - 35ms/step
Epoch 7/50
653/653 - 23s - loss: 2.5146 - accuracy30: 0.6231 - val_loss: 2.5586 - val_accuracy30: 0.6686 - 23s/epoch - 35ms/step
Epoch 8/50
653/653 - 23s - loss: 2.4976 - accuracy30: 0.6253 - val_loss: 2.5588 - val_accuracy30: 0.6748 - 23s/epoch - 35ms/step
Epoch 9/50
653/653 - 23s - loss: 2.4822 - accuracy30: 0.6254 - val_loss: 2.5703 - val_accuracy30: 0.6770 - 23s/epoch - 35ms/step
Epoch 10/50
653/653 - 21s - loss: 2.4716 - accuracy30: 0.6270 - val_loss: 2.5461 - val_accuracy30: 0.6637 - 21s/epoch - 32ms/step
Epoch 11/50
653/653 - 21s - loss: 2.4611 - accuracy30: 0.6276 - val_loss: 2.5345 - val_accuracy30: 0.6740 - 21s/epoch - 32ms/step
Epoch 12/50
653/653 - 21s - loss: 2.4482 - accuracy30: 0.6297 - val_loss: 2.5280 - val_accuracy30: 0.6806 - 21s/epoch - 32ms/step
Epoch 13/50
653/653 - 21s - loss: 2.4402 - accuracy30: 0.6312 - val_loss: 2.5363 - val_accuracy30: 0.6867 - 21s/epoch - 32ms/step
Epoch 14/50
653/653 - 21s - loss: 2.4285 - accuracy30: 0.6321 - val_loss: 2.5374 - val_accuracy30: 0.6699 - 21s/epoch - 32ms/step
Epoch 15/50
653/653 - 21s - loss: 2.4180 - accuracy30: 0.6329 - val_loss: 2.5340 - val_accuracy30: 0.6804 - 21s/epoch - 32ms/step
Epoch 16/50
653/653 - 21s - loss: 2.4049 - accuracy30: 0.6341 - val_loss: 2.5422 - val_accuracy30: 0.6785 - 21s/epoch - 32ms/step
Epoch 17/50
653/653 - 21s - loss: 2.3981 - accuracy30: 0.6353 - val_loss: 2.5462 - val_accuracy30: 0.6754 - 21s/epoch - 32ms/step
Epoch 18/50
653/653 - 23s - loss: 2.3913 - accuracy30: 0.6353 - val_loss: 2.5761 - val_accuracy30: 0.6765 - 23s/epoch - 35ms/step
Epoch 19/50
653/653 - 21s - loss: 2.3781 - accuracy30: 0.6366 - val_loss: 2.5494 - val_accuracy30: 0.6811 - 21s/epoch - 33ms/step
Epoch 20/50
653/653 - 21s - loss: 2.3721 - accuracy30: 0.6384 - val_loss: 2.5362 - val_accuracy30: 0.6738 - 21s/epoch - 33ms/step
Epoch 21/50
653/653 - 22s - loss: 2.3621 - accuracy30: 0.6388 - val_loss: 2.5553 - val_accuracy30: 0.6827 - 22s/epoch - 33ms/step
Epoch 22/50
653/653 - 21s - loss: 2.3535 - accuracy30: 0.6396 - val_loss: 2.5410 - val_accuracy30: 0.6727 - 21s/epoch - 33ms/step
testing model: results/QRTEA/W1/deepVOL_L3/h30
Evaluating performance on  test set...
1645/1645 - 24s - 24s/epoch - 14ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.71943694
{'0': {'precision': 0.3430911834447079, 'recall': 0.5628503226947219, 'f1-score': 0.42631667057287304, 'support': 56555}, '1': {'precision': 0.8425670249785153, 'recall': 0.7744064691143814, 'f1-score': 0.8070501553544139, 'support': 308914}, '2': {'precision': 0.5025053040220286, 'recall': 0.4008570245404296, 'f1-score': 0.44596232235320044, 'support': 55541}, 'accuracy': 0.6967079166765635, 'macro avg': {'precision': 0.562721170815084, 'recall': 0.5793712721165108, 'f1-score': 0.5597763827601625, 'support': 421010}, 'weighted avg': {'precision': 0.7306095316610437, 'recall': 0.6967079166765635, 'f1-score': 0.7082696951170314, 'support': 421010}}
[[ 31832  19703   5020]
 [ 52667 239225  17022]
 [  8281  24996  22264]]
Evaluating performance on  train set...
653/653 - 11s - 11s/epoch - 17ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.8182221
{'0': {'precision': 0.43586846231897425, 'recall': 0.5712170207621868, 'f1-score': 0.4944475690947379, 'support': 33089}, '1': {'precision': 0.7825964972860981, 'recall': 0.7147686394323166, 'f1-score': 0.7471463304075494, 'support': 101465}, '2': {'precision': 0.4914030372696953, 'recall': 0.4689160795946113, 'f1-score': 0.47989627966543863, 'support': 32364}, 'accuracy': 0.6386429264668879, 'macro avg': {'precision': 0.5699559989582559, 'recall': 0.5849672465963716, 'f1-score': 0.5738300597225753, 'support': 166918}, 'weighted avg': {'precision': 0.6574028747349171, 'recall': 0.6386429264668879, 'f1-score': 0.6452350329123884, 'support': 166918}}
[[18901  9178  5010]
 [18244 72524 10697]
 [ 6219 10969 15176]]
Evaluating performance on  val set...
181/181 - 3s - 3s/epoch - 17ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.7633964
{'0': {'precision': 0.45905286576967896, 'recall': 0.5275140004869735, 'f1-score': 0.49090806095281253, 'support': 8214}, '1': {'precision': 0.8007987165921425, 'recall': 0.7766485699152542, 'f1-score': 0.7885387782539282, 'support': 30208}, '2': {'precision': 0.48040773100344186, 'recall': 0.4612353838332486, 'f1-score': 0.4706263779016989, 'support': 7868}, 'accuracy': 0.6788291207604235, 'macro avg': {'precision': 0.5800864377884211, 'recall': 0.5884659847451588, 'f1-score': 0.5833577390361465, 'support': 46290}, 'weighted avg': {'precision': 0.6856996305418592, 'recall': 0.6788291207604235, 'f1-score': 0.6816890595699208, 'support': 46290}}
[[ 4333  2713  1168]
 [ 3990 23461  2757]
 [ 1116  3123  3629]]
training model: results/QRTEA/W1/deepVOL_L3/h50
Epoch 1/50
653/653 - 24s - loss: 3.2068 - accuracy50: 0.4141 - val_loss: 3.1365 - val_accuracy50: 0.5570 - 24s/epoch - 37ms/step
Epoch 2/50
653/653 - 21s - loss: 2.9319 - accuracy50: 0.5085 - val_loss: 2.8648 - val_accuracy50: 0.5949 - 21s/epoch - 32ms/step
Epoch 3/50
653/653 - 21s - loss: 2.8012 - accuracy50: 0.5563 - val_loss: 2.8159 - val_accuracy50: 0.5926 - 21s/epoch - 31ms/step
Epoch 4/50
653/653 - 21s - loss: 2.7479 - accuracy50: 0.5709 - val_loss: 2.7998 - val_accuracy50: 0.5881 - 21s/epoch - 32ms/step
Epoch 5/50
653/653 - 21s - loss: 2.7161 - accuracy50: 0.5753 - val_loss: 2.7783 - val_accuracy50: 0.5939 - 21s/epoch - 31ms/step
Epoch 6/50
653/653 - 21s - loss: 2.6857 - accuracy50: 0.5818 - val_loss: 2.7733 - val_accuracy50: 0.6045 - 21s/epoch - 32ms/step
Epoch 7/50
653/653 - 21s - loss: 2.6685 - accuracy50: 0.5854 - val_loss: 2.7761 - val_accuracy50: 0.6117 - 21s/epoch - 32ms/step
Epoch 8/50
653/653 - 21s - loss: 2.6534 - accuracy50: 0.5882 - val_loss: 2.7894 - val_accuracy50: 0.6060 - 21s/epoch - 32ms/step
Epoch 9/50
653/653 - 21s - loss: 2.6411 - accuracy50: 0.5920 - val_loss: 2.8089 - val_accuracy50: 0.6112 - 21s/epoch - 32ms/step
Epoch 10/50
653/653 - 21s - loss: 2.6278 - accuracy50: 0.5930 - val_loss: 2.7955 - val_accuracy50: 0.6157 - 21s/epoch - 32ms/step
Epoch 11/50
653/653 - 21s - loss: 2.6148 - accuracy50: 0.5956 - val_loss: 2.7990 - val_accuracy50: 0.5954 - 21s/epoch - 32ms/step
Epoch 12/50
653/653 - 21s - loss: 2.6056 - accuracy50: 0.5955 - val_loss: 2.7659 - val_accuracy50: 0.6116 - 21s/epoch - 32ms/step
Epoch 13/50
653/653 - 21s - loss: 2.5944 - accuracy50: 0.5979 - val_loss: 2.7754 - val_accuracy50: 0.6061 - 21s/epoch - 32ms/step
Epoch 14/50
653/653 - 21s - loss: 2.5832 - accuracy50: 0.5992 - val_loss: 2.7557 - val_accuracy50: 0.6085 - 21s/epoch - 32ms/step
Epoch 15/50
653/653 - 21s - loss: 2.5745 - accuracy50: 0.5996 - val_loss: 2.7491 - val_accuracy50: 0.6166 - 21s/epoch - 33ms/step
Epoch 16/50
653/653 - 21s - loss: 2.5635 - accuracy50: 0.6012 - val_loss: 2.7650 - val_accuracy50: 0.6226 - 21s/epoch - 33ms/step
Epoch 17/50
653/653 - 21s - loss: 2.5541 - accuracy50: 0.6037 - val_loss: 2.7666 - val_accuracy50: 0.6197 - 21s/epoch - 32ms/step
Epoch 18/50
653/653 - 21s - loss: 2.5483 - accuracy50: 0.6034 - val_loss: 2.7842 - val_accuracy50: 0.6254 - 21s/epoch - 32ms/step
Epoch 19/50
653/653 - 21s - loss: 2.5389 - accuracy50: 0.6048 - val_loss: 2.7810 - val_accuracy50: 0.6229 - 21s/epoch - 32ms/step
Epoch 20/50
653/653 - 21s - loss: 2.5280 - accuracy50: 0.6047 - val_loss: 2.7819 - val_accuracy50: 0.6149 - 21s/epoch - 32ms/step
Epoch 21/50
653/653 - 21s - loss: 2.5204 - accuracy50: 0.6057 - val_loss: 2.7380 - val_accuracy50: 0.6259 - 21s/epoch - 32ms/step
Epoch 22/50
653/653 - 20s - loss: 2.5100 - accuracy50: 0.6068 - val_loss: 2.7706 - val_accuracy50: 0.6169 - 20s/epoch - 31ms/step
Epoch 23/50
653/653 - 20s - loss: 2.5028 - accuracy50: 0.6076 - val_loss: 2.7533 - val_accuracy50: 0.6218 - 20s/epoch - 31ms/step
Epoch 24/50
653/653 - 21s - loss: 2.4913 - accuracy50: 0.6084 - val_loss: 2.7550 - val_accuracy50: 0.6110 - 21s/epoch - 32ms/step
Epoch 25/50
653/653 - 20s - loss: 2.4835 - accuracy50: 0.6105 - val_loss: 2.8083 - val_accuracy50: 0.6144 - 20s/epoch - 31ms/step
Epoch 26/50
653/653 - 21s - loss: 2.4772 - accuracy50: 0.6117 - val_loss: 2.7898 - val_accuracy50: 0.6090 - 21s/epoch - 32ms/step
Epoch 27/50
653/653 - 21s - loss: 2.4735 - accuracy50: 0.6116 - val_loss: 2.7680 - val_accuracy50: 0.5980 - 21s/epoch - 32ms/step
Epoch 28/50
653/653 - 21s - loss: 2.4578 - accuracy50: 0.6150 - val_loss: 2.7781 - val_accuracy50: 0.6046 - 21s/epoch - 32ms/step
Epoch 29/50
653/653 - 21s - loss: 2.4538 - accuracy50: 0.6148 - val_loss: 2.8164 - val_accuracy50: 0.6049 - 21s/epoch - 31ms/step
Epoch 30/50
653/653 - 20s - loss: 2.4410 - accuracy50: 0.6173 - val_loss: 2.8206 - val_accuracy50: 0.6003 - 20s/epoch - 31ms/step
Epoch 31/50
653/653 - 21s - loss: 2.4282 - accuracy50: 0.6192 - val_loss: 2.8524 - val_accuracy50: 0.6161 - 21s/epoch - 32ms/step
testing model: results/QRTEA/W1/deepVOL_L3/h50
Evaluating performance on  test set...
1645/1645 - 23s - 23s/epoch - 14ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.8118649
{'0': {'precision': 0.37887005762168724, 'recall': 0.5171359876115571, 'f1-score': 0.4373348650201034, 'support': 73617}, '1': {'precision': 0.7615858954629493, 'recall': 0.7647333432249239, 'f1-score': 0.7631563741422897, 'support': 276329}, '2': {'precision': 0.5441285767372724, 'recall': 0.3296746594618935, 'f1-score': 0.4105853487556958, 'support': 71064}, 'accuracy': 0.6480036103655495, 'macro avg': {'precision': 0.561528176607303, 'recall': 0.5371813300994582, 'f1-score': 0.5370255293060296, 'support': 421010}, 'weighted avg': {'precision': 0.65795942879403, 'recall': 0.6480036103655495, 'f1-score': 0.6466719453042077, 'support': 421010}}
[[ 38070  28566   6981]
 [ 52364 211318  12647]
 [ 10049  37587  23428]]
Evaluating performance on  train set...
653/653 - 10s - 10s/epoch - 15ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.88277966
{'0': {'precision': 0.46616142645661635, 'recall': 0.5256889420441521, 'f1-score': 0.4941388638412984, 'support': 40134}, '1': {'precision': 0.6848968830687773, 'recall': 0.7195952519945514, 'f1-score': 0.7018174511029739, 'support': 87363}, '2': {'precision': 0.5314027452293271, 'recall': 0.40265340808198674, 'f1-score': 0.458154738710655, 'support': 39421}, 'accuracy': 0.5981200349872392, 'macro avg': {'precision': 0.560820351584907, 'recall': 0.5493125340402302, 'f1-score': 0.5513703512183091, 'support': 166918}, 'weighted avg': {'precision': 0.5960531321045827, 'recall': 0.5981200349872392, 'f1-score': 0.5943371301886465, 'support': 166918}}
[[21098 12260  6776]
 [17276 62866  7221]
 [ 6885 16663 15873]]
Evaluating performance on  val set...
181/181 - 3s - 3s/epoch - 17ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.85211474
{'0': {'precision': 0.4835011464460173, 'recall': 0.4677403799787829, 'f1-score': 0.47549019607843135, 'support': 10369}, '1': {'precision': 0.6953396470668393, 'recall': 0.7800580906519912, 'f1-score': 0.7352665706051873, 'support': 26166}, '2': {'precision': 0.5191889934829833, 'recall': 0.3675038441824705, 'f1-score': 0.4303721488595438, 'support': 9755}, 'accuracy': 0.6231583495355368, 'macro avg': {'precision': 0.5660099289986134, 'recall': 0.5384341049377482, 'f1-score': 0.5470429718477209, 'support': 46290}, 'weighted avg': {'precision': 0.6107662394486104, 'recall': 0.6231583495355368, 'f1-score': 0.6128240060859244, 'support': 46290}}
[[ 4850  4155  1364]
 [ 3799 20411  1956]
 [ 1382  4788  3585]]
training model: results/QRTEA/W1/deepVOL_L3/h100
Epoch 1/50
653/653 - 24s - loss: 3.2888 - accuracy100: 0.3839 - val_loss: 3.2775 - val_accuracy100: 0.4165 - 24s/epoch - 36ms/step
Epoch 2/50
653/653 - 22s - loss: 3.1950 - accuracy100: 0.4103 - val_loss: 3.1852 - val_accuracy100: 0.4355 - 22s/epoch - 34ms/step
Epoch 3/50
653/653 - 23s - loss: 3.0777 - accuracy100: 0.4625 - val_loss: 3.0983 - val_accuracy100: 0.4908 - 23s/epoch - 35ms/step
Epoch 4/50
653/653 - 23s - loss: 2.9875 - accuracy100: 0.5001 - val_loss: 3.0601 - val_accuracy100: 0.4935 - 23s/epoch - 35ms/step
Epoch 5/50
653/653 - 23s - loss: 2.9509 - accuracy100: 0.5076 - val_loss: 3.0374 - val_accuracy100: 0.4990 - 23s/epoch - 36ms/step
Epoch 6/50
653/653 - 23s - loss: 2.9184 - accuracy100: 0.5154 - val_loss: 3.0552 - val_accuracy100: 0.4968 - 23s/epoch - 35ms/step
Epoch 7/50
653/653 - 22s - loss: 2.9025 - accuracy100: 0.5180 - val_loss: 3.0621 - val_accuracy100: 0.5018 - 22s/epoch - 33ms/step
Epoch 8/50
653/653 - 23s - loss: 2.8852 - accuracy100: 0.5239 - val_loss: 3.0649 - val_accuracy100: 0.5020 - 23s/epoch - 35ms/step
Epoch 9/50
653/653 - 23s - loss: 2.8709 - accuracy100: 0.5267 - val_loss: 3.0634 - val_accuracy100: 0.5021 - 23s/epoch - 35ms/step
Epoch 10/50
653/653 - 22s - loss: 2.8564 - accuracy100: 0.5295 - val_loss: 3.0472 - val_accuracy100: 0.5057 - 22s/epoch - 33ms/step
Epoch 11/50
653/653 - 23s - loss: 2.8469 - accuracy100: 0.5311 - val_loss: 3.0584 - val_accuracy100: 0.5031 - 23s/epoch - 35ms/step
Epoch 12/50
653/653 - 23s - loss: 2.8332 - accuracy100: 0.5339 - val_loss: 3.0291 - val_accuracy100: 0.5053 - 23s/epoch - 35ms/step
Epoch 13/50
653/653 - 22s - loss: 2.8220 - accuracy100: 0.5366 - val_loss: 3.0629 - val_accuracy100: 0.5048 - 22s/epoch - 33ms/step
Epoch 14/50
653/653 - 23s - loss: 2.8158 - accuracy100: 0.5359 - val_loss: 3.0761 - val_accuracy100: 0.5042 - 23s/epoch - 35ms/step
Epoch 15/50
653/653 - 23s - loss: 2.8084 - accuracy100: 0.5369 - val_loss: 3.0799 - val_accuracy100: 0.5040 - 23s/epoch - 35ms/step
Epoch 16/50
653/653 - 23s - loss: 2.8014 - accuracy100: 0.5386 - val_loss: 3.0716 - val_accuracy100: 0.5029 - 23s/epoch - 35ms/step
Epoch 17/50
653/653 - 23s - loss: 2.7860 - accuracy100: 0.5439 - val_loss: 3.0838 - val_accuracy100: 0.5036 - 23s/epoch - 35ms/step
Epoch 18/50
653/653 - 23s - loss: 2.7742 - accuracy100: 0.5449 - val_loss: 3.0892 - val_accuracy100: 0.5027 - 23s/epoch - 35ms/step
Epoch 19/50
653/653 - 23s - loss: 2.7630 - accuracy100: 0.5495 - val_loss: 3.1413 - val_accuracy100: 0.5021 - 23s/epoch - 35ms/step
Epoch 20/50
653/653 - 23s - loss: 2.7479 - accuracy100: 0.5526 - val_loss: 3.1764 - val_accuracy100: 0.4947 - 23s/epoch - 35ms/step
Epoch 21/50
653/653 - 23s - loss: 2.7417 - accuracy100: 0.5533 - val_loss: 3.1840 - val_accuracy100: 0.4933 - 23s/epoch - 35ms/step
Epoch 22/50
653/653 - 23s - loss: 2.7271 - accuracy100: 0.5570 - val_loss: 3.1758 - val_accuracy100: 0.4909 - 23s/epoch - 35ms/step
testing model: results/QRTEA/W1/deepVOL_L3/h100
Evaluating performance on  test set...
1645/1645 - 23s - 23s/epoch - 14ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 0.9792504
{'0': {'precision': 0.39870082397916445, 'recall': 0.4965053534002864, 'f1-score': 0.4422603384848012, 'support': 105447}, '1': {'precision': 0.6052255992051296, 'recall': 0.6648675398675399, 'f1-score': 0.6336462151148569, 'support': 216216}, '2': {'precision': 0.4976520422440726, 'recall': 0.26134659325394827, 'f1-score': 0.34271383315733894, 'support': 99347}, 'accuracy': 0.5274791572646731, 'macro avg': {'precision': 0.500526155142789, 'recall': 0.4742398288405915, 'f1-score': 0.4728734622523323, 'support': 421010}, 'weighted avg': {'precision': 0.528114537385547, 'recall': 0.5274791572646731, 'f1-score': 0.5170591367002277, 'support': 421010}}
[[ 52355  42789  10303]
 [ 56555 143755  15906]
 [ 22404  50979  25964]]
Evaluating performance on  train set...
653/653 - 9s - 9s/epoch - 14ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 0.9942374
{'0': {'precision': 0.4755547162685299, 'recall': 0.4891042573026725, 'f1-score': 0.482234328772632, 'support': 51488}, '1': {'precision': 0.5219821115442355, 'recall': 0.6415536088068843, 'f1-score': 0.5756239392337442, 'support': 64495}, '2': {'precision': 0.5048135124228973, 'recall': 0.3438500049082164, 'f1-score': 0.40906702168657816, 'support': 50935}, 'accuracy': 0.5036844438586612, 'macro avg': {'precision': 0.5007834467452209, 'recall': 0.491502623672591, 'f1-score': 0.4889750965643181, 'support': 166918}, 'weighted avg': {'precision': 0.5024219902619238, 'recall': 0.5036844438586612, 'f1-score': 0.49599189919799824, 'support': 166918}}
[[25183 16726  9579]
 [15517 41377  7601]
 [12255 21166 17514]]
Evaluating performance on  val set...
181/181 - 2s - 2s/epoch - 14ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 0.9974182
{'0': {'precision': 0.48566547831253715, 'recall': 0.4610774220843323, 'f1-score': 0.47305215944440426, 'support': 14182}, '1': {'precision': 0.5221680876979293, 'recall': 0.6754017435143367, 'f1-score': 0.5889814984429382, 'support': 19042}, '2': {'precision': 0.4862127867252318, 'recall': 0.3049900505127813, 'f1-score': 0.3748471451415671, 'support': 13066}, 'accuracy': 0.5051847051198963, 'macro avg': {'precision': 0.49801545091189947, 'recall': 0.4804897387038167, 'f1-score': 0.4789602676763032, 'support': 46290}, 'weighted avg': {'precision': 0.5008357919793529, 'recall': 0.5051847051198963, 'f1-score': 0.49302147800843993, 'support': 46290}}
[[ 6539  5632  2011]
 [ 3981 12861  2200]
 [ 2944  6137  3985]]
training model: results/QRTEA/W1/deepVOL_L3/h200
Epoch 1/50
653/653 - 24s - loss: 3.2915 - accuracy200: 0.3818 - val_loss: 3.4540 - val_accuracy200: 0.3086 - 24s/epoch - 37ms/step
Epoch 2/50
653/653 - 24s - loss: 3.2531 - accuracy200: 0.3908 - val_loss: 3.2809 - val_accuracy200: 0.3511 - 24s/epoch - 36ms/step
Epoch 3/50
653/653 - 22s - loss: 3.2225 - accuracy200: 0.4074 - val_loss: 3.2865 - val_accuracy200: 0.3296 - 22s/epoch - 33ms/step
Epoch 4/50
653/653 - 23s - loss: 3.1976 - accuracy200: 0.4186 - val_loss: 3.2527 - val_accuracy200: 0.3872 - 23s/epoch - 36ms/step
Epoch 5/50
653/653 - 23s - loss: 3.1631 - accuracy200: 0.4363 - val_loss: 3.2568 - val_accuracy200: 0.3962 - 23s/epoch - 36ms/step
Epoch 6/50
653/653 - 23s - loss: 3.1499 - accuracy200: 0.4407 - val_loss: 3.2554 - val_accuracy200: 0.4029 - 23s/epoch - 35ms/step
Epoch 7/50
653/653 - 23s - loss: 3.1327 - accuracy200: 0.4471 - val_loss: 3.2435 - val_accuracy200: 0.4076 - 23s/epoch - 35ms/step
Epoch 8/50
653/653 - 23s - loss: 3.1156 - accuracy200: 0.4522 - val_loss: 3.2386 - val_accuracy200: 0.4146 - 23s/epoch - 35ms/step
Epoch 9/50
653/653 - 23s - loss: 3.1003 - accuracy200: 0.4580 - val_loss: 3.2511 - val_accuracy200: 0.4145 - 23s/epoch - 35ms/step
Epoch 10/50
653/653 - 23s - loss: 3.0868 - accuracy200: 0.4620 - val_loss: 3.2477 - val_accuracy200: 0.4111 - 23s/epoch - 35ms/step
Epoch 11/50
653/653 - 23s - loss: 3.0709 - accuracy200: 0.4674 - val_loss: 3.2526 - val_accuracy200: 0.4119 - 23s/epoch - 35ms/step
Epoch 12/50
653/653 - 23s - loss: 3.0556 - accuracy200: 0.4716 - val_loss: 3.2521 - val_accuracy200: 0.4173 - 23s/epoch - 35ms/step
Epoch 13/50
653/653 - 23s - loss: 3.0374 - accuracy200: 0.4792 - val_loss: 3.3239 - val_accuracy200: 0.4114 - 23s/epoch - 35ms/step
Epoch 14/50
653/653 - 23s - loss: 3.0313 - accuracy200: 0.4793 - val_loss: 3.3436 - val_accuracy200: 0.4115 - 23s/epoch - 35ms/step
Epoch 15/50
653/653 - 23s - loss: 3.0132 - accuracy200: 0.4874 - val_loss: 3.3618 - val_accuracy200: 0.4083 - 23s/epoch - 35ms/step
Epoch 16/50
653/653 - 23s - loss: 3.0051 - accuracy200: 0.4892 - val_loss: 3.3397 - val_accuracy200: 0.4147 - 23s/epoch - 35ms/step
Epoch 17/50
653/653 - 23s - loss: 2.9889 - accuracy200: 0.4977 - val_loss: 3.3674 - val_accuracy200: 0.4113 - 23s/epoch - 35ms/step
Epoch 18/50
653/653 - 23s - loss: 2.9783 - accuracy200: 0.4980 - val_loss: 3.3379 - val_accuracy200: 0.4113 - 23s/epoch - 35ms/step
testing model: results/QRTEA/W1/deepVOL_L3/h200
Evaluating performance on  test set...
1645/1645 - 29s - 29s/epoch - 18ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.080744
{'0': {'precision': 0.413365671397201, 'recall': 0.4756197817282237, 'f1-score': 0.44231295284454764, 'support': 132587}, '1': {'precision': 0.43734854431891873, 'recall': 0.6219346462329972, 'f1-score': 0.5135590078603669, 'support': 164826}, '2': {'precision': 0.42691483427766197, 'recall': 0.11765657742501841, 'f1-score': 0.18447291640238486, 'support': 123597}, 'accuracy': 0.42781406617420015, 'macro avg': {'precision': 0.42587634999792723, 'recall': 0.4050703351287464, 'f1-score': 0.3801149590357665, 'support': 421010}, 'weighted avg': {'precision': 0.4267326624347806, 'recall': 0.42781406617420015, 'f1-score': 0.3945111126979845, 'support': 421010}}
[[ 63061  60371   9155]
 [ 51949 102511  10366]
 [ 37545  71510  14542]]
Evaluating performance on  train set...
653/653 - 11s - 11s/epoch - 17ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.079241
{'0': {'precision': 0.43833952456955605, 'recall': 0.5326353728653566, 'f1-score': 0.4809086964606707, 'support': 58265}, '1': {'precision': 0.3792954317982429, 'recall': 0.5859468952220971, 'f1-score': 0.46049986498244766, 'support': 52387}, '2': {'precision': 0.48380513495720867, 'recall': 0.13061173710588989, 'f1-score': 0.20569301388266903, 'support': 56266}, 'accuracy': 0.4138499143291916, 'macro avg': {'precision': 0.4338133637750025, 'recall': 0.41639800173111446, 'f1-score': 0.38236719177526246, 'support': 166918}, 'weighted avg': {'precision': 0.43513450860998837, 'recall': 0.4138499143291916, 'f1-score': 0.3817315972228203, 'support': 166918}}
[[31034 22530  4701]
 [18551 30696  3140]
 [21214 27703  7349]]
Evaluating performance on  val set...
181/181 - 3s - 3s/epoch - 18ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0856681
{'0': {'precision': 0.4705985915492958, 'recall': 0.47820382849305265, 'f1-score': 0.4743707296873614, 'support': 16769}, '1': {'precision': 0.3690872751499001, 'recall': 0.6223407989889771, 'f1-score': 0.4633680963956193, 'support': 14243}, '2': {'precision': 0.43599541459686664, 'recall': 0.1493651001439979, 'f1-score': 0.22250390015600624, 'support': 15278}, 'accuracy': 0.4140203067617196, 'macro avg': {'precision': 0.42522709376535417, 'recall': 0.41663657587534253, 'f1-score': 0.38674757541299565, 'support': 46290}, 'weighted avg': {'precision': 0.4279437413234197, 'recall': 0.4140203067617196, 'f1-score': 0.38785675415151505, 'support': 46290}}
[[8019 7134 1616]
 [4043 8864 1336]
 [4978 8018 2282]]
training model: results/QRTEA/W1/deepVOL_L3/h300
Epoch 1/50
653/653 - 24s - loss: 3.3091 - accuracy300: 0.3732 - val_loss: 3.3488 - val_accuracy300: 0.3332 - 24s/epoch - 37ms/step
Epoch 2/50
653/653 - 21s - loss: 3.2836 - accuracy300: 0.3744 - val_loss: 3.2821 - val_accuracy300: 0.3629 - 21s/epoch - 33ms/step
Epoch 3/50
653/653 - 21s - loss: 3.2627 - accuracy300: 0.3806 - val_loss: 3.2724 - val_accuracy300: 0.3625 - 21s/epoch - 32ms/step
Epoch 4/50
653/653 - 21s - loss: 3.2440 - accuracy300: 0.3899 - val_loss: 3.2785 - val_accuracy300: 0.3521 - 21s/epoch - 32ms/step
Epoch 5/50
653/653 - 21s - loss: 3.2300 - accuracy300: 0.4009 - val_loss: 3.3235 - val_accuracy300: 0.3463 - 21s/epoch - 32ms/step
Epoch 6/50
653/653 - 21s - loss: 3.2231 - accuracy300: 0.4061 - val_loss: 3.3299 - val_accuracy300: 0.3423 - 21s/epoch - 32ms/step
Epoch 7/50
653/653 - 21s - loss: 3.2112 - accuracy300: 0.4138 - val_loss: 3.3575 - val_accuracy300: 0.3454 - 21s/epoch - 32ms/step
Epoch 8/50
653/653 - 21s - loss: 3.2050 - accuracy300: 0.4160 - val_loss: 3.3924 - val_accuracy300: 0.3393 - 21s/epoch - 32ms/step
Epoch 9/50
653/653 - 20s - loss: 3.1937 - accuracy300: 0.4221 - val_loss: 3.3933 - val_accuracy300: 0.3402 - 20s/epoch - 31ms/step
Epoch 10/50
653/653 - 21s - loss: 3.1924 - accuracy300: 0.4235 - val_loss: 3.3868 - val_accuracy300: 0.3483 - 21s/epoch - 32ms/step
Epoch 11/50
653/653 - 21s - loss: 3.1756 - accuracy300: 0.4311 - val_loss: 3.4067 - val_accuracy300: 0.3519 - 21s/epoch - 31ms/step
Epoch 12/50
653/653 - 21s - loss: 3.1633 - accuracy300: 0.4376 - val_loss: 3.3812 - val_accuracy300: 0.3540 - 21s/epoch - 32ms/step
Epoch 13/50
653/653 - 21s - loss: 3.1493 - accuracy300: 0.4433 - val_loss: 3.3991 - val_accuracy300: 0.3606 - 21s/epoch - 32ms/step
testing model: results/QRTEA/W1/deepVOL_L3/h300
Evaluating performance on  test set...
1645/1645 - 22s - 22s/epoch - 13ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0815046
{'0': {'precision': 0.3869601658652786, 'recall': 0.32494184237431284, 'f1-score': 0.3532495983054328, 'support': 134978}, '1': {'precision': 0.38688666691084006, 'recall': 0.38952602207635767, 'f1-score': 0.3882018583512492, 'support': 162708}, '2': {'precision': 0.3593331803930565, 'recall': 0.4191317180759625, 'f1-score': 0.3869357078425428, 'support': 123324}, 'accuracy': 0.3774922210873851, 'macro avg': {'precision': 0.37772667105639174, 'recall': 0.37786652750887767, 'f1-score': 0.3761290548330749, 'support': 421010}, 'weighted avg': {'precision': 0.3788391492047358, 'recall': 0.3774922210873851, 'f1-score': 0.376625095562242, 'support': 421010}}
[[43860 52183 38935]
 [46106 63379 53223]
 [23379 48256 51689]]
Evaluating performance on  train set...
653/653 - 9s - 9s/epoch - 13ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0886437
{'0': {'precision': 0.40046977670740047, 'recall': 0.23774977052884275, 'f1-score': 0.29836628454339037, 'support': 56652}, '1': {'precision': 0.33924161195108726, 'recall': 0.39959201773835923, 'f1-score': 0.3669520031927284, 'support': 56375}, '2': {'precision': 0.37965939504493057, 'recall': 0.47117329424208126, 'f1-score': 0.4204948166793628, 'support': 53891}, 'accuracy': 0.3677733977162439, 'macro avg': {'precision': 0.37312359456780614, 'recall': 0.36950502750309444, 'f1-score': 0.3619377014718272, 'support': 166918}, 'weighted avg': {'precision': 0.3730717125902332, 'recall': 0.3677733977162439, 'f1-score': 0.3609607837238031, 'support': 166918}}
[[13469 22806 20377]
 [12736 22527 21112]
 [ 7428 21071 25392]]
Evaluating performance on  val set...
181/181 - 2s - 2s/epoch - 14ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0908475
{'0': {'precision': 0.43052003410059675, 'recall': 0.21814254859611232, 'f1-score': 0.28956422018348627, 'support': 16205}, '1': {'precision': 0.3282985339848956, 'recall': 0.3890241495031914, 'f1-score': 0.35609095015810877, 'support': 15197}, '2': {'precision': 0.3699865477554681, 'recall': 0.4987909725953788, 'f1-score': 0.42484052747504214, 'support': 14888}, 'accuracy': 0.3645063728667099, 'macro avg': {'precision': 0.3762683719469868, 'recall': 0.3686525568982275, 'f1-score': 0.35683189927221237, 'support': 46290}, 'weighted avg': {'precision': 0.3774916763135026, 'recall': 0.3645063728667099, 'f1-score': 0.35491311580632107, 'support': 46290}}
[[3535 6558 6112]
 [2752 5912 6533]
 [1924 5538 7426]]
training model: results/QRTEA/W1/deepVOL_L3/h500
Epoch 1/50
653/653 - 24s - loss: 3.2598 - accuracy500: 0.4050 - val_loss: 3.3029 - val_accuracy500: 0.3274 - 24s/epoch - 37ms/step
Epoch 2/50
653/653 - 22s - loss: 3.2542 - accuracy500: 0.4001 - val_loss: 3.3335 - val_accuracy500: 0.2767 - 22s/epoch - 34ms/step
Epoch 3/50
653/653 - 21s - loss: 3.2478 - accuracy500: 0.4043 - val_loss: 3.3848 - val_accuracy500: 0.2738 - 21s/epoch - 33ms/step
Epoch 4/50
653/653 - 21s - loss: 3.2480 - accuracy500: 0.4060 - val_loss: 3.3029 - val_accuracy500: 0.3479 - 21s/epoch - 32ms/step
Epoch 5/50
653/653 - 24s - loss: 3.2607 - accuracy500: 0.3940 - val_loss: 3.2863 - val_accuracy500: 0.3645 - 24s/epoch - 36ms/step
Epoch 6/50
653/653 - 23s - loss: 3.2582 - accuracy500: 0.3955 - val_loss: 3.2816 - val_accuracy500: 0.3691 - 23s/epoch - 36ms/step
Epoch 7/50
653/653 - 21s - loss: 3.2540 - accuracy500: 0.3896 - val_loss: 3.2914 - val_accuracy500: 0.3628 - 21s/epoch - 32ms/step
Epoch 8/50
653/653 - 21s - loss: 3.2474 - accuracy500: 0.3931 - val_loss: 3.3068 - val_accuracy500: 0.3644 - 21s/epoch - 33ms/step
Epoch 9/50
653/653 - 21s - loss: 3.2422 - accuracy500: 0.3961 - val_loss: 3.2949 - val_accuracy500: 0.3704 - 21s/epoch - 32ms/step
Epoch 10/50
653/653 - 21s - loss: 3.2363 - accuracy500: 0.4008 - val_loss: 3.3171 - val_accuracy500: 0.3659 - 21s/epoch - 32ms/step
Epoch 11/50
653/653 - 21s - loss: 3.2421 - accuracy500: 0.3962 - val_loss: 3.3065 - val_accuracy500: 0.3641 - 21s/epoch - 31ms/step
Epoch 12/50
653/653 - 21s - loss: 3.2376 - accuracy500: 0.4023 - val_loss: 3.3135 - val_accuracy500: 0.3668 - 21s/epoch - 32ms/step
Epoch 13/50
653/653 - 21s - loss: 3.2279 - accuracy500: 0.4047 - val_loss: 3.2902 - val_accuracy500: 0.3784 - 21s/epoch - 32ms/step
Epoch 14/50
653/653 - 21s - loss: 3.2077 - accuracy500: 0.4214 - val_loss: 3.2949 - val_accuracy500: 0.3813 - 21s/epoch - 32ms/step
Epoch 15/50
653/653 - 21s - loss: 3.2083 - accuracy500: 0.4183 - val_loss: 3.2915 - val_accuracy500: 0.3824 - 21s/epoch - 32ms/step
Epoch 16/50
653/653 - 21s - loss: 3.2025 - accuracy500: 0.4226 - val_loss: 3.2910 - val_accuracy500: 0.3843 - 21s/epoch - 32ms/step
testing model: results/QRTEA/W1/deepVOL_L3/h500
Evaluating performance on  test set...
1645/1645 - 22s - 22s/epoch - 13ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1074384
{'0': {'precision': 0.3799225532271819, 'recall': 0.349588371494726, 'f1-score': 0.36412479148941873, 'support': 155480}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 127553}, '2': {'precision': 0.3327684713467461, 'recall': 0.670336360407894, 'f1-score': 0.4447527294846858, 'support': 137977}, 'accuracy': 0.34879219020925867, 'macro avg': {'precision': 0.237563674857976, 'recall': 0.33997491063420665, 'f1-score': 0.26962584032470155, 'support': 421010}, 'weighted avg': {'precision': 0.2493640387325057, 'recall': 0.34879219020925867, 'f1-score': 0.2802303269206986, 'support': 421010}}
[[ 54354      0 101126]
 [ 43226      0  84327]
 [ 45486      0  92491]]
Evaluating performance on  train set...
653/653 - 9s - 9s/epoch - 14ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1020868
{'0': {'precision': 0.38204868154158217, 'recall': 0.38936742006615216, 'f1-score': 0.38567333287830186, 'support': 58048}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 56058}, '2': {'precision': 0.3574119786929973, 'recall': 0.7292660758918428, 'f1-score': 0.47971601170828926, 'support': 52812}, 'accuracy': 0.3661438550665596, 'macro avg': {'precision': 0.24648688674485983, 'recall': 0.3728778319859983, 'f1-score': 0.28846311486219706, 'support': 166918}, 'weighted avg': {'precision': 0.2459459332418333, 'recall': 0.3661438550665596, 'f1-score': 0.2859028243644055, 'support': 166918}}
[[22602     0 35446]
 [22260     0 33798]
 [14298     0 38514]]
Evaluating performance on  val set...
181/181 - 3s - 3s/epoch - 14ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0945969
{'0': {'precision': 0.4063069376313945, 'recall': 0.32186077495281445, 'f1-score': 0.35918721348036176, 'support': 18014}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12021}, '2': {'precision': 0.35212367270455963, 'recall': 0.6936327283912642, 'f1-score': 0.4671154842050751, 'support': 16255}, 'accuracy': 0.36882696046662344, 'macro avg': {'precision': 0.25281020344531807, 'recall': 0.3384978344480262, 'f1-score': 0.27543423256181226, 'support': 46290}, 'weighted avg': {'precision': 0.2817667633247906, 'recall': 0.36882696046662344, 'f1-score': 0.3038099083903377, 'support': 46290}}
[[ 5798     0 12216]
 [ 3492     0  8529]
 [ 4980     0 11275]]
training model: results/QRTEA/W1/deepVOL_L3/h1000
Epoch 1/50
653/653 - 24s - loss: 3.2382 - accuracy1000: 0.4206 - val_loss: 3.2130 - val_accuracy1000: 0.3821 - 24s/epoch - 37ms/step
Epoch 2/50
653/653 - 21s - loss: 3.2280 - accuracy1000: 0.4109 - val_loss: 3.3255 - val_accuracy1000: 0.3191 - 21s/epoch - 33ms/step
Epoch 3/50
653/653 - 21s - loss: 3.2634 - accuracy1000: 0.3893 - val_loss: 3.1837 - val_accuracy1000: 0.3792 - 21s/epoch - 33ms/step
Epoch 4/50
653/653 - 22s - loss: 3.2294 - accuracy1000: 0.4128 - val_loss: 3.2189 - val_accuracy1000: 0.3876 - 22s/epoch - 33ms/step
Epoch 5/50
653/653 - 21s - loss: 3.2172 - accuracy1000: 0.4139 - val_loss: 3.2469 - val_accuracy1000: 0.3851 - 21s/epoch - 32ms/step
Epoch 6/50
653/653 - 21s - loss: 3.2099 - accuracy1000: 0.4162 - val_loss: 3.2393 - val_accuracy1000: 0.3749 - 21s/epoch - 32ms/step
Epoch 7/50
653/653 - 21s - loss: 3.2395 - accuracy1000: 0.4033 - val_loss: 3.2918 - val_accuracy1000: 0.3816 - 21s/epoch - 32ms/step
Epoch 8/50
653/653 - 21s - loss: 3.2293 - accuracy1000: 0.4139 - val_loss: 3.2680 - val_accuracy1000: 0.3768 - 21s/epoch - 32ms/step
Epoch 9/50
653/653 - 21s - loss: 3.2449 - accuracy1000: 0.4012 - val_loss: 3.2551 - val_accuracy1000: 0.3802 - 21s/epoch - 33ms/step
Epoch 10/50
653/653 - 23s - loss: 3.2316 - accuracy1000: 0.4062 - val_loss: 3.2793 - val_accuracy1000: 0.3798 - 23s/epoch - 35ms/step
Epoch 11/50
653/653 - 21s - loss: 3.2274 - accuracy1000: 0.4118 - val_loss: 3.2711 - val_accuracy1000: 0.3797 - 21s/epoch - 32ms/step
Epoch 12/50
653/653 - 21s - loss: 3.2118 - accuracy1000: 0.4154 - val_loss: 3.3389 - val_accuracy1000: 0.3797 - 21s/epoch - 32ms/step
Epoch 13/50
653/653 - 21s - loss: 3.2156 - accuracy1000: 0.4229 - val_loss: 3.3220 - val_accuracy1000: 0.3833 - 21s/epoch - 32ms/step
testing model: results/QRTEA/W1/deepVOL_L3/h1000
Evaluating performance on  test set...
1645/1645 - 22s - 22s/epoch - 13ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0715307
{'0': {'precision': 0.4318649947602356, 'recall': 0.13619295616549193, 'f1-score': 0.2070808804099685, 'support': 175501}, '1': {'precision': 1.0, 'recall': 1.1723054559095918e-05, 'f1-score': 2.3445834261397608e-05, 'support': 85302}, '2': {'precision': 0.3804896858582903, 'recall': 0.868445199023763, 'f1-score': 0.5291459866506931, 'support': 160207}, 'accuracy': 0.3872449585520534, 'macro avg': {'precision': 0.6041182268728419, 'recall': 0.334883292747938, 'f1-score': 0.24541677096497436, 'support': 421010}, 'weighted avg': {'precision': 0.5274265446134657, 'recall': 0.3872449585520534, 'f1-score': 0.28768388554364893, 'support': 421010}}
[[ 23902      0 151599]
 [ 10368      1  74933]
 [ 21076      0 139131]]
Evaluating performance on  train set...
653/653 - 9s - 9s/epoch - 14ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1209967
{'0': {'precision': 0.3678992279561154, 'recall': 0.15142493979127641, 'f1-score': 0.21454467903604177, 'support': 59792}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 53594}, '2': {'precision': 0.32505551339348454, 'recall': 0.8641186579989539, 'f1-score': 0.47240604575163403, 'support': 53532}, 'accuracy': 0.3313722905857966, 'macro avg': {'precision': 0.2309849137832, 'recall': 0.3385145325967434, 'f1-score': 0.22898357492922528, 'support': 166918}, 'weighted avg': {'precision': 0.2360338752017881, 'recall': 0.3313722905857966, 'f1-score': 0.22835701296504557, 'support': 166918}}
[[ 9054     0 50738]
 [ 8282     0 45312]
 [ 7274     0 46258]]
Evaluating performance on  val set...
181/181 - 2s - 2s/epoch - 14ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0691535
{'0': {'precision': 0.4375606599805888, 'recall': 0.13567057879426223, 'f1-score': 0.20712098009188362, 'support': 19938}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 8992}, '2': {'precision': 0.37456367806921315, 'recall': 0.8653801843317972, 'f1-score': 0.5228300967494953, 'support': 17360}, 'accuracy': 0.38297688485634046, 'macro avg': {'precision': 0.27070811268326733, 'recall': 0.3336835877086865, 'f1-score': 0.24331702561379298, 'support': 46290}, 'weighted avg': {'precision': 0.32893734910292766, 'recall': 0.38297688485634046, 'f1-score': 0.28528642429559764, 'support': 46290}}
[[ 2705     0 17233]
 [ 1140     0  7852]
 [ 2337     0 15023]]

============================================

        Job resource usage summary 

                 Memory (GB)    NCPUs
 Requested  :        96            32
 Used       :        16 (peak)  14.66 (ave)

============================================
