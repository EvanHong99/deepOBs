This machine has 1 visible gpus.
This machine has 1 physical gpus.
getting alphas...
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-06-26.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-06-18.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-06-05.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-06-06.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-06-14.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-06-10.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-06-12.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-06-07.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-06-28.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-06-11.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-06-24.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-06-13.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-06-04.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-06-20.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-06-19.csv
training model: results/QRTEA/W4/deepLOB_L1/h10
Epoch 1/50
634/634 - 30s - loss: 2.9697 - accuracy10: 0.4185 - val_loss: 2.5074 - val_accuracy10: 0.4030 - 30s/epoch - 48ms/step
Epoch 2/50
634/634 - 10s - loss: 2.8075 - accuracy10: 0.4623 - val_loss: 2.4855 - val_accuracy10: 0.3437 - 10s/epoch - 16ms/step
Epoch 3/50
634/634 - 10s - loss: 2.6837 - accuracy10: 0.5272 - val_loss: 2.3734 - val_accuracy10: 0.4414 - 10s/epoch - 16ms/step
Epoch 4/50
634/634 - 10s - loss: 2.5914 - accuracy10: 0.5710 - val_loss: 2.3203 - val_accuracy10: 0.4729 - 10s/epoch - 16ms/step
Epoch 5/50
634/634 - 10s - loss: 2.5290 - accuracy10: 0.5954 - val_loss: 2.2846 - val_accuracy10: 0.5116 - 10s/epoch - 16ms/step
Epoch 6/50
634/634 - 10s - loss: 2.4812 - accuracy10: 0.6140 - val_loss: 2.2590 - val_accuracy10: 0.5452 - 10s/epoch - 16ms/step
Epoch 7/50
634/634 - 10s - loss: 2.4420 - accuracy10: 0.6283 - val_loss: 2.2528 - val_accuracy10: 0.5416 - 10s/epoch - 16ms/step
Epoch 8/50
634/634 - 10s - loss: 2.4261 - accuracy10: 0.6303 - val_loss: 2.2467 - val_accuracy10: 0.5464 - 10s/epoch - 16ms/step
Epoch 9/50
634/634 - 10s - loss: 2.3987 - accuracy10: 0.6384 - val_loss: 2.3044 - val_accuracy10: 0.5052 - 10s/epoch - 16ms/step
Epoch 10/50
634/634 - 10s - loss: 2.3747 - accuracy10: 0.6422 - val_loss: 2.2331 - val_accuracy10: 0.5422 - 10s/epoch - 16ms/step
Epoch 11/50
634/634 - 10s - loss: 2.3605 - accuracy10: 0.6443 - val_loss: 2.2806 - val_accuracy10: 0.5101 - 10s/epoch - 16ms/step
Epoch 12/50
634/634 - 10s - loss: 2.3418 - accuracy10: 0.6484 - val_loss: 2.2431 - val_accuracy10: 0.5321 - 10s/epoch - 16ms/step
Epoch 13/50
634/634 - 10s - loss: 2.3311 - accuracy10: 0.6524 - val_loss: 2.2002 - val_accuracy10: 0.5503 - 10s/epoch - 16ms/step
Epoch 14/50
634/634 - 10s - loss: 2.3097 - accuracy10: 0.6567 - val_loss: 2.2405 - val_accuracy10: 0.5260 - 10s/epoch - 16ms/step
Epoch 15/50
634/634 - 10s - loss: 2.2985 - accuracy10: 0.6581 - val_loss: 2.2659 - val_accuracy10: 0.5058 - 10s/epoch - 16ms/step
Epoch 16/50
634/634 - 10s - loss: 2.2865 - accuracy10: 0.6596 - val_loss: 2.2413 - val_accuracy10: 0.5195 - 10s/epoch - 16ms/step
Epoch 17/50
634/634 - 10s - loss: 2.2783 - accuracy10: 0.6602 - val_loss: 2.2629 - val_accuracy10: 0.5125 - 10s/epoch - 16ms/step
Epoch 18/50
634/634 - 10s - loss: 2.2665 - accuracy10: 0.6629 - val_loss: 2.2123 - val_accuracy10: 0.5389 - 10s/epoch - 16ms/step
Epoch 19/50
634/634 - 10s - loss: 2.2541 - accuracy10: 0.6647 - val_loss: 2.2036 - val_accuracy10: 0.5421 - 10s/epoch - 16ms/step
Epoch 20/50
634/634 - 10s - loss: 2.2490 - accuracy10: 0.6643 - val_loss: 2.2051 - val_accuracy10: 0.5448 - 10s/epoch - 16ms/step
Epoch 21/50
634/634 - 10s - loss: 2.2379 - accuracy10: 0.6660 - val_loss: 2.2077 - val_accuracy10: 0.5538 - 10s/epoch - 16ms/step
Epoch 22/50
634/634 - 10s - loss: 2.2314 - accuracy10: 0.6654 - val_loss: 2.2444 - val_accuracy10: 0.5155 - 10s/epoch - 16ms/step
Epoch 23/50
634/634 - 10s - loss: 2.2215 - accuracy10: 0.6664 - val_loss: 2.1828 - val_accuracy10: 0.5608 - 10s/epoch - 16ms/step
Epoch 24/50
634/634 - 10s - loss: 2.2125 - accuracy10: 0.6672 - val_loss: 2.2734 - val_accuracy10: 0.5030 - 10s/epoch - 16ms/step
Epoch 25/50
634/634 - 10s - loss: 2.2039 - accuracy10: 0.6688 - val_loss: 2.2297 - val_accuracy10: 0.5332 - 10s/epoch - 16ms/step
Epoch 26/50
634/634 - 10s - loss: 2.2035 - accuracy10: 0.6656 - val_loss: 2.2885 - val_accuracy10: 0.4966 - 10s/epoch - 16ms/step
Epoch 27/50
634/634 - 10s - loss: 2.1934 - accuracy10: 0.6696 - val_loss: 2.2063 - val_accuracy10: 0.5522 - 10s/epoch - 16ms/step
Epoch 28/50
634/634 - 10s - loss: 2.1871 - accuracy10: 0.6680 - val_loss: 2.2171 - val_accuracy10: 0.5442 - 10s/epoch - 16ms/step
Epoch 29/50
634/634 - 10s - loss: 2.1785 - accuracy10: 0.6703 - val_loss: 2.1761 - val_accuracy10: 0.5806 - 10s/epoch - 16ms/step
Epoch 30/50
634/634 - 10s - loss: 2.1684 - accuracy10: 0.6716 - val_loss: 2.1672 - val_accuracy10: 0.5703 - 10s/epoch - 16ms/step
Epoch 31/50
634/634 - 10s - loss: 2.1680 - accuracy10: 0.6707 - val_loss: 2.1571 - val_accuracy10: 0.5891 - 10s/epoch - 16ms/step
Epoch 32/50
634/634 - 10s - loss: 2.1615 - accuracy10: 0.6712 - val_loss: 2.1747 - val_accuracy10: 0.5893 - 10s/epoch - 16ms/step
Epoch 33/50
634/634 - 10s - loss: 2.1506 - accuracy10: 0.6740 - val_loss: 2.1944 - val_accuracy10: 0.5694 - 10s/epoch - 16ms/step
Epoch 34/50
634/634 - 10s - loss: 2.1462 - accuracy10: 0.6736 - val_loss: 2.1613 - val_accuracy10: 0.5805 - 10s/epoch - 16ms/step
Epoch 35/50
634/634 - 10s - loss: 2.1410 - accuracy10: 0.6743 - val_loss: 2.1538 - val_accuracy10: 0.5945 - 10s/epoch - 16ms/step
Epoch 36/50
634/634 - 10s - loss: 2.1328 - accuracy10: 0.6738 - val_loss: 2.2293 - val_accuracy10: 0.5490 - 10s/epoch - 16ms/step
Epoch 37/50
634/634 - 10s - loss: 2.1278 - accuracy10: 0.6718 - val_loss: 2.2346 - val_accuracy10: 0.5433 - 10s/epoch - 16ms/step
Epoch 38/50
634/634 - 10s - loss: 2.1241 - accuracy10: 0.6743 - val_loss: 2.1912 - val_accuracy10: 0.5883 - 10s/epoch - 16ms/step
Epoch 39/50
634/634 - 10s - loss: 2.1127 - accuracy10: 0.6753 - val_loss: 2.2543 - val_accuracy10: 0.5548 - 10s/epoch - 16ms/step
Epoch 40/50
634/634 - 10s - loss: 2.1059 - accuracy10: 0.6761 - val_loss: 2.2150 - val_accuracy10: 0.5791 - 10s/epoch - 16ms/step
Epoch 41/50
634/634 - 10s - loss: 2.1026 - accuracy10: 0.6740 - val_loss: 2.2724 - val_accuracy10: 0.5288 - 10s/epoch - 16ms/step
Epoch 42/50
634/634 - 10s - loss: 2.0993 - accuracy10: 0.6751 - val_loss: 2.1965 - val_accuracy10: 0.5911 - 10s/epoch - 16ms/step
Epoch 43/50
634/634 - 10s - loss: 2.0941 - accuracy10: 0.6754 - val_loss: 2.1933 - val_accuracy10: 0.5828 - 10s/epoch - 16ms/step
Epoch 44/50
634/634 - 10s - loss: 2.0824 - accuracy10: 0.6760 - val_loss: 2.1768 - val_accuracy10: 0.5922 - 10s/epoch - 16ms/step
Epoch 45/50
634/634 - 10s - loss: 2.0889 - accuracy10: 0.6742 - val_loss: 2.2629 - val_accuracy10: 0.5503 - 10s/epoch - 15ms/step
testing model: results/QRTEA/W4/deepLOB_L1/h10
Evaluating performance on  test set...
1613/1613 - 10s - 10s/epoch - 6ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.944823
{'0': {'precision': 0.20061293713922995, 'recall': 0.5989281061234158, 'f1-score': 0.3005542430050967, 'support': 33772}, '1': {'precision': 0.932562393640238, 'recall': 0.5511129144447021, 'f1-score': 0.6928027660229495, 'support': 345040}, '2': {'precision': 0.2141588664027526, 'recall': 0.6802597173663953, 'f1-score': 0.3257616793173553, 'support': 34037}, 'accuracy': 0.5656717104801029, 'macro avg': {'precision': 0.4491113990607401, 'recall': 0.6101002459781711, 'f1-score': 0.4397062294484672, 'support': 412849}, 'weighted avg': {'precision': 0.8134590461656545, 'recall': 0.565671710480103, 'f1-score': 0.6304555286854309, 'support': 412849}}
[[ 20227   6837   6708]
 [ 76630 190156  78254]
 [  3969   6914  23154]]
Evaluating performance on  train set...
634/634 - 4s - 4s/epoch - 6ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.8647238
{'0': {'precision': 0.25351614955120505, 'recall': 0.6727306826706677, 'f1-score': 0.36825624967917464, 'support': 15996}, '1': {'precision': 0.9215096276080846, 'recall': 0.6074325207377169, 'f1-score': 0.7322120285423037, 'support': 130077}, '2': {'precision': 0.2894164019296388, 'recall': 0.6106249612114442, 'f1-score': 0.39270390548604045, 'support': 16113}, 'accuracy': 0.6141898807541958, 'macro avg': {'precision': 0.4881473930296428, 'recall': 0.630262721539943, 'f1-score': 0.49772406123583957, 'support': 162186}, 'weighted avg': {'precision': 0.7928293357188053, 'recall': 0.6141898807541958, 'f1-score': 0.6625862222119165, 'support': 162186}}
[[10761  2862  2373]
 [29280 79013 21784]
 [ 2406  3868  9839]]
Evaluating performance on  val set...
206/206 - 1s - 1s/epoch - 6ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.88622063
{'0': {'precision': 0.2130449306831468, 'recall': 0.6382286715036277, 'f1-score': 0.31945401039383886, 'support': 3997}, '1': {'precision': 0.9475190839694656, 'recall': 0.5791386271870794, 'f1-score': 0.7188840006682631, 'support': 44580}, '2': {'precision': 0.22157240153982824, 'recall': 0.7206838430050566, 'f1-score': 0.3389389049317706, 'support': 4153}, 'accuracy': 0.5947657879764839, 'macro avg': {'precision': 0.4607121387308135, 'recall': 0.6460170472319212, 'f1-score': 0.4590923053312908, 'support': 52730}, 'weighted avg': {'precision': 0.8346696668859136, 'recall': 0.5947657879764839, 'f1-score': 0.6586823383560968, 'support': 52730}}
[[ 2551   665   781]
 [ 9028 25818  9734]
 [  395   765  2993]]
training model: results/QRTEA/W4/deepLOB_L1/h20
Epoch 1/50
634/634 - 12s - loss: 2.9586 - accuracy20: 0.4254 - val_loss: 2.6150 - val_accuracy20: 0.4856 - 12s/epoch - 19ms/step
Epoch 2/50
634/634 - 10s - loss: 2.8308 - accuracy20: 0.4738 - val_loss: 2.5541 - val_accuracy20: 0.4436 - 10s/epoch - 16ms/step
Epoch 3/50
634/634 - 10s - loss: 2.7444 - accuracy20: 0.5137 - val_loss: 2.5077 - val_accuracy20: 0.4272 - 10s/epoch - 16ms/step
Epoch 4/50
634/634 - 10s - loss: 2.6585 - accuracy20: 0.5549 - val_loss: 2.5001 - val_accuracy20: 0.4220 - 10s/epoch - 15ms/step
Epoch 5/50
634/634 - 10s - loss: 2.6056 - accuracy20: 0.5712 - val_loss: 2.4814 - val_accuracy20: 0.4368 - 10s/epoch - 15ms/step
Epoch 6/50
634/634 - 10s - loss: 2.5606 - accuracy20: 0.5892 - val_loss: 2.4138 - val_accuracy20: 0.5009 - 10s/epoch - 16ms/step
Epoch 7/50
634/634 - 10s - loss: 2.5291 - accuracy20: 0.5988 - val_loss: 2.4195 - val_accuracy20: 0.4863 - 10s/epoch - 15ms/step
Epoch 8/50
634/634 - 10s - loss: 2.5048 - accuracy20: 0.6070 - val_loss: 2.4148 - val_accuracy20: 0.4838 - 10s/epoch - 16ms/step
Epoch 9/50
634/634 - 10s - loss: 2.4774 - accuracy20: 0.6131 - val_loss: 2.4108 - val_accuracy20: 0.4872 - 10s/epoch - 16ms/step
Epoch 10/50
634/634 - 10s - loss: 2.4542 - accuracy20: 0.6176 - val_loss: 2.3670 - val_accuracy20: 0.5187 - 10s/epoch - 16ms/step
Epoch 11/50
634/634 - 10s - loss: 2.4362 - accuracy20: 0.6222 - val_loss: 2.3616 - val_accuracy20: 0.5306 - 10s/epoch - 16ms/step
Epoch 12/50
634/634 - 10s - loss: 2.4186 - accuracy20: 0.6259 - val_loss: 2.4072 - val_accuracy20: 0.5078 - 10s/epoch - 15ms/step
Epoch 13/50
634/634 - 10s - loss: 2.4048 - accuracy20: 0.6280 - val_loss: 2.3519 - val_accuracy20: 0.5266 - 10s/epoch - 16ms/step
Epoch 14/50
634/634 - 10s - loss: 2.3898 - accuracy20: 0.6309 - val_loss: 2.3171 - val_accuracy20: 0.5475 - 10s/epoch - 16ms/step
Epoch 15/50
634/634 - 10s - loss: 2.3827 - accuracy20: 0.6324 - val_loss: 2.3587 - val_accuracy20: 0.5489 - 10s/epoch - 16ms/step
Epoch 16/50
634/634 - 10s - loss: 2.3688 - accuracy20: 0.6366 - val_loss: 2.3418 - val_accuracy20: 0.5431 - 10s/epoch - 16ms/step
Epoch 17/50
634/634 - 10s - loss: 2.3576 - accuracy20: 0.6365 - val_loss: 2.3757 - val_accuracy20: 0.5338 - 10s/epoch - 16ms/step
Epoch 18/50
634/634 - 10s - loss: 2.3476 - accuracy20: 0.6377 - val_loss: 2.3934 - val_accuracy20: 0.5307 - 10s/epoch - 16ms/step
Epoch 19/50
634/634 - 10s - loss: 2.3422 - accuracy20: 0.6384 - val_loss: 2.3233 - val_accuracy20: 0.5526 - 10s/epoch - 16ms/step
Epoch 20/50
634/634 - 10s - loss: 2.3262 - accuracy20: 0.6413 - val_loss: 2.3360 - val_accuracy20: 0.5789 - 10s/epoch - 15ms/step
Epoch 21/50
634/634 - 10s - loss: 2.3242 - accuracy20: 0.6399 - val_loss: 2.3574 - val_accuracy20: 0.5622 - 10s/epoch - 16ms/step
Epoch 22/50
634/634 - 10s - loss: 2.3132 - accuracy20: 0.6437 - val_loss: 2.2953 - val_accuracy20: 0.5890 - 10s/epoch - 16ms/step
Epoch 23/50
634/634 - 10s - loss: 2.3063 - accuracy20: 0.6432 - val_loss: 2.3069 - val_accuracy20: 0.5866 - 10s/epoch - 16ms/step
Epoch 24/50
634/634 - 10s - loss: 2.3010 - accuracy20: 0.6437 - val_loss: 2.3307 - val_accuracy20: 0.5695 - 10s/epoch - 16ms/step
Epoch 25/50
634/634 - 10s - loss: 2.2956 - accuracy20: 0.6434 - val_loss: 2.3443 - val_accuracy20: 0.5592 - 10s/epoch - 16ms/step
Epoch 26/50
634/634 - 10s - loss: 2.2871 - accuracy20: 0.6448 - val_loss: 2.2903 - val_accuracy20: 0.5905 - 10s/epoch - 16ms/step
Epoch 27/50
634/634 - 10s - loss: 2.2837 - accuracy20: 0.6448 - val_loss: 2.3111 - val_accuracy20: 0.5826 - 10s/epoch - 16ms/step
Epoch 28/50
634/634 - 10s - loss: 2.2736 - accuracy20: 0.6466 - val_loss: 2.3275 - val_accuracy20: 0.5588 - 10s/epoch - 16ms/step
Epoch 29/50
634/634 - 10s - loss: 2.2729 - accuracy20: 0.6484 - val_loss: 2.3083 - val_accuracy20: 0.5908 - 10s/epoch - 16ms/step
Epoch 30/50
634/634 - 10s - loss: 2.2689 - accuracy20: 0.6478 - val_loss: 2.2733 - val_accuracy20: 0.6094 - 10s/epoch - 16ms/step
Epoch 31/50
634/634 - 10s - loss: 2.2574 - accuracy20: 0.6486 - val_loss: 2.3094 - val_accuracy20: 0.5786 - 10s/epoch - 16ms/step
Epoch 32/50
634/634 - 10s - loss: 2.2539 - accuracy20: 0.6482 - val_loss: 2.3007 - val_accuracy20: 0.6120 - 10s/epoch - 16ms/step
Epoch 33/50
634/634 - 10s - loss: 2.2493 - accuracy20: 0.6494 - val_loss: 2.3154 - val_accuracy20: 0.5765 - 10s/epoch - 16ms/step
Epoch 34/50
634/634 - 10s - loss: 2.2419 - accuracy20: 0.6519 - val_loss: 2.2823 - val_accuracy20: 0.6089 - 10s/epoch - 16ms/step
Epoch 35/50
634/634 - 10s - loss: 2.2364 - accuracy20: 0.6506 - val_loss: 2.2670 - val_accuracy20: 0.6200 - 10s/epoch - 16ms/step
Epoch 36/50
634/634 - 10s - loss: 2.2307 - accuracy20: 0.6520 - val_loss: 2.2982 - val_accuracy20: 0.5959 - 10s/epoch - 16ms/step
Epoch 37/50
634/634 - 10s - loss: 2.2221 - accuracy20: 0.6510 - val_loss: 2.3178 - val_accuracy20: 0.5961 - 10s/epoch - 16ms/step
Epoch 38/50
634/634 - 10s - loss: 2.2207 - accuracy20: 0.6527 - val_loss: 2.3496 - val_accuracy20: 0.5857 - 10s/epoch - 15ms/step
Epoch 39/50
634/634 - 10s - loss: 2.2129 - accuracy20: 0.6525 - val_loss: 2.2687 - val_accuracy20: 0.6111 - 10s/epoch - 16ms/step
Epoch 40/50
634/634 - 10s - loss: 2.2077 - accuracy20: 0.6540 - val_loss: 2.3272 - val_accuracy20: 0.5749 - 10s/epoch - 16ms/step
Epoch 41/50
634/634 - 10s - loss: 2.2026 - accuracy20: 0.6533 - val_loss: 2.3407 - val_accuracy20: 0.5763 - 10s/epoch - 15ms/step
Epoch 42/50
634/634 - 10s - loss: 2.1969 - accuracy20: 0.6533 - val_loss: 2.3086 - val_accuracy20: 0.5952 - 10s/epoch - 16ms/step
Epoch 43/50
634/634 - 10s - loss: 2.1937 - accuracy20: 0.6536 - val_loss: 2.3264 - val_accuracy20: 0.5959 - 10s/epoch - 16ms/step
Epoch 44/50
634/634 - 10s - loss: 2.1834 - accuracy20: 0.6537 - val_loss: 2.3265 - val_accuracy20: 0.5998 - 10s/epoch - 16ms/step
Epoch 45/50
634/634 - 10s - loss: 2.1796 - accuracy20: 0.6569 - val_loss: 2.3382 - val_accuracy20: 0.5728 - 10s/epoch - 16ms/step
testing model: results/QRTEA/W4/deepLOB_L1/h20
Evaluating performance on  test set...
1613/1613 - 9s - 9s/epoch - 6ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.95384395
{'0': {'precision': 0.24032229812576633, 'recall': 0.5914430434314042, 'f1-score': 0.3417717577456017, 'support': 46395}, '1': {'precision': 0.8835229259109856, 'recall': 0.5142968957906107, 'f1-score': 0.6501454495082422, 'support': 319405}, '2': {'precision': 0.2713847300078053, 'recall': 0.650322004718485, 'f1-score': 0.3829579518502062, 'support': 47049}, 'accuracy': 0.5384680597506595, 'macro avg': {'precision': 0.4650766513481857, 'recall': 0.5853539813134999, 'f1-score': 0.45829171970135, 'support': 412849}, 'weighted avg': {'precision': 0.7414812033801234, 'recall': 0.5384680597506595, 'f1-score': 0.5850419806694157, 'support': 412849}}
[[ 27440  10223   8732]
 [ 81721 164269  73415]
 [  5019  11433  30597]]
Evaluating performance on  train set...
634/634 - 4s - 4s/epoch - 6ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.8568644
{'0': {'precision': 0.3278369693894808, 'recall': 0.5417578834598724, 'f1-score': 0.4084850826206824, 'support': 21469}, '1': {'precision': 0.8491379795727622, 'recall': 0.6336745155380763, 'f1-score': 0.725752041616739, 'support': 118998}, '2': {'precision': 0.32409972299168976, 'recall': 0.5656337768773885, 'f1-score': 0.4120823829330471, 'support': 21719}, 'accuracy': 0.6123956445069242, 'macro avg': {'precision': 0.5003582239846442, 'recall': 0.5803553919584458, 'f1-score': 0.5154398357234895, 'support': 162186}, 'weighted avg': {'precision': 0.7098219024618575, 'recall': 0.6123956445069242, 'f1-score': 0.6417497500525013, 'support': 162186}}
[[11631  6174  3664]
 [21636 75406 21956]
 [ 2211  7223 12285]]
Evaluating performance on  val set...
206/206 - 1s - 1s/epoch - 6ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.8324891
{'0': {'precision': 0.30184061092617975, 'recall': 0.5664155796435789, 'f1-score': 0.39381746183815547, 'support': 5443}, '1': {'precision': 0.9104, 'recall': 0.6161565116950621, 'f1-score': 0.7349205665819951, 'support': 41556}, '2': {'precision': 0.2773955944687652, 'recall': 0.6965625545280055, 'f1-score': 0.39677964417055955, 'support': 5731}, 'accuracy': 0.6197610468424047, 'macro avg': {'precision': 0.496545401798315, 'recall': 0.6263782152888822, 'f1-score': 0.50850589086357, 'support': 52730}, 'weighted avg': {'precision': 0.7787835197643029, 'recall': 0.6197610468424047, 'f1-score': 0.6629594471915029, 'support': 52730}}
[[ 3083  1214  1146]
 [ 6698 25605  9253]
 [  433  1306  3992]]
training model: results/QRTEA/W4/deepLOB_L1/h30
Epoch 1/50
634/634 - 12s - loss: 2.9934 - accuracy30: 0.4413 - val_loss: 2.7239 - val_accuracy30: 0.3708 - 12s/epoch - 19ms/step
Epoch 2/50
634/634 - 10s - loss: 2.8836 - accuracy30: 0.4852 - val_loss: 2.6224 - val_accuracy30: 0.4355 - 10s/epoch - 16ms/step
Epoch 3/50
634/634 - 10s - loss: 2.8112 - accuracy30: 0.5104 - val_loss: 2.5946 - val_accuracy30: 0.4639 - 10s/epoch - 16ms/step
Epoch 4/50
634/634 - 10s - loss: 2.7356 - accuracy30: 0.5446 - val_loss: 2.5195 - val_accuracy30: 0.4787 - 10s/epoch - 16ms/step
Epoch 5/50
634/634 - 10s - loss: 2.6723 - accuracy30: 0.5672 - val_loss: 2.5127 - val_accuracy30: 0.4847 - 10s/epoch - 16ms/step
Epoch 6/50
634/634 - 10s - loss: 2.6331 - accuracy30: 0.5795 - val_loss: 2.5224 - val_accuracy30: 0.4869 - 10s/epoch - 15ms/step
Epoch 7/50
634/634 - 10s - loss: 2.6047 - accuracy30: 0.5871 - val_loss: 2.4596 - val_accuracy30: 0.5469 - 10s/epoch - 16ms/step
Epoch 8/50
634/634 - 10s - loss: 2.5782 - accuracy30: 0.5936 - val_loss: 2.4911 - val_accuracy30: 0.5123 - 10s/epoch - 16ms/step
Epoch 9/50
634/634 - 10s - loss: 2.5569 - accuracy30: 0.5988 - val_loss: 2.4620 - val_accuracy30: 0.5544 - 10s/epoch - 15ms/step
Epoch 10/50
634/634 - 10s - loss: 2.5377 - accuracy30: 0.6023 - val_loss: 2.4476 - val_accuracy30: 0.5487 - 10s/epoch - 16ms/step
Epoch 11/50
634/634 - 10s - loss: 2.5228 - accuracy30: 0.6068 - val_loss: 2.4137 - val_accuracy30: 0.5894 - 10s/epoch - 16ms/step
Epoch 12/50
634/634 - 10s - loss: 2.5091 - accuracy30: 0.6080 - val_loss: 2.4182 - val_accuracy30: 0.5701 - 10s/epoch - 16ms/step
Epoch 13/50
634/634 - 10s - loss: 2.4996 - accuracy30: 0.6114 - val_loss: 2.3914 - val_accuracy30: 0.5912 - 10s/epoch - 15ms/step
Epoch 14/50
634/634 - 10s - loss: 2.4845 - accuracy30: 0.6124 - val_loss: 2.4234 - val_accuracy30: 0.5805 - 10s/epoch - 16ms/step
Epoch 15/50
634/634 - 10s - loss: 2.4737 - accuracy30: 0.6153 - val_loss: 2.4023 - val_accuracy30: 0.5676 - 10s/epoch - 16ms/step
Epoch 16/50
634/634 - 10s - loss: 2.4637 - accuracy30: 0.6161 - val_loss: 2.3954 - val_accuracy30: 0.5891 - 10s/epoch - 16ms/step
Epoch 17/50
634/634 - 10s - loss: 2.4576 - accuracy30: 0.6157 - val_loss: 2.4104 - val_accuracy30: 0.5916 - 10s/epoch - 16ms/step
Epoch 18/50
634/634 - 10s - loss: 2.4485 - accuracy30: 0.6196 - val_loss: 2.4047 - val_accuracy30: 0.5799 - 10s/epoch - 16ms/step
Epoch 19/50
634/634 - 10s - loss: 2.4434 - accuracy30: 0.6185 - val_loss: 2.4174 - val_accuracy30: 0.5785 - 10s/epoch - 16ms/step
Epoch 20/50
634/634 - 10s - loss: 2.4386 - accuracy30: 0.6192 - val_loss: 2.3934 - val_accuracy30: 0.5866 - 10s/epoch - 16ms/step
Epoch 21/50
634/634 - 10s - loss: 2.4301 - accuracy30: 0.6214 - val_loss: 2.4130 - val_accuracy30: 0.5661 - 10s/epoch - 15ms/step
Epoch 22/50
634/634 - 10s - loss: 2.4201 - accuracy30: 0.6210 - val_loss: 2.3805 - val_accuracy30: 0.5820 - 10s/epoch - 16ms/step
Epoch 23/50
634/634 - 10s - loss: 2.4140 - accuracy30: 0.6221 - val_loss: 2.4106 - val_accuracy30: 0.5730 - 10s/epoch - 16ms/step
Epoch 24/50
634/634 - 10s - loss: 2.4100 - accuracy30: 0.6229 - val_loss: 2.3713 - val_accuracy30: 0.5911 - 10s/epoch - 16ms/step
Epoch 25/50
634/634 - 10s - loss: 2.4002 - accuracy30: 0.6229 - val_loss: 2.4007 - val_accuracy30: 0.5863 - 10s/epoch - 16ms/step
Epoch 26/50
634/634 - 10s - loss: 2.3957 - accuracy30: 0.6247 - val_loss: 2.4154 - val_accuracy30: 0.5655 - 10s/epoch - 16ms/step
Epoch 27/50
634/634 - 10s - loss: 2.3922 - accuracy30: 0.6253 - val_loss: 2.4110 - val_accuracy30: 0.5685 - 10s/epoch - 16ms/step
Epoch 28/50
634/634 - 10s - loss: 2.3826 - accuracy30: 0.6259 - val_loss: 2.4108 - val_accuracy30: 0.5784 - 10s/epoch - 16ms/step
Epoch 29/50
634/634 - 10s - loss: 2.3778 - accuracy30: 0.6270 - val_loss: 2.3674 - val_accuracy30: 0.5937 - 10s/epoch - 16ms/step
Epoch 30/50
634/634 - 10s - loss: 2.3757 - accuracy30: 0.6279 - val_loss: 2.3658 - val_accuracy30: 0.5986 - 10s/epoch - 16ms/step
Epoch 31/50
634/634 - 10s - loss: 2.3657 - accuracy30: 0.6277 - val_loss: 2.3645 - val_accuracy30: 0.6024 - 10s/epoch - 15ms/step
Epoch 32/50
634/634 - 10s - loss: 2.3657 - accuracy30: 0.6281 - val_loss: 2.3749 - val_accuracy30: 0.5899 - 10s/epoch - 16ms/step
Epoch 33/50
634/634 - 10s - loss: 2.3592 - accuracy30: 0.6277 - val_loss: 2.3900 - val_accuracy30: 0.5921 - 10s/epoch - 16ms/step
Epoch 34/50
634/634 - 10s - loss: 2.3526 - accuracy30: 0.6298 - val_loss: 2.3402 - val_accuracy30: 0.6018 - 10s/epoch - 16ms/step
Epoch 35/50
634/634 - 10s - loss: 2.3485 - accuracy30: 0.6287 - val_loss: 2.3625 - val_accuracy30: 0.6019 - 10s/epoch - 16ms/step
Epoch 36/50
634/634 - 10s - loss: 2.3424 - accuracy30: 0.6299 - val_loss: 2.3763 - val_accuracy30: 0.5999 - 10s/epoch - 16ms/step
Epoch 37/50
634/634 - 10s - loss: 2.3355 - accuracy30: 0.6311 - val_loss: 2.3812 - val_accuracy30: 0.5844 - 10s/epoch - 16ms/step
Epoch 38/50
634/634 - 10s - loss: 2.3361 - accuracy30: 0.6289 - val_loss: 2.3875 - val_accuracy30: 0.5932 - 10s/epoch - 16ms/step
Epoch 39/50
634/634 - 10s - loss: 2.3294 - accuracy30: 0.6296 - val_loss: 2.4074 - val_accuracy30: 0.5920 - 10s/epoch - 16ms/step
Epoch 40/50
634/634 - 10s - loss: 2.3225 - accuracy30: 0.6310 - val_loss: 2.4206 - val_accuracy30: 0.5720 - 10s/epoch - 16ms/step
Epoch 41/50
634/634 - 10s - loss: 2.3161 - accuracy30: 0.6312 - val_loss: 2.4232 - val_accuracy30: 0.5864 - 10s/epoch - 16ms/step
Epoch 42/50
634/634 - 10s - loss: 2.3116 - accuracy30: 0.6330 - val_loss: 2.4710 - val_accuracy30: 0.5560 - 10s/epoch - 16ms/step
Epoch 43/50
634/634 - 10s - loss: 2.3111 - accuracy30: 0.6314 - val_loss: 2.4179 - val_accuracy30: 0.5789 - 10s/epoch - 16ms/step
Epoch 44/50
634/634 - 10s - loss: 2.3025 - accuracy30: 0.6316 - val_loss: 2.4036 - val_accuracy30: 0.5804 - 10s/epoch - 16ms/step
testing model: results/QRTEA/W4/deepLOB_L1/h30
Evaluating performance on  test set...
1613/1613 - 9s - 9s/epoch - 6ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.1207592
{'0': {'precision': 0.2775423368223981, 'recall': 0.5855927029841634, 'f1-score': 0.37659638345534746, 'support': 55694}, '1': {'precision': 0.8707865602571135, 'recall': 0.37511523497951565, 'f1-score': 0.5243516084761928, 'support': 300473}, '2': {'precision': 0.2552892671577196, 'recall': 0.747203697822942, 'f1-score': 0.3805574524673831, 'support': 56682}, 'accuracy': 0.45459477920498775, 'macro avg': {'precision': 0.4678727214124104, 'recall': 0.5693038785955404, 'f1-score': 0.42716848146630776, 'support': 412849}, 'weighted avg': {'precision': 0.7062524052817283, 'recall': 0.45459477920498775, 'f1-score': 0.48467700625309834, 'support': 412849}}
[[ 32614   8220  14860]
 [ 79072 112712 108689]
 [  5824   8505  42353]]
Evaluating performance on  train set...
634/634 - 4s - 4s/epoch - 6ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.88388777
{'0': {'precision': 0.3641856088743624, 'recall': 0.5735902035722642, 'f1-score': 0.44550796631731987, 'support': 25642}, '1': {'precision': 0.8237757075951945, 'recall': 0.5851579308973223, 'f1-score': 0.6842606002304512, 'support': 110618}, '2': {'precision': 0.360494169905608, 'recall': 0.6010182828049063, 'f1-score': 0.45067245119305854, 'support': 25926}, 'accuracy': 0.5858643779364433, 'macro avg': {'precision': 0.5161518287917216, 'recall': 0.5865888057581642, 'f1-score': 0.5268136725802766, 'support': 162186}, 'weighted avg': {'precision': 0.6770562222047182, 'recall': 0.5858643779364433, 'f1-score': 0.6091733461472137, 'support': 162186}}
[[14708  6605  4329]
 [22576 64729 23313]
 [ 3102  7242 15582]]
Evaluating performance on  val set...
206/206 - 1s - 1s/epoch - 6ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.86836094
{'0': {'precision': 0.325046665535381, 'recall': 0.5819535166337536, 'f1-score': 0.41711579291197126, 'support': 6583}, '1': {'precision': 0.8721389696563036, 'recall': 0.5963043201223397, 'f1-score': 0.7083150421580054, 'support': 39235}, '2': {'precision': 0.32270859895169285, 'recall': 0.6591435185185185, 'f1-score': 0.43328578221588204, 'support': 6912}, 'accuracy': 0.6027498577659777, 'macro avg': {'precision': 0.5066314113811258, 'recall': 0.6124671184248706, 'f1-score': 0.5195722057619528, 'support': 52730}, 'weighted avg': {'precision': 0.7318171156768175, 'recall': 0.6027498577659776, 'f1-score': 0.6359090701779827, 'support': 52730}}
[[ 3831  1637  1115]
 [ 7392 23396  8447]
 [  563  1793  4556]]
training model: results/QRTEA/W4/deepLOB_L1/h50
Epoch 1/50
634/634 - 12s - loss: 3.0709 - accuracy50: 0.4428 - val_loss: 2.8303 - val_accuracy50: 0.4258 - 12s/epoch - 20ms/step
Epoch 2/50
634/634 - 10s - loss: 2.9880 - accuracy50: 0.4665 - val_loss: 2.7858 - val_accuracy50: 0.4389 - 10s/epoch - 16ms/step
Epoch 3/50
634/634 - 10s - loss: 2.9261 - accuracy50: 0.4922 - val_loss: 2.7649 - val_accuracy50: 0.4582 - 10s/epoch - 16ms/step
Epoch 4/50
634/634 - 10s - loss: 2.8810 - accuracy50: 0.5120 - val_loss: 2.7784 - val_accuracy50: 0.4248 - 10s/epoch - 16ms/step
Epoch 5/50
634/634 - 10s - loss: 2.8434 - accuracy50: 0.5281 - val_loss: 2.7555 - val_accuracy50: 0.4286 - 10s/epoch - 16ms/step
Epoch 6/50
634/634 - 10s - loss: 2.8156 - accuracy50: 0.5390 - val_loss: 2.7620 - val_accuracy50: 0.4503 - 10s/epoch - 16ms/step
Epoch 7/50
634/634 - 10s - loss: 2.7910 - accuracy50: 0.5483 - val_loss: 2.6807 - val_accuracy50: 0.4840 - 10s/epoch - 16ms/step
Epoch 8/50
634/634 - 10s - loss: 2.7635 - accuracy50: 0.5546 - val_loss: 2.7005 - val_accuracy50: 0.4852 - 10s/epoch - 16ms/step
Epoch 9/50
634/634 - 10s - loss: 2.7417 - accuracy50: 0.5631 - val_loss: 2.6669 - val_accuracy50: 0.5205 - 10s/epoch - 16ms/step
Epoch 10/50
634/634 - 10s - loss: 2.7226 - accuracy50: 0.5670 - val_loss: 2.6968 - val_accuracy50: 0.4912 - 10s/epoch - 16ms/step
Epoch 11/50
634/634 - 10s - loss: 2.7036 - accuracy50: 0.5712 - val_loss: 2.6735 - val_accuracy50: 0.5045 - 10s/epoch - 16ms/step
Epoch 12/50
634/634 - 10s - loss: 2.6929 - accuracy50: 0.5739 - val_loss: 2.6682 - val_accuracy50: 0.4975 - 10s/epoch - 16ms/step
Epoch 13/50
634/634 - 10s - loss: 2.6781 - accuracy50: 0.5769 - val_loss: 2.7077 - val_accuracy50: 0.4841 - 10s/epoch - 16ms/step
Epoch 14/50
634/634 - 10s - loss: 2.6667 - accuracy50: 0.5795 - val_loss: 2.7329 - val_accuracy50: 0.4833 - 10s/epoch - 16ms/step
Epoch 15/50
634/634 - 10s - loss: 2.6549 - accuracy50: 0.5816 - val_loss: 2.6997 - val_accuracy50: 0.4936 - 10s/epoch - 16ms/step
Epoch 16/50
634/634 - 10s - loss: 2.6483 - accuracy50: 0.5834 - val_loss: 2.6869 - val_accuracy50: 0.4896 - 10s/epoch - 16ms/step
Epoch 17/50
634/634 - 10s - loss: 2.6396 - accuracy50: 0.5844 - val_loss: 2.6814 - val_accuracy50: 0.4997 - 10s/epoch - 16ms/step
Epoch 18/50
634/634 - 10s - loss: 2.6298 - accuracy50: 0.5867 - val_loss: 2.6986 - val_accuracy50: 0.5010 - 10s/epoch - 16ms/step
Epoch 19/50
634/634 - 10s - loss: 2.6195 - accuracy50: 0.5868 - val_loss: 2.7037 - val_accuracy50: 0.4951 - 10s/epoch - 16ms/step
testing model: results/QRTEA/W4/deepLOB_L1/h50
Evaluating performance on  test set...
1613/1613 - 10s - 10s/epoch - 6ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0029266
{'0': {'precision': 0.2843115595159192, 'recall': 0.4850964021947031, 'f1-score': 0.35850555618609353, 'support': 71627}, '1': {'precision': 0.6887530155561101, 'recall': 0.5550254737218449, 'f1-score': 0.6147002412918394, 'support': 268512}, '2': {'precision': 0.3312685160247778, 'recall': 0.3383303534589465, 'f1-score': 0.3347621963666054, 'support': 72710}, 'accuracy': 0.5047293320318083, 'macro avg': {'precision': 0.43477769703226904, 'recall': 0.4594840764584982, 'f1-score': 0.4359893312815128, 'support': 412849}, 'weighted avg': {'precision': 0.5556253438584339, 'recall': 0.5047293320318083, 'f1-score': 0.5209498580849453, 'support': 412849}}
[[ 34746  29128   7753]
 [ 77574 149031  41907]
 [  9891  38219  24600]]
Evaluating performance on  train set...
634/634 - 4s - 4s/epoch - 6ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.9882658
{'0': {'precision': 0.37085347757407494, 'recall': 0.4766665641246501, 'f1-score': 0.4171546258530873, 'support': 32507}, '1': {'precision': 0.6825353157183355, 'recall': 0.588729313689076, 'f1-score': 0.6321713649481795, 'support': 96924}, '2': {'precision': 0.37246270481780386, 'recall': 0.41847046252480535, 'f1-score': 0.394128472022543, 'support': 32755}, 'accuracy': 0.5318831465107963, 'macro avg': {'precision': 0.47528383270340474, 'recall': 0.4946221134461772, 'f1-score': 0.48115148760793663, 'support': 162186}, 'weighted avg': {'precision': 0.5574427067224764, 'recall': 0.5318831465107963, 'f1-score': 0.5410004618150892, 'support': 162186}}
[[15495 11878  5134]
 [21902 57062 17960]
 [ 4385 14663 13707]]
Evaluating performance on  val set...
206/206 - 1s - 1s/epoch - 6ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.9893117
{'0': {'precision': 0.3190742864853923, 'recall': 0.5532288254562471, 'f1-score': 0.4047242072831529, 'support': 8548}, '1': {'precision': 0.8007984773223156, 'recall': 0.4890426104952797, 'f1-score': 0.6072446932094203, 'support': 35273}, '2': {'precision': 0.3353494623655914, 'recall': 0.6161185318217532, 'f1-score': 0.4343078688135459, 'support': 8909}, 'accuracy': 0.520917883557747, 'macro avg': {'precision': 0.48507407539109976, 'recall': 0.5527966559244267, 'f1-score': 0.48209225643537296, 'support': 52730}, 'weighted avg': {'precision': 0.6440667561479656, 'recall': 0.520917883557747, 'f1-score': 0.5451957783176968, 'support': 52730}}
[[ 4729  1933  1886]
 [ 9030 17250  8993]
 [ 1062  2358  5489]]
training model: results/QRTEA/W4/deepLOB_L1/h100
Epoch 1/50
634/634 - 13s - loss: 3.1786 - accuracy100: 0.4314 - val_loss: 3.1503 - val_accuracy100: 0.3920 - 13s/epoch - 20ms/step
Epoch 2/50
634/634 - 10s - loss: 3.1094 - accuracy100: 0.4529 - val_loss: 3.0691 - val_accuracy100: 0.4170 - 10s/epoch - 16ms/step
Epoch 3/50
634/634 - 10s - loss: 3.0745 - accuracy100: 0.4698 - val_loss: 3.1105 - val_accuracy100: 0.4366 - 10s/epoch - 16ms/step
Epoch 4/50
634/634 - 10s - loss: 3.0513 - accuracy100: 0.4744 - val_loss: 3.0122 - val_accuracy100: 0.4826 - 10s/epoch - 16ms/step
Epoch 5/50
634/634 - 10s - loss: 3.0290 - accuracy100: 0.4859 - val_loss: 3.0843 - val_accuracy100: 0.4303 - 10s/epoch - 16ms/step
Epoch 6/50
634/634 - 10s - loss: 3.0127 - accuracy100: 0.4925 - val_loss: 3.0665 - val_accuracy100: 0.4505 - 10s/epoch - 16ms/step
Epoch 7/50
634/634 - 10s - loss: 2.9954 - accuracy100: 0.4978 - val_loss: 3.0249 - val_accuracy100: 0.4841 - 10s/epoch - 16ms/step
Epoch 8/50
634/634 - 10s - loss: 2.9809 - accuracy100: 0.5015 - val_loss: 3.0359 - val_accuracy100: 0.4753 - 10s/epoch - 16ms/step
Epoch 9/50
634/634 - 10s - loss: 2.9679 - accuracy100: 0.5065 - val_loss: 3.0264 - val_accuracy100: 0.4873 - 10s/epoch - 15ms/step
Epoch 10/50
634/634 - 10s - loss: 2.9571 - accuracy100: 0.5100 - val_loss: 3.0355 - val_accuracy100: 0.4953 - 10s/epoch - 16ms/step
Epoch 11/50
634/634 - 10s - loss: 2.9503 - accuracy100: 0.5109 - val_loss: 3.0230 - val_accuracy100: 0.5053 - 10s/epoch - 16ms/step
Epoch 12/50
634/634 - 10s - loss: 2.9457 - accuracy100: 0.5127 - val_loss: 3.0281 - val_accuracy100: 0.4988 - 10s/epoch - 15ms/step
Epoch 13/50
634/634 - 10s - loss: 2.9387 - accuracy100: 0.5145 - val_loss: 3.0404 - val_accuracy100: 0.4988 - 10s/epoch - 16ms/step
Epoch 14/50
634/634 - 10s - loss: 2.9309 - accuracy100: 0.5163 - val_loss: 3.0268 - val_accuracy100: 0.5017 - 10s/epoch - 16ms/step
testing model: results/QRTEA/W4/deepLOB_L1/h100
Evaluating performance on  test set...
1613/1613 - 8s - 8s/epoch - 5ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0947472
{'0': {'precision': 0.3115102064661237, 'recall': 0.633810769047902, 'f1-score': 0.41771742855743965, 'support': 100956}, '1': {'precision': 0.5546544123041626, 'recall': 0.3964276180306613, 'f1-score': 0.46237931216622324, 'support': 209776}, '2': {'precision': 0.4121759090197715, 'recall': 0.23211610211815858, 'f1-score': 0.29698541572695836, 'support': 102117}, 'accuracy': 0.41383411368321105, 'macro avg': {'precision': 0.4261135092633526, 'recall': 0.4207848297322406, 'f1-score': 0.3923607188168738, 'support': 412849}, 'weighted avg': {'precision': 0.4599555181213567, 'recall': 0.41383411368321105, 'f1-score': 0.4105482222415855, 'support': 412849}}
[[ 63987  28298   8671]
 [101482  83161  25133]
 [ 39940  38474  23703]]
Evaluating performance on  train set...
634/634 - 4s - 4s/epoch - 6ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0631179
{'0': {'precision': 0.3977523949889462, 'recall': 0.5363127230025744, 'f1-score': 0.4567554572555053, 'support': 44282}, '1': {'precision': 0.5222889225871944, 'recall': 0.5663518380104641, 'f1-score': 0.5434286533922726, 'support': 73585}, '2': {'precision': 0.40996253030636987, 'recall': 0.2098422798348338, 'f1-score': 0.2775953674407498, 'support': 44319}, 'accuracy': 0.46073027264992045, 'macro avg': {'precision': 0.44333461596083684, 'recall': 0.4375022802826241, 'f1-score': 0.42592649269617594, 'support': 162186}, 'weighted avg': {'precision': 0.4575920936710149, 'recall': 0.46073027264992045, 'f1-score': 0.44712238853948716, 'support': 162186}}
[[23749 16908  3625]
 [22150 41675  9760]
 [13809 21210  9300]]
Evaluating performance on  val set...
206/206 - 1s - 1s/epoch - 6ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0301373
{'0': {'precision': 0.3609636129897714, 'recall': 0.5231691510045366, 'f1-score': 0.4271870348933356, 'support': 12344}, '1': {'precision': 0.6336539828460408, 'recall': 0.4838616297582863, 'f1-score': 0.5487186852417981, 'support': 27636}, '2': {'precision': 0.40470297029702973, 'recall': 0.436, 'f1-score': 0.41976893453145064, 'support': 12750}, 'accuracy': 0.481490612554523, 'macro avg': {'precision': 0.4664401887109473, 'recall': 0.4810102602542743, 'f1-score': 0.46522488488886143, 'support': 52730}, 'weighted avg': {'precision': 0.5144577883551309, 'recall': 0.481490612554523, 'f1-score': 0.4890885693028952, 'support': 52730}}
[[ 6458  3690  2196]
 [ 8283 13372  5981]
 [ 3150  4041  5559]]
training model: results/QRTEA/W4/deepLOB_L1/h200
Epoch 1/50
634/634 - 12s - loss: 3.2601 - accuracy200: 0.4008 - val_loss: 3.2893 - val_accuracy200: 0.4060 - 12s/epoch - 19ms/step
Epoch 2/50
634/634 - 10s - loss: 3.2169 - accuracy200: 0.4169 - val_loss: 3.2803 - val_accuracy200: 0.4051 - 10s/epoch - 17ms/step
Epoch 3/50
634/634 - 10s - loss: 3.2024 - accuracy200: 0.4250 - val_loss: 3.2595 - val_accuracy200: 0.4239 - 10s/epoch - 16ms/step
Epoch 4/50
634/634 - 10s - loss: 3.1813 - accuracy200: 0.4342 - val_loss: 3.2938 - val_accuracy200: 0.3918 - 10s/epoch - 16ms/step
Epoch 5/50
634/634 - 10s - loss: 3.1628 - accuracy200: 0.4424 - val_loss: 3.3539 - val_accuracy200: 0.3882 - 10s/epoch - 16ms/step
Epoch 6/50
634/634 - 10s - loss: 3.1454 - accuracy200: 0.4492 - val_loss: 3.4647 - val_accuracy200: 0.3682 - 10s/epoch - 16ms/step
Epoch 7/50
634/634 - 10s - loss: 3.1314 - accuracy200: 0.4533 - val_loss: 3.4476 - val_accuracy200: 0.3694 - 10s/epoch - 16ms/step
Epoch 8/50
634/634 - 10s - loss: 3.1194 - accuracy200: 0.4556 - val_loss: 3.4856 - val_accuracy200: 0.3671 - 10s/epoch - 16ms/step
Epoch 9/50
634/634 - 10s - loss: 3.1126 - accuracy200: 0.4581 - val_loss: 3.4236 - val_accuracy200: 0.3832 - 10s/epoch - 16ms/step
Epoch 10/50
634/634 - 10s - loss: 3.0974 - accuracy200: 0.4636 - val_loss: 3.4414 - val_accuracy200: 0.3768 - 10s/epoch - 16ms/step
Epoch 11/50
634/634 - 10s - loss: 3.0917 - accuracy200: 0.4665 - val_loss: 3.3799 - val_accuracy200: 0.3844 - 10s/epoch - 16ms/step
Epoch 12/50
634/634 - 10s - loss: 3.0832 - accuracy200: 0.4676 - val_loss: 3.4426 - val_accuracy200: 0.3728 - 10s/epoch - 16ms/step
Epoch 13/50
634/634 - 10s - loss: 3.0777 - accuracy200: 0.4688 - val_loss: 3.4286 - val_accuracy200: 0.3769 - 10s/epoch - 16ms/step
testing model: results/QRTEA/W4/deepLOB_L1/h200
Evaluating performance on  test set...
1613/1613 - 9s - 9s/epoch - 6ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1346283
{'0': {'precision': 0.3287489102005231, 'recall': 0.704889941270855, 'f1-score': 0.44838059187546137, 'support': 128386}, '1': {'precision': 0.3667026803025145, 'recall': 0.16170654344676352, 'f1-score': 0.22444052919303045, 'support': 153222}, '2': {'precision': 0.41560241135967546, 'recall': 0.22167615303144597, 'f1-score': 0.2891330381677872, 'support': 131241}, 'accuracy': 0.34968717376086655, 'macro avg': {'precision': 0.3703513339542377, 'recall': 0.36275754591635484, 'f1-score': 0.320651386412093, 'support': 412849}, 'weighted avg': {'precision': 0.3704447673012928, 'recall': 0.34968717376086655, 'f1-score': 0.31464561254772583, 'support': 412849}}
[[ 90498  19774  18114]
 [105650  24777  22795]
 [ 79132  23016  29093]]
Evaluating performance on  train set...
634/634 - 4s - 4s/epoch - 7ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1195219
{'0': {'precision': 0.36898558703816586, 'recall': 0.6908478444943489, 'f1-score': 0.48104332222507046, 'support': 54326}, '1': {'precision': 0.3862665184636285, 'recall': 0.2893996594862684, 'f1-score': 0.33088943197807896, 'support': 54036}, '2': {'precision': 0.4188722669735328, 'recall': 0.15554399524375742, 'f1-score': 0.22684965655525596, 'support': 53824}, 'accuracy': 0.37944705461630474, 'macro avg': {'precision': 0.39137479082510906, 'recall': 0.3785971664081249, 'f1-score': 0.34626080358613515, 'support': 162186}, 'weighted avg': {'precision': 0.3912988142670727, 'recall': 0.37944705461630474, 'f1-score': 0.34665789145793563, 'support': 162186}}
[[37531 11377  5418]
 [32201 15638  6197]
 [31982 13470  8372]]
Evaluating performance on  val set...
206/206 - 1s - 1s/epoch - 6ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0856442
{'0': {'precision': 0.38852735598939503, 'recall': 0.503970487088101, 'f1-score': 0.4387827317763623, 'support': 15993}, '1': {'precision': 0.4487779009786434, 'recall': 0.4612297478075608, 'f1-score': 0.45491863363143237, 'support': 20183}, '2': {'precision': 0.449119373776908, 'recall': 0.3050018122508155, 'f1-score': 0.36328968196862865, 'support': 16554}, 'accuracy': 0.42514697515645744, 'macro avg': {'precision': 0.42880821024831545, 'recall': 0.42340068238215917, 'f1-score': 0.41899701579214116, 'support': 52730}, 'weighted avg': {'precision': 0.4306111225733603, 'recall': 0.42514697515645744, 'f1-score': 0.42125872192663083, 'support': 52730}}
[[8060 5122 2811]
 [7492 9309 3382]
 [5193 6312 5049]]
training model: results/QRTEA/W4/deepLOB_L1/h300
Epoch 1/50
634/634 - 12s - loss: 3.2892 - accuracy300: 0.3870 - val_loss: 3.3440 - val_accuracy300: 0.3560 - 12s/epoch - 19ms/step
Epoch 2/50
634/634 - 10s - loss: 3.2518 - accuracy300: 0.3989 - val_loss: 3.4045 - val_accuracy300: 0.3468 - 10s/epoch - 15ms/step
Epoch 3/50
634/634 - 10s - loss: 3.2409 - accuracy300: 0.4054 - val_loss: 3.5139 - val_accuracy300: 0.3414 - 10s/epoch - 16ms/step
Epoch 4/50
634/634 - 10s - loss: 3.2323 - accuracy300: 0.4064 - val_loss: 3.4206 - val_accuracy300: 0.3456 - 10s/epoch - 16ms/step
Epoch 5/50
634/634 - 10s - loss: 3.2137 - accuracy300: 0.4173 - val_loss: 3.3207 - val_accuracy300: 0.3511 - 10s/epoch - 16ms/step
Epoch 6/50
634/634 - 10s - loss: 3.2078 - accuracy300: 0.4192 - val_loss: 3.3545 - val_accuracy300: 0.3628 - 10s/epoch - 16ms/step
Epoch 7/50
634/634 - 10s - loss: 3.2010 - accuracy300: 0.4244 - val_loss: 3.3581 - val_accuracy300: 0.3571 - 10s/epoch - 16ms/step
Epoch 8/50
634/634 - 10s - loss: 3.1861 - accuracy300: 0.4309 - val_loss: 3.4273 - val_accuracy300: 0.3599 - 10s/epoch - 16ms/step
Epoch 9/50
634/634 - 10s - loss: 3.1811 - accuracy300: 0.4332 - val_loss: 3.4304 - val_accuracy300: 0.3619 - 10s/epoch - 16ms/step
Epoch 10/50
634/634 - 10s - loss: 3.1791 - accuracy300: 0.4331 - val_loss: 3.4493 - val_accuracy300: 0.3704 - 10s/epoch - 15ms/step
Epoch 11/50
634/634 - 10s - loss: 3.1670 - accuracy300: 0.4384 - val_loss: 3.4715 - val_accuracy300: 0.3677 - 10s/epoch - 15ms/step
Epoch 12/50
634/634 - 10s - loss: 3.1568 - accuracy300: 0.4437 - val_loss: 3.5139 - val_accuracy300: 0.3620 - 10s/epoch - 16ms/step
Epoch 13/50
634/634 - 10s - loss: 3.1552 - accuracy300: 0.4429 - val_loss: 3.4606 - val_accuracy300: 0.3607 - 10s/epoch - 16ms/step
Epoch 14/50
634/634 - 10s - loss: 3.1502 - accuracy300: 0.4461 - val_loss: 3.4366 - val_accuracy300: 0.3721 - 10s/epoch - 16ms/step
Epoch 15/50
634/634 - 10s - loss: 3.1385 - accuracy300: 0.4496 - val_loss: 3.4507 - val_accuracy300: 0.3778 - 10s/epoch - 16ms/step
testing model: results/QRTEA/W4/deepLOB_L1/h300
Evaluating performance on  test set...
1613/1613 - 8s - 8s/epoch - 5ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1302179
{'0': {'precision': 0.3434491774333203, 'recall': 0.5875800572200357, 'f1-score': 0.43350709046978714, 'support': 137714}, '1': {'precision': 0.3270129451576516, 'recall': 0.22731006466836925, 'f1-score': 0.26819501407495183, 'support': 133914}, '2': {'precision': 0.3905893536121673, 'recall': 0.23276991382301498, 'f1-score': 0.2917016075001886, 'support': 141221}, 'accuracy': 0.3493529111127797, 'macro avg': {'precision': 0.35368382540104637, 'recall': 0.34922001190380664, 'f1-score': 0.3311345706816425, 'support': 412849}, 'weighted avg': {'precision': 0.35424281193695006, 'recall': 0.3493529111127797, 'f1-score': 0.3313789188894087, 'support': 412849}}
[[80918 30699 26097]
 [78283 30440 25191]
 [76403 31946 32872]]
Evaluating performance on  train set...
634/634 - 4s - 4s/epoch - 6ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1158518
{'0': {'precision': 0.3594971618292814, 'recall': 0.4916151001427996, 'f1-score': 0.41530181413260336, 'support': 54622}, '1': {'precision': 0.3417758002630015, 'recall': 0.3547416049659711, 'f1-score': 0.34813802214739853, 'support': 53484}, '2': {'precision': 0.3780217030991025, 'recall': 0.2235207100591716, 'f1-score': 0.28093008122523444, 'support': 54080}, 'accuracy': 0.3570838420085581, 'macro avg': {'precision': 0.35976488839712845, 'recall': 0.35662580505598074, 'f1-score': 0.3481233058350788, 'support': 162186}, 'weighted avg': {'precision': 0.3598300998748649, 'recall': 0.3570838420085581, 'f1-score': 0.34834775172174665, 'support': 162186}}
[[26853 17720 10049]
 [24671 18973  9840]
 [23172 18820 12088]]
Evaluating performance on  val set...
206/206 - 1s - 1s/epoch - 6ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1068629
{'0': {'precision': 0.3430827354926349, 'recall': 0.47684229158062424, 'f1-score': 0.39905199229743743, 'support': 16949}, '1': {'precision': 0.3406672746618027, 'recall': 0.4926094840375845, 'f1-score': 0.4027855778950915, 'support': 18199}, '2': {'precision': 0.4767238361918096, 'recall': 0.07746558980775793, 'f1-score': 0.13327462204608834, 'support': 17582}, 'accuracy': 0.34911814906125543, 'macro avg': {'precision': 0.3868246154487491, 'recall': 0.3489724551419889, 'f1-score': 0.31170406407953904, 'support': 52730}, 'weighted avg': {'precision': 0.38680962456588686, 'recall': 0.34911814906125543, 'f1-score': 0.31172124700125853, 'support': 52730}}
[[8082 8151  716]
 [8455 8965  779]
 [7020 9200 1362]]
training model: results/QRTEA/W4/deepLOB_L1/h500
Epoch 1/50
634/634 - 12s - loss: 3.2695 - accuracy500: 0.3950 - val_loss: 3.4357 - val_accuracy500: 0.3551 - 12s/epoch - 19ms/step
Epoch 2/50
634/634 - 10s - loss: 3.2455 - accuracy500: 0.4029 - val_loss: 3.4350 - val_accuracy500: 0.3507 - 10s/epoch - 16ms/step
Epoch 3/50
634/634 - 10s - loss: 3.2220 - accuracy500: 0.4144 - val_loss: 3.4105 - val_accuracy500: 0.3534 - 10s/epoch - 16ms/step
Epoch 4/50
634/634 - 10s - loss: 3.2120 - accuracy500: 0.4170 - val_loss: 3.3411 - val_accuracy500: 0.3599 - 10s/epoch - 16ms/step
Epoch 5/50
634/634 - 10s - loss: 3.1940 - accuracy500: 0.4282 - val_loss: 3.4253 - val_accuracy500: 0.3500 - 10s/epoch - 16ms/step
Epoch 6/50
634/634 - 10s - loss: 3.1877 - accuracy500: 0.4289 - val_loss: 3.3620 - val_accuracy500: 0.3574 - 10s/epoch - 16ms/step
Epoch 7/50
634/634 - 10s - loss: 3.1934 - accuracy500: 0.4216 - val_loss: 3.4956 - val_accuracy500: 0.3483 - 10s/epoch - 16ms/step
Epoch 8/50
634/634 - 10s - loss: 3.1845 - accuracy500: 0.4297 - val_loss: 3.4468 - val_accuracy500: 0.3498 - 10s/epoch - 16ms/step
Epoch 9/50
634/634 - 10s - loss: 3.1813 - accuracy500: 0.4305 - val_loss: 3.4854 - val_accuracy500: 0.3547 - 10s/epoch - 16ms/step
Epoch 10/50
634/634 - 10s - loss: 3.1708 - accuracy500: 0.4341 - val_loss: 3.4095 - val_accuracy500: 0.3504 - 10s/epoch - 16ms/step
Epoch 11/50
634/634 - 10s - loss: 3.1603 - accuracy500: 0.4435 - val_loss: 3.4396 - val_accuracy500: 0.3575 - 10s/epoch - 16ms/step
Epoch 12/50
634/634 - 10s - loss: 3.1461 - accuracy500: 0.4487 - val_loss: 3.4617 - val_accuracy500: 0.3519 - 10s/epoch - 16ms/step
Epoch 13/50
634/634 - 10s - loss: 3.1348 - accuracy500: 0.4542 - val_loss: 3.4608 - val_accuracy500: 0.3490 - 10s/epoch - 16ms/step
Epoch 14/50
634/634 - 10s - loss: 3.1370 - accuracy500: 0.4532 - val_loss: 3.5099 - val_accuracy500: 0.3478 - 10s/epoch - 16ms/step
testing model: results/QRTEA/W4/deepLOB_L1/h500
Evaluating performance on  test set...
1613/1613 - 9s - 9s/epoch - 6ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.159116
{'0': {'precision': 0.36829549492063723, 'recall': 0.3590936406377037, 'f1-score': 0.36363636363636365, 'support': 141445}, '1': {'precision': 0.3113277067893939, 'recall': 0.5267768219139409, 'f1-score': 0.39135982288510834, 'support': 127517}, '2': {'precision': 0.39396704689480355, 'recall': 0.16202297636339627, 'f1-score': 0.22961460046685248, 'support': 143887}, 'accuracy': 0.34220259707544404, 'macro avg': {'precision': 0.3578634162016116, 'recall': 0.34929781297168033, 'f1-score': 0.32820359566277485, 'support': 412849}, 'weighted avg': {'precision': 0.3596469119272792, 'recall': 0.34220259707544404, 'f1-score': 0.3254897844169656, 'support': 412849}}
[[50792 72980 17673]
 [42155 67173 18189]
 [44964 75610 23313]]
Evaluating performance on  train set...
634/634 - 4s - 4s/epoch - 6ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1395917
{'0': {'precision': 0.3503168714738388, 'recall': 0.3350333536596633, 'f1-score': 0.34250469902619174, 'support': 54117}, '1': {'precision': 0.34671239954706856, 'recall': 0.5840586688395867, 'f1-score': 0.43512392988458964, 'support': 53998}, '2': {'precision': 0.3929213540864026, 'recall': 0.14146215161546855, 'f1-score': 0.20802850227093478, 'support': 54071}, 'accuracy': 0.3534090488698161, 'macro avg': {'precision': 0.36331687503577, 'recall': 0.35351805803823955, 'f1-score': 0.32855237706057205, 'support': 162186}, 'weighted avg': {'precision': 0.3633206615928515, 'recall': 0.3534090488698161, 'f1-score': 0.3285083663781103, 'support': 162186}}
[[18131 29481  6505]
 [17147 31538  5313]
 [16478 29944  7649]]
Evaluating performance on  val set...
206/206 - 1s - 1s/epoch - 6ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1130354
{'0': {'precision': 0.3455267381937991, 'recall': 0.7011027941260499, 'f1-score': 0.4629140571945975, 'support': 17501}, '1': {'precision': 0.36194612200583565, 'recall': 0.308555561982993, 'f1-score': 0.3331251561329003, 'support': 17287}, '2': {'precision': 0.5628525382755842, 'recall': 0.07786199977705942, 'f1-score': 0.13679984332158246, 'support': 17942}, 'accuracy': 0.360345154560971, 'macro avg': {'precision': 0.42344179949173966, 'recall': 0.3625067852953674, 'f1-score': 0.3109463522163601, 'support': 52730}, 'weighted avg': {'precision': 0.4248573164798993, 'recall': 0.360345154560971, 'f1-score': 0.30939989148317715, 'support': 52730}}
[[12270  4755   476]
 [11344  5334   609]
 [11897  4648  1397]]
training model: results/QRTEA/W4/deepLOB_L1/h1000
Epoch 1/50
634/634 - 13s - loss: 3.2503 - accuracy1000: 0.4158 - val_loss: 3.4380 - val_accuracy1000: 0.3751 - 13s/epoch - 20ms/step
Epoch 2/50
634/634 - 11s - loss: 3.2067 - accuracy1000: 0.4294 - val_loss: 3.5068 - val_accuracy1000: 0.3644 - 11s/epoch - 17ms/step
Epoch 3/50
634/634 - 10s - loss: 3.1893 - accuracy1000: 0.4378 - val_loss: 3.5345 - val_accuracy1000: 0.3709 - 10s/epoch - 16ms/step
Epoch 4/50
634/634 - 10s - loss: 3.1725 - accuracy1000: 0.4410 - val_loss: 3.5585 - val_accuracy1000: 0.3798 - 10s/epoch - 16ms/step
Epoch 5/50
634/634 - 10s - loss: 3.1686 - accuracy1000: 0.4424 - val_loss: 3.4587 - val_accuracy1000: 0.3830 - 10s/epoch - 16ms/step
Epoch 6/50
634/634 - 10s - loss: 3.1611 - accuracy1000: 0.4447 - val_loss: 3.4297 - val_accuracy1000: 0.3849 - 10s/epoch - 16ms/step
Epoch 7/50
634/634 - 10s - loss: 3.1431 - accuracy1000: 0.4522 - val_loss: 3.5245 - val_accuracy1000: 0.3845 - 10s/epoch - 15ms/step
Epoch 8/50
634/634 - 10s - loss: 3.1301 - accuracy1000: 0.4544 - val_loss: 3.7195 - val_accuracy1000: 0.3852 - 10s/epoch - 15ms/step
Epoch 9/50
634/634 - 10s - loss: 3.1172 - accuracy1000: 0.4612 - val_loss: 3.9396 - val_accuracy1000: 0.3851 - 10s/epoch - 16ms/step
Epoch 10/50
634/634 - 10s - loss: 3.0917 - accuracy1000: 0.4740 - val_loss: 3.7887 - val_accuracy1000: 0.3850 - 10s/epoch - 15ms/step
Epoch 11/50
634/634 - 10s - loss: 3.0753 - accuracy1000: 0.4797 - val_loss: 3.6578 - val_accuracy1000: 0.3852 - 10s/epoch - 16ms/step
Epoch 12/50
634/634 - 10s - loss: 3.0620 - accuracy1000: 0.4813 - val_loss: 3.6481 - val_accuracy1000: 0.3855 - 10s/epoch - 16ms/step
Epoch 13/50
634/634 - 10s - loss: 3.0481 - accuracy1000: 0.4838 - val_loss: 3.6361 - val_accuracy1000: 0.3845 - 10s/epoch - 16ms/step
Epoch 14/50
634/634 - 10s - loss: 3.0545 - accuracy1000: 0.4829 - val_loss: 3.7616 - val_accuracy1000: 0.3848 - 10s/epoch - 16ms/step
Epoch 15/50
634/634 - 10s - loss: 3.0554 - accuracy1000: 0.4811 - val_loss: 3.8256 - val_accuracy1000: 0.3841 - 10s/epoch - 16ms/step
Epoch 16/50
634/634 - 10s - loss: 3.0371 - accuracy1000: 0.4864 - val_loss: 3.6662 - val_accuracy1000: 0.3847 - 10s/epoch - 16ms/step
testing model: results/QRTEA/W4/deepLOB_L1/h1000
Evaluating performance on  test set...
1613/1613 - 9s - 9s/epoch - 6ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1410396
{'0': {'precision': 0.39712924174412106, 'recall': 0.8668184333651959, 'f1-score': 0.5447044271708075, 'support': 159016}, '1': {'precision': 0.24270701975620007, 'recall': 0.0285864226869455, 'f1-score': 0.05114849362636973, 'support': 100992}, '2': {'precision': 0.41453181851934356, 'recall': 0.14609954135343264, 'f1-score': 0.21605251827448246, 'support': 152841}, 'accuracy': 0.3949506962594072, 'macro avg': {'precision': 0.35145602667322157, 'recall': 0.34716813246852474, 'f1-score': 0.2706351463572199, 'support': 412849}, 'weighted avg': {'precision': 0.36579676472200806, 'recall': 0.3949506962594072, 'f1-score': 0.30229936563948956, 'support': 412849}}
[[137838   4540  16638]
 [ 83205   2887  14900]
 [126043   4468  22330]]
Evaluating performance on  train set...
634/634 - 4s - 4s/epoch - 6ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1606178
{'0': {'precision': 0.3376863523858861, 'recall': 0.8535445386098279, 'f1-score': 0.4839201938444089, 'support': 54986}, '1': {'precision': 0.38892961876832843, 'recall': 0.03941161175290665, 'f1-score': 0.07157071064791393, 'support': 53842}, '2': {'precision': 0.44269131071790824, 'recall': 0.14723190524382473, 'f1-score': 0.22097209720972102, 'support': 53358}, 'accuracy': 0.35089958442775576, 'macro avg': {'precision': 0.3897690939573743, 'recall': 0.34672935186885306, 'f1-score': 0.25882100056734797, 'support': 162186}, 'weighted avg': {'precision': 0.3892437896199476, 'recall': 0.35089958442775576, 'f1-score': 0.2605217166978034, 'support': 162186}}
[[46933  1715  6338]
 [48168  2122  3552]
 [43883  1619  7856]]
Evaluating performance on  val set...
206/206 - 1s - 1s/epoch - 6ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1391753
{'0': {'precision': 0.3808987891959019, 'recall': 0.9871266217439405, 'f1-score': 0.549690571532581, 'support': 19886}, '1': {'precision': 0.25, 'recall': 0.0030485591928576614, 'f1-score': 0.006023664395840803, 'support': 13777}, '2': {'precision': 0.6023391812865497, 'recall': 0.03241202076886768, 'f1-score': 0.06151396008560196, 'support': 19067}, 'accuracy': 0.3847904418736962, 'macro avg': {'precision': 0.41107932349415055, 'recall': 0.34086240056855527, 'f1-score': 0.2057427320046746, 'support': 52730}, 'weighted avg': {'precision': 0.4267704246451801, 'recall': 0.3847904418736962, 'f1-score': 0.23112121006695577, 'support': 52730}}
[[19630    67   189]
 [13516    42   219]
 [18390    59   618]]
training model: results/QRTEA/W4/deepOF_L1/h10
Epoch 1/50
634/634 - 12s - loss: 3.0702 - accuracy10: 0.4407 - val_loss: 2.5676 - val_accuracy10: 0.5752 - 12s/epoch - 18ms/step
Epoch 2/50
634/634 - 9s - loss: 2.9552 - accuracy10: 0.4736 - val_loss: 2.5241 - val_accuracy10: 0.6453 - 9s/epoch - 14ms/step
Epoch 3/50
634/634 - 9s - loss: 2.9134 - accuracy10: 0.4994 - val_loss: 2.4915 - val_accuracy10: 0.6644 - 9s/epoch - 14ms/step
Epoch 4/50
634/634 - 9s - loss: 2.8780 - accuracy10: 0.5151 - val_loss: 2.4643 - val_accuracy10: 0.6770 - 9s/epoch - 14ms/step
Epoch 5/50
634/634 - 9s - loss: 2.8514 - accuracy10: 0.5246 - val_loss: 2.4479 - val_accuracy10: 0.6786 - 9s/epoch - 14ms/step
Epoch 6/50
634/634 - 9s - loss: 2.8267 - accuracy10: 0.5308 - val_loss: 2.4309 - val_accuracy10: 0.6797 - 9s/epoch - 14ms/step
Epoch 7/50
634/634 - 9s - loss: 2.8031 - accuracy10: 0.5385 - val_loss: 2.4185 - val_accuracy10: 0.6925 - 9s/epoch - 14ms/step
Epoch 8/50
634/634 - 9s - loss: 2.7856 - accuracy10: 0.5411 - val_loss: 2.4085 - val_accuracy10: 0.6945 - 9s/epoch - 14ms/step
Epoch 9/50
634/634 - 9s - loss: 2.7708 - accuracy10: 0.5483 - val_loss: 2.3947 - val_accuracy10: 0.6862 - 9s/epoch - 14ms/step
Epoch 10/50
634/634 - 9s - loss: 2.7541 - accuracy10: 0.5516 - val_loss: 2.3862 - val_accuracy10: 0.6949 - 9s/epoch - 14ms/step
Epoch 11/50
634/634 - 9s - loss: 2.7391 - accuracy10: 0.5513 - val_loss: 2.3903 - val_accuracy10: 0.6965 - 9s/epoch - 14ms/step
Epoch 12/50
634/634 - 9s - loss: 2.7244 - accuracy10: 0.5526 - val_loss: 2.3754 - val_accuracy10: 0.6960 - 9s/epoch - 14ms/step
Epoch 13/50
634/634 - 9s - loss: 2.7075 - accuracy10: 0.5584 - val_loss: 2.3853 - val_accuracy10: 0.6981 - 9s/epoch - 14ms/step
Epoch 14/50
634/634 - 9s - loss: 2.6925 - accuracy10: 0.5594 - val_loss: 2.3701 - val_accuracy10: 0.6969 - 9s/epoch - 14ms/step
Epoch 15/50
634/634 - 9s - loss: 2.6786 - accuracy10: 0.5627 - val_loss: 2.3696 - val_accuracy10: 0.7113 - 9s/epoch - 14ms/step
Epoch 16/50
634/634 - 9s - loss: 2.6702 - accuracy10: 0.5576 - val_loss: 2.3697 - val_accuracy10: 0.7045 - 9s/epoch - 14ms/step
Epoch 17/50
634/634 - 9s - loss: 2.6522 - accuracy10: 0.5649 - val_loss: 2.3614 - val_accuracy10: 0.7091 - 9s/epoch - 14ms/step
Epoch 18/50
634/634 - 9s - loss: 2.6375 - accuracy10: 0.5658 - val_loss: 2.3412 - val_accuracy10: 0.6931 - 9s/epoch - 14ms/step
Epoch 19/50
634/634 - 9s - loss: 2.6293 - accuracy10: 0.5658 - val_loss: 2.3561 - val_accuracy10: 0.7057 - 9s/epoch - 14ms/step
Epoch 20/50
634/634 - 9s - loss: 2.6158 - accuracy10: 0.5680 - val_loss: 2.3501 - val_accuracy10: 0.6963 - 9s/epoch - 14ms/step
Epoch 21/50
634/634 - 9s - loss: 2.6018 - accuracy10: 0.5687 - val_loss: 2.3455 - val_accuracy10: 0.6959 - 9s/epoch - 14ms/step
Epoch 22/50
634/634 - 9s - loss: 2.5925 - accuracy10: 0.5686 - val_loss: 2.3501 - val_accuracy10: 0.7078 - 9s/epoch - 14ms/step
Epoch 23/50
634/634 - 9s - loss: 2.5767 - accuracy10: 0.5693 - val_loss: 2.3344 - val_accuracy10: 0.6813 - 9s/epoch - 14ms/step
Epoch 24/50
634/634 - 9s - loss: 2.5647 - accuracy10: 0.5738 - val_loss: 2.3235 - val_accuracy10: 0.6894 - 9s/epoch - 14ms/step
Epoch 25/50
634/634 - 9s - loss: 2.5518 - accuracy10: 0.5794 - val_loss: 2.3382 - val_accuracy10: 0.6926 - 9s/epoch - 14ms/step
Epoch 26/50
634/634 - 9s - loss: 2.5339 - accuracy10: 0.5789 - val_loss: 2.3224 - val_accuracy10: 0.6962 - 9s/epoch - 14ms/step
Epoch 27/50
634/634 - 9s - loss: 2.5257 - accuracy10: 0.5805 - val_loss: 2.3290 - val_accuracy10: 0.6900 - 9s/epoch - 14ms/step
Epoch 28/50
634/634 - 9s - loss: 2.5169 - accuracy10: 0.5819 - val_loss: 2.3206 - val_accuracy10: 0.6850 - 9s/epoch - 14ms/step
Epoch 29/50
634/634 - 9s - loss: 2.5085 - accuracy10: 0.5831 - val_loss: 2.3455 - val_accuracy10: 0.6960 - 9s/epoch - 14ms/step
Epoch 30/50
634/634 - 9s - loss: 2.4954 - accuracy10: 0.5852 - val_loss: 2.3365 - val_accuracy10: 0.6862 - 9s/epoch - 14ms/step
Epoch 31/50
634/634 - 9s - loss: 2.4866 - accuracy10: 0.5860 - val_loss: 2.3538 - val_accuracy10: 0.6840 - 9s/epoch - 14ms/step
Epoch 32/50
634/634 - 9s - loss: 2.4729 - accuracy10: 0.5909 - val_loss: 2.3447 - val_accuracy10: 0.6929 - 9s/epoch - 14ms/step
Epoch 33/50
634/634 - 9s - loss: 2.4643 - accuracy10: 0.5905 - val_loss: 2.3330 - val_accuracy10: 0.6855 - 9s/epoch - 14ms/step
Epoch 34/50
634/634 - 9s - loss: 2.4437 - accuracy10: 0.5950 - val_loss: 2.3437 - val_accuracy10: 0.6701 - 9s/epoch - 14ms/step
Epoch 35/50
634/634 - 9s - loss: 2.4408 - accuracy10: 0.5937 - val_loss: 2.3594 - val_accuracy10: 0.6800 - 9s/epoch - 14ms/step
Epoch 36/50
634/634 - 9s - loss: 2.4259 - accuracy10: 0.5951 - val_loss: 2.3536 - val_accuracy10: 0.6845 - 9s/epoch - 14ms/step
Epoch 37/50
634/634 - 9s - loss: 2.4112 - accuracy10: 0.5987 - val_loss: 2.4007 - val_accuracy10: 0.6937 - 9s/epoch - 14ms/step
Epoch 38/50
634/634 - 9s - loss: 2.4029 - accuracy10: 0.5984 - val_loss: 2.3645 - val_accuracy10: 0.6674 - 9s/epoch - 14ms/step
testing model: results/QRTEA/W4/deepOF_L1/h10
Evaluating performance on  test set...
1613/1613 - 9s - 9s/epoch - 6ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.80573964
{'0': {'precision': 0.20342790227284824, 'recall': 0.5658405140505167, 'f1-score': 0.2992655004463377, 'support': 33771}, '1': {'precision': 0.923590712720355, 'recall': 0.6388107976512732, 'f1-score': 0.7552472472403874, 'support': 345038}, '2': {'precision': 0.24137501401677028, 'recall': 0.5691914443530379, 'f1-score': 0.3389940243400964, 'support': 34036}, 'accuracy': 0.6271021812060217, 'macro avg': {'precision': 0.45613120966999116, 'recall': 0.5912809186849426, 'f1-score': 0.46450225734227385, 'support': 412845}, 'weighted avg': {'precision': 0.808437297291567, 'recall': 0.6271021812060217, 'f1-score': 0.6836306495690673, 'support': 412845}}
[[ 19109   8648   6014]
 [ 69750 220414  54874]
 [  5076   9587  19373]]
Evaluating performance on  train set...
634/634 - 5s - 5s/epoch - 8ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.77479404
{'0': {'precision': 0.28452404382339436, 'recall': 0.5399315281668223, 'f1-score': 0.3726665377757728, 'support': 16065}, '1': {'precision': 0.9049770480956123, 'recall': 0.6729890978426337, 'f1-score': 0.7719299792759823, 'support': 130066}, '2': {'precision': 0.27115736505032023, 'recall': 0.5907194020554345, 'f1-score': 0.3716956359859693, 'support': 16055}, 'accuracy': 0.6516653718570037, 'macro avg': {'precision': 0.48688615232310894, 'recall': 0.6012133426882968, 'f1-score': 0.5054307176792415, 'support': 162186}, 'weighted avg': {'precision': 0.7807767316384252, 'recall': 0.6516653718570037, 'f1-score': 0.6927620512845278, 'support': 162186}}
[[ 8674  4641  2750]
 [19791 87533 22742]
 [ 2021  4550  9484]]
Evaluating performance on  val set...
206/206 - 1s - 1s/epoch - 7ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.73521143
{'0': {'precision': 0.23296599123118852, 'recall': 0.489785749875436, 'f1-score': 0.3157472095077491, 'support': 4014}, '1': {'precision': 0.9180597186995619, 'recall': 0.7148660173257327, 'f1-score': 0.8038206273500391, 'support': 44558}, '2': {'precision': 0.2449447571398791, 'recall': 0.56531152273274, 'f1-score': 0.341793324121882, 'support': 4157}, 'accuracy': 0.6859413226118455, 'macro avg': {'precision': 0.46532348902354315, 'recall': 0.5899877633113029, 'f1-score': 0.4871203869932234, 'support': 52729}, 'weighted avg': {'precision': 0.8128404822782066, 'recall': 0.6859413226118455, 'f1-score': 0.7302411132546003, 'support': 52729}}
[[ 1966  1436   612]
 [ 6073 31853  6632]
 [  400  1407  2350]]
training model: results/QRTEA/W4/deepOF_L1/h20
Epoch 1/50
634/634 - 11s - loss: 3.0946 - accuracy20: 0.4249 - val_loss: 2.6354 - val_accuracy20: 0.5909 - 11s/epoch - 18ms/step
Epoch 2/50
634/634 - 9s - loss: 2.9815 - accuracy20: 0.4607 - val_loss: 2.5938 - val_accuracy20: 0.6226 - 9s/epoch - 14ms/step
Epoch 3/50
634/634 - 9s - loss: 2.9385 - accuracy20: 0.4780 - val_loss: 2.5694 - val_accuracy20: 0.6185 - 9s/epoch - 14ms/step
Epoch 4/50
634/634 - 13s - loss: 2.9112 - accuracy20: 0.4889 - val_loss: 2.5459 - val_accuracy20: 0.6360 - 13s/epoch - 20ms/step
Epoch 5/50
634/634 - 13s - loss: 2.8849 - accuracy20: 0.5007 - val_loss: 2.5342 - val_accuracy20: 0.6597 - 13s/epoch - 20ms/step
Epoch 6/50
634/634 - 9s - loss: 2.8621 - accuracy20: 0.5095 - val_loss: 2.5153 - val_accuracy20: 0.6360 - 9s/epoch - 14ms/step
Epoch 7/50
634/634 - 12s - loss: 2.8417 - accuracy20: 0.5097 - val_loss: 2.5008 - val_accuracy20: 0.6491 - 12s/epoch - 19ms/step
Epoch 8/50
634/634 - 9s - loss: 2.8212 - accuracy20: 0.5190 - val_loss: 2.4961 - val_accuracy20: 0.6376 - 9s/epoch - 14ms/step
Epoch 9/50
634/634 - 9s - loss: 2.8040 - accuracy20: 0.5230 - val_loss: 2.4766 - val_accuracy20: 0.6478 - 9s/epoch - 14ms/step
Epoch 10/50
634/634 - 9s - loss: 2.7879 - accuracy20: 0.5272 - val_loss: 2.4751 - val_accuracy20: 0.6476 - 9s/epoch - 14ms/step
Epoch 11/50
634/634 - 9s - loss: 2.7785 - accuracy20: 0.5295 - val_loss: 2.4549 - val_accuracy20: 0.6474 - 9s/epoch - 14ms/step
Epoch 12/50
634/634 - 9s - loss: 2.7628 - accuracy20: 0.5341 - val_loss: 2.4634 - val_accuracy20: 0.6479 - 9s/epoch - 14ms/step
Epoch 13/50
634/634 - 9s - loss: 2.7477 - accuracy20: 0.5382 - val_loss: 2.4597 - val_accuracy20: 0.6583 - 9s/epoch - 14ms/step
Epoch 14/50
634/634 - 9s - loss: 2.7357 - accuracy20: 0.5407 - val_loss: 2.4563 - val_accuracy20: 0.6343 - 9s/epoch - 14ms/step
Epoch 15/50
634/634 - 9s - loss: 2.7224 - accuracy20: 0.5454 - val_loss: 2.4501 - val_accuracy20: 0.6409 - 9s/epoch - 14ms/step
Epoch 16/50
634/634 - 9s - loss: 2.7131 - accuracy20: 0.5449 - val_loss: 2.4507 - val_accuracy20: 0.6526 - 9s/epoch - 14ms/step
Epoch 17/50
634/634 - 9s - loss: 2.6974 - accuracy20: 0.5530 - val_loss: 2.4392 - val_accuracy20: 0.6285 - 9s/epoch - 14ms/step
Epoch 18/50
634/634 - 9s - loss: 2.6820 - accuracy20: 0.5532 - val_loss: 2.4394 - val_accuracy20: 0.6492 - 9s/epoch - 14ms/step
Epoch 19/50
634/634 - 9s - loss: 2.6741 - accuracy20: 0.5559 - val_loss: 2.4301 - val_accuracy20: 0.6528 - 9s/epoch - 14ms/step
Epoch 20/50
634/634 - 9s - loss: 2.6614 - accuracy20: 0.5567 - val_loss: 2.4460 - val_accuracy20: 0.6575 - 9s/epoch - 14ms/step
Epoch 21/50
634/634 - 9s - loss: 2.6519 - accuracy20: 0.5597 - val_loss: 2.4335 - val_accuracy20: 0.6524 - 9s/epoch - 14ms/step
Epoch 22/50
634/634 - 9s - loss: 2.6379 - accuracy20: 0.5586 - val_loss: 2.4380 - val_accuracy20: 0.6508 - 9s/epoch - 14ms/step
Epoch 23/50
634/634 - 9s - loss: 2.6283 - accuracy20: 0.5631 - val_loss: 2.4346 - val_accuracy20: 0.6485 - 9s/epoch - 14ms/step
Epoch 24/50
634/634 - 9s - loss: 2.6161 - accuracy20: 0.5632 - val_loss: 2.4395 - val_accuracy20: 0.6560 - 9s/epoch - 14ms/step
Epoch 25/50
634/634 - 9s - loss: 2.6098 - accuracy20: 0.5609 - val_loss: 2.4256 - val_accuracy20: 0.6428 - 9s/epoch - 14ms/step
Epoch 26/50
634/634 - 9s - loss: 2.6000 - accuracy20: 0.5614 - val_loss: 2.4366 - val_accuracy20: 0.6550 - 9s/epoch - 14ms/step
Epoch 27/50
634/634 - 9s - loss: 2.5835 - accuracy20: 0.5677 - val_loss: 2.4414 - val_accuracy20: 0.6578 - 9s/epoch - 14ms/step
Epoch 28/50
634/634 - 9s - loss: 2.5753 - accuracy20: 0.5680 - val_loss: 2.4330 - val_accuracy20: 0.6682 - 9s/epoch - 14ms/step
Epoch 29/50
634/634 - 9s - loss: 2.6254 - accuracy20: 0.5546 - val_loss: 2.4432 - val_accuracy20: 0.6697 - 9s/epoch - 14ms/step
Epoch 30/50
634/634 - 9s - loss: 2.5998 - accuracy20: 0.5654 - val_loss: 2.4303 - val_accuracy20: 0.6522 - 9s/epoch - 14ms/step
Epoch 31/50
634/634 - 9s - loss: 2.5688 - accuracy20: 0.5684 - val_loss: 2.4223 - val_accuracy20: 0.6616 - 9s/epoch - 14ms/step
Epoch 32/50
634/634 - 9s - loss: 2.5463 - accuracy20: 0.5721 - val_loss: 2.4393 - val_accuracy20: 0.6686 - 9s/epoch - 14ms/step
Epoch 33/50
634/634 - 9s - loss: 2.5313 - accuracy20: 0.5721 - val_loss: 2.4484 - val_accuracy20: 0.6624 - 9s/epoch - 14ms/step
Epoch 34/50
634/634 - 9s - loss: 2.5226 - accuracy20: 0.5742 - val_loss: 2.4439 - val_accuracy20: 0.6688 - 9s/epoch - 14ms/step
Epoch 35/50
634/634 - 9s - loss: 2.5120 - accuracy20: 0.5751 - val_loss: 2.4529 - val_accuracy20: 0.6825 - 9s/epoch - 14ms/step
Epoch 36/50
634/634 - 9s - loss: 2.4965 - accuracy20: 0.5773 - val_loss: 2.4598 - val_accuracy20: 0.6434 - 9s/epoch - 14ms/step
Epoch 37/50
634/634 - 9s - loss: 2.4840 - accuracy20: 0.5783 - val_loss: 2.4832 - val_accuracy20: 0.6611 - 9s/epoch - 14ms/step
Epoch 38/50
634/634 - 9s - loss: 2.4788 - accuracy20: 0.5805 - val_loss: 2.4772 - val_accuracy20: 0.6530 - 9s/epoch - 14ms/step
Epoch 39/50
634/634 - 9s - loss: 2.4624 - accuracy20: 0.5823 - val_loss: 2.4688 - val_accuracy20: 0.6565 - 9s/epoch - 14ms/step
Epoch 40/50
634/634 - 9s - loss: 2.4479 - accuracy20: 0.5849 - val_loss: 2.4936 - val_accuracy20: 0.6487 - 9s/epoch - 14ms/step
Epoch 41/50
634/634 - 9s - loss: 2.4416 - accuracy20: 0.5857 - val_loss: 2.5037 - val_accuracy20: 0.6596 - 9s/epoch - 14ms/step
testing model: results/QRTEA/W4/deepOF_L1/h20
Evaluating performance on  test set...
1613/1613 - 9s - 9s/epoch - 6ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.82952327
{'0': {'precision': 0.2713291018319995, 'recall': 0.5509979738759322, 'f1-score': 0.36360662266727356, 'support': 46394}, '1': {'precision': 0.874736725889187, 'recall': 0.6449438483671099, 'f1-score': 0.7424666470835234, 'support': 319403}, '2': {'precision': 0.3155349732363024, 'recall': 0.5575582383948308, 'f1-score': 0.4030019280551224, 'support': 47048}, 'accuracy': 0.6244280541123182, 'macro avg': {'precision': 0.4872002669858297, 'recall': 0.5845000202126243, 'f1-score': 0.5030250659353065, 'support': 412845}, 'weighted avg': {'precision': 0.7432011196221326, 'recall': 0.6244280541123183, 'f1-score': 0.6612062029129129, 'support': 412845}}
[[ 25563  14384   6447]
 [ 62950 205997  50456]
 [  5701  15115  26232]]
Evaluating performance on  train set...
634/634 - 3s - 3s/epoch - 5ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.8182127
{'0': {'precision': 0.33834695415290095, 'recall': 0.5432253861902103, 'f1-score': 0.41697917782777955, 'support': 21492}, '1': {'precision': 0.8488382174440784, 'recall': 0.6581019199260597, 'f1-score': 0.7413991395589885, 'support': 119015}, '2': {'precision': 0.3414200180750113, 'recall': 0.5576364223442041, 'f1-score': 0.42352899959710616, 'support': 21679}, 'accuracy': 0.6294501374964547, 'macro avg': {'precision': 0.5095350632239969, 'recall': 0.5863212428201581, 'f1-score': 0.5273024389946247, 'support': 162186}, 'weighted avg': {'precision': 0.7133653814731808, 'recall': 0.6294501374964547, 'f1-score': 0.6559198714238794, 'support': 162186}}
[[11675  6797  3020]
 [20392 78324 20299]
 [ 2439  7151 12089]]
Evaluating performance on  val set...
206/206 - 1s - 1s/epoch - 6ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.7884098
{'0': {'precision': 0.2749895002099958, 'recall': 0.47984609747160134, 'f1-score': 0.3496195434521426, 'support': 5458}, '1': {'precision': 0.8707354962060107, 'recall': 0.7017624115182742, 'f1-score': 0.7771704351535836, 'support': 41534}, '2': {'precision': 0.3082930839584832, 'recall': 0.5229213874847481, 'f1-score': 0.3878975950349108, 'support': 5737}, 'accuracy': 0.659333573555349, 'macro avg': {'precision': 0.4846726934581633, 'recall': 0.5681766321582079, 'f1-score': 0.5048958578802124, 'support': 52729}, 'weighted avg': {'precision': 0.7478749495388957, 'recall': 0.659333573555349, 'f1-score': 0.6905609593306532, 'support': 52729}}
[[ 2619  2103   736]
 [ 6392 29147  5995]
 [  513  2224  3000]]
training model: results/QRTEA/W4/deepOF_L1/h30
Epoch 1/50
634/634 - 11s - loss: 3.1232 - accuracy30: 0.4134 - val_loss: 2.6977 - val_accuracy30: 0.5694 - 11s/epoch - 17ms/step
Epoch 2/50
634/634 - 9s - loss: 3.0192 - accuracy30: 0.4431 - val_loss: 2.6634 - val_accuracy30: 0.5955 - 9s/epoch - 15ms/step
Epoch 3/50
634/634 - 10s - loss: 2.9878 - accuracy30: 0.4531 - val_loss: 2.6339 - val_accuracy30: 0.6102 - 10s/epoch - 15ms/step
Epoch 4/50
634/634 - 9s - loss: 2.9553 - accuracy30: 0.4674 - val_loss: 2.6257 - val_accuracy30: 0.6210 - 9s/epoch - 15ms/step
Epoch 5/50
634/634 - 9s - loss: 2.9303 - accuracy30: 0.4786 - val_loss: 2.6031 - val_accuracy30: 0.6216 - 9s/epoch - 14ms/step
Epoch 6/50
634/634 - 9s - loss: 2.9086 - accuracy30: 0.4864 - val_loss: 2.5912 - val_accuracy30: 0.6277 - 9s/epoch - 14ms/step
Epoch 7/50
634/634 - 9s - loss: 2.8877 - accuracy30: 0.4938 - val_loss: 2.5799 - val_accuracy30: 0.6265 - 9s/epoch - 14ms/step
Epoch 8/50
634/634 - 9s - loss: 2.8716 - accuracy30: 0.4984 - val_loss: 2.5726 - val_accuracy30: 0.6310 - 9s/epoch - 14ms/step
Epoch 9/50
634/634 - 9s - loss: 2.8519 - accuracy30: 0.5063 - val_loss: 2.5622 - val_accuracy30: 0.6400 - 9s/epoch - 14ms/step
Epoch 10/50
634/634 - 9s - loss: 2.8389 - accuracy30: 0.5085 - val_loss: 2.5553 - val_accuracy30: 0.6255 - 9s/epoch - 14ms/step
Epoch 11/50
634/634 - 9s - loss: 2.8238 - accuracy30: 0.5111 - val_loss: 2.5374 - val_accuracy30: 0.6332 - 9s/epoch - 14ms/step
Epoch 12/50
634/634 - 9s - loss: 2.8115 - accuracy30: 0.5179 - val_loss: 2.5298 - val_accuracy30: 0.6257 - 9s/epoch - 14ms/step
Epoch 13/50
634/634 - 9s - loss: 2.7950 - accuracy30: 0.5238 - val_loss: 2.5427 - val_accuracy30: 0.6234 - 9s/epoch - 14ms/step
Epoch 14/50
634/634 - 9s - loss: 2.7839 - accuracy30: 0.5233 - val_loss: 2.5294 - val_accuracy30: 0.6333 - 9s/epoch - 14ms/step
Epoch 15/50
634/634 - 9s - loss: 2.7727 - accuracy30: 0.5260 - val_loss: 2.5225 - val_accuracy30: 0.6271 - 9s/epoch - 14ms/step
Epoch 16/50
634/634 - 9s - loss: 2.7596 - accuracy30: 0.5287 - val_loss: 2.5176 - val_accuracy30: 0.6316 - 9s/epoch - 14ms/step
Epoch 17/50
634/634 - 9s - loss: 2.7508 - accuracy30: 0.5324 - val_loss: 2.5186 - val_accuracy30: 0.6160 - 9s/epoch - 14ms/step
Epoch 18/50
634/634 - 9s - loss: 2.7383 - accuracy30: 0.5341 - val_loss: 2.5177 - val_accuracy30: 0.6240 - 9s/epoch - 14ms/step
Epoch 19/50
634/634 - 9s - loss: 2.7273 - accuracy30: 0.5385 - val_loss: 2.5192 - val_accuracy30: 0.6174 - 9s/epoch - 14ms/step
Epoch 20/50
634/634 - 9s - loss: 2.7144 - accuracy30: 0.5423 - val_loss: 2.5186 - val_accuracy30: 0.6316 - 9s/epoch - 14ms/step
Epoch 21/50
634/634 - 9s - loss: 2.7042 - accuracy30: 0.5432 - val_loss: 2.5164 - val_accuracy30: 0.6171 - 9s/epoch - 14ms/step
Epoch 22/50
634/634 - 9s - loss: 2.6949 - accuracy30: 0.5440 - val_loss: 2.5184 - val_accuracy30: 0.6254 - 9s/epoch - 14ms/step
Epoch 23/50
634/634 - 9s - loss: 2.6832 - accuracy30: 0.5449 - val_loss: 2.5187 - val_accuracy30: 0.6198 - 9s/epoch - 14ms/step
Epoch 24/50
634/634 - 9s - loss: 2.6753 - accuracy30: 0.5474 - val_loss: 2.5148 - val_accuracy30: 0.6271 - 9s/epoch - 14ms/step
Epoch 25/50
634/634 - 9s - loss: 2.6640 - accuracy30: 0.5493 - val_loss: 2.5209 - val_accuracy30: 0.6169 - 9s/epoch - 14ms/step
Epoch 26/50
634/634 - 9s - loss: 2.6497 - accuracy30: 0.5508 - val_loss: 2.5301 - val_accuracy30: 0.6239 - 9s/epoch - 14ms/step
Epoch 27/50
634/634 - 9s - loss: 2.6396 - accuracy30: 0.5500 - val_loss: 2.5339 - val_accuracy30: 0.6303 - 9s/epoch - 14ms/step
Epoch 28/50
634/634 - 9s - loss: 2.6234 - accuracy30: 0.5549 - val_loss: 2.5161 - val_accuracy30: 0.6138 - 9s/epoch - 14ms/step
Epoch 29/50
634/634 - 9s - loss: 2.6117 - accuracy30: 0.5539 - val_loss: 2.5245 - val_accuracy30: 0.6112 - 9s/epoch - 14ms/step
Epoch 30/50
634/634 - 9s - loss: 2.6056 - accuracy30: 0.5552 - val_loss: 2.5226 - val_accuracy30: 0.6116 - 9s/epoch - 15ms/step
Epoch 31/50
634/634 - 9s - loss: 2.6019 - accuracy30: 0.5566 - val_loss: 2.5337 - val_accuracy30: 0.6116 - 9s/epoch - 14ms/step
Epoch 32/50
634/634 - 9s - loss: 2.5885 - accuracy30: 0.5575 - val_loss: 2.5322 - val_accuracy30: 0.6034 - 9s/epoch - 14ms/step
Epoch 33/50
634/634 - 9s - loss: 2.5714 - accuracy30: 0.5646 - val_loss: 2.5350 - val_accuracy30: 0.6246 - 9s/epoch - 14ms/step
Epoch 34/50
634/634 - 9s - loss: 2.5696 - accuracy30: 0.5610 - val_loss: 2.5437 - val_accuracy30: 0.6167 - 9s/epoch - 14ms/step
testing model: results/QRTEA/W4/deepOF_L1/h30
Evaluating performance on  test set...
1613/1613 - 10s - 10s/epoch - 6ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.8591094
{'0': {'precision': 0.30791234560414016, 'recall': 0.5469807695760688, 'f1-score': 0.3940191557748647, 'support': 55693}, '1': {'precision': 0.8299685053856228, 'recall': 0.6305966299576332, 'f1-score': 0.7166751140395338, 'support': 300471}, '2': {'precision': 0.3487350790721577, 'recall': 0.526772639861682, 'f1-score': 0.4196515787180514, 'support': 56681}, 'accuracy': 0.6050624326321017, 'macro avg': {'precision': 0.49553864335397363, 'recall': 0.5681166797984614, 'f1-score': 0.51011528284415, 'support': 412845}, 'weighted avg': {'precision': 0.6934725673372424, 'recall': 0.6050624326321017, 'f1-score': 0.632369214030593, 'support': 412845}}
[[ 30463  19043   6187]
 [ 61422 189476  49573]
 [  7049  19774  29858]]
Evaluating performance on  train set...
634/634 - 4s - 4s/epoch - 6ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.85375
{'0': {'precision': 0.3751854236054745, 'recall': 0.5221032132424538, 'f1-score': 0.43661650706794347, 'support': 25675}, '1': {'precision': 0.7937750937385938, 'recall': 0.6488847096266693, 'f1-score': 0.7140540271628277, 'support': 110599}, '2': {'precision': 0.3718304388836487, 'recall': 0.5172506946588453, 'f1-score': 0.43264792278640374, 'support': 25912}, 'accuracy': 0.607783655802597, 'macro avg': {'precision': 0.5135969854092389, 'recall': 0.5627462058426561, 'f1-score': 0.527772819005725, 'support': 162186}, 'weighted avg': {'precision': 0.6600969730791708, 'recall': 0.607783655802597, 'f1-score': 0.6251745720616597, 'support': 162186}}
[[13405  9100  3170]
 [19360 71766 19473]
 [ 2964  9545 13403]]
Evaluating performance on  val set...
206/206 - 1s - 1s/epoch - 6ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.8340379
{'0': {'precision': 0.3110052595018359, 'recall': 0.47398669086509376, 'f1-score': 0.3755767271855714, 'support': 6612}, '1': {'precision': 0.8237243002229379, 'recall': 0.6784921829171874, 'f1-score': 0.744087826026152, 'support': 39209}, '2': {'precision': 0.31991116261104674, 'recall': 0.4795888824551245, 'f1-score': 0.3838044485634847, 'support': 6908}, 'accuracy': 0.6267898120578809, 'macro avg': {'precision': 0.4848802407786068, 'recall': 0.5440225854124685, 'f1-score': 0.5011563339250693, 'support': 52729}, 'weighted avg': {'precision': 0.6934271306981816, 'recall': 0.6267898120578809, 'f1-score': 0.6506775023513995, 'support': 52729}}
[[ 3134  2749   729]
 [ 6292 26603  6314]
 [  651  2944  3313]]
training model: results/QRTEA/W4/deepOF_L1/h50
Epoch 1/50
634/634 - 11s - loss: 3.1839 - accuracy50: 0.3970 - val_loss: 2.8213 - val_accuracy50: 0.5327 - 11s/epoch - 18ms/step
Epoch 2/50
634/634 - 10s - loss: 3.0949 - accuracy50: 0.4266 - val_loss: 2.7932 - val_accuracy50: 0.5410 - 10s/epoch - 15ms/step
Epoch 3/50
634/634 - 9s - loss: 3.0621 - accuracy50: 0.4408 - val_loss: 2.7697 - val_accuracy50: 0.5637 - 9s/epoch - 15ms/step
Epoch 4/50
634/634 - 9s - loss: 3.0386 - accuracy50: 0.4532 - val_loss: 2.7587 - val_accuracy50: 0.5720 - 9s/epoch - 14ms/step
Epoch 5/50
634/634 - 9s - loss: 3.0179 - accuracy50: 0.4625 - val_loss: 2.7366 - val_accuracy50: 0.5791 - 9s/epoch - 15ms/step
Epoch 6/50
634/634 - 9s - loss: 3.0007 - accuracy50: 0.4691 - val_loss: 2.7253 - val_accuracy50: 0.5764 - 9s/epoch - 14ms/step
Epoch 7/50
634/634 - 9s - loss: 2.9803 - accuracy50: 0.4774 - val_loss: 2.7142 - val_accuracy50: 0.5768 - 9s/epoch - 14ms/step
Epoch 8/50
634/634 - 9s - loss: 2.9687 - accuracy50: 0.4792 - val_loss: 2.7076 - val_accuracy50: 0.5878 - 9s/epoch - 14ms/step
Epoch 9/50
634/634 - 9s - loss: 2.9539 - accuracy50: 0.4837 - val_loss: 2.7063 - val_accuracy50: 0.5861 - 9s/epoch - 14ms/step
Epoch 10/50
634/634 - 9s - loss: 2.9403 - accuracy50: 0.4877 - val_loss: 2.7024 - val_accuracy50: 0.5963 - 9s/epoch - 14ms/step
Epoch 11/50
634/634 - 9s - loss: 2.9288 - accuracy50: 0.4898 - val_loss: 2.6937 - val_accuracy50: 0.5902 - 9s/epoch - 14ms/step
Epoch 12/50
634/634 - 9s - loss: 2.9163 - accuracy50: 0.4937 - val_loss: 2.6921 - val_accuracy50: 0.6032 - 9s/epoch - 14ms/step
Epoch 13/50
634/634 - 9s - loss: 2.9047 - accuracy50: 0.4973 - val_loss: 2.6853 - val_accuracy50: 0.6000 - 9s/epoch - 14ms/step
Epoch 14/50
634/634 - 9s - loss: 2.8949 - accuracy50: 0.5018 - val_loss: 2.6834 - val_accuracy50: 0.5993 - 9s/epoch - 14ms/step
Epoch 15/50
634/634 - 9s - loss: 2.8823 - accuracy50: 0.5043 - val_loss: 2.6950 - val_accuracy50: 0.6013 - 9s/epoch - 14ms/step
Epoch 16/50
634/634 - 9s - loss: 2.8736 - accuracy50: 0.5063 - val_loss: 2.6883 - val_accuracy50: 0.6003 - 9s/epoch - 14ms/step
Epoch 17/50
634/634 - 9s - loss: 2.8660 - accuracy50: 0.5103 - val_loss: 2.6786 - val_accuracy50: 0.6044 - 9s/epoch - 14ms/step
Epoch 18/50
634/634 - 9s - loss: 2.8510 - accuracy50: 0.5139 - val_loss: 2.6813 - val_accuracy50: 0.5883 - 9s/epoch - 14ms/step
Epoch 19/50
634/634 - 9s - loss: 2.8412 - accuracy50: 0.5159 - val_loss: 2.6732 - val_accuracy50: 0.5913 - 9s/epoch - 14ms/step
Epoch 20/50
634/634 - 9s - loss: 2.8295 - accuracy50: 0.5180 - val_loss: 2.6887 - val_accuracy50: 0.5833 - 9s/epoch - 14ms/step
Epoch 21/50
634/634 - 9s - loss: 2.8222 - accuracy50: 0.5194 - val_loss: 2.6955 - val_accuracy50: 0.5868 - 9s/epoch - 14ms/step
Epoch 22/50
634/634 - 9s - loss: 2.8098 - accuracy50: 0.5219 - val_loss: 2.6752 - val_accuracy50: 0.5835 - 9s/epoch - 14ms/step
Epoch 23/50
634/634 - 9s - loss: 2.7984 - accuracy50: 0.5262 - val_loss: 2.6803 - val_accuracy50: 0.6021 - 9s/epoch - 14ms/step
Epoch 24/50
634/634 - 9s - loss: 2.7876 - accuracy50: 0.5298 - val_loss: 2.6900 - val_accuracy50: 0.5932 - 9s/epoch - 14ms/step
Epoch 25/50
634/634 - 9s - loss: 2.7777 - accuracy50: 0.5300 - val_loss: 2.6860 - val_accuracy50: 0.5843 - 9s/epoch - 14ms/step
Epoch 26/50
634/634 - 9s - loss: 2.7673 - accuracy50: 0.5331 - val_loss: 2.6845 - val_accuracy50: 0.5781 - 9s/epoch - 14ms/step
Epoch 27/50
634/634 - 9s - loss: 2.7581 - accuracy50: 0.5342 - val_loss: 2.6862 - val_accuracy50: 0.5752 - 9s/epoch - 14ms/step
Epoch 28/50
634/634 - 9s - loss: 2.7413 - accuracy50: 0.5381 - val_loss: 2.6870 - val_accuracy50: 0.5570 - 9s/epoch - 14ms/step
Epoch 29/50
634/634 - 9s - loss: 2.7396 - accuracy50: 0.5380 - val_loss: 2.6899 - val_accuracy50: 0.5814 - 9s/epoch - 14ms/step
testing model: results/QRTEA/W4/deepOF_L1/h50
Evaluating performance on  test set...
1613/1613 - 13s - 13s/epoch - 8ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.89628166
{'0': {'precision': 0.40663747649665366, 'recall': 0.4317645580577157, 'f1-score': 0.4188244853737812, 'support': 71627}, '1': {'precision': 0.7342421325494175, 'recall': 0.6846299951584671, 'f1-score': 0.7085686973984201, 'support': 268510}, '2': {'precision': 0.3907549898756147, 'recall': 0.46447433569896024, 'f1-score': 0.42443742027109405, 'support': 72708}, 'accuracy': 0.6019862175877145, 'macro avg': {'precision': 0.5105448663072286, 'recall': 0.5269562963050477, 'f1-score': 0.5172768676810985, 'support': 412845}, 'weighted avg': {'precision': 0.6169109262404683, 'recall': 0.6019862175877145, 'f1-score': 0.6082595606229658, 'support': 412845}}
[[ 30926  33183   7518]
 [ 39544 183830  45136]
 [  5583  33354  33771]]
Evaluating performance on  train set...
634/634 - 3s - 3s/epoch - 5ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.92230827
{'0': {'precision': 0.4282929283400937, 'recall': 0.4186568311049639, 'f1-score': 0.4234200627933725, 'support': 32535}, '1': {'precision': 0.6838028244991315, 'recall': 0.6541204396511688, 'f1-score': 0.6686323740400035, 'support': 96895}, '2': {'precision': 0.4011779062980846, 'recall': 0.4616558798388082, 'f1-score': 0.4292973740241306, 'support': 32756}, 'accuracy': 0.5680145018682253, 'macro avg': {'precision': 0.5044245530457699, 'recall': 0.5114777168649803, 'f1-score': 0.5071166036191689, 'support': 162186}, 'weighted avg': {'precision': 0.5754662461746907, 'recall': 0.5680145018682253, 'f1-score': 0.5711045984802816, 'support': 162186}}
[[13621 14694  4220]
 [15162 63381 18352]
 [ 3020 14614 15122]]
Evaluating performance on  val set...
206/206 - 1s - 1s/epoch - 6ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.9002905
{'0': {'precision': 0.3699383802816901, 'recall': 0.39248190520663084, 'f1-score': 0.38087685510365926, 'support': 8566}, '1': {'precision': 0.7369398365932162, 'recall': 0.6758628519527702, 'f1-score': 0.7050811322989459, 'support': 35232}, '2': {'precision': 0.3561655927266308, 'recall': 0.4517971111857575, 'f1-score': 0.39832181638696945, 'support': 8931}, 'accuracy': 0.5918754385632194, 'macro avg': {'precision': 0.487681269867179, 'recall': 0.5067139561150529, 'f1-score': 0.49475993459652484, 'support': 52729}, 'weighted avg': {'precision': 0.612825416696442, 'recall': 0.5918754385632194, 'f1-score': 0.6004555697268378, 'support': 52729}}
[[ 3362  4248   956]
 [ 5082 23812  6338]
 [  644  4252  4035]]
training model: results/QRTEA/W4/deepOF_L1/h100
Epoch 1/50
634/634 - 11s - loss: 3.2611 - accuracy100: 0.3869 - val_loss: 3.0706 - val_accuracy100: 0.4646 - 11s/epoch - 18ms/step
Epoch 2/50
634/634 - 10s - loss: 3.2012 - accuracy100: 0.4135 - val_loss: 3.0409 - val_accuracy100: 0.4839 - 10s/epoch - 15ms/step
Epoch 3/50
634/634 - 9s - loss: 3.1782 - accuracy100: 0.4204 - val_loss: 3.0273 - val_accuracy100: 0.4986 - 9s/epoch - 14ms/step
Epoch 4/50
634/634 - 9s - loss: 3.1619 - accuracy100: 0.4281 - val_loss: 3.0158 - val_accuracy100: 0.5030 - 9s/epoch - 14ms/step
Epoch 5/50
634/634 - 9s - loss: 3.1474 - accuracy100: 0.4356 - val_loss: 3.0055 - val_accuracy100: 0.5091 - 9s/epoch - 14ms/step
Epoch 6/50
634/634 - 9s - loss: 3.1396 - accuracy100: 0.4405 - val_loss: 2.9998 - val_accuracy100: 0.5141 - 9s/epoch - 14ms/step
Epoch 7/50
634/634 - 9s - loss: 3.1259 - accuracy100: 0.4474 - val_loss: 2.9903 - val_accuracy100: 0.5193 - 9s/epoch - 14ms/step
Epoch 8/50
634/634 - 9s - loss: 3.1146 - accuracy100: 0.4525 - val_loss: 2.9889 - val_accuracy100: 0.5213 - 9s/epoch - 14ms/step
Epoch 9/50
634/634 - 9s - loss: 3.1048 - accuracy100: 0.4558 - val_loss: 2.9819 - val_accuracy100: 0.5251 - 9s/epoch - 14ms/step
Epoch 10/50
634/634 - 9s - loss: 3.0962 - accuracy100: 0.4591 - val_loss: 2.9811 - val_accuracy100: 0.5238 - 9s/epoch - 14ms/step
Epoch 11/50
634/634 - 9s - loss: 3.0880 - accuracy100: 0.4632 - val_loss: 2.9779 - val_accuracy100: 0.5252 - 9s/epoch - 14ms/step
Epoch 12/50
634/634 - 9s - loss: 3.0794 - accuracy100: 0.4647 - val_loss: 2.9786 - val_accuracy100: 0.5268 - 9s/epoch - 14ms/step
Epoch 13/50
634/634 - 9s - loss: 3.0713 - accuracy100: 0.4680 - val_loss: 2.9741 - val_accuracy100: 0.5294 - 9s/epoch - 15ms/step
Epoch 14/50
634/634 - 9s - loss: 3.0633 - accuracy100: 0.4704 - val_loss: 2.9759 - val_accuracy100: 0.5284 - 9s/epoch - 14ms/step
Epoch 15/50
634/634 - 9s - loss: 3.0566 - accuracy100: 0.4718 - val_loss: 2.9718 - val_accuracy100: 0.5310 - 9s/epoch - 14ms/step
Epoch 16/50
634/634 - 9s - loss: 3.0493 - accuracy100: 0.4767 - val_loss: 2.9728 - val_accuracy100: 0.5268 - 9s/epoch - 14ms/step
Epoch 17/50
634/634 - 9s - loss: 3.0417 - accuracy100: 0.4782 - val_loss: 2.9686 - val_accuracy100: 0.5278 - 9s/epoch - 14ms/step
Epoch 18/50
634/634 - 9s - loss: 3.0355 - accuracy100: 0.4793 - val_loss: 2.9671 - val_accuracy100: 0.5290 - 9s/epoch - 14ms/step
Epoch 19/50
634/634 - 9s - loss: 3.0283 - accuracy100: 0.4824 - val_loss: 2.9678 - val_accuracy100: 0.5277 - 9s/epoch - 14ms/step
Epoch 20/50
634/634 - 9s - loss: 3.0201 - accuracy100: 0.4838 - val_loss: 2.9715 - val_accuracy100: 0.5282 - 9s/epoch - 14ms/step
Epoch 21/50
634/634 - 9s - loss: 3.0125 - accuracy100: 0.4866 - val_loss: 2.9739 - val_accuracy100: 0.5265 - 9s/epoch - 14ms/step
Epoch 22/50
634/634 - 9s - loss: 3.0053 - accuracy100: 0.4877 - val_loss: 2.9777 - val_accuracy100: 0.5234 - 9s/epoch - 14ms/step
Epoch 23/50
634/634 - 9s - loss: 2.9970 - accuracy100: 0.4893 - val_loss: 2.9707 - val_accuracy100: 0.5228 - 9s/epoch - 14ms/step
Epoch 24/50
634/634 - 9s - loss: 2.9906 - accuracy100: 0.4912 - val_loss: 2.9791 - val_accuracy100: 0.5200 - 9s/epoch - 14ms/step
Epoch 25/50
634/634 - 9s - loss: 2.9799 - accuracy100: 0.4948 - val_loss: 2.9809 - val_accuracy100: 0.5218 - 9s/epoch - 14ms/step
Epoch 26/50
634/634 - 9s - loss: 2.9748 - accuracy100: 0.4945 - val_loss: 2.9926 - val_accuracy100: 0.5214 - 9s/epoch - 14ms/step
Epoch 27/50
634/634 - 9s - loss: 2.9666 - accuracy100: 0.4959 - val_loss: 2.9830 - val_accuracy100: 0.5198 - 9s/epoch - 14ms/step
Epoch 28/50
634/634 - 9s - loss: 2.9593 - accuracy100: 0.4990 - val_loss: 2.9836 - val_accuracy100: 0.5150 - 9s/epoch - 14ms/step
testing model: results/QRTEA/W4/deepOF_L1/h100
Evaluating performance on  test set...
1613/1613 - 10s - 10s/epoch - 6ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 0.9755537
{'0': {'precision': 0.5026819782123831, 'recall': 0.27013025605467783, 'f1-score': 0.3514168266690721, 'support': 100955}, '1': {'precision': 0.5507343102537768, 'recall': 0.8103310197544047, 'f1-score': 0.655776156224623, 'support': 209776}, '2': {'precision': 0.49624526903898913, 'recall': 0.2426797500832403, 'f1-score': 0.3259564225161295, 'support': 102114}, 'accuracy': 0.5378289672879653, 'macro avg': {'precision': 0.5165538525017164, 'recall': 0.4410470086307743, 'f1-score': 0.44438313513660826, 'support': 412845}, 'weighted avg': {'precision': 0.5255063987231886, 'recall': 0.5378289672879653, 'f1-score': 0.49977133988146816, 'support': 412845}}
[[ 27271  67307   6377]
 [ 21009 169988  18779]
 [  5971  71362  24781]]
Evaluating performance on  train set...
634/634 - 3s - 3s/epoch - 5ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0061816
{'0': {'precision': 0.49604598374459985, 'recall': 0.3059570047872821, 'f1-score': 0.3784742590575156, 'support': 44284}, '1': {'precision': 0.5021849115320469, 'recall': 0.7324590609499219, 'f1-score': 0.5958477049615282, 'support': 73585}, '2': {'precision': 0.46690869486295156, 'recall': 0.2902046618679062, 'f1-score': 0.35793604408449525, 'support': 44317}, 'accuracy': 0.49515987816457646, 'macro avg': {'precision': 0.4883798633798661, 'recall': 0.44287357586837, 'f1-score': 0.44408600270117965, 'support': 162186}, 'weighted avg': {'precision': 0.49086955526045994, 'recall': 0.49515987816457646, 'f1-score': 0.4714861894577192, 'support': 162186}}
[[13549 26120  4615]
 [ 9618 53898 10069]
 [ 4147 27309 12861]]
Evaluating performance on  val set...
206/206 - 1s - 1s/epoch - 6ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 0.98418653
{'0': {'precision': 0.45996839610218593, 'recall': 0.28290272940795336, 'f1-score': 0.3503334837771426, 'support': 12347}, '1': {'precision': 0.5674343456472328, 'recall': 0.7501629136195785, 'f1-score': 0.6461279408784047, 'support': 27622}, '2': {'precision': 0.42689719192388026, 'recall': 0.2883228840125392, 'f1-score': 0.34418561137618114, 'support': 12760}, 'accuracy': 0.5289878435016784, 'macro avg': {'precision': 0.4847666445577663, 'recall': 0.4404628423466903, 'f1-score': 0.44688234534390947, 'support': 52729}, 'weighted avg': {'precision': 0.5082612879267626, 'recall': 0.5289878435016784, 'f1-score': 0.5037971876633304, 'support': 52729}}
[[ 3493  7667  1187]
 [ 3149 20721  3752]
 [  952  8129  3679]]
training model: results/QRTEA/W4/deepOF_L1/h200
Epoch 1/50
634/634 - 11s - loss: 3.3001 - accuracy200: 0.3738 - val_loss: 3.2562 - val_accuracy200: 0.3967 - 11s/epoch - 17ms/step
Epoch 2/50
634/634 - 9s - loss: 3.2581 - accuracy200: 0.3979 - val_loss: 3.2405 - val_accuracy200: 0.4074 - 9s/epoch - 14ms/step
Epoch 3/50
634/634 - 9s - loss: 3.2415 - accuracy200: 0.4053 - val_loss: 3.2297 - val_accuracy200: 0.4095 - 9s/epoch - 14ms/step
Epoch 4/50
634/634 - 9s - loss: 3.2295 - accuracy200: 0.4090 - val_loss: 3.2233 - val_accuracy200: 0.4156 - 9s/epoch - 14ms/step
Epoch 5/50
634/634 - 9s - loss: 3.2195 - accuracy200: 0.4140 - val_loss: 3.2206 - val_accuracy200: 0.4162 - 9s/epoch - 14ms/step
Epoch 6/50
634/634 - 9s - loss: 3.2127 - accuracy200: 0.4176 - val_loss: 3.2170 - val_accuracy200: 0.4186 - 9s/epoch - 14ms/step
Epoch 7/50
634/634 - 9s - loss: 3.2053 - accuracy200: 0.4203 - val_loss: 3.2128 - val_accuracy200: 0.4194 - 9s/epoch - 14ms/step
Epoch 8/50
634/634 - 9s - loss: 3.2004 - accuracy200: 0.4226 - val_loss: 3.2140 - val_accuracy200: 0.4206 - 9s/epoch - 14ms/step
Epoch 9/50
634/634 - 9s - loss: 3.1949 - accuracy200: 0.4248 - val_loss: 3.2122 - val_accuracy200: 0.4206 - 9s/epoch - 14ms/step
Epoch 10/50
634/634 - 9s - loss: 3.1901 - accuracy200: 0.4272 - val_loss: 3.2054 - val_accuracy200: 0.4216 - 9s/epoch - 14ms/step
Epoch 11/50
634/634 - 9s - loss: 3.1853 - accuracy200: 0.4297 - val_loss: 3.2093 - val_accuracy200: 0.4217 - 9s/epoch - 14ms/step
Epoch 12/50
634/634 - 9s - loss: 3.1811 - accuracy200: 0.4312 - val_loss: 3.2071 - val_accuracy200: 0.4224 - 9s/epoch - 14ms/step
Epoch 13/50
634/634 - 9s - loss: 3.1774 - accuracy200: 0.4314 - val_loss: 3.2043 - val_accuracy200: 0.4237 - 9s/epoch - 14ms/step
Epoch 14/50
634/634 - 9s - loss: 3.1737 - accuracy200: 0.4340 - val_loss: 3.2045 - val_accuracy200: 0.4221 - 9s/epoch - 14ms/step
Epoch 15/50
634/634 - 9s - loss: 3.1700 - accuracy200: 0.4361 - val_loss: 3.2050 - val_accuracy200: 0.4231 - 9s/epoch - 14ms/step
Epoch 16/50
634/634 - 9s - loss: 3.1666 - accuracy200: 0.4361 - val_loss: 3.2019 - val_accuracy200: 0.4237 - 9s/epoch - 14ms/step
Epoch 17/50
634/634 - 9s - loss: 3.1628 - accuracy200: 0.4382 - val_loss: 3.2033 - val_accuracy200: 0.4256 - 9s/epoch - 14ms/step
Epoch 18/50
634/634 - 9s - loss: 3.1590 - accuracy200: 0.4394 - val_loss: 3.2027 - val_accuracy200: 0.4252 - 9s/epoch - 14ms/step
Epoch 19/50
634/634 - 9s - loss: 3.1562 - accuracy200: 0.4414 - val_loss: 3.2023 - val_accuracy200: 0.4257 - 9s/epoch - 14ms/step
Epoch 20/50
634/634 - 9s - loss: 3.1512 - accuracy200: 0.4431 - val_loss: 3.2008 - val_accuracy200: 0.4260 - 9s/epoch - 14ms/step
Epoch 21/50
634/634 - 9s - loss: 3.1468 - accuracy200: 0.4445 - val_loss: 3.2005 - val_accuracy200: 0.4264 - 9s/epoch - 15ms/step
Epoch 22/50
634/634 - 9s - loss: 3.1446 - accuracy200: 0.4460 - val_loss: 3.2016 - val_accuracy200: 0.4258 - 9s/epoch - 14ms/step
Epoch 23/50
634/634 - 9s - loss: 3.1405 - accuracy200: 0.4476 - val_loss: 3.2009 - val_accuracy200: 0.4268 - 9s/epoch - 14ms/step
Epoch 24/50
634/634 - 9s - loss: 3.1367 - accuracy200: 0.4494 - val_loss: 3.2032 - val_accuracy200: 0.4273 - 9s/epoch - 14ms/step
Epoch 25/50
634/634 - 9s - loss: 3.1313 - accuracy200: 0.4522 - val_loss: 3.2099 - val_accuracy200: 0.4253 - 9s/epoch - 14ms/step
Epoch 26/50
634/634 - 9s - loss: 3.1272 - accuracy200: 0.4531 - val_loss: 3.2076 - val_accuracy200: 0.4279 - 9s/epoch - 14ms/step
Epoch 27/50
634/634 - 9s - loss: 3.1225 - accuracy200: 0.4550 - val_loss: 3.2138 - val_accuracy200: 0.4247 - 9s/epoch - 14ms/step
Epoch 28/50
634/634 - 9s - loss: 3.1197 - accuracy200: 0.4552 - val_loss: 3.2085 - val_accuracy200: 0.4260 - 9s/epoch - 14ms/step
Epoch 29/50
634/634 - 9s - loss: 3.1146 - accuracy200: 0.4585 - val_loss: 3.2101 - val_accuracy200: 0.4270 - 9s/epoch - 14ms/step
Epoch 30/50
634/634 - 9s - loss: 3.1091 - accuracy200: 0.4605 - val_loss: 3.2101 - val_accuracy200: 0.4276 - 9s/epoch - 14ms/step
Epoch 31/50
634/634 - 9s - loss: 3.1033 - accuracy200: 0.4624 - val_loss: 3.2230 - val_accuracy200: 0.4239 - 9s/epoch - 14ms/step
testing model: results/QRTEA/W4/deepOF_L1/h200
Evaluating performance on  test set...
1613/1613 - 9s - 9s/epoch - 6ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0633888
{'0': {'precision': 0.5358140020353312, 'recall': 0.15994204885343968, 'f1-score': 0.24634838369114676, 'support': 128384}, '1': {'precision': 0.3944857378819643, 'recall': 0.8105416359376326, 'f1-score': 0.530688550789354, 'support': 153221}, '2': {'precision': 0.4919098187665405, 'recall': 0.22377323986589454, 'f1-score': 0.3076117355008327, 'support': 131240}, 'accuracy': 0.42169337160435516, 'macro avg': {'precision': 0.47406985289461206, 'recall': 0.39808564155232223, 'f1-score': 0.36154955666044447, 'support': 412845}, 'weighted avg': {'precision': 0.4694054395626378, 'recall': 0.42169337160435516, 'f1-score': 0.3713519250552364, 'support': 412845}}
[[ 20534  95402  12448]
 [ 11143 124192  17886]
 [  6646  95226  29368]]
Evaluating performance on  train set...
634/634 - 4s - 4s/epoch - 6ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0737607
{'0': {'precision': 0.513330947481435, 'recall': 0.2112637160321084, 'f1-score': 0.29933481152993346, 'support': 54316}, '1': {'precision': 0.36339897336838906, 'recall': 0.7515164965231543, 'f1-score': 0.4899031911943772, 'support': 54072}, '2': {'precision': 0.47511602998928953, 'recall': 0.24736979069853898, 'f1-score': 0.3253471543125367, 'support': 53798}, 'accuracy': 0.40335787305932697, 'macro avg': {'precision': 0.4506153169463712, 'recall': 0.4033833344179339, 'f1-score': 0.37152838567894914, 'support': 162186}, 'weighted avg': {'precision': 0.4506682772418147, 'recall': 0.40335787305932697, 'f1-score': 0.37149779379865144, 'support': 162186}}
[[11475 35820  7021]
 [ 5755 40636  7681]
 [ 5124 35366 13308]]
Evaluating performance on  val set...
206/206 - 1s - 1s/epoch - 6ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0671184
{'0': {'precision': 0.48038912909203213, 'recall': 0.19463213213213212, 'f1-score': 0.2770258236865539, 'support': 15984}, '1': {'precision': 0.41039188615123195, 'recall': 0.7654253738734278, 'f1-score': 0.5343081337066612, 'support': 20194}, '2': {'precision': 0.45593200605425543, 'recall': 0.2366020180049544, 'f1-score': 0.3115354017501989, 'support': 16551}, 'accuracy': 0.4264067211591344, 'macro avg': {'precision': 0.44890434043250654, 'recall': 0.39888650800350484, 'f1-score': 0.3742897863811379, 'support': 52729}, 'weighted avg': {'precision': 0.4459049900538414, 'recall': 0.4264067211591344, 'f1-score': 0.3863912012791013, 'support': 52729}}
[[ 3111 10958  1915]
 [ 1979 15457  2758]
 [ 1386 11249  3916]]
training model: results/QRTEA/W4/deepOF_L1/h300
Epoch 1/50
634/634 - 11s - loss: 3.3153 - accuracy300: 0.3577 - val_loss: 3.2946 - val_accuracy300: 0.3653 - 11s/epoch - 17ms/step
Epoch 2/50
634/634 - 9s - loss: 3.2855 - accuracy300: 0.3744 - val_loss: 3.2851 - val_accuracy300: 0.3683 - 9s/epoch - 14ms/step
Epoch 3/50
634/634 - 9s - loss: 3.2721 - accuracy300: 0.3815 - val_loss: 3.2750 - val_accuracy300: 0.3748 - 9s/epoch - 14ms/step
Epoch 4/50
634/634 - 9s - loss: 3.2655 - accuracy300: 0.3848 - val_loss: 3.2693 - val_accuracy300: 0.3785 - 9s/epoch - 14ms/step
Epoch 5/50
634/634 - 9s - loss: 3.2592 - accuracy300: 0.3882 - val_loss: 3.2678 - val_accuracy300: 0.3813 - 9s/epoch - 14ms/step
Epoch 6/50
634/634 - 9s - loss: 3.2566 - accuracy300: 0.3895 - val_loss: 3.2652 - val_accuracy300: 0.3841 - 9s/epoch - 14ms/step
Epoch 7/50
634/634 - 9s - loss: 3.2528 - accuracy300: 0.3909 - val_loss: 3.2625 - val_accuracy300: 0.3845 - 9s/epoch - 14ms/step
Epoch 8/50
634/634 - 9s - loss: 3.2500 - accuracy300: 0.3932 - val_loss: 3.2614 - val_accuracy300: 0.3894 - 9s/epoch - 14ms/step
Epoch 9/50
634/634 - 9s - loss: 3.2475 - accuracy300: 0.3947 - val_loss: 3.2590 - val_accuracy300: 0.3891 - 9s/epoch - 14ms/step
Epoch 10/50
634/634 - 9s - loss: 3.2454 - accuracy300: 0.3961 - val_loss: 3.2593 - val_accuracy300: 0.3891 - 9s/epoch - 14ms/step
Epoch 11/50
634/634 - 9s - loss: 3.2424 - accuracy300: 0.3962 - val_loss: 3.2589 - val_accuracy300: 0.3891 - 9s/epoch - 14ms/step
Epoch 12/50
634/634 - 9s - loss: 3.2416 - accuracy300: 0.3981 - val_loss: 3.2594 - val_accuracy300: 0.3897 - 9s/epoch - 14ms/step
Epoch 13/50
634/634 - 9s - loss: 3.2393 - accuracy300: 0.4001 - val_loss: 3.2557 - val_accuracy300: 0.3930 - 9s/epoch - 14ms/step
Epoch 14/50
634/634 - 9s - loss: 3.2376 - accuracy300: 0.3989 - val_loss: 3.2574 - val_accuracy300: 0.3899 - 9s/epoch - 14ms/step
Epoch 15/50
634/634 - 9s - loss: 3.2357 - accuracy300: 0.4014 - val_loss: 3.2550 - val_accuracy300: 0.3931 - 9s/epoch - 14ms/step
Epoch 16/50
634/634 - 9s - loss: 3.2351 - accuracy300: 0.4010 - val_loss: 3.2546 - val_accuracy300: 0.3925 - 9s/epoch - 14ms/step
Epoch 17/50
634/634 - 9s - loss: 3.2325 - accuracy300: 0.4034 - val_loss: 3.2555 - val_accuracy300: 0.3929 - 9s/epoch - 14ms/step
Epoch 18/50
634/634 - 9s - loss: 3.2312 - accuracy300: 0.4038 - val_loss: 3.2554 - val_accuracy300: 0.3922 - 9s/epoch - 14ms/step
Epoch 19/50
634/634 - 9s - loss: 3.2290 - accuracy300: 0.4045 - val_loss: 3.2542 - val_accuracy300: 0.3948 - 9s/epoch - 14ms/step
Epoch 20/50
634/634 - 9s - loss: 3.2275 - accuracy300: 0.4047 - val_loss: 3.2565 - val_accuracy300: 0.3945 - 9s/epoch - 14ms/step
Epoch 21/50
634/634 - 9s - loss: 3.2255 - accuracy300: 0.4063 - val_loss: 3.2565 - val_accuracy300: 0.3943 - 9s/epoch - 14ms/step
Epoch 22/50
634/634 - 9s - loss: 3.2245 - accuracy300: 0.4070 - val_loss: 3.2568 - val_accuracy300: 0.3935 - 9s/epoch - 14ms/step
Epoch 23/50
634/634 - 9s - loss: 3.2226 - accuracy300: 0.4083 - val_loss: 3.2573 - val_accuracy300: 0.3928 - 9s/epoch - 14ms/step
Epoch 24/50
634/634 - 9s - loss: 3.2192 - accuracy300: 0.4098 - val_loss: 3.2614 - val_accuracy300: 0.3911 - 9s/epoch - 14ms/step
Epoch 25/50
634/634 - 9s - loss: 3.2180 - accuracy300: 0.4092 - val_loss: 3.2595 - val_accuracy300: 0.3926 - 9s/epoch - 14ms/step
Epoch 26/50
634/634 - 9s - loss: 3.2154 - accuracy300: 0.4120 - val_loss: 3.2593 - val_accuracy300: 0.3934 - 9s/epoch - 14ms/step
Epoch 27/50
634/634 - 9s - loss: 3.2135 - accuracy300: 0.4130 - val_loss: 3.2572 - val_accuracy300: 0.3937 - 9s/epoch - 14ms/step
Epoch 28/50
634/634 - 9s - loss: 3.2121 - accuracy300: 0.4136 - val_loss: 3.2609 - val_accuracy300: 0.3923 - 9s/epoch - 14ms/step
Epoch 29/50
634/634 - 9s - loss: 3.2073 - accuracy300: 0.4159 - val_loss: 3.2591 - val_accuracy300: 0.3943 - 9s/epoch - 14ms/step
testing model: results/QRTEA/W4/deepOF_L1/h300
Evaluating performance on  test set...
1613/1613 - 8s - 8s/epoch - 5ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.080276
{'0': {'precision': 0.45796824267224123, 'recall': 0.29907342860462416, 'f1-score': 0.3618456888826413, 'support': 137712}, '1': {'precision': 0.34623500361659143, 'recall': 0.518310532289862, 'f1-score': 0.41514817107635993, 'support': 133912}, '2': {'precision': 0.43704266300797073, 'recall': 0.37894505774636916, 'f1-score': 0.40592561127777627, 'support': 141221}, 'accuracy': 0.39750753914907533, 'macro avg': {'precision': 0.4137486364322678, 'recall': 0.39877633954695174, 'f1-score': 0.3943064904122591, 'support': 412845}, 'weighted avg': {'precision': 0.41456804939343656, 'recall': 0.39750753914907533, 'f1-score': 0.39421341215914607, 'support': 412845}}
[[41186 65092 31434]
 [27005 69408 37499]
 [21741 65965 53515]]
Evaluating performance on  train set...
634/634 - 4s - 4s/epoch - 6ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0841035
{'0': {'precision': 0.4252248875562219, 'recall': 0.332095354836349, 'f1-score': 0.37293393735811065, 'support': 54659}, '1': {'precision': 0.3460308229136377, 'recall': 0.44537594969871624, 'f1-score': 0.38946799980362956, 'support': 53438}, '2': {'precision': 0.4104657123703616, 'recall': 0.3848841723825547, 'f1-score': 0.3972635415573387, 'support': 54089}, 'accuracy': 0.387024774024885, 'macro avg': {'precision': 0.39390714094674045, 'recall': 0.3874518256392066, 'f1-score': 0.38655515957302633, 'support': 162186}, 'weighted avg': {'precision': 0.394209377875988, 'recall': 0.387024774024885, 'f1-score': 0.3864955961356604, 'support': 162186}}
[[18152 22704 13803]
 [13541 23800 16097]
 [10995 22276 20818]]
Evaluating performance on  val set...
206/206 - 1s - 1s/epoch - 6ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0851626
{'0': {'precision': 0.41838986514098897, 'recall': 0.3017033064183415, 'f1-score': 0.3505924251763578, 'support': 16967}, '1': {'precision': 0.36771538022658734, 'recall': 0.4968612334801762, 'f1-score': 0.422642746732868, 'support': 18160}, '2': {'precision': 0.41156931561794935, 'recall': 0.3730826042495171, 'f1-score': 0.39138208474879316, 'support': 17602}, 'accuracy': 0.39274403079899106, 'macro avg': {'precision': 0.3992248536618419, 'recall': 0.390549048049345, 'f1-score': 0.3882057522193397, 'support': 52729}, 'weighted avg': {'precision': 0.3986606087782649, 'recall': 0.39274403079899106, 'f1-score': 0.38902314503184976, 'support': 52729}}
[[5119 7676 4172]
 [3920 9023 5217]
 [3196 7839 6567]]
training model: results/QRTEA/W4/deepOF_L1/h500
Epoch 1/50
634/634 - 12s - loss: 3.3088 - accuracy500: 0.3635 - val_loss: 3.3117 - val_accuracy500: 0.3580 - 12s/epoch - 18ms/step
Epoch 2/50
634/634 - 9s - loss: 3.2891 - accuracy500: 0.3689 - val_loss: 3.3029 - val_accuracy500: 0.3605 - 9s/epoch - 14ms/step
Epoch 3/50
634/634 - 9s - loss: 3.2819 - accuracy500: 0.3742 - val_loss: 3.2983 - val_accuracy500: 0.3639 - 9s/epoch - 15ms/step
Epoch 4/50
634/634 - 9s - loss: 3.2799 - accuracy500: 0.3736 - val_loss: 3.2935 - val_accuracy500: 0.3662 - 9s/epoch - 15ms/step
Epoch 5/50
634/634 - 9s - loss: 3.2782 - accuracy500: 0.3753 - val_loss: 3.2930 - val_accuracy500: 0.3685 - 9s/epoch - 14ms/step
Epoch 6/50
634/634 - 9s - loss: 3.2780 - accuracy500: 0.3750 - val_loss: 3.2889 - val_accuracy500: 0.3681 - 9s/epoch - 14ms/step
Epoch 7/50
634/634 - 9s - loss: 3.2770 - accuracy500: 0.3755 - val_loss: 3.2870 - val_accuracy500: 0.3703 - 9s/epoch - 14ms/step
Epoch 8/50
634/634 - 9s - loss: 3.2769 - accuracy500: 0.3749 - val_loss: 3.2883 - val_accuracy500: 0.3695 - 9s/epoch - 14ms/step
Epoch 9/50
634/634 - 9s - loss: 3.2767 - accuracy500: 0.3747 - val_loss: 3.2861 - val_accuracy500: 0.3712 - 9s/epoch - 14ms/step
Epoch 10/50
634/634 - 9s - loss: 3.2751 - accuracy500: 0.3765 - val_loss: 3.2848 - val_accuracy500: 0.3723 - 9s/epoch - 14ms/step
Epoch 11/50
634/634 - 9s - loss: 3.2732 - accuracy500: 0.3773 - val_loss: 3.2846 - val_accuracy500: 0.3687 - 9s/epoch - 14ms/step
Epoch 12/50
634/634 - 9s - loss: 3.2720 - accuracy500: 0.3780 - val_loss: 3.2834 - val_accuracy500: 0.3718 - 9s/epoch - 14ms/step
Epoch 13/50
634/634 - 9s - loss: 3.2705 - accuracy500: 0.3807 - val_loss: 3.2824 - val_accuracy500: 0.3736 - 9s/epoch - 14ms/step
Epoch 14/50
634/634 - 9s - loss: 3.2693 - accuracy500: 0.3799 - val_loss: 3.2844 - val_accuracy500: 0.3722 - 9s/epoch - 14ms/step
Epoch 15/50
634/634 - 9s - loss: 3.2685 - accuracy500: 0.3808 - val_loss: 3.2829 - val_accuracy500: 0.3713 - 9s/epoch - 14ms/step
Epoch 16/50
634/634 - 9s - loss: 3.2678 - accuracy500: 0.3801 - val_loss: 3.2815 - val_accuracy500: 0.3716 - 9s/epoch - 14ms/step
Epoch 17/50
634/634 - 9s - loss: 3.2668 - accuracy500: 0.3826 - val_loss: 3.2809 - val_accuracy500: 0.3733 - 9s/epoch - 14ms/step
Epoch 18/50
634/634 - 9s - loss: 3.2641 - accuracy500: 0.3843 - val_loss: 3.2822 - val_accuracy500: 0.3732 - 9s/epoch - 14ms/step
Epoch 19/50
634/634 - 9s - loss: 3.2640 - accuracy500: 0.3843 - val_loss: 3.2819 - val_accuracy500: 0.3725 - 9s/epoch - 14ms/step
Epoch 20/50
634/634 - 9s - loss: 3.2626 - accuracy500: 0.3837 - val_loss: 3.2814 - val_accuracy500: 0.3718 - 9s/epoch - 14ms/step
Epoch 21/50
634/634 - 9s - loss: 3.2610 - accuracy500: 0.3861 - val_loss: 3.2830 - val_accuracy500: 0.3712 - 9s/epoch - 14ms/step
Epoch 22/50
634/634 - 9s - loss: 3.2594 - accuracy500: 0.3867 - val_loss: 3.2819 - val_accuracy500: 0.3733 - 9s/epoch - 14ms/step
Epoch 23/50
634/634 - 9s - loss: 3.2577 - accuracy500: 0.3886 - val_loss: 3.2814 - val_accuracy500: 0.3740 - 9s/epoch - 14ms/step
Epoch 24/50
634/634 - 9s - loss: 3.2565 - accuracy500: 0.3895 - val_loss: 3.2835 - val_accuracy500: 0.3720 - 9s/epoch - 14ms/step
Epoch 25/50
634/634 - 9s - loss: 3.2555 - accuracy500: 0.3901 - val_loss: 3.2840 - val_accuracy500: 0.3733 - 9s/epoch - 14ms/step
Epoch 26/50
634/634 - 9s - loss: 3.2543 - accuracy500: 0.3900 - val_loss: 3.2842 - val_accuracy500: 0.3710 - 9s/epoch - 14ms/step
Epoch 27/50
634/634 - 9s - loss: 3.2531 - accuracy500: 0.3911 - val_loss: 3.2832 - val_accuracy500: 0.3740 - 9s/epoch - 14ms/step
testing model: results/QRTEA/W4/deepOF_L1/h500
Evaluating performance on  test set...
1613/1613 - 10s - 10s/epoch - 6ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0903896
{'0': {'precision': 0.38035386304109203, 'recall': 0.4948671540277994, 'f1-score': 0.43011909004879134, 'support': 141442}, '1': {'precision': 0.36387298282144714, 'recall': 0.0054816220582353725, 'f1-score': 0.010800537709173504, 'support': 127517}, '2': {'precision': 0.3840359985544165, 'recall': 0.6055974868993509, 'f1-score': 0.470014887373781, 'support': 143886}, 'accuracy': 0.38230086352020737, 'macro avg': {'precision': 0.37608761480565195, 'recall': 0.36864875432846195, 'f1-score': 0.3036448383772486, 'support': 412845}, 'weighted avg': {'precision': 0.3765466602107362, 'recall': 0.38230086352020737, 'f1-score': 0.314507184503641, 'support': 412845}}
[[69995   611 70836]
 [57893   699 68925]
 [56138   611 87137]]
Evaluating performance on  train set...
634/634 - 4s - 4s/epoch - 6ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0924335
{'0': {'precision': 0.3734957057456862, 'recall': 0.5285566515201892, 'f1-score': 0.43769884973078804, 'support': 54138}, '1': {'precision': 0.4048964218455744, 'recall': 0.015922387617566466, 'f1-score': 0.030639874590280745, 'support': 54012}, '2': {'precision': 0.36613220208992425, 'recall': 0.565419350062921, 'f1-score': 0.44445899159174884, 'support': 54036}, 'accuracy': 0.37011825928255215, 'macro avg': {'precision': 0.3815081098937283, 'recall': 0.36996612973355886, 'f1-score': 0.3042659053042725, 'support': 162186}, 'weighted avg': {'precision': 0.3814996098708537, 'recall': 0.37011825928255215, 'f1-score': 0.30439031299093255, 'support': 162186}}
[[28615   620 24903]
 [25160   860 27992]
 [22839   644 30553]]
Evaluating performance on  val set...
206/206 - 2s - 2s/epoch - 7ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0936397
{'0': {'precision': 0.37112455664510746, 'recall': 0.5077353428098419, 'f1-score': 0.4288124969866448, 'support': 17517}, '1': {'precision': 0.34545454545454546, 'recall': 0.024244533379734354, 'f1-score': 0.04530919733347785, 'support': 17241}, '2': {'precision': 0.3759163823764245, 'recall': 0.5763730454621334, 'f1-score': 0.45504667764964307, 'support': 17971}, 'accuracy': 0.37303950387832124, 'macro avg': {'precision': 0.3641651614920258, 'recall': 0.3694509738839032, 'f1-score': 0.30972279065658853, 'support': 52729}, 'weighted avg': {'precision': 0.3643642774302735, 'recall': 0.37303950387832124, 'f1-score': 0.3123580615028406, 'support': 52729}}
[[ 8894   398  8225]
 [ 7852   418  8971]
 [ 7219   394 10358]]
training model: results/QRTEA/W4/deepOF_L1/h1000
Epoch 1/50
634/634 - 11s - loss: 3.3319 - accuracy1000: 0.3563 - val_loss: 3.2781 - val_accuracy1000: 0.3728 - 11s/epoch - 18ms/step
Epoch 2/50
634/634 - 9s - loss: 3.3121 - accuracy1000: 0.3575 - val_loss: 3.2672 - val_accuracy1000: 0.3767 - 9s/epoch - 14ms/step
Epoch 3/50
634/634 - 9s - loss: 3.3091 - accuracy1000: 0.3485 - val_loss: 3.2638 - val_accuracy1000: 0.3756 - 9s/epoch - 14ms/step
Epoch 4/50
634/634 - 9s - loss: 3.3066 - accuracy1000: 0.3416 - val_loss: 3.2636 - val_accuracy1000: 0.3762 - 9s/epoch - 14ms/step
Epoch 5/50
634/634 - 9s - loss: 3.3023 - accuracy1000: 0.3424 - val_loss: 3.2633 - val_accuracy1000: 0.3777 - 9s/epoch - 14ms/step
Epoch 6/50
634/634 - 9s - loss: 3.3014 - accuracy1000: 0.3407 - val_loss: 3.2640 - val_accuracy1000: 0.3816 - 9s/epoch - 14ms/step
Epoch 7/50
634/634 - 9s - loss: 3.2986 - accuracy1000: 0.3447 - val_loss: 3.2651 - val_accuracy1000: 0.3813 - 9s/epoch - 14ms/step
Epoch 8/50
634/634 - 9s - loss: 3.2972 - accuracy1000: 0.3472 - val_loss: 3.2654 - val_accuracy1000: 0.3824 - 9s/epoch - 14ms/step
Epoch 9/50
634/634 - 9s - loss: 3.2962 - accuracy1000: 0.3477 - val_loss: 3.2658 - val_accuracy1000: 0.3837 - 9s/epoch - 14ms/step
Epoch 10/50
634/634 - 9s - loss: 3.2950 - accuracy1000: 0.3473 - val_loss: 3.2664 - val_accuracy1000: 0.3822 - 9s/epoch - 14ms/step
Epoch 11/50
634/634 - 9s - loss: 3.2941 - accuracy1000: 0.3502 - val_loss: 3.2674 - val_accuracy1000: 0.3807 - 9s/epoch - 14ms/step
Epoch 12/50
634/634 - 9s - loss: 3.2935 - accuracy1000: 0.3500 - val_loss: 3.2675 - val_accuracy1000: 0.3809 - 9s/epoch - 14ms/step
Epoch 13/50
634/634 - 9s - loss: 3.2926 - accuracy1000: 0.3514 - val_loss: 3.2668 - val_accuracy1000: 0.3802 - 9s/epoch - 14ms/step
Epoch 14/50
634/634 - 9s - loss: 3.2913 - accuracy1000: 0.3524 - val_loss: 3.2673 - val_accuracy1000: 0.3827 - 9s/epoch - 14ms/step
Epoch 15/50
634/634 - 9s - loss: 3.2903 - accuracy1000: 0.3544 - val_loss: 3.2659 - val_accuracy1000: 0.3824 - 9s/epoch - 14ms/step
testing model: results/QRTEA/W4/deepOF_L1/h1000
Evaluating performance on  test set...
1613/1613 - 10s - 10s/epoch - 6ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0819907
{'0': {'precision': 0.3964488004707383, 'recall': 0.5550517564491176, 'f1-score': 0.4625317377758795, 'support': 159014}, '1': {'precision': 0.2876557191392978, 'recall': 0.002515100505000495, 'f1-score': 0.0049866009639453045, 'support': 100990}, '2': {'precision': 0.38328236493374107, 'recall': 0.4747940670369861, 'f1-score': 0.4241584690829811, 'support': 152841}, 'accuracy': 0.39017791180709466, 'macro avg': {'precision': 0.3557956281812591, 'recall': 0.34412030799703475, 'f1-score': 0.29722560260760195, 'support': 412845}, 'weighted avg': {'precision': 0.36496147603282, 'recall': 0.39017791180709466, 'f1-score': 0.3364008844848659, 'support': 412845}}
[[88261   304 70449]
 [54420   254 46316]
 [79948   325 72568]]
Evaluating performance on  train set...
634/634 - 4s - 4s/epoch - 6ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1027006
{'0': {'precision': 0.3516497735604917, 'recall': 0.5930317137038115, 'f1-score': 0.4415021796225598, 'support': 54992}, '1': {'precision': 0.3754071661237785, 'recall': 0.008559863339275104, 'f1-score': 0.016738072761600463, 'support': 53856}, '2': {'precision': 0.34735700255064644, 'recall': 0.4442611271513743, 'f1-score': 0.3898779163513113, 'support': 53338}, 'accuracy': 0.3500240464651696, 'macro avg': {'precision': 0.3581379807449722, 'recall': 0.34861756806482025, 'f1-score': 0.28270605624515716, 'support': 162186}, 'weighted avg': {'precision': 0.35812696834774366, 'recall': 0.3500240464651696, 'f1-score': 0.28347602019162443, 'support': 162186}}
[[32612   381 21999]
 [30872   461 22523]
 [29256   386 23696]]
Evaluating performance on  val set...
206/206 - 1s - 1s/epoch - 6ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.087858
{'0': {'precision': 0.3860084859774397, 'recall': 0.5626225551812559, 'f1-score': 0.4578747084577929, 'support': 19889}, '1': {'precision': 0.2613480055020633, 'recall': 0.013788098693759071, 'f1-score': 0.026194251051216654, 'support': 13780}, '2': {'precision': 0.37691739451614303, 'recall': 0.4550891920251836, 'f1-score': 0.4123309485893566, 'support': 19060}, 'accuracy': 0.38032202393369874, 'macro avg': {'precision': 0.34142462866521534, 'recall': 0.34383328196673285, 'f1-score': 0.298799969366122, 'support': 52729}, 'weighted avg': {'precision': 0.3501440162510462, 'recall': 0.38032202393369874, 'f1-score': 0.328598204709286, 'support': 52729}}
[[11190   276  8423]
 [ 7674   190  5916]
 [10125   261  8674]]
training model: results/QRTEA/W4/deepLOB_L2/h10
Epoch 1/50
634/634 - 29s - loss: 3.0444 - accuracy10: 0.4235 - val_loss: 2.5816 - val_accuracy10: 0.6112 - 29s/epoch - 46ms/step
Epoch 2/50
634/634 - 27s - loss: 2.7641 - accuracy10: 0.4857 - val_loss: 2.4813 - val_accuracy10: 0.6058 - 27s/epoch - 42ms/step
Epoch 3/50
634/634 - 26s - loss: 2.6734 - accuracy10: 0.5209 - val_loss: 2.3971 - val_accuracy10: 0.6159 - 26s/epoch - 41ms/step
Epoch 4/50
634/634 - 26s - loss: 2.5950 - accuracy10: 0.5502 - val_loss: 2.3785 - val_accuracy10: 0.6119 - 26s/epoch - 41ms/step
Epoch 5/50
634/634 - 26s - loss: 2.5176 - accuracy10: 0.5825 - val_loss: 2.3425 - val_accuracy10: 0.6120 - 26s/epoch - 41ms/step
Epoch 6/50
634/634 - 26s - loss: 2.4635 - accuracy10: 0.6060 - val_loss: 2.3378 - val_accuracy10: 0.6060 - 26s/epoch - 41ms/step
Epoch 7/50
634/634 - 26s - loss: 2.4125 - accuracy10: 0.6207 - val_loss: 2.3331 - val_accuracy10: 0.6050 - 26s/epoch - 41ms/step
Epoch 8/50
634/634 - 26s - loss: 2.3699 - accuracy10: 0.6384 - val_loss: 2.2937 - val_accuracy10: 0.6047 - 26s/epoch - 41ms/step
Epoch 9/50
634/634 - 26s - loss: 2.3385 - accuracy10: 0.6487 - val_loss: 2.2673 - val_accuracy10: 0.6367 - 26s/epoch - 41ms/step
Epoch 10/50
634/634 - 26s - loss: 2.3084 - accuracy10: 0.6572 - val_loss: 2.2779 - val_accuracy10: 0.6500 - 26s/epoch - 41ms/step
Epoch 11/50
634/634 - 26s - loss: 2.2743 - accuracy10: 0.6651 - val_loss: 2.3080 - val_accuracy10: 0.6118 - 26s/epoch - 41ms/step
Epoch 12/50
634/634 - 26s - loss: 2.2502 - accuracy10: 0.6693 - val_loss: 2.3567 - val_accuracy10: 0.6247 - 26s/epoch - 41ms/step
Epoch 13/50
634/634 - 26s - loss: 2.2257 - accuracy10: 0.6752 - val_loss: 2.3151 - val_accuracy10: 0.6247 - 26s/epoch - 41ms/step
Epoch 14/50
634/634 - 26s - loss: 2.2006 - accuracy10: 0.6787 - val_loss: 2.3046 - val_accuracy10: 0.6276 - 26s/epoch - 41ms/step
Epoch 15/50
634/634 - 26s - loss: 2.1816 - accuracy10: 0.6831 - val_loss: 2.3359 - val_accuracy10: 0.6520 - 26s/epoch - 40ms/step
Epoch 16/50
634/634 - 26s - loss: 2.1638 - accuracy10: 0.6841 - val_loss: 2.3268 - val_accuracy10: 0.6340 - 26s/epoch - 41ms/step
Epoch 17/50
634/634 - 26s - loss: 2.1411 - accuracy10: 0.6867 - val_loss: 2.3590 - val_accuracy10: 0.6408 - 26s/epoch - 40ms/step
Epoch 18/50
634/634 - 26s - loss: 2.1186 - accuracy10: 0.6883 - val_loss: 2.4182 - val_accuracy10: 0.6539 - 26s/epoch - 41ms/step
Epoch 19/50
634/634 - 26s - loss: 2.1028 - accuracy10: 0.6889 - val_loss: 2.3643 - val_accuracy10: 0.6598 - 26s/epoch - 41ms/step
testing model: results/QRTEA/W4/deepLOB_L2/h10
Evaluating performance on  test set...
1613/1613 - 22s - 22s/epoch - 14ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 1.3600327
{'0': {'precision': 0.14321837014979014, 'recall': 0.6607840814876229, 'f1-score': 0.23541326019304817, 'support': 33772}, '1': {'precision': 0.9454220580411368, 'recall': 0.2729596568513796, 'f1-score': 0.42361450010007673, 'support': 345040}, '2': {'precision': 0.15931441059131451, 'recall': 0.7367864382877457, 'f1-score': 0.2619809975502614, 'support': 34037}, 'accuracy': 0.34292441061986345, 'macro avg': {'precision': 0.41598494626074717, 'recall': 0.5568433922089161, 'f1-score': 0.30700291928112877, 'support': 412849}, 'weighted avg': {'precision': 0.8149899413502493, 'recall': 0.34292441061986345, 'f1-score': 0.39489346214085136, 'support': 412849}}
[[ 22316   3244   8212]
 [126736  94182 124122]
 [  6766   2193  25078]]
Evaluating performance on  train set...
634/634 - 9s - 9s/epoch - 14ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.7912755
{'0': {'precision': 0.27410015421770884, 'recall': 0.5888972243060765, 'f1-score': 0.3740841490776959, 'support': 15996}, '1': {'precision': 0.9079389818205109, 'recall': 0.6538665559630066, 'f1-score': 0.7602366885061274, 'support': 130077}, '2': {'precision': 0.28024134497100345, 'recall': 0.5938062434059455, 'f1-score': 0.3807780320366132, 'support': 16113}, 'accuracy': 0.6414918673621645, 'macro avg': {'precision': 0.48742682700307444, 'recall': 0.6121900078916762, 'f1-score': 0.5050329565401455, 'support': 162186}, 'weighted avg': {'precision': 0.7830639746750696, 'recall': 0.6414918673621645, 'f1-score': 0.6844526297563557, 'support': 162186}}
[[ 9420  4286  2290]
 [22740 85053 22284]
 [ 2207  4338  9568]]
Evaluating performance on  val set...
206/206 - 3s - 3s/epoch - 15ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.7825948
{'0': {'precision': 0.2354155350353069, 'recall': 0.5421566174630973, 'f1-score': 0.3282835933949401, 'support': 3997}, '1': {'precision': 0.9276562702213019, 'recall': 0.6431583669807088, 'f1-score': 0.7596439169139467, 'support': 44580}, '2': {'precision': 0.2217642862804153, 'recall': 0.6737298338550446, 'f1-score': 0.33369111508646393, 'support': 4153}, 'accuracy': 0.637910108097857, 'macro avg': {'precision': 0.4616120305123414, 'recall': 0.6196816060996169, 'f1-score': 0.47387287513178356, 'support': 52730}, 'weighted avg': {'precision': 0.8195877015157277, 'recall': 0.637910108097857, 'f1-score': 0.6933983413574324, 'support': 52730}}
[[ 2167  1207   623]
 [ 6712 28672  9196]
 [  326  1029  2798]]
training model: results/QRTEA/W4/deepLOB_L2/h20
Epoch 1/50
634/634 - 29s - loss: 3.0694 - accuracy20: 0.4167 - val_loss: 2.5459 - val_accuracy20: 0.5491 - 29s/epoch - 45ms/step
Epoch 2/50
634/634 - 26s - loss: 2.8282 - accuracy20: 0.4749 - val_loss: 2.5144 - val_accuracy20: 0.5052 - 26s/epoch - 42ms/step
Epoch 3/50
634/634 - 27s - loss: 2.7523 - accuracy20: 0.5093 - val_loss: 2.4744 - val_accuracy20: 0.5903 - 27s/epoch - 42ms/step
Epoch 4/50
634/634 - 26s - loss: 2.6750 - accuracy20: 0.5420 - val_loss: 2.4628 - val_accuracy20: 0.6298 - 26s/epoch - 41ms/step
Epoch 5/50
634/634 - 26s - loss: 2.5991 - accuracy20: 0.5734 - val_loss: 2.4196 - val_accuracy20: 0.6185 - 26s/epoch - 42ms/step
Epoch 6/50
634/634 - 26s - loss: 2.5310 - accuracy20: 0.5966 - val_loss: 2.3925 - val_accuracy20: 0.6323 - 26s/epoch - 41ms/step
Epoch 7/50
634/634 - 26s - loss: 2.4843 - accuracy20: 0.6118 - val_loss: 2.3749 - val_accuracy20: 0.6224 - 26s/epoch - 41ms/step
Epoch 8/50
634/634 - 26s - loss: 2.4434 - accuracy20: 0.6245 - val_loss: 2.3662 - val_accuracy20: 0.6281 - 26s/epoch - 41ms/step
Epoch 9/50
634/634 - 26s - loss: 2.4133 - accuracy20: 0.6292 - val_loss: 2.3547 - val_accuracy20: 0.6215 - 26s/epoch - 41ms/step
Epoch 10/50
634/634 - 26s - loss: 2.3844 - accuracy20: 0.6359 - val_loss: 2.3658 - val_accuracy20: 0.6283 - 26s/epoch - 40ms/step
Epoch 11/50
634/634 - 26s - loss: 2.3625 - accuracy20: 0.6419 - val_loss: 2.4136 - val_accuracy20: 0.6100 - 26s/epoch - 41ms/step
Epoch 12/50
634/634 - 26s - loss: 2.3422 - accuracy20: 0.6452 - val_loss: 2.3583 - val_accuracy20: 0.6232 - 26s/epoch - 41ms/step
Epoch 13/50
634/634 - 26s - loss: 2.3172 - accuracy20: 0.6488 - val_loss: 2.3728 - val_accuracy20: 0.6218 - 26s/epoch - 41ms/step
Epoch 14/50
634/634 - 26s - loss: 2.2946 - accuracy20: 0.6527 - val_loss: 2.3717 - val_accuracy20: 0.6296 - 26s/epoch - 41ms/step
Epoch 15/50
634/634 - 26s - loss: 2.2762 - accuracy20: 0.6553 - val_loss: 2.3444 - val_accuracy20: 0.6262 - 26s/epoch - 41ms/step
Epoch 16/50
634/634 - 26s - loss: 2.2587 - accuracy20: 0.6559 - val_loss: 2.3545 - val_accuracy20: 0.6350 - 26s/epoch - 41ms/step
Epoch 17/50
634/634 - 26s - loss: 2.2385 - accuracy20: 0.6588 - val_loss: 2.3725 - val_accuracy20: 0.6036 - 26s/epoch - 41ms/step
Epoch 18/50
634/634 - 26s - loss: 2.2157 - accuracy20: 0.6606 - val_loss: 2.3405 - val_accuracy20: 0.6244 - 26s/epoch - 41ms/step
Epoch 19/50
634/634 - 26s - loss: 2.2010 - accuracy20: 0.6605 - val_loss: 2.3488 - val_accuracy20: 0.6640 - 26s/epoch - 41ms/step
Epoch 20/50
634/634 - 26s - loss: 2.1843 - accuracy20: 0.6621 - val_loss: 2.3830 - val_accuracy20: 0.6335 - 26s/epoch - 41ms/step
Epoch 21/50
634/634 - 26s - loss: 2.1693 - accuracy20: 0.6646 - val_loss: 2.4167 - val_accuracy20: 0.6134 - 26s/epoch - 41ms/step
Epoch 22/50
634/634 - 26s - loss: 2.1537 - accuracy20: 0.6665 - val_loss: 2.4237 - val_accuracy20: 0.6236 - 26s/epoch - 41ms/step
Epoch 23/50
634/634 - 26s - loss: 2.1369 - accuracy20: 0.6658 - val_loss: 2.4435 - val_accuracy20: 0.6156 - 26s/epoch - 41ms/step
Epoch 24/50
634/634 - 26s - loss: 2.1164 - accuracy20: 0.6677 - val_loss: 2.4338 - val_accuracy20: 0.6346 - 26s/epoch - 41ms/step
Epoch 25/50
634/634 - 26s - loss: 2.1054 - accuracy20: 0.6675 - val_loss: 2.4383 - val_accuracy20: 0.6065 - 26s/epoch - 41ms/step
Epoch 26/50
634/634 - 26s - loss: 2.0905 - accuracy20: 0.6688 - val_loss: 2.5294 - val_accuracy20: 0.6186 - 26s/epoch - 41ms/step
Epoch 27/50
634/634 - 26s - loss: 2.0768 - accuracy20: 0.6706 - val_loss: 2.4758 - val_accuracy20: 0.6115 - 26s/epoch - 41ms/step
Epoch 28/50
634/634 - 26s - loss: 2.0572 - accuracy20: 0.6698 - val_loss: 2.5544 - val_accuracy20: 0.5975 - 26s/epoch - 41ms/step
testing model: results/QRTEA/W4/deepLOB_L2/h20
Evaluating performance on  test set...
1613/1613 - 22s - 22s/epoch - 14ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.9821398
{'0': {'precision': 0.23102179151110758, 'recall': 0.5641771742644681, 'f1-score': 0.3278103396453261, 'support': 46395}, '1': {'precision': 0.8795172066958833, 'recall': 0.5365852131306649, 'f1-score': 0.6665279589943823, 'support': 319405}, '2': {'precision': 0.2631397948071302, 'recall': 0.5854747178473506, 'f1-score': 0.3630899420685291, 'support': 47049}, 'accuracy': 0.5452574670157855, 'macro avg': {'precision': 0.457892931004707, 'recall': 0.5620790350808278, 'f1-score': 0.4524760802360792, 'support': 412849}, 'weighted avg': {'precision': 0.7363973598767033, 'recall': 0.5452574670157855, 'f1-score': 0.5938833378180105, 'support': 412849}}
[[ 26175  10485   9735]
 [ 80616 171388  67401]
 [  6510  12993  27546]]
Evaluating performance on  train set...
634/634 - 9s - 9s/epoch - 14ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.8524389
{'0': {'precision': 0.2964062964062964, 'recall': 0.6507988262145419, 'f1-score': 0.40730537700234676, 'support': 21469}, '1': {'precision': 0.8667625828506782, 'recall': 0.5923292828450898, 'f1-score': 0.7037375386258917, 'support': 118998}, '2': {'precision': 0.3444124885106888, 'recall': 0.5348312537409642, 'f1-score': 0.4190022724813332, 'support': 21719}, 'accuracy': 0.5923692550528405, 'macro avg': {'precision': 0.502527122589221, 'recall': 0.592653120933532, 'f1-score': 0.5100150627031905, 'support': 162186}, 'weighted avg': {'precision': 0.7213129089414342, 'recall': 0.5923692550528405, 'f1-score': 0.6263679301313883, 'support': 162186}}
[[13972  4756  2741]
 [29142 70486 19370]
 [ 4024  6079 11616]]
Evaluating performance on  val set...
206/206 - 3s - 3s/epoch - 15ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.8041953
{'0': {'precision': 0.29342540361797315, 'recall': 0.5542899136505604, 'f1-score': 0.3837201907790143, 'support': 5443}, '1': {'precision': 0.8996642785449763, 'recall': 0.625517374145731, 'f1-score': 0.7379522775341026, 'support': 41556}, '2': {'precision': 0.2848395426042051, 'recall': 0.6737044145873321, 'f1-score': 0.40039406823602613, 'support': 5731}, 'accuracy': 0.6234022378152854, 'macro avg': {'precision': 0.4926430749223849, 'recall': 0.6178372341278745, 'f1-score': 0.5073555121830476, 'support': 52730}, 'weighted avg': {'precision': 0.7702632021576401, 'recall': 0.6234022378152854, 'f1-score': 0.6646992650991468, 'support': 52730}}
[[ 3017  1523   903]
 [ 6771 25994  8791]
 [  494  1376  3861]]
training model: results/QRTEA/W4/deepLOB_L2/h30
Epoch 1/50
634/634 - 29s - loss: 3.1013 - accuracy30: 0.4262 - val_loss: 2.6630 - val_accuracy30: 0.5770 - 29s/epoch - 45ms/step
Epoch 2/50
634/634 - 26s - loss: 2.8766 - accuracy30: 0.4708 - val_loss: 2.5760 - val_accuracy30: 0.6090 - 26s/epoch - 41ms/step
Epoch 3/50
634/634 - 26s - loss: 2.7971 - accuracy30: 0.5155 - val_loss: 2.5764 - val_accuracy30: 0.5337 - 26s/epoch - 41ms/step
Epoch 4/50
634/634 - 26s - loss: 2.7513 - accuracy30: 0.5325 - val_loss: 2.5994 - val_accuracy30: 0.6108 - 26s/epoch - 41ms/step
Epoch 5/50
634/634 - 26s - loss: 2.7104 - accuracy30: 0.5505 - val_loss: 2.6130 - val_accuracy30: 0.5369 - 26s/epoch - 41ms/step
Epoch 6/50
634/634 - 26s - loss: 2.6677 - accuracy30: 0.5633 - val_loss: 2.6262 - val_accuracy30: 0.5589 - 26s/epoch - 41ms/step
Epoch 7/50
634/634 - 26s - loss: 2.6285 - accuracy30: 0.5744 - val_loss: 2.5909 - val_accuracy30: 0.5406 - 26s/epoch - 41ms/step
Epoch 8/50
634/634 - 26s - loss: 2.5870 - accuracy30: 0.5881 - val_loss: 2.5796 - val_accuracy30: 0.5503 - 26s/epoch - 41ms/step
Epoch 9/50
634/634 - 26s - loss: 2.5562 - accuracy30: 0.5941 - val_loss: 2.6075 - val_accuracy30: 0.4951 - 26s/epoch - 42ms/step
Epoch 10/50
634/634 - 26s - loss: 2.5249 - accuracy30: 0.6026 - val_loss: 2.6136 - val_accuracy30: 0.4898 - 26s/epoch - 41ms/step
Epoch 11/50
634/634 - 26s - loss: 2.4984 - accuracy30: 0.6084 - val_loss: 2.5991 - val_accuracy30: 0.4936 - 26s/epoch - 41ms/step
Epoch 12/50
634/634 - 26s - loss: 2.4709 - accuracy30: 0.6127 - val_loss: 2.6176 - val_accuracy30: 0.5247 - 26s/epoch - 41ms/step
testing model: results/QRTEA/W4/deepLOB_L2/h30
Evaluating performance on  test set...
1613/1613 - 22s - 22s/epoch - 14ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.046647
{'0': {'precision': 0.20863127653864974, 'recall': 0.7119438359607857, 'f1-score': 0.322697733848226, 'support': 55694}, '1': {'precision': 0.8234957249021122, 'recall': 0.4115710895820922, 'f1-score': 0.5488399960057252, 'support': 300473}, '2': {'precision': 0.3009886538885217, 'recall': 0.3856427084435976, 'f1-score': 0.3380972267334849, 'support': 56682}, 'accuracy': 0.44853202987048535, 'macro avg': {'precision': 0.44437188510976117, 'recall': 0.5030525446621585, 'f1-score': 0.403211652195812, 'support': 412849}, 'weighted avg': {'precision': 0.6688120357413125, 'recall': 0.44853202987048535, 'f1-score': 0.48939916219847635, 'support': 412849}}
[[ 39651  11310   4733]
 [130775 123666  46032]
 [ 19627  15196  21859]]
Evaluating performance on  train set...
634/634 - 9s - 9s/epoch - 14ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.89981663
{'0': {'precision': 0.30762756204645236, 'recall': 0.5273769596755323, 'f1-score': 0.3885863708854758, 'support': 25642}, '1': {'precision': 0.7537783973891828, 'recall': 0.6451933681679293, 'f1-score': 0.6952718204002903, 'support': 110618}, '2': {'precision': 0.34161569826707444, 'recall': 0.3102291136311039, 'f1-score': 0.32516676773802305, 'support': 25926}, 'accuracy': 0.5730210992317463, 'macro avg': {'precision': 0.46767388590090314, 'recall': 0.49426648049152183, 'f1-score': 0.46967498634126303, 'support': 162186}, 'weighted avg': {'precision': 0.6173552174766251, 'recall': 0.5730210992317463, 'f1-score': 0.5876215183287131, 'support': 162186}}
[[13523 10372  1747]
 [25494 71370 13754]
 [ 4942 12941  8043]]
Evaluating performance on  val set...
206/206 - 3s - 3s/epoch - 14ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.8479785
{'0': {'precision': 0.2933420609687675, 'recall': 0.4765304572383412, 'f1-score': 0.36314174914626385, 'support': 6583}, '1': {'precision': 0.8132423553196866, 'recall': 0.6561488466930037, 'f1-score': 0.7262981196484743, 'support': 39235}, '2': {'precision': 0.3083815028901734, 'recall': 0.4631076388888889, 'f1-score': 0.37022900763358774, 'support': 6912}, 'accuracy': 0.6084202541247866, 'macro avg': {'precision': 0.47165530639287584, 'recall': 0.5319289809400779, 'f1-score': 0.4865562921427753, 'support': 52730}, 'weighted avg': {'precision': 0.6821575487635535, 'recall': 0.6084202541247866, 'f1-score': 0.6342858289361104, 'support': 52730}}
[[ 3137  2826   620]
 [ 6932 25744  6559]
 [  625  3086  3201]]
training model: results/QRTEA/W4/deepLOB_L2/h50
Epoch 1/50
634/634 - 28s - loss: 3.1446 - accuracy50: 0.4315 - val_loss: 2.8280 - val_accuracy50: 0.5019 - 28s/epoch - 45ms/step
Epoch 2/50
634/634 - 26s - loss: 2.9626 - accuracy50: 0.4741 - val_loss: 2.8127 - val_accuracy50: 0.4768 - 26s/epoch - 42ms/step
Epoch 3/50
634/634 - 27s - loss: 2.9070 - accuracy50: 0.4978 - val_loss: 2.7881 - val_accuracy50: 0.5233 - 27s/epoch - 43ms/step
Epoch 4/50
634/634 - 27s - loss: 2.8679 - accuracy50: 0.5166 - val_loss: 2.7700 - val_accuracy50: 0.5150 - 27s/epoch - 42ms/step
Epoch 5/50
634/634 - 26s - loss: 2.8283 - accuracy50: 0.5306 - val_loss: 2.7922 - val_accuracy50: 0.5381 - 26s/epoch - 41ms/step
Epoch 6/50
634/634 - 26s - loss: 2.8029 - accuracy50: 0.5378 - val_loss: 2.7710 - val_accuracy50: 0.5713 - 26s/epoch - 41ms/step
Epoch 7/50
634/634 - 26s - loss: 2.7711 - accuracy50: 0.5457 - val_loss: 2.7690 - val_accuracy50: 0.5713 - 26s/epoch - 41ms/step
Epoch 8/50
634/634 - 26s - loss: 2.7298 - accuracy50: 0.5570 - val_loss: 2.7738 - val_accuracy50: 0.5168 - 26s/epoch - 41ms/step
Epoch 9/50
634/634 - 26s - loss: 2.7046 - accuracy50: 0.5648 - val_loss: 2.8227 - val_accuracy50: 0.4947 - 26s/epoch - 41ms/step
Epoch 10/50
634/634 - 26s - loss: 2.6782 - accuracy50: 0.5730 - val_loss: 2.8186 - val_accuracy50: 0.5338 - 26s/epoch - 41ms/step
Epoch 11/50
634/634 - 26s - loss: 2.6522 - accuracy50: 0.5783 - val_loss: 2.8071 - val_accuracy50: 0.5254 - 26s/epoch - 41ms/step
Epoch 12/50
634/634 - 26s - loss: 2.6272 - accuracy50: 0.5830 - val_loss: 2.8401 - val_accuracy50: 0.5138 - 26s/epoch - 41ms/step
Epoch 13/50
634/634 - 26s - loss: 2.6060 - accuracy50: 0.5887 - val_loss: 2.8446 - val_accuracy50: 0.4769 - 26s/epoch - 41ms/step
Epoch 14/50
634/634 - 26s - loss: 2.5808 - accuracy50: 0.5940 - val_loss: 2.8646 - val_accuracy50: 0.4946 - 26s/epoch - 41ms/step
Epoch 15/50
634/634 - 26s - loss: 2.5589 - accuracy50: 0.5954 - val_loss: 3.0087 - val_accuracy50: 0.4399 - 26s/epoch - 41ms/step
Epoch 16/50
634/634 - 26s - loss: 2.5409 - accuracy50: 0.5973 - val_loss: 2.9537 - val_accuracy50: 0.4776 - 26s/epoch - 41ms/step
Epoch 17/50
634/634 - 26s - loss: 2.5198 - accuracy50: 0.6012 - val_loss: 2.9677 - val_accuracy50: 0.4509 - 26s/epoch - 41ms/step
testing model: results/QRTEA/W4/deepLOB_L2/h50
Evaluating performance on  test set...
1613/1613 - 22s - 22s/epoch - 14ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.3696059
{'0': {'precision': 0.22617833446019503, 'recall': 0.8266575453390481, 'f1-score': 0.3551779158768625, 'support': 71627}, '1': {'precision': 0.7429958727846565, 'recall': 0.17096442617089738, 'f1-score': 0.277968010608634, 'support': 268512}, '2': {'precision': 0.30873144777373285, 'recall': 0.3790675285380278, 'f1-score': 0.34030311448590916, 'support': 72710}, 'accuracy': 0.32137415859067114, 'macro avg': {'precision': 0.42596855167286146, 'recall': 0.4588965000159911, 'f1-score': 0.3244830136571352, 'support': 412849}, 'weighted avg': {'precision': 0.576849276425914, 'recall': 0.32137415859067114, 'f1-score': 0.30234181141126176, 'support': 412849}}
[[ 59211   4998   7418]
 [168311  45906  54295]
 [ 34267  10881  27562]]
Evaluating performance on  train set...
634/634 - 9s - 9s/epoch - 14ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.96426904
{'0': {'precision': 0.3614184775363285, 'recall': 0.5837819546559203, 'f1-score': 0.4464441150869269, 'support': 32507}, '1': {'precision': 0.7067695946891175, 'recall': 0.5733770789484545, 'f1-score': 0.6331235225427929, 'support': 96924}, '2': {'precision': 0.38801211028085547, 'recall': 0.36779117691955426, 'f1-score': 0.37763114587088387, 'support': 32755}, 'accuracy': 0.5339425104509637, 'macro avg': {'precision': 0.48540006083543386, 'recall': 0.5083167368413097, 'f1-score': 0.48573292783353456, 'support': 162186}, 'weighted avg': {'precision': 0.5731746471160944, 'recall': 0.5339425104509637, 'f1-score': 0.5441081926372757, 'support': 162186}}
[[18977 10354  3176]
 [25525 55574 15825]
 [ 8005 12703 12047]]
Evaluating performance on  val set...
206/206 - 3s - 3s/epoch - 14ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.9092765
{'0': {'precision': 0.3460424259415008, 'recall': 0.4332007487131493, 'f1-score': 0.3847472595979012, 'support': 8548}, '1': {'precision': 0.7473911721995204, 'recall': 0.6274204065432484, 'f1-score': 0.6821712594784539, 'support': 35273}, '2': {'precision': 0.3398292800773071, 'recall': 0.47367830283982487, 'f1-score': 0.39574248605054624, 'support': 8909}, 'accuracy': 0.5699601744737341, 'macro avg': {'precision': 0.47775429273944275, 'recall': 0.5114331526987409, 'f1-score': 0.4875536683756338, 'support': 52730}, 'weighted avg': {'precision': 0.613469344398831, 'recall': 0.5699601744737341, 'f1-score': 0.5855626060847844, 'support': 52730}}
[[ 3703  3763  1082]
 [ 6026 22131  7116]
 [  972  3717  4220]]
training model: results/QRTEA/W4/deepLOB_L2/h100
Epoch 1/50
634/634 - 29s - loss: 3.2590 - accuracy100: 0.4065 - val_loss: 3.1649 - val_accuracy100: 0.3951 - 29s/epoch - 45ms/step
Epoch 2/50
634/634 - 26s - loss: 3.1166 - accuracy100: 0.4563 - val_loss: 3.0629 - val_accuracy100: 0.4299 - 26s/epoch - 42ms/step
Epoch 3/50
634/634 - 26s - loss: 3.0493 - accuracy100: 0.4773 - val_loss: 3.0556 - val_accuracy100: 0.4293 - 26s/epoch - 41ms/step
Epoch 4/50
634/634 - 26s - loss: 3.0211 - accuracy100: 0.4853 - val_loss: 3.0701 - val_accuracy100: 0.4452 - 26s/epoch - 41ms/step
Epoch 5/50
634/634 - 27s - loss: 2.9955 - accuracy100: 0.4935 - val_loss: 3.1043 - val_accuracy100: 0.4245 - 27s/epoch - 42ms/step
Epoch 6/50
634/634 - 26s - loss: 2.9687 - accuracy100: 0.5018 - val_loss: 3.1065 - val_accuracy100: 0.4596 - 26s/epoch - 42ms/step
Epoch 7/50
634/634 - 26s - loss: 2.9402 - accuracy100: 0.5089 - val_loss: 3.1278 - val_accuracy100: 0.4533 - 26s/epoch - 42ms/step
Epoch 8/50
634/634 - 26s - loss: 2.9162 - accuracy100: 0.5161 - val_loss: 3.1554 - val_accuracy100: 0.4635 - 26s/epoch - 41ms/step
Epoch 9/50
634/634 - 26s - loss: 2.9003 - accuracy100: 0.5190 - val_loss: 3.1933 - val_accuracy100: 0.4590 - 26s/epoch - 41ms/step
Epoch 10/50
634/634 - 26s - loss: 2.8830 - accuracy100: 0.5238 - val_loss: 3.2203 - val_accuracy100: 0.4619 - 26s/epoch - 41ms/step
Epoch 11/50
634/634 - 26s - loss: 2.8600 - accuracy100: 0.5300 - val_loss: 3.2332 - val_accuracy100: 0.4488 - 26s/epoch - 41ms/step
Epoch 12/50
634/634 - 26s - loss: 2.8468 - accuracy100: 0.5336 - val_loss: 3.2326 - val_accuracy100: 0.4808 - 26s/epoch - 41ms/step
Epoch 13/50
634/634 - 26s - loss: 2.8257 - accuracy100: 0.5386 - val_loss: 3.1962 - val_accuracy100: 0.4523 - 26s/epoch - 41ms/step
testing model: results/QRTEA/W4/deepLOB_L2/h100
Evaluating performance on  test set...
1613/1613 - 22s - 22s/epoch - 14ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.1207422
{'0': {'precision': 0.2955282791006905, 'recall': 0.6956694005309244, 'f1-score': 0.41483144076431244, 'support': 100956}, '1': {'precision': 0.6023806316923699, 'recall': 0.17055811913660285, 'f1-score': 0.2658448872839671, 'support': 209776}, '2': {'precision': 0.35891679043901764, 'recall': 0.40702331639198175, 'f1-score': 0.3814593361814602, 'support': 102117}, 'accuracy': 0.35745514703923226, 'macro avg': {'precision': 0.4189419004106927, 'recall': 0.4244169453531697, 'f1-score': 0.35404522140991324, 'support': 412849}, 'weighted avg': {'precision': 0.46712444072299814, 'recall': 0.35745514703923226, 'f1-score': 0.33087420107963345, 'support': 412849}}
[[ 70232  11998  18726]
 [118483  35779  55514]
 [ 48934  11619  41564]]
Evaluating performance on  train set...
634/634 - 9s - 9s/epoch - 14ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0632108
{'0': {'precision': 0.3755412023564483, 'recall': 0.5974210740255634, 'f1-score': 0.4611817619217795, 'support': 44282}, '1': {'precision': 0.6112778790854257, 'recall': 0.2961065434531494, 'f1-score': 0.39895633067838504, 'support': 73585}, '2': {'precision': 0.36863590986879635, 'recall': 0.4665944628714547, 'f1-score': 0.4118707364437584, 'support': 44319}, 'accuracy': 0.4249626971501856, 'macro avg': {'precision': 0.4518183304368901, 'recall': 0.4533740267833892, 'f1-score': 0.424002943014641, 'support': 162186}, 'weighted avg': {'precision': 0.48060975142567475, 'recall': 0.4249626971501856, 'f1-score': 0.41947487170803976, 'support': 162186}}
[[26455  6952 10875]
 [27254 21789 24542]
 [16736  6904 20679]]
Evaluating performance on  val set...
206/206 - 3s - 3s/epoch - 14ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0571867
{'0': {'precision': 0.3548704493276484, 'recall': 0.4382696046662346, 'f1-score': 0.392185291239262, 'support': 12344}, '1': {'precision': 0.5995021995832368, 'recall': 0.374764799536836, 'f1-score': 0.46121303883149267, 'support': 27636}, '2': {'precision': 0.3384630610124202, 'recall': 0.5364705882352941, 'f1-score': 0.4150611365636093, 'support': 12750}, 'accuracy': 0.4287312725203869, 'macro avg': {'precision': 0.4309452366411018, 'recall': 0.44983499747945493, 'f1-score': 0.4228198222114547, 'support': 52730}, 'weighted avg': {'precision': 0.4791156389548868, 'recall': 0.4287312725203869, 'f1-score': 0.4338943346745799, 'support': 52730}}
[[ 5410  3443  3491]
 [ 7401 10357  9878]
 [ 2434  3476  6840]]
training model: results/QRTEA/W4/deepLOB_L2/h200
Epoch 1/50
634/634 - 28s - loss: 3.2841 - accuracy200: 0.3887 - val_loss: 3.2779 - val_accuracy200: 0.3852 - 28s/epoch - 44ms/step
Epoch 2/50
634/634 - 26s - loss: 3.2216 - accuracy200: 0.4138 - val_loss: 3.2838 - val_accuracy200: 0.3866 - 26s/epoch - 41ms/step
Epoch 3/50
634/634 - 26s - loss: 3.1805 - accuracy200: 0.4347 - val_loss: 3.3945 - val_accuracy200: 0.3977 - 26s/epoch - 41ms/step
Epoch 4/50
634/634 - 26s - loss: 3.1555 - accuracy200: 0.4447 - val_loss: 3.2809 - val_accuracy200: 0.4123 - 26s/epoch - 41ms/step
Epoch 5/50
634/634 - 26s - loss: 3.1236 - accuracy200: 0.4530 - val_loss: 3.2757 - val_accuracy200: 0.4083 - 26s/epoch - 41ms/step
Epoch 6/50
634/634 - 26s - loss: 3.0876 - accuracy200: 0.4679 - val_loss: 3.3261 - val_accuracy200: 0.4047 - 26s/epoch - 41ms/step
Epoch 7/50
634/634 - 26s - loss: 3.0659 - accuracy200: 0.4715 - val_loss: 3.4530 - val_accuracy200: 0.3691 - 26s/epoch - 41ms/step
Epoch 8/50
634/634 - 26s - loss: 3.0410 - accuracy200: 0.4784 - val_loss: 3.3787 - val_accuracy200: 0.3892 - 26s/epoch - 41ms/step
Epoch 9/50
634/634 - 26s - loss: 3.0159 - accuracy200: 0.4884 - val_loss: 3.3879 - val_accuracy200: 0.3987 - 26s/epoch - 41ms/step
Epoch 10/50
634/634 - 26s - loss: 2.9905 - accuracy200: 0.4951 - val_loss: 3.4042 - val_accuracy200: 0.3855 - 26s/epoch - 40ms/step
Epoch 11/50
634/634 - 26s - loss: 2.9636 - accuracy200: 0.5034 - val_loss: 3.4743 - val_accuracy200: 0.3848 - 26s/epoch - 41ms/step
Epoch 12/50
634/634 - 26s - loss: 2.9343 - accuracy200: 0.5120 - val_loss: 3.4824 - val_accuracy200: 0.3809 - 26s/epoch - 41ms/step
Epoch 13/50
634/634 - 26s - loss: 2.9063 - accuracy200: 0.5203 - val_loss: 3.5735 - val_accuracy200: 0.3727 - 26s/epoch - 41ms/step
Epoch 14/50
634/634 - 26s - loss: 2.8745 - accuracy200: 0.5257 - val_loss: 3.6149 - val_accuracy200: 0.3839 - 26s/epoch - 41ms/step
Epoch 15/50
634/634 - 26s - loss: 2.8441 - accuracy200: 0.5361 - val_loss: 3.6245 - val_accuracy200: 0.3818 - 26s/epoch - 41ms/step
testing model: results/QRTEA/W4/deepLOB_L2/h200
Evaluating performance on  test set...
1613/1613 - 23s - 23s/epoch - 14ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1060122
{'0': {'precision': 0.34756687077022236, 'recall': 0.6048323025875095, 'f1-score': 0.44145286268980843, 'support': 128386}, '1': {'precision': 0.421768837133954, 'recall': 0.28886191278014905, 'f1-score': 0.3428868031964549, 'support': 153222}, '2': {'precision': 0.43603096077828013, 'recall': 0.28072020176621637, 'f1-score': 0.34154865923470934, 'support': 131241}, 'accuracy': 0.3845328437273676, 'macro avg': {'precision': 0.4017888895608188, 'recall': 0.3914714723779584, 'f1-score': 0.3752961083736575, 'support': 412849}, 'weighted avg': {'precision': 0.4032276313072013, 'recall': 0.3845328437273676, 'f1-score': 0.37311306694525953, 'support': 412849}}
[[77652 31268 19466]
 [80776 44260 28186]
 [64988 29411 36842]]
Evaluating performance on  train set...
634/634 - 9s - 9s/epoch - 14ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0883
{'0': {'precision': 0.4333731144718565, 'recall': 0.40774214924713764, 'f1-score': 0.4201671108413395, 'support': 54326}, '1': {'precision': 0.39374181341871634, 'recall': 0.5006662225183212, 'f1-score': 0.44081273524188164, 'support': 54036}, '2': {'precision': 0.431909921393669, 'recall': 0.33994129013079666, 'f1-score': 0.380446422073669, 'support': 53824}, 'accuracy': 0.416201151764024, 'macro avg': {'precision': 0.4196749497614139, 'recall': 0.4161165539654184, 'f1-score': 0.4138087560522967, 'support': 162186}, 'weighted avg': {'precision': 0.41968345021015796, 'recall': 0.416201151764024, 'f1-score': 0.4138637345195645, 'support': 162186}}
[[22151 20957 11218]
 [14134 27054 12848]
 [14828 20699 18297]]
Evaluating performance on  val set...
206/206 - 3s - 3s/epoch - 15ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0933707
{'0': {'precision': 0.39446439890133106, 'recall': 0.35021571937722756, 'f1-score': 0.3710254372019078, 'support': 15993}, '1': {'precision': 0.405850228173861, 'recall': 0.5375811326363772, 'f1-score': 0.4625189163842531, 'support': 20183}, '2': {'precision': 0.4264643553445791, 'recall': 0.30391446176150777, 'f1-score': 0.35490811611583367, 'support': 16554}, 'accuracy': 0.40739616916366395, 'macro avg': {'precision': 0.4089263274732571, 'recall': 0.3972371045917042, 'f1-score': 0.39615082323399814, 'support': 52730}, 'weighted avg': {'precision': 0.40886848521214086, 'recall': 0.40739616916366395, 'f1-score': 0.4009857398205007, 'support': 52730}}
[[ 5601  7827  2565]
 [ 5132 10850  4201]
 [ 3466  8057  5031]]
training model: results/QRTEA/W4/deepLOB_L2/h300
Epoch 1/50
634/634 - 29s - loss: 3.2965 - accuracy300: 0.3809 - val_loss: 3.3229 - val_accuracy300: 0.3442 - 29s/epoch - 45ms/step
Epoch 2/50
634/634 - 26s - loss: 3.2648 - accuracy300: 0.3888 - val_loss: 3.3440 - val_accuracy300: 0.3606 - 26s/epoch - 41ms/step
Epoch 3/50
634/634 - 26s - loss: 3.2437 - accuracy300: 0.4010 - val_loss: 3.3311 - val_accuracy300: 0.3756 - 26s/epoch - 41ms/step
Epoch 4/50
634/634 - 26s - loss: 3.2126 - accuracy300: 0.4184 - val_loss: 3.3558 - val_accuracy300: 0.3726 - 26s/epoch - 42ms/step
Epoch 5/50
634/634 - 26s - loss: 3.1768 - accuracy300: 0.4361 - val_loss: 3.4503 - val_accuracy300: 0.3599 - 26s/epoch - 41ms/step
Epoch 6/50
634/634 - 26s - loss: 3.1443 - accuracy300: 0.4493 - val_loss: 3.6073 - val_accuracy300: 0.3489 - 26s/epoch - 41ms/step
Epoch 7/50
634/634 - 26s - loss: 3.1153 - accuracy300: 0.4598 - val_loss: 3.6794 - val_accuracy300: 0.3481 - 26s/epoch - 41ms/step
Epoch 8/50
634/634 - 26s - loss: 3.0838 - accuracy300: 0.4720 - val_loss: 3.8058 - val_accuracy300: 0.3516 - 26s/epoch - 41ms/step
Epoch 9/50
634/634 - 26s - loss: 3.0512 - accuracy300: 0.4819 - val_loss: 3.7888 - val_accuracy300: 0.3589 - 26s/epoch - 41ms/step
Epoch 10/50
634/634 - 26s - loss: 3.0219 - accuracy300: 0.4905 - val_loss: 3.8156 - val_accuracy300: 0.3639 - 26s/epoch - 41ms/step
Epoch 11/50
634/634 - 26s - loss: 2.9920 - accuracy300: 0.4996 - val_loss: 3.8815 - val_accuracy300: 0.3681 - 26s/epoch - 41ms/step
testing model: results/QRTEA/W4/deepLOB_L2/h300
Evaluating performance on  test set...
1613/1613 - 21s - 21s/epoch - 13ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.2045561
{'0': {'precision': 0.3242585773724859, 'recall': 0.1771279608463918, 'f1-score': 0.22910571472849287, 'support': 137714}, '1': {'precision': 0.32807803324375434, 'recall': 0.6153576175754589, 'f1-score': 0.4279789866758074, 'support': 133914}, '2': {'precision': 0.349127210892223, 'recall': 0.21371467416319104, 'f1-score': 0.2651316829769665, 'support': 141221}, 'accuracy': 0.33178958892960864, 'macro avg': {'precision': 0.3338212738361544, 'recall': 0.33540008419501394, 'f1-score': 0.30740546146042225, 'support': 412849}, 'weighted avg': {'precision': 0.3340041548301904, 'recall': 0.33178958892960864, 'f1-score': 0.30593656233032884, 'support': 412849}}
[[24393 83473 29848]
 [25091 82405 26418]
 [25743 85297 30181]]
Evaluating performance on  train set...
634/634 - 9s - 9s/epoch - 14ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.147489
{'0': {'precision': 0.3476601512341275, 'recall': 0.17844458276884773, 'f1-score': 0.23583924121077213, 'support': 54622}, '1': {'precision': 0.33150905274720965, 'recall': 0.6319646997232817, 'f1-score': 0.4348888974665792, 'support': 53484}, '2': {'precision': 0.3525099403578529, 'recall': 0.20983727810650887, 'f1-score': 0.2630749258160237, 'support': 54080}, 'accuracy': 0.3384694116631522, 'macro avg': {'precision': 0.3438930481130633, 'recall': 0.3400821868662128, 'f1-score': 0.3112676881644583, 'support': 162186}, 'weighted avg': {'precision': 0.34395114579800323, 'recall': 0.3384694116631522, 'f1-score': 0.3105613358344609, 'support': 162186}}
[[ 9747 34044 10831]
 [ 9671 33800 10013]
 [ 8618 34114 11348]]
Evaluating performance on  val set...
206/206 - 3s - 3s/epoch - 14ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1065371
{'0': {'precision': 0.32677235482721767, 'recall': 0.21647294825653432, 'f1-score': 0.2604251694644568, 'support': 16949}, '1': {'precision': 0.34574523668536, 'recall': 0.5454145832188582, 'f1-score': 0.4232113925130042, 'support': 18199}, '2': {'precision': 0.36707574454779957, 'recall': 0.2670913434194062, 'f1-score': 0.30920164609053497, 'support': 17582}, 'accuracy': 0.34688033377583916, 'macro avg': {'precision': 0.34653111202012576, 'recall': 0.34299295829826626, 'f1-score': 0.3309460693559987, 'support': 52730}, 'weighted avg': {'precision': 0.3467591114174624, 'recall': 0.34688033377583916, 'f1-score': 0.3328722486470895, 'support': 52730}}
[[3669 9294 3986]
 [4162 9926 4111]
 [3397 9489 4696]]
training model: results/QRTEA/W4/deepLOB_L2/h500
Epoch 1/50
634/634 - 28s - loss: 3.2851 - accuracy500: 0.3886 - val_loss: 3.3863 - val_accuracy500: 0.3389 - 28s/epoch - 45ms/step
Epoch 2/50
634/634 - 26s - loss: 3.2562 - accuracy500: 0.3914 - val_loss: 3.3449 - val_accuracy500: 0.3480 - 26s/epoch - 42ms/step
Epoch 3/50
634/634 - 26s - loss: 3.2528 - accuracy500: 0.3914 - val_loss: 3.3234 - val_accuracy500: 0.3394 - 26s/epoch - 41ms/step
Epoch 4/50
634/634 - 26s - loss: 3.2296 - accuracy500: 0.4073 - val_loss: 3.3342 - val_accuracy500: 0.3287 - 26s/epoch - 41ms/step
Epoch 5/50
634/634 - 26s - loss: 3.2173 - accuracy500: 0.4165 - val_loss: 3.5083 - val_accuracy500: 0.3229 - 26s/epoch - 41ms/step
Epoch 6/50
634/634 - 26s - loss: 3.1866 - accuracy500: 0.4295 - val_loss: 3.4847 - val_accuracy500: 0.3338 - 26s/epoch - 41ms/step
Epoch 7/50
634/634 - 26s - loss: 3.1614 - accuracy500: 0.4441 - val_loss: 3.4613 - val_accuracy500: 0.3381 - 26s/epoch - 40ms/step
Epoch 8/50
634/634 - 26s - loss: 3.1458 - accuracy500: 0.4489 - val_loss: 3.5304 - val_accuracy500: 0.3357 - 26s/epoch - 41ms/step
Epoch 9/50
634/634 - 26s - loss: 3.1137 - accuracy500: 0.4635 - val_loss: 3.5382 - val_accuracy500: 0.3512 - 26s/epoch - 41ms/step
Epoch 10/50
634/634 - 26s - loss: 3.0928 - accuracy500: 0.4716 - val_loss: 3.4643 - val_accuracy500: 0.3427 - 26s/epoch - 40ms/step
Epoch 11/50
634/634 - 26s - loss: 3.0608 - accuracy500: 0.4804 - val_loss: 3.4824 - val_accuracy500: 0.3399 - 26s/epoch - 41ms/step
Epoch 12/50
634/634 - 26s - loss: 3.0312 - accuracy500: 0.4901 - val_loss: 3.4851 - val_accuracy500: 0.3378 - 26s/epoch - 41ms/step
Epoch 13/50
634/634 - 26s - loss: 3.0192 - accuracy500: 0.4930 - val_loss: 3.4677 - val_accuracy500: 0.3378 - 26s/epoch - 40ms/step
testing model: results/QRTEA/W4/deepLOB_L2/h500
Evaluating performance on  test set...
1613/1613 - 22s - 22s/epoch - 14ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1123106
{'0': {'precision': 0.3296342036144788, 'recall': 0.13398140620028987, 'f1-score': 0.19052358547472553, 'support': 141445}, '1': {'precision': 0.3053952321204517, 'recall': 0.6776116125693045, 'f1-score': 0.42103339732782397, 'support': 127517}, '2': {'precision': 0.35989947944713696, 'recall': 0.18114909616574118, 'f1-score': 0.24099671767370906, 'support': 143887}, 'accuracy': 0.3183318840544606, 'macro avg': {'precision': 0.33164297172735585, 'recall': 0.3309140383117785, 'f1-score': 0.28418456682541954, 'support': 412849}, 'weighted avg': {'precision': 0.3326956106076648, 'recall': 0.3183318840544606, 'f1-score': 0.27931233693297464, 'support': 412849}}
[[18951 98916 23578]
 [18330 86407 22780]
 [20210 97612 26065]]
Evaluating performance on  train set...
634/634 - 9s - 9s/epoch - 14ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1058125
{'0': {'precision': 0.36158840621300714, 'recall': 0.18626309662398138, 'f1-score': 0.24587164914505938, 'support': 54117}, '1': {'precision': 0.34108900667722175, 'recall': 0.6423386051335235, 'f1-score': 0.4455734904006115, 'support': 53998}, '2': {'precision': 0.3518393623543838, 'recall': 0.2122579571304396, 'f1-score': 0.26477950421612395, 'support': 54071}, 'accuracy': 0.346774690787121, 'macro avg': {'precision': 0.3515055917482042, 'recall': 0.3469532196293148, 'f1-score': 0.3187415479205983, 'support': 162186}, 'weighted avg': {'precision': 0.3515131399963611, 'recall': 0.346774690787121, 'f1-score': 0.3186637930765013, 'support': 162186}}
[[10080 33323 10714]
 [ 8884 34685 10429]
 [ 8913 33681 11477]]
Evaluating performance on  val set...
206/206 - 3s - 3s/epoch - 14ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.108315
{'0': {'precision': 0.32736457760216076, 'recall': 0.3739786297925833, 'f1-score': 0.34912252627087, 'support': 17501}, '1': {'precision': 0.3390038713519952, 'recall': 0.5268120553016717, 'f1-score': 0.412538787343435, 'support': 17287}, '2': {'precision': 0.35552528520347354, 'recall': 0.11637498606621335, 'f1-score': 0.1753516691161033, 'support': 17942}, 'accuracy': 0.3364308742651242, 'macro avg': {'precision': 0.34063124471920986, 'recall': 0.3390552237201561, 'f1-score': 0.3123376609101361, 'support': 52730}, 'weighted avg': {'precision': 0.3407624134989205, 'recall': 0.3364308742651242, 'f1-score': 0.3107853403442743, 'support': 52730}}
[[6545 9151 1805]
 [6200 9107 1980]
 [7248 8606 2088]]
training model: results/QRTEA/W4/deepLOB_L2/h1000
Epoch 1/50
634/634 - 28s - loss: 3.2604 - accuracy1000: 0.4137 - val_loss: 3.2772 - val_accuracy1000: 0.3809 - 28s/epoch - 44ms/step
Epoch 2/50
634/634 - 26s - loss: 3.2268 - accuracy1000: 0.4198 - val_loss: 3.6861 - val_accuracy1000: 0.3403 - 26s/epoch - 41ms/step
Epoch 3/50
634/634 - 26s - loss: 3.1995 - accuracy1000: 0.4386 - val_loss: 3.3949 - val_accuracy1000: 0.3761 - 26s/epoch - 41ms/step
Epoch 4/50
634/634 - 26s - loss: 3.1699 - accuracy1000: 0.4404 - val_loss: 3.4947 - val_accuracy1000: 0.3797 - 26s/epoch - 41ms/step
Epoch 5/50
634/634 - 26s - loss: 3.1455 - accuracy1000: 0.4502 - val_loss: 3.3111 - val_accuracy1000: 0.3861 - 26s/epoch - 41ms/step
Epoch 6/50
634/634 - 26s - loss: 3.1176 - accuracy1000: 0.4618 - val_loss: 3.4205 - val_accuracy1000: 0.3893 - 26s/epoch - 41ms/step
Epoch 7/50
634/634 - 26s - loss: 3.1047 - accuracy1000: 0.4696 - val_loss: 3.4846 - val_accuracy1000: 0.3861 - 26s/epoch - 41ms/step
Epoch 8/50
634/634 - 26s - loss: 3.0559 - accuracy1000: 0.4880 - val_loss: 3.3856 - val_accuracy1000: 0.3783 - 26s/epoch - 40ms/step
Epoch 9/50
634/634 - 26s - loss: 3.0251 - accuracy1000: 0.4947 - val_loss: 3.3720 - val_accuracy1000: 0.3893 - 26s/epoch - 41ms/step
Epoch 10/50
634/634 - 26s - loss: 2.9879 - accuracy1000: 0.5054 - val_loss: 3.4448 - val_accuracy1000: 0.3869 - 26s/epoch - 41ms/step
Epoch 11/50
634/634 - 26s - loss: 2.9492 - accuracy1000: 0.5173 - val_loss: 3.5379 - val_accuracy1000: 0.3526 - 26s/epoch - 41ms/step
testing model: results/QRTEA/W4/deepLOB_L2/h1000
Evaluating performance on  test set...
1613/1613 - 22s - 22s/epoch - 13ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.133337
{'0': {'precision': 0.4160343427311753, 'recall': 0.33824898123459274, 'f1-score': 0.3731308597611524, 'support': 159016}, '1': {'precision': 0.25975744384331717, 'recall': 0.3285111692015209, 'f1-score': 0.29011652056052295, 'support': 100992}, '2': {'precision': 0.37750656117453046, 'recall': 0.3849163509791221, 'f1-score': 0.3811754491677519, 'support': 152841}, 'accuracy': 0.35314364331753256, 'macro avg': {'precision': 0.35109944924967434, 'recall': 0.3505588338050785, 'f1-score': 0.3481409431631424, 'support': 412849}, 'weighted avg': {'precision': 0.3635421694828891, 'recall': 0.35314364331753256, 'f1-score': 0.3558019064269893, 'support': 412849}}
[[53787 45919 59310]
 [30115 33177 37700]
 [45383 48627 58831]]
Evaluating performance on  train set...
634/634 - 9s - 9s/epoch - 14ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1133837
{'0': {'precision': 0.3365439020626511, 'recall': 0.47595751645873496, 'f1-score': 0.39429001883239173, 'support': 54986}, '1': {'precision': 0.3970489430978345, 'recall': 0.2853720144125404, 'f1-score': 0.3320726172465961, 'support': 53842}, '2': {'precision': 0.36254483422272765, 'recall': 0.31067506278346263, 'f1-score': 0.3346117357340385, 'support': 53358}, 'accuracy': 0.3583108283082387, 'macro avg': {'precision': 0.3653792264610711, 'recall': 0.3573348645515793, 'f1-score': 0.3536581239376755, 'support': 162186}, 'weighted avg': {'precision': 0.36518429123072793, 'recall': 0.3583108283082387, 'f1-score': 0.3540015650463415, 'support': 162186}}
[[26171 11638 17177]
 [26507 15365 11970]
 [25086 11695 16577]]
Evaluating performance on  val set...
206/206 - 3s - 3s/epoch - 14ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0919068
{'0': {'precision': 0.39645874099174344, 'recall': 0.4177310670823695, 'f1-score': 0.4068170131491956, 'support': 19886}, '1': {'precision': 0.28073124606009664, 'recall': 0.09697321622994846, 'f1-score': 0.1441519205869659, 'support': 13777}, '2': {'precision': 0.3823377007920645, 'recall': 0.5417737452142445, 'f1-score': 0.4483020505587501, 'support': 19067}, 'accuracy': 0.3787786838611796, 'macro avg': {'precision': 0.3531758959479682, 'recall': 0.3521593428421875, 'f1-score': 0.3330903280983039, 'support': 52730}, 'weighted avg': {'precision': 0.3611159840950892, 'recall': 0.3787786838611796, 'f1-score': 0.35319020161986003, 'support': 52730}}
[[ 8307  1931  9648]
 [ 5401  1336  7040]
 [ 7245  1492 10330]]
training model: results/QRTEA/W4/deepOF_L2/h10
Epoch 1/50
634/634 - 17s - loss: 2.9140 - accuracy10: 0.4797 - val_loss: 2.3156 - val_accuracy10: 0.6262 - 17s/epoch - 26ms/step
Epoch 2/50
634/634 - 14s - loss: 2.5821 - accuracy10: 0.5783 - val_loss: 2.1814 - val_accuracy10: 0.7121 - 14s/epoch - 22ms/step
Epoch 3/50
634/634 - 14s - loss: 2.4135 - accuracy10: 0.6254 - val_loss: 2.1352 - val_accuracy10: 0.7117 - 14s/epoch - 23ms/step
Epoch 4/50
634/634 - 14s - loss: 2.3183 - accuracy10: 0.6444 - val_loss: 2.0762 - val_accuracy10: 0.7426 - 14s/epoch - 22ms/step
Epoch 5/50
634/634 - 14s - loss: 2.2656 - accuracy10: 0.6532 - val_loss: 2.0398 - val_accuracy10: 0.7584 - 14s/epoch - 22ms/step
Epoch 6/50
634/634 - 14s - loss: 2.2321 - accuracy10: 0.6572 - val_loss: 2.0423 - val_accuracy10: 0.7349 - 14s/epoch - 22ms/step
Epoch 7/50
634/634 - 14s - loss: 2.2015 - accuracy10: 0.6625 - val_loss: 2.0708 - val_accuracy10: 0.7383 - 14s/epoch - 23ms/step
Epoch 8/50
634/634 - 14s - loss: 2.1759 - accuracy10: 0.6671 - val_loss: 2.0226 - val_accuracy10: 0.7394 - 14s/epoch - 23ms/step
Epoch 9/50
634/634 - 14s - loss: 2.1535 - accuracy10: 0.6698 - val_loss: 2.0208 - val_accuracy10: 0.7429 - 14s/epoch - 23ms/step
Epoch 10/50
634/634 - 14s - loss: 2.1378 - accuracy10: 0.6707 - val_loss: 2.0259 - val_accuracy10: 0.7310 - 14s/epoch - 22ms/step
Epoch 11/50
634/634 - 14s - loss: 2.1168 - accuracy10: 0.6737 - val_loss: 2.0397 - val_accuracy10: 0.7272 - 14s/epoch - 23ms/step
Epoch 12/50
634/634 - 14s - loss: 2.1008 - accuracy10: 0.6745 - val_loss: 1.9989 - val_accuracy10: 0.7446 - 14s/epoch - 23ms/step
Epoch 13/50
634/634 - 14s - loss: 2.0846 - accuracy10: 0.6762 - val_loss: 2.0191 - val_accuracy10: 0.7388 - 14s/epoch - 23ms/step
Epoch 14/50
634/634 - 14s - loss: 2.0678 - accuracy10: 0.6757 - val_loss: 2.0244 - val_accuracy10: 0.7324 - 14s/epoch - 22ms/step
Epoch 15/50
634/634 - 14s - loss: 2.0650 - accuracy10: 0.6758 - val_loss: 2.0542 - val_accuracy10: 0.7397 - 14s/epoch - 23ms/step
Epoch 16/50
634/634 - 14s - loss: 2.0490 - accuracy10: 0.6764 - val_loss: 2.0375 - val_accuracy10: 0.7317 - 14s/epoch - 23ms/step
Epoch 17/50
634/634 - 14s - loss: 2.0317 - accuracy10: 0.6785 - val_loss: 2.0425 - val_accuracy10: 0.7224 - 14s/epoch - 23ms/step
Epoch 18/50
634/634 - 14s - loss: 2.0209 - accuracy10: 0.6776 - val_loss: 2.0285 - val_accuracy10: 0.7236 - 14s/epoch - 22ms/step
Epoch 19/50
634/634 - 14s - loss: 2.0074 - accuracy10: 0.6792 - val_loss: 2.0542 - val_accuracy10: 0.7303 - 14s/epoch - 22ms/step
Epoch 20/50
634/634 - 14s - loss: 1.9923 - accuracy10: 0.6806 - val_loss: 2.0701 - val_accuracy10: 0.7314 - 14s/epoch - 22ms/step
Epoch 21/50
634/634 - 14s - loss: 1.9809 - accuracy10: 0.6794 - val_loss: 2.0710 - val_accuracy10: 0.7478 - 14s/epoch - 22ms/step
Epoch 22/50
634/634 - 14s - loss: 1.9693 - accuracy10: 0.6796 - val_loss: 2.1030 - val_accuracy10: 0.7292 - 14s/epoch - 23ms/step
testing model: results/QRTEA/W4/deepOF_L2/h10
Evaluating performance on  test set...
1613/1613 - 13s - 13s/epoch - 8ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.6470862
{'0': {'precision': 0.2739688178409315, 'recall': 0.6165941192147109, 'f1-score': 0.37937254044599916, 'support': 33771}, '1': {'precision': 0.940770487941341, 'recall': 0.7407329047815023, 'f1-score': 0.8288531076194646, 'support': 345038}, '2': {'precision': 0.3213233488828873, 'recall': 0.6152309319544013, 'f1-score': 0.4221603967581952, 'support': 34036}, 'accuracy': 0.7202315639041287, 'macro avg': {'precision': 0.5120208848883866, 'recall': 0.6575193186502047, 'f1-score': 0.5434620149412197, 'support': 412845}, 'weighted avg': {'precision': 0.8351568507991824, 'recall': 0.7202315639041287, 'f1-score': 0.758556503952497, 'support': 412845}}
[[ 20823   7520   5428]
 [ 50657 255581  38800]
 [  4525   8571  20940]]
Evaluating performance on  train set...
634/634 - 5s - 5s/epoch - 8ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.64624614
{'0': {'precision': 0.3503744138848065, 'recall': 0.6232804232804233, 'f1-score': 0.4485809645409135, 'support': 16065}, '1': {'precision': 0.9253351078999905, 'recall': 0.7483585256715821, 'f1-score': 0.827490053388649, 'support': 130066}, '2': {'precision': 0.34861707368569217, 'recall': 0.6170663344752414, 'f1-score': 0.44552874777955165, 'support': 16055}, 'accuracy': 0.722972389725377, 'macro avg': {'precision': 0.5414421984901631, 'recall': 0.6629017611424156, 'f1-score': 0.5738665885697047, 'support': 162186}, 'weighted avg': {'precision': 0.811293503885683, 'recall': 0.722972389725377, 'f1-score': 0.7521471552723324, 'support': 162186}}
[[10013  3825  2227]
 [16446 97336 16284]
 [ 2119  4029  9907]]
Evaluating performance on  val set...
206/206 - 2s - 2s/epoch - 8ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.60604227
{'0': {'precision': 0.2974195264698058, 'recall': 0.5570503238664674, 'f1-score': 0.3877904960110996, 'support': 4014}, '1': {'precision': 0.9360290333938196, 'recall': 0.7756407379146282, 'f1-score': 0.8483204673482161, 'support': 44558}, '2': {'precision': 0.3016409266409266, 'recall': 0.6013952369497234, 'f1-score': 0.4017677782241864, 'support': 4157}, 'accuracy': 0.745263517229608, 'macro avg': {'precision': 0.5116964955015173, 'recall': 0.644695432910273, 'f1-score': 0.545959580527834, 'support': 52729}, 'weighted avg': {'precision': 0.8374015244221955, 'recall': 0.745263517229608, 'f1-score': 0.7780576739397355, 'support': 52729}}
[[ 2236  1146   632]
 [ 4841 34561  5156]
 [  441  1216  2500]]
training model: results/QRTEA/W4/deepOF_L2/h20
Epoch 1/50
634/634 - 17s - loss: 2.9485 - accuracy20: 0.4625 - val_loss: 2.4018 - val_accuracy20: 0.6280 - 17s/epoch - 27ms/step
Epoch 2/50
634/634 - 15s - loss: 2.6470 - accuracy20: 0.5490 - val_loss: 2.2681 - val_accuracy20: 0.7167 - 15s/epoch - 23ms/step
Epoch 3/50
634/634 - 15s - loss: 2.4912 - accuracy20: 0.5909 - val_loss: 2.2416 - val_accuracy20: 0.6944 - 15s/epoch - 23ms/step
Epoch 4/50
634/634 - 15s - loss: 2.4060 - accuracy20: 0.6126 - val_loss: 2.1833 - val_accuracy20: 0.7136 - 15s/epoch - 23ms/step
Epoch 5/50
634/634 - 14s - loss: 2.3617 - accuracy20: 0.6264 - val_loss: 2.1687 - val_accuracy20: 0.7171 - 14s/epoch - 23ms/step
Epoch 6/50
634/634 - 15s - loss: 2.3209 - accuracy20: 0.6365 - val_loss: 2.1323 - val_accuracy20: 0.7255 - 15s/epoch - 23ms/step
Epoch 7/50
634/634 - 14s - loss: 2.2997 - accuracy20: 0.6402 - val_loss: 2.1246 - val_accuracy20: 0.7376 - 14s/epoch - 23ms/step
Epoch 8/50
634/634 - 14s - loss: 2.2752 - accuracy20: 0.6467 - val_loss: 2.1186 - val_accuracy20: 0.7337 - 14s/epoch - 22ms/step
Epoch 9/50
634/634 - 14s - loss: 2.2492 - accuracy20: 0.6493 - val_loss: 2.1582 - val_accuracy20: 0.7081 - 14s/epoch - 22ms/step
Epoch 10/50
634/634 - 14s - loss: 2.2356 - accuracy20: 0.6494 - val_loss: 2.1294 - val_accuracy20: 0.7259 - 14s/epoch - 23ms/step
Epoch 11/50
634/634 - 14s - loss: 2.2159 - accuracy20: 0.6523 - val_loss: 2.1199 - val_accuracy20: 0.7285 - 14s/epoch - 23ms/step
Epoch 12/50
634/634 - 14s - loss: 2.2035 - accuracy20: 0.6536 - val_loss: 2.1363 - val_accuracy20: 0.7275 - 14s/epoch - 22ms/step
Epoch 13/50
634/634 - 14s - loss: 2.1850 - accuracy20: 0.6553 - val_loss: 2.1408 - val_accuracy20: 0.7180 - 14s/epoch - 23ms/step
Epoch 14/50
634/634 - 14s - loss: 2.1671 - accuracy20: 0.6565 - val_loss: 2.1358 - val_accuracy20: 0.7111 - 14s/epoch - 23ms/step
Epoch 15/50
634/634 - 14s - loss: 2.1568 - accuracy20: 0.6557 - val_loss: 2.1493 - val_accuracy20: 0.7028 - 14s/epoch - 22ms/step
Epoch 16/50
634/634 - 14s - loss: 2.1410 - accuracy20: 0.6575 - val_loss: 2.1576 - val_accuracy20: 0.7031 - 14s/epoch - 23ms/step
Epoch 17/50
634/634 - 14s - loss: 2.1279 - accuracy20: 0.6582 - val_loss: 2.1629 - val_accuracy20: 0.6865 - 14s/epoch - 23ms/step
Epoch 18/50
634/634 - 14s - loss: 2.1181 - accuracy20: 0.6578 - val_loss: 2.1860 - val_accuracy20: 0.6964 - 14s/epoch - 23ms/step
testing model: results/QRTEA/W4/deepOF_L2/h20
Evaluating performance on  test set...
1613/1613 - 12s - 12s/epoch - 8ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.6600603
{'0': {'precision': 0.394312154384381, 'recall': 0.5271802388239859, 'f1-score': 0.4511672093044705, 'support': 46394}, '1': {'precision': 0.8912594263362824, 'recall': 0.7818649167352842, 'f1-score': 0.8329858806341539, 'support': 319403}, '2': {'precision': 0.3905606139990654, 'recall': 0.5862310831491243, 'f1-score': 0.46879753881717046, 'support': 47048}, 'accuracy': 0.730949872228076, 'macro avg': {'precision': 0.5587107315732429, 'recall': 0.6317587462361315, 'f1-score': 0.5843168762519316, 'support': 412845}, 'weighted avg': {'precision': 0.7783544633168008, 'recall': 0.730949872228076, 'f1-score': 0.748575439564322, 'support': 412845}}
[[ 24458  16245   5691]
 [ 32326 249730  37347]
 [  5243  14224  27581]]
Evaluating performance on  train set...
634/634 - 5s - 5s/epoch - 8ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.6885565
{'0': {'precision': 0.4432370820668693, 'recall': 0.5428066257211985, 'f1-score': 0.4879946456956412, 'support': 21492}, '1': {'precision': 0.8689524791612959, 'recall': 0.7646767214216695, 'f1-score': 0.8134866009975509, 'support': 119015}, '2': {'precision': 0.40201715221790385, 'recall': 0.5773329028091702, 'f1-score': 0.4739831856396274, 'support': 21679}, 'accuracy': 0.7102339289457783, 'macro avg': {'precision': 0.5714022378153564, 'recall': 0.6282720833173462, 'f1-score': 0.591821477444273, 'support': 162186}, 'weighted avg': {'precision': 0.7501249214981239, 'recall': 0.7102339289457783, 'f1-score': 0.7249736119301032, 'support': 162186}}
[[11666  7271  2555]
 [11945 91008 16062]
 [ 2709  6454 12516]]
Evaluating performance on  val set...
206/206 - 2s - 2s/epoch - 8ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.66088027
{'0': {'precision': 0.418109610802224, 'recall': 0.48222792231586664, 'f1-score': 0.4478856462179869, 'support': 5458}, '1': {'precision': 0.8898873354146871, 'recall': 0.7892088409495834, 'f1-score': 0.8365297502839132, 'support': 41534}, '2': {'precision': 0.34722366913220126, 'recall': 0.5809656614955552, 'f1-score': 0.43466353677621283, 'support': 5737}, 'accuracy': 0.7347759297540253, 'macro avg': {'precision': 0.5517402051163708, 'recall': 0.617467474920335, 'f1-score': 0.5730263110927043, 'support': 52729}, 'weighted avg': {'precision': 0.78201075375379, 'recall': 0.7347759297540253, 'f1-score': 0.7525773524215319, 'support': 52729}}
[[ 2632  2143   683]
 [ 3172 32779  5583]
 [  491  1913  3333]]
training model: results/QRTEA/W4/deepOF_L2/h30
Epoch 1/50
634/634 - 17s - loss: 3.0031 - accuracy30: 0.4462 - val_loss: 2.4945 - val_accuracy30: 0.5738 - 17s/epoch - 26ms/step
Epoch 2/50
634/634 - 14s - loss: 2.7432 - accuracy30: 0.5170 - val_loss: 2.3935 - val_accuracy30: 0.6697 - 14s/epoch - 22ms/step
Epoch 3/50
634/634 - 14s - loss: 2.6127 - accuracy30: 0.5587 - val_loss: 2.3736 - val_accuracy30: 0.6710 - 14s/epoch - 22ms/step
Epoch 4/50
634/634 - 14s - loss: 2.5312 - accuracy30: 0.5821 - val_loss: 2.3527 - val_accuracy30: 0.6803 - 14s/epoch - 22ms/step
Epoch 5/50
634/634 - 14s - loss: 2.4818 - accuracy30: 0.5938 - val_loss: 2.3192 - val_accuracy30: 0.6996 - 14s/epoch - 22ms/step
Epoch 6/50
634/634 - 14s - loss: 2.4408 - accuracy30: 0.6053 - val_loss: 2.2741 - val_accuracy30: 0.7023 - 14s/epoch - 23ms/step
Epoch 7/50
634/634 - 14s - loss: 2.4202 - accuracy30: 0.6107 - val_loss: 2.2641 - val_accuracy30: 0.7059 - 14s/epoch - 22ms/step
Epoch 8/50
634/634 - 14s - loss: 2.3988 - accuracy30: 0.6164 - val_loss: 2.2733 - val_accuracy30: 0.7038 - 14s/epoch - 22ms/step
Epoch 9/50
634/634 - 14s - loss: 2.3800 - accuracy30: 0.6222 - val_loss: 2.2576 - val_accuracy30: 0.6925 - 14s/epoch - 23ms/step
Epoch 10/50
634/634 - 14s - loss: 2.3614 - accuracy30: 0.6220 - val_loss: 2.2372 - val_accuracy30: 0.7040 - 14s/epoch - 23ms/step
Epoch 11/50
634/634 - 14s - loss: 2.3439 - accuracy30: 0.6254 - val_loss: 2.2529 - val_accuracy30: 0.6928 - 14s/epoch - 22ms/step
Epoch 12/50
634/634 - 14s - loss: 2.3253 - accuracy30: 0.6271 - val_loss: 2.2522 - val_accuracy30: 0.6954 - 14s/epoch - 22ms/step
Epoch 13/50
634/634 - 14s - loss: 2.3168 - accuracy30: 0.6288 - val_loss: 2.2584 - val_accuracy30: 0.6954 - 14s/epoch - 23ms/step
Epoch 14/50
634/634 - 14s - loss: 2.2979 - accuracy30: 0.6324 - val_loss: 2.2788 - val_accuracy30: 0.6858 - 14s/epoch - 22ms/step
Epoch 15/50
634/634 - 14s - loss: 2.2867 - accuracy30: 0.6344 - val_loss: 2.2561 - val_accuracy30: 0.6923 - 14s/epoch - 22ms/step
Epoch 16/50
634/634 - 14s - loss: 2.2715 - accuracy30: 0.6359 - val_loss: 2.2769 - val_accuracy30: 0.6895 - 14s/epoch - 22ms/step
Epoch 17/50
634/634 - 14s - loss: 2.2567 - accuracy30: 0.6358 - val_loss: 2.2998 - val_accuracy30: 0.6818 - 14s/epoch - 22ms/step
Epoch 18/50
634/634 - 14s - loss: 2.2455 - accuracy30: 0.6383 - val_loss: 2.3079 - val_accuracy30: 0.6943 - 14s/epoch - 23ms/step
Epoch 19/50
634/634 - 14s - loss: 2.2335 - accuracy30: 0.6389 - val_loss: 2.3224 - val_accuracy30: 0.6991 - 14s/epoch - 23ms/step
Epoch 20/50
634/634 - 14s - loss: 2.2130 - accuracy30: 0.6404 - val_loss: 2.3644 - val_accuracy30: 0.6887 - 14s/epoch - 23ms/step
testing model: results/QRTEA/W4/deepOF_L2/h30
Evaluating performance on  test set...
1613/1613 - 13s - 13s/epoch - 8ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.711454
{'0': {'precision': 0.4038426325564362, 'recall': 0.5544143788267826, 'f1-score': 0.46729877185946384, 'support': 55693}, '1': {'precision': 0.8497534027458937, 'recall': 0.7637941764762656, 'f1-score': 0.8044841178728483, 'support': 300471}, '2': {'precision': 0.4470148240865015, 'recall': 0.5229618390642367, 'f1-score': 0.48201509041238455, 'support': 56681}, 'accuracy': 0.7024839830929284, 'macro avg': {'precision': 0.5668702864629438, 'recall': 0.613723464789095, 'f1-score': 0.5845993267148989, 'support': 412845}, 'weighted avg': {'precision': 0.7343063611173056, 'recall': 0.7024839830929284, 'f1-score': 0.7147246914028414, 'support': 412845}}
[[ 30877  19327   5489]
 [ 39793 229498  31180]
 [  5788  21251  29642]]
Evaluating performance on  train set...
634/634 - 6s - 6s/epoch - 9ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.7398507
{'0': {'precision': 0.47293497363796133, 'recall': 0.5240506329113924, 'f1-score': 0.4971824480369515, 'support': 25675}, '1': {'precision': 0.8167646508513299, 'recall': 0.7499163645240915, 'f1-score': 0.781914342009748, 'support': 110599}, '2': {'precision': 0.4341234583242723, 'recall': 0.5392868169188021, 'f1-score': 0.48102442298755616, 'support': 25912}, 'accuracy': 0.680508798539948, 'macro avg': {'precision': 0.5746076942711879, 'recall': 0.6044179381180953, 'f1-score': 0.5867070710114185, 'support': 162186}, 'weighted avg': {'precision': 0.7012008812089788, 'recall': 0.680508798539948, 'f1-score': 0.6887672703793076, 'support': 162186}}
[[13455  9447  2773]
 [12217 82940 15442]
 [ 2778  9160 13974]]
Evaluating performance on  val set...
206/206 - 2s - 2s/epoch - 8ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.7152608
{'0': {'precision': 0.44056442417331815, 'recall': 0.4674833635813672, 'f1-score': 0.45362488993249195, 'support': 6612}, '1': {'precision': 0.8464166690004761, 'recall': 0.7708179244561197, 'f1-score': 0.8068503390463986, 'support': 39209}, '2': {'precision': 0.3733759744153508, 'recall': 0.540822235089751, 'f1-score': 0.4417642189901857, 'support': 6908}, 'accuracy': 0.7026493959680631, 'macro avg': {'precision': 0.5534523558630483, 'recall': 0.5930411743757461, 'f1-score': 0.5674131493230253, 'support': 52729}, 'weighted avg': {'precision': 0.7335516391119666, 'recall': 0.7026493959680631, 'f1-score': 0.714727568144438, 'support': 52729}}
[[ 3091  2792   729]
 [ 3445 30223  5541]
 [  480  2692  3736]]
training model: results/QRTEA/W4/deepOF_L2/h50
Epoch 1/50
634/634 - 17s - loss: 3.0913 - accuracy50: 0.4263 - val_loss: 2.6685 - val_accuracy50: 0.5362 - 17s/epoch - 26ms/step
Epoch 2/50
634/634 - 15s - loss: 2.8802 - accuracy50: 0.4938 - val_loss: 2.5847 - val_accuracy50: 0.6239 - 15s/epoch - 23ms/step
Epoch 3/50
634/634 - 15s - loss: 2.7843 - accuracy50: 0.5295 - val_loss: 2.5608 - val_accuracy50: 0.6308 - 15s/epoch - 23ms/step
Epoch 4/50
634/634 - 15s - loss: 2.7217 - accuracy50: 0.5462 - val_loss: 2.5309 - val_accuracy50: 0.6341 - 15s/epoch - 23ms/step
Epoch 5/50
634/634 - 14s - loss: 2.6801 - accuracy50: 0.5582 - val_loss: 2.4936 - val_accuracy50: 0.6504 - 14s/epoch - 23ms/step
Epoch 6/50
634/634 - 14s - loss: 2.6455 - accuracy50: 0.5675 - val_loss: 2.4859 - val_accuracy50: 0.6368 - 14s/epoch - 23ms/step
Epoch 7/50
634/634 - 14s - loss: 2.6261 - accuracy50: 0.5744 - val_loss: 2.4811 - val_accuracy50: 0.6386 - 14s/epoch - 23ms/step
Epoch 8/50
634/634 - 14s - loss: 2.6007 - accuracy50: 0.5811 - val_loss: 2.4689 - val_accuracy50: 0.6510 - 14s/epoch - 23ms/step
Epoch 9/50
634/634 - 14s - loss: 2.5816 - accuracy50: 0.5860 - val_loss: 2.4695 - val_accuracy50: 0.6369 - 14s/epoch - 22ms/step
Epoch 10/50
634/634 - 14s - loss: 2.5654 - accuracy50: 0.5885 - val_loss: 2.4500 - val_accuracy50: 0.6462 - 14s/epoch - 22ms/step
Epoch 11/50
634/634 - 14s - loss: 2.5454 - accuracy50: 0.5939 - val_loss: 2.4501 - val_accuracy50: 0.6411 - 14s/epoch - 22ms/step
Epoch 12/50
634/634 - 14s - loss: 2.5331 - accuracy50: 0.5937 - val_loss: 2.4716 - val_accuracy50: 0.6302 - 14s/epoch - 22ms/step
Epoch 13/50
634/634 - 14s - loss: 2.5128 - accuracy50: 0.5963 - val_loss: 2.4684 - val_accuracy50: 0.6421 - 14s/epoch - 23ms/step
Epoch 14/50
634/634 - 14s - loss: 2.4961 - accuracy50: 0.6010 - val_loss: 2.4870 - val_accuracy50: 0.6294 - 14s/epoch - 22ms/step
Epoch 15/50
634/634 - 14s - loss: 2.4841 - accuracy50: 0.6038 - val_loss: 2.4725 - val_accuracy50: 0.6321 - 14s/epoch - 23ms/step
Epoch 16/50
634/634 - 14s - loss: 2.4662 - accuracy50: 0.6057 - val_loss: 2.4917 - val_accuracy50: 0.6347 - 14s/epoch - 22ms/step
Epoch 17/50
634/634 - 14s - loss: 2.4453 - accuracy50: 0.6075 - val_loss: 2.4760 - val_accuracy50: 0.6325 - 14s/epoch - 22ms/step
Epoch 18/50
634/634 - 14s - loss: 2.4323 - accuracy50: 0.6083 - val_loss: 2.5078 - val_accuracy50: 0.6136 - 14s/epoch - 23ms/step
Epoch 19/50
634/634 - 14s - loss: 2.4137 - accuracy50: 0.6117 - val_loss: 2.4965 - val_accuracy50: 0.6352 - 14s/epoch - 23ms/step
Epoch 20/50
634/634 - 14s - loss: 2.3991 - accuracy50: 0.6128 - val_loss: 2.5136 - val_accuracy50: 0.6204 - 14s/epoch - 23ms/step
testing model: results/QRTEA/W4/deepOF_L2/h50
Evaluating performance on  test set...
1613/1613 - 13s - 13s/epoch - 8ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.7954485
{'0': {'precision': 0.46120689655172414, 'recall': 0.4929705278735672, 'f1-score': 0.4765600221341953, 'support': 71627}, '1': {'precision': 0.7725994422199025, 'recall': 0.7387099176939407, 'f1-score': 0.7552747114663337, 'support': 268510}, '2': {'precision': 0.46717282817744143, 'recall': 0.5111542058645541, 'f1-score': 0.4881749101871129, 'support': 72708}, 'accuracy': 0.6559992248906975, 'macro avg': {'precision': 0.5669930556496894, 'recall': 0.5809448838106873, 'f1-score': 0.573336547929214, 'support': 412845}, 'weighted avg': {'precision': 0.6647839857595509, 'recall': 0.6559992248906975, 'f1-score': 0.6598786441669776, 'support': 412845}}
[[ 35310  29783   6534]
 [ 34305 198351  35854]
 [  6945  28598  37165]]
Evaluating performance on  train set...
634/634 - 5s - 5s/epoch - 8ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.8333838
{'0': {'precision': 0.49015242865535047, 'recall': 0.4872598739818657, 'f1-score': 0.4887018712044145, 'support': 32535}, '1': {'precision': 0.7303545555271457, 'recall': 0.7075081273543526, 'f1-score': 0.7187498361807306, 'support': 96895}, '2': {'precision': 0.45512660162872787, 'recall': 0.49990841372572964, 'f1-score': 0.47646759292936636, 'support': 32756}, 'accuracy': 0.6213976545447819, 'macro avg': {'precision': 0.5585445286037414, 'recall': 0.5648921383539827, 'f1-score': 0.5613064334381704, 'support': 162186}, 'weighted avg': {'precision': 0.6265826944807519, 'recall': 0.6213976545447819, 'f1-score': 0.6236688322688879, 'support': 162186}}
[[15853 12963  3719]
 [12456 68554 15885]
 [ 4034 12347 16375]]
Evaluating performance on  val set...
206/206 - 2s - 2s/epoch - 9ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.81216776
{'0': {'precision': 0.46647937683565316, 'recall': 0.4264534204996498, 'f1-score': 0.4455693114594133, 'support': 8566}, '1': {'precision': 0.7695817039933641, 'recall': 0.7373410535876476, 'f1-score': 0.7531164840262076, 'support': 35232}, '2': {'precision': 0.40315921737569554, 'recall': 0.5029671929235248, 'f1-score': 0.4475663827031335, 'support': 8931}, 'accuracy': 0.6471391454417873, 'macro avg': {'precision': 0.5464067660682376, 'recall': 0.5555872223369408, 'f1-score': 0.5487507260629182, 'support': 52729}, 'weighted avg': {'precision': 0.6582787442858911, 'recall': 0.6471391454417873, 'f1-score': 0.6514017343604918, 'support': 52729}}
[[ 3653  3995   918]
 [ 3522 25978  5732]
 [  656  3783  4492]]
training model: results/QRTEA/W4/deepOF_L2/h100
Epoch 1/50
634/634 - 17s - loss: 3.2137 - accuracy100: 0.3978 - val_loss: 2.9797 - val_accuracy100: 0.4873 - 17s/epoch - 27ms/step
Epoch 2/50
634/634 - 15s - loss: 3.0879 - accuracy100: 0.4483 - val_loss: 2.9288 - val_accuracy100: 0.5357 - 15s/epoch - 23ms/step
Epoch 3/50
634/634 - 14s - loss: 3.0319 - accuracy100: 0.4718 - val_loss: 2.9113 - val_accuracy100: 0.5492 - 14s/epoch - 23ms/step
Epoch 4/50
634/634 - 14s - loss: 2.9926 - accuracy100: 0.4864 - val_loss: 2.8929 - val_accuracy100: 0.5531 - 14s/epoch - 23ms/step
Epoch 5/50
634/634 - 14s - loss: 2.9644 - accuracy100: 0.4950 - val_loss: 2.8853 - val_accuracy100: 0.5571 - 14s/epoch - 23ms/step
Epoch 6/50
634/634 - 14s - loss: 2.9392 - accuracy100: 0.5024 - val_loss: 2.8649 - val_accuracy100: 0.5578 - 14s/epoch - 22ms/step
Epoch 7/50
634/634 - 14s - loss: 2.9161 - accuracy100: 0.5087 - val_loss: 2.8575 - val_accuracy100: 0.5607 - 14s/epoch - 22ms/step
Epoch 8/50
634/634 - 14s - loss: 2.8980 - accuracy100: 0.5135 - val_loss: 2.8500 - val_accuracy100: 0.5611 - 14s/epoch - 22ms/step
Epoch 9/50
634/634 - 14s - loss: 2.8820 - accuracy100: 0.5173 - val_loss: 2.8458 - val_accuracy100: 0.5575 - 14s/epoch - 23ms/step
Epoch 10/50
634/634 - 14s - loss: 2.8693 - accuracy100: 0.5205 - val_loss: 2.8417 - val_accuracy100: 0.5595 - 14s/epoch - 23ms/step
Epoch 11/50
634/634 - 14s - loss: 2.8549 - accuracy100: 0.5259 - val_loss: 2.8398 - val_accuracy100: 0.5619 - 14s/epoch - 22ms/step
Epoch 12/50
634/634 - 14s - loss: 2.8382 - accuracy100: 0.5304 - val_loss: 2.8559 - val_accuracy100: 0.5571 - 14s/epoch - 22ms/step
Epoch 13/50
634/634 - 14s - loss: 2.8229 - accuracy100: 0.5342 - val_loss: 2.8407 - val_accuracy100: 0.5562 - 14s/epoch - 22ms/step
Epoch 14/50
634/634 - 14s - loss: 2.8068 - accuracy100: 0.5387 - val_loss: 2.8604 - val_accuracy100: 0.5545 - 14s/epoch - 22ms/step
Epoch 15/50
634/634 - 14s - loss: 2.7924 - accuracy100: 0.5416 - val_loss: 2.8430 - val_accuracy100: 0.5536 - 14s/epoch - 23ms/step
Epoch 16/50
634/634 - 14s - loss: 2.7830 - accuracy100: 0.5438 - val_loss: 2.8645 - val_accuracy100: 0.5504 - 14s/epoch - 22ms/step
Epoch 17/50
634/634 - 14s - loss: 2.7661 - accuracy100: 0.5480 - val_loss: 2.8546 - val_accuracy100: 0.5539 - 14s/epoch - 22ms/step
Epoch 18/50
634/634 - 14s - loss: 2.7490 - accuracy100: 0.5514 - val_loss: 2.8723 - val_accuracy100: 0.5578 - 14s/epoch - 22ms/step
Epoch 19/50
634/634 - 14s - loss: 2.7306 - accuracy100: 0.5534 - val_loss: 2.8854 - val_accuracy100: 0.5487 - 14s/epoch - 22ms/step
Epoch 20/50
634/634 - 14s - loss: 2.7161 - accuracy100: 0.5559 - val_loss: 2.9179 - val_accuracy100: 0.5454 - 14s/epoch - 22ms/step
Epoch 21/50
634/634 - 14s - loss: 2.7008 - accuracy100: 0.5602 - val_loss: 2.9022 - val_accuracy100: 0.5450 - 14s/epoch - 23ms/step
testing model: results/QRTEA/W4/deepOF_L2/h100
Evaluating performance on  test set...
1613/1613 - 13s - 13s/epoch - 8ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 0.9084899
{'0': {'precision': 0.52558002572726, 'recall': 0.3359120400178297, 'f1-score': 0.4098671726755218, 'support': 100955}, '1': {'precision': 0.5910485135144306, 'recall': 0.8303857447944474, 'f1-score': 0.6905676533901026, 'support': 209776}, '2': {'precision': 0.5566417910447761, 'recall': 0.2921832461758427, 'f1-score': 0.3832153820465726, 'support': 102114}, 'accuracy': 0.5763494774067749, 'macro avg': {'precision': 0.5577567767621555, 'recall': 0.4861603436627066, 'f1-score': 0.49455006937073237, 'support': 412845}, 'weighted avg': {'precision': 0.5665289498941369, 'recall': 0.5763494774067749, 'f1-score': 0.5459054027475764, 'support': 412845}}
[[ 33912  58945   8098]
 [ 19915 174195  15666]
 [ 10696  61582  29836]]
Evaluating performance on  train set...
634/634 - 5s - 5s/epoch - 9ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 0.9461678
{'0': {'precision': 0.5207316279372518, 'recall': 0.3613043085538795, 'f1-score': 0.4266097853619517, 'support': 44284}, '1': {'precision': 0.5449437117423291, 'recall': 0.7670313243188149, 'f1-score': 0.6371903205594973, 'support': 73585}, '2': {'precision': 0.5175356809868751, 'recall': 0.32565381230678975, 'f1-score': 0.3997617827514092, 'support': 44317}, 'accuracy': 0.5356442602937368, 'macro avg': {'precision': 0.5277370068888186, 'recall': 0.48466314839316144, 'f1-score': 0.4878539628909528, 'support': 162186}, 'weighted avg': {'precision': 0.5308435451545009, 'recall': 0.5356442602937368, 'f1-score': 0.5148155845728576, 'support': 162186}}
[[16000 23369  4915]
 [ 8604 56442  8539]
 [ 6122 23763 14432]]
Evaluating performance on  val set...
206/206 - 2s - 2s/epoch - 9ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 0.9294404
{'0': {'precision': 0.5131826741996234, 'recall': 0.30898193893253423, 'f1-score': 0.3857236742328497, 'support': 12347}, '1': {'precision': 0.5972153157633019, 'recall': 0.7826370284555789, 'f1-score': 0.6774678784080226, 'support': 27622}, '2': {'precision': 0.46795646916565903, 'recall': 0.3336206896551724, 'f1-score': 0.3895319577252139, 'support': 12760}, 'accuracy': 0.5630677615733277, 'macro avg': {'precision': 0.5261181530428615, 'recall': 0.47507988568109516, 'f1-score': 0.4842411701220288, 'support': 52729}, 'weighted avg': {'precision': 0.5462586522958995, 'recall': 0.5630677615733277, 'f1-score': 0.5394749705800057, 'support': 52729}}
[[ 3815  7168  1364]
 [ 2528 21618  3476]
 [ 1091  7412  4257]]
training model: results/QRTEA/W4/deepOF_L2/h200
Epoch 1/50
634/634 - 17s - loss: 3.2740 - accuracy200: 0.3775 - val_loss: 3.2103 - val_accuracy200: 0.4111 - 17s/epoch - 27ms/step
Epoch 2/50
634/634 - 15s - loss: 3.1974 - accuracy200: 0.4120 - val_loss: 3.1759 - val_accuracy200: 0.4245 - 15s/epoch - 23ms/step
Epoch 3/50
634/634 - 14s - loss: 3.1645 - accuracy200: 0.4248 - val_loss: 3.1622 - val_accuracy200: 0.4298 - 14s/epoch - 23ms/step
Epoch 4/50
634/634 - 15s - loss: 3.1399 - accuracy200: 0.4338 - val_loss: 3.1561 - val_accuracy200: 0.4334 - 15s/epoch - 23ms/step
Epoch 5/50
634/634 - 15s - loss: 3.1239 - accuracy200: 0.4380 - val_loss: 3.1482 - val_accuracy200: 0.4362 - 15s/epoch - 23ms/step
Epoch 6/50
634/634 - 14s - loss: 3.1096 - accuracy200: 0.4430 - val_loss: 3.1396 - val_accuracy200: 0.4381 - 14s/epoch - 23ms/step
Epoch 7/50
634/634 - 14s - loss: 3.0971 - accuracy200: 0.4474 - val_loss: 3.1397 - val_accuracy200: 0.4406 - 14s/epoch - 23ms/step
Epoch 8/50
634/634 - 14s - loss: 3.0861 - accuracy200: 0.4498 - val_loss: 3.1370 - val_accuracy200: 0.4410 - 14s/epoch - 23ms/step
Epoch 9/50
634/634 - 14s - loss: 3.0752 - accuracy200: 0.4540 - val_loss: 3.1307 - val_accuracy200: 0.4425 - 14s/epoch - 23ms/step
Epoch 10/50
634/634 - 14s - loss: 3.0663 - accuracy200: 0.4559 - val_loss: 3.1316 - val_accuracy200: 0.4430 - 14s/epoch - 22ms/step
Epoch 11/50
634/634 - 14s - loss: 3.0566 - accuracy200: 0.4598 - val_loss: 3.1317 - val_accuracy200: 0.4445 - 14s/epoch - 22ms/step
Epoch 12/50
634/634 - 14s - loss: 3.0482 - accuracy200: 0.4627 - val_loss: 3.1336 - val_accuracy200: 0.4421 - 14s/epoch - 22ms/step
Epoch 13/50
634/634 - 14s - loss: 3.0399 - accuracy200: 0.4658 - val_loss: 3.1425 - val_accuracy200: 0.4422 - 14s/epoch - 22ms/step
Epoch 14/50
634/634 - 14s - loss: 3.0311 - accuracy200: 0.4679 - val_loss: 3.1457 - val_accuracy200: 0.4444 - 14s/epoch - 23ms/step
Epoch 15/50
634/634 - 14s - loss: 3.0225 - accuracy200: 0.4714 - val_loss: 3.1697 - val_accuracy200: 0.4377 - 14s/epoch - 22ms/step
Epoch 16/50
634/634 - 14s - loss: 3.0147 - accuracy200: 0.4732 - val_loss: 3.1815 - val_accuracy200: 0.4369 - 14s/epoch - 22ms/step
Epoch 17/50
634/634 - 14s - loss: 3.0051 - accuracy200: 0.4766 - val_loss: 3.1483 - val_accuracy200: 0.4458 - 14s/epoch - 22ms/step
Epoch 18/50
634/634 - 14s - loss: 2.9953 - accuracy200: 0.4799 - val_loss: 3.1454 - val_accuracy200: 0.4452 - 14s/epoch - 23ms/step
Epoch 19/50
634/634 - 14s - loss: 2.9879 - accuracy200: 0.4820 - val_loss: 3.1628 - val_accuracy200: 0.4414 - 14s/epoch - 22ms/step
testing model: results/QRTEA/W4/deepOF_L2/h200
Evaluating performance on  test set...
1613/1613 - 12s - 12s/epoch - 8ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0350171
{'0': {'precision': 0.5555292757279512, 'recall': 0.1646544740777667, 'f1-score': 0.2540195630752962, 'support': 128384}, '1': {'precision': 0.41480528408750467, 'recall': 0.8584724026079976, 'f1-score': 0.5593420705726265, 'support': 153221}, '2': {'precision': 0.5071069509447045, 'recall': 0.22291222188357207, 'f1-score': 0.3096914201026835, 'support': 131240}, 'accuracy': 0.44067386064988073, 'macro avg': {'precision': 0.4924805035867201, 'recall': 0.41534636618977877, 'f1-score': 0.37435101791686876, 'support': 412845}, 'weighted avg': {'precision': 0.4879086998999912, 'recall': 0.44067386064988073, 'f1-score': 0.38503288390399165, 'support': 412845}}
[[ 21139  92729  14516]
 [  7766 131536  13919]
 [  9147  92838  29255]]
Evaluating performance on  train set...
634/634 - 5s - 5s/epoch - 8ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0465047
{'0': {'precision': 0.5462460896767466, 'recall': 0.19288975624125487, 'f1-score': 0.28510395123544136, 'support': 54316}, '1': {'precision': 0.3853518598368518, 'recall': 0.8098646249445184, 'f1-score': 0.5222197709154438, 'support': 54072}, '2': {'precision': 0.49249157217284706, 'recall': 0.26883899029703706, 'f1-score': 0.3478145854626345, 'support': 53798}, 'accuracy': 0.4237788711726043, 'macro avg': {'precision': 0.4746965072288152, 'recall': 0.42386445716093685, 'f1-score': 0.38504610253783983, 'support': 162186}, 'weighted avg': {'precision': 0.4747740863683379, 'recall': 0.4237788711726043, 'f1-score': 0.38495864462384494, 'support': 162186}}
[[10477 35441  8398]
 [ 3775 43791  6506]
 [ 4928 34407 14463]]
Evaluating performance on  val set...
206/206 - 2s - 2s/epoch - 8ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0443646
{'0': {'precision': 0.5371986699916874, 'recall': 0.16172422422422422, 'f1-score': 0.24860550105789578, 'support': 15984}, '1': {'precision': 0.42458701498271223, 'recall': 0.8209369119540457, 'f1-score': 0.5596988470433328, 'support': 20194}, '2': {'precision': 0.4731740306582507, 'recall': 0.2536402634281916, 'f1-score': 0.330252133894505, 'support': 16551}, 'accuracy': 0.4430389349314419, 'macro avg': {'precision': 0.47831990521088347, 'recall': 0.4121004665354872, 'f1-score': 0.3795188273319112, 'support': 52729}, 'weighted avg': {'precision': 0.4739744183112278, 'recall': 0.4430389349314419, 'f1-score': 0.39337502919058626, 'support': 52729}}
[[ 2585 11205  2194]
 [ 1136 16578  2480]
 [ 1091 11262  4198]]
training model: results/QRTEA/W4/deepOF_L2/h300
Epoch 1/50
634/634 - 17s - loss: 3.3052 - accuracy300: 0.3626 - val_loss: 3.2781 - val_accuracy300: 0.3732 - 17s/epoch - 26ms/step
Epoch 2/50
634/634 - 15s - loss: 3.2683 - accuracy300: 0.3851 - val_loss: 3.2607 - val_accuracy300: 0.3819 - 15s/epoch - 23ms/step
Epoch 3/50
634/634 - 15s - loss: 3.2523 - accuracy300: 0.3942 - val_loss: 3.2498 - val_accuracy300: 0.3899 - 15s/epoch - 24ms/step
Epoch 4/50
634/634 - 15s - loss: 3.2426 - accuracy300: 0.3986 - val_loss: 3.2433 - val_accuracy300: 0.3927 - 15s/epoch - 23ms/step
Epoch 5/50
634/634 - 14s - loss: 3.2347 - accuracy300: 0.4027 - val_loss: 3.2396 - val_accuracy300: 0.3955 - 14s/epoch - 23ms/step
Epoch 6/50
634/634 - 14s - loss: 3.2265 - accuracy300: 0.4081 - val_loss: 3.2359 - val_accuracy300: 0.3962 - 14s/epoch - 23ms/step
Epoch 7/50
634/634 - 14s - loss: 3.2196 - accuracy300: 0.4099 - val_loss: 3.2334 - val_accuracy300: 0.3981 - 14s/epoch - 23ms/step
Epoch 8/50
634/634 - 14s - loss: 3.2145 - accuracy300: 0.4134 - val_loss: 3.2310 - val_accuracy300: 0.4002 - 14s/epoch - 23ms/step
Epoch 9/50
634/634 - 14s - loss: 3.2092 - accuracy300: 0.4156 - val_loss: 3.2296 - val_accuracy300: 0.4020 - 14s/epoch - 23ms/step
Epoch 10/50
634/634 - 14s - loss: 3.2040 - accuracy300: 0.4179 - val_loss: 3.2275 - val_accuracy300: 0.4003 - 14s/epoch - 23ms/step
Epoch 11/50
634/634 - 14s - loss: 3.1992 - accuracy300: 0.4206 - val_loss: 3.2284 - val_accuracy300: 0.4023 - 14s/epoch - 23ms/step
Epoch 12/50
634/634 - 14s - loss: 3.1933 - accuracy300: 0.4231 - val_loss: 3.2318 - val_accuracy300: 0.4014 - 14s/epoch - 22ms/step
Epoch 13/50
634/634 - 14s - loss: 3.1895 - accuracy300: 0.4241 - val_loss: 3.2295 - val_accuracy300: 0.4009 - 14s/epoch - 22ms/step
Epoch 14/50
634/634 - 14s - loss: 3.1842 - accuracy300: 0.4265 - val_loss: 3.2302 - val_accuracy300: 0.4009 - 14s/epoch - 22ms/step
Epoch 15/50
634/634 - 14s - loss: 3.1815 - accuracy300: 0.4263 - val_loss: 3.2296 - val_accuracy300: 0.4014 - 14s/epoch - 22ms/step
Epoch 16/50
634/634 - 14s - loss: 3.1721 - accuracy300: 0.4305 - val_loss: 3.2314 - val_accuracy300: 0.4030 - 14s/epoch - 22ms/step
Epoch 17/50
634/634 - 14s - loss: 3.1747 - accuracy300: 0.4305 - val_loss: 3.2311 - val_accuracy300: 0.4009 - 14s/epoch - 23ms/step
Epoch 18/50
634/634 - 14s - loss: 3.1689 - accuracy300: 0.4334 - val_loss: 3.2324 - val_accuracy300: 0.4037 - 14s/epoch - 23ms/step
Epoch 19/50
634/634 - 14s - loss: 3.1628 - accuracy300: 0.4352 - val_loss: 3.2365 - val_accuracy300: 0.4018 - 14s/epoch - 22ms/step
Epoch 20/50
634/634 - 14s - loss: 3.1594 - accuracy300: 0.4368 - val_loss: 3.2363 - val_accuracy300: 0.4017 - 14s/epoch - 23ms/step
testing model: results/QRTEA/W4/deepOF_L2/h300
Evaluating performance on  test set...
1613/1613 - 12s - 12s/epoch - 8ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0707934
{'0': {'precision': 0.4810942444259737, 'recall': 0.23957244103636574, 'f1-score': 0.3198619412571683, 'support': 137712}, '1': {'precision': 0.3581742721746984, 'recall': 0.527167094808531, 'f1-score': 0.4265421170613222, 'support': 133912}, '2': {'precision': 0.4374685746123636, 'recall': 0.4559095318684898, 'f1-score': 0.44649872570606286, 'support': 141221}, 'accuracy': 0.40685971732732623, 'macro avg': {'precision': 0.42557903040434525, 'recall': 0.4075496892377955, 'f1-score': 0.3976342613415178, 'support': 412845}, 'weighted avg': {'precision': 0.42630050817905146, 'recall': 0.40685971732732623, 'f1-score': 0.39778350755673153, 'support': 412845}}
[[32992 66195 38525]
 [19053 70594 44265]
 [16532 60305 64384]]
Evaluating performance on  train set...
634/634 - 5s - 5s/epoch - 9ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.075095
{'0': {'precision': 0.44447015270708007, 'recall': 0.2811613823889936, 'f1-score': 0.34443884126183677, 'support': 54659}, '1': {'precision': 0.3622695629753771, 'recall': 0.4206931397133126, 'f1-score': 0.3893016087415797, 'support': 53438}, '2': {'precision': 0.412850474418037, 'recall': 0.5003605169258075, 'f1-score': 0.452412594134216, 'support': 54089}, 'accuracy': 0.40023799834757623, 'macro avg': {'precision': 0.4065300633668314, 'recall': 0.4007383463427046, 'f1-score': 0.39538434804587747, 'support': 162186}, 'weighted avg': {'precision': 0.4068410608430549, 'recall': 0.40023799834757623, 'f1-score': 0.39522971647730926, 'support': 162186}}
[[15368 20920 18371]
 [10838 22481 20119]
 [ 8370 18655 27064]]
Evaluating performance on  val set...
206/206 - 2s - 2s/epoch - 9ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0760307
{'0': {'precision': 0.4484562519232742, 'recall': 0.25767666647020687, 'f1-score': 0.32729450516544395, 'support': 16967}, '1': {'precision': 0.37562677131022454, 'recall': 0.4743942731277533, 'f1-score': 0.41927241756904726, 'support': 18160}, '2': {'precision': 0.41007732601646296, 'recall': 0.466992387228724, 'f1-score': 0.43668818232528483, 'support': 17602}, 'accuracy': 0.40218854899580875, 'macro avg': {'precision': 0.4113867830833206, 'recall': 0.39968777560889474, 'f1-score': 0.39441836835325866, 'support': 52729}, 'weighted avg': {'precision': 0.4105619390831924, 'recall': 0.40218854899580875, 'f1-score': 0.39548973728850634, 'support': 52729}}
[[4372 7340 5255]
 [2975 8615 6570]
 [2402 6980 8220]]
training model: results/QRTEA/W4/deepOF_L2/h500
Epoch 1/50
634/634 - 17s - loss: 3.2975 - accuracy500: 0.3685 - val_loss: 3.3046 - val_accuracy500: 0.3633 - 17s/epoch - 26ms/step
Epoch 2/50
634/634 - 14s - loss: 3.2780 - accuracy500: 0.3796 - val_loss: 3.2900 - val_accuracy500: 0.3706 - 14s/epoch - 23ms/step
Epoch 3/50
634/634 - 14s - loss: 3.2714 - accuracy500: 0.3823 - val_loss: 3.2831 - val_accuracy500: 0.3750 - 14s/epoch - 22ms/step
Epoch 4/50
634/634 - 14s - loss: 3.2669 - accuracy500: 0.3840 - val_loss: 3.2786 - val_accuracy500: 0.3786 - 14s/epoch - 22ms/step
Epoch 5/50
634/634 - 14s - loss: 3.2631 - accuracy500: 0.3860 - val_loss: 3.2774 - val_accuracy500: 0.3776 - 14s/epoch - 23ms/step
Epoch 6/50
634/634 - 14s - loss: 3.2600 - accuracy500: 0.3903 - val_loss: 3.2780 - val_accuracy500: 0.3798 - 14s/epoch - 22ms/step
Epoch 7/50
634/634 - 14s - loss: 3.2579 - accuracy500: 0.3908 - val_loss: 3.2735 - val_accuracy500: 0.3829 - 14s/epoch - 22ms/step
Epoch 8/50
634/634 - 14s - loss: 3.2558 - accuracy500: 0.3928 - val_loss: 3.2717 - val_accuracy500: 0.3830 - 14s/epoch - 23ms/step
Epoch 9/50
634/634 - 14s - loss: 3.2537 - accuracy500: 0.3936 - val_loss: 3.2708 - val_accuracy500: 0.3824 - 14s/epoch - 23ms/step
Epoch 10/50
634/634 - 14s - loss: 3.2513 - accuracy500: 0.3952 - val_loss: 3.2706 - val_accuracy500: 0.3831 - 14s/epoch - 23ms/step
Epoch 11/50
634/634 - 14s - loss: 3.2485 - accuracy500: 0.3982 - val_loss: 3.2691 - val_accuracy500: 0.3850 - 14s/epoch - 23ms/step
Epoch 12/50
634/634 - 14s - loss: 3.2454 - accuracy500: 0.3987 - val_loss: 3.2702 - val_accuracy500: 0.3844 - 14s/epoch - 22ms/step
Epoch 13/50
634/634 - 14s - loss: 3.2425 - accuracy500: 0.4018 - val_loss: 3.2673 - val_accuracy500: 0.3837 - 14s/epoch - 23ms/step
Epoch 14/50
634/634 - 14s - loss: 3.2394 - accuracy500: 0.4032 - val_loss: 3.2674 - val_accuracy500: 0.3862 - 14s/epoch - 23ms/step
Epoch 15/50
634/634 - 14s - loss: 3.2367 - accuracy500: 0.4043 - val_loss: 3.2689 - val_accuracy500: 0.3852 - 14s/epoch - 23ms/step
Epoch 16/50
634/634 - 14s - loss: 3.2327 - accuracy500: 0.4065 - val_loss: 3.2703 - val_accuracy500: 0.3842 - 14s/epoch - 22ms/step
Epoch 17/50
634/634 - 14s - loss: 3.2291 - accuracy500: 0.4086 - val_loss: 3.2696 - val_accuracy500: 0.3860 - 14s/epoch - 22ms/step
Epoch 18/50
634/634 - 14s - loss: 3.2271 - accuracy500: 0.4101 - val_loss: 3.2712 - val_accuracy500: 0.3841 - 14s/epoch - 22ms/step
Epoch 19/50
634/634 - 14s - loss: 3.2224 - accuracy500: 0.4125 - val_loss: 3.2695 - val_accuracy500: 0.3859 - 14s/epoch - 22ms/step
Epoch 20/50
634/634 - 14s - loss: 3.2167 - accuracy500: 0.4154 - val_loss: 3.2691 - val_accuracy500: 0.3864 - 14s/epoch - 22ms/step
Epoch 21/50
634/634 - 14s - loss: 3.2131 - accuracy500: 0.4171 - val_loss: 3.2699 - val_accuracy500: 0.3865 - 14s/epoch - 22ms/step
Epoch 22/50
634/634 - 14s - loss: 3.2060 - accuracy500: 0.4215 - val_loss: 3.2717 - val_accuracy500: 0.3843 - 14s/epoch - 23ms/step
Epoch 23/50
634/634 - 14s - loss: 3.2005 - accuracy500: 0.4257 - val_loss: 3.2751 - val_accuracy500: 0.3838 - 14s/epoch - 22ms/step
testing model: results/QRTEA/W4/deepOF_L2/h500
Evaluating performance on  test set...
1613/1613 - 13s - 13s/epoch - 8ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0870937
{'0': {'precision': 0.3871060712972441, 'recall': 0.55076992689583, 'f1-score': 0.4546579355908067, 'support': 141442}, '1': {'precision': 0.39876685934489403, 'recall': 0.04057498215924151, 'f1-score': 0.07365543945562737, 'support': 127517}, '2': {'precision': 0.3937712709185009, 'recall': 0.543583114410019, 'f1-score': 0.4567054193405233, 'support': 143886}, 'accuracy': 0.39067931063716405, 'macro avg': {'precision': 0.3932147338535463, 'recall': 0.37830934115503023, 'f1-score': 0.3283395981289858, 'support': 412845}, 'weighted avg': {'precision': 0.393030758824467, 'recall': 0.39067931063716405, 'f1-score': 0.33768984574387156, 'support': 412845}}
[[77902  3766 59774]
 [61703  5174 60640]
 [61637  4035 78214]]
Evaluating performance on  train set...
634/634 - 5s - 5s/epoch - 8ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0857226
{'0': {'precision': 0.3849947117927023, 'recall': 0.5379031364291256, 'f1-score': 0.4487817657846476, 'support': 54138}, '1': {'precision': 0.4562459336369551, 'recall': 0.051932903799155744, 'f1-score': 0.09325132978723405, 'support': 54012}, '2': {'precision': 0.37995970049006195, 'recall': 0.5653268191575986, 'f1-score': 0.4544683636580032, 'support': 54036}, 'accuracy': 0.38519970897611383, 'macro avg': {'precision': 0.4070667819732398, 'recall': 0.38505428646196, 'f1-score': 0.3321671530766283, 'support': 162186}, 'weighted avg': {'precision': 0.40704562323698423, 'recall': 0.38519970897611383, 'f1-score': 0.3322758472318276, 'support': 162186}}
[[29121  1563 23454]
 [24811  2805 26396]
 [21708  1780 30548]]
Evaluating performance on  val set...
206/206 - 2s - 2s/epoch - 9ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.089129
{'0': {'precision': 0.38208799338526483, 'recall': 0.5012273791174288, 'f1-score': 0.43362307388384036, 'support': 17517}, '1': {'precision': 0.4191895668374476, 'recall': 0.052201148425265353, 'f1-score': 0.09284093253558903, 'support': 17241}, '2': {'precision': 0.38144404593703585, 'recall': 0.585888375716432, 'f1-score': 0.46206170184754464, 'support': 17971}, 'accuracy': 0.38326158281021827, 'macro avg': {'precision': 0.39424053538658277, 'recall': 0.3797723010863754, 'f1-score': 0.3295085694223247, 'support': 52729}, 'weighted avg': {'precision': 0.39399976581214496, 'recall': 0.38326158281021827, 'f1-score': 0.3318886522970575, 'support': 52729}}
[[ 8780   587  8150]
 [ 7417   900  8924]
 [ 6782   660 10529]]
training model: results/QRTEA/W4/deepOF_L2/h1000
Epoch 1/50
634/634 - 17s - loss: 3.3239 - accuracy1000: 0.3629 - val_loss: 3.2690 - val_accuracy1000: 0.3785 - 17s/epoch - 27ms/step
Epoch 2/50
634/634 - 15s - loss: 3.3083 - accuracy1000: 0.3627 - val_loss: 3.2644 - val_accuracy1000: 0.3795 - 15s/epoch - 23ms/step
Epoch 3/50
634/634 - 14s - loss: 3.3006 - accuracy1000: 0.3622 - val_loss: 3.2603 - val_accuracy1000: 0.3846 - 14s/epoch - 22ms/step
Epoch 4/50
634/634 - 14s - loss: 3.2980 - accuracy1000: 0.3577 - val_loss: 3.2598 - val_accuracy1000: 0.3854 - 14s/epoch - 23ms/step
Epoch 5/50
634/634 - 14s - loss: 3.2954 - accuracy1000: 0.3548 - val_loss: 3.2600 - val_accuracy1000: 0.3880 - 14s/epoch - 23ms/step
Epoch 6/50
634/634 - 14s - loss: 3.2917 - accuracy1000: 0.3553 - val_loss: 3.2604 - val_accuracy1000: 0.3897 - 14s/epoch - 23ms/step
Epoch 7/50
634/634 - 14s - loss: 3.2882 - accuracy1000: 0.3588 - val_loss: 3.2584 - val_accuracy1000: 0.3912 - 14s/epoch - 23ms/step
Epoch 8/50
634/634 - 14s - loss: 3.2853 - accuracy1000: 0.3620 - val_loss: 3.2601 - val_accuracy1000: 0.3913 - 14s/epoch - 22ms/step
Epoch 9/50
634/634 - 14s - loss: 3.2815 - accuracy1000: 0.3644 - val_loss: 3.2609 - val_accuracy1000: 0.3922 - 14s/epoch - 23ms/step
Epoch 10/50
634/634 - 14s - loss: 3.2769 - accuracy1000: 0.3683 - val_loss: 3.2638 - val_accuracy1000: 0.3908 - 14s/epoch - 22ms/step
Epoch 11/50
634/634 - 14s - loss: 3.2735 - accuracy1000: 0.3724 - val_loss: 3.2633 - val_accuracy1000: 0.3865 - 14s/epoch - 23ms/step
Epoch 12/50
634/634 - 14s - loss: 3.2697 - accuracy1000: 0.3765 - val_loss: 3.2672 - val_accuracy1000: 0.3863 - 14s/epoch - 23ms/step
Epoch 13/50
634/634 - 14s - loss: 3.2638 - accuracy1000: 0.3821 - val_loss: 3.2714 - val_accuracy1000: 0.3791 - 14s/epoch - 23ms/step
Epoch 14/50
634/634 - 14s - loss: 3.2572 - accuracy1000: 0.3876 - val_loss: 3.2727 - val_accuracy1000: 0.3800 - 14s/epoch - 22ms/step
Epoch 15/50
634/634 - 14s - loss: 3.2511 - accuracy1000: 0.3926 - val_loss: 3.2787 - val_accuracy1000: 0.3745 - 14s/epoch - 22ms/step
Epoch 16/50
634/634 - 14s - loss: 3.2437 - accuracy1000: 0.3956 - val_loss: 3.2774 - val_accuracy1000: 0.3764 - 14s/epoch - 22ms/step
Epoch 17/50
634/634 - 14s - loss: 3.2327 - accuracy1000: 0.4011 - val_loss: 3.2783 - val_accuracy1000: 0.3753 - 14s/epoch - 22ms/step
testing model: results/QRTEA/W4/deepOF_L2/h1000
Evaluating performance on  test set...
1613/1613 - 12s - 12s/epoch - 8ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0813383
{'0': {'precision': 0.40308416320013446, 'recall': 0.6032802143207516, 'f1-score': 0.48326968997793474, 'support': 159014}, '1': {'precision': 0.2885456885456886, 'recall': 0.011100108921675414, 'f1-score': 0.021377830750893924, 'support': 100990}, '2': {'precision': 0.39117973913552084, 'recall': 0.4375789218861431, 'f1-score': 0.4130804697802113, 'support': 152841}, 'accuracy': 0.397076384599547, 'macro avg': {'precision': 0.3609365302937813, 'recall': 0.3506530817095234, 'f1-score': 0.30590933016967997, 'support': 412845}, 'weighted avg': {'precision': 0.37065861696895297, 'recall': 0.397076384599547, 'f1-score': 0.34429683220424456, 'support': 412845}}
[[95930  1462 61622]
 [57401  1121 42468]
 [84659  1302 66880]]
Evaluating performance on  train set...
634/634 - 5s - 5s/epoch - 8ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1024182
{'0': {'precision': 0.36360969114278296, 'recall': 0.5859397730578993, 'f1-score': 0.44874624849417516, 'support': 54992}, '1': {'precision': 0.394873848618342, 'recall': 0.018308080808080808, 'f1-score': 0.03499370042411229, 'support': 53856}, '2': {'precision': 0.3591147005853219, 'recall': 0.4785143799917507, 'f1-score': 0.4103046378908448, 'support': 53338}, 'accuracy': 0.3621212681735785, 'macro avg': {'precision': 0.3725327467821489, 'recall': 0.36092074461924356, 'f1-score': 0.29801486226971075, 'support': 162186}, 'weighted avg': {'precision': 0.3725131024030018, 'recall': 0.3621212681735785, 'f1-score': 0.2987119924226169, 'support': 162186}}
[[32222   779 21991]
 [29312   986 23558]
 [27083   732 25523]]
Evaluating performance on  val set...
206/206 - 2s - 2s/epoch - 8ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0862999
{'0': {'precision': 0.401186477020942, 'recall': 0.5644326009351903, 'f1-score': 0.4690104656263709, 'support': 19889}, '1': {'precision': 0.2717889908256881, 'recall': 0.017198838896952104, 'f1-score': 0.03235053235053235, 'support': 13780}, '2': {'precision': 0.38609424083769633, 'recall': 0.48363064008394546, 'f1-score': 0.42939326889484103, 'support': 19060}, 'accuracy': 0.3922130137116198, 'macro avg': {'precision': 0.35302323622810877, 'recall': 0.3550873599720293, 'f1-score': 0.31025142229058145, 'support': 52729}, 'weighted avg': {'precision': 0.3619148166173072, 'recall': 0.3922130137116198, 'f1-score': 0.34057492445843646, 'support': 52729}}
[[11226   310  8353]
 [ 7239   237  6304]
 [ 9517   325  9218]]
training model: results/QRTEA/W4/deepVOL_L2/h10
Epoch 1/50
634/634 - 17s - loss: 2.7533 - accuracy10: 0.5594 - val_loss: 2.2615 - val_accuracy10: 0.5546 - 17s/epoch - 27ms/step
Epoch 2/50
634/634 - 14s - loss: 2.4785 - accuracy10: 0.6263 - val_loss: 2.2384 - val_accuracy10: 0.5227 - 14s/epoch - 22ms/step
Epoch 3/50
634/634 - 13s - loss: 2.3943 - accuracy10: 0.6501 - val_loss: 2.0896 - val_accuracy10: 0.5673 - 13s/epoch - 21ms/step
Epoch 4/50
634/634 - 14s - loss: 2.3303 - accuracy10: 0.6694 - val_loss: 2.0666 - val_accuracy10: 0.5934 - 14s/epoch - 21ms/step
Epoch 5/50
634/634 - 14s - loss: 2.3054 - accuracy10: 0.6741 - val_loss: 2.1238 - val_accuracy10: 0.5509 - 14s/epoch - 22ms/step
Epoch 6/50
634/634 - 14s - loss: 2.2796 - accuracy10: 0.6796 - val_loss: 2.0668 - val_accuracy10: 0.5888 - 14s/epoch - 21ms/step
Epoch 7/50
634/634 - 13s - loss: 2.2631 - accuracy10: 0.6847 - val_loss: 2.0956 - val_accuracy10: 0.5753 - 13s/epoch - 21ms/step
Epoch 8/50
634/634 - 14s - loss: 2.2512 - accuracy10: 0.6898 - val_loss: 2.0715 - val_accuracy10: 0.6081 - 14s/epoch - 21ms/step
Epoch 9/50
634/634 - 14s - loss: 2.2340 - accuracy10: 0.6917 - val_loss: 2.0694 - val_accuracy10: 0.6104 - 14s/epoch - 21ms/step
Epoch 10/50
634/634 - 14s - loss: 2.2224 - accuracy10: 0.6924 - val_loss: 2.0631 - val_accuracy10: 0.6217 - 14s/epoch - 22ms/step
Epoch 11/50
634/634 - 14s - loss: 2.2132 - accuracy10: 0.6943 - val_loss: 2.0462 - val_accuracy10: 0.6300 - 14s/epoch - 22ms/step
Epoch 12/50
634/634 - 13s - loss: 2.1984 - accuracy10: 0.6959 - val_loss: 2.0419 - val_accuracy10: 0.6472 - 13s/epoch - 21ms/step
Epoch 13/50
634/634 - 13s - loss: 2.1939 - accuracy10: 0.6951 - val_loss: 2.0448 - val_accuracy10: 0.6537 - 13s/epoch - 21ms/step
Epoch 14/50
634/634 - 13s - loss: 2.1794 - accuracy10: 0.6955 - val_loss: 2.0154 - val_accuracy10: 0.6739 - 13s/epoch - 21ms/step
Epoch 15/50
634/634 - 14s - loss: 2.1679 - accuracy10: 0.6970 - val_loss: 2.0789 - val_accuracy10: 0.6269 - 14s/epoch - 21ms/step
Epoch 16/50
634/634 - 13s - loss: 2.1595 - accuracy10: 0.6975 - val_loss: 2.0013 - val_accuracy10: 0.6819 - 13s/epoch - 21ms/step
Epoch 17/50
634/634 - 14s - loss: 2.1516 - accuracy10: 0.6976 - val_loss: 2.0055 - val_accuracy10: 0.6792 - 14s/epoch - 22ms/step
Epoch 18/50
634/634 - 13s - loss: 2.1458 - accuracy10: 0.6997 - val_loss: 2.0260 - val_accuracy10: 0.6820 - 13s/epoch - 21ms/step
Epoch 19/50
634/634 - 14s - loss: 2.1387 - accuracy10: 0.6991 - val_loss: 1.9888 - val_accuracy10: 0.6896 - 14s/epoch - 21ms/step
Epoch 20/50
634/634 - 13s - loss: 2.1298 - accuracy10: 0.6977 - val_loss: 1.9873 - val_accuracy10: 0.6968 - 13s/epoch - 21ms/step
Epoch 21/50
634/634 - 13s - loss: 2.1217 - accuracy10: 0.6980 - val_loss: 2.0194 - val_accuracy10: 0.6814 - 13s/epoch - 21ms/step
Epoch 22/50
634/634 - 13s - loss: 2.1108 - accuracy10: 0.6983 - val_loss: 2.0227 - val_accuracy10: 0.6809 - 13s/epoch - 21ms/step
Epoch 23/50
634/634 - 14s - loss: 2.1039 - accuracy10: 0.6998 - val_loss: 2.0036 - val_accuracy10: 0.7068 - 14s/epoch - 22ms/step
Epoch 24/50
634/634 - 13s - loss: 2.0966 - accuracy10: 0.7011 - val_loss: 2.0032 - val_accuracy10: 0.7018 - 13s/epoch - 21ms/step
Epoch 25/50
634/634 - 14s - loss: 2.0901 - accuracy10: 0.6998 - val_loss: 1.9991 - val_accuracy10: 0.6972 - 14s/epoch - 21ms/step
Epoch 26/50
634/634 - 14s - loss: 2.0793 - accuracy10: 0.7014 - val_loss: 2.0107 - val_accuracy10: 0.6958 - 14s/epoch - 21ms/step
Epoch 27/50
634/634 - 13s - loss: 2.0721 - accuracy10: 0.7013 - val_loss: 2.0052 - val_accuracy10: 0.7008 - 13s/epoch - 21ms/step
Epoch 28/50
634/634 - 14s - loss: 2.0566 - accuracy10: 0.7030 - val_loss: 1.9897 - val_accuracy10: 0.7150 - 14s/epoch - 22ms/step
Epoch 29/50
634/634 - 14s - loss: 2.0627 - accuracy10: 0.7018 - val_loss: 2.0340 - val_accuracy10: 0.6806 - 14s/epoch - 22ms/step
Epoch 30/50
634/634 - 13s - loss: 2.0514 - accuracy10: 0.7027 - val_loss: 2.0035 - val_accuracy10: 0.6887 - 13s/epoch - 21ms/step
testing model: results/QRTEA/W4/deepVOL_L2/h10
Evaluating performance on  test set...
1613/1613 - 14s - 14s/epoch - 9ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.7313415
{'0': {'precision': 0.22058111130579977, 'recall': 0.6336906312921947, 'f1-score': 0.32724992927756075, 'support': 33772}, '1': {'precision': 0.9440139218528489, 'recall': 0.6870420820774403, 'f1-score': 0.7952851267118003, 'support': 345040}, '2': {'precision': 0.3363672889108666, 'recall': 0.6395099450597879, 'f1-score': 0.44085509726680777, 'support': 34037}, 'accuracy': 0.6787590620299432, 'macro avg': {'precision': 0.5003207740231718, 'recall': 0.6534142194764743, 'f1-score': 0.5211300510853896, 'support': 412849}, 'weighted avg': {'precision': 0.83473851771419, 'recall': 0.6787590620299432, 'f1-score': 0.7277780730433443, 'support': 412849}}
[[ 21401   6234   6137]
 [ 71175 237057  36808]
 [  4445   7825  21767]]
Evaluating performance on  train set...
634/634 - 5s - 5s/epoch - 8ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.73009944
{'0': {'precision': 0.3018804974218987, 'recall': 0.6222180545136284, 'f1-score': 0.4065269779030348, 'support': 15996}, '1': {'precision': 0.9349394810262004, 'recall': 0.6852787195276644, 'f1-score': 0.7908738837453808, 'support': 130077}, '2': {'precision': 0.32107220877369075, 'recall': 0.6749829330354372, 'f1-score': 0.4351531398163523, 'support': 16113}, 'accuracy': 0.678036328659687, 'macro avg': {'precision': 0.5192973957405966, 'recall': 0.6608265690255767, 'f1-score': 0.5441846671549228, 'support': 162186}, 'weighted avg': {'precision': 0.8115154193961022, 'recall': 0.678036328659687, 'f1-score': 0.7176262455227068, 'support': 162186}}
[[ 9953  3068  2975]
 [20915 89139 20023]
 [ 2102  3135 10876]]
Evaluating performance on  val set...
206/206 - 2s - 2s/epoch - 8ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.69801474
{'0': {'precision': 0.26599019496066584, 'recall': 0.5836877658243683, 'f1-score': 0.36544486215538846, 'support': 3997}, '1': {'precision': 0.9455464799688837, 'recall': 0.7089053387169134, 'f1-score': 0.8103021678653385, 'support': 44580}, '2': {'precision': 0.26765375854214124, 'recall': 0.679027209246328, 'f1-score': 0.38396078698345704, 'support': 4153}, 'accuracy': 0.6970604968708515, 'macro avg': {'precision': 0.4930634778238969, 'recall': 0.6572067712625366, 'f1-score': 0.5199026056680612, 'support': 52730}, 'weighted avg': {'precision': 0.8406446225203136, 'recall': 0.6970604968708515, 'f1-score': 0.7430028997878658, 'support': 52730}}
[[ 2333   877   787]
 [ 6048 31603  6929]
 [  390   943  2820]]
training model: results/QRTEA/W4/deepVOL_L2/h20
Epoch 1/50
634/634 - 16s - loss: 2.8028 - accuracy20: 0.5453 - val_loss: 2.4405 - val_accuracy20: 0.4559 - 16s/epoch - 25ms/step
Epoch 2/50
634/634 - 14s - loss: 2.5534 - accuracy20: 0.6174 - val_loss: 2.3326 - val_accuracy20: 0.5087 - 14s/epoch - 22ms/step
Epoch 3/50
634/634 - 14s - loss: 2.4805 - accuracy20: 0.6282 - val_loss: 2.2863 - val_accuracy20: 0.5654 - 14s/epoch - 21ms/step
Epoch 4/50
634/634 - 14s - loss: 2.4395 - accuracy20: 0.6404 - val_loss: 2.3090 - val_accuracy20: 0.5572 - 14s/epoch - 21ms/step
Epoch 5/50
634/634 - 14s - loss: 2.4130 - accuracy20: 0.6462 - val_loss: 2.3164 - val_accuracy20: 0.5665 - 14s/epoch - 22ms/step
Epoch 6/50
634/634 - 14s - loss: 2.3955 - accuracy20: 0.6483 - val_loss: 2.2883 - val_accuracy20: 0.5654 - 14s/epoch - 23ms/step
Epoch 7/50
634/634 - 14s - loss: 2.3745 - accuracy20: 0.6531 - val_loss: 2.3065 - val_accuracy20: 0.5712 - 14s/epoch - 22ms/step
Epoch 8/50
634/634 - 13s - loss: 2.3631 - accuracy20: 0.6552 - val_loss: 2.3011 - val_accuracy20: 0.5591 - 13s/epoch - 21ms/step
Epoch 9/50
634/634 - 14s - loss: 2.3473 - accuracy20: 0.6587 - val_loss: 2.2383 - val_accuracy20: 0.5898 - 14s/epoch - 22ms/step
Epoch 10/50
634/634 - 13s - loss: 2.3389 - accuracy20: 0.6595 - val_loss: 2.2599 - val_accuracy20: 0.6088 - 13s/epoch - 21ms/step
Epoch 11/50
634/634 - 14s - loss: 2.3272 - accuracy20: 0.6615 - val_loss: 2.2995 - val_accuracy20: 0.5893 - 14s/epoch - 22ms/step
Epoch 12/50
634/634 - 13s - loss: 2.3141 - accuracy20: 0.6628 - val_loss: 2.2410 - val_accuracy20: 0.6154 - 13s/epoch - 21ms/step
Epoch 13/50
634/634 - 13s - loss: 2.3052 - accuracy20: 0.6663 - val_loss: 2.2246 - val_accuracy20: 0.6205 - 13s/epoch - 21ms/step
Epoch 14/50
634/634 - 13s - loss: 2.2971 - accuracy20: 0.6664 - val_loss: 2.2455 - val_accuracy20: 0.6371 - 13s/epoch - 21ms/step
Epoch 15/50
634/634 - 13s - loss: 2.2901 - accuracy20: 0.6676 - val_loss: 2.2270 - val_accuracy20: 0.6443 - 13s/epoch - 21ms/step
Epoch 16/50
634/634 - 13s - loss: 2.2860 - accuracy20: 0.6669 - val_loss: 2.2314 - val_accuracy20: 0.6431 - 13s/epoch - 21ms/step
Epoch 17/50
634/634 - 13s - loss: 2.2754 - accuracy20: 0.6692 - val_loss: 2.2076 - val_accuracy20: 0.6581 - 13s/epoch - 21ms/step
Epoch 18/50
634/634 - 14s - loss: 2.2679 - accuracy20: 0.6707 - val_loss: 2.2545 - val_accuracy20: 0.6406 - 14s/epoch - 22ms/step
Epoch 19/50
634/634 - 13s - loss: 2.2681 - accuracy20: 0.6714 - val_loss: 2.2129 - val_accuracy20: 0.6433 - 13s/epoch - 21ms/step
Epoch 20/50
634/634 - 13s - loss: 2.2479 - accuracy20: 0.6723 - val_loss: 2.2028 - val_accuracy20: 0.6512 - 13s/epoch - 21ms/step
Epoch 21/50
634/634 - 13s - loss: 2.2460 - accuracy20: 0.6739 - val_loss: 2.1968 - val_accuracy20: 0.6663 - 13s/epoch - 21ms/step
Epoch 22/50
634/634 - 13s - loss: 2.2370 - accuracy20: 0.6738 - val_loss: 2.2500 - val_accuracy20: 0.6449 - 13s/epoch - 21ms/step
Epoch 23/50
634/634 - 14s - loss: 2.2341 - accuracy20: 0.6720 - val_loss: 2.2143 - val_accuracy20: 0.6607 - 14s/epoch - 21ms/step
Epoch 24/50
634/634 - 14s - loss: 2.2233 - accuracy20: 0.6724 - val_loss: 2.1795 - val_accuracy20: 0.6697 - 14s/epoch - 21ms/step
Epoch 25/50
634/634 - 13s - loss: 2.2230 - accuracy20: 0.6720 - val_loss: 2.1879 - val_accuracy20: 0.6564 - 13s/epoch - 21ms/step
Epoch 26/50
634/634 - 13s - loss: 2.2093 - accuracy20: 0.6730 - val_loss: 2.2066 - val_accuracy20: 0.6555 - 13s/epoch - 21ms/step
Epoch 27/50
634/634 - 13s - loss: 2.2069 - accuracy20: 0.6749 - val_loss: 2.1812 - val_accuracy20: 0.6790 - 13s/epoch - 21ms/step
Epoch 28/50
634/634 - 13s - loss: 2.1960 - accuracy20: 0.6760 - val_loss: 2.1858 - val_accuracy20: 0.6672 - 13s/epoch - 21ms/step
Epoch 29/50
634/634 - 13s - loss: 2.1890 - accuracy20: 0.6757 - val_loss: 2.2054 - val_accuracy20: 0.6649 - 13s/epoch - 21ms/step
Epoch 30/50
634/634 - 13s - loss: 2.1836 - accuracy20: 0.6761 - val_loss: 2.2053 - val_accuracy20: 0.6735 - 13s/epoch - 21ms/step
Epoch 31/50
634/634 - 13s - loss: 2.1719 - accuracy20: 0.6778 - val_loss: 2.2043 - val_accuracy20: 0.6910 - 13s/epoch - 21ms/step
Epoch 32/50
634/634 - 13s - loss: 2.1641 - accuracy20: 0.6780 - val_loss: 2.2053 - val_accuracy20: 0.6634 - 13s/epoch - 21ms/step
Epoch 33/50
634/634 - 13s - loss: 2.1565 - accuracy20: 0.6769 - val_loss: 2.2093 - val_accuracy20: 0.6600 - 13s/epoch - 21ms/step
Epoch 34/50
634/634 - 13s - loss: 2.1476 - accuracy20: 0.6782 - val_loss: 2.2084 - val_accuracy20: 0.6644 - 13s/epoch - 21ms/step
testing model: results/QRTEA/W4/deepVOL_L2/h20
Evaluating performance on  test set...
1613/1613 - 13s - 13s/epoch - 8ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.7749313
{'0': {'precision': 0.27599763523499854, 'recall': 0.603750404138377, 'f1-score': 0.3788213814788518, 'support': 46395}, '1': {'precision': 0.9006407187373803, 'recall': 0.677299979649661, 'f1-score': 0.7731645949635813, 'support': 319405}, '2': {'precision': 0.4115373805508713, 'recall': 0.6224361835533168, 'f1-score': 0.4954783476723431, 'support': 47049}, 'accuracy': 0.6627822763286335, 'macro avg': {'precision': 0.52939191150775, 'recall': 0.6344955224471183, 'f1-score': 0.5491547747049254, 'support': 412849}, 'weighted avg': {'precision': 0.7747057187314942, 'recall': 0.6627822763286335, 'f1-score': 0.6972036173702494, 'support': 412849}}
[[ 28011  10389   7995]
 [ 69192 216333  33880]
 [  4287  13477  29285]]
Evaluating performance on  train set...
634/634 - 5s - 5s/epoch - 8ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.7687176
{'0': {'precision': 0.3667943886760189, 'recall': 0.5395221016349154, 'f1-score': 0.4366988387875132, 'support': 21469}, '1': {'precision': 0.8788332727000364, 'recall': 0.6902132808954773, 'f1-score': 0.773185977331777, 'support': 118998}, '2': {'precision': 0.3791219144526098, 'recall': 0.6484644781067268, 'f1-score': 0.4784942583406945, 'support': 21719}, 'accuracy': 0.6646751260897982, 'macro avg': {'precision': 0.5415831919428884, 'recall': 0.6260666202123731, 'f1-score': 0.5627930248199949, 'support': 162186}, 'weighted avg': {'precision': 0.744134878320204, 'recall': 0.6646751260897982, 'f1-score': 0.6891808731786804, 'support': 162186}}
[[11583  5506  4380]
 [18179 82134 18685]
 [ 1817  5818 14084]]
Evaluating performance on  val set...
206/206 - 2s - 2s/epoch - 8ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.7660171
{'0': {'precision': 0.2984869325997249, 'recall': 0.5581480801028844, 'f1-score': 0.3889635746751169, 'support': 5443}, '1': {'precision': 0.9029457266441449, 'recall': 0.6882038694773318, 'f1-score': 0.7810839967772331, 'support': 41556}, '2': {'precision': 0.3380825443515029, 'recall': 0.6417728145175362, 'f1-score': 0.44286574352799524, 'support': 5731}, 'accuracy': 0.6697326000379291, 'macro avg': {'precision': 0.5131717345317909, 'recall': 0.6293749213659176, 'f1-score': 0.5376377716601151, 'support': 52730}, 'weighted avg': {'precision': 0.7791585065852996, 'recall': 0.6697326000379291, 'f1-score': 0.7038482625296852, 'support': 52730}}
[[ 3038  1412   993]
 [ 6749 28599  6208]
 [  391  1662  3678]]
training model: results/QRTEA/W4/deepVOL_L2/h30
Epoch 1/50
634/634 - 19s - loss: 2.8811 - accuracy30: 0.5260 - val_loss: 2.5337 - val_accuracy30: 0.4981 - 19s/epoch - 29ms/step
Epoch 2/50
634/634 - 14s - loss: 2.6591 - accuracy30: 0.5957 - val_loss: 2.5330 - val_accuracy30: 0.4810 - 14s/epoch - 22ms/step
Epoch 3/50
634/634 - 14s - loss: 2.5948 - accuracy30: 0.6076 - val_loss: 2.5365 - val_accuracy30: 0.4705 - 14s/epoch - 22ms/step
Epoch 4/50
634/634 - 15s - loss: 2.5402 - accuracy30: 0.6194 - val_loss: 2.4622 - val_accuracy30: 0.4984 - 15s/epoch - 23ms/step
Epoch 5/50
634/634 - 15s - loss: 2.5141 - accuracy30: 0.6204 - val_loss: 2.4207 - val_accuracy30: 0.5045 - 15s/epoch - 24ms/step
Epoch 6/50
634/634 - 13s - loss: 2.4976 - accuracy30: 0.6237 - val_loss: 2.4282 - val_accuracy30: 0.5225 - 13s/epoch - 21ms/step
Epoch 7/50
634/634 - 15s - loss: 2.4796 - accuracy30: 0.6272 - val_loss: 2.4115 - val_accuracy30: 0.5378 - 15s/epoch - 23ms/step
Epoch 8/50
634/634 - 14s - loss: 2.4626 - accuracy30: 0.6325 - val_loss: 2.4102 - val_accuracy30: 0.5515 - 14s/epoch - 23ms/step
Epoch 9/50
634/634 - 15s - loss: 2.4495 - accuracy30: 0.6342 - val_loss: 2.3469 - val_accuracy30: 0.6019 - 15s/epoch - 23ms/step
Epoch 10/50
634/634 - 13s - loss: 2.4349 - accuracy30: 0.6376 - val_loss: 2.3532 - val_accuracy30: 0.6071 - 13s/epoch - 21ms/step
Epoch 11/50
634/634 - 14s - loss: 2.4226 - accuracy30: 0.6401 - val_loss: 2.3328 - val_accuracy30: 0.6214 - 14s/epoch - 23ms/step
Epoch 12/50
634/634 - 13s - loss: 2.4099 - accuracy30: 0.6422 - val_loss: 2.3646 - val_accuracy30: 0.6194 - 13s/epoch - 21ms/step
Epoch 13/50
634/634 - 13s - loss: 2.3988 - accuracy30: 0.6433 - val_loss: 2.3618 - val_accuracy30: 0.6181 - 13s/epoch - 21ms/step
Epoch 14/50
634/634 - 13s - loss: 2.3843 - accuracy30: 0.6447 - val_loss: 2.3385 - val_accuracy30: 0.6223 - 13s/epoch - 21ms/step
Epoch 15/50
634/634 - 14s - loss: 2.3776 - accuracy30: 0.6460 - val_loss: 2.3676 - val_accuracy30: 0.5990 - 14s/epoch - 22ms/step
Epoch 16/50
634/634 - 13s - loss: 2.3636 - accuracy30: 0.6473 - val_loss: 2.3870 - val_accuracy30: 0.5901 - 13s/epoch - 21ms/step
Epoch 17/50
634/634 - 14s - loss: 2.3528 - accuracy30: 0.6477 - val_loss: 2.4149 - val_accuracy30: 0.5951 - 14s/epoch - 22ms/step
Epoch 18/50
634/634 - 13s - loss: 2.3474 - accuracy30: 0.6467 - val_loss: 2.3845 - val_accuracy30: 0.5935 - 13s/epoch - 21ms/step
Epoch 19/50
634/634 - 13s - loss: 2.3345 - accuracy30: 0.6466 - val_loss: 2.4048 - val_accuracy30: 0.5996 - 13s/epoch - 21ms/step
Epoch 20/50
634/634 - 13s - loss: 2.3291 - accuracy30: 0.6483 - val_loss: 2.4157 - val_accuracy30: 0.5981 - 13s/epoch - 21ms/step
Epoch 21/50
634/634 - 13s - loss: 2.3158 - accuracy30: 0.6496 - val_loss: 2.4002 - val_accuracy30: 0.6125 - 13s/epoch - 21ms/step
testing model: results/QRTEA/W4/deepVOL_L2/h30
Evaluating performance on  test set...
1613/1613 - 18s - 18s/epoch - 11ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.8292569
{'0': {'precision': 0.2894709862620463, 'recall': 0.6083599669623299, 'f1-score': 0.39228444732607004, 'support': 55694}, '1': {'precision': 0.8601648835121001, 'recall': 0.6344064192123752, 'f1-score': 0.7302349813439982, 'support': 300473}, '2': {'precision': 0.4461652513815878, 'recall': 0.5839772767368829, 'f1-score': 0.5058530472522769, 'support': 56682}, 'accuracy': 0.6239690540609278, 'macro avg': {'precision': 0.5319337070519113, 'recall': 0.6089145543038627, 'f1-score': 0.5427908253074484, 'support': 412849}, 'weighted avg': {'precision': 0.7263373749996266, 'recall': 0.6239690540609278, 'f1-score': 0.6538384445235591, 'support': 412849}}
[[ 33882  13066   8746]
 [ 77508 190622  32343]
 [  5658  17923  33101]]
Evaluating performance on  train set...
634/634 - 6s - 6s/epoch - 10ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.8394382
{'0': {'precision': 0.38252416047718735, 'recall': 0.5202012323531706, 'f1-score': 0.4408639465899889, 'support': 25642}, '1': {'precision': 0.8321946499581107, 'recall': 0.6375635068433709, 'f1-score': 0.7219921685051057, 'support': 110618}, '2': {'precision': 0.3786647246758128, 'recall': 0.6217310807683407, 'f1-score': 0.47066896370485006, 'support': 25926}, 'accuracy': 0.6164773778254596, 'macro avg': {'precision': 0.5311278450370369, 'recall': 0.5931652733216274, 'f1-score': 0.5445083595999816, 'support': 162186}, 'weighted avg': {'precision': 0.6886023082384882, 'recall': 0.6164773778254596, 'f1-score': 0.637370220408483, 'support': 162186}}
[[13339  6933  5370]
 [19013 70526 21079]
 [ 2519  7288 16119]]
Evaluating performance on  val set...
206/206 - 3s - 3s/epoch - 14ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.831045
{'0': {'precision': 0.33252309188138063, 'recall': 0.5195199756949719, 'f1-score': 0.40550154138012806, 'support': 6583}, '1': {'precision': 0.8655943861599389, 'recall': 0.6350707276666242, 'f1-score': 0.732626688816689, 'support': 39235}, '2': {'precision': 0.32601215315908927, 'recall': 0.6442418981481481, 'f1-score': 0.43293957513003745, 'support': 6912}, 'accuracy': 0.6218471458372843, 'macro avg': {'precision': 0.5080432104001362, 'recall': 0.5996108671699147, 'f1-score': 0.5236892684422849, 'support': 52730}, 'weighted avg': {'precision': 0.7283138869234963, 'recall': 0.6218471458372843, 'f1-score': 0.6525033780756114, 'support': 52730}}
[[ 3420  1888  1275]
 [ 6387 24917  7931]
 [  478  1981  4453]]
training model: results/QRTEA/W4/deepVOL_L2/h50
Epoch 1/50
634/634 - 22s - loss: 3.0338 - accuracy50: 0.4824 - val_loss: 2.6873 - val_accuracy50: 0.4628 - 22s/epoch - 34ms/step
Epoch 2/50
634/634 - 15s - loss: 2.8274 - accuracy50: 0.5549 - val_loss: 2.6643 - val_accuracy50: 0.4820 - 15s/epoch - 24ms/step
Epoch 3/50
634/634 - 15s - loss: 2.7642 - accuracy50: 0.5696 - val_loss: 2.6357 - val_accuracy50: 0.5132 - 15s/epoch - 24ms/step
Epoch 4/50
634/634 - 14s - loss: 2.7194 - accuracy50: 0.5800 - val_loss: 2.6368 - val_accuracy50: 0.5246 - 14s/epoch - 22ms/step
Epoch 5/50
634/634 - 13s - loss: 2.6970 - accuracy50: 0.5828 - val_loss: 2.6601 - val_accuracy50: 0.5238 - 13s/epoch - 21ms/step
Epoch 6/50
634/634 - 15s - loss: 2.6746 - accuracy50: 0.5846 - val_loss: 2.5986 - val_accuracy50: 0.5572 - 15s/epoch - 24ms/step
Epoch 7/50
634/634 - 13s - loss: 2.6602 - accuracy50: 0.5885 - val_loss: 2.6110 - val_accuracy50: 0.5520 - 13s/epoch - 21ms/step
Epoch 8/50
634/634 - 13s - loss: 2.6444 - accuracy50: 0.5926 - val_loss: 2.6099 - val_accuracy50: 0.5545 - 13s/epoch - 21ms/step
Epoch 9/50
634/634 - 14s - loss: 2.6306 - accuracy50: 0.5946 - val_loss: 2.6018 - val_accuracy50: 0.5531 - 14s/epoch - 22ms/step
Epoch 10/50
634/634 - 14s - loss: 2.6215 - accuracy50: 0.5964 - val_loss: 2.6257 - val_accuracy50: 0.5348 - 14s/epoch - 22ms/step
Epoch 11/50
634/634 - 13s - loss: 2.6090 - accuracy50: 0.6005 - val_loss: 2.6184 - val_accuracy50: 0.5470 - 13s/epoch - 21ms/step
Epoch 12/50
634/634 - 14s - loss: 2.5942 - accuracy50: 0.6016 - val_loss: 2.6475 - val_accuracy50: 0.5367 - 14s/epoch - 22ms/step
Epoch 13/50
634/634 - 13s - loss: 2.5829 - accuracy50: 0.6042 - val_loss: 2.6401 - val_accuracy50: 0.5535 - 13s/epoch - 21ms/step
Epoch 14/50
634/634 - 13s - loss: 2.5735 - accuracy50: 0.6068 - val_loss: 2.6204 - val_accuracy50: 0.5675 - 13s/epoch - 21ms/step
Epoch 15/50
634/634 - 14s - loss: 2.5630 - accuracy50: 0.6069 - val_loss: 2.6539 - val_accuracy50: 0.5548 - 14s/epoch - 21ms/step
Epoch 16/50
634/634 - 14s - loss: 2.5500 - accuracy50: 0.6086 - val_loss: 2.6691 - val_accuracy50: 0.5351 - 14s/epoch - 22ms/step
testing model: results/QRTEA/W4/deepVOL_L2/h50
Evaluating performance on  test set...
1613/1613 - 15s - 15s/epoch - 10ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.93643165
{'0': {'precision': 0.30832161101650996, 'recall': 0.5814148296033619, 'f1-score': 0.40295698534569924, 'support': 71627}, '1': {'precision': 0.7805385977430693, 'recall': 0.5499716958646168, 'f1-score': 0.6452774373125166, 'support': 268512}, '2': {'precision': 0.4569786868960535, 'recall': 0.5567459771695777, 'f1-score': 0.5019529554726153, 'support': 72710}, 'accuracy': 0.5566199748576356, 'macro avg': {'precision': 0.515279631885211, 'recall': 0.5627108342125188, 'f1-score': 0.5167291260436104, 'support': 412849}, 'weighted avg': {'precision': 0.6416269684889114, 'recall': 0.5566199748576356, 'f1-score': 0.5779942173274701, 'support': 412849}}
[[ 41645  18298  11684]
 [ 84419 147674  36419]
 [  9006  23223  40481]]
Evaluating performance on  train set...
634/634 - 6s - 6s/epoch - 9ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.9397344
{'0': {'precision': 0.3928829666356781, 'recall': 0.4680222721260036, 'f1-score': 0.427173562072693, 'support': 32507}, '1': {'precision': 0.744862135615952, 'recall': 0.584468243159589, 'f1-score': 0.6549888135416848, 'support': 96924}, '2': {'precision': 0.40161150836339093, 'recall': 0.5812852999542054, 'f1-score': 0.4750261962975899, 'support': 32755}, 'accuracy': 0.5604861085420443, 'macro avg': {'precision': 0.513118870205007, 'recall': 0.5445919384132659, 'f1-score': 0.5190628573039893, 'support': 162186}, 'weighted avg': {'precision': 0.6049921028036291, 'recall': 0.5604861085420443, 'f1-score': 0.5729825620321042, 'support': 162186}}
[[15214  9210  8083]
 [19989 56649 20286]
 [ 3521 10194 19040]]
Evaluating performance on  val set...
206/206 - 3s - 3s/epoch - 13ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.9472412
{'0': {'precision': 0.3278540190016589, 'recall': 0.5086569957884886, 'f1-score': 0.3987161852361302, 'support': 8548}, '1': {'precision': 0.7885868701319345, 'recall': 0.5625832789952655, 'f1-score': 0.6566838195145358, 'support': 35273}, '2': {'precision': 0.36073825503355705, 'recall': 0.5791895835671793, 'f1-score': 0.4445784689613579, 'support': 8909}, 'accuracy': 0.556647069979139, 'macro avg': {'precision': 0.49239304805571676, 'recall': 0.5501432861169778, 'f1-score': 0.4999928245706746, 'support': 52730}, 'weighted avg': {'precision': 0.6416108086228687, 'recall': 0.556647069979139, 'f1-score': 0.5790287103567495, 'support': 52730}}
[[ 4348  2488  1712]
 [ 7997 19844  7432]
 [  917  2832  5160]]
training model: results/QRTEA/W4/deepVOL_L2/h100
Epoch 1/50
634/634 - 21s - loss: 3.1486 - accuracy100: 0.4486 - val_loss: 3.0678 - val_accuracy100: 0.4104 - 21s/epoch - 33ms/step
Epoch 2/50
634/634 - 15s - loss: 3.0275 - accuracy100: 0.4940 - val_loss: 3.0225 - val_accuracy100: 0.4412 - 15s/epoch - 23ms/step
Epoch 3/50
634/634 - 13s - loss: 2.9773 - accuracy100: 0.5094 - val_loss: 3.0252 - val_accuracy100: 0.4293 - 13s/epoch - 21ms/step
Epoch 4/50
634/634 - 14s - loss: 2.9515 - accuracy100: 0.5130 - val_loss: 3.0262 - val_accuracy100: 0.4374 - 14s/epoch - 22ms/step
Epoch 5/50
634/634 - 15s - loss: 2.9279 - accuracy100: 0.5190 - val_loss: 2.9961 - val_accuracy100: 0.4462 - 15s/epoch - 24ms/step
Epoch 6/50
634/634 - 13s - loss: 2.9058 - accuracy100: 0.5228 - val_loss: 3.0046 - val_accuracy100: 0.4379 - 13s/epoch - 21ms/step
Epoch 7/50
634/634 - 15s - loss: 2.8961 - accuracy100: 0.5244 - val_loss: 2.9627 - val_accuracy100: 0.4684 - 15s/epoch - 23ms/step
Epoch 8/50
634/634 - 13s - loss: 2.8814 - accuracy100: 0.5284 - val_loss: 2.9791 - val_accuracy100: 0.4608 - 13s/epoch - 21ms/step
Epoch 9/50
634/634 - 14s - loss: 2.8693 - accuracy100: 0.5316 - val_loss: 2.9845 - val_accuracy100: 0.4725 - 14s/epoch - 22ms/step
Epoch 10/50
634/634 - 15s - loss: 2.8549 - accuracy100: 0.5337 - val_loss: 2.9586 - val_accuracy100: 0.4949 - 15s/epoch - 23ms/step
Epoch 11/50
634/634 - 14s - loss: 2.8468 - accuracy100: 0.5364 - val_loss: 2.9850 - val_accuracy100: 0.4786 - 14s/epoch - 23ms/step
Epoch 12/50
634/634 - 14s - loss: 2.8375 - accuracy100: 0.5381 - val_loss: 3.0078 - val_accuracy100: 0.4694 - 14s/epoch - 23ms/step
Epoch 13/50
634/634 - 14s - loss: 2.8233 - accuracy100: 0.5395 - val_loss: 3.0110 - val_accuracy100: 0.4645 - 14s/epoch - 23ms/step
Epoch 14/50
634/634 - 15s - loss: 2.8098 - accuracy100: 0.5429 - val_loss: 3.0235 - val_accuracy100: 0.4666 - 15s/epoch - 23ms/step
Epoch 15/50
634/634 - 15s - loss: 2.7981 - accuracy100: 0.5466 - val_loss: 3.0333 - val_accuracy100: 0.4591 - 15s/epoch - 24ms/step
Epoch 16/50
634/634 - 15s - loss: 2.7898 - accuracy100: 0.5489 - val_loss: 3.0519 - val_accuracy100: 0.4514 - 15s/epoch - 23ms/step
Epoch 17/50
634/634 - 15s - loss: 2.7715 - accuracy100: 0.5514 - val_loss: 3.0765 - val_accuracy100: 0.4642 - 15s/epoch - 23ms/step
Epoch 18/50
634/634 - 15s - loss: 2.7624 - accuracy100: 0.5538 - val_loss: 3.0502 - val_accuracy100: 0.4842 - 15s/epoch - 24ms/step
Epoch 19/50
634/634 - 16s - loss: 2.7488 - accuracy100: 0.5564 - val_loss: 3.0490 - val_accuracy100: 0.4819 - 16s/epoch - 25ms/step
Epoch 20/50
634/634 - 14s - loss: 2.7353 - accuracy100: 0.5592 - val_loss: 3.0485 - val_accuracy100: 0.4766 - 14s/epoch - 23ms/step
testing model: results/QRTEA/W4/deepVOL_L2/h100
Evaluating performance on  test set...
1613/1613 - 15s - 15s/epoch - 9ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.011744
{'0': {'precision': 0.35515910713934734, 'recall': 0.5369566940053092, 'f1-score': 0.4275343173402632, 'support': 100956}, '1': {'precision': 0.6057678293820443, 'recall': 0.475521508656853, 'f1-score': 0.5328002820151263, 'support': 209776}, '2': {'precision': 0.47208615925646824, 'recall': 0.44169922735685535, 'f1-score': 0.4563874512422784, 'support': 102117}, 'accuracy': 0.48217871425145753, 'macro avg': {'precision': 0.47767103192595334, 'recall': 0.4847258100063392, 'f1-score': 0.47224068353255594, 'support': 412849}, 'weighted avg': {'precision': 0.5114194713360102, 'recall': 0.48217871425145753, 'f1-score': 0.48815858548747, 'support': 412849}}
[[54209 28491 18256]
 [77840 99753 32183]
 [20584 36428 45105]]
Evaluating performance on  train set...
634/634 - 6s - 6s/epoch - 9ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0005602
{'0': {'precision': 0.4491076204833925, 'recall': 0.4170994986676302, 'f1-score': 0.4325121768452604, 'support': 44282}, '1': {'precision': 0.5909283210443612, 'recall': 0.5314941903920636, 'f1-score': 0.5596376878993196, 'support': 73585}, '2': {'precision': 0.42441140024783147, 'recall': 0.5255082470272344, 'f1-score': 0.4695801199657241, 'support': 44319}, 'accuracy': 0.4986250354531217, 'macro avg': {'precision': 0.488149113925195, 'recall': 0.49136731202897604, 'f1-score': 0.487243328236768, 'support': 162186}, 'weighted avg': {'precision': 0.5067042346557566, 'recall': 0.4986250354531217, 'f1-score': 0.500319169446772, 'support': 162186}}
[[18470 12900 12912]
 [15801 39110 18674]
 [ 6855 14174 23290]]
Evaluating performance on  val set...
206/206 - 2s - 2s/epoch - 9ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0128783
{'0': {'precision': 0.406805758718916, 'recall': 0.42806221646143877, 'f1-score': 0.4171633837287333, 'support': 12344}, '1': {'precision': 0.6394520796480246, 'recall': 0.5101317122593718, 'f1-score': 0.5675180645291146, 'support': 27636}, '2': {'precision': 0.380072340906522, 'recall': 0.5274509803921569, 'f1-score': 0.44179477072657997, 'support': 12750}, 'accuracy': 0.49510714963019153, 'macro avg': {'precision': 0.47544339309115413, 'recall': 0.4885483030376558, 'f1-score': 0.4754920729948093, 'support': 52730}, 'weighted avg': {'precision': 0.5222725261774562, 'recall': 0.49510714963019153, 'f1-score': 0.501920678301498, 'support': 52730}}
[[ 5284  3824  3236]
 [ 5805 14098  7733]
 [ 1900  4125  6725]]
training model: results/QRTEA/W4/deepVOL_L2/h200
Epoch 1/50
634/634 - 17s - loss: 3.2453 - accuracy200: 0.4079 - val_loss: 3.3000 - val_accuracy200: 0.3725 - 17s/epoch - 27ms/step
Epoch 2/50
634/634 - 15s - loss: 3.1616 - accuracy200: 0.4369 - val_loss: 3.3030 - val_accuracy200: 0.3835 - 15s/epoch - 24ms/step
Epoch 3/50
634/634 - 15s - loss: 3.1365 - accuracy200: 0.4443 - val_loss: 3.1953 - val_accuracy200: 0.4259 - 15s/epoch - 23ms/step
Epoch 4/50
634/634 - 16s - loss: 3.1052 - accuracy200: 0.4513 - val_loss: 3.1741 - val_accuracy200: 0.4369 - 16s/epoch - 25ms/step
Epoch 5/50
634/634 - 14s - loss: 3.0823 - accuracy200: 0.4565 - val_loss: 3.1732 - val_accuracy200: 0.4423 - 14s/epoch - 23ms/step
Epoch 6/50
634/634 - 15s - loss: 3.0667 - accuracy200: 0.4631 - val_loss: 3.1717 - val_accuracy200: 0.4439 - 15s/epoch - 23ms/step
Epoch 7/50
634/634 - 14s - loss: 3.0490 - accuracy200: 0.4695 - val_loss: 3.1841 - val_accuracy200: 0.4380 - 14s/epoch - 23ms/step
Epoch 8/50
634/634 - 15s - loss: 3.0333 - accuracy200: 0.4744 - val_loss: 3.1902 - val_accuracy200: 0.4397 - 15s/epoch - 23ms/step
Epoch 9/50
634/634 - 15s - loss: 3.0133 - accuracy200: 0.4805 - val_loss: 3.2109 - val_accuracy200: 0.4319 - 15s/epoch - 23ms/step
Epoch 10/50
634/634 - 15s - loss: 2.9990 - accuracy200: 0.4852 - val_loss: 3.2288 - val_accuracy200: 0.4281 - 15s/epoch - 24ms/step
Epoch 11/50
634/634 - 14s - loss: 2.9864 - accuracy200: 0.4895 - val_loss: 3.2377 - val_accuracy200: 0.4282 - 14s/epoch - 23ms/step
Epoch 12/50
634/634 - 15s - loss: 2.9813 - accuracy200: 0.4914 - val_loss: 3.2440 - val_accuracy200: 0.4249 - 15s/epoch - 23ms/step
Epoch 13/50
634/634 - 15s - loss: 2.9682 - accuracy200: 0.4945 - val_loss: 3.2644 - val_accuracy200: 0.4309 - 15s/epoch - 23ms/step
Epoch 14/50
634/634 - 15s - loss: 2.9515 - accuracy200: 0.5010 - val_loss: 3.2598 - val_accuracy200: 0.4309 - 15s/epoch - 23ms/step
Epoch 15/50
634/634 - 14s - loss: 2.9400 - accuracy200: 0.5042 - val_loss: 3.3071 - val_accuracy200: 0.4268 - 14s/epoch - 23ms/step
Epoch 16/50
634/634 - 14s - loss: 2.9266 - accuracy200: 0.5084 - val_loss: 3.3170 - val_accuracy200: 0.4325 - 14s/epoch - 23ms/step
testing model: results/QRTEA/W4/deepVOL_L2/h200
Evaluating performance on  test set...
1613/1613 - 16s - 16s/epoch - 10ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0805202
{'0': {'precision': 0.36370717403007985, 'recall': 0.4946333712398548, 'f1-score': 0.41918491821458276, 'support': 128386}, '1': {'precision': 0.4158558643763226, 'recall': 0.4591507746929292, 'f1-score': 0.4364322137991786, 'support': 153222}, '2': {'precision': 0.49873322426997524, 'recall': 0.262486570507692, 'f1-score': 0.3439499985023513, 'support': 131241}, 'accuracy': 0.40766721004531925, 'macro avg': {'precision': 0.42609875422545923, 'recall': 0.40542357214682534, 'f1-score': 0.3998557101720375, 'support': 412849}, 'weighted avg': {'precision': 0.4259848602828408, 'recall': 0.40766721004531925, 'f1-score': 0.401669456208159, 'support': 412849}}
[[63504 46425 18457]
 [66703 70352 16167]
 [44395 52397 34449]]
Evaluating performance on  train set...
634/634 - 6s - 6s/epoch - 9ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0439851
{'0': {'precision': 0.4556214223145715, 'recall': 0.4116997386150278, 'f1-score': 0.4325484697577721, 'support': 54326}, '1': {'precision': 0.43370597940490413, 'recall': 0.5643089791990524, 'f1-score': 0.4904619442836003, 'support': 54036}, '2': {'precision': 0.46296945476641194, 'recall': 0.36805142687277054, 'f1-score': 0.410089739476054, 'support': 53824}, 'accuracy': 0.44805963523362063, 'macro avg': {'precision': 0.45076561882862914, 'recall': 0.44802004822895025, 'f1-score': 0.4443667178391421, 'support': 162186}, 'weighted avg': {'precision': 0.45075834921098096, 'recall': 0.44805963523362063, 'f1-score': 0.44439039082860715, 'support': 162186}}
[[22366 19140 12820]
 [13384 30493 10159]
 [13339 20675 19810]]
Evaluating performance on  val set...
206/206 - 2s - 2s/epoch - 9ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0573337
{'0': {'precision': 0.42012217031979876, 'recall': 0.3655349215281686, 'f1-score': 0.3909321920556373, 'support': 15993}, '1': {'precision': 0.4599357066317419, 'recall': 0.5741961056334539, 'f1-score': 0.5107536359629793, 'support': 20183}, '2': {'precision': 0.44338375679248054, 'recall': 0.364745680802223, 'f1-score': 0.4002386318440939, 'support': 16554}, 'accuracy': 0.44515456097098427, 'macro avg': {'precision': 0.44114721124800704, 'recall': 0.43482556932128186, 'f1-score': 0.43397481995423687, 'support': 52730}, 'weighted avg': {'precision': 0.4426639663723822, 'recall': 0.44515456097098427, 'f1-score': 0.43971684987168125, 'support': 52730}}
[[ 5846  6631  3516]
 [ 4530 11589  4064]
 [ 3539  6977  6038]]
training model: results/QRTEA/W4/deepVOL_L2/h300
Epoch 1/50
634/634 - 17s - loss: 3.3026 - accuracy300: 0.3777 - val_loss: 3.3118 - val_accuracy300: 0.3596 - 17s/epoch - 26ms/step
Epoch 2/50
634/634 - 14s - loss: 3.2587 - accuracy300: 0.3929 - val_loss: 3.2811 - val_accuracy300: 0.3657 - 14s/epoch - 23ms/step
Epoch 3/50
634/634 - 14s - loss: 3.2345 - accuracy300: 0.4064 - val_loss: 3.2816 - val_accuracy300: 0.3675 - 14s/epoch - 23ms/step
Epoch 4/50
634/634 - 15s - loss: 3.2233 - accuracy300: 0.4138 - val_loss: 3.2974 - val_accuracy300: 0.3741 - 15s/epoch - 23ms/step
Epoch 5/50
634/634 - 15s - loss: 3.2147 - accuracy300: 0.4176 - val_loss: 3.2782 - val_accuracy300: 0.3873 - 15s/epoch - 23ms/step
Epoch 6/50
634/634 - 15s - loss: 3.2006 - accuracy300: 0.4230 - val_loss: 3.2777 - val_accuracy300: 0.3929 - 15s/epoch - 23ms/step
Epoch 7/50
634/634 - 15s - loss: 3.1859 - accuracy300: 0.4307 - val_loss: 3.2900 - val_accuracy300: 0.3913 - 15s/epoch - 23ms/step
Epoch 8/50
634/634 - 14s - loss: 3.1702 - accuracy300: 0.4381 - val_loss: 3.3044 - val_accuracy300: 0.3922 - 14s/epoch - 23ms/step
Epoch 9/50
634/634 - 15s - loss: 3.1609 - accuracy300: 0.4418 - val_loss: 3.3218 - val_accuracy300: 0.3840 - 15s/epoch - 23ms/step
Epoch 10/50
634/634 - 15s - loss: 3.1414 - accuracy300: 0.4519 - val_loss: 3.3573 - val_accuracy300: 0.3823 - 15s/epoch - 23ms/step
Epoch 11/50
634/634 - 15s - loss: 3.1288 - accuracy300: 0.4563 - val_loss: 3.3688 - val_accuracy300: 0.3777 - 15s/epoch - 23ms/step
Epoch 12/50
634/634 - 15s - loss: 3.1179 - accuracy300: 0.4595 - val_loss: 3.3970 - val_accuracy300: 0.3749 - 15s/epoch - 24ms/step
Epoch 13/50
634/634 - 14s - loss: 3.1032 - accuracy300: 0.4654 - val_loss: 3.3929 - val_accuracy300: 0.3804 - 14s/epoch - 23ms/step
Epoch 14/50
634/634 - 15s - loss: 3.0900 - accuracy300: 0.4704 - val_loss: 3.4329 - val_accuracy300: 0.3735 - 15s/epoch - 24ms/step
Epoch 15/50
634/634 - 15s - loss: 3.0734 - accuracy300: 0.4753 - val_loss: 3.4810 - val_accuracy300: 0.3701 - 15s/epoch - 23ms/step
Epoch 16/50
634/634 - 15s - loss: 3.0605 - accuracy300: 0.4795 - val_loss: 3.4857 - val_accuracy300: 0.3653 - 15s/epoch - 23ms/step
testing model: results/QRTEA/W4/deepVOL_L2/h300
Evaluating performance on  test set...
1613/1613 - 14s - 14s/epoch - 8ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0992734
{'0': {'precision': 0.37351230706359434, 'recall': 0.4313940485353704, 'f1-score': 0.4003720065101139, 'support': 137714}, '1': {'precision': 0.374966730383024, 'recall': 0.3471705721582508, 'f1-score': 0.3605336931613294, 'support': 133914}, '2': {'precision': 0.42852850770759665, 'recall': 0.3938932595010657, 'f1-score': 0.41048157385952744, 'support': 141221}, 'accuracy': 0.39124716300632917, 'macro avg': {'precision': 0.39233584838473834, 'recall': 0.390819293398229, 'f1-score': 0.3904624245103236, 'support': 412849}, 'weighted avg': {'precision': 0.39280316283784783, 'recall': 0.39124716300632917, 'f1-score': 0.39090795383434723, 'support': 412849}}
[[59409 39977 38328]
 [51570 46491 35853]
 [48076 37519 55626]]
Evaluating performance on  train set...
634/634 - 6s - 6s/epoch - 9ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0799098
{'0': {'precision': 0.4348514586492997, 'recall': 0.35694408846252423, 'f1-score': 0.3920649922580386, 'support': 54622}, '1': {'precision': 0.41692293135260444, 'recall': 0.3295378056989006, 'f1-score': 0.3681154577163266, 'support': 53484}, '2': {'precision': 0.3975305024242101, 'recall': 0.5518676035502958, 'f1-score': 0.46215429403202324, 'support': 54080}, 'accuracy': 0.41290247000357616, 'macro avg': {'precision': 0.4164349641420381, 'recall': 0.4127831659039069, 'f1-score': 0.4074449146687962, 'support': 162186}, 'weighted avg': {'precision': 0.41649471597983817, 'recall': 0.41290247000357616, 'f1-score': 0.40753804501541696, 'support': 162186}}
[[19497 12818 22307]
 [12935 17625 22924]
 [12404 11831 29845]]
Evaluating performance on  val set...
206/206 - 2s - 2s/epoch - 9ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0925019
{'0': {'precision': 0.3859895179744593, 'recall': 0.3085137766239896, 'f1-score': 0.3429302203567681, 'support': 16949}, '1': {'precision': 0.3920115432544107, 'recall': 0.328424638716413, 'f1-score': 0.3574119476170544, 'support': 18199}, '2': {'precision': 0.3974348262032086, 'recall': 0.5410647252872256, 'f1-score': 0.45825906835589386, 'support': 17582}, 'accuracy': 0.39292622795372656, 'macro avg': {'precision': 0.3918119624773595, 'recall': 0.3926677135425427, 'f1-score': 0.38620041210990547, 'support': 52730}, 'weighted avg': {'precision': 0.39188419363058874, 'recall': 0.39292622795372656, 'f1-score': 0.38638299410853333, 'support': 52730}}
[[5229 4916 6804]
 [4603 5977 7619]
 [3715 4354 9513]]
training model: results/QRTEA/W4/deepVOL_L2/h500
Epoch 1/50
634/634 - 17s - loss: 3.2894 - accuracy500: 0.3846 - val_loss: 3.3116 - val_accuracy500: 0.3390 - 17s/epoch - 27ms/step
Epoch 2/50
634/634 - 15s - loss: 3.2776 - accuracy500: 0.3797 - val_loss: 3.3122 - val_accuracy500: 0.3449 - 15s/epoch - 24ms/step
Epoch 3/50
634/634 - 14s - loss: 3.2705 - accuracy500: 0.3855 - val_loss: 3.2986 - val_accuracy500: 0.3558 - 14s/epoch - 22ms/step
Epoch 4/50
634/634 - 15s - loss: 3.2598 - accuracy500: 0.3908 - val_loss: 3.2909 - val_accuracy500: 0.3573 - 15s/epoch - 23ms/step
Epoch 5/50
634/634 - 14s - loss: 3.2528 - accuracy500: 0.3958 - val_loss: 3.3055 - val_accuracy500: 0.3517 - 14s/epoch - 23ms/step
Epoch 6/50
634/634 - 14s - loss: 3.2435 - accuracy500: 0.4000 - val_loss: 3.3132 - val_accuracy500: 0.3495 - 14s/epoch - 23ms/step
Epoch 7/50
634/634 - 15s - loss: 3.2484 - accuracy500: 0.3967 - val_loss: 3.2951 - val_accuracy500: 0.3616 - 15s/epoch - 24ms/step
Epoch 8/50
634/634 - 15s - loss: 3.2335 - accuracy500: 0.4060 - val_loss: 3.3043 - val_accuracy500: 0.3625 - 15s/epoch - 23ms/step
Epoch 9/50
634/634 - 15s - loss: 3.2165 - accuracy500: 0.4133 - val_loss: 3.3102 - val_accuracy500: 0.3591 - 15s/epoch - 24ms/step
Epoch 10/50
634/634 - 14s - loss: 3.1979 - accuracy500: 0.4210 - val_loss: 3.3183 - val_accuracy500: 0.3597 - 14s/epoch - 23ms/step
Epoch 11/50
634/634 - 16s - loss: 3.1807 - accuracy500: 0.4310 - val_loss: 3.3403 - val_accuracy500: 0.3581 - 16s/epoch - 25ms/step
Epoch 12/50
634/634 - 15s - loss: 3.1712 - accuracy500: 0.4367 - val_loss: 3.3384 - val_accuracy500: 0.3574 - 15s/epoch - 24ms/step
Epoch 13/50
634/634 - 15s - loss: 3.1576 - accuracy500: 0.4407 - val_loss: 3.3548 - val_accuracy500: 0.3592 - 15s/epoch - 24ms/step
Epoch 14/50
634/634 - 16s - loss: 3.1574 - accuracy500: 0.4436 - val_loss: 3.3436 - val_accuracy500: 0.3469 - 16s/epoch - 25ms/step
testing model: results/QRTEA/W4/deepVOL_L2/h500
Evaluating performance on  test set...
1613/1613 - 17s - 17s/epoch - 11ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0994904
{'0': {'precision': 0.353735158161878, 'recall': 0.6898016897027113, 'f1-score': 0.4676540369544899, 'support': 141445}, '1': {'precision': 0.330412966429055, 'recall': 0.06506583435934032, 'f1-score': 0.10872185968498572, 'support': 127517}, '2': {'precision': 0.37513961738135876, 'recall': 0.2917775754585195, 'f1-score': 0.3282486317435497, 'support': 143887}, 'accuracy': 0.35811882794920175, 'macro avg': {'precision': 0.3530959139907639, 'recall': 0.3488816998401904, 'f1-score': 0.30154150946100844, 'support': 412849}, 'weighted avg': {'precision': 0.3539915412475074, 'recall': 0.35811882794920175, 'f1-score': 0.3082045045868157, 'support': 412849}}
[[97569  9286 34590]
 [83880  8297 35340]
 [94376  7528 41983]]
Evaluating performance on  train set...
634/634 - 5s - 5s/epoch - 9ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.096437
{'0': {'precision': 0.35547697068122197, 'recall': 0.6835559990391189, 'f1-score': 0.467720318624352, 'support': 54117}, '1': {'precision': 0.3592679794520548, 'recall': 0.06216896922108226, 'f1-score': 0.10599602159704462, 'support': 53998}, '2': {'precision': 0.36876524734004384, 'recall': 0.3326737067929204, 'f1-score': 0.34979095770539625, 'support': 54071}, 'accuracy': 0.35969195861541686, 'macro avg': {'precision': 0.36117006582444017, 'recall': 0.3594662250177072, 'f1-score': 0.30783576597559764, 'support': 162186}, 'weighted avg': {'precision': 0.3611693072505102, 'recall': 0.35969195861541686, 'f1-score': 0.3079719613978997, 'support': 162186}}
[[36992  3152 13973]
 [33823  3357 16818]
 [33248  2835 17988]]
Evaluating performance on  val set...
206/206 - 2s - 2s/epoch - 8ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0968199
{'0': {'precision': 0.348165519795106, 'recall': 0.64470601679904, 'f1-score': 0.4521519596056745, 'support': 17501}, '1': {'precision': 0.3419939577039275, 'recall': 0.09822409903395615, 'f1-score': 0.15261549523638326, 'support': 17287}, '2': {'precision': 0.39210834744107304, 'recall': 0.3356370527254487, 'f1-score': 0.3616816816816817, 'support': 17942}, 'accuracy': 0.36038308363360516, 'macro avg': {'precision': 0.36075594164670216, 'recall': 0.3595223895194816, 'f1-score': 0.3221497121745798, 'support': 52730}, 'weighted avg': {'precision': 0.361094296957134, 'recall': 0.36038308363360516, 'f1-score': 0.323168371779689, 'support': 52730}}
[[11283  1630  4588]
 [10841  1698  4748]
 [10283  1637  6022]]
training model: results/QRTEA/W4/deepVOL_L2/h1000
Epoch 1/50
634/634 - 18s - loss: 3.2850 - accuracy1000: 0.4003 - val_loss: 3.2920 - val_accuracy1000: 0.3701 - 18s/epoch - 28ms/step
Epoch 2/50
634/634 - 17s - loss: 3.2802 - accuracy1000: 0.3868 - val_loss: 3.2605 - val_accuracy1000: 0.3761 - 17s/epoch - 26ms/step
Epoch 3/50
634/634 - 16s - loss: 3.2962 - accuracy1000: 0.3604 - val_loss: 3.2864 - val_accuracy1000: 0.3841 - 16s/epoch - 25ms/step
Epoch 4/50
634/634 - 15s - loss: 3.2723 - accuracy1000: 0.3863 - val_loss: 3.2928 - val_accuracy1000: 0.3715 - 15s/epoch - 24ms/step
Epoch 5/50
634/634 - 14s - loss: 3.2848 - accuracy1000: 0.3659 - val_loss: 3.2902 - val_accuracy1000: 0.3758 - 14s/epoch - 23ms/step
Epoch 6/50
634/634 - 15s - loss: 3.2704 - accuracy1000: 0.3856 - val_loss: 3.2701 - val_accuracy1000: 0.3873 - 15s/epoch - 23ms/step
Epoch 7/50
634/634 - 15s - loss: 3.2472 - accuracy1000: 0.4032 - val_loss: 3.2895 - val_accuracy1000: 0.3690 - 15s/epoch - 24ms/step
Epoch 8/50
634/634 - 14s - loss: 3.2303 - accuracy1000: 0.4188 - val_loss: 3.2875 - val_accuracy1000: 0.3765 - 14s/epoch - 23ms/step
Epoch 9/50
634/634 - 15s - loss: 3.2177 - accuracy1000: 0.4240 - val_loss: 3.2924 - val_accuracy1000: 0.3680 - 15s/epoch - 24ms/step
Epoch 10/50
634/634 - 15s - loss: 3.2008 - accuracy1000: 0.4321 - val_loss: 3.3091 - val_accuracy1000: 0.3831 - 15s/epoch - 23ms/step
Epoch 11/50
634/634 - 14s - loss: 3.1756 - accuracy1000: 0.4423 - val_loss: 3.3282 - val_accuracy1000: 0.3800 - 14s/epoch - 23ms/step
Epoch 12/50
634/634 - 15s - loss: 3.1690 - accuracy1000: 0.4431 - val_loss: 3.3183 - val_accuracy1000: 0.3791 - 15s/epoch - 23ms/step
testing model: results/QRTEA/W4/deepVOL_L2/h1000
Evaluating performance on  test set...
1613/1613 - 17s - 17s/epoch - 11ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0807593
{'0': {'precision': 0.38799403241712394, 'recall': 0.3859737384917241, 'f1-score': 0.38698124866016825, 'support': 159016}, '1': {'precision': 0.23344947735191637, 'recall': 0.0006634188846641318, 'f1-score': 0.001323077834496786, 'support': 100992}, '2': {'precision': 0.3762570073985549, 'recall': 0.626206318985089, 'f1-score': 0.47007109266603636, 'support': 152841}, 'accuracy': 0.38065491257094, 'macro avg': {'precision': 0.3325668390558651, 'recall': 0.33761449212049244, 'f1-score': 0.2861251397202338, 'support': 412849}, 'weighted avg': {'precision': 0.34584384591792316, 'recall': 0.38065491257094, 'f1-score': 0.3234014528018149, 'support': 412849}}
[[61376    39 97601]
 [39862    67 61063]
 [56950   181 95710]]
Evaluating performance on  train set...
634/634 - 5s - 5s/epoch - 9ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.115062
{'0': {'precision': 0.3512807023312399, 'recall': 0.38858982286400173, 'f1-score': 0.36899457741857494, 'support': 54986}, '1': {'precision': 0.4722222222222222, 'recall': 0.0012629545707811747, 'f1-score': 0.0025191716370910975, 'support': 53842}, '2': {'precision': 0.3348087258931394, 'recall': 0.6351062633531992, 'f1-score': 0.4384696003208819, 'support': 53358}, 'accuracy': 0.3411083570715105, 'macro avg': {'precision': 0.38610388348220054, 'recall': 0.34165301359599404, 'f1-score': 0.2699944497921826, 'support': 162186}, 'weighted avg': {'precision': 0.3860113300992723, 'recall': 0.3411083570715105, 'f1-score': 0.27018999178192715, 'support': 162186}}
[[21367    29 33590]
 [20036    68 33738]
 [19423    47 33888]]
Evaluating performance on  val set...
206/206 - 2s - 2s/epoch - 8ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0869821
{'0': {'precision': 0.3923704366855665, 'recall': 0.3967112541486473, 'f1-score': 0.39452890578115624, 'support': 19886}, '1': {'precision': 0.125, 'recall': 7.258474268708717e-05, 'f1-score': 0.0001450852375770765, 'support': 13777}, '2': {'precision': 0.36825484424822175, 'recall': 0.6299365395709865, 'f1-score': 0.46479500029023085, 'support': 19067}, 'accuracy': 0.37741323724634934, 'macro avg': {'precision': 0.29520842697792943, 'recall': 0.342240126154107, 'f1-score': 0.28648966376965473, 'support': 52730}, 'weighted avg': {'precision': 0.313793260368102, 'recall': 0.37741323724634934, 'f1-score': 0.31689449896104693, 'support': 52730}}
[[ 7889     7 11990]
 [ 5161     1  8615]
 [ 7056     0 12011]]
training model: results/QRTEA/W4/deepVOL_L3/h10
Epoch 1/50
634/634 - 26s - loss: 3.1075 - accuracy10: 0.3712 - val_loss: 2.5276 - val_accuracy10: 0.6319 - 26s/epoch - 41ms/step
Epoch 2/50
634/634 - 23s - loss: 2.5701 - accuracy10: 0.6074 - val_loss: 2.1490 - val_accuracy10: 0.6104 - 23s/epoch - 37ms/step
Epoch 3/50
634/634 - 23s - loss: 2.3920 - accuracy10: 0.6602 - val_loss: 2.1009 - val_accuracy10: 0.6401 - 23s/epoch - 37ms/step
Epoch 4/50
634/634 - 23s - loss: 2.3186 - accuracy10: 0.6704 - val_loss: 2.0512 - val_accuracy10: 0.6569 - 23s/epoch - 37ms/step
Epoch 5/50
634/634 - 23s - loss: 2.2762 - accuracy10: 0.6805 - val_loss: 2.0211 - val_accuracy10: 0.6427 - 23s/epoch - 37ms/step
Epoch 6/50
634/634 - 25s - loss: 2.2561 - accuracy10: 0.6806 - val_loss: 2.0308 - val_accuracy10: 0.6393 - 25s/epoch - 39ms/step
Epoch 7/50
634/634 - 23s - loss: 2.2263 - accuracy10: 0.6876 - val_loss: 2.0041 - val_accuracy10: 0.6683 - 23s/epoch - 37ms/step
Epoch 8/50
634/634 - 23s - loss: 2.2070 - accuracy10: 0.6885 - val_loss: 1.9810 - val_accuracy10: 0.6741 - 23s/epoch - 36ms/step
Epoch 9/50
634/634 - 23s - loss: 2.1891 - accuracy10: 0.6925 - val_loss: 1.9643 - val_accuracy10: 0.6740 - 23s/epoch - 36ms/step
Epoch 10/50
634/634 - 23s - loss: 2.1748 - accuracy10: 0.6927 - val_loss: 1.9465 - val_accuracy10: 0.6918 - 23s/epoch - 37ms/step
Epoch 11/50
634/634 - 25s - loss: 2.1622 - accuracy10: 0.6936 - val_loss: 1.9844 - val_accuracy10: 0.6712 - 25s/epoch - 39ms/step
Epoch 12/50
634/634 - 25s - loss: 2.1494 - accuracy10: 0.6942 - val_loss: 1.9973 - val_accuracy10: 0.6664 - 25s/epoch - 39ms/step
Epoch 13/50
634/634 - 24s - loss: 2.1464 - accuracy10: 0.6937 - val_loss: 1.9590 - val_accuracy10: 0.6832 - 24s/epoch - 38ms/step
Epoch 14/50
634/634 - 23s - loss: 2.1362 - accuracy10: 0.6956 - val_loss: 1.9725 - val_accuracy10: 0.6737 - 23s/epoch - 37ms/step
Epoch 15/50
634/634 - 23s - loss: 2.1242 - accuracy10: 0.6942 - val_loss: 1.9559 - val_accuracy10: 0.6933 - 23s/epoch - 36ms/step
Epoch 16/50
634/634 - 23s - loss: 2.1124 - accuracy10: 0.6969 - val_loss: 1.9730 - val_accuracy10: 0.6744 - 23s/epoch - 37ms/step
Epoch 17/50
634/634 - 23s - loss: 2.1060 - accuracy10: 0.6966 - val_loss: 1.9773 - val_accuracy10: 0.6760 - 23s/epoch - 36ms/step
Epoch 18/50
634/634 - 24s - loss: 2.0987 - accuracy10: 0.6993 - val_loss: 1.9536 - val_accuracy10: 0.6750 - 24s/epoch - 37ms/step
Epoch 19/50
634/634 - 23s - loss: 2.0888 - accuracy10: 0.6985 - val_loss: 1.9619 - val_accuracy10: 0.6879 - 23s/epoch - 37ms/step
Epoch 20/50
634/634 - 23s - loss: 2.0828 - accuracy10: 0.6965 - val_loss: 1.9739 - val_accuracy10: 0.6802 - 23s/epoch - 37ms/step
testing model: results/QRTEA/W4/deepVOL_L3/h10
Evaluating performance on  test set...
1613/1613 - 25s - 25s/epoch - 16ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.7320983
{'0': {'precision': 0.23506556580864496, 'recall': 0.6162501480516405, 'f1-score': 0.3403183739544923, 'support': 33772}, '1': {'precision': 0.9503321106374542, 'recall': 0.694557152793879, 'f1-score': 0.8025585425684216, 'support': 345040}, '2': {'precision': 0.32618489817985225, 'recall': 0.6913065193759732, 'f1-score': 0.44323469022547896, 'support': 34037}, 'accuracy': 0.6878834634454728, 'macro avg': {'precision': 0.5038608582086505, 'recall': 0.6673712734071642, 'f1-score': 0.528703868916131, 'support': 412849}, 'weighted avg': {'precision': 0.8403643490045619, 'recall': 0.6878834634454728, 'f1-score': 0.7351220683693165, 'support': 412849}}
[[ 20812   5855   7105]
 [ 63888 239650  41502]
 [  3837   6670  23530]]
Evaluating performance on  train set...
634/634 - 10s - 10s/epoch - 16ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.8011118
{'0': {'precision': 0.29874411302982734, 'recall': 0.5948362090522631, 'f1-score': 0.39773439785980025, 'support': 15996}, '1': {'precision': 0.940105152939604, 'recall': 0.6488233892233062, 'f1-score': 0.767765441139681, 'support': 130077}, '2': {'precision': 0.28807751097085943, 'recall': 0.7251908396946565, 'f1-score': 0.4123511248345832, 'support': 16113}, 'accuracy': 0.6510857903888129, 'macro avg': {'precision': 0.5089755923134303, 'recall': 0.6562834793234086, 'f1-score': 0.5259503212780215, 'support': 162186}, 'weighted avg': {'precision': 0.8120710896453667, 'recall': 0.6510857903888129, 'f1-score': 0.6959601839230962, 'support': 162186}}
[[ 9515  2771  3710]
 [20513 84397 25167]
 [ 1822  2606 11685]]
Evaluating performance on  val set...
206/206 - 3s - 3s/epoch - 16ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.7280065
{'0': {'precision': 0.2766812865497076, 'recall': 0.5681761320990744, 'f1-score': 0.37214256452273653, 'support': 3997}, '1': {'precision': 0.9504021447721179, 'recall': 0.6997756841633019, 'f1-score': 0.8060565345460182, 'support': 44580}, '2': {'precision': 0.2588476662677381, 'recall': 0.7291114856730074, 'f1-score': 0.3820579143271718, 'support': 4153}, 'accuracy': 0.6921107528920918, 'macro avg': {'precision': 0.4953103658631879, 'recall': 0.6656877673117946, 'f1-score': 0.5200856711319756, 'support': 52730}, 'weighted avg': {'precision': 0.8448666238249594, 'recall': 0.6921107528920918, 'f1-score': 0.73977130018319, 'support': 52730}}
[[ 2271   839   887]
 [ 5601 31196  7783]
 [  336   789  3028]]
training model: results/QRTEA/W4/deepVOL_L3/h20
Epoch 1/50
634/634 - 26s - loss: 3.1718 - accuracy20: 0.3821 - val_loss: 2.6284 - val_accuracy20: 0.3637 - 26s/epoch - 41ms/step
Epoch 2/50
634/634 - 25s - loss: 2.8171 - accuracy20: 0.4433 - val_loss: 2.3531 - val_accuracy20: 0.5077 - 25s/epoch - 40ms/step
Epoch 3/50
634/634 - 25s - loss: 2.5525 - accuracy20: 0.6107 - val_loss: 2.2173 - val_accuracy20: 0.5893 - 25s/epoch - 39ms/step
Epoch 4/50
634/634 - 24s - loss: 2.4589 - accuracy20: 0.6342 - val_loss: 2.1743 - val_accuracy20: 0.6111 - 24s/epoch - 37ms/step
Epoch 5/50
634/634 - 24s - loss: 2.4115 - accuracy20: 0.6422 - val_loss: 2.1886 - val_accuracy20: 0.6055 - 24s/epoch - 37ms/step
Epoch 6/50
634/634 - 24s - loss: 2.3805 - accuracy20: 0.6452 - val_loss: 2.1418 - val_accuracy20: 0.6463 - 24s/epoch - 38ms/step
Epoch 7/50
634/634 - 24s - loss: 2.3551 - accuracy20: 0.6525 - val_loss: 2.1624 - val_accuracy20: 0.6273 - 24s/epoch - 37ms/step
Epoch 8/50
634/634 - 24s - loss: 2.3365 - accuracy20: 0.6557 - val_loss: 2.1290 - val_accuracy20: 0.6465 - 24s/epoch - 38ms/step
Epoch 9/50
634/634 - 23s - loss: 2.3175 - accuracy20: 0.6592 - val_loss: 2.1104 - val_accuracy20: 0.6582 - 23s/epoch - 36ms/step
Epoch 10/50
634/634 - 23s - loss: 2.2988 - accuracy20: 0.6620 - val_loss: 2.1216 - val_accuracy20: 0.6679 - 23s/epoch - 37ms/step
Epoch 11/50
634/634 - 23s - loss: 2.2858 - accuracy20: 0.6641 - val_loss: 2.1165 - val_accuracy20: 0.6577 - 23s/epoch - 37ms/step
Epoch 12/50
634/634 - 24s - loss: 2.2779 - accuracy20: 0.6627 - val_loss: 2.0965 - val_accuracy20: 0.6709 - 24s/epoch - 37ms/step
Epoch 13/50
634/634 - 23s - loss: 2.2613 - accuracy20: 0.6658 - val_loss: 2.0954 - val_accuracy20: 0.6770 - 23s/epoch - 37ms/step
Epoch 14/50
634/634 - 24s - loss: 2.2500 - accuracy20: 0.6689 - val_loss: 2.1058 - val_accuracy20: 0.6652 - 24s/epoch - 38ms/step
Epoch 15/50
634/634 - 23s - loss: 2.2412 - accuracy20: 0.6689 - val_loss: 2.0839 - val_accuracy20: 0.6721 - 23s/epoch - 37ms/step
Epoch 16/50
634/634 - 24s - loss: 2.2287 - accuracy20: 0.6696 - val_loss: 2.0974 - val_accuracy20: 0.6765 - 24s/epoch - 37ms/step
Epoch 17/50
634/634 - 24s - loss: 2.2181 - accuracy20: 0.6709 - val_loss: 2.0857 - val_accuracy20: 0.6817 - 24s/epoch - 38ms/step
Epoch 18/50
634/634 - 24s - loss: 2.2071 - accuracy20: 0.6719 - val_loss: 2.0869 - val_accuracy20: 0.6912 - 24s/epoch - 37ms/step
Epoch 19/50
634/634 - 23s - loss: 2.1957 - accuracy20: 0.6721 - val_loss: 2.1037 - val_accuracy20: 0.6788 - 23s/epoch - 37ms/step
Epoch 20/50
634/634 - 24s - loss: 2.1868 - accuracy20: 0.6727 - val_loss: 2.0897 - val_accuracy20: 0.6808 - 24s/epoch - 37ms/step
Epoch 21/50
634/634 - 23s - loss: 2.1740 - accuracy20: 0.6754 - val_loss: 2.1106 - val_accuracy20: 0.6661 - 23s/epoch - 37ms/step
Epoch 22/50
634/634 - 24s - loss: 2.1599 - accuracy20: 0.6752 - val_loss: 2.1036 - val_accuracy20: 0.6870 - 24s/epoch - 38ms/step
Epoch 23/50
634/634 - 23s - loss: 2.1526 - accuracy20: 0.6763 - val_loss: 2.1117 - val_accuracy20: 0.6718 - 23s/epoch - 37ms/step
Epoch 24/50
634/634 - 24s - loss: 2.1430 - accuracy20: 0.6763 - val_loss: 2.1108 - val_accuracy20: 0.6587 - 24s/epoch - 37ms/step
Epoch 25/50
634/634 - 23s - loss: 2.1358 - accuracy20: 0.6747 - val_loss: 2.1150 - val_accuracy20: 0.6701 - 23s/epoch - 37ms/step
testing model: results/QRTEA/W4/deepVOL_L3/h20
Evaluating performance on  test set...
1613/1613 - 26s - 26s/epoch - 16ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.7483491
{'0': {'precision': 0.28355359765051397, 'recall': 0.6243129647591336, 'f1-score': 0.3899828334848026, 'support': 46395}, '1': {'precision': 0.9107162388416332, 'recall': 0.677791518604906, 'f1-score': 0.7771768688556664, 'support': 319405}, '2': {'precision': 0.4160306912379256, 'recall': 0.6453697209292439, 'f1-score': 0.505923321725511, 'support': 47049}, 'accuracy': 0.6680868792221853, 'macro avg': {'precision': 0.5367668425766908, 'recall': 0.6491580680977612, 'f1-score': 0.5576943413553267, 'support': 412849}, 'weighted avg': {'precision': 0.7838619384381714, 'recall': 0.6680868792221853, 'f1-score': 0.702752380943723, 'support': 412849}}
[[ 28965   9061   8369]
 [ 68663 216490  34252]
 [  4522  12163  30364]]
Evaluating performance on  train set...
634/634 - 10s - 10s/epoch - 16ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.8044171
{'0': {'precision': 0.34237044808260403, 'recall': 0.5776235502352228, 'f1-score': 0.4299185300745363, 'support': 21469}, '1': {'precision': 0.8974021508436192, 'recall': 0.6360274962604413, 'f1-score': 0.7444390347059315, 'support': 118998}, '2': {'precision': 0.36184115696920194, 'recall': 0.6934941756066118, 'f1-score': 0.47555450311784675, 'support': 21719}, 'accuracy': 0.6359920091746514, 'macro avg': {'precision': 0.5338712519651417, 'recall': 0.635715074034092, 'f1-score': 0.5499706892994382, 'support': 162186}, 'weighted avg': {'precision': 0.7522119072188013, 'recall': 0.6359920091746514, 'f1-score': 0.6667976608790104, 'support': 162186}}
[[12401  4154  4914]
 [21662 75686 21650]
 [ 2158  4499 15062]]
Evaluating performance on  val set...
206/206 - 3s - 3s/epoch - 16ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.7453951
{'0': {'precision': 0.31788609748773894, 'recall': 0.5835017453610142, 'f1-score': 0.4115588959440196, 'support': 5443}, '1': {'precision': 0.9122896644209585, 'recall': 0.6875541438059486, 'f1-score': 0.7841372212692967, 'support': 41556}, '2': {'precision': 0.3318739054290718, 'recall': 0.6613156517187228, 'f1-score': 0.4419567372164888, 'support': 5731}, 'accuracy': 0.6739616916366394, 'macro avg': {'precision': 0.5206832224459231, 'recall': 0.6441238469618952, 'f1-score': 0.545884284809935, 'support': 52730}, 'weighted avg': {'precision': 0.7878500412538807, 'recall': 0.6739616916366394, 'f1-score': 0.7084880617993152, 'support': 52730}}
[[ 3176  1237  1030]
 [ 6384 28572  6600]
 [  431  1510  3790]]
training model: results/QRTEA/W4/deepVOL_L3/h30
Epoch 1/50
634/634 - 27s - loss: 3.1961 - accuracy30: 0.3706 - val_loss: 2.6821 - val_accuracy30: 0.2969 - 27s/epoch - 42ms/step
Epoch 2/50
634/634 - 24s - loss: 2.9245 - accuracy30: 0.3936 - val_loss: 2.5624 - val_accuracy30: 0.4365 - 24s/epoch - 37ms/step
Epoch 3/50
634/634 - 26s - loss: 2.6710 - accuracy30: 0.5723 - val_loss: 2.3941 - val_accuracy30: 0.5859 - 26s/epoch - 40ms/step
Epoch 4/50
634/634 - 25s - loss: 2.5719 - accuracy30: 0.6103 - val_loss: 2.3255 - val_accuracy30: 0.6075 - 25s/epoch - 40ms/step
Epoch 5/50
634/634 - 23s - loss: 2.5065 - accuracy30: 0.6278 - val_loss: 2.3104 - val_accuracy30: 0.6212 - 23s/epoch - 37ms/step
Epoch 6/50
634/634 - 23s - loss: 2.4717 - accuracy30: 0.6321 - val_loss: 2.2851 - val_accuracy30: 0.6131 - 23s/epoch - 37ms/step
Epoch 7/50
634/634 - 23s - loss: 2.4519 - accuracy30: 0.6350 - val_loss: 2.2938 - val_accuracy30: 0.6343 - 23s/epoch - 36ms/step
Epoch 8/50
634/634 - 25s - loss: 2.4283 - accuracy30: 0.6374 - val_loss: 2.2596 - val_accuracy30: 0.6569 - 25s/epoch - 39ms/step
Epoch 9/50
634/634 - 23s - loss: 2.4126 - accuracy30: 0.6412 - val_loss: 2.2791 - val_accuracy30: 0.6401 - 23s/epoch - 36ms/step
Epoch 10/50
634/634 - 23s - loss: 2.4037 - accuracy30: 0.6411 - val_loss: 2.2601 - val_accuracy30: 0.6614 - 23s/epoch - 36ms/step
Epoch 11/50
634/634 - 25s - loss: 2.3836 - accuracy30: 0.6424 - val_loss: 2.2742 - val_accuracy30: 0.6493 - 25s/epoch - 39ms/step
Epoch 12/50
634/634 - 23s - loss: 2.3716 - accuracy30: 0.6459 - val_loss: 2.2764 - val_accuracy30: 0.6370 - 23s/epoch - 36ms/step
Epoch 13/50
634/634 - 24s - loss: 2.3583 - accuracy30: 0.6452 - val_loss: 2.2482 - val_accuracy30: 0.6404 - 24s/epoch - 37ms/step
Epoch 14/50
634/634 - 23s - loss: 2.3489 - accuracy30: 0.6478 - val_loss: 2.2589 - val_accuracy30: 0.6634 - 23s/epoch - 37ms/step
Epoch 15/50
634/634 - 24s - loss: 2.3371 - accuracy30: 0.6497 - val_loss: 2.2592 - val_accuracy30: 0.6616 - 24s/epoch - 37ms/step
Epoch 16/50
634/634 - 24s - loss: 2.3265 - accuracy30: 0.6495 - val_loss: 2.2672 - val_accuracy30: 0.6532 - 24s/epoch - 37ms/step
Epoch 17/50
634/634 - 23s - loss: 2.3145 - accuracy30: 0.6506 - val_loss: 2.2595 - val_accuracy30: 0.6461 - 23s/epoch - 37ms/step
Epoch 18/50
634/634 - 24s - loss: 2.3036 - accuracy30: 0.6515 - val_loss: 2.2584 - val_accuracy30: 0.6668 - 24s/epoch - 37ms/step
Epoch 19/50
634/634 - 23s - loss: 2.3013 - accuracy30: 0.6508 - val_loss: 2.2611 - val_accuracy30: 0.6587 - 23s/epoch - 37ms/step
Epoch 20/50
634/634 - 23s - loss: 2.3144 - accuracy30: 0.6453 - val_loss: 2.2531 - val_accuracy30: 0.6462 - 23s/epoch - 37ms/step
Epoch 21/50
634/634 - 23s - loss: 2.3103 - accuracy30: 0.6502 - val_loss: 2.2631 - val_accuracy30: 0.6612 - 23s/epoch - 37ms/step
Epoch 22/50
634/634 - 23s - loss: 2.2805 - accuracy30: 0.6531 - val_loss: 2.2851 - val_accuracy30: 0.6634 - 23s/epoch - 37ms/step
Epoch 23/50
634/634 - 25s - loss: 2.2716 - accuracy30: 0.6522 - val_loss: 2.2688 - val_accuracy30: 0.6726 - 25s/epoch - 39ms/step
testing model: results/QRTEA/W4/deepVOL_L3/h30
Evaluating performance on  test set...
1613/1613 - 25s - 25s/epoch - 16ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.85376364
{'0': {'precision': 0.28459885677220575, 'recall': 0.6302474234208353, 'f1-score': 0.3921264152735031, 'support': 55694}, '1': {'precision': 0.8700233596225455, 'recall': 0.625966392987057, 'f1-score': 0.7280870517828042, 'support': 300473}, '2': {'precision': 0.46967775368544507, 'recall': 0.6076179386754172, 'f1-score': 0.5298167078170309, 'support': 56682}, 'accuracy': 0.6240247645022756, 'macro avg': {'precision': 0.5414333233600654, 'recall': 0.6212772516944365, 'f1-score': 0.5500100582911127, 'support': 412849}, 'weighted avg': {'precision': 0.7360832946170022, 'recall': 0.6240247645022756, 'f1-score': 0.6555439395882319, 'support': 412849}}
[[ 35101  11575   9018]
 [ 82517 188086  29870]
 [  5717  16524  34441]]
Evaluating performance on  train set...
634/634 - 10s - 10s/epoch - 16ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.838885
{'0': {'precision': 0.37381464658538527, 'recall': 0.5488261446065049, 'f1-score': 0.444721831597908, 'support': 25642}, '1': {'precision': 0.8524097507668236, 'recall': 0.6205319206639064, 'f1-score': 0.7182191529990322, 'support': 110618}, '2': {'precision': 0.39312005816595474, 'recall': 0.6673609503972846, 'f1-score': 0.49478109182418717, 'support': 25926}, 'accuracy': 0.6166808479153565, 'macro avg': {'precision': 0.5397814851727212, 'recall': 0.6122396718892319, 'f1-score': 0.5525740254737092, 'support': 162186}, 'weighted avg': {'precision': 0.7033236383293101, 'recall': 0.6166808479153565, 'f1-score': 0.6392612066325969, 'support': 162186}}
[[14073  5661  5908]
 [21174 68642 20802]
 [ 2400  6224 17302]]
Evaluating performance on  val set...
206/206 - 3s - 3s/epoch - 16ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.8143939
{'0': {'precision': 0.3362763915547025, 'recall': 0.5322801154488835, 'f1-score': 0.412162559548315, 'support': 6583}, '1': {'precision': 0.871082957072579, 'recall': 0.6589014910156747, 'f1-score': 0.7502793377156705, 'support': 39235}, '2': {'precision': 0.34974667511082963, 'recall': 0.6391782407407407, 'f1-score': 0.45210806385591484, 'support': 6912}, 'accuracy': 0.6405082495732979, 'macro avg': {'precision': 0.519035341246037, 'recall': 0.610119949068433, 'f1-score': 0.5381833203733001, 'support': 52730}, 'weighted avg': {'precision': 0.7359775521470376, 'recall': 0.6405082495732979, 'f1-score': 0.6689824934980652, 'support': 52730}}
[[ 3504  1753  1326]
 [ 6495 25852  6888]
 [  421  2073  4418]]
training model: results/QRTEA/W4/deepVOL_L3/h50
Epoch 1/50
634/634 - 26s - loss: 3.2380 - accuracy50: 0.4013 - val_loss: 2.8440 - val_accuracy50: 0.4213 - 26s/epoch - 41ms/step
Epoch 2/50
634/634 - 23s - loss: 3.0190 - accuracy50: 0.4377 - val_loss: 2.6962 - val_accuracy50: 0.4829 - 23s/epoch - 37ms/step
Epoch 3/50
634/634 - 24s - loss: 2.8498 - accuracy50: 0.5393 - val_loss: 2.6322 - val_accuracy50: 0.5227 - 24s/epoch - 37ms/step
Epoch 4/50
634/634 - 24s - loss: 2.7695 - accuracy50: 0.5675 - val_loss: 2.6156 - val_accuracy50: 0.5462 - 24s/epoch - 37ms/step
Epoch 5/50
634/634 - 23s - loss: 2.7245 - accuracy50: 0.5753 - val_loss: 2.5568 - val_accuracy50: 0.5784 - 23s/epoch - 37ms/step
Epoch 6/50
634/634 - 25s - loss: 2.6924 - accuracy50: 0.5838 - val_loss: 2.5562 - val_accuracy50: 0.5786 - 25s/epoch - 39ms/step
Epoch 7/50
634/634 - 26s - loss: 2.6626 - accuracy50: 0.5880 - val_loss: 2.5326 - val_accuracy50: 0.5791 - 26s/epoch - 40ms/step
Epoch 8/50
634/634 - 24s - loss: 2.6429 - accuracy50: 0.5917 - val_loss: 2.5310 - val_accuracy50: 0.5783 - 24s/epoch - 37ms/step
Epoch 9/50
634/634 - 23s - loss: 2.6298 - accuracy50: 0.5936 - val_loss: 2.5119 - val_accuracy50: 0.5998 - 23s/epoch - 37ms/step
Epoch 10/50
634/634 - 24s - loss: 2.6102 - accuracy50: 0.5984 - val_loss: 2.4982 - val_accuracy50: 0.5909 - 24s/epoch - 37ms/step
Epoch 11/50
634/634 - 23s - loss: 2.5965 - accuracy50: 0.6020 - val_loss: 2.5190 - val_accuracy50: 0.5787 - 23s/epoch - 36ms/step
Epoch 12/50
634/634 - 23s - loss: 2.5820 - accuracy50: 0.6038 - val_loss: 2.5305 - val_accuracy50: 0.5755 - 23s/epoch - 36ms/step
Epoch 13/50
634/634 - 24s - loss: 2.5730 - accuracy50: 0.6067 - val_loss: 2.5147 - val_accuracy50: 0.5887 - 24s/epoch - 37ms/step
Epoch 14/50
634/634 - 23s - loss: 2.5631 - accuracy50: 0.6083 - val_loss: 2.5099 - val_accuracy50: 0.5935 - 23s/epoch - 36ms/step
Epoch 15/50
634/634 - 23s - loss: 2.5521 - accuracy50: 0.6093 - val_loss: 2.5131 - val_accuracy50: 0.5723 - 23s/epoch - 37ms/step
Epoch 16/50
634/634 - 23s - loss: 2.5449 - accuracy50: 0.6093 - val_loss: 2.4937 - val_accuracy50: 0.6010 - 23s/epoch - 37ms/step
Epoch 17/50
634/634 - 25s - loss: 2.5349 - accuracy50: 0.6117 - val_loss: 2.5267 - val_accuracy50: 0.5688 - 25s/epoch - 39ms/step
Epoch 18/50
634/634 - 25s - loss: 2.5309 - accuracy50: 0.6105 - val_loss: 2.5099 - val_accuracy50: 0.5835 - 25s/epoch - 40ms/step
Epoch 19/50
634/634 - 24s - loss: 2.5212 - accuracy50: 0.6125 - val_loss: 2.5196 - val_accuracy50: 0.5821 - 24s/epoch - 38ms/step
Epoch 20/50
634/634 - 24s - loss: 2.5140 - accuracy50: 0.6138 - val_loss: 2.5382 - val_accuracy50: 0.5606 - 24s/epoch - 37ms/step
Epoch 21/50
634/634 - 23s - loss: 2.5051 - accuracy50: 0.6130 - val_loss: 2.5229 - val_accuracy50: 0.5794 - 23s/epoch - 37ms/step
Epoch 22/50
634/634 - 23s - loss: 2.4941 - accuracy50: 0.6161 - val_loss: 2.4917 - val_accuracy50: 0.5816 - 23s/epoch - 36ms/step
Epoch 23/50
634/634 - 25s - loss: 2.4871 - accuracy50: 0.6179 - val_loss: 2.5325 - val_accuracy50: 0.5774 - 25s/epoch - 40ms/step
Epoch 24/50
634/634 - 25s - loss: 2.4793 - accuracy50: 0.6202 - val_loss: 2.5534 - val_accuracy50: 0.5673 - 25s/epoch - 39ms/step
Epoch 25/50
634/634 - 23s - loss: 2.4685 - accuracy50: 0.6196 - val_loss: 2.5565 - val_accuracy50: 0.5688 - 23s/epoch - 37ms/step
Epoch 26/50
634/634 - 23s - loss: 2.4586 - accuracy50: 0.6213 - val_loss: 2.5483 - val_accuracy50: 0.5945 - 23s/epoch - 36ms/step
Epoch 27/50
634/634 - 24s - loss: 2.4529 - accuracy50: 0.6213 - val_loss: 2.5733 - val_accuracy50: 0.5894 - 24s/epoch - 38ms/step
Epoch 28/50
634/634 - 24s - loss: 2.4404 - accuracy50: 0.6222 - val_loss: 2.5979 - val_accuracy50: 0.5763 - 24s/epoch - 38ms/step
Epoch 29/50
634/634 - 23s - loss: 2.4351 - accuracy50: 0.6225 - val_loss: 2.5728 - val_accuracy50: 0.6031 - 23s/epoch - 37ms/step
Epoch 30/50
634/634 - 23s - loss: 2.4271 - accuracy50: 0.6210 - val_loss: 2.5935 - val_accuracy50: 0.5905 - 23s/epoch - 37ms/step
Epoch 31/50
634/634 - 23s - loss: 2.4105 - accuracy50: 0.6244 - val_loss: 2.6194 - val_accuracy50: 0.5749 - 23s/epoch - 37ms/step
Epoch 32/50
634/634 - 25s - loss: 2.3966 - accuracy50: 0.6266 - val_loss: 2.5678 - val_accuracy50: 0.5990 - 25s/epoch - 39ms/step
testing model: results/QRTEA/W4/deepVOL_L3/h50
Evaluating performance on  test set...
1613/1613 - 26s - 26s/epoch - 16ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.86249125
{'0': {'precision': 0.351434896357416, 'recall': 0.6095047956776076, 'f1-score': 0.44581622858076503, 'support': 71627}, '1': {'precision': 0.8012171172263305, 'recall': 0.6153579728280301, 'f1-score': 0.6960948904340719, 'support': 268512}, '2': {'precision': 0.4923482081093217, 'recall': 0.5579562646128455, 'f1-score': 0.5231031081368586, 'support': 72710}, 'accuracy': 0.6042330246651924, 'macro avg': {'precision': 0.5483334072310228, 'recall': 0.5942730110394944, 'f1-score': 0.5550047423838985, 'support': 412849}, 'weighted avg': {'precision': 0.6687851396362783, 'recall': 0.6042330246651924, 'f1-score': 0.6222060298497004, 'support': 412849}}
[[ 43657  17169  10801]
 [ 72252 165231  31029]
 [  8316  23825  40569]]
Evaluating performance on  train set...
634/634 - 10s - 10s/epoch - 16ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.8920325
{'0': {'precision': 0.4046800813927199, 'recall': 0.5506198664902944, 'f1-score': 0.4665024694736568, 'support': 32507}, '1': {'precision': 0.7794870348697847, 'recall': 0.5703644092278486, 'f1-score': 0.658726801513301, 'support': 96924}, '2': {'precision': 0.42291910279579037, 'recall': 0.6072965959395512, 'f1-score': 0.4986088482265947, 'support': 32755}, 'accuracy': 0.573865808392833, 'macro avg': {'precision': 0.5356954063527649, 'recall': 0.5760936238858981, 'f1-score': 0.5412793730711841, 'support': 162186}, 'weighted avg': {'precision': 0.6323520648245118, 'recall': 0.573865808392833, 'f1-score': 0.5878618691423271, 'support': 162186}}
[[17899  7303  7305]
 [21804 55282 19838]
 [ 4527  8336 19892]]
Evaluating performance on  val set...
206/206 - 3s - 3s/epoch - 16ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.8854196
{'0': {'precision': 0.34681697612732093, 'recall': 0.5506551240056153, 'f1-score': 0.4255877034358047, 'support': 8548}, '1': {'precision': 0.807925533969333, 'recall': 0.5930314971791455, 'f1-score': 0.6839971224903538, 'support': 35273}, '2': {'precision': 0.38622145172231853, 'recall': 0.5751487260074082, 'f1-score': 0.46212121212121204, 'support': 8909}, 'accuracy': 0.5831405272141096, 'macro avg': {'precision': 0.5136546539396575, 'recall': 0.5729451157307229, 'f1-score': 0.5239020126824568, 'support': 52730}, 'weighted avg': {'precision': 0.6619267169548787, 'recall': 0.5831405272141096, 'f1-score': 0.6046196106459205, 'support': 52730}}
[[ 4707  2226  1615]
 [ 7827 20918  6528]
 [ 1038  2747  5124]]
training model: results/QRTEA/W4/deepVOL_L3/h100
Epoch 1/50
634/634 - 25s - loss: 3.2972 - accuracy100: 0.3884 - val_loss: 3.1511 - val_accuracy100: 0.3650 - 25s/epoch - 40ms/step
Epoch 2/50
634/634 - 25s - loss: 3.1983 - accuracy100: 0.4107 - val_loss: 3.0272 - val_accuracy100: 0.4482 - 25s/epoch - 40ms/step
Epoch 3/50
634/634 - 25s - loss: 3.0746 - accuracy100: 0.4684 - val_loss: 2.9750 - val_accuracy100: 0.4655 - 25s/epoch - 40ms/step
Epoch 4/50
634/634 - 23s - loss: 3.0125 - accuracy100: 0.4941 - val_loss: 2.9484 - val_accuracy100: 0.4880 - 23s/epoch - 37ms/step
Epoch 5/50
634/634 - 23s - loss: 2.9725 - accuracy100: 0.5070 - val_loss: 2.9241 - val_accuracy100: 0.5069 - 23s/epoch - 36ms/step
Epoch 6/50
634/634 - 23s - loss: 2.9427 - accuracy100: 0.5129 - val_loss: 2.8971 - val_accuracy100: 0.5089 - 23s/epoch - 36ms/step
Epoch 7/50
634/634 - 23s - loss: 2.9181 - accuracy100: 0.5169 - val_loss: 2.8786 - val_accuracy100: 0.5259 - 23s/epoch - 36ms/step
Epoch 8/50
634/634 - 23s - loss: 2.8987 - accuracy100: 0.5232 - val_loss: 2.8883 - val_accuracy100: 0.5149 - 23s/epoch - 37ms/step
Epoch 9/50
634/634 - 23s - loss: 2.8786 - accuracy100: 0.5279 - val_loss: 2.8891 - val_accuracy100: 0.5214 - 23s/epoch - 37ms/step
Epoch 10/50
634/634 - 23s - loss: 2.8631 - accuracy100: 0.5317 - val_loss: 2.9039 - val_accuracy100: 0.5196 - 23s/epoch - 36ms/step
Epoch 11/50
634/634 - 23s - loss: 2.8536 - accuracy100: 0.5331 - val_loss: 2.9299 - val_accuracy100: 0.5130 - 23s/epoch - 36ms/step
Epoch 12/50
634/634 - 23s - loss: 2.8451 - accuracy100: 0.5357 - val_loss: 2.8983 - val_accuracy100: 0.5209 - 23s/epoch - 37ms/step
Epoch 13/50
634/634 - 23s - loss: 2.8333 - accuracy100: 0.5385 - val_loss: 2.9315 - val_accuracy100: 0.5169 - 23s/epoch - 37ms/step
Epoch 14/50
634/634 - 23s - loss: 2.8238 - accuracy100: 0.5398 - val_loss: 2.8954 - val_accuracy100: 0.5243 - 23s/epoch - 37ms/step
Epoch 15/50
634/634 - 23s - loss: 2.8156 - accuracy100: 0.5407 - val_loss: 2.9248 - val_accuracy100: 0.5097 - 23s/epoch - 36ms/step
Epoch 16/50
634/634 - 24s - loss: 2.8057 - accuracy100: 0.5430 - val_loss: 2.9172 - val_accuracy100: 0.5154 - 24s/epoch - 37ms/step
Epoch 17/50
634/634 - 23s - loss: 2.7893 - accuracy100: 0.5467 - val_loss: 2.9386 - val_accuracy100: 0.5187 - 23s/epoch - 36ms/step
testing model: results/QRTEA/W4/deepVOL_L3/h100
Evaluating performance on  test set...
1613/1613 - 26s - 26s/epoch - 16ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 0.99754095
{'0': {'precision': 0.3782983384012336, 'recall': 0.5200384325844922, 'f1-score': 0.43798646856151296, 'support': 100956}, '1': {'precision': 0.6099692124239948, 'recall': 0.565722484936313, 'f1-score': 0.5870132439684915, 'support': 209776}, '2': {'precision': 0.49763545806711273, 'recall': 0.387457524212423, 'f1-score': 0.4356889194769443, 'support': 102117}, 'accuracy': 0.5104578187182238, 'macro avg': {'precision': 0.49530100296411367, 'recall': 0.49107281391107604, 'f1-score': 0.4868962106689829, 'support': 412849}, 'weighted avg': {'precision': 0.5255321646135276, 'recall': 0.5104578187182238, 'f1-score': 0.513141360587182, 'support': 412849}}
[[ 52501  32986  15469]
 [ 66628 118675  24473]
 [ 19653  42898  39566]]
Evaluating performance on  train set...
634/634 - 10s - 10s/epoch - 16ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 0.98050994
{'0': {'precision': 0.4543633555362487, 'recall': 0.425161465155142, 'f1-score': 0.4392776313026436, 'support': 44282}, '1': {'precision': 0.5920558386034885, 'recall': 0.5890466807093837, 'f1-score': 0.5905474263603913, 'support': 73585}, '2': {'precision': 0.4424788068743558, 'recall': 0.4746271350887881, 'f1-score': 0.45798950554116136, 'support': 44319}, 'accuracy': 0.513034417273994, 'macro avg': {'precision': 0.49629933367136436, 'recall': 0.49627842698443797, 'f1-score': 0.49593818773473203, 'support': 162186}, 'weighted avg': {'precision': 0.5135878881984786, 'recall': 0.513034417273994, 'f1-score': 0.5130230805011023, 'support': 162186}}
[[18827 14214 11241]
 [14977 43345 15263]
 [ 7632 15652 21035]]
Evaluating performance on  val set...
206/206 - 4s - 4s/epoch - 18ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 0.9735345
{'0': {'precision': 0.4234525122066467, 'recall': 0.4355962410887881, 'f1-score': 0.4294385432473445, 'support': 12344}, '1': {'precision': 0.6386573723291408, 'recall': 0.6100014473874656, 'f1-score': 0.6240005922416345, 'support': 27636}, '2': {'precision': 0.41324435318275154, 'recall': 0.4419607843137255, 'f1-score': 0.4271204426589858, 'support': 12750}, 'accuracy': 0.528541627157216, 'macro avg': {'precision': 0.49178474590617965, 'recall': 0.4958528242633264, 'f1-score': 0.4935198593826549, 'support': 52730}, 'weighted avg': {'precision': 0.53377391343537, 'recall': 0.528541627157216, 'f1-score': 0.530848765198883, 'support': 52730}}
[[ 5377  4440  2527]
 [ 5304 16858  5474]
 [ 2017  5098  5635]]
training model: results/QRTEA/W4/deepVOL_L3/h200
Epoch 1/50
634/634 - 28s - loss: 3.3235 - accuracy200: 0.3565 - val_loss: 3.2906 - val_accuracy200: 0.3555 - 28s/epoch - 43ms/step
Epoch 2/50
634/634 - 25s - loss: 3.2448 - accuracy200: 0.3956 - val_loss: 3.2456 - val_accuracy200: 0.3923 - 25s/epoch - 40ms/step
Epoch 3/50
634/634 - 25s - loss: 3.1845 - accuracy200: 0.4244 - val_loss: 3.2497 - val_accuracy200: 0.3938 - 25s/epoch - 40ms/step
Epoch 4/50
634/634 - 25s - loss: 3.1657 - accuracy200: 0.4348 - val_loss: 3.2203 - val_accuracy200: 0.4112 - 25s/epoch - 39ms/step
Epoch 5/50
634/634 - 25s - loss: 3.1438 - accuracy200: 0.4441 - val_loss: 3.2035 - val_accuracy200: 0.4219 - 25s/epoch - 39ms/step
Epoch 6/50
634/634 - 25s - loss: 3.1258 - accuracy200: 0.4537 - val_loss: 3.1954 - val_accuracy200: 0.4233 - 25s/epoch - 40ms/step
Epoch 7/50
634/634 - 25s - loss: 3.1038 - accuracy200: 0.4610 - val_loss: 3.1813 - val_accuracy200: 0.4328 - 25s/epoch - 40ms/step
Epoch 8/50
634/634 - 25s - loss: 3.0824 - accuracy200: 0.4669 - val_loss: 3.1988 - val_accuracy200: 0.4299 - 25s/epoch - 39ms/step
Epoch 9/50
634/634 - 25s - loss: 3.0622 - accuracy200: 0.4725 - val_loss: 3.2084 - val_accuracy200: 0.4267 - 25s/epoch - 39ms/step
Epoch 10/50
634/634 - 25s - loss: 3.0357 - accuracy200: 0.4819 - val_loss: 3.2336 - val_accuracy200: 0.4229 - 25s/epoch - 39ms/step
Epoch 11/50
634/634 - 25s - loss: 3.0169 - accuracy200: 0.4859 - val_loss: 3.2486 - val_accuracy200: 0.4108 - 25s/epoch - 39ms/step
Epoch 12/50
634/634 - 25s - loss: 3.0087 - accuracy200: 0.4876 - val_loss: 3.2589 - val_accuracy200: 0.4213 - 25s/epoch - 40ms/step
Epoch 13/50
634/634 - 26s - loss: 2.9890 - accuracy200: 0.4936 - val_loss: 3.2696 - val_accuracy200: 0.4182 - 26s/epoch - 41ms/step
Epoch 14/50
634/634 - 25s - loss: 2.9698 - accuracy200: 0.4980 - val_loss: 3.2508 - val_accuracy200: 0.4242 - 25s/epoch - 39ms/step
Epoch 15/50
634/634 - 24s - loss: 2.9487 - accuracy200: 0.5032 - val_loss: 3.2985 - val_accuracy200: 0.4129 - 24s/epoch - 39ms/step
Epoch 16/50
634/634 - 25s - loss: 2.9299 - accuracy200: 0.5090 - val_loss: 3.3403 - val_accuracy200: 0.4198 - 25s/epoch - 39ms/step
Epoch 17/50
634/634 - 25s - loss: 2.9157 - accuracy200: 0.5142 - val_loss: 3.3437 - val_accuracy200: 0.4129 - 25s/epoch - 39ms/step
testing model: results/QRTEA/W4/deepVOL_L3/h200
Evaluating performance on  test set...
1613/1613 - 25s - 25s/epoch - 16ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0680007
{'0': {'precision': 0.3906338777115718, 'recall': 0.4177013069960899, 'f1-score': 0.4037144104671997, 'support': 128386}, '1': {'precision': 0.42723336788828586, 'recall': 0.45725809609586093, 'f1-score': 0.4417361259977554, 'support': 153222}, '2': {'precision': 0.4283140790664743, 'recall': 0.36413925526321805, 'f1-score': 0.39362814947821, 'support': 131241}, 'accuracy': 0.41535525095131637, 'macro avg': {'precision': 0.4153937748887773, 'recall': 0.4130328861183896, 'f1-score': 0.4130262286477217, 'support': 412849}, 'weighted avg': {'precision': 0.4161953648167246, 'recall': 0.41535525095131637, 'f1-score': 0.41461920209456665, 'support': 412849}}
[[53627 43161 31598]
 [50971 70062 32189]
 [32684 50767 47790]]
Evaluating performance on  train set...
634/634 - 10s - 10s/epoch - 16ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0447797
{'0': {'precision': 0.4528574240535398, 'recall': 0.3811434672164341, 'f1-score': 0.41391718058151505, 'support': 54326}, '1': {'precision': 0.46965555971546236, 'recall': 0.4643015767266267, 'f1-score': 0.46696322215604524, 'support': 54036}, '2': {'precision': 0.4271528956426566, 'recall': 0.5003158442330559, 'f1-score': 0.46084865702037364, 'support': 53824}, 'accuracy': 0.4483987520501153, 'macro avg': {'precision': 0.4498886264705529, 'recall': 0.4485869627253722, 'f1-score': 0.4472430199193113, 'support': 162186}, 'weighted avg': {'precision': 0.4499236536999967, 'recall': 0.4483987520501153, 'f1-score': 0.4471656464809542, 'support': 162186}}
[[20706 13324 20296]
 [13129 25089 15818]
 [11888 15007 26929]]
Evaluating performance on  val set...
206/206 - 3s - 3s/epoch - 16ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0609608
{'0': {'precision': 0.41254889438812165, 'recall': 0.3231413743512787, 'f1-score': 0.36241234221598884, 'support': 15993}, '1': {'precision': 0.47904406120464665, 'recall': 0.46380617351236186, 'f1-score': 0.47130198368744336, 'support': 20183}, '2': {'precision': 0.40010647565579327, 'recall': 0.49939591639482905, 'f1-score': 0.4442712811693895, 'support': 16554}, 'accuracy': 0.43231556988431635, 'macro avg': {'precision': 0.4305664770828539, 'recall': 0.42878115475282313, 'f1-score': 0.42599520235760724, 'support': 52730}, 'weighted avg': {'precision': 0.43409450698366425, 'recall': 0.43231556988431635, 'f1-score': 0.4297897840755178, 'support': 52730}}
[[5168 4901 5924]
 [4351 9361 6471]
 [3008 5279 8267]]
training model: results/QRTEA/W4/deepVOL_L3/h300
Epoch 1/50
634/634 - 26s - loss: 3.3235 - accuracy300: 0.3593 - val_loss: 3.3223 - val_accuracy300: 0.3310 - 26s/epoch - 41ms/step
Epoch 2/50
634/634 - 24s - loss: 3.2884 - accuracy300: 0.3653 - val_loss: 3.3183 - val_accuracy300: 0.3370 - 24s/epoch - 38ms/step
Epoch 3/50
634/634 - 23s - loss: 3.2768 - accuracy300: 0.3709 - val_loss: 3.2791 - val_accuracy300: 0.3629 - 23s/epoch - 37ms/step
Epoch 4/50
634/634 - 23s - loss: 3.2645 - accuracy300: 0.3823 - val_loss: 3.2690 - val_accuracy300: 0.3724 - 23s/epoch - 37ms/step
Epoch 5/50
634/634 - 25s - loss: 3.2500 - accuracy300: 0.3946 - val_loss: 3.2706 - val_accuracy300: 0.3776 - 25s/epoch - 39ms/step
Epoch 6/50
634/634 - 23s - loss: 3.2279 - accuracy300: 0.4092 - val_loss: 3.2754 - val_accuracy300: 0.3742 - 23s/epoch - 36ms/step
Epoch 7/50
634/634 - 23s - loss: 3.2154 - accuracy300: 0.4164 - val_loss: 3.2560 - val_accuracy300: 0.3869 - 23s/epoch - 37ms/step
Epoch 8/50
634/634 - 23s - loss: 3.1960 - accuracy300: 0.4287 - val_loss: 3.2719 - val_accuracy300: 0.3835 - 23s/epoch - 36ms/step
Epoch 9/50
634/634 - 23s - loss: 3.1905 - accuracy300: 0.4300 - val_loss: 3.2732 - val_accuracy300: 0.3766 - 23s/epoch - 37ms/step
Epoch 10/50
634/634 - 24s - loss: 3.1811 - accuracy300: 0.4342 - val_loss: 3.2685 - val_accuracy300: 0.3837 - 24s/epoch - 38ms/step
Epoch 11/50
634/634 - 25s - loss: 3.1645 - accuracy300: 0.4416 - val_loss: 3.2922 - val_accuracy300: 0.3724 - 25s/epoch - 39ms/step
Epoch 12/50
634/634 - 25s - loss: 3.1515 - accuracy300: 0.4482 - val_loss: 3.3134 - val_accuracy300: 0.3758 - 25s/epoch - 39ms/step
Epoch 13/50
634/634 - 23s - loss: 3.1345 - accuracy300: 0.4561 - val_loss: 3.3215 - val_accuracy300: 0.3742 - 23s/epoch - 36ms/step
Epoch 14/50
634/634 - 25s - loss: 3.1237 - accuracy300: 0.4587 - val_loss: 3.3420 - val_accuracy300: 0.3727 - 25s/epoch - 39ms/step
Epoch 15/50
634/634 - 24s - loss: 3.1067 - accuracy300: 0.4654 - val_loss: 3.3679 - val_accuracy300: 0.3739 - 24s/epoch - 37ms/step
Epoch 16/50
634/634 - 23s - loss: 3.0946 - accuracy300: 0.4684 - val_loss: 3.3944 - val_accuracy300: 0.3743 - 23s/epoch - 37ms/step
Epoch 17/50
634/634 - 25s - loss: 3.0843 - accuracy300: 0.4730 - val_loss: 3.4281 - val_accuracy300: 0.3745 - 25s/epoch - 39ms/step
testing model: results/QRTEA/W4/deepVOL_L3/h300
Evaluating performance on  test set...
1613/1613 - 25s - 25s/epoch - 15ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.094417
{'0': {'precision': 0.3709490111725771, 'recall': 0.47085263662372745, 'f1-score': 0.41497262548917335, 'support': 137714}, '1': {'precision': 0.3476161208183335, 'recall': 0.266073748823872, 'f1-score': 0.30142757439248774, 'support': 133914}, '2': {'precision': 0.4194105278689734, 'recall': 0.40255344460101544, 'f1-score': 0.41080913117940787, 'support': 141221}, 'accuracy': 0.3810666853982933, 'macro avg': {'precision': 0.37932521995329466, 'recall': 0.37982661001620494, 'f1-score': 0.37573644368702297, 'support': 412849}, 'weighted avg': {'precision': 0.37995759099348886, 'recall': 0.3810666853982933, 'f1-score': 0.3767183368691671, 'support': 412849}}
[[64843 35061 37810]
 [57397 35631 40886]
 [52563 31809 56849]]
Evaluating performance on  train set...
634/634 - 11s - 11s/epoch - 18ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.070851
{'0': {'precision': 0.4156921618204804, 'recall': 0.4815825125407345, 'f1-score': 0.4462180454954114, 'support': 54622}, '1': {'precision': 0.4428736120381045, 'recall': 0.27294144043078306, 'f1-score': 0.33773685306434076, 'support': 53484}, '2': {'precision': 0.4051922843624894, 'recall': 0.4940828402366864, 'f1-score': 0.44524428447643805, 'support': 54080}, 'accuracy': 0.4169472087603122, 'macro avg': {'precision': 0.42125268607369143, 'recall': 0.4162022644027346, 'f1-score': 0.40973306101206336, 'support': 162186}, 'weighted avg': {'precision': 0.42115465124935375, 'recall': 0.4169472087603122, 'f1-score': 0.41011955923957266, 'support': 162186}}
[[26305  9549 18768]
 [18430 14598 20456]
 [18545  8815 26720]]
Evaluating performance on  val set...
206/206 - 4s - 4s/epoch - 18ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0858859
{'0': {'precision': 0.3821290549244642, 'recall': 0.385037465337188, 'f1-score': 0.38357774708319864, 'support': 16949}, '1': {'precision': 0.3903901680610054, 'recall': 0.2897411945711303, 'f1-score': 0.33261843184255346, 'support': 18199}, '2': {'precision': 0.38600135470760893, 'recall': 0.48617904675236034, 'f1-score': 0.4303370503687669, 'support': 17582}, 'accuracy': 0.38587142044377015, 'macro avg': {'precision': 0.3861735258976928, 'recall': 0.3869859022202262, 'f1-score': 0.382177743098173, 'support': 52730}, 'weighted avg': {'precision': 0.38627141738907955, 'recall': 0.38587142044377015, 'f1-score': 0.3815810372842675, 'support': 52730}}
[[6526 4257 6166]
 [5495 5273 7431]
 [5057 3977 8548]]
training model: results/QRTEA/W4/deepVOL_L3/h500
Epoch 1/50
634/634 - 27s - loss: 3.2966 - accuracy500: 0.3769 - val_loss: 3.3162 - val_accuracy500: 0.3429 - 27s/epoch - 42ms/step
Epoch 2/50
634/634 - 23s - loss: 3.2859 - accuracy500: 0.3693 - val_loss: 3.3123 - val_accuracy500: 0.3493 - 23s/epoch - 37ms/step
Epoch 3/50
634/634 - 23s - loss: 3.2792 - accuracy500: 0.3698 - val_loss: 3.3155 - val_accuracy500: 0.3533 - 23s/epoch - 37ms/step
Epoch 4/50
634/634 - 23s - loss: 3.2731 - accuracy500: 0.3863 - val_loss: 3.2977 - val_accuracy500: 0.3657 - 23s/epoch - 36ms/step
Epoch 5/50
634/634 - 24s - loss: 3.2606 - accuracy500: 0.3962 - val_loss: 3.2986 - val_accuracy500: 0.3647 - 24s/epoch - 37ms/step
Epoch 6/50
634/634 - 23s - loss: 3.2659 - accuracy500: 0.3868 - val_loss: 3.3172 - val_accuracy500: 0.3541 - 23s/epoch - 37ms/step
Epoch 7/50
634/634 - 24s - loss: 3.2618 - accuracy500: 0.3911 - val_loss: 3.3086 - val_accuracy500: 0.3576 - 24s/epoch - 37ms/step
Epoch 8/50
634/634 - 23s - loss: 3.2536 - accuracy500: 0.3967 - val_loss: 3.3019 - val_accuracy500: 0.3630 - 23s/epoch - 37ms/step
Epoch 9/50
634/634 - 23s - loss: 3.2399 - accuracy500: 0.4072 - val_loss: 3.3103 - val_accuracy500: 0.3659 - 23s/epoch - 37ms/step
Epoch 10/50
634/634 - 23s - loss: 3.2339 - accuracy500: 0.4112 - val_loss: 3.3120 - val_accuracy500: 0.3571 - 23s/epoch - 37ms/step
Epoch 11/50
634/634 - 23s - loss: 3.2239 - accuracy500: 0.4171 - val_loss: 3.3169 - val_accuracy500: 0.3593 - 23s/epoch - 37ms/step
Epoch 12/50
634/634 - 24s - loss: 3.2159 - accuracy500: 0.4237 - val_loss: 3.3229 - val_accuracy500: 0.3571 - 24s/epoch - 38ms/step
Epoch 13/50
634/634 - 23s - loss: 3.1960 - accuracy500: 0.4336 - val_loss: 3.3563 - val_accuracy500: 0.3577 - 23s/epoch - 36ms/step
Epoch 14/50
634/634 - 23s - loss: 3.1850 - accuracy500: 0.4395 - val_loss: 3.3563 - val_accuracy500: 0.3579 - 23s/epoch - 37ms/step
testing model: results/QRTEA/W4/deepVOL_L3/h500
Evaluating performance on  test set...
1613/1613 - 25s - 25s/epoch - 15ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0959663
{'0': {'precision': 0.38136675801679243, 'recall': 0.49388808370744813, 'f1-score': 0.4303946424005693, 'support': 141445}, '1': {'precision': 0.32597078731742074, 'recall': 0.007175513853054887, 'f1-score': 0.01404192627605046, 'support': 127517}, '2': {'precision': 0.3721216235277523, 'recall': 0.5867173545907552, 'f1-score': 0.45540537989108587, 'support': 143887}, 'accuracy': 0.37590983628396824, 'macro avg': {'precision': 0.3598197229539885, 'recall': 0.3625936507170861, 'f1-score': 0.2999473161892352, 'support': 412849}, 'weighted avg': {'precision': 0.36103442667556046, 'recall': 0.37590983628396824, 'f1-score': 0.31051224153063306, 'support': 412849}}
[[69858   856 70731]
 [54890   915 71712]
 [58430  1036 84421]]
Evaluating performance on  train set...
634/634 - 10s - 10s/epoch - 16ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0983206
{'0': {'precision': 0.37682528901947465, 'recall': 0.4716078127021084, 'f1-score': 0.41892224611394707, 'support': 54117}, '1': {'precision': 0.3964165733482643, 'recall': 0.0065557983629023295, 'f1-score': 0.01289828933704979, 'support': 53998}, '2': {'precision': 0.36447779060322344, 'recall': 0.6306892789110614, 'f1-score': 0.46197717343448363, 'support': 54071}, 'accuracy': 0.369809971267557, 'macro avg': {'precision': 0.37923988432365413, 'recall': 0.369617629992024, 'f1-score': 0.2979325696284935, 'support': 162186}, 'weighted avg': {'precision': 0.37923146824777343, 'recall': 0.369809971267557, 'f1-score': 0.2980951793949321, 'support': 162186}}
[[25522   261 28334]
 [22516   354 31128]
 [19691   278 34102]]
Evaluating performance on  val set...
206/206 - 3s - 3s/epoch - 15ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.098811
{'0': {'precision': 0.36362081498268267, 'recall': 0.48591509056625337, 'f1-score': 0.4159655644687928, 'support': 17501}, '1': {'precision': 0.32819383259911894, 'recall': 0.008619193613698155, 'f1-score': 0.016797249309509047, 'support': 17287}, '2': {'precision': 0.3747100972688567, 'recall': 0.6033329617656894, 'f1-score': 0.4623006128419209, 'support': 17942}, 'accuracy': 0.3693912383842215, 'macro avg': {'precision': 0.35550824828355276, 'recall': 0.36595574864854696, 'f1-score': 0.29835447554007427, 'support': 52730}, 'weighted avg': {'precision': 0.3557796933880282, 'recall': 0.3693912383842215, 'f1-score': 0.30086829107133645, 'support': 52730}}
[[ 8504   169  8828]
 [ 7902   149  9236]
 [ 6981   136 10825]]
training model: results/QRTEA/W4/deepVOL_L3/h1000
Epoch 1/50
634/634 - 26s - loss: 3.2822 - accuracy1000: 0.3988 - val_loss: 3.2709 - val_accuracy1000: 0.3722 - 26s/epoch - 40ms/step
Epoch 2/50
634/634 - 24s - loss: 3.3042 - accuracy1000: 0.3468 - val_loss: 3.2680 - val_accuracy1000: 0.3760 - 24s/epoch - 37ms/step
Epoch 3/50
634/634 - 23s - loss: 3.2972 - accuracy1000: 0.3488 - val_loss: 3.2765 - val_accuracy1000: 0.3653 - 23s/epoch - 36ms/step
Epoch 4/50
634/634 - 24s - loss: 3.2918 - accuracy1000: 0.3634 - val_loss: 3.3000 - val_accuracy1000: 0.3606 - 24s/epoch - 38ms/step
Epoch 5/50
634/634 - 23s - loss: 3.2870 - accuracy1000: 0.3719 - val_loss: 3.2782 - val_accuracy1000: 0.3755 - 23s/epoch - 37ms/step
Epoch 6/50
634/634 - 23s - loss: 3.2762 - accuracy1000: 0.3839 - val_loss: 3.2743 - val_accuracy1000: 0.3794 - 23s/epoch - 37ms/step
Epoch 7/50
634/634 - 23s - loss: 3.2812 - accuracy1000: 0.3827 - val_loss: 3.2886 - val_accuracy1000: 0.3692 - 23s/epoch - 37ms/step
Epoch 8/50
634/634 - 23s - loss: 3.2763 - accuracy1000: 0.3808 - val_loss: 3.2699 - val_accuracy1000: 0.3799 - 23s/epoch - 37ms/step
Epoch 9/50
634/634 - 23s - loss: 3.2489 - accuracy1000: 0.4082 - val_loss: 3.3048 - val_accuracy1000: 0.3679 - 23s/epoch - 37ms/step
Epoch 10/50
634/634 - 23s - loss: 3.2589 - accuracy1000: 0.3947 - val_loss: 3.3243 - val_accuracy1000: 0.3663 - 23s/epoch - 37ms/step
Epoch 11/50
634/634 - 23s - loss: 3.2414 - accuracy1000: 0.4058 - val_loss: 3.3526 - val_accuracy1000: 0.3670 - 23s/epoch - 36ms/step
Epoch 12/50
634/634 - 23s - loss: 3.2278 - accuracy1000: 0.4180 - val_loss: 3.3536 - val_accuracy1000: 0.3607 - 23s/epoch - 36ms/step
testing model: results/QRTEA/W4/deepVOL_L3/h1000
Evaluating performance on  test set...
1613/1613 - 25s - 25s/epoch - 16ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0860795
{'0': {'precision': 0.3854020106427297, 'recall': 0.9250389897871912, 'f1-score': 0.5441097866595153, 'support': 159016}, '1': {'precision': 0.13333333333333333, 'recall': 1.9803548795944232e-05, 'f1-score': 3.9601215757323746e-05, 'support': 100992}, '2': {'precision': 0.3630675437189155, 'recall': 0.07403118273238202, 'f1-score': 0.12298512005043315, 'support': 152841}, 'accuracy': 0.3837068758795589, 'macro avg': {'precision': 0.29393429589832615, 'recall': 0.3330299920227897, 'f1-score': 0.22237816930856857, 'support': 412849}, 'weighted avg': {'precision': 0.3154719826714054, 'recall': 0.3837068758795589, 'f1-score': 0.25511344335352515, 'support': 412849}}
[[147096      7  11913]
 [ 93053      2   7937]
 [141520      6  11315]]
Evaluating performance on  train set...
634/634 - 10s - 10s/epoch - 16ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1020886
{'0': {'precision': 0.34068604850289147, 'recall': 0.9406939948350489, 'f1-score': 0.500212753611976, 'support': 54986}, '1': {'precision': 0.125, 'recall': 1.857286133501727e-05, 'f1-score': 3.714020427112349e-05, 'support': 53842}, '2': {'precision': 0.3525888717156105, 'recall': 0.06840586228869149, 'f1-score': 0.11458169832051483, 'support': 53358}, 'accuracy': 0.3414351423674053, 'macro avg': {'precision': 0.2727583067395007, 'recall': 0.3363728099950251, 'f1-score': 0.20494386404558732, 'support': 162186}, 'weighted avg': {'precision': 0.27299921127582855, 'recall': 0.3414351423674053, 'f1-score': 0.20729624278280806, 'support': 162186}}
[[51725     3  3258]
 [50397     1  3444]
 [49704     4  3650]]
Evaluating performance on  val set...
206/206 - 3s - 3s/epoch - 16ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0893242
{'0': {'precision': 0.3772722717707185, 'recall': 0.946595594890878, 'f1-score': 0.5395164872959688, 'support': 19886}, '1': {'precision': 0.2, 'recall': 7.258474268708717e-05, 'f1-score': 0.00014511681903932666, 'support': 13777}, '2': {'precision': 0.3537102473498233, 'recall': 0.0524990821838779, 'f1-score': 0.09142804950449834, 'support': 19067}, 'accuracy': 0.37599089702256777, 'macro avg': {'precision': 0.310327506373514, 'recall': 0.33305575393914766, 'f1-score': 0.2103632178731688, 'support': 52730}, 'weighted avg': {'precision': 0.322435609380838, 'recall': 0.37599089702256777, 'f1-score': 0.23656519553737548, 'support': 52730}}
[[18824     3  1059]
 [13006     1   770]
 [18065     1  1001]]

============================================

        Job resource usage summary 

                 Memory (GB)    NCPUs
 Requested  :        96            32
 Used       :        16 (peak)  15.93 (ave)

============================================
