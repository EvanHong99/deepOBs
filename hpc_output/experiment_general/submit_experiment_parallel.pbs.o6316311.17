This machine has 1 visible gpus.
This machine has 1 physical gpus.
getting alphas...
data/WBA_orderbooks/WBA_orderbooks_2019-03-13.csv
data/WBA_orderbooks/WBA_orderbooks_2019-03-05.csv
data/WBA_orderbooks/WBA_orderbooks_2019-02-20.csv
data/WBA_orderbooks/WBA_orderbooks_2019-02-21.csv
data/WBA_orderbooks/WBA_orderbooks_2019-03-01.csv
data/WBA_orderbooks/WBA_orderbooks_2019-02-25.csv
data/WBA_orderbooks/WBA_orderbooks_2019-02-27.csv
data/WBA_orderbooks/WBA_orderbooks_2019-02-22.csv
data/WBA_orderbooks/WBA_orderbooks_2019-03-15.csv
data/WBA_orderbooks/WBA_orderbooks_2019-02-26.csv
data/WBA_orderbooks/WBA_orderbooks_2019-03-11.csv
data/WBA_orderbooks/WBA_orderbooks_2019-02-28.csv
data/WBA_orderbooks/WBA_orderbooks_2019-02-19.csv
data/WBA_orderbooks/WBA_orderbooks_2019-03-07.csv
data/WBA_orderbooks/WBA_orderbooks_2019-03-06.csv
training model: results/WBA/W1/deepLOB_L1/h10
Epoch 1/50
2222/2222 - 86s - loss: 2.9729 - accuracy10: 0.4486 - val_loss: 3.2926 - val_accuracy10: 0.5689 - 86s/epoch - 39ms/step
Epoch 2/50
2222/2222 - 69s - loss: 2.8631 - accuracy10: 0.4815 - val_loss: 3.2382 - val_accuracy10: 0.5956 - 69s/epoch - 31ms/step
Epoch 3/50
2222/2222 - 71s - loss: 2.7874 - accuracy10: 0.5154 - val_loss: 3.2278 - val_accuracy10: 0.5746 - 71s/epoch - 32ms/step
Epoch 4/50
2222/2222 - 72s - loss: 2.7245 - accuracy10: 0.5378 - val_loss: 3.2816 - val_accuracy10: 0.5299 - 72s/epoch - 33ms/step
Epoch 5/50
2222/2222 - 69s - loss: 2.6869 - accuracy10: 0.5492 - val_loss: 3.4765 - val_accuracy10: 0.5465 - 69s/epoch - 31ms/step
Epoch 6/50
2222/2222 - 69s - loss: 2.6594 - accuracy10: 0.5562 - val_loss: 3.4399 - val_accuracy10: 0.5707 - 69s/epoch - 31ms/step
Epoch 7/50
2222/2222 - 70s - loss: 2.6413 - accuracy10: 0.5614 - val_loss: 3.5462 - val_accuracy10: 0.5593 - 70s/epoch - 31ms/step
Epoch 8/50
2222/2222 - 67s - loss: 2.6272 - accuracy10: 0.5641 - val_loss: 3.5382 - val_accuracy10: 0.5586 - 67s/epoch - 30ms/step
Epoch 9/50
2222/2222 - 68s - loss: 2.6155 - accuracy10: 0.5659 - val_loss: 3.4787 - val_accuracy10: 0.5508 - 68s/epoch - 31ms/step
Epoch 10/50
2222/2222 - 69s - loss: 2.6046 - accuracy10: 0.5685 - val_loss: 3.4935 - val_accuracy10: 0.5629 - 69s/epoch - 31ms/step
Epoch 11/50
2222/2222 - 69s - loss: 2.5949 - accuracy10: 0.5704 - val_loss: 3.4703 - val_accuracy10: 0.5768 - 69s/epoch - 31ms/step
Epoch 12/50
2222/2222 - 69s - loss: 2.5871 - accuracy10: 0.5717 - val_loss: 3.4296 - val_accuracy10: 0.5647 - 69s/epoch - 31ms/step
Epoch 13/50
2222/2222 - 70s - loss: 2.5801 - accuracy10: 0.5735 - val_loss: 3.4872 - val_accuracy10: 0.5636 - 70s/epoch - 32ms/step
testing model: results/WBA/W1/deepLOB_L1/h10
Evaluating performance on  test set...
5696/5696 - 69s - 69s/epoch - 12ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 1.044679
{'0': {'precision': 0.2910053335262082, 'recall': 0.3203548226329184, 'f1-score': 0.3049755894878986, 'support': 339099}, '1': {'precision': 0.5473241364006214, 'recall': 0.7506086612495816, 'f1-score': 0.6330470083459171, 'support': 788616}, '2': {'precision': 0.49547581903276133, 'recall': 0.004807619532013962, 'f1-score': 0.009522838621467165, 'support': 330309}, 'accuracy': 0.48158466527299965, 'macro avg': {'precision': 0.44460176298653026, 'recall': 0.35859036780483794, 'f1-score': 0.31584847881842765, 'support': 1458024}, 'weighted avg': {'precision': 0.47596494368680387, 'recall': 0.48158466527299965, 'f1-score': 0.4154893172236526, 'support': 1458024}}
[[108632 230230    237]
 [195294 591942   1380]
 [ 69373 259348   1588]]
Evaluating performance on  train set...
2222/2222 - 27s - 27s/epoch - 12ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.91784316
{'0': {'precision': 0.29877849193596384, 'recall': 0.37655872039603216, 'f1-score': 0.33318953716992555, 'support': 106658}, '1': {'precision': 0.6670302801397469, 'recall': 0.7516976419228647, 'f1-score': 0.7068375562006701, 'support': 357113}, '2': {'precision': 0.42578653985450193, 'recall': 0.1289485731725927, 'f1-score': 0.19794877050680448, 'support': 104848}, 'accuracy': 0.566502350431484, 'macro avg': {'precision': 0.4638651039767376, 'recall': 0.41906831183049653, 'f1-score': 0.4126586212924668, 'support': 568619}, 'weighted avg': {'precision': 0.5534728314655617, 'recall': 0.566502350431484, 'f1-score': 0.5429166850792134, 'support': 568619}}
[[ 40163  62883   3612]
 [ 74051 268441  14621]
 [ 20210  71118  13520]]
Evaluating performance on  val set...
641/641 - 8s - 8s/epoch - 13ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.9132719
{'0': {'precision': 0.30590496985807186, 'recall': 0.423145108338805, 'f1-score': 0.35509821748353854, 'support': 30460}, '1': {'precision': 0.6840694823965627, 'recall': 0.7484138885684624, 'f1-score': 0.7147965718115507, 'support': 104028}, '2': {'precision': 0.4626582278481013, 'recall': 0.12449334105385061, 'f1-score': 0.19619420811079202, 'support': 29359}, 'accuracy': 0.5761472593334025, 'macro avg': {'precision': 0.4842108933675786, 'recall': 0.43201744598703934, 'f1-score': 0.42202966580196044, 'support': 163847}, 'weighted avg': {'precision': 0.574093077126947, 'recall': 0.5761472593334025, 'f1-score': 0.555000794844491, 'support': 163847}}
[[12889 16615   956]
 [22883 77856  3289]
 [ 6362 19342  3655]]
training model: results/WBA/W1/deepLOB_L1/h20
Epoch 1/50
2222/2222 - 77s - loss: 3.0435 - accuracy20: 0.4571 - val_loss: 3.3673 - val_accuracy20: 0.5139 - 77s/epoch - 35ms/step
Epoch 2/50
2222/2222 - 72s - loss: 2.9781 - accuracy20: 0.4740 - val_loss: 3.3959 - val_accuracy20: 0.4483 - 72s/epoch - 32ms/step
Epoch 3/50
2222/2222 - 70s - loss: 2.9130 - accuracy20: 0.5009 - val_loss: 3.1916 - val_accuracy20: 0.5541 - 70s/epoch - 31ms/step
Epoch 4/50
2222/2222 - 72s - loss: 2.8402 - accuracy20: 0.5300 - val_loss: 3.1630 - val_accuracy20: 0.5430 - 72s/epoch - 32ms/step
Epoch 5/50
2222/2222 - 73s - loss: 2.7959 - accuracy20: 0.5442 - val_loss: 3.1357 - val_accuracy20: 0.5356 - 73s/epoch - 33ms/step
Epoch 6/50
2222/2222 - 70s - loss: 2.7682 - accuracy20: 0.5505 - val_loss: 3.1115 - val_accuracy20: 0.5574 - 70s/epoch - 32ms/step
Epoch 7/50
2222/2222 - 71s - loss: 2.7476 - accuracy20: 0.5555 - val_loss: 3.0595 - val_accuracy20: 0.5538 - 71s/epoch - 32ms/step
Epoch 8/50
2222/2222 - 72s - loss: 2.7320 - accuracy20: 0.5582 - val_loss: 3.0762 - val_accuracy20: 0.5657 - 72s/epoch - 33ms/step
Epoch 9/50
2222/2222 - 72s - loss: 2.7192 - accuracy20: 0.5614 - val_loss: 3.0752 - val_accuracy20: 0.5624 - 72s/epoch - 33ms/step
Epoch 10/50
2222/2222 - 73s - loss: 2.7069 - accuracy20: 0.5639 - val_loss: 3.0740 - val_accuracy20: 0.5612 - 73s/epoch - 33ms/step
Epoch 11/50
2222/2222 - 74s - loss: 2.6987 - accuracy20: 0.5650 - val_loss: 3.0643 - val_accuracy20: 0.5649 - 74s/epoch - 33ms/step
Epoch 12/50
2222/2222 - 74s - loss: 2.6911 - accuracy20: 0.5669 - val_loss: 3.0413 - val_accuracy20: 0.5617 - 74s/epoch - 33ms/step
Epoch 13/50
2222/2222 - 73s - loss: 2.6845 - accuracy20: 0.5680 - val_loss: 3.0645 - val_accuracy20: 0.5671 - 73s/epoch - 33ms/step
Epoch 14/50
2222/2222 - 72s - loss: 2.6779 - accuracy20: 0.5687 - val_loss: 3.0762 - val_accuracy20: 0.5640 - 72s/epoch - 32ms/step
Epoch 15/50
2222/2222 - 73s - loss: 2.6740 - accuracy20: 0.5702 - val_loss: 3.0661 - val_accuracy20: 0.5684 - 73s/epoch - 33ms/step
Epoch 16/50
2222/2222 - 74s - loss: 2.6687 - accuracy20: 0.5711 - val_loss: 3.0382 - val_accuracy20: 0.5691 - 74s/epoch - 33ms/step
Epoch 17/50
2222/2222 - 75s - loss: 2.6638 - accuracy20: 0.5718 - val_loss: 3.0565 - val_accuracy20: 0.5697 - 75s/epoch - 34ms/step
Epoch 18/50
2222/2222 - 74s - loss: 2.6603 - accuracy20: 0.5720 - val_loss: 3.0316 - val_accuracy20: 0.5683 - 74s/epoch - 33ms/step
Epoch 19/50
2222/2222 - 71s - loss: 2.6552 - accuracy20: 0.5735 - val_loss: 3.0311 - val_accuracy20: 0.5680 - 71s/epoch - 32ms/step
Epoch 20/50
2222/2222 - 72s - loss: 2.6514 - accuracy20: 0.5738 - val_loss: 3.0591 - val_accuracy20: 0.5707 - 72s/epoch - 33ms/step
Epoch 21/50
2222/2222 - 73s - loss: 2.6493 - accuracy20: 0.5739 - val_loss: 3.0660 - val_accuracy20: 0.5710 - 73s/epoch - 33ms/step
Epoch 22/50
2222/2222 - 72s - loss: 2.6464 - accuracy20: 0.5746 - val_loss: 3.0470 - val_accuracy20: 0.5684 - 72s/epoch - 33ms/step
Epoch 23/50
2222/2222 - 72s - loss: 2.6427 - accuracy20: 0.5757 - val_loss: 3.0350 - val_accuracy20: 0.5665 - 72s/epoch - 32ms/step
Epoch 24/50
2222/2222 - 73s - loss: 2.6404 - accuracy20: 0.5766 - val_loss: 3.0813 - val_accuracy20: 0.5651 - 73s/epoch - 33ms/step
Epoch 25/50
2222/2222 - 72s - loss: 2.6363 - accuracy20: 0.5768 - val_loss: 3.0367 - val_accuracy20: 0.5654 - 72s/epoch - 32ms/step
Epoch 26/50
2222/2222 - 77s - loss: 2.6335 - accuracy20: 0.5778 - val_loss: 3.0427 - val_accuracy20: 0.5675 - 77s/epoch - 35ms/step
Epoch 27/50
2222/2222 - 74s - loss: 2.6315 - accuracy20: 0.5779 - val_loss: 3.0334 - val_accuracy20: 0.5684 - 74s/epoch - 33ms/step
Epoch 28/50
2222/2222 - 75s - loss: 2.6286 - accuracy20: 0.5787 - val_loss: 3.0588 - val_accuracy20: 0.5651 - 75s/epoch - 34ms/step
Epoch 29/50
2222/2222 - 76s - loss: 2.6253 - accuracy20: 0.5797 - val_loss: 3.0829 - val_accuracy20: 0.5654 - 76s/epoch - 34ms/step
testing model: results/WBA/W1/deepLOB_L1/h20
Evaluating performance on  test set...
5696/5696 - 69s - 69s/epoch - 12ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 1.0238062
{'0': {'precision': 0.4304963384283422, 'recall': 0.5571791142933892, 'f1-score': 0.4857133340533274, 'support': 431836}, '1': {'precision': 0.5367392127024002, 'recall': 0.5483727671924332, 'f1-score': 0.542493627908945, 'support': 607811}, '2': {'precision': 0.5006975255819305, 'recall': 0.33285051520518577, 'f1-score': 0.3998748031236046, 'support': 418377}, 'accuracy': 0.4891373530202521, 'macro avg': {'precision': 0.489311025570891, 'recall': 0.4794674655636693, 'f1-score': 0.4760272550286257, 'support': 1458024}, 'weighted avg': {'precision': 0.4949302227355595, 'recall': 0.4891373530202521, 'f1-score': 0.48475232115771805, 'support': 1458024}}
[[240610 136899  54327]
 [189962 333307  84542]
 [128341 150779 139257]]
Evaluating performance on  train set...
2222/2222 - 31s - 31s/epoch - 14ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.9100175
{'0': {'precision': 0.4569923487976682, 'recall': 0.4398644008358052, 'f1-score': 0.4482648221638163, 'support': 136874}, '1': {'precision': 0.6401884763500783, 'recall': 0.703665788888814, 'f1-score': 0.6704279487751236, 'support': 296962}, '2': {'precision': 0.47000941449107436, 'recall': 0.3852192042023104, 'f1-score': 0.4234111175897346, 'support': 134783}, 'accuracy': 0.5646821509657609, 'macro avg': {'precision': 0.5223967465462737, 'recall': 0.5095831313089766, 'f1-score': 0.5140346295095581, 'support': 568619}, 'weighted avg': {'precision': 0.5557522699321593, 'recall': 0.5646821509657609, 'f1-score': 0.5583985840344864, 'support': 568619}}
[[ 60206  58533  18135]
 [ 47588 208962  40412]
 [ 23950  58912  51921]]
Evaluating performance on  val set...
641/641 - 10s - 10s/epoch - 15ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.91144425
{'0': {'precision': 0.46494803342164254, 'recall': 0.34748064475187207, 'f1-score': 0.39772215523628285, 'support': 39395}, '1': {'precision': 0.6233250714604522, 'recall': 0.7595584151083132, 'f1-score': 0.6847312994538883, 'support': 86416}, '2': {'precision': 0.4680777953405264, 'recall': 0.3581343989904301, 'f1-score': 0.40579105722541625, 'support': 38036}, 'accuracy': 0.5672914365230978, 'macro avg': {'precision': 0.5187836334075404, 'recall': 0.48839115295020513, 'f1-score': 0.49608150397186246, 'support': 163847}, 'weighted avg': {'precision': 0.549205625831076, 'recall': 0.5672914365230978, 'f1-score': 0.5509693368311077, 'support': 163847}}
[[13689 20446  5260]
 [10558 65638 10220]
 [ 5195 19219 13622]]
training model: results/WBA/W1/deepLOB_L1/h30
Epoch 1/50
2222/2222 - 84s - loss: 3.0754 - accuracy30: 0.4650 - val_loss: 3.5503 - val_accuracy30: 0.4527 - 84s/epoch - 38ms/step
Epoch 2/50
2222/2222 - 82s - loss: 3.0397 - accuracy30: 0.4673 - val_loss: 3.4995 - val_accuracy30: 0.4650 - 82s/epoch - 37ms/step
Epoch 3/50
2222/2222 - 80s - loss: 2.9711 - accuracy30: 0.4984 - val_loss: 3.3725 - val_accuracy30: 0.4959 - 80s/epoch - 36ms/step
Epoch 4/50
2222/2222 - 82s - loss: 2.9261 - accuracy30: 0.5131 - val_loss: 3.3342 - val_accuracy30: 0.4963 - 82s/epoch - 37ms/step
Epoch 5/50
2222/2222 - 84s - loss: 2.8919 - accuracy30: 0.5245 - val_loss: 3.4775 - val_accuracy30: 0.4875 - 84s/epoch - 38ms/step
Epoch 6/50
2222/2222 - 82s - loss: 2.8681 - accuracy30: 0.5308 - val_loss: 3.5432 - val_accuracy30: 0.4765 - 82s/epoch - 37ms/step
Epoch 7/50
2222/2222 - 83s - loss: 2.8468 - accuracy30: 0.5367 - val_loss: 3.6181 - val_accuracy30: 0.4752 - 83s/epoch - 37ms/step
Epoch 8/50
2222/2222 - 74s - loss: 2.8327 - accuracy30: 0.5393 - val_loss: 3.6038 - val_accuracy30: 0.4655 - 74s/epoch - 34ms/step
Epoch 9/50
2222/2222 - 79s - loss: 2.8199 - accuracy30: 0.5428 - val_loss: 3.6326 - val_accuracy30: 0.4655 - 79s/epoch - 35ms/step
Epoch 10/50
2222/2222 - 80s - loss: 2.8086 - accuracy30: 0.5454 - val_loss: 3.6307 - val_accuracy30: 0.4581 - 80s/epoch - 36ms/step
Epoch 11/50
2222/2222 - 78s - loss: 2.7994 - accuracy30: 0.5464 - val_loss: 3.6495 - val_accuracy30: 0.4570 - 78s/epoch - 35ms/step
Epoch 12/50
2222/2222 - 77s - loss: 2.7901 - accuracy30: 0.5487 - val_loss: 3.6698 - val_accuracy30: 0.4633 - 77s/epoch - 35ms/step
Epoch 13/50
2222/2222 - 79s - loss: 2.7835 - accuracy30: 0.5502 - val_loss: 3.6499 - val_accuracy30: 0.4655 - 79s/epoch - 36ms/step
Epoch 14/50
2222/2222 - 77s - loss: 2.7761 - accuracy30: 0.5515 - val_loss: 3.6706 - val_accuracy30: 0.4538 - 77s/epoch - 34ms/step
testing model: results/WBA/W1/deepLOB_L1/h30
Evaluating performance on  test set...
5696/5696 - 69s - 69s/epoch - 12ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.2689775
{'0': {'precision': 0.43159302555973844, 'recall': 0.01795203039462325, 'f1-score': 0.0344702761617844, 'support': 485349}, '1': {'precision': 0.342863372508152, 'recall': 0.9856771798142759, 'f1-score': 0.5087576762104404, 'support': 499343}, '2': {'precision': 0.5140997830802603, 'recall': 0.0025035281789526167, 'f1-score': 0.004982791498558775, 'support': 473332}, 'accuracy': 0.34436264423630886, 'macro avg': {'precision': 0.4295187270493836, 'recall': 0.3353775794626173, 'f1-score': 0.18273691462359454, 'support': 1458024}, 'weighted avg': {'precision': 0.42798990065024817, 'recall': 0.34436264423630886, 'f1-score': 0.1873310816847951, 'support': 1458024}}
[[  8713 476223    413]
 [  6445 492191    707]
 [  5030 467117   1185]]
Evaluating performance on  train set...
2222/2222 - 34s - 34s/epoch - 15ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.0428972
{'0': {'precision': 0.4779377387995937, 'recall': 0.1893429901707191, 'f1-score': 0.2712326511193859, 'support': 156573}, '1': {'precision': 0.49998203743398756, 'recall': 0.810863299851624, 'f1-score': 0.618558228356314, 'support': 257454}, '2': {'precision': 0.43400145977205096, 'recall': 0.25001293728006624, 'f1-score': 0.3172622687740871, 'support': 154592}, 'accuracy': 0.48724365524191066, 'macro avg': {'precision': 0.47064041200187745, 'recall': 0.4167397424341364, 'f1-score': 0.40235104941659566, 'support': 568619}, 'weighted avg': {'precision': 0.47597367430859605, 'recall': 0.48724365524191066, 'f1-score': 0.4410056798335718, 'support': 568619}}
[[ 29646 105582  21345]
 [ 19634 208760  29060]
 [ 12749 103193  38650]]
Evaluating performance on  val set...
641/641 - 10s - 10s/epoch - 15ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.0325906
{'0': {'precision': 0.48132319476050395, 'recall': 0.19089128089986573, 'f1-score': 0.27336632727043475, 'support': 45429}, '1': {'precision': 0.512003502951405, 'recall': 0.8161501187903518, 'f1-score': 0.6292520878825199, 'support': 74501}, '2': {'precision': 0.4351567982861153, 'recall': 0.2682560284172416, 'f1-score': 0.3319059022397521, 'support': 43917}, 'accuracy': 0.495932180631931, 'macro avg': {'precision': 0.4761611653326747, 'recall': 0.42509914270248633, 'f1-score': 0.4115081057975689, 'support': 163847}, 'weighted avg': {'precision': 0.48289920168504086, 'recall': 0.495932180631931, 'f1-score': 0.450877832304329, 'support': 163847}}
[[ 8672 29831  6926]
 [ 5331 60804  8366]
 [ 4014 28122 11781]]
training model: results/WBA/W1/deepLOB_L1/h50
Epoch 1/50
2222/2222 - 97s - loss: 3.1439 - accuracy50: 0.4484 - val_loss: 3.5277 - val_accuracy50: 0.3638 - 97s/epoch - 44ms/step
Epoch 2/50
2222/2222 - 81s - loss: 3.1312 - accuracy50: 0.4491 - val_loss: 3.3876 - val_accuracy50: 0.3778 - 81s/epoch - 37ms/step
Epoch 3/50
2222/2222 - 80s - loss: 3.0803 - accuracy50: 0.4735 - val_loss: 3.3097 - val_accuracy50: 0.4118 - 80s/epoch - 36ms/step
Epoch 4/50
2222/2222 - 80s - loss: 3.0339 - accuracy50: 0.4901 - val_loss: 3.2962 - val_accuracy50: 0.4228 - 80s/epoch - 36ms/step
Epoch 5/50
2222/2222 - 79s - loss: 3.0022 - accuracy50: 0.5002 - val_loss: 3.3114 - val_accuracy50: 0.4244 - 79s/epoch - 36ms/step
Epoch 6/50
2222/2222 - 79s - loss: 2.9792 - accuracy50: 0.5054 - val_loss: 3.3377 - val_accuracy50: 0.4123 - 79s/epoch - 35ms/step
Epoch 7/50
2222/2222 - 83s - loss: 2.9605 - accuracy50: 0.5090 - val_loss: 3.3652 - val_accuracy50: 0.3947 - 83s/epoch - 37ms/step
Epoch 8/50
2222/2222 - 81s - loss: 2.9456 - accuracy50: 0.5119 - val_loss: 3.3412 - val_accuracy50: 0.4004 - 81s/epoch - 36ms/step
Epoch 9/50
2222/2222 - 87s - loss: 2.9337 - accuracy50: 0.5151 - val_loss: 3.3050 - val_accuracy50: 0.4129 - 87s/epoch - 39ms/step
Epoch 10/50
2222/2222 - 87s - loss: 2.9253 - accuracy50: 0.5165 - val_loss: 3.3727 - val_accuracy50: 0.3981 - 87s/epoch - 39ms/step
Epoch 11/50
2222/2222 - 85s - loss: 2.9158 - accuracy50: 0.5189 - val_loss: 3.3759 - val_accuracy50: 0.3991 - 85s/epoch - 38ms/step
Epoch 12/50
2222/2222 - 81s - loss: 2.9079 - accuracy50: 0.5202 - val_loss: 3.3695 - val_accuracy50: 0.3946 - 81s/epoch - 37ms/step
Epoch 13/50
2222/2222 - 83s - loss: 2.9009 - accuracy50: 0.5214 - val_loss: 3.3746 - val_accuracy50: 0.3987 - 83s/epoch - 37ms/step
Epoch 14/50
2222/2222 - 87s - loss: 2.8959 - accuracy50: 0.5228 - val_loss: 3.4120 - val_accuracy50: 0.4040 - 87s/epoch - 39ms/step
testing model: results/WBA/W1/deepLOB_L1/h50
Evaluating performance on  test set...
5696/5696 - 87s - 87s/epoch - 15ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.1754125
{'0': {'precision': 0.47581504702194355, 'recall': 0.11102557022348115, 'f1-score': 0.18004083345318458, 'support': 546847}, '1': {'precision': 0.25674900234271675, 'recall': 0.843435740313585, 'f1-score': 0.39366349390168626, 'support': 372403}, '2': {'precision': 0.4546881129854845, 'recall': 0.09034957143440478, 'f1-score': 0.15074508540920858, 'support': 538774}, 'accuracy': 0.29045475245949315, 'macro avg': {'precision': 0.39575072078338164, 'recall': 0.3482702939904903, 'f1-score': 0.2414831375880265, 'support': 1458024}, 'weighted avg': {'precision': 0.41205512606368966, 'recall': 0.29045475245949315, 'f1-score': 0.2237780642959953, 'support': 1458024}}
[[ 60714 455287  30846]
 [ 30771 314098  27534]
 [ 36115 453981  48678]]
Evaluating performance on  train set...
2222/2222 - 37s - 37s/epoch - 17ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0833298
{'0': {'precision': 0.47115164341271315, 'recall': 0.23667309631318223, 'f1-score': 0.31507493881243226, 'support': 182488}, '1': {'precision': 0.40167583350308955, 'recall': 0.7179398799930093, 'f1-score': 0.515139429047152, 'support': 205988}, '2': {'precision': 0.44870604458745117, 'recall': 0.2709403085326657, 'f1-score': 0.3378674918142864, 'support': 180143}, 'accuracy': 0.4218729940434632, 'macro avg': {'precision': 0.4405111738344179, 'recall': 0.40851776161295245, 'f1-score': 0.3893606198912902, 'support': 568619}, 'weighted avg': {'precision': 0.4388723832387782, 'recall': 0.4218729940434632, 'f1-score': 0.39477119076652184, 'support': 568619}}
[[ 43190 110661  28637]
 [ 26771 147887  31330]
 [ 21708 109627  48808]]
Evaluating performance on  val set...
641/641 - 9s - 9s/epoch - 15ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0833355
{'0': {'precision': 0.48840358156802793, 'recall': 0.21102094734855634, 'f1-score': 0.29470909929498584, 'support': 52990}, '1': {'precision': 0.4017192880990562, 'recall': 0.7732125689419622, 'f1-score': 0.5287360298951593, 'support': 59289}, '2': {'precision': 0.45899012483696666, 'recall': 0.23884967421656841, 'f1-score': 0.3141971608229277, 'support': 51568}, 'accuracy': 0.4232118989056864, 'macro avg': {'precision': 0.4497043315013503, 'recall': 0.40769439683569564, 'f1-score': 0.3792140966710243, 'support': 163847}, 'weighted avg': {'precision': 0.4477789853765247, 'recall': 0.4232118989056864, 'f1-score': 0.38552664887005644, 'support': 163847}}
[[11182 34369  7439]
 [ 6367 45843  7079]
 [ 5346 33905 12317]]
training model: results/WBA/W1/deepLOB_L1/h100
Epoch 1/50
2222/2222 - 91s - loss: 3.2220 - accuracy100: 0.4136 - val_loss: 3.4278 - val_accuracy100: 0.3228 - 91s/epoch - 41ms/step
Epoch 2/50
2222/2222 - 83s - loss: 3.2068 - accuracy100: 0.4184 - val_loss: 3.3850 - val_accuracy100: 0.3342 - 83s/epoch - 38ms/step
Epoch 3/50
2222/2222 - 82s - loss: 3.1818 - accuracy100: 0.4328 - val_loss: 3.4486 - val_accuracy100: 0.3299 - 82s/epoch - 37ms/step
Epoch 4/50
2222/2222 - 95s - loss: 3.1652 - accuracy100: 0.4404 - val_loss: 3.4779 - val_accuracy100: 0.3317 - 95s/epoch - 43ms/step
Epoch 5/50
2222/2222 - 87s - loss: 3.1558 - accuracy100: 0.4427 - val_loss: 3.5127 - val_accuracy100: 0.3322 - 87s/epoch - 39ms/step
Epoch 6/50
2222/2222 - 86s - loss: 3.1476 - accuracy100: 0.4457 - val_loss: 3.5181 - val_accuracy100: 0.3305 - 86s/epoch - 39ms/step
Epoch 7/50
2222/2222 - 90s - loss: 3.1403 - accuracy100: 0.4482 - val_loss: 3.5172 - val_accuracy100: 0.3288 - 90s/epoch - 41ms/step
Epoch 8/50
2222/2222 - 86s - loss: 3.1366 - accuracy100: 0.4494 - val_loss: 3.5146 - val_accuracy100: 0.3290 - 86s/epoch - 39ms/step
Epoch 9/50
2222/2222 - 86s - loss: 3.1317 - accuracy100: 0.4511 - val_loss: 3.5009 - val_accuracy100: 0.3289 - 86s/epoch - 39ms/step
Epoch 10/50
2222/2222 - 93s - loss: 3.1287 - accuracy100: 0.4520 - val_loss: 3.4838 - val_accuracy100: 0.3285 - 93s/epoch - 42ms/step
Epoch 11/50
2222/2222 - 89s - loss: 3.1231 - accuracy100: 0.4536 - val_loss: 3.4896 - val_accuracy100: 0.3262 - 89s/epoch - 40ms/step
Epoch 12/50
2222/2222 - 92s - loss: 3.1201 - accuracy100: 0.4546 - val_loss: 3.4840 - val_accuracy100: 0.3288 - 92s/epoch - 41ms/step
testing model: results/WBA/W1/deepLOB_L1/h100
Evaluating performance on  test set...
5696/5696 - 90s - 90s/epoch - 16ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.1236792
{'0': {'precision': 0.37993017374775356, 'recall': 0.9477329320963479, 'f1-score': 0.5424152196033295, 'support': 548969}, '1': {'precision': 0.2558291238751547, 'recall': 0.042336756442549896, 'f1-score': 0.07265066879464964, 'support': 361270}, '2': {'precision': 0.3721002808696557, 'recall': 0.019589802568525973, 'f1-score': 0.0372200948971947, 'support': 547785}, 'accuracy': 0.3746865620867695, 'macro avg': {'precision': 0.3359531928308546, 'recall': 0.33655316370247457, 'f1-score': 0.2174286610983913, 'support': 1458024}, 'weighted avg': {'precision': 0.34623862672404027, 'recall': 0.3746865620867695, 'f1-score': 0.23621302357788557, 'support': 1458024}}
[[520276  19336   9357]
 [337224  15295   8751]
 [511899  25155  10731]]
Evaluating performance on  train set...
2222/2222 - 37s - 37s/epoch - 17ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.122423
{'0': {'precision': 0.35221445911540056, 'recall': 0.6215441038179425, 'f1-score': 0.44963264750789883, 'support': 191412}, '1': {'precision': 0.3367010059386741, 'recall': 0.3698183735084104, 'f1-score': 0.35248351849126314, 'support': 187803}, '2': {'precision': 0.37326982576127665, 'recall': 0.04840974847416105, 'f1-score': 0.08570440439691916, 'support': 189404}, 'accuracy': 0.3474963024450467, 'macro avg': {'precision': 0.3540617636051171, 'recall': 0.34659074193350464, 'f1-score': 0.29594019013202705, 'support': 568619}, 'weighted avg': {'precision': 0.3541041209403603, 'recall': 0.3474963024450467, 'f1-score': 0.2963237309312399, 'support': 568619}}
[[118971  64162   8279]
 [111234  69453   7116]
 [107575  72660   9169]]
Evaluating performance on  val set...
641/641 - 10s - 10s/epoch - 15ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.1288803
{'0': {'precision': 0.3604070175438597, 'recall': 0.44950723825861677, 'f1-score': 0.4000560848127001, 'support': 57127}, '1': {'precision': 0.3073653242526379, 'recall': 0.5170082605985037, 'f1-score': 0.38553009116333126, 'support': 51328}, '2': {'precision': 0.39073482428115014, 'recall': 0.0441580011554015, 'f1-score': 0.07934860182962435, 'support': 55392}, 'accuracy': 0.33361611747544967, 'macro avg': {'precision': 0.3528357220258826, 'recall': 0.3368911666708407, 'f1-score': 0.28831159260188527, 'support': 163847}, 'weighted avg': {'precision': 0.35404372640969284, 'recall': 0.33361611747544967, 'f1-score': 0.28708350002669036, 'support': 163847}}
[[25679 29443  2005]
 [22982 26537  1809]
 [22589 30357  2446]]
training model: results/WBA/W1/deepLOB_L1/h200
Epoch 1/50
2222/2222 - 94s - loss: 3.2641 - accuracy200: 0.3888 - val_loss: 3.4139 - val_accuracy200: 0.3526 - 94s/epoch - 42ms/step
Epoch 2/50
2222/2222 - 93s - loss: 3.2482 - accuracy200: 0.3949 - val_loss: 3.3207 - val_accuracy200: 0.3575 - 93s/epoch - 42ms/step
Epoch 3/50
2222/2222 - 93s - loss: 3.2381 - accuracy200: 0.4017 - val_loss: 3.3230 - val_accuracy200: 0.3506 - 93s/epoch - 42ms/step
Epoch 4/50
2222/2222 - 94s - loss: 3.2331 - accuracy200: 0.4050 - val_loss: 3.3251 - val_accuracy200: 0.3385 - 94s/epoch - 42ms/step
Epoch 5/50
2222/2222 - 94s - loss: 3.2280 - accuracy200: 0.4075 - val_loss: 3.3360 - val_accuracy200: 0.3342 - 94s/epoch - 42ms/step
Epoch 6/50
2222/2222 - 96s - loss: 3.2234 - accuracy200: 0.4113 - val_loss: 3.3632 - val_accuracy200: 0.3358 - 96s/epoch - 43ms/step
Epoch 7/50
2222/2222 - 94s - loss: 3.2208 - accuracy200: 0.4125 - val_loss: 3.3614 - val_accuracy200: 0.3439 - 94s/epoch - 42ms/step
Epoch 8/50
2222/2222 - 90s - loss: 3.2168 - accuracy200: 0.4143 - val_loss: 3.3549 - val_accuracy200: 0.3467 - 90s/epoch - 41ms/step
Epoch 9/50
2222/2222 - 98s - loss: 3.2137 - accuracy200: 0.4162 - val_loss: 3.3727 - val_accuracy200: 0.3342 - 98s/epoch - 44ms/step
Epoch 10/50
2222/2222 - 91s - loss: 3.2108 - accuracy200: 0.4180 - val_loss: 3.3850 - val_accuracy200: 0.3398 - 91s/epoch - 41ms/step
Epoch 11/50
2222/2222 - 95s - loss: 3.2083 - accuracy200: 0.4194 - val_loss: 3.3932 - val_accuracy200: 0.3428 - 95s/epoch - 43ms/step
Epoch 12/50
2222/2222 - 93s - loss: 3.2053 - accuracy200: 0.4203 - val_loss: 3.4072 - val_accuracy200: 0.3451 - 93s/epoch - 42ms/step
testing model: results/WBA/W1/deepLOB_L1/h200
Evaluating performance on  test set...
5696/5696 - 95s - 95s/epoch - 17ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1123945
{'0': {'precision': 0.3536860860333632, 'recall': 0.6715904207524319, 'f1-score': 0.4633524434848938, 'support': 511940}, '1': {'precision': 0.30378551066753695, 'recall': 0.33399899119589144, 'f1-score': 0.31817660606815124, 'support': 436160}, '2': {'precision': 0.3564170705017977, 'recall': 0.0044712545398922195, 'f1-score': 0.00883171515394493, 'support': 509924}, 'accuracy': 0.33728594316691635, 'macro avg': {'precision': 0.33796288906756594, 'recall': 0.3366868888294052, 'f1-score': 0.2634535882356633, 'support': 1458024}, 'weighted avg': {'precision': 0.3397137231453197, 'recall': 0.33728594316691635, 'f1-score': 0.26096145326723125, 'support': 1458024}}
[[343814 165820   2306]
 [288672 145677   1811]
 [339602 168042   2280]]
Evaluating performance on  train set...
2222/2222 - 38s - 38s/epoch - 17ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1055335
{'0': {'precision': 0.3469603838175594, 'recall': 0.7044909560723515, 'f1-score': 0.46493916216884523, 'support': 193500}, '1': {'precision': 0.32888853717405925, 'recall': 0.18032422347447377, 'f1-score': 0.2329343435935699, 'support': 184379}, '2': {'precision': 0.3534408832672312, 'recall': 0.13829296424452134, 'f1-score': 0.1988001748488914, 'support': 190740}, 'accuracy': 0.34459805247450404, 'macro avg': {'precision': 0.3430966014196166, 'recall': 0.34103604793044884, 'f1-score': 0.2988912268704355, 'support': 568619}, 'weighted avg': {'precision': 0.3432742977964248, 'recall': 0.34459805247450404, 'f1-score': 0.3004350444986677, 'support': 568619}}
[[136319  32812  24369]
 [127246  33248  23885]
 [129330  35032  26378]]
Evaluating performance on  val set...
641/641 - 12s - 12s/epoch - 19ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1075641
{'0': {'precision': 0.376811873368712, 'recall': 0.6503324468085107, 'f1-score': 0.47715395544823125, 'support': 60160}, '1': {'precision': 0.3124639505007603, 'recall': 0.12867909045757844, 'f1-score': 0.18228816151728355, 'support': 46309}, '2': {'precision': 0.3316970718245537, 'recall': 0.23671093450451391, 'f1-score': 0.27626748029494025, 'support': 57378}, 'accuracy': 0.3580474467033269, 'macro avg': {'precision': 0.34032429856467533, 'recall': 0.3385741572568677, 'f1-score': 0.31190319908681835, 'support': 163847}, 'weighted avg': {'precision': 0.34282598993421104, 'recall': 0.3580474467033269, 'f1-score': 0.32346542759911723, 'support': 163847}}
[[39124  6441 14595]
 [27580  5959 12770]
 [37125  6671 13582]]
training model: results/WBA/W1/deepLOB_L1/h300
Epoch 1/50
2222/2222 - 98s - loss: 3.2880 - accuracy300: 0.3720 - val_loss: 3.3109 - val_accuracy300: 0.3214 - 98s/epoch - 44ms/step
Epoch 2/50
2222/2222 - 95s - loss: 3.2732 - accuracy300: 0.3761 - val_loss: 3.3083 - val_accuracy300: 0.3451 - 95s/epoch - 43ms/step
Epoch 3/50
2222/2222 - 94s - loss: 3.2670 - accuracy300: 0.3831 - val_loss: 3.3458 - val_accuracy300: 0.3445 - 94s/epoch - 42ms/step
Epoch 4/50
2222/2222 - 96s - loss: 3.2608 - accuracy300: 0.3906 - val_loss: 3.3581 - val_accuracy300: 0.3460 - 96s/epoch - 43ms/step
Epoch 5/50
2222/2222 - 88s - loss: 3.2537 - accuracy300: 0.3960 - val_loss: 3.3496 - val_accuracy300: 0.3497 - 88s/epoch - 40ms/step
Epoch 6/50
2222/2222 - 94s - loss: 3.2496 - accuracy300: 0.3998 - val_loss: 3.3511 - val_accuracy300: 0.3435 - 94s/epoch - 42ms/step
Epoch 7/50
2222/2222 - 90s - loss: 3.2441 - accuracy300: 0.4024 - val_loss: 3.3341 - val_accuracy300: 0.3486 - 90s/epoch - 41ms/step
Epoch 8/50
2222/2222 - 93s - loss: 3.2414 - accuracy300: 0.4035 - val_loss: 3.3174 - val_accuracy300: 0.3543 - 93s/epoch - 42ms/step
Epoch 9/50
2222/2222 - 95s - loss: 3.2384 - accuracy300: 0.4043 - val_loss: 3.3269 - val_accuracy300: 0.3529 - 95s/epoch - 43ms/step
Epoch 10/50
2222/2222 - 100s - loss: 3.2353 - accuracy300: 0.4064 - val_loss: 3.3228 - val_accuracy300: 0.3504 - 100s/epoch - 45ms/step
Epoch 11/50
2222/2222 - 98s - loss: 3.2337 - accuracy300: 0.4069 - val_loss: 3.3499 - val_accuracy300: 0.3442 - 98s/epoch - 44ms/step
Epoch 12/50
2222/2222 - 92s - loss: 3.2300 - accuracy300: 0.4088 - val_loss: 3.3535 - val_accuracy300: 0.3365 - 92s/epoch - 41ms/step
testing model: results/WBA/W1/deepLOB_L1/h300
Evaluating performance on  test set...
5696/5696 - 89s - 89s/epoch - 16ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1106651
{'0': {'precision': 0.3610098845654734, 'recall': 0.7983305361377144, 'f1-score': 0.49718824522888694, 'support': 519568}, '1': {'precision': 0.30683111687800674, 'recall': 0.15520881464368225, 'f1-score': 0.206141896825197, 'support': 422025}, '2': {'precision': 0.36175221275972463, 'recall': 0.06695376536265252, 'f1-score': 0.11299433181974892, 'support': 516431}, 'accuracy': 0.35312587447120214, 'macro avg': {'precision': 0.3431977380677349, 'recall': 0.34016437204801636, 'f1-score': 0.2721081579579443, 'support': 1458024}, 'weighted avg': {'precision': 0.3455907740833292, 'recall': 0.35312587447120214, 'f1-score': 0.27686369496026186, 'support': 1458024}}
[[414787  73017  31764]
 [327282  65502  29241]
 [406894  74960  34577]]
Evaluating performance on  train set...
2222/2222 - 37s - 37s/epoch - 17ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.104468
{'0': {'precision': 0.34434333751198287, 'recall': 0.6003373461758006, 'f1-score': 0.43765511243073835, 'support': 194459}, '1': {'precision': 0.31239791038187037, 'recall': 0.11588451397721504, 'f1-score': 0.1690570425171016, 'support': 183191}, '2': {'precision': 0.3522850302216668, 'recall': 0.2981792856432196, 'f1-score': 0.3229818949087939, 'support': 190969}, 'accuracy': 0.3427831289492613, 'macro avg': {'precision': 0.3363420927051733, 'recall': 0.33813371526541175, 'f1-score': 0.30989801661887795, 'support': 568619}, 'weighted avg': {'precision': 0.3367187283689243, 'recall': 0.3427831289492613, 'f1-score': 0.31260867764312616, 'support': 568619}}
[[116741  23042  54676]
 [111942  21229  50020]
 [110342  23684  56943]]
Evaluating performance on  val set...
641/641 - 11s - 11s/epoch - 17ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1042173
{'0': {'precision': 0.36145254007571154, 'recall': 0.5276569615719183, 'f1-score': 0.4290201571243335, 'support': 58629}, '1': {'precision': 0.2963949008676042, 'recall': 0.19031816901974982, 'f1-score': 0.23179708263420248, 'support': 49722}, '2': {'precision': 0.3468660968660969, 'recall': 0.28958843880640045, 'f1-score': 0.3156499194720509, 'support': 55496}, 'accuracy': 0.3446508022728521, 'macro avg': {'precision': 0.3349045126031375, 'recall': 0.33585452313268954, 'f1-score': 0.3254890530768623, 'support': 163847}, 'weighted avg': {'precision': 0.3367692368167792, 'recall': 0.3446508022728521, 'f1-score': 0.33077044600023986, 'support': 163847}}
[[30936 11340 16353]
 [26351  9463 13908]
 [28301 11124 16071]]
training model: results/WBA/W1/deepLOB_L1/h500
Epoch 1/50
2222/2222 - 103s - loss: 3.2288 - accuracy500: 0.4168 - val_loss: 3.2687 - val_accuracy500: 0.3703 - 103s/epoch - 46ms/step
Epoch 2/50
2222/2222 - 97s - loss: 3.2027 - accuracy500: 0.4312 - val_loss: 3.3238 - val_accuracy500: 0.3330 - 97s/epoch - 44ms/step
Epoch 3/50
2222/2222 - 100s - loss: 3.1886 - accuracy500: 0.4370 - val_loss: 3.4087 - val_accuracy500: 0.2911 - 100s/epoch - 45ms/step
Epoch 4/50
2222/2222 - 98s - loss: 3.1810 - accuracy500: 0.4411 - val_loss: 3.4120 - val_accuracy500: 0.2831 - 98s/epoch - 44ms/step
Epoch 5/50
2222/2222 - 99s - loss: 3.1892 - accuracy500: 0.4370 - val_loss: 3.3348 - val_accuracy500: 0.3002 - 99s/epoch - 44ms/step
Epoch 6/50
2222/2222 - 94s - loss: 3.1748 - accuracy500: 0.4434 - val_loss: 3.4374 - val_accuracy500: 0.2562 - 94s/epoch - 42ms/step
Epoch 7/50
2222/2222 - 94s - loss: 3.1741 - accuracy500: 0.4426 - val_loss: 3.5110 - val_accuracy500: 0.2468 - 94s/epoch - 42ms/step
Epoch 8/50
2222/2222 - 99s - loss: 3.1710 - accuracy500: 0.4463 - val_loss: 3.4541 - val_accuracy500: 0.2626 - 99s/epoch - 45ms/step
Epoch 9/50
2222/2222 - 98s - loss: 3.1673 - accuracy500: 0.4457 - val_loss: 3.5483 - val_accuracy500: 0.2455 - 98s/epoch - 44ms/step
Epoch 10/50
2222/2222 - 105s - loss: 3.1580 - accuracy500: 0.4517 - val_loss: 3.4671 - val_accuracy500: 0.2641 - 105s/epoch - 47ms/step
Epoch 11/50
2222/2222 - 102s - loss: 3.1568 - accuracy500: 0.4517 - val_loss: 3.5343 - val_accuracy500: 0.2579 - 102s/epoch - 46ms/step
testing model: results/WBA/W1/deepLOB_L1/h500
Evaluating performance on  test set...
5696/5696 - 94s - 94s/epoch - 16ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0909171
{'0': {'precision': 0.38347707408614695, 'recall': 0.9011445292575325, 'f1-score': 0.5380078717483092, 'support': 558745}, '1': {'precision': 0.25642862014869383, 'recall': 0.02204526330294865, 'f1-score': 0.04060011933270877, 'support': 341071}, '2': {'precision': 0.3915809490880802, 'recall': 0.08115612818160972, 'f1-score': 0.13444764637971918, 'support': 558208}, 'accuracy': 0.3815650496836815, 'macro avg': {'precision': 0.34382888110764037, 'recall': 0.33478197358069695, 'f1-score': 0.2376852124869124, 'support': 1458024}, 'weighted avg': {'precision': 0.3568596141706573, 'recall': 0.3815650496836815, 'f1-score': 0.2671468256978387, 'support': 1458024}}
[[503510  10907  44328]
 [307492   7519  26060]
 [502010  10896  45302]]
Evaluating performance on  train set...
2222/2222 - 42s - 42s/epoch - 19ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1177889
{'0': {'precision': 0.3292158744731461, 'recall': 0.6990768492986452, 'f1-score': 0.4476297282773767, 'support': 191843}, '1': {'precision': 0.34503843466107614, 'recall': 0.010338040849656097, 'f1-score': 0.020074606385249483, 'support': 191042}, '2': {'precision': 0.3563565751909673, 'recall': 0.2983944781246298, 'f1-score': 0.3248099678249301, 'support': 185734}, 'accuracy': 0.3367984537977099, 'macro avg': {'precision': 0.34353696144172985, 'recall': 0.33593645609097705, 'f1-score': 0.26417143416251876, 'support': 568619}, 'weighted avg': {'precision': 0.34339711789017285, 'recall': 0.3367984537977099, 'f1-score': 0.26386381299070755, 'support': 568619}}
[[134113   1983  55747]
 [144712   1975  44355]
 [128546   1766  55422]]
Evaluating performance on  val set...
641/641 - 11s - 11s/epoch - 18ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0885031
{'0': {'precision': 0.3799155915041388, 'recall': 0.6883292842459353, 'f1-score': 0.48960127609373527, 'support': 64212}, '1': {'precision': 0.33288227334235454, 'recall': 0.006180438660402483, 'f1-score': 0.012135563119727692, 'support': 39803}, '2': {'precision': 0.3484359297825483, 'recall': 0.2723626153229041, 'f1-score': 0.305738220091744, 'support': 59832}, 'accuracy': 0.3707178038047691, 'macro avg': {'precision': 0.3537445982096805, 'recall': 0.3222907794097473, 'f1-score': 0.2691583531017357, 'support': 163847}, 'weighted avg': {'precision': 0.35699446214003877, 'recall': 0.3707178038047691, 'f1-score': 0.3064702932852886, 'support': 163847}}
[[44199   293 19720]
 [28804   246 10753]
 [43336   200 16296]]
training model: results/WBA/W1/deepLOB_L1/h1000
Epoch 1/50
2222/2222 - 109s - loss: 3.2732 - accuracy1000: 0.3904 - val_loss: 3.3257 - val_accuracy1000: 0.3305 - 109s/epoch - 49ms/step
Epoch 2/50
2222/2222 - 99s - loss: 3.2232 - accuracy1000: 0.4123 - val_loss: 3.4005 - val_accuracy1000: 0.3156 - 99s/epoch - 45ms/step
Epoch 3/50
2222/2222 - 99s - loss: 3.1771 - accuracy1000: 0.4374 - val_loss: 3.3842 - val_accuracy1000: 0.3081 - 99s/epoch - 45ms/step
Epoch 4/50
2222/2222 - 103s - loss: 3.1668 - accuracy1000: 0.4408 - val_loss: 3.3783 - val_accuracy1000: 0.3168 - 103s/epoch - 46ms/step
Epoch 5/50
2222/2222 - 98s - loss: 3.1497 - accuracy1000: 0.4477 - val_loss: 3.4276 - val_accuracy1000: 0.3227 - 98s/epoch - 44ms/step
Epoch 6/50
2222/2222 - 101s - loss: 3.1400 - accuracy1000: 0.4514 - val_loss: 3.4223 - val_accuracy1000: 0.3248 - 101s/epoch - 46ms/step
Epoch 7/50
2222/2222 - 100s - loss: 3.1297 - accuracy1000: 0.4556 - val_loss: 3.4392 - val_accuracy1000: 0.3260 - 100s/epoch - 45ms/step
Epoch 8/50
2222/2222 - 103s - loss: 3.1238 - accuracy1000: 0.4566 - val_loss: 3.4093 - val_accuracy1000: 0.3327 - 103s/epoch - 46ms/step
Epoch 9/50
2222/2222 - 102s - loss: 3.1213 - accuracy1000: 0.4569 - val_loss: 3.4437 - val_accuracy1000: 0.3247 - 102s/epoch - 46ms/step
Epoch 10/50
2222/2222 - 105s - loss: 3.1094 - accuracy1000: 0.4610 - val_loss: 3.4186 - val_accuracy1000: 0.3309 - 105s/epoch - 47ms/step
Epoch 11/50
2222/2222 - 101s - loss: 3.1160 - accuracy1000: 0.4601 - val_loss: 3.3849 - val_accuracy1000: 0.3292 - 101s/epoch - 46ms/step
testing model: results/WBA/W1/deepLOB_L1/h1000
Evaluating performance on  test set...
5696/5696 - 101s - 101s/epoch - 18ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1000125
{'0': {'precision': 0.3418037960323583, 'recall': 0.4915229100918302, 'f1-score': 0.4032137582333089, 'support': 505716}, '1': {'precision': 0.2763291800753638, 'recall': 0.09090682875737745, 'f1-score': 0.13680689719737527, 'support': 442057}, '2': {'precision': 0.35010583176592985, 'recall': 0.40164350486329276, 'f1-score': 0.3741080343989763, 'support': 510251}, 'accuracy': 0.33860622321717615, 'macro avg': {'precision': 0.3227462692912173, 'recall': 0.3280244145708335, 'f1-score': 0.30470956327655346, 'support': 1458024}, 'weighted avg': {'precision': 0.324857991113502, 'recall': 0.33860622321717615, 'f1-score': 0.3122562414426705, 'support': 1458024}}
[[248571  53113 204032]
 [225479  40186 176392]
 [253183  52129 204939]]
Evaluating performance on  train set...
2222/2222 - 44s - 44s/epoch - 20ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1017832
{'0': {'precision': 0.3423753307750144, 'recall': 0.5540024542979181, 'f1-score': 0.4232072161962085, 'support': 189871}, '1': {'precision': 0.34473045167557065, 'recall': 0.0540396503943722, 'f1-score': 0.09343284760889312, 'support': 197022}, '2': {'precision': 0.3267968468683433, 'recall': 0.41450865588853547, 'f1-score': 0.3654636886957914, 'support': 181726}, 'accuracy': 0.3361882033488153, 'macro avg': {'precision': 0.33796754310630944, 'recall': 0.3408502535269419, 'f1-score': 0.2940345841669643, 'support': 568619}, 'weighted avg': {'precision': 0.33821260505470907, 'recall': 0.3361882033488153, 'f1-score': 0.2904886367496004, 'support': 568619}}
[[105189  10178  74504]
 [105705  10647  80670]
 [ 96339  10060  75327]]
Evaluating performance on  val set...
641/641 - 11s - 11s/epoch - 17ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1068575
{'0': {'precision': 0.33616966909416124, 'recall': 0.4508799287146358, 'f1-score': 0.3851654504600116, 'support': 58357}, '1': {'precision': 0.3155373831775701, 'recall': 0.05202935680850654, 'f1-score': 0.08932912208754322, 'support': 51913}, '2': {'precision': 0.32921303088928416, 'recall': 0.47324411594527505, 'f1-score': 0.3883026785304073, 'support': 53577}, 'accuracy': 0.3318217605448986, 'macro avg': {'precision': 0.3269733610536718, 'recall': 0.3253844671561391, 'f1-score': 0.287599083692654, 'support': 163847}, 'weighted avg': {'precision': 0.32735779177025115, 'recall': 0.3318217605448986, 'f1-score': 0.2924590350451895, 'support': 163847}}
[[26312  3117 28928]
 [26478  2701 22734]
 [25480  2742 25355]]
training model: results/WBA/W1/deepOF_L1/h10
Epoch 1/50
2222/2222 - 93s - loss: 3.1616 - accuracy10: 0.4116 - val_loss: 3.4748 - val_accuracy10: 0.6214 - 93s/epoch - 42ms/step
Epoch 2/50
2222/2222 - 88s - loss: 3.1298 - accuracy10: 0.4216 - val_loss: 3.4299 - val_accuracy10: 0.6253 - 88s/epoch - 39ms/step
Epoch 3/50
2222/2222 - 91s - loss: 3.1130 - accuracy10: 0.4359 - val_loss: 3.4015 - val_accuracy10: 0.6277 - 91s/epoch - 41ms/step
Epoch 4/50
2222/2222 - 96s - loss: 3.0993 - accuracy10: 0.4428 - val_loss: 3.4040 - val_accuracy10: 0.6288 - 96s/epoch - 43ms/step
Epoch 5/50
2222/2222 - 96s - loss: 3.0883 - accuracy10: 0.4467 - val_loss: 3.4219 - val_accuracy10: 0.6303 - 96s/epoch - 43ms/step
Epoch 6/50
2222/2222 - 91s - loss: 3.0787 - accuracy10: 0.4503 - val_loss: 3.4257 - val_accuracy10: 0.6303 - 91s/epoch - 41ms/step
Epoch 7/50
2222/2222 - 95s - loss: 3.0696 - accuracy10: 0.4532 - val_loss: 3.4150 - val_accuracy10: 0.6305 - 95s/epoch - 43ms/step
Epoch 8/50
2222/2222 - 99s - loss: 3.0603 - accuracy10: 0.4566 - val_loss: 3.4321 - val_accuracy10: 0.6303 - 99s/epoch - 45ms/step
Epoch 9/50
2222/2222 - 96s - loss: 3.0513 - accuracy10: 0.4587 - val_loss: 3.4305 - val_accuracy10: 0.6296 - 96s/epoch - 43ms/step
Epoch 10/50
2222/2222 - 101s - loss: 3.0435 - accuracy10: 0.4607 - val_loss: 3.4246 - val_accuracy10: 0.6303 - 101s/epoch - 45ms/step
Epoch 11/50
2222/2222 - 98s - loss: 3.0355 - accuracy10: 0.4623 - val_loss: 3.4293 - val_accuracy10: 0.6308 - 98s/epoch - 44ms/step
Epoch 12/50
2222/2222 - 100s - loss: 3.0269 - accuracy10: 0.4644 - val_loss: 3.4148 - val_accuracy10: 0.6284 - 100s/epoch - 45ms/step
Epoch 13/50
2222/2222 - 95s - loss: 3.0194 - accuracy10: 0.4657 - val_loss: 3.4339 - val_accuracy10: 0.6289 - 95s/epoch - 43ms/step
testing model: results/WBA/W1/deepOF_L1/h10
Evaluating performance on  test set...
5696/5696 - 97s - 97s/epoch - 17ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.99117345
{'0': {'precision': 0.41796951338675004, 'recall': 0.07568608484862784, 'f1-score': 0.12816415398674663, 'support': 339098}, '1': {'precision': 0.550971202270612, 'recall': 0.9240706808772341, 'f1-score': 0.6903347489217309, 'support': 788615}, '2': {'precision': 0.4414404671785444, 'recall': 0.09886590010475135, 'f1-score': 0.16155060081824074, 'support': 330306}, 'accuracy': 0.5398125813175274, 'macro avg': {'precision': 0.47012706094530216, 'recall': 0.3662075552768711, 'f1-score': 0.3266831679089061, 'support': 1458019}, 'weighted avg': {'precision': 0.4952248329280587, 'recall': 0.5398125813175274, 'f1-score': 0.4397951460600845, 'support': 1458019}}
[[ 25665 305264   8169]
 [ 26728 728736  33151]
 [  9011 288639  32656]]
Evaluating performance on  train set...
2222/2222 - 40s - 40s/epoch - 18ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.90627587
{'0': {'precision': 0.3925001907377737, 'recall': 0.09650974102109539, 'f1-score': 0.15492565405608885, 'support': 106611}, '1': {'precision': 0.6400267675478296, 'recall': 0.9271393670432132, 'f1-score': 0.7572828420132454, 'support': 356928}, '2': {'precision': 0.3799684542586751, 'recall': 0.09170243340724597, 'f1-score': 0.14774722283979483, 'support': 105079}, 'accuracy': 0.6170170483523209, 'macro avg': {'precision': 0.4708318041814262, 'recall': 0.3717838471571849, 'f1-score': 0.3533185729697097, 'support': 568618}, 'weighted avg': {'precision': 0.5455596149385068, 'recall': 0.6170170483523209, 'f1-score': 0.5317055731043691, 'support': 568618}}
[[ 10289  93520   2802]
 [ 13084 330922  12922]
 [  2841  92602   9636]]
Evaluating performance on  val set...
641/641 - 11s - 11s/epoch - 18ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.8931016
{'0': {'precision': 0.4080703407128278, 'recall': 0.08508757570797185, 'f1-score': 0.14081378338841632, 'support': 30545}, '1': {'precision': 0.6471758681983392, 'recall': 0.9380684112365167, 'f1-score': 0.7659327289140075, 'support': 104018}, '2': {'precision': 0.39910514541387027, 'recall': 0.09138407950005123, 'f1-score': 0.14871623874624876, 'support': 29283}, 'accuracy': 0.6277296973987769, 'macro avg': {'precision': 0.48478378477501244, 'recall': 0.3715133554815133, 'f1-score': 0.35182091701622425, 'support': 163846}, 'weighted avg': {'precision': 0.558264736328519, 'recall': 0.6277296973987769, 'f1-score': 0.5390842939649599, 'support': 163846}}
[[ 2599 27206   740]
 [ 3153 97576  3289]
 [  617 25990  2676]]
training model: results/WBA/W1/deepOF_L1/h20
Epoch 1/50
2222/2222 - 103s - loss: 3.1919 - accuracy20: 0.4181 - val_loss: 3.5022 - val_accuracy20: 0.5273 - 103s/epoch - 46ms/step
Epoch 2/50
2222/2222 - 96s - loss: 3.1621 - accuracy20: 0.4290 - val_loss: 3.4558 - val_accuracy20: 0.5330 - 96s/epoch - 43ms/step
Epoch 3/50
2222/2222 - 94s - loss: 3.1491 - accuracy20: 0.4354 - val_loss: 3.4592 - val_accuracy20: 0.5336 - 94s/epoch - 42ms/step
Epoch 4/50
2222/2222 - 96s - loss: 3.1362 - accuracy20: 0.4411 - val_loss: 3.4671 - val_accuracy20: 0.5345 - 96s/epoch - 43ms/step
Epoch 5/50
2222/2222 - 98s - loss: 3.1268 - accuracy20: 0.4457 - val_loss: 3.4821 - val_accuracy20: 0.5346 - 98s/epoch - 44ms/step
Epoch 6/50
2222/2222 - 94s - loss: 3.1175 - accuracy20: 0.4469 - val_loss: 3.4732 - val_accuracy20: 0.5354 - 94s/epoch - 42ms/step
Epoch 7/50
2222/2222 - 91s - loss: 3.1066 - accuracy20: 0.4516 - val_loss: 3.4904 - val_accuracy20: 0.5356 - 91s/epoch - 41ms/step
Epoch 8/50
2222/2222 - 94s - loss: 3.0973 - accuracy20: 0.4557 - val_loss: 3.4915 - val_accuracy20: 0.5357 - 94s/epoch - 42ms/step
Epoch 9/50
2222/2222 - 97s - loss: 3.0877 - accuracy20: 0.4586 - val_loss: 3.4965 - val_accuracy20: 0.5356 - 97s/epoch - 43ms/step
Epoch 10/50
2222/2222 - 95s - loss: 3.0765 - accuracy20: 0.4633 - val_loss: 3.4973 - val_accuracy20: 0.5359 - 95s/epoch - 43ms/step
Epoch 11/50
2222/2222 - 95s - loss: 3.0688 - accuracy20: 0.4651 - val_loss: 3.4888 - val_accuracy20: 0.5364 - 95s/epoch - 43ms/step
Epoch 12/50
2222/2222 - 94s - loss: 3.0597 - accuracy20: 0.4688 - val_loss: 3.4748 - val_accuracy20: 0.5349 - 94s/epoch - 42ms/step
testing model: results/WBA/W1/deepOF_L1/h20
Evaluating performance on  test set...
5696/5696 - 101s - 101s/epoch - 18ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 1.1081045
{'0': {'precision': 0.5038454096933346, 'recall': 0.04824307488525684, 'f1-score': 0.08805491333144541, 'support': 431834}, '1': {'precision': 0.42203226739552646, 'recall': 0.9409635561054341, 'f1-score': 0.5827119588667679, 'support': 607811}, '2': {'precision': 0.5020408163265306, 'recall': 0.07379282651407593, 'f1-score': 0.1286726169016961, 'support': 418374}, 'accuracy': 0.4277269363430792, 'macro avg': {'precision': 0.4759728311384639, 'recall': 0.354333152501589, 'f1-score': 0.2664798296999698, 'support': 1458019}, 'weighted avg': {'precision': 0.4692217711958827, 'recall': 0.4277269363430792, 'f1-score': 0.3059199648961849, 'support': 1458019}}
[[ 20833 402521   8480]
 [ 13741 571928  22142]
 [  6774 380727  30873]]
Evaluating performance on  train set...
2222/2222 - 40s - 40s/epoch - 18ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 1.002894
{'0': {'precision': 0.5006521739130435, 'recall': 0.06732097312861288, 'f1-score': 0.11868304592333014, 'support': 136837}, '1': {'precision': 0.5309741552201834, 'recall': 0.94493968878808, 'f1-score': 0.6799022246795385, 'support': 296711}, '2': {'precision': 0.44790586538028043, 'recall': 0.0735544532464648, 'f1-score': 0.12635849692529777, 'support': 135070}, 'accuracy': 0.526752582577407, 'macro avg': {'precision': 0.4931773981711691, 'recall': 0.36193837172105253, 'f1-score': 0.3083145891760555, 'support': 568618}, 'weighted avg': {'precision': 0.503945107837229, 'recall': 0.526752582577407, 'f1-score': 0.4133564943804123, 'support': 568618}}
[[  9212 124655   2970]
 [  7061 280374   9276]
 [  2127 123008   9935]]
Evaluating performance on  val set...
641/641 - 10s - 10s/epoch - 16ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.9956149
{'0': {'precision': 0.5139126712328768, 'recall': 0.06082484673455946, 'f1-score': 0.10877542699225298, 'support': 39474}, '1': {'precision': 0.5362245163981438, 'recall': 0.952520984081042, 'f1-score': 0.6861684604702949, 'support': 86375}, '2': {'precision': 0.46238244514106586, 'recall': 0.0698739374161118, 'f1-score': 0.12140195249091199, 'support': 37997}, 'accuracy': 0.5330005004699535, 'macro avg': {'precision': 0.5041732109240288, 'recall': 0.36107325607723767, 'f1-score': 0.30544861331782, 'support': 163846}, 'weighted avg': {'precision': 0.5137246387227111, 'recall': 0.5330005004699535, 'f1-score': 0.41608896138453855, 'support': 163846}}
[[ 2401 36289   784]
 [ 1798 82274  2303]
 [  473 34869  2655]]
training model: results/WBA/W1/deepOF_L1/h30
Epoch 1/50
2222/2222 - 100s - loss: 3.2105 - accuracy30: 0.4181 - val_loss: 3.5308 - val_accuracy30: 0.4590 - 100s/epoch - 45ms/step
Epoch 2/50
2222/2222 - 100s - loss: 3.1890 - accuracy30: 0.4231 - val_loss: 3.4713 - val_accuracy30: 0.4650 - 100s/epoch - 45ms/step
Epoch 3/50
2222/2222 - 101s - loss: 3.1753 - accuracy30: 0.4297 - val_loss: 3.4602 - val_accuracy30: 0.4663 - 101s/epoch - 46ms/step
Epoch 4/50
2222/2222 - 94s - loss: 3.1618 - accuracy30: 0.4371 - val_loss: 3.4766 - val_accuracy30: 0.4677 - 94s/epoch - 42ms/step
Epoch 5/50
2222/2222 - 99s - loss: 3.1532 - accuracy30: 0.4405 - val_loss: 3.4780 - val_accuracy30: 0.4683 - 99s/epoch - 45ms/step
Epoch 6/50
2222/2222 - 97s - loss: 3.1436 - accuracy30: 0.4446 - val_loss: 3.4989 - val_accuracy30: 0.4681 - 97s/epoch - 43ms/step
Epoch 7/50
2222/2222 - 94s - loss: 3.1352 - accuracy30: 0.4472 - val_loss: 3.5007 - val_accuracy30: 0.4687 - 94s/epoch - 42ms/step
Epoch 8/50
2222/2222 - 93s - loss: 3.1256 - accuracy30: 0.4515 - val_loss: 3.5033 - val_accuracy30: 0.4700 - 93s/epoch - 42ms/step
Epoch 9/50
2222/2222 - 100s - loss: 3.1179 - accuracy30: 0.4542 - val_loss: 3.4968 - val_accuracy30: 0.4696 - 100s/epoch - 45ms/step
Epoch 10/50
2222/2222 - 99s - loss: 3.1099 - accuracy30: 0.4581 - val_loss: 3.4932 - val_accuracy30: 0.4711 - 99s/epoch - 45ms/step
Epoch 11/50
2222/2222 - 94s - loss: 3.1022 - accuracy30: 0.4607 - val_loss: 3.4960 - val_accuracy30: 0.4705 - 94s/epoch - 42ms/step
Epoch 12/50
2222/2222 - 96s - loss: 3.0953 - accuracy30: 0.4634 - val_loss: 3.4918 - val_accuracy30: 0.4717 - 96s/epoch - 43ms/step
Epoch 13/50
2222/2222 - 101s - loss: 3.0873 - accuracy30: 0.4661 - val_loss: 3.4898 - val_accuracy30: 0.4705 - 101s/epoch - 45ms/step
testing model: results/WBA/W1/deepOF_L1/h30
Evaluating performance on  test set...
5696/5696 - 94s - 94s/epoch - 17ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.165399
{'0': {'precision': 0.527281520254893, 'recall': 0.03818917187084704, 'f1-score': 0.07122011761790129, 'support': 485347}, '1': {'precision': 0.3466749411356709, 'recall': 0.950913500339446, 'f1-score': 0.5081085361403689, 'support': 499343}, '2': {'precision': 0.5452323657692886, 'recall': 0.061272391930348655, 'f1-score': 0.11016464680421102, 'support': 473329}, 'accuracy': 0.3582731089238206, 'macro avg': {'precision': 0.4730629423866175, 'recall': 0.3501250213802139, 'f1-score': 0.22983110018749373, 'support': 1458019}, 'weighted avg': {'precision': 0.47125483248151945, 'recall': 0.3582731089238206, 'f1-score': 0.23348874966281383, 'support': 1458019}}
[[ 18535 457454   9358]
 [  9679 474832  14832]
 [  6938 437389  29002]]
Evaluating performance on  train set...
2222/2222 - 44s - 44s/epoch - 20ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.0601927
{'0': {'precision': 0.5525901680619374, 'recall': 0.05606646996461918, 'f1-score': 0.10180380242246433, 'support': 156582}, '1': {'precision': 0.4608081868962566, 'recall': 0.9586082223734085, 'f1-score': 0.6224170919977181, 'support': 257225}, '2': {'precision': 0.5170145190562614, 'recall': 0.05888470457525628, 'f1-score': 0.10572768972935985, 'support': 154811}, 'accuracy': 0.4651154201942253, 'macro avg': {'precision': 0.5101376246714852, 'recall': 0.357853132304428, 'f1-score': 0.27664952804984744, 'support': 568618}, 'weighted avg': {'precision': 0.5013851026163132, 'recall': 0.4651154201942253, 'f1-score': 0.3383812838403274, 'support': 568618}}
[[  8779 145000   2803]
 [  4934 246578   5713]
 [  2174 143521   9116]]
Evaluating performance on  val set...
641/641 - 13s - 13s/epoch - 20ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.0589687
{'0': {'precision': 0.5606287425149701, 'recall': 0.04943133070814176, 'f1-score': 0.09085211765895078, 'support': 45457}, '1': {'precision': 0.4624436606549872, 'recall': 0.9628779335159229, 'f1-score': 0.6248088826550392, 'support': 74484}, '2': {'precision': 0.5175752473163544, 'recall': 0.0560072884637285, 'f1-score': 0.10107694837224597, 'support': 43905}, 'accuracy': 0.4664440999475117, 'macro avg': {'precision': 0.5135492168287706, 'recall': 0.35610551756259773, 'f1-score': 0.27224598289541196, 'support': 163846}, 'weighted avg': {'precision': 0.5044572073908036, 'recall': 0.4664440999475117, 'f1-score': 0.3363274840178236, 'support': 163846}}
[[ 2247 42417   793]
 [ 1266 71719  1499]
 [  495 40951  2459]]
training model: results/WBA/W1/deepOF_L1/h50
Epoch 1/50
2222/2222 - 106s - loss: 3.2375 - accuracy50: 0.4098 - val_loss: 3.5721 - val_accuracy50: 0.3677 - 106s/epoch - 48ms/step
Epoch 2/50
2222/2222 - 98s - loss: 3.2241 - accuracy50: 0.4132 - val_loss: 3.5278 - val_accuracy50: 0.3711 - 98s/epoch - 44ms/step
Epoch 3/50
2222/2222 - 97s - loss: 3.2113 - accuracy50: 0.4189 - val_loss: 3.5269 - val_accuracy50: 0.3733 - 97s/epoch - 44ms/step
Epoch 4/50
2222/2222 - 90s - loss: 3.1994 - accuracy50: 0.4252 - val_loss: 3.5367 - val_accuracy50: 0.3738 - 90s/epoch - 40ms/step
Epoch 5/50
2222/2222 - 100s - loss: 3.1914 - accuracy50: 0.4284 - val_loss: 3.5382 - val_accuracy50: 0.3748 - 100s/epoch - 45ms/step
Epoch 6/50
2222/2222 - 99s - loss: 3.1825 - accuracy50: 0.4324 - val_loss: 3.5369 - val_accuracy50: 0.3760 - 99s/epoch - 44ms/step
Epoch 7/50
2222/2222 - 95s - loss: 3.1742 - accuracy50: 0.4360 - val_loss: 3.5395 - val_accuracy50: 0.3767 - 95s/epoch - 43ms/step
Epoch 8/50
2222/2222 - 93s - loss: 3.1667 - accuracy50: 0.4400 - val_loss: 3.5430 - val_accuracy50: 0.3775 - 93s/epoch - 42ms/step
Epoch 9/50
2222/2222 - 100s - loss: 3.1602 - accuracy50: 0.4428 - val_loss: 3.5431 - val_accuracy50: 0.3786 - 100s/epoch - 45ms/step
Epoch 10/50
2222/2222 - 107s - loss: 3.1536 - accuracy50: 0.4451 - val_loss: 3.5359 - val_accuracy50: 0.3786 - 107s/epoch - 48ms/step
Epoch 11/50
2222/2222 - 102s - loss: 3.1476 - accuracy50: 0.4472 - val_loss: 3.5327 - val_accuracy50: 0.3803 - 102s/epoch - 46ms/step
Epoch 12/50
2222/2222 - 103s - loss: 3.1419 - accuracy50: 0.4500 - val_loss: 3.5178 - val_accuracy50: 0.3813 - 103s/epoch - 46ms/step
Epoch 13/50
2222/2222 - 103s - loss: 3.1366 - accuracy50: 0.4524 - val_loss: 3.5137 - val_accuracy50: 0.3813 - 103s/epoch - 46ms/step
Epoch 14/50
2222/2222 - 105s - loss: 3.1304 - accuracy50: 0.4551 - val_loss: 3.5078 - val_accuracy50: 0.3823 - 105s/epoch - 47ms/step
Epoch 15/50
2222/2222 - 99s - loss: 3.1253 - accuracy50: 0.4568 - val_loss: 3.5125 - val_accuracy50: 0.3818 - 99s/epoch - 44ms/step
Epoch 16/50
2222/2222 - 101s - loss: 3.1200 - accuracy50: 0.4585 - val_loss: 3.4899 - val_accuracy50: 0.3838 - 101s/epoch - 45ms/step
Epoch 17/50
2222/2222 - 98s - loss: 3.1144 - accuracy50: 0.4606 - val_loss: 3.4856 - val_accuracy50: 0.3849 - 98s/epoch - 44ms/step
Epoch 18/50
2222/2222 - 104s - loss: 3.1091 - accuracy50: 0.4622 - val_loss: 3.4761 - val_accuracy50: 0.3852 - 104s/epoch - 47ms/step
Epoch 19/50
2222/2222 - 96s - loss: 3.1044 - accuracy50: 0.4643 - val_loss: 3.4682 - val_accuracy50: 0.3860 - 96s/epoch - 43ms/step
Epoch 20/50
2222/2222 - 97s - loss: 3.0995 - accuracy50: 0.4658 - val_loss: 3.4696 - val_accuracy50: 0.3879 - 97s/epoch - 44ms/step
Epoch 21/50
2222/2222 - 102s - loss: 3.0959 - accuracy50: 0.4667 - val_loss: 3.4460 - val_accuracy50: 0.3884 - 102s/epoch - 46ms/step
Epoch 22/50
2222/2222 - 104s - loss: 3.0907 - accuracy50: 0.4691 - val_loss: 3.4414 - val_accuracy50: 0.3893 - 104s/epoch - 47ms/step
Epoch 23/50
2222/2222 - 105s - loss: 3.0864 - accuracy50: 0.4702 - val_loss: 3.4565 - val_accuracy50: 0.3904 - 105s/epoch - 47ms/step
Epoch 24/50
2222/2222 - 107s - loss: 3.0830 - accuracy50: 0.4718 - val_loss: 3.4337 - val_accuracy50: 0.3911 - 107s/epoch - 48ms/step
Epoch 25/50
2222/2222 - 107s - loss: 3.0786 - accuracy50: 0.4726 - val_loss: 3.4407 - val_accuracy50: 0.3894 - 107s/epoch - 48ms/step
Epoch 26/50
2222/2222 - 103s - loss: 3.0744 - accuracy50: 0.4743 - val_loss: 3.4453 - val_accuracy50: 0.3902 - 103s/epoch - 46ms/step
Epoch 27/50
2222/2222 - 105s - loss: 3.0708 - accuracy50: 0.4749 - val_loss: 3.4448 - val_accuracy50: 0.3911 - 105s/epoch - 47ms/step
Epoch 28/50
2222/2222 - 106s - loss: 3.0682 - accuracy50: 0.4761 - val_loss: 3.4307 - val_accuracy50: 0.3922 - 106s/epoch - 48ms/step
Epoch 29/50
2222/2222 - 109s - loss: 3.0626 - accuracy50: 0.4775 - val_loss: 3.4459 - val_accuracy50: 0.3912 - 109s/epoch - 49ms/step
Epoch 30/50
2222/2222 - 102s - loss: 3.0596 - accuracy50: 0.4786 - val_loss: 3.4408 - val_accuracy50: 0.3921 - 102s/epoch - 46ms/step
Epoch 31/50
2222/2222 - 105s - loss: 3.0560 - accuracy50: 0.4803 - val_loss: 3.4322 - val_accuracy50: 0.3938 - 105s/epoch - 47ms/step
Epoch 32/50
2222/2222 - 100s - loss: 3.0520 - accuracy50: 0.4809 - val_loss: 3.4204 - val_accuracy50: 0.3935 - 100s/epoch - 45ms/step
Epoch 33/50
2222/2222 - 102s - loss: 3.0492 - accuracy50: 0.4823 - val_loss: 3.4398 - val_accuracy50: 0.3934 - 102s/epoch - 46ms/step
Epoch 34/50
2222/2222 - 105s - loss: 3.0455 - accuracy50: 0.4836 - val_loss: 3.4280 - val_accuracy50: 0.3950 - 105s/epoch - 47ms/step
Epoch 35/50
2222/2222 - 103s - loss: 3.0421 - accuracy50: 0.4844 - val_loss: 3.4266 - val_accuracy50: 0.3958 - 103s/epoch - 46ms/step
Epoch 36/50
2222/2222 - 111s - loss: 3.0390 - accuracy50: 0.4855 - val_loss: 3.4383 - val_accuracy50: 0.3943 - 111s/epoch - 50ms/step
Epoch 37/50
2222/2222 - 107s - loss: 3.0342 - accuracy50: 0.4869 - val_loss: 3.4421 - val_accuracy50: 0.3944 - 107s/epoch - 48ms/step
Epoch 38/50
2222/2222 - 96s - loss: 3.0295 - accuracy50: 0.4876 - val_loss: 3.4323 - val_accuracy50: 0.3960 - 96s/epoch - 43ms/step
Epoch 39/50
2222/2222 - 106s - loss: 3.0278 - accuracy50: 0.4887 - val_loss: 3.4425 - val_accuracy50: 0.3968 - 106s/epoch - 48ms/step
Epoch 40/50
2222/2222 - 106s - loss: 3.0250 - accuracy50: 0.4896 - val_loss: 3.4383 - val_accuracy50: 0.3946 - 106s/epoch - 48ms/step
Epoch 41/50
2222/2222 - 104s - loss: 3.0211 - accuracy50: 0.4905 - val_loss: 3.4359 - val_accuracy50: 0.3952 - 104s/epoch - 47ms/step
Epoch 42/50
2222/2222 - 106s - loss: 3.0175 - accuracy50: 0.4916 - val_loss: 3.4385 - val_accuracy50: 0.3969 - 106s/epoch - 48ms/step
testing model: results/WBA/W1/deepOF_L1/h50
Evaluating performance on  test set...
5696/5696 - 109s - 109s/epoch - 19ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.2046608
{'0': {'precision': 0.47956522566767557, 'recall': 0.09213962300034378, 'f1-score': 0.15457961988618057, 'support': 546844}, '1': {'precision': 0.26389902775582763, 'recall': 0.8474555790366888, 'f1-score': 0.40246866662925873, 'support': 372403}, '2': {'precision': 0.47788743155481983, 'recall': 0.13931124854298294, 'f1-score': 0.2157331079915842, 'support': 538772}, 'accuracy': 0.3024912569726458, 'macro avg': {'precision': 0.4071172283261077, 'recall': 0.3596354835266718, 'f1-score': 0.25759379816900785, 'support': 1458019}, 'weighted avg': {'precision': 0.4238604045434396, 'recall': 0.3024912569726458, 'f1-score': 0.2404923629764881, 'support': 1458019}}
[[ 50386 448757  47701]
 [ 22506 315595  34302]
 [ 32174 431541  75057]]
Evaluating performance on  train set...
2222/2222 - 43s - 43s/epoch - 19ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.1088731
{'0': {'precision': 0.5391171217147231, 'recall': 0.1158199987939985, 'f1-score': 0.19067645559110333, 'support': 182421}, '1': {'precision': 0.3813949705653578, 'recall': 0.8878344069631406, 'f1-score': 0.5335766465947813, 'support': 205999}, '2': {'precision': 0.47792186967589345, 'recall': 0.1323211134418806, 'f1-score': 0.20725893024003758, 'support': 180198}, 'accuracy': 0.40073476393642127, 'macro avg': {'precision': 0.46614465398532473, 'recall': 0.37865850639967324, 'f1-score': 0.31050401080864076, 'support': 568618}, 'weighted avg': {'precision': 0.4625844276362536, 'recall': 0.40073476393642127, 'f1-score': 0.3201574519952891, 'support': 568618}}
[[ 21128 148498  12795]
 [  9854 182893  13252]
 [  8208 148146  23844]]
Evaluating performance on  val set...
641/641 - 13s - 13s/epoch - 20ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.120293
{'0': {'precision': 0.5259420003945552, 'recall': 0.10056392750042437, 'f1-score': 0.16884371190170838, 'support': 53021}, '1': {'precision': 0.37697574893009983, 'recall': 0.8912196684822016, 'f1-score': 0.5298366440604904, 'support': 59303}, '2': {'precision': 0.4592833876221498, 'recall': 0.12041458017934087, 'f1-score': 0.19080424419498695, 'support': 51522}, 'accuracy': 0.39297877275002135, 'macro avg': {'precision': 0.4540670456489349, 'recall': 0.37073272538732227, 'f1-score': 0.29649486671906194, 'support': 163846}, 'weighted avg': {'precision': 0.4510635739584111, 'recall': 0.39297877275002135, 'f1-score': 0.3064083421070631, 'support': 163846}}
[[ 5332 44214  3475]
 [ 2622 52852  3829]
 [ 2184 43134  6204]]
training model: results/WBA/W1/deepOF_L1/h100
Epoch 1/50
2222/2222 - 100s - loss: 3.2657 - accuracy100: 0.3920 - val_loss: 3.4754 - val_accuracy100: 0.3198 - 100s/epoch - 45ms/step
Epoch 2/50
2222/2222 - 106s - loss: 3.2532 - accuracy100: 0.3960 - val_loss: 3.4246 - val_accuracy100: 0.3216 - 106s/epoch - 48ms/step
Epoch 3/50
2222/2222 - 105s - loss: 3.2472 - accuracy100: 0.3983 - val_loss: 3.4184 - val_accuracy100: 0.3228 - 105s/epoch - 47ms/step
Epoch 4/50
2222/2222 - 102s - loss: 3.2416 - accuracy100: 0.4012 - val_loss: 3.4261 - val_accuracy100: 0.3226 - 102s/epoch - 46ms/step
Epoch 5/50
2222/2222 - 111s - loss: 3.2364 - accuracy100: 0.4042 - val_loss: 3.4355 - val_accuracy100: 0.3235 - 111s/epoch - 50ms/step
Epoch 6/50
2222/2222 - 106s - loss: 3.2306 - accuracy100: 0.4074 - val_loss: 3.4391 - val_accuracy100: 0.3244 - 106s/epoch - 48ms/step
Epoch 7/50
2222/2222 - 110s - loss: 3.2271 - accuracy100: 0.4088 - val_loss: 3.4355 - val_accuracy100: 0.3252 - 110s/epoch - 49ms/step
Epoch 8/50
2222/2222 - 108s - loss: 3.2237 - accuracy100: 0.4113 - val_loss: 3.4463 - val_accuracy100: 0.3260 - 108s/epoch - 49ms/step
Epoch 9/50
2222/2222 - 110s - loss: 3.2198 - accuracy100: 0.4140 - val_loss: 3.4443 - val_accuracy100: 0.3262 - 110s/epoch - 49ms/step
Epoch 10/50
2222/2222 - 111s - loss: 3.2165 - accuracy100: 0.4153 - val_loss: 3.4438 - val_accuracy100: 0.3277 - 111s/epoch - 50ms/step
Epoch 11/50
2222/2222 - 111s - loss: 3.2140 - accuracy100: 0.4168 - val_loss: 3.4444 - val_accuracy100: 0.3283 - 111s/epoch - 50ms/step
Epoch 12/50
2222/2222 - 109s - loss: 3.2115 - accuracy100: 0.4178 - val_loss: 3.4440 - val_accuracy100: 0.3287 - 109s/epoch - 49ms/step
Epoch 13/50
2222/2222 - 105s - loss: 3.2087 - accuracy100: 0.4198 - val_loss: 3.4369 - val_accuracy100: 0.3297 - 105s/epoch - 47ms/step
testing model: results/WBA/W1/deepOF_L1/h100
Evaluating performance on  test set...
5696/5696 - 99s - 99s/epoch - 17ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.1862558
{'0': {'precision': 0.45397776945172974, 'recall': 0.03972909167747483, 'f1-score': 0.07306410277884794, 'support': 548968}, '1': {'precision': 0.24763471822295352, 'recall': 0.9514875383371901, 'f1-score': 0.39298970085785223, 'support': 361268}, '2': {'precision': 0.5130736880599744, 'recall': 0.02048986551243832, 'f1-score': 0.03940603062533902, 'support': 547783}, 'accuracy': 0.2584163855203533, 'macro avg': {'precision': 0.40489539191155255, 'recall': 0.33723549850903445, 'f1-score': 0.16848661142067975, 'support': 1458019}, 'weighted avg': {'precision': 0.42505263072011007, 'recall': 0.2584163855203533, 'f1-score': 0.1396898197471043, 'support': 1458019}}
[[ 21810 521787   5371]
 [ 12245 343742   5281]
 [ 13987 522572  11224]]
Evaluating performance on  train set...
2222/2222 - 46s - 46s/epoch - 21ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.130266
{'0': {'precision': 0.47592316463468115, 'recall': 0.05674574746782821, 'f1-score': 0.10140113342770778, 'support': 191239}, '1': {'precision': 0.3321114670226611, 'recall': 0.9479975518241571, 'f1-score': 0.491896944767775, 'support': 187895}, '2': {'precision': 0.4696138425828234, 'recall': 0.02349010998290093, 'f1-score': 0.044742212080698826, 'support': 189484}, 'accuracy': 0.34017037800421374, 'macro avg': {'precision': 0.4258828247467219, 'recall': 0.3427444697582955, 'f1-score': 0.2126800967587272, 'support': 568618}, 'weighted avg': {'precision': 0.42629931434769636, 'recall': 0.34017037800421374, 'f1-score': 0.21155637195203394, 'support': 568618}}
[[ 10852 178089   2298]
 [  7042 178124   2729]
 [  4908 180125   4451]]
Evaluating performance on  val set...
641/641 - 13s - 13s/epoch - 20ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.1417061
{'0': {'precision': 0.5, 'recall': 0.04757405560513009, 'f1-score': 0.08688150053522072, 'support': 57153}, '1': {'precision': 0.3143646196432233, 'recall': 0.9557585911322372, 'f1-score': 0.4731142355686706, 'support': 51332}, '2': {'precision': 0.4812286689419795, 'recall': 0.020375354491428983, 'f1-score': 0.03909539901221731, 'support': 55361}, 'accuracy': 0.32291297926101337, 'macro avg': {'precision': 0.43186442952840093, 'recall': 0.3412360004095987, 'f1-score': 0.19969704503870286, 'support': 163846}, 'weighted avg': {'precision': 0.43549897462753356, 'recall': 0.32291297926101337, 'f1-score': 0.1917397966689198, 'support': 163846}}
[[ 2719 53886   548]
 [ 1603 49061   668]
 [ 1116 53117  1128]]
training model: results/WBA/W1/deepOF_L1/h200
Epoch 1/50
2222/2222 - 112s - loss: 3.2813 - accuracy200: 0.3786 - val_loss: 3.2947 - val_accuracy200: 0.3427 - 112s/epoch - 51ms/step
Epoch 2/50
2222/2222 - 111s - loss: 3.2672 - accuracy200: 0.3828 - val_loss: 3.2803 - val_accuracy200: 0.3730 - 111s/epoch - 50ms/step
Epoch 3/50
2222/2222 - 110s - loss: 3.2650 - accuracy200: 0.3841 - val_loss: 3.2728 - val_accuracy200: 0.3883 - 110s/epoch - 50ms/step
Epoch 4/50
2222/2222 - 108s - loss: 3.2641 - accuracy200: 0.3846 - val_loss: 3.2695 - val_accuracy200: 0.3918 - 108s/epoch - 49ms/step
Epoch 5/50
2222/2222 - 100s - loss: 3.2626 - accuracy200: 0.3857 - val_loss: 3.2699 - val_accuracy200: 0.3910 - 100s/epoch - 45ms/step
Epoch 6/50
2222/2222 - 110s - loss: 3.2613 - accuracy200: 0.3864 - val_loss: 3.2695 - val_accuracy200: 0.3913 - 110s/epoch - 50ms/step
Epoch 7/50
2222/2222 - 104s - loss: 3.2598 - accuracy200: 0.3873 - val_loss: 3.2702 - val_accuracy200: 0.3912 - 104s/epoch - 47ms/step
Epoch 8/50
2222/2222 - 106s - loss: 3.2587 - accuracy200: 0.3878 - val_loss: 3.2703 - val_accuracy200: 0.3927 - 106s/epoch - 48ms/step
Epoch 9/50
2222/2222 - 113s - loss: 3.2572 - accuracy200: 0.3885 - val_loss: 3.2706 - val_accuracy200: 0.3922 - 113s/epoch - 51ms/step
Epoch 10/50
2222/2222 - 108s - loss: 3.2554 - accuracy200: 0.3898 - val_loss: 3.2714 - val_accuracy200: 0.3922 - 108s/epoch - 49ms/step
Epoch 11/50
2222/2222 - 112s - loss: 3.2542 - accuracy200: 0.3907 - val_loss: 3.2720 - val_accuracy200: 0.3923 - 112s/epoch - 51ms/step
Epoch 12/50
2222/2222 - 108s - loss: 3.2534 - accuracy200: 0.3909 - val_loss: 3.2721 - val_accuracy200: 0.3931 - 108s/epoch - 49ms/step
Epoch 13/50
2222/2222 - 102s - loss: 3.2518 - accuracy200: 0.3918 - val_loss: 3.2725 - val_accuracy200: 0.3923 - 102s/epoch - 46ms/step
Epoch 14/50
2222/2222 - 112s - loss: 3.2507 - accuracy200: 0.3929 - val_loss: 3.2720 - val_accuracy200: 0.3918 - 112s/epoch - 51ms/step
Epoch 15/50
2222/2222 - 108s - loss: 3.2494 - accuracy200: 0.3938 - val_loss: 3.2725 - val_accuracy200: 0.3936 - 108s/epoch - 49ms/step
Epoch 16/50
2222/2222 - 109s - loss: 3.2489 - accuracy200: 0.3946 - val_loss: 3.2722 - val_accuracy200: 0.3929 - 109s/epoch - 49ms/step
testing model: results/WBA/W1/deepOF_L1/h200
Evaluating performance on  test set...
5696/5696 - 105s - 105s/epoch - 18ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0966246
{'0': {'precision': 0.37960962686177413, 'recall': 0.4685304303833074, 'f1-score': 0.41940870574822786, 'support': 511939}, '1': {'precision': 0.3163444639718805, 'recall': 0.00041269258987527513, 'f1-score': 0.0008243098122634404, 'support': 436160}, '2': {'precision': 0.3722621194704897, 'recall': 0.6027161123313461, 'f1-score': 0.46025310124274343, 'support': 509920}, 'accuracy': 0.37542446291852166, 'macro avg': {'precision': 0.3560720701013815, 'recall': 0.35721974510150956, 'f1-score': 0.2934953722677449, 'support': 1458019}, 'weighted avg': {'precision': 0.35811445127419966, 'recall': 0.37542446291852166, 'f1-score': 0.3084757234065253, 'support': 1458019}}
[[239859    189 271891]
 [189615    180 246365]
 [202383    200 307337]]
Evaluating performance on  train set...
2222/2222 - 46s - 46s/epoch - 21ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.095438
{'0': {'precision': 0.37582903463522477, 'recall': 0.4982502571630905, 'f1-score': 0.428466650367835, 'support': 193457}, '1': {'precision': 0.36363636363636365, 'recall': 0.0004989532827871964, 'f1-score': 0.0009965391926949345, 'support': 184386}, '2': {'precision': 0.36601131160786426, 'recall': 0.5983802909186214, 'f1-score': 0.4542012903174467, 'support': 190775}, 'accuracy': 0.3704385017709605, 'macro avg': {'precision': 0.3684922366264842, 'recall': 0.36570983378816635, 'f1-score': 0.29455482662599225, 'support': 568618}, 'weighted avg': {'precision': 0.36858140275346807, 'recall': 0.3704385017709605, 'f1-score': 0.298484873528635, 'support': 568618}}
[[ 96390     85  96982]
 [ 83540     92 100754]
 [ 76543     76 114156]]
Evaluating performance on  val set...
641/641 - 13s - 13s/epoch - 20ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0909574
{'0': {'precision': 0.40913477465539344, 'recall': 0.4724245750590427, 'f1-score': 0.4385077921777188, 'support': 60126}, '1': {'precision': 0.3, 'recall': 0.0004532798031470569, 'f1-score': 0.0009051919222397033, 'support': 46329}, '2': {'precision': 0.3771953067865054, 'recall': 0.6200972277883292, 'f1-score': 0.46906550678792674, 'support': 57391}, 'accuracy': 0.3906961414987244, 'macro avg': {'precision': 0.3621100271472996, 'recall': 0.364325027550173, 'f1-score': 0.3028261636292951, 'support': 163846}, 'weighted avg': {'precision': 0.36708832264879526, 'recall': 0.3906961414987244, 'f1-score': 0.3254751086331608, 'support': 163846}}
[[28405    24 31697]
 [19244    21 27064]
 [21778    25 35588]]
training model: results/WBA/W1/deepOF_L1/h300
Epoch 1/50
2222/2222 - 112s - loss: 3.2963 - accuracy300: 0.3648 - val_loss: 3.2938 - val_accuracy300: 0.3362 - 112s/epoch - 50ms/step
Epoch 2/50
2222/2222 - 106s - loss: 3.2823 - accuracy300: 0.3670 - val_loss: 3.2907 - val_accuracy300: 0.3497 - 106s/epoch - 48ms/step
Epoch 3/50
2222/2222 - 113s - loss: 3.2796 - accuracy300: 0.3690 - val_loss: 3.2890 - val_accuracy300: 0.3577 - 113s/epoch - 51ms/step
Epoch 4/50
2222/2222 - 110s - loss: 3.2783 - accuracy300: 0.3700 - val_loss: 3.2878 - val_accuracy300: 0.3637 - 110s/epoch - 49ms/step
Epoch 5/50
2222/2222 - 106s - loss: 3.2775 - accuracy300: 0.3718 - val_loss: 3.2866 - val_accuracy300: 0.3678 - 106s/epoch - 48ms/step
Epoch 6/50
2222/2222 - 112s - loss: 3.2767 - accuracy300: 0.3731 - val_loss: 3.2856 - val_accuracy300: 0.3687 - 112s/epoch - 50ms/step
Epoch 7/50
2222/2222 - 111s - loss: 3.2760 - accuracy300: 0.3732 - val_loss: 3.2858 - val_accuracy300: 0.3704 - 111s/epoch - 50ms/step
Epoch 8/50
2222/2222 - 101s - loss: 3.2752 - accuracy300: 0.3736 - val_loss: 3.2858 - val_accuracy300: 0.3709 - 101s/epoch - 46ms/step
Epoch 9/50
2222/2222 - 114s - loss: 3.2743 - accuracy300: 0.3749 - val_loss: 3.2860 - val_accuracy300: 0.3704 - 114s/epoch - 51ms/step
Epoch 10/50
2222/2222 - 113s - loss: 3.2734 - accuracy300: 0.3756 - val_loss: 3.2859 - val_accuracy300: 0.3717 - 113s/epoch - 51ms/step
Epoch 11/50
2222/2222 - 112s - loss: 3.2728 - accuracy300: 0.3764 - val_loss: 3.2859 - val_accuracy300: 0.3719 - 112s/epoch - 50ms/step
Epoch 12/50
2222/2222 - 112s - loss: 3.2716 - accuracy300: 0.3779 - val_loss: 3.2867 - val_accuracy300: 0.3710 - 112s/epoch - 51ms/step
Epoch 13/50
2222/2222 - 110s - loss: 3.2711 - accuracy300: 0.3773 - val_loss: 3.2851 - val_accuracy300: 0.3735 - 110s/epoch - 50ms/step
Epoch 14/50
2222/2222 - 108s - loss: 3.2703 - accuracy300: 0.3782 - val_loss: 3.2864 - val_accuracy300: 0.3726 - 108s/epoch - 49ms/step
Epoch 15/50
2222/2222 - 100s - loss: 3.2696 - accuracy300: 0.3790 - val_loss: 3.2868 - val_accuracy300: 0.3712 - 100s/epoch - 45ms/step
Epoch 16/50
2222/2222 - 102s - loss: 3.2688 - accuracy300: 0.3795 - val_loss: 3.2856 - val_accuracy300: 0.3739 - 102s/epoch - 46ms/step
Epoch 17/50
2222/2222 - 108s - loss: 3.2681 - accuracy300: 0.3802 - val_loss: 3.2865 - val_accuracy300: 0.3731 - 108s/epoch - 48ms/step
Epoch 18/50
2222/2222 - 113s - loss: 3.2671 - accuracy300: 0.3806 - val_loss: 3.2867 - val_accuracy300: 0.3729 - 113s/epoch - 51ms/step
Epoch 19/50
2222/2222 - 113s - loss: 3.2663 - accuracy300: 0.3823 - val_loss: 3.2863 - val_accuracy300: 0.3735 - 113s/epoch - 51ms/step
Epoch 20/50
2222/2222 - 113s - loss: 3.2656 - accuracy300: 0.3825 - val_loss: 3.2870 - val_accuracy300: 0.3740 - 113s/epoch - 51ms/step
Epoch 21/50
2222/2222 - 102s - loss: 3.2647 - accuracy300: 0.3832 - val_loss: 3.2883 - val_accuracy300: 0.3730 - 102s/epoch - 46ms/step
Epoch 22/50
2222/2222 - 114s - loss: 3.2639 - accuracy300: 0.3836 - val_loss: 3.2889 - val_accuracy300: 0.3718 - 114s/epoch - 52ms/step
Epoch 23/50
2222/2222 - 116s - loss: 3.2628 - accuracy300: 0.3847 - val_loss: 3.2898 - val_accuracy300: 0.3719 - 116s/epoch - 52ms/step
testing model: results/WBA/W1/deepOF_L1/h300
Evaluating performance on  test set...
5696/5696 - 112s - 112s/epoch - 20ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0996269
{'0': {'precision': 0.3812363381191316, 'recall': 0.47263303359714226, 'f1-score': 0.4220432140352807, 'support': 519568}, '1': {'precision': 0.2989144175462992, 'recall': 0.08964634796516795, 'f1-score': 0.13792738879278446, 'support': 422025}, '2': {'precision': 0.3736932999477684, 'recall': 0.49735683331203306, 'f1-score': 0.42674677195993516, 'support': 516426}, 'accuracy': 0.37053426601436606, 'macro avg': {'precision': 0.3512813518710664, 'recall': 0.3532120716247811, 'f1-score': 0.32890579159600014, 'support': 1458019}, 'weighted avg': {'precision': 0.35473645741769083, 'recall': 0.37053426601436606, 'f1-score': 0.34147160177016833, 'support': 1458019}}
[[245565  43120 230883]
 [184600  37833 199592]
 [213963  45615 256848]]
Evaluating performance on  train set...
2222/2222 - 46s - 46s/epoch - 20ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0958616
{'0': {'precision': 0.37224384917802567, 'recall': 0.49638833153264394, 'f1-score': 0.4254447562962587, 'support': 194370}, '1': {'precision': 0.33765861193865165, 'recall': 0.08351663946640175, 'f1-score': 0.13391153664385358, 'support': 183209}, '2': {'precision': 0.36539699367687706, 'recall': 0.5051586325305304, 'f1-score': 0.4240589345467089, 'support': 191039}, 'accuracy': 0.3663074331097503, 'macro avg': {'precision': 0.35843315159785144, 'recall': 0.361687867843192, 'f1-score': 0.3278050758289404, 'support': 568618}, 'weighted avg': {'precision': 0.35880012569851494, 'recall': 0.3663074331097503, 'f1-score': 0.3310470136280531, 'support': 568618}}
[[96483 14934 82953]
 [83256 15301 84652]
 [79454 15080 96505]]
Evaluating performance on  val set...
641/641 - 13s - 13s/epoch - 20ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0963048
{'0': {'precision': 0.39092964716924783, 'recall': 0.4686636887509803, 'f1-score': 0.4262818773212582, 'support': 58654}, '1': {'precision': 0.31734789657820633, 'recall': 0.07476428844259493, 'f1-score': 0.12101786469688587, 'support': 49743}, '2': {'precision': 0.3660677178828994, 'recall': 0.5400999116305073, 'f1-score': 0.4363721140325953, 'support': 55449}, 'accuracy': 0.3732529326318616, 'macro avg': {'precision': 0.3581150872101178, 'recall': 0.36117596294136084, 'f1-score': 0.32789061868357977, 'support': 163846}, 'weighted avg': {'precision': 0.36017670760008585, 'recall': 0.3732529326318616, 'f1-score': 0.3370196783992997, 'support': 163846}}
[[27489  4133 27032]
 [21194  3719 24830]
 [21634  3867 29948]]
training model: results/WBA/W1/deepOF_L1/h500
Epoch 1/50
2222/2222 - 128s - loss: 3.2440 - accuracy500: 0.4066 - val_loss: 3.2386 - val_accuracy500: 0.3878 - 128s/epoch - 58ms/step
Epoch 2/50
2222/2222 - 104s - loss: 3.2384 - accuracy500: 0.4056 - val_loss: 3.2380 - val_accuracy500: 0.3862 - 104s/epoch - 47ms/step
Epoch 3/50
2222/2222 - 107s - loss: 3.2467 - accuracy500: 0.3997 - val_loss: 3.2366 - val_accuracy500: 0.3894 - 107s/epoch - 48ms/step
Epoch 4/50
2222/2222 - 112s - loss: 3.2538 - accuracy500: 0.3965 - val_loss: 3.2367 - val_accuracy500: 0.3924 - 112s/epoch - 51ms/step
Epoch 5/50
2222/2222 - 117s - loss: 3.2596 - accuracy500: 0.3920 - val_loss: 3.2343 - val_accuracy500: 0.3952 - 117s/epoch - 53ms/step
Epoch 6/50
2222/2222 - 114s - loss: 3.2611 - accuracy500: 0.3898 - val_loss: 3.2334 - val_accuracy500: 0.3964 - 114s/epoch - 51ms/step
Epoch 7/50
2222/2222 - 109s - loss: 3.2602 - accuracy500: 0.3903 - val_loss: 3.2333 - val_accuracy500: 0.3963 - 109s/epoch - 49ms/step
Epoch 8/50
2222/2222 - 107s - loss: 3.2586 - accuracy500: 0.3915 - val_loss: 3.2342 - val_accuracy500: 0.3962 - 107s/epoch - 48ms/step
Epoch 9/50
2222/2222 - 108s - loss: 3.2565 - accuracy500: 0.3927 - val_loss: 3.2346 - val_accuracy500: 0.3952 - 108s/epoch - 48ms/step
Epoch 10/50
2222/2222 - 112s - loss: 3.2526 - accuracy500: 0.3963 - val_loss: 3.2353 - val_accuracy500: 0.3957 - 112s/epoch - 51ms/step
Epoch 11/50
2222/2222 - 111s - loss: 3.2525 - accuracy500: 0.3955 - val_loss: 3.2355 - val_accuracy500: 0.3942 - 111s/epoch - 50ms/step
Epoch 12/50
2222/2222 - 113s - loss: 3.2505 - accuracy500: 0.3974 - val_loss: 3.2349 - val_accuracy500: 0.3960 - 113s/epoch - 51ms/step
Epoch 13/50
2222/2222 - 110s - loss: 3.2475 - accuracy500: 0.3999 - val_loss: 3.2349 - val_accuracy500: 0.3963 - 110s/epoch - 49ms/step
Epoch 14/50
2222/2222 - 110s - loss: 3.2471 - accuracy500: 0.4004 - val_loss: 3.2344 - val_accuracy500: 0.3970 - 110s/epoch - 49ms/step
Epoch 15/50
2222/2222 - 117s - loss: 3.2450 - accuracy500: 0.4017 - val_loss: 3.2347 - val_accuracy500: 0.3983 - 117s/epoch - 52ms/step
Epoch 16/50
2222/2222 - 112s - loss: 3.2436 - accuracy500: 0.4027 - val_loss: 3.2349 - val_accuracy500: 0.3977 - 112s/epoch - 50ms/step
Epoch 17/50
2222/2222 - 110s - loss: 3.2411 - accuracy500: 0.4054 - val_loss: 3.2346 - val_accuracy500: 0.3984 - 110s/epoch - 50ms/step
testing model: results/WBA/W1/deepOF_L1/h500
Evaluating performance on  test set...
5696/5696 - 112s - 112s/epoch - 20ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0754879
{'0': {'precision': 0.39886272692809904, 'recall': 0.42369059230955086, 'f1-score': 0.4109019587423086, 'support': 558745}, '1': {'precision': 1.0, 'recall': 5.863898906382854e-06, 'f1-score': 1.17277290425482e-05, 'support': 341070}, '2': {'precision': 0.3935189683652365, 'recall': 0.6094438592342585, 'f1-score': 0.47823849929992074, 'support': 558204}, 'accuracy': 0.39569511782768263, 'macro avg': {'precision': 0.5974605650977786, 'recall': 0.3443801051475719, 'f1-score': 0.29638406192375727, 'support': 1458019}, 'weighted avg': {'precision': 0.5374390982386301, 'recall': 0.39569511782768263, 'f1-score': 0.34056350306630345, 'support': 1458019}}
[[236735      0 322010]
 [138780      2 202288]
 [218010      0 340194]]
Evaluating performance on  train set...
2222/2222 - 47s - 47s/epoch - 21ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1191032
{'0': {'precision': 0.3619190621623691, 'recall': 0.44364783481502723, 'f1-score': 0.3986375530302497, 'support': 191785}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 191042}, '2': {'precision': 0.34432304721699186, 'recall': 0.6181139021804071, 'f1-score': 0.442274919846336, 'support': 185791}, 'accuracy': 0.3515980851819675, 'macro avg': {'precision': 0.23541403645978698, 'recall': 0.35392057899847806, 'f1-score': 0.28030415762552857, 'support': 568618}, 'weighted avg': {'precision': 0.2345735987997251, 'recall': 0.3515980851819675, 'f1-score': 0.2789630344819845, 'support': 568618}}
[[ 85085      0 106700]
 [ 79058      0 111984]
 [ 70951      0 114840]]
Evaluating performance on  val set...
641/641 - 14s - 14s/epoch - 22ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0779593
{'0': {'precision': 0.4190181124880839, 'recall': 0.41067285382830626, 'f1-score': 0.4148035137111805, 'support': 64219}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 39766}, '2': {'precision': 0.3833865181456009, 'recall': 0.6462638445732614, 'f1-score': 0.48126792189939477, 'support': 59861}, 'accuracy': 0.39707408175970116, 'macro avg': {'precision': 0.26746821021122824, 'recall': 0.35231223280052254, 'f1-score': 0.29869047853685843, 'support': 163846}, 'weighted avg': {'precision': 0.3043029706467419, 'recall': 0.39707408175970116, 'f1-score': 0.33841195952197783, 'support': 163846}}
[[26373     0 37846]
 [15392     0 24374]
 [21175     0 38686]]
training model: results/WBA/W1/deepOF_L1/h1000
Epoch 1/50
2222/2222 - 120s - loss: 3.2913 - accuracy1000: 0.3754 - val_loss: 3.3051 - val_accuracy1000: 0.3307 - 120s/epoch - 54ms/step
Epoch 2/50
2222/2222 - 116s - loss: 3.2794 - accuracy1000: 0.3771 - val_loss: 3.2968 - val_accuracy1000: 0.3537 - 116s/epoch - 52ms/step
Epoch 3/50
2222/2222 - 114s - loss: 3.2796 - accuracy1000: 0.3770 - val_loss: 3.2961 - val_accuracy1000: 0.3579 - 114s/epoch - 51ms/step
Epoch 4/50
2222/2222 - 120s - loss: 3.2796 - accuracy1000: 0.3759 - val_loss: 3.2959 - val_accuracy1000: 0.3599 - 120s/epoch - 54ms/step
Epoch 5/50
2222/2222 - 111s - loss: 3.2792 - accuracy1000: 0.3768 - val_loss: 3.2953 - val_accuracy1000: 0.3587 - 111s/epoch - 50ms/step
Epoch 6/50
2222/2222 - 108s - loss: 3.2785 - accuracy1000: 0.3770 - val_loss: 3.2957 - val_accuracy1000: 0.3590 - 108s/epoch - 49ms/step
Epoch 7/50
2222/2222 - 115s - loss: 3.2775 - accuracy1000: 0.3778 - val_loss: 3.2956 - val_accuracy1000: 0.3591 - 115s/epoch - 52ms/step
Epoch 8/50
2222/2222 - 110s - loss: 3.2763 - accuracy1000: 0.3789 - val_loss: 3.2955 - val_accuracy1000: 0.3601 - 110s/epoch - 49ms/step
Epoch 9/50
2222/2222 - 118s - loss: 3.2752 - accuracy1000: 0.3801 - val_loss: 3.2967 - val_accuracy1000: 0.3556 - 118s/epoch - 53ms/step
Epoch 10/50
2222/2222 - 110s - loss: 3.2738 - accuracy1000: 0.3805 - val_loss: 3.2966 - val_accuracy1000: 0.3565 - 110s/epoch - 49ms/step
Epoch 11/50
2222/2222 - 106s - loss: 3.2725 - accuracy1000: 0.3817 - val_loss: 3.2970 - val_accuracy1000: 0.3567 - 106s/epoch - 48ms/step
Epoch 12/50
2222/2222 - 112s - loss: 3.2715 - accuracy1000: 0.3821 - val_loss: 3.2971 - val_accuracy1000: 0.3565 - 112s/epoch - 50ms/step
Epoch 13/50
2222/2222 - 102s - loss: 3.2705 - accuracy1000: 0.3826 - val_loss: 3.2974 - val_accuracy1000: 0.3556 - 102s/epoch - 46ms/step
Epoch 14/50
2222/2222 - 113s - loss: 3.2698 - accuracy1000: 0.3837 - val_loss: 3.2976 - val_accuracy1000: 0.3555 - 113s/epoch - 51ms/step
Epoch 15/50
2222/2222 - 115s - loss: 3.2689 - accuracy1000: 0.3839 - val_loss: 3.2978 - val_accuracy1000: 0.3537 - 115s/epoch - 52ms/step
testing model: results/WBA/W1/deepOF_L1/h1000
Evaluating performance on  test set...
5696/5696 - 118s - 118s/epoch - 21ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0981278
{'0': {'precision': 0.3497917119141438, 'recall': 0.8471293119642487, 'f1-score': 0.49513511139517163, 'support': 505715}, '1': {'precision': 0.3089856250317468, 'recall': 0.027521337746037277, 'f1-score': 0.05054099133624549, 'support': 442057}, '2': {'precision': 0.36512823686558465, 'recall': 0.13875240814742665, 'f1-score': 0.2010889787061206, 'support': 510247}, 'accuracy': 0.3507293114835952, 'macro avg': {'precision': 0.34130185793715845, 'recall': 0.3378010192859042, 'f1-score': 0.24892169381251258, 'support': 1458019}, 'weighted avg': {'precision': 0.3427868645821996, 'recall': 0.3507293114835952, 'f1-score': 0.25743443671460925, 'support': 1458019}}
[[428406  13539  63770]
 [370560  12166  59331]
 [425780  13669  70798]]
Evaluating performance on  train set...
2222/2222 - 47s - 47s/epoch - 21ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0981688
{'0': {'precision': 0.336766718629182, 'recall': 0.858375974241554, 'f1-score': 0.4837455174513138, 'support': 189763}, '1': {'precision': 0.3528676949815338, 'recall': 0.03296630809823422, 'f1-score': 0.06029922224490933, 'support': 197080}, '2': {'precision': 0.3501894053274006, 'recall': 0.12815843762893686, 'f1-score': 0.1876447347754119, 'support': 181775}, 'accuracy': 0.33885842516417, 'macro avg': {'precision': 0.3466079396460388, 'recall': 0.3398335733229083, 'f1-score': 0.24389649149054501, 'support': 568618}, 'weighted avg': {'precision': 0.346638177665108, 'recall': 0.33885842516417, 'f1-score': 0.2423241842712346, 'support': 568618}}
[[162888   6013  20862]
 [168217   6497  22366]
 [152577   5902  23296]]
Evaluating performance on  val set...
641/641 - 10s - 10s/epoch - 16ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0966756
{'0': {'precision': 0.36027238853912374, 'recall': 0.864987146529563, 'f1-score': 0.5086775110358589, 'support': 58350}, '1': {'precision': 0.32543332154227095, 'recall': 0.03544391578217402, 'f1-score': 0.06392551288064342, 'support': 51913}, '2': {'precision': 0.3558956790805614, 'recall': 0.1202060354963328, 'f1-score': 0.17971289463037626, 'support': 53583}, 'accuracy': 0.3585867216776729, 'macro avg': {'precision': 0.34720046305398533, 'recall': 0.3402123659360233, 'f1-score': 0.2507719728489595, 'support': 163846}, 'weighted avg': {'precision': 0.3478026443407559, 'recall': 0.3585867216776729, 'f1-score': 0.2601800102052822, 'support': 163846}}
[[50472  1955  5923]
 [44339  1840  5734]
 [45283  1859  6441]]
training model: results/WBA/W1/deepLOB_L2/h10
Epoch 1/50
2222/2222 - 232s - loss: 2.9898 - accuracy10: 0.4439 - val_loss: 3.0422 - val_accuracy10: 0.4931 - 232s/epoch - 104ms/step
Epoch 2/50
2222/2222 - 223s - loss: 2.8155 - accuracy10: 0.4966 - val_loss: 3.0056 - val_accuracy10: 0.5765 - 223s/epoch - 101ms/step
Epoch 3/50
2222/2222 - 217s - loss: 2.7139 - accuracy10: 0.5421 - val_loss: 2.8527 - val_accuracy10: 0.6076 - 217s/epoch - 97ms/step
Epoch 4/50
2222/2222 - 228s - loss: 2.6357 - accuracy10: 0.5714 - val_loss: 2.7598 - val_accuracy10: 0.5697 - 228s/epoch - 103ms/step
Epoch 5/50
2222/2222 - 221s - loss: 2.5870 - accuracy10: 0.5828 - val_loss: 2.7016 - val_accuracy10: 0.5897 - 221s/epoch - 99ms/step
Epoch 6/50
2222/2222 - 222s - loss: 2.5556 - accuracy10: 0.5894 - val_loss: 2.6847 - val_accuracy10: 0.5890 - 222s/epoch - 100ms/step
Epoch 7/50
2222/2222 - 231s - loss: 2.5313 - accuracy10: 0.5930 - val_loss: 2.6911 - val_accuracy10: 0.5858 - 231s/epoch - 104ms/step
Epoch 8/50
2222/2222 - 227s - loss: 2.5124 - accuracy10: 0.5954 - val_loss: 2.6626 - val_accuracy10: 0.5773 - 227s/epoch - 102ms/step
Epoch 9/50
2222/2222 - 224s - loss: 2.4973 - accuracy10: 0.5975 - val_loss: 2.6540 - val_accuracy10: 0.5887 - 224s/epoch - 101ms/step
Epoch 10/50
2222/2222 - 222s - loss: 2.4860 - accuracy10: 0.5985 - val_loss: 2.6558 - val_accuracy10: 0.5855 - 222s/epoch - 100ms/step
Epoch 11/50
2222/2222 - 227s - loss: 2.4751 - accuracy10: 0.6005 - val_loss: 2.6405 - val_accuracy10: 0.5828 - 227s/epoch - 102ms/step
Epoch 12/50
2222/2222 - 227s - loss: 2.4651 - accuracy10: 0.6012 - val_loss: 2.6300 - val_accuracy10: 0.5808 - 227s/epoch - 102ms/step
Epoch 13/50
2222/2222 - 217s - loss: 2.4578 - accuracy10: 0.6025 - val_loss: 2.6714 - val_accuracy10: 0.5828 - 217s/epoch - 98ms/step
Epoch 14/50
2222/2222 - 226s - loss: 2.4499 - accuracy10: 0.6030 - val_loss: 2.6557 - val_accuracy10: 0.5893 - 226s/epoch - 102ms/step
Epoch 15/50
2222/2222 - 220s - loss: 2.4444 - accuracy10: 0.6041 - val_loss: 2.6606 - val_accuracy10: 0.5917 - 220s/epoch - 99ms/step
Epoch 16/50
2222/2222 - 218s - loss: 2.4378 - accuracy10: 0.6044 - val_loss: 2.6648 - val_accuracy10: 0.5862 - 218s/epoch - 98ms/step
Epoch 17/50
2222/2222 - 226s - loss: 2.4316 - accuracy10: 0.6060 - val_loss: 2.6725 - val_accuracy10: 0.5825 - 226s/epoch - 102ms/step
Epoch 18/50
2222/2222 - 226s - loss: 2.4261 - accuracy10: 0.6065 - val_loss: 2.6640 - val_accuracy10: 0.5901 - 226s/epoch - 102ms/step
Epoch 19/50
2222/2222 - 228s - loss: 2.4200 - accuracy10: 0.6072 - val_loss: 2.6528 - val_accuracy10: 0.5871 - 228s/epoch - 102ms/step
Epoch 20/50
2222/2222 - 224s - loss: 2.4161 - accuracy10: 0.6079 - val_loss: 2.6486 - val_accuracy10: 0.5988 - 224s/epoch - 101ms/step
Epoch 21/50
2222/2222 - 219s - loss: 2.4107 - accuracy10: 0.6083 - val_loss: 2.6513 - val_accuracy10: 0.5926 - 219s/epoch - 99ms/step
Epoch 22/50
2222/2222 - 230s - loss: 2.4056 - accuracy10: 0.6090 - val_loss: 2.6421 - val_accuracy10: 0.5856 - 230s/epoch - 104ms/step
testing model: results/WBA/W1/deepLOB_L2/h10
Evaluating performance on  test set...
5696/5696 - 268s - 268s/epoch - 47ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.990292
{'0': {'precision': 0.37338201720791536, 'recall': 0.7403413162527758, 'f1-score': 0.4964071879968047, 'support': 339099}, '1': {'precision': 0.7816764547337363, 'recall': 0.4192420645789586, 'f1-score': 0.5457683355618284, 'support': 788616}, '2': {'precision': 0.4372599567129406, 'recall': 0.4801322398118126, 'f1-score': 0.4576943278826674, 'support': 330309}, 'accuracy': 0.5077159223716482, 'macro avg': {'precision': 0.5307728095515308, 'recall': 0.546571873547849, 'f1-score': 0.49995661714710016, 'support': 1458024}, 'weighted avg': {'precision': 0.6086915762164284, 'recall': 0.5077159223716482, 'f1-score': 0.5143354145806593, 'support': 1458024}}
[[251049  43915  44135]
 [298027 330621 159968]
 [123289  48428 158592]]
Evaluating performance on  train set...
2222/2222 - 110s - 110s/epoch - 49ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.86657715
{'0': {'precision': 0.3728113963849856, 'recall': 0.7037165519698475, 'f1-score': 0.48740685422991376, 'support': 106658}, '1': {'precision': 0.833591712340751, 'recall': 0.5736727590426559, 'f1-score': 0.6796289784300584, 'support': 357113}, '2': {'precision': 0.4235943684223519, 'recall': 0.490986952540821, 'f1-score': 0.4548076880601828, 'support': 104848}, 'accuracy': 0.5828190756904008, 'macro avg': {'precision': 0.5433324923826962, 'recall': 0.5894587545177749, 'f1-score': 0.5406145069067183, 'support': 568619}, 'weighted avg': {'precision': 0.6715617617862208, 'recall': 0.5828190756904008, 'f1-score': 0.6021182199509366, 'support': 568619}}
[[ 75057  18816  12785]
 [ 94982 204866  57265]
 [ 31288  22081  51479]]
Evaluating performance on  val set...
641/641 - 30s - 30s/epoch - 47ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.8723286
{'0': {'precision': 0.36723432762146535, 'recall': 0.6838804990151017, 'f1-score': 0.47786291062580294, 'support': 30460}, '1': {'precision': 0.8315606265712628, 'recall': 0.5786903525973777, 'f1-score': 0.6824545691580416, 'support': 104028}, '2': {'precision': 0.4055400385844683, 'recall': 0.4797166116012126, 'f1-score': 0.43952065909374616, 'support': 29359}, 'accuracy': 0.5805110865624638, 'macro avg': {'precision': 0.5347783309257322, 'recall': 0.5807624877378973, 'f1-score': 0.5332793796258636, 'support': 163847}, 'weighted avg': {'precision': 0.6689032846076314, 'recall': 0.5805110865624638, 'f1-score': 0.600889703249788, 'support': 163847}}
[[20831  5793  3836]
 [27019 60200 16809]
 [ 8874  6401 14084]]
training model: results/WBA/W1/deepLOB_L2/h20
Epoch 1/50
2222/2222 - 237s - loss: 3.0519 - accuracy20: 0.4544 - val_loss: 3.1715 - val_accuracy20: 0.5205 - 237s/epoch - 107ms/step
Epoch 2/50
2222/2222 - 231s - loss: 2.9231 - accuracy20: 0.4957 - val_loss: 3.1757 - val_accuracy20: 0.5296 - 231s/epoch - 104ms/step
Epoch 3/50
2222/2222 - 223s - loss: 2.8560 - accuracy20: 0.5192 - val_loss: 3.1098 - val_accuracy20: 0.5652 - 223s/epoch - 101ms/step
Epoch 4/50
2222/2222 - 222s - loss: 2.8041 - accuracy20: 0.5383 - val_loss: 2.9995 - val_accuracy20: 0.5640 - 222s/epoch - 100ms/step
Epoch 5/50
2222/2222 - 230s - loss: 2.7587 - accuracy20: 0.5540 - val_loss: 2.9885 - val_accuracy20: 0.5703 - 230s/epoch - 103ms/step
Epoch 6/50
2222/2222 - 227s - loss: 2.7185 - accuracy20: 0.5657 - val_loss: 2.9211 - val_accuracy20: 0.5742 - 227s/epoch - 102ms/step
Epoch 7/50
2222/2222 - 232s - loss: 2.6849 - accuracy20: 0.5753 - val_loss: 2.9033 - val_accuracy20: 0.5771 - 232s/epoch - 104ms/step
Epoch 8/50
2222/2222 - 224s - loss: 2.6595 - accuracy20: 0.5805 - val_loss: 2.8934 - val_accuracy20: 0.5768 - 224s/epoch - 101ms/step
Epoch 9/50
2222/2222 - 220s - loss: 2.6372 - accuracy20: 0.5839 - val_loss: 2.8782 - val_accuracy20: 0.5753 - 220s/epoch - 99ms/step
Epoch 10/50
2222/2222 - 222s - loss: 2.6241 - accuracy20: 0.5852 - val_loss: 2.8762 - val_accuracy20: 0.5785 - 222s/epoch - 100ms/step
Epoch 11/50
2222/2222 - 225s - loss: 2.6096 - accuracy20: 0.5879 - val_loss: 2.8848 - val_accuracy20: 0.5751 - 225s/epoch - 101ms/step
Epoch 12/50
2222/2222 - 214s - loss: 2.5978 - accuracy20: 0.5896 - val_loss: 2.8534 - val_accuracy20: 0.5795 - 214s/epoch - 96ms/step
Epoch 13/50
2222/2222 - 219s - loss: 2.5887 - accuracy20: 0.5910 - val_loss: 2.8666 - val_accuracy20: 0.5727 - 219s/epoch - 99ms/step
Epoch 14/50
2222/2222 - 222s - loss: 2.5796 - accuracy20: 0.5920 - val_loss: 2.8508 - val_accuracy20: 0.5684 - 222s/epoch - 100ms/step
Epoch 15/50
2222/2222 - 225s - loss: 2.5730 - accuracy20: 0.5930 - val_loss: 2.8774 - val_accuracy20: 0.5710 - 225s/epoch - 101ms/step
Epoch 16/50
2222/2222 - 219s - loss: 2.5661 - accuracy20: 0.5937 - val_loss: 2.8764 - val_accuracy20: 0.5676 - 219s/epoch - 99ms/step
Epoch 17/50
2222/2222 - 216s - loss: 2.5605 - accuracy20: 0.5951 - val_loss: 2.8780 - val_accuracy20: 0.5620 - 216s/epoch - 97ms/step
Epoch 18/50
2222/2222 - 222s - loss: 2.5550 - accuracy20: 0.5956 - val_loss: 2.9090 - val_accuracy20: 0.5571 - 222s/epoch - 100ms/step
Epoch 19/50
2222/2222 - 220s - loss: 2.5506 - accuracy20: 0.5961 - val_loss: 2.9291 - val_accuracy20: 0.5499 - 220s/epoch - 99ms/step
Epoch 20/50
2222/2222 - 228s - loss: 2.5452 - accuracy20: 0.5974 - val_loss: 2.9107 - val_accuracy20: 0.5500 - 228s/epoch - 103ms/step
Epoch 21/50
2222/2222 - 221s - loss: 2.5411 - accuracy20: 0.5984 - val_loss: 2.9274 - val_accuracy20: 0.5592 - 221s/epoch - 99ms/step
Epoch 22/50
2222/2222 - 216s - loss: 2.5363 - accuracy20: 0.5992 - val_loss: 2.9355 - val_accuracy20: 0.5483 - 216s/epoch - 97ms/step
Epoch 23/50
2222/2222 - 222s - loss: 2.5313 - accuracy20: 0.6000 - val_loss: 2.9116 - val_accuracy20: 0.5480 - 222s/epoch - 100ms/step
Epoch 24/50
2222/2222 - 220s - loss: 2.5276 - accuracy20: 0.6007 - val_loss: 2.9688 - val_accuracy20: 0.5311 - 220s/epoch - 99ms/step
testing model: results/WBA/W1/deepLOB_L2/h20
Evaluating performance on  test set...
5696/5696 - 281s - 281s/epoch - 49ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 1.0162483
{'0': {'precision': 0.43863732580547127, 'recall': 0.5782287720338276, 'f1-score': 0.4988517619136568, 'support': 431836}, '1': {'precision': 0.5616079464017866, 'recall': 0.5544091831177784, 'f1-score': 0.5579853472878241, 'support': 607811}, '2': {'precision': 0.5113510031481501, 'recall': 0.35290658903333594, 'f1-score': 0.41760498247817196, 'support': 418377}, 'accuracy': 0.5036432870789507, 'macro avg': {'precision': 0.5038654251184693, 'recall': 0.495181514728314, 'f1-score': 0.491480697226551, 'support': 1458024}, 'weighted avg': {'precision': 0.5107655116658308, 'recall': 0.5036432870789507, 'f1-score': 0.5001893666581453, 'support': 1458024}}
[[249700 122579  59557]
 [189299 336976  81536]
 [130264 140465 147648]]
Evaluating performance on  train set...
2222/2222 - 108s - 108s/epoch - 49ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.9004421
{'0': {'precision': 0.4348243621630079, 'recall': 0.5888335257243889, 'f1-score': 0.500243617077402, 'support': 136874}, '1': {'precision': 0.6970791325399752, 'recall': 0.6428431920582431, 'f1-score': 0.6688635101494519, 'support': 296962}, '2': {'precision': 0.4945297004816788, 'recall': 0.40143044745999124, 'f1-score': 0.44314310051107325, 'support': 134783}, 'accuracy': 0.5726189240950443, 'macro avg': {'precision': 0.5421443983948874, 'recall': 0.5443690550808744, 'f1-score': 0.537416742579309, 'support': 568619}, 'weighted avg': {'precision': 0.5859395477886912, 'recall': 0.5726189240950443, 'f1-score': 0.5747707112513614, 'support': 568619}}
[[ 80596  37327  18951]
 [ 69710 190900  36352]
 [ 35047  45630  54106]]
Evaluating performance on  val set...
641/641 - 28s - 28s/epoch - 44ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.9134865
{'0': {'precision': 0.42775067959667623, 'recall': 0.5631932986419597, 'f1-score': 0.4862158134642356, 'support': 39395}, '1': {'precision': 0.696971216527931, 'recall': 0.6433530827624514, 'f1-score': 0.6690896837240649, 'support': 86416}, '2': {'precision': 0.47801924868053397, 'recall': 0.40480071511199917, 'f1-score': 0.4383737152293369, 'support': 38036}, 'accuracy': 0.5687012883971022, 'macro avg': {'precision': 0.5342470482683804, 'recall': 0.5371156988388034, 'f1-score': 0.5312264041392125, 'support': 163847}, 'weighted avg': {'precision': 0.5814121882793187, 'recall': 0.5687012883971022, 'f1-score': 0.5715607164768681, 'support': 163847}}
[[22187 11340  5868]
 [19875 55596 10945]
 [ 9807 12832 15397]]
training model: results/WBA/W1/deepLOB_L2/h30
Epoch 1/50
2222/2222 - 231s - loss: 3.1180 - accuracy30: 0.4474 - val_loss: 3.3024 - val_accuracy30: 0.4377 - 231s/epoch - 104ms/step
Epoch 2/50
2222/2222 - 221s - loss: 2.9820 - accuracy30: 0.4908 - val_loss: 3.1452 - val_accuracy30: 0.4955 - 221s/epoch - 100ms/step
Epoch 3/50
2222/2222 - 226s - loss: 2.9180 - accuracy30: 0.5117 - val_loss: 3.1001 - val_accuracy30: 0.5222 - 226s/epoch - 102ms/step
Epoch 4/50
2222/2222 - 230s - loss: 2.8677 - accuracy30: 0.5299 - val_loss: 3.0693 - val_accuracy30: 0.5285 - 230s/epoch - 103ms/step
Epoch 5/50
2222/2222 - 227s - loss: 2.8263 - accuracy30: 0.5411 - val_loss: 3.0326 - val_accuracy30: 0.5393 - 227s/epoch - 102ms/step
Epoch 6/50
2222/2222 - 222s - loss: 2.7910 - accuracy30: 0.5497 - val_loss: 2.9767 - val_accuracy30: 0.5438 - 222s/epoch - 100ms/step
Epoch 7/50
2222/2222 - 220s - loss: 2.7625 - accuracy30: 0.5564 - val_loss: 2.9670 - val_accuracy30: 0.5449 - 220s/epoch - 99ms/step
Epoch 8/50
2222/2222 - 223s - loss: 2.7407 - accuracy30: 0.5607 - val_loss: 2.9701 - val_accuracy30: 0.5481 - 223s/epoch - 100ms/step
Epoch 9/50
2222/2222 - 222s - loss: 2.7222 - accuracy30: 0.5642 - val_loss: 2.9550 - val_accuracy30: 0.5519 - 222s/epoch - 100ms/step
Epoch 10/50
2222/2222 - 220s - loss: 2.7086 - accuracy30: 0.5664 - val_loss: 2.9249 - val_accuracy30: 0.5529 - 220s/epoch - 99ms/step
Epoch 11/50
2222/2222 - 224s - loss: 2.6976 - accuracy30: 0.5690 - val_loss: 2.9366 - val_accuracy30: 0.5517 - 224s/epoch - 101ms/step
Epoch 12/50
2222/2222 - 223s - loss: 2.6881 - accuracy30: 0.5710 - val_loss: 2.9326 - val_accuracy30: 0.5529 - 223s/epoch - 100ms/step
Epoch 13/50
2222/2222 - 225s - loss: 2.6794 - accuracy30: 0.5721 - val_loss: 2.9250 - val_accuracy30: 0.5559 - 225s/epoch - 101ms/step
Epoch 14/50
2222/2222 - 225s - loss: 2.6718 - accuracy30: 0.5743 - val_loss: 2.9163 - val_accuracy30: 0.5531 - 225s/epoch - 101ms/step
Epoch 15/50
2222/2222 - 228s - loss: 2.6636 - accuracy30: 0.5755 - val_loss: 2.9206 - val_accuracy30: 0.5536 - 228s/epoch - 103ms/step
Epoch 16/50
2222/2222 - 225s - loss: 2.6585 - accuracy30: 0.5763 - val_loss: 2.9229 - val_accuracy30: 0.5544 - 225s/epoch - 101ms/step
Epoch 17/50
2222/2222 - 223s - loss: 2.6536 - accuracy30: 0.5771 - val_loss: 2.9207 - val_accuracy30: 0.5534 - 223s/epoch - 101ms/step
Epoch 18/50
2222/2222 - 222s - loss: 2.6473 - accuracy30: 0.5780 - val_loss: 2.9244 - val_accuracy30: 0.5519 - 222s/epoch - 100ms/step
Epoch 19/50
2222/2222 - 228s - loss: 2.6421 - accuracy30: 0.5794 - val_loss: 2.9370 - val_accuracy30: 0.5509 - 228s/epoch - 102ms/step
Epoch 20/50
2222/2222 - 225s - loss: 2.6366 - accuracy30: 0.5804 - val_loss: 2.9376 - val_accuracy30: 0.5492 - 225s/epoch - 101ms/step
Epoch 21/50
2222/2222 - 226s - loss: 2.6324 - accuracy30: 0.5810 - val_loss: 2.9574 - val_accuracy30: 0.5486 - 226s/epoch - 102ms/step
Epoch 22/50
2222/2222 - 224s - loss: 2.6266 - accuracy30: 0.5821 - val_loss: 2.9432 - val_accuracy30: 0.5479 - 224s/epoch - 101ms/step
Epoch 23/50
2222/2222 - 221s - loss: 2.6233 - accuracy30: 0.5830 - val_loss: 2.9419 - val_accuracy30: 0.5494 - 221s/epoch - 99ms/step
Epoch 24/50
2222/2222 - 218s - loss: 2.6176 - accuracy30: 0.5837 - val_loss: 2.9419 - val_accuracy30: 0.5474 - 218s/epoch - 98ms/step
testing model: results/WBA/W1/deepLOB_L2/h30
Evaluating performance on  test set...
5696/5696 - 269s - 269s/epoch - 47ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.006985
{'0': {'precision': 0.4943980701995993, 'recall': 0.4585957733507229, 'f1-score': 0.47582440722098523, 'support': 485349}, '1': {'precision': 0.48263845656940885, 'recall': 0.6598490416407159, 'f1-score': 0.5575002326506096, 'support': 499343}, '2': {'precision': 0.5206821781721439, 'recall': 0.35766016242299276, 'f1-score': 0.4240425715777859, 'support': 473332}, 'accuracy': 0.4947531727872792, 'macro avg': {'precision': 0.49923956831371735, 'recall': 0.49203499247147714, 'f1-score': 0.4857890704831269, 'support': 1458024}, 'weighted avg': {'precision': 0.4989035026519597, 'recall': 0.4947531727872792, 'f1-score': 0.48698626180557236, 'support': 1458024}}
[[222579 178068  84702]
 [ 98711 329491  71141]
 [128912 175128 169292]]
Evaluating performance on  train set...
2222/2222 - 99s - 99s/epoch - 44ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.91473967
{'0': {'precision': 0.4979381157976309, 'recall': 0.4596322482164869, 'f1-score': 0.47801900359015753, 'support': 156573}, '1': {'precision': 0.6032085962157421, 'recall': 0.7505185392341933, 'f1-score': 0.6688485775752404, 'support': 257454}, '2': {'precision': 0.5185420762499519, 'recall': 0.34805164562202445, 'f1-score': 0.4165260338447723, 'support': 154592}, 'accuracy': 0.5610013031572987, 'macro avg': {'precision': 0.5398962627544416, 'recall': 0.5194008110242349, 'f1-score': 0.52113120500339, 'support': 568619}, 'weighted avg': {'precision': 0.5512031556921994, 'recall': 0.5610013031572987, 'f1-score': 0.5477027742026008, 'support': 568619}}
[[ 71966  61635  22972]
 [ 37244 193224  26986]
 [ 35318  65468  53806]]
Evaluating performance on  val set...
641/641 - 32s - 32s/epoch - 49ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.9299763
{'0': {'precision': 0.4943471735867934, 'recall': 0.43505249950472163, 'f1-score': 0.4628083691414254, 'support': 45429}, '1': {'precision': 0.6013348860279054, 'recall': 0.7485671333270695, 'f1-score': 0.6669217844693052, 'support': 74501}, '2': {'precision': 0.4907630522088353, 'recall': 0.3478151968486008, 'f1-score': 0.4071053543349058, 'support': 43917}, 'accuracy': 0.5542243678553773, 'macro avg': {'precision': 0.5288150372745114, 'recall': 0.5104782765601307, 'f1-score': 0.5122785026485456, 'support': 163847}, 'weighted avg': {'precision': 0.5420336597966081, 'recall': 0.5542243678553773, 'f1-score': 0.5406880022997039, 'support': 163847}}
[[19764 18287  7378]
 [10260 55769  8472]
 [ 9956 18686 15275]]
training model: results/WBA/W1/deepLOB_L2/h50
Epoch 1/50
2222/2222 - 226s - loss: 3.1652 - accuracy50: 0.4386 - val_loss: 3.3705 - val_accuracy50: 0.4049 - 226s/epoch - 102ms/step
Epoch 2/50
2222/2222 - 229s - loss: 3.0486 - accuracy50: 0.4811 - val_loss: 3.1449 - val_accuracy50: 0.4598 - 229s/epoch - 103ms/step
Epoch 3/50
2222/2222 - 224s - loss: 3.0050 - accuracy50: 0.4921 - val_loss: 3.1165 - val_accuracy50: 0.4673 - 224s/epoch - 101ms/step
Epoch 4/50
2222/2222 - 224s - loss: 2.9810 - accuracy50: 0.4994 - val_loss: 3.1123 - val_accuracy50: 0.4692 - 224s/epoch - 101ms/step
Epoch 5/50
2222/2222 - 223s - loss: 2.9590 - accuracy50: 0.5057 - val_loss: 3.0798 - val_accuracy50: 0.4757 - 223s/epoch - 101ms/step
Epoch 6/50
2222/2222 - 219s - loss: 2.9369 - accuracy50: 0.5110 - val_loss: 3.0710 - val_accuracy50: 0.4813 - 219s/epoch - 98ms/step
Epoch 7/50
2222/2222 - 223s - loss: 2.9184 - accuracy50: 0.5156 - val_loss: 3.0500 - val_accuracy50: 0.4897 - 223s/epoch - 100ms/step
Epoch 8/50
2222/2222 - 215s - loss: 2.8987 - accuracy50: 0.5207 - val_loss: 3.0475 - val_accuracy50: 0.4915 - 215s/epoch - 97ms/step
Epoch 9/50
2222/2222 - 216s - loss: 2.8815 - accuracy50: 0.5245 - val_loss: 3.0389 - val_accuracy50: 0.4947 - 216s/epoch - 97ms/step
Epoch 10/50
2222/2222 - 225s - loss: 2.8643 - accuracy50: 0.5284 - val_loss: 3.0756 - val_accuracy50: 0.4901 - 225s/epoch - 101ms/step
Epoch 11/50
2222/2222 - 218s - loss: 2.8500 - accuracy50: 0.5314 - val_loss: 3.0510 - val_accuracy50: 0.4923 - 218s/epoch - 98ms/step
Epoch 12/50
2222/2222 - 224s - loss: 2.8386 - accuracy50: 0.5340 - val_loss: 3.0285 - val_accuracy50: 0.4970 - 224s/epoch - 101ms/step
Epoch 13/50
2222/2222 - 216s - loss: 2.8283 - accuracy50: 0.5361 - val_loss: 3.0251 - val_accuracy50: 0.4972 - 216s/epoch - 97ms/step
Epoch 14/50
2222/2222 - 220s - loss: 2.8199 - accuracy50: 0.5379 - val_loss: 3.0328 - val_accuracy50: 0.4963 - 220s/epoch - 99ms/step
Epoch 15/50
2222/2222 - 221s - loss: 2.8121 - accuracy50: 0.5395 - val_loss: 3.0271 - val_accuracy50: 0.4988 - 221s/epoch - 99ms/step
Epoch 16/50
2222/2222 - 224s - loss: 2.8062 - accuracy50: 0.5407 - val_loss: 3.0110 - val_accuracy50: 0.4997 - 224s/epoch - 101ms/step
Epoch 17/50
2222/2222 - 223s - loss: 2.8002 - accuracy50: 0.5423 - val_loss: 3.0209 - val_accuracy50: 0.4978 - 223s/epoch - 100ms/step
Epoch 18/50
2222/2222 - 213s - loss: 2.7943 - accuracy50: 0.5434 - val_loss: 3.0246 - val_accuracy50: 0.4991 - 213s/epoch - 96ms/step
Epoch 19/50
2222/2222 - 218s - loss: 2.7899 - accuracy50: 0.5443 - val_loss: 3.0322 - val_accuracy50: 0.4972 - 218s/epoch - 98ms/step
Epoch 20/50
2222/2222 - 219s - loss: 2.7836 - accuracy50: 0.5457 - val_loss: 3.0228 - val_accuracy50: 0.4978 - 219s/epoch - 99ms/step
Epoch 21/50
2222/2222 - 219s - loss: 2.7793 - accuracy50: 0.5465 - val_loss: 3.0525 - val_accuracy50: 0.4928 - 219s/epoch - 98ms/step
Epoch 22/50
2222/2222 - 220s - loss: 2.7733 - accuracy50: 0.5481 - val_loss: 3.0477 - val_accuracy50: 0.4945 - 220s/epoch - 99ms/step
Epoch 23/50
2222/2222 - 217s - loss: 2.7682 - accuracy50: 0.5487 - val_loss: 3.0639 - val_accuracy50: 0.4891 - 217s/epoch - 98ms/step
Epoch 24/50
2222/2222 - 220s - loss: 2.7639 - accuracy50: 0.5500 - val_loss: 3.0659 - val_accuracy50: 0.4923 - 220s/epoch - 99ms/step
Epoch 25/50
2222/2222 - 216s - loss: 2.7593 - accuracy50: 0.5510 - val_loss: 3.0765 - val_accuracy50: 0.4887 - 216s/epoch - 97ms/step
Epoch 26/50
2222/2222 - 213s - loss: 2.7543 - accuracy50: 0.5519 - val_loss: 3.0825 - val_accuracy50: 0.4915 - 213s/epoch - 96ms/step
testing model: results/WBA/W1/deepLOB_L2/h50
Evaluating performance on  test set...
5696/5696 - 261s - 261s/epoch - 46ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0637422
{'0': {'precision': 0.4700934534976474, 'recall': 0.542074839946091, 'f1-score': 0.5035246316547594, 'support': 546847}, '1': {'precision': 0.37588936892234864, 'recall': 0.5663246536682035, 'f1-score': 0.4518621280698465, 'support': 372403}, '2': {'precision': 0.5410724140390658, 'recall': 0.26750734074027327, 'f1-score': 0.3580125319041912, 'support': 538774}, 'accuracy': 0.44680951753880593, 'macro avg': {'precision': 0.46235174548635394, 'recall': 0.4586356114515226, 'f1-score': 0.4377997638762657, 'support': 1458024}, 'weighted avg': {'precision': 0.47226058845471747, 'recall': 0.44680951753880593, 'f1-score': 0.43655906225840857, 'support': 1458024}}
[[296432 175692  74723]
 [113980 210901  47522]
 [220169 174479 144126]]
Evaluating performance on  train set...
2222/2222 - 106s - 106s/epoch - 48ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.99136645
{'0': {'precision': 0.48244348998338404, 'recall': 0.5059565560475209, 'f1-score': 0.49392034664455553, 'support': 182488}, '1': {'precision': 0.5105130578780626, 'recall': 0.6719808920908014, 'f1-score': 0.580222875670419, 'support': 205988}, '2': {'precision': 0.5249486323964636, 'recall': 0.3091765985911193, 'f1-score': 0.38915459350687015, 'support': 180143}, 'accuracy': 0.5037591075922542, 'macro avg': {'precision': 0.5059683934193034, 'recall': 0.4957046822431472, 'f1-score': 0.4877659386072815, 'support': 568619}, 'weighted avg': {'precision': 0.5060779412085602, 'recall': 0.5037591075922542, 'f1-score': 0.4919936932641681, 'support': 568619}}
[[ 92331  64002  26155]
 [ 43321 138420  24247]
 [ 55730  68717  55696]]
Evaluating performance on  val set...
641/641 - 31s - 31s/epoch - 48ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.9967937
{'0': {'precision': 0.48072496071911425, 'recall': 0.4965465182109832, 'f1-score': 0.48850766774349264, 'support': 52990}, '1': {'precision': 0.5210442844943272, 'recall': 0.6483327430046045, 'f1-score': 0.5777607431122334, 'support': 59289}, '2': {'precision': 0.48927560837577816, 'recall': 0.33530484021098356, 'f1-score': 0.3979150365904175, 'support': 51568}, 'accuracy': 0.5007232357015997, 'macro avg': {'precision': 0.49701495119640654, 'recall': 0.49339470047552375, 'f1-score': 0.4880611491487145, 'support': 163847}, 'weighted avg': {'precision': 0.4980059129835283, 'recall': 0.5007232357015997, 'f1-score': 0.4922919590776977, 'support': 163847}}
[[26312 17305  9373]
 [12174 38439  8676]
 [16248 18029 17291]]
training model: results/WBA/W1/deepLOB_L2/h100
Epoch 1/50
2222/2222 - 232s - loss: 3.2371 - accuracy100: 0.4038 - val_loss: 3.3315 - val_accuracy100: 0.3523 - 232s/epoch - 105ms/step
Epoch 2/50
2222/2222 - 229s - loss: 3.1868 - accuracy100: 0.4292 - val_loss: 3.3066 - val_accuracy100: 0.3790 - 229s/epoch - 103ms/step
Epoch 3/50
2222/2222 - 221s - loss: 3.1626 - accuracy100: 0.4389 - val_loss: 3.2861 - val_accuracy100: 0.3992 - 221s/epoch - 99ms/step
Epoch 4/50
2222/2222 - 217s - loss: 3.1521 - accuracy100: 0.4431 - val_loss: 3.2624 - val_accuracy100: 0.4040 - 217s/epoch - 98ms/step
Epoch 5/50
2222/2222 - 214s - loss: 3.1420 - accuracy100: 0.4459 - val_loss: 3.2681 - val_accuracy100: 0.4042 - 214s/epoch - 96ms/step
Epoch 6/50
2222/2222 - 223s - loss: 3.1341 - accuracy100: 0.4496 - val_loss: 3.2733 - val_accuracy100: 0.4055 - 223s/epoch - 100ms/step
Epoch 7/50
2222/2222 - 219s - loss: 3.1272 - accuracy100: 0.4515 - val_loss: 3.2734 - val_accuracy100: 0.4067 - 219s/epoch - 98ms/step
Epoch 8/50
2222/2222 - 217s - loss: 3.1217 - accuracy100: 0.4535 - val_loss: 3.2699 - val_accuracy100: 0.4061 - 217s/epoch - 98ms/step
Epoch 9/50
2222/2222 - 217s - loss: 3.1158 - accuracy100: 0.4556 - val_loss: 3.2809 - val_accuracy100: 0.4078 - 217s/epoch - 98ms/step
Epoch 10/50
2222/2222 - 221s - loss: 3.1103 - accuracy100: 0.4586 - val_loss: 3.2824 - val_accuracy100: 0.4043 - 221s/epoch - 99ms/step
Epoch 11/50
2222/2222 - 220s - loss: 3.1051 - accuracy100: 0.4599 - val_loss: 3.2923 - val_accuracy100: 0.4039 - 220s/epoch - 99ms/step
Epoch 12/50
2222/2222 - 214s - loss: 3.1002 - accuracy100: 0.4609 - val_loss: 3.2976 - val_accuracy100: 0.4043 - 214s/epoch - 96ms/step
Epoch 13/50
2222/2222 - 217s - loss: 3.0941 - accuracy100: 0.4638 - val_loss: 3.2774 - val_accuracy100: 0.4062 - 217s/epoch - 97ms/step
Epoch 14/50
2222/2222 - 226s - loss: 3.0900 - accuracy100: 0.4653 - val_loss: 3.2787 - val_accuracy100: 0.4049 - 226s/epoch - 102ms/step
testing model: results/WBA/W1/deepLOB_L2/h100
Evaluating performance on  test set...
5696/5696 - 270s - 270s/epoch - 47ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.1286867
{'0': {'precision': 0.4430837236556983, 'recall': 0.41046397884033525, 'f1-score': 0.42615054235227035, 'support': 548969}, '1': {'precision': 0.27314319457672115, 'recall': 0.5787222852714037, 'f1-score': 0.3711244498367372, 'support': 361270}, '2': {'precision': 0.4699096338077151, 'recall': 0.1578666812709366, 'f1-score': 0.23633600887657244, 'support': 547785}, 'accuracy': 0.3572533785452091, 'macro avg': {'precision': 0.39537885068004486, 'recall': 0.38235098179422516, 'f1-score': 0.3445370003551933, 'support': 1458024}, 'weighted avg': {'precision': 0.4110543580569568, 'recall': 0.3572533785452091, 'f1-score': 0.34120212541052464, 'support': 1458024}}
[[225332 262025  61612]
 [116255 209075  35940]
 [166967 294341  86477]]
Evaluating performance on  train set...
2222/2222 - 96s - 96s/epoch - 43ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0841731
{'0': {'precision': 0.42455557782039904, 'recall': 0.3874104026915763, 'f1-score': 0.40513334626321784, 'support': 191412}, '1': {'precision': 0.38471575801024915, 'recall': 0.540049945954005, 'f1-score': 0.44933700164365115, 'support': 187803}, '2': {'precision': 0.42423056559471467, 'recall': 0.29189985427974063, 'f1-score': 0.3458387937208931, 'support': 189404}, 'accuracy': 0.4060099996658571, 'macro avg': {'precision': 0.411167300475121, 'recall': 0.4064534009751073, 'f1-score': 0.400103047209254, 'support': 568619}, 'weighted avg': {'precision': 0.4112890561329438, 'recall': 0.4060099996658571, 'f1-score': 0.3999821882148323, 'support': 568619}}
[[ 74155  75050  42207]
 [ 53551 101423  32829]
 [ 46959  87158  55287]]
Evaluating performance on  val set...
641/641 - 29s - 29s/epoch - 45ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0884708
{'0': {'precision': 0.4394504936281114, 'recall': 0.3482941516270765, 'f1-score': 0.38859810163665476, 'support': 57127}, '1': {'precision': 0.37844352128851144, 'recall': 0.5200280548628429, 'f1-score': 0.43808007615358735, 'support': 51328}, '2': {'precision': 0.40954224692437396, 'recall': 0.35517764298093585, 'f1-score': 0.38042753139774343, 'support': 55392}, 'accuracy': 0.40441997717382683, 'macro avg': {'precision': 0.4091454206136656, 'recall': 0.4078332831569518, 'f1-score': 0.4023685697293285, 'support': 163847}, 'weighted avg': {'precision': 0.4102278439753231, 'recall': 0.40441997717382683, 'f1-score': 0.40133697730316886, 'support': 163847}}
[[19897 20349 16881]
 [13152 26692 11484]
 [12228 23490 19674]]
training model: results/WBA/W1/deepLOB_L2/h200
Epoch 1/50
2222/2222 - 224s - loss: 3.2756 - accuracy200: 0.3821 - val_loss: 3.2862 - val_accuracy200: 0.3719 - 224s/epoch - 101ms/step
Epoch 2/50
2222/2222 - 214s - loss: 3.2543 - accuracy200: 0.3901 - val_loss: 3.3059 - val_accuracy200: 0.3687 - 214s/epoch - 96ms/step
Epoch 3/50
2222/2222 - 216s - loss: 3.2400 - accuracy200: 0.4006 - val_loss: 3.3391 - val_accuracy200: 0.3542 - 216s/epoch - 97ms/step
Epoch 4/50
2222/2222 - 218s - loss: 3.2254 - accuracy200: 0.4075 - val_loss: 3.3516 - val_accuracy200: 0.3518 - 218s/epoch - 98ms/step
Epoch 5/50
2222/2222 - 222s - loss: 3.2194 - accuracy200: 0.4109 - val_loss: 3.3935 - val_accuracy200: 0.3459 - 222s/epoch - 100ms/step
Epoch 6/50
2222/2222 - 220s - loss: 3.2124 - accuracy200: 0.4157 - val_loss: 3.3569 - val_accuracy200: 0.3431 - 220s/epoch - 99ms/step
Epoch 7/50
2222/2222 - 220s - loss: 3.2060 - accuracy200: 0.4199 - val_loss: 3.3572 - val_accuracy200: 0.3386 - 220s/epoch - 99ms/step
Epoch 8/50
2222/2222 - 215s - loss: 3.2028 - accuracy200: 0.4219 - val_loss: 3.3474 - val_accuracy200: 0.3478 - 215s/epoch - 97ms/step
Epoch 9/50
2222/2222 - 223s - loss: 3.1972 - accuracy200: 0.4242 - val_loss: 3.3702 - val_accuracy200: 0.3460 - 223s/epoch - 100ms/step
Epoch 10/50
2222/2222 - 224s - loss: 3.1913 - accuracy200: 0.4286 - val_loss: 3.3844 - val_accuracy200: 0.3502 - 224s/epoch - 101ms/step
Epoch 11/50
2222/2222 - 224s - loss: 3.1857 - accuracy200: 0.4297 - val_loss: 3.3846 - val_accuracy200: 0.3426 - 224s/epoch - 101ms/step
testing model: results/WBA/W1/deepLOB_L2/h200
Evaluating performance on  test set...
5696/5696 - 270s - 270s/epoch - 47ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1069885
{'0': {'precision': 0.3523076617784216, 'recall': 0.8669883189436262, 'f1-score': 0.5010212979712321, 'support': 511940}, '1': {'precision': 0.3096666812666988, 'recall': 0.04862894350696992, 'f1-score': 0.08405775849940453, 'support': 436160}, '2': {'precision': 0.354717592092887, 'recall': 0.09022717110785136, 'f1-score': 0.14386129481106263, 'support': 509924}, 'accuracy': 0.3505189214992346, 'macro avg': {'precision': 0.33889731171266907, 'recall': 0.33528147785281576, 'f1-score': 0.24298011709389974, 'support': 1458024}, 'weighted avg': {'precision': 0.340394683148221, 'recall': 0.3505189214992346, 'f1-score': 0.2513770706968672, 'support': 1458024}}
[[443846  23077  45017]
 [376270  21210  38680]
 [439709  24206  46009]]
Evaluating performance on  train set...
2222/2222 - 107s - 107s/epoch - 48ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1027081
{'0': {'precision': 0.3443921589070429, 'recall': 0.8876899224806202, 'f1-score': 0.49625500356081637, 'support': 193500}, '1': {'precision': 0.32651449899511914, 'recall': 0.024672007115777828, 'f1-score': 0.04587743493805185, 'support': 184379}, '2': {'precision': 0.3679957089218666, 'recall': 0.10790605012058299, 'f1-score': 0.16687882596181133, 'support': 190740}, 'accuracy': 0.34627580154725746, 'macro avg': {'precision': 0.3463007889413429, 'recall': 0.34008932657232704, 'f1-score': 0.23633708815355983, 'support': 568619}, 'weighted avg': {'precision': 0.3465128690361925, 'recall': 0.34627580154725746, 'f1-score': 0.23972931968403607, 'support': 568619}}
[[171768   4491  17241]
 [161723   4549  18107]
 [165266   4892  20582]]
Evaluating performance on  val set...
641/641 - 29s - 29s/epoch - 45ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0961516
{'0': {'precision': 0.37203864034965617, 'recall': 0.888563829787234, 'f1-score': 0.5244795039343811, 'support': 60160}, '1': {'precision': 0.3295788442703232, 'recall': 0.02906562439266665, 'f1-score': 0.05342011787351418, 'support': 46309}, '2': {'precision': 0.3824242801169227, 'recall': 0.10716650981212311, 'f1-score': 0.16741767292429585, 'support': 57378}, 'accuracy': 0.37199948732659127, 'macro avg': {'precision': 0.3613472549123007, 'recall': 0.34159865466400796, 'f1-score': 0.24843909824406374, 'support': 163847}, 'weighted avg': {'precision': 0.3636749629062388, 'recall': 0.37199948732659127, 'f1-score': 0.2663009419296489, 'support': 163847}}
[[53456  1335  5369]
 [40402  1346  4561]
 [49826  1403  6149]]
training model: results/WBA/W1/deepLOB_L2/h300
Epoch 1/50
2222/2222 - 227s - loss: 3.2908 - accuracy300: 0.3713 - val_loss: 3.3168 - val_accuracy300: 0.3490 - 227s/epoch - 102ms/step
Epoch 2/50
2222/2222 - 216s - loss: 3.2703 - accuracy300: 0.3783 - val_loss: 3.3096 - val_accuracy300: 0.3551 - 216s/epoch - 97ms/step
Epoch 3/50
2222/2222 - 220s - loss: 3.2572 - accuracy300: 0.3889 - val_loss: 3.3336 - val_accuracy300: 0.3449 - 220s/epoch - 99ms/step
Epoch 4/50
2222/2222 - 214s - loss: 3.2448 - accuracy300: 0.4003 - val_loss: 3.3776 - val_accuracy300: 0.3406 - 214s/epoch - 96ms/step
Epoch 5/50
2222/2222 - 211s - loss: 3.2358 - accuracy300: 0.4047 - val_loss: 3.3812 - val_accuracy300: 0.3467 - 211s/epoch - 95ms/step
Epoch 6/50
2222/2222 - 210s - loss: 3.2296 - accuracy300: 0.4081 - val_loss: 3.3872 - val_accuracy300: 0.3447 - 210s/epoch - 94ms/step
Epoch 7/50
2222/2222 - 220s - loss: 3.2197 - accuracy300: 0.4143 - val_loss: 3.3894 - val_accuracy300: 0.3418 - 220s/epoch - 99ms/step
Epoch 8/50
2222/2222 - 212s - loss: 3.2145 - accuracy300: 0.4165 - val_loss: 3.3786 - val_accuracy300: 0.3341 - 212s/epoch - 95ms/step
Epoch 9/50
2222/2222 - 217s - loss: 3.2090 - accuracy300: 0.4193 - val_loss: 3.3750 - val_accuracy300: 0.3411 - 217s/epoch - 98ms/step
Epoch 10/50
2222/2222 - 213s - loss: 3.2019 - accuracy300: 0.4234 - val_loss: 3.3953 - val_accuracy300: 0.3393 - 213s/epoch - 96ms/step
Epoch 11/50
2222/2222 - 219s - loss: 3.1950 - accuracy300: 0.4267 - val_loss: 3.4085 - val_accuracy300: 0.3380 - 219s/epoch - 99ms/step
Epoch 12/50
2222/2222 - 219s - loss: 3.1907 - accuracy300: 0.4293 - val_loss: 3.4014 - val_accuracy300: 0.3356 - 219s/epoch - 98ms/step
testing model: results/WBA/W1/deepLOB_L2/h300
Evaluating performance on  test set...
5696/5696 - 262s - 262s/epoch - 46ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1092441
{'0': {'precision': 0.35728563425988524, 'recall': 0.889985526437348, 'f1-score': 0.5098795728068197, 'support': 519568}, '1': {'precision': 0.3004320293543232, 'recall': 0.06014335643623008, 'f1-score': 0.10022309529920437, 'support': 422025}, '2': {'precision': 0.3470383538845601, 'recall': 0.05329850454368541, 'f1-score': 0.09240530764001377, 'support': 516431}, 'accuracy': 0.3534338255063017, 'macro avg': {'precision': 0.33491867249958956, 'recall': 0.3344757958057545, 'f1-score': 0.23416932524867928, 'support': 1458024}, 'weighted avg': {'precision': 0.33719978117257027, 'recall': 0.3534338255063017, 'f1-score': 0.24343544901015374, 'support': 1458024}}
[[462408  29361  27799]
 [372653  25382  23990]
 [459164  29742  27525]]
Evaluating performance on  train set...
2222/2222 - 110s - 110s/epoch - 49ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1079439
{'0': {'precision': 0.3447864312647701, 'recall': 0.7457716022400609, 'f1-score': 0.47156028633999536, 'support': 194459}, '1': {'precision': 0.3355447154471545, 'recall': 0.08448559154106916, 'f1-score': 0.1349840394913569, 'support': 183191}, '2': {'precision': 0.3585983510011779, 'recall': 0.19130853698767863, 'f1-score': 0.2495074253284116, 'support': 190969}, 'accuracy': 0.34651146022204676, 'macro avg': {'precision': 0.34630983257103415, 'recall': 0.34052191025626954, 'f1-score': 0.28535058371992134, 'support': 568619}, 'weighted avg': {'precision': 0.3464477358251123, 'recall': 0.34651146022204676, 'f1-score': 0.288550305929615, 'support': 568619}}
[[145022  14628  34809]
 [137177  15477  30537]
 [138415  16020  36534]]
Evaluating performance on  val set...
641/641 - 30s - 30s/epoch - 46ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1020056
{'0': {'precision': 0.36299839715640597, 'recall': 0.7455184294461785, 'f1-score': 0.4882596067917784, 'support': 58629}, '1': {'precision': 0.34096615446419604, 'recall': 0.06827963476931741, 'f1-score': 0.1137753648687143, 'support': 49722}, '2': {'precision': 0.33355237611637145, 'recall': 0.2012217096727692, 'f1-score': 0.2510143298679404, 'support': 55496}, 'accuracy': 0.35564276428619385, 'macro avg': {'precision': 0.34583897591232454, 'recall': 0.3383399246294217, 'f1-score': 0.28434976717614435, 'support': 163847}, 'weighted avg': {'precision': 0.34633880891383934, 'recall': 0.35564276428619385, 'f1-score': 0.29425990362318877, 'support': 163847}}
[[43709  2934 11986]
 [36001  3395 10326]
 [40701  3628 11167]]
training model: results/WBA/W1/deepLOB_L2/h500
Epoch 1/50
2222/2222 - 230s - loss: 3.2202 - accuracy500: 0.4155 - val_loss: 3.3037 - val_accuracy500: 0.3810 - 230s/epoch - 104ms/step
Epoch 2/50
2222/2222 - 232s - loss: 3.2050 - accuracy500: 0.4227 - val_loss: 3.4900 - val_accuracy500: 0.2714 - 232s/epoch - 105ms/step
Epoch 3/50
2222/2222 - 223s - loss: 3.1906 - accuracy500: 0.4367 - val_loss: 3.4387 - val_accuracy500: 0.2571 - 223s/epoch - 100ms/step
Epoch 4/50
2222/2222 - 217s - loss: 3.1663 - accuracy500: 0.4497 - val_loss: 3.5571 - val_accuracy500: 0.2596 - 217s/epoch - 98ms/step
Epoch 5/50
2222/2222 - 220s - loss: 3.1555 - accuracy500: 0.4530 - val_loss: 3.5567 - val_accuracy500: 0.2578 - 220s/epoch - 99ms/step
Epoch 6/50
2222/2222 - 211s - loss: 3.1479 - accuracy500: 0.4560 - val_loss: 3.6527 - val_accuracy500: 0.2455 - 211s/epoch - 95ms/step
Epoch 7/50
2222/2222 - 215s - loss: 3.1461 - accuracy500: 0.4545 - val_loss: 3.5640 - val_accuracy500: 0.2608 - 215s/epoch - 97ms/step
Epoch 8/50
2222/2222 - 207s - loss: 3.1363 - accuracy500: 0.4601 - val_loss: 3.5587 - val_accuracy500: 0.2605 - 207s/epoch - 93ms/step
Epoch 9/50
2222/2222 - 215s - loss: 3.1314 - accuracy500: 0.4611 - val_loss: 3.5441 - val_accuracy500: 0.2641 - 215s/epoch - 97ms/step
Epoch 10/50
2222/2222 - 219s - loss: 3.1257 - accuracy500: 0.4629 - val_loss: 3.6585 - val_accuracy500: 0.2881 - 219s/epoch - 98ms/step
Epoch 11/50
2222/2222 - 218s - loss: 3.1194 - accuracy500: 0.4659 - val_loss: 3.5895 - val_accuracy500: 0.2676 - 218s/epoch - 98ms/step
testing model: results/WBA/W1/deepLOB_L2/h500
Evaluating performance on  test set...
5696/5696 - 268s - 268s/epoch - 47ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1296961
{'0': {'precision': 0.3835005503029324, 'recall': 0.9684829394446482, 'f1-score': 0.5494353193697183, 'support': 558745}, '1': {'precision': 0.24991896272285252, 'recall': 0.02712631680793735, 'f1-score': 0.0489405989563359, 'support': 341071}, '2': {'precision': 0.3588276623506976, 'recall': 0.006404422724145838, 'f1-score': 0.012584239603922057, 'support': 558208}, 'accuracy': 0.37994024789715397, 'macro avg': {'precision': 0.3307490584588275, 'recall': 0.33400455965891046, 'f1-score': 0.20365338597665875, 'support': 1458024}, 'weighted avg': {'precision': 0.34280615220278693, 'recall': 0.37994024789715397, 'f1-score': 0.22682142390570792, 'support': 1458024}}
[[541135  13627   3983]
 [329414   9252   2405]
 [540492  14141   3575]]
Evaluating performance on  train set...
2222/2222 - 107s - 107s/epoch - 48ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1258881
{'0': {'precision': 0.31996216125431, 'recall': 0.6752657120666378, 'f1-score': 0.434190967607869, 'support': 191843}, '1': {'precision': 0.4186242790828527, 'recall': 0.015577726363836225, 'f1-score': 0.03003769852284369, 'support': 191042}, '2': {'precision': 0.35966009933986237, 'recall': 0.3033101101575371, 'f1-score': 0.32909033554537803, 'support': 185734}, 'accuracy': 0.3321310051194209, 'macro avg': {'precision': 0.3660821798923417, 'recall': 0.3313845161960037, 'f1-score': 0.26443966722536355, 'support': 568619}, 'weighted avg': {'precision': 0.36607716118674705, 'recall': 0.3321310051194209, 'f1-score': 0.26407528447375617, 'support': 568619}}
[[129545   2083  60215]
 [147982   2976  40084]
 [127349   2050  56335]]
Evaluating performance on  val set...
641/641 - 33s - 33s/epoch - 51ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0997969
{'0': {'precision': 0.385991104475755, 'recall': 0.7730642247554974, 'f1-score': 0.5148950294581363, 'support': 64212}, '1': {'precision': 0.28987068965517243, 'recall': 0.013516569102831446, 'f1-score': 0.025828752490458247, 'support': 39803}, '2': {'precision': 0.36361458052535417, 'recall': 0.2029014574140928, 'f1-score': 0.2604619229985304, 'support': 59832}, 'accuracy': 0.38034263672816715, 'macro avg': {'precision': 0.3464921248854272, 'recall': 0.32982741709080726, 'f1-score': 0.26706190164904164, 'support': 163847}, 'weighted avg': {'precision': 0.35446954440993733, 'recall': 0.38034263672816715, 'f1-score': 0.30317588508664567, 'support': 163847}}
[[49640   668 13904]
 [31922   538  7343]
 [47042   650 12140]]
training model: results/WBA/W1/deepLOB_L2/h1000
Epoch 1/50
2222/2222 - 217s - loss: 3.2729 - accuracy1000: 0.3852 - val_loss: 3.3029 - val_accuracy1000: 0.3340 - 217s/epoch - 98ms/step
Epoch 2/50
2222/2222 - 217s - loss: 3.2628 - accuracy1000: 0.3874 - val_loss: 3.3060 - val_accuracy1000: 0.3552 - 217s/epoch - 98ms/step
Epoch 3/50
2222/2222 - 219s - loss: 3.2244 - accuracy1000: 0.4105 - val_loss: 3.3798 - val_accuracy1000: 0.3246 - 219s/epoch - 98ms/step
Epoch 4/50
2222/2222 - 208s - loss: 3.1794 - accuracy1000: 0.4323 - val_loss: 3.3737 - val_accuracy1000: 0.3279 - 208s/epoch - 94ms/step
Epoch 5/50
2222/2222 - 224s - loss: 3.1646 - accuracy1000: 0.4401 - val_loss: 3.3327 - val_accuracy1000: 0.3299 - 224s/epoch - 101ms/step
Epoch 6/50
2222/2222 - 224s - loss: 3.1539 - accuracy1000: 0.4461 - val_loss: 3.4539 - val_accuracy1000: 0.3277 - 224s/epoch - 101ms/step
Epoch 7/50
2222/2222 - 226s - loss: 3.1370 - accuracy1000: 0.4516 - val_loss: 3.5196 - val_accuracy1000: 0.3259 - 226s/epoch - 102ms/step
Epoch 8/50
2222/2222 - 218s - loss: 3.1246 - accuracy1000: 0.4560 - val_loss: 3.4047 - val_accuracy1000: 0.3230 - 218s/epoch - 98ms/step
Epoch 9/50
2222/2222 - 209s - loss: 3.1116 - accuracy1000: 0.4610 - val_loss: 3.4006 - val_accuracy1000: 0.3252 - 209s/epoch - 94ms/step
Epoch 10/50
2222/2222 - 209s - loss: 3.1007 - accuracy1000: 0.4653 - val_loss: 3.5423 - val_accuracy1000: 0.3252 - 209s/epoch - 94ms/step
Epoch 11/50
2222/2222 - 215s - loss: 3.0940 - accuracy1000: 0.4679 - val_loss: 3.6455 - val_accuracy1000: 0.3232 - 215s/epoch - 97ms/step
testing model: results/WBA/W1/deepLOB_L2/h1000
Evaluating performance on  test set...
5696/5696 - 258s - 258s/epoch - 45ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0984797
{'0': {'precision': 0.3603371584542019, 'recall': 0.5688251904230833, 'f1-score': 0.4411906122151629, 'support': 505716}, '1': {'precision': 0.31888579335536776, 'recall': 0.1556156785210957, 'f1-score': 0.2091611176989267, 'support': 442057}, '2': {'precision': 0.3478654540048921, 'recall': 0.30268632496555614, 'f1-score': 0.3237071029821857, 'support': 510251}, 'accuracy': 0.3504064404975501, 'macro avg': {'precision': 0.3423628019381539, 'recall': 0.342375731303245, 'f1-score': 0.3246862776320918, 'support': 1458024}, 'weighted avg': {'precision': 0.3434049503640332, 'recall': 0.3504064404975501, 'f1-score': 0.329727193007386, 'support': 1458024}}
[[287664  71929 146123]
 [229853  68791 143413]
 [280802  75003 154446]]
Evaluating performance on  train set...
2222/2222 - 94s - 94s/epoch - 42ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0999998
{'0': {'precision': 0.31690606509191277, 'recall': 0.3912393151139458, 'f1-score': 0.35017134991679977, 'support': 189871}, '1': {'precision': 0.345689435312948, 'recall': 0.19951071453949304, 'f1-score': 0.2530034016560948, 'support': 197022}, '2': {'precision': 0.32637651188419203, 'recall': 0.3960192817758604, 'f1-score': 0.3578409314097193, 'support': 181726}, 'accuracy': 0.32633450517833557, 'macro avg': {'precision': 0.3296573374296842, 'recall': 0.3289231038097664, 'f1-score': 0.3203385609942046, 'support': 568619}, 'weighted avg': {'precision': 0.32990595356110314, 'recall': 0.32633450517833557, 'f1-score': 0.3189545577662766, 'support': 568619}}
[[74285 38785 76801]
 [85979 39308 71735]
 [74143 35616 71967]]
Evaluating performance on  val set...
641/641 - 31s - 31s/epoch - 48ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0994449
{'0': {'precision': 0.3459441088780066, 'recall': 0.38374145346745037, 'f1-score': 0.3638638394670566, 'support': 58357}, '1': {'precision': 0.3210524788953033, 'recall': 0.2131835956311521, 'f1-score': 0.2562280051861456, 'support': 51913}, '2': {'precision': 0.3271042494933713, 'recall': 0.3946656214420367, 'f1-score': 0.35772288952799863, 'support': 53577}, 'accuracy': 0.33327433520296373, 'macro avg': {'precision': 0.3313669457555604, 'recall': 0.3305302235135464, 'f1-score': 0.32593824472706695, 'support': 163847}, 'weighted avg': {'precision': 0.331896965301727, 'recall': 0.33327433520296373, 'f1-score': 0.327752633647543, 'support': 163847}}
[[22394 12621 23342]
 [20690 11067 20156]
 [21649 10783 21145]]
training model: results/WBA/W1/deepOF_L2/h10
Epoch 1/50
2222/2222 - 159s - loss: 2.8594 - accuracy10: 0.5096 - val_loss: 3.0032 - val_accuracy10: 0.6361 - 159s/epoch - 71ms/step
Epoch 2/50
2222/2222 - 151s - loss: 2.6359 - accuracy10: 0.5751 - val_loss: 2.8708 - val_accuracy10: 0.6339 - 151s/epoch - 68ms/step
Epoch 3/50
2222/2222 - 152s - loss: 2.5810 - accuracy10: 0.5874 - val_loss: 2.8421 - val_accuracy10: 0.6398 - 152s/epoch - 68ms/step
Epoch 4/50
2222/2222 - 147s - loss: 2.5577 - accuracy10: 0.5923 - val_loss: 2.8157 - val_accuracy10: 0.6337 - 147s/epoch - 66ms/step
Epoch 5/50
2222/2222 - 155s - loss: 2.5386 - accuracy10: 0.5935 - val_loss: 2.8035 - val_accuracy10: 0.6354 - 155s/epoch - 70ms/step
Epoch 6/50
2222/2222 - 146s - loss: 2.5261 - accuracy10: 0.5965 - val_loss: 2.7825 - val_accuracy10: 0.6361 - 146s/epoch - 66ms/step
Epoch 7/50
2222/2222 - 144s - loss: 2.5161 - accuracy10: 0.5976 - val_loss: 2.7618 - val_accuracy10: 0.6317 - 144s/epoch - 65ms/step
Epoch 8/50
2222/2222 - 147s - loss: 2.5060 - accuracy10: 0.5989 - val_loss: 2.7608 - val_accuracy10: 0.6318 - 147s/epoch - 66ms/step
Epoch 9/50
2222/2222 - 151s - loss: 2.4973 - accuracy10: 0.6002 - val_loss: 2.7654 - val_accuracy10: 0.6315 - 151s/epoch - 68ms/step
Epoch 10/50
2222/2222 - 150s - loss: 2.4905 - accuracy10: 0.6012 - val_loss: 2.7519 - val_accuracy10: 0.6345 - 150s/epoch - 67ms/step
Epoch 11/50
2222/2222 - 150s - loss: 2.4835 - accuracy10: 0.6023 - val_loss: 2.7432 - val_accuracy10: 0.6306 - 150s/epoch - 67ms/step
Epoch 12/50
2222/2222 - 149s - loss: 2.4770 - accuracy10: 0.6033 - val_loss: 2.7372 - val_accuracy10: 0.6364 - 149s/epoch - 67ms/step
Epoch 13/50
2222/2222 - 157s - loss: 2.4715 - accuracy10: 0.6043 - val_loss: 2.7299 - val_accuracy10: 0.6292 - 157s/epoch - 71ms/step
Epoch 14/50
2222/2222 - 146s - loss: 2.4648 - accuracy10: 0.6054 - val_loss: 2.7295 - val_accuracy10: 0.6369 - 146s/epoch - 66ms/step
Epoch 15/50
2222/2222 - 150s - loss: 2.4601 - accuracy10: 0.6058 - val_loss: 2.7340 - val_accuracy10: 0.6349 - 150s/epoch - 67ms/step
Epoch 16/50
2222/2222 - 148s - loss: 2.4537 - accuracy10: 0.6067 - val_loss: 2.7155 - val_accuracy10: 0.6338 - 148s/epoch - 67ms/step
Epoch 17/50
2222/2222 - 147s - loss: 2.4494 - accuracy10: 0.6071 - val_loss: 2.7118 - val_accuracy10: 0.6343 - 147s/epoch - 66ms/step
Epoch 18/50
2222/2222 - 148s - loss: 2.4448 - accuracy10: 0.6073 - val_loss: 2.7169 - val_accuracy10: 0.6321 - 148s/epoch - 67ms/step
Epoch 19/50
2222/2222 - 150s - loss: 2.4402 - accuracy10: 0.6084 - val_loss: 2.7236 - val_accuracy10: 0.6320 - 150s/epoch - 67ms/step
Epoch 20/50
2222/2222 - 150s - loss: 2.4352 - accuracy10: 0.6087 - val_loss: 2.7242 - val_accuracy10: 0.6332 - 150s/epoch - 67ms/step
Epoch 21/50
2222/2222 - 138s - loss: 2.4308 - accuracy10: 0.6091 - val_loss: 2.7063 - val_accuracy10: 0.6285 - 138s/epoch - 62ms/step
Epoch 22/50
2222/2222 - 146s - loss: 2.4276 - accuracy10: 0.6091 - val_loss: 2.7187 - val_accuracy10: 0.6293 - 146s/epoch - 66ms/step
Epoch 23/50
2222/2222 - 154s - loss: 2.4220 - accuracy10: 0.6093 - val_loss: 2.7150 - val_accuracy10: 0.6328 - 154s/epoch - 69ms/step
Epoch 24/50
2222/2222 - 147s - loss: 2.4193 - accuracy10: 0.6098 - val_loss: 2.7170 - val_accuracy10: 0.6305 - 147s/epoch - 66ms/step
Epoch 25/50
2222/2222 - 152s - loss: 2.4143 - accuracy10: 0.6103 - val_loss: 2.7055 - val_accuracy10: 0.6294 - 152s/epoch - 69ms/step
Epoch 26/50
2222/2222 - 152s - loss: 2.4101 - accuracy10: 0.6107 - val_loss: 2.7099 - val_accuracy10: 0.6280 - 152s/epoch - 68ms/step
Epoch 27/50
2222/2222 - 147s - loss: 2.4070 - accuracy10: 0.6113 - val_loss: 2.7076 - val_accuracy10: 0.6282 - 147s/epoch - 66ms/step
Epoch 28/50
2222/2222 - 149s - loss: 2.4022 - accuracy10: 0.6111 - val_loss: 2.7038 - val_accuracy10: 0.6240 - 149s/epoch - 67ms/step
Epoch 29/50
2222/2222 - 146s - loss: 2.3975 - accuracy10: 0.6117 - val_loss: 2.7159 - val_accuracy10: 0.6295 - 146s/epoch - 66ms/step
Epoch 30/50
2222/2222 - 145s - loss: 2.3949 - accuracy10: 0.6118 - val_loss: 2.7001 - val_accuracy10: 0.6310 - 145s/epoch - 65ms/step
Epoch 31/50
2222/2222 - 149s - loss: 2.3912 - accuracy10: 0.6125 - val_loss: 2.7029 - val_accuracy10: 0.6270 - 149s/epoch - 67ms/step
Epoch 32/50
2222/2222 - 146s - loss: 2.3869 - accuracy10: 0.6122 - val_loss: 2.6984 - val_accuracy10: 0.6253 - 146s/epoch - 66ms/step
Epoch 33/50
2222/2222 - 150s - loss: 2.3838 - accuracy10: 0.6132 - val_loss: 2.7125 - val_accuracy10: 0.6244 - 150s/epoch - 68ms/step
Epoch 34/50
2222/2222 - 145s - loss: 2.3804 - accuracy10: 0.6137 - val_loss: 2.7086 - val_accuracy10: 0.6264 - 145s/epoch - 65ms/step
Epoch 35/50
2222/2222 - 153s - loss: 2.3769 - accuracy10: 0.6138 - val_loss: 2.7068 - val_accuracy10: 0.6209 - 153s/epoch - 69ms/step
Epoch 36/50
2222/2222 - 151s - loss: 2.3745 - accuracy10: 0.6143 - val_loss: 2.7065 - val_accuracy10: 0.6252 - 151s/epoch - 68ms/step
Epoch 37/50
2222/2222 - 150s - loss: 2.3690 - accuracy10: 0.6150 - val_loss: 2.7074 - val_accuracy10: 0.6235 - 150s/epoch - 67ms/step
Epoch 38/50
2222/2222 - 148s - loss: 2.3665 - accuracy10: 0.6155 - val_loss: 2.7093 - val_accuracy10: 0.6227 - 148s/epoch - 67ms/step
Epoch 39/50
2222/2222 - 148s - loss: 2.3640 - accuracy10: 0.6151 - val_loss: 2.7232 - val_accuracy10: 0.6205 - 148s/epoch - 67ms/step
Epoch 40/50
2222/2222 - 142s - loss: 2.3591 - accuracy10: 0.6160 - val_loss: 2.7263 - val_accuracy10: 0.6241 - 142s/epoch - 64ms/step
Epoch 41/50
2222/2222 - 145s - loss: 2.3580 - accuracy10: 0.6158 - val_loss: 2.7244 - val_accuracy10: 0.6202 - 145s/epoch - 65ms/step
Epoch 42/50
2222/2222 - 151s - loss: 2.3530 - accuracy10: 0.6164 - val_loss: 2.7243 - val_accuracy10: 0.6211 - 151s/epoch - 68ms/step
testing model: results/WBA/W1/deepOF_L2/h10
Evaluating performance on  test set...
5696/5696 - 189s - 189s/epoch - 33ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.90960455
{'0': {'precision': 0.43323636187487724, 'recall': 0.47474476405051047, 'f1-score': 0.45304178363128533, 'support': 339098}, '1': {'precision': 0.7050438991164801, 'recall': 0.6457904046968419, 'f1-score': 0.674117593333479, 'support': 788615}, '2': {'precision': 0.4407955088521096, 'recall': 0.4858858149715718, 'f1-score': 0.46224366359447006, 'support': 330306}, 'accuracy': 0.5697840700292658, 'macro avg': {'precision': 0.5263585899478224, 'recall': 0.5354736612396414, 'f1-score': 0.5298010135197447, 'support': 1458019}, 'weighted avg': {'precision': 0.5819644186308237, 'recall': 0.5697840700292658, 'f1-score': 0.5747021569401483, 'support': 1458019}}
[[160985 113445  64668]
 [140400 509280 138935]
 [ 70202  99613 160491]]
Evaluating performance on  train set...
2222/2222 - 57s - 57s/epoch - 26ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.77462465
{'0': {'precision': 0.4517465908356492, 'recall': 0.5245143559295007, 'f1-score': 0.48541852036719546, 'support': 106611}, '1': {'precision': 0.7940449969235159, 'recall': 0.7484282544378699, 'f1-score': 0.7705620962542782, 'support': 356928}, '2': {'precision': 0.4597319460202378, 'recall': 0.4743098050038542, 'f1-score': 0.46690711508735777, 'support': 105079}, 'accuracy': 0.6557900031303968, 'macro avg': {'precision': 0.5685078445931343, 'recall': 0.5824174717904081, 'f1-score': 0.5742959105696105, 'support': 568618}, 'weighted avg': {'precision': 0.6680868731087596, 'recall': 0.6557900031303968, 'f1-score': 0.6609855377652105, 'support': 568618}}
[[ 55919  34054  16638]
 [ 47860 267135  41933]
 [ 20005  35234  49840]]
Evaluating performance on  val set...
641/641 - 21s - 21s/epoch - 32ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.8216204
{'0': {'precision': 0.4306799583395328, 'recall': 0.4738255033557047, 'f1-score': 0.4512236944660951, 'support': 30545}, '1': {'precision': 0.7943681199618619, 'recall': 0.7048491607221827, 'f1-score': 0.7469360310522938, 'support': 104018}, '2': {'precision': 0.389194887336935, 'recall': 0.5043199125772633, 'f1-score': 0.4393407508776105, 'support': 29283}, 'accuracy': 0.6259414328088571, 'macro avg': {'precision': 0.5380809885461099, 'recall': 0.5609981922183835, 'f1-score': 0.5458334921319997, 'support': 163846}, 'weighted avg': {'precision': 0.6541538781267865, 'recall': 0.6259414328088571, 'f1-score': 0.6368335817378113, 'support': 163846}}
[[14473 10026  6046]
 [13570 73317 17131]
 [ 5562  8953 14768]]
training model: results/WBA/W1/deepOF_L2/h20
Epoch 1/50
2222/2222 - 160s - loss: 2.9311 - accuracy20: 0.5046 - val_loss: 3.1163 - val_accuracy20: 0.5797 - 160s/epoch - 72ms/step
Epoch 2/50
2222/2222 - 149s - loss: 2.7269 - accuracy20: 0.5646 - val_loss: 2.9527 - val_accuracy20: 0.5899 - 149s/epoch - 67ms/step
Epoch 3/50
2222/2222 - 154s - loss: 2.6751 - accuracy20: 0.5767 - val_loss: 2.9187 - val_accuracy20: 0.5950 - 154s/epoch - 69ms/step
Epoch 4/50
2222/2222 - 153s - loss: 2.6535 - accuracy20: 0.5806 - val_loss: 2.9006 - val_accuracy20: 0.5947 - 153s/epoch - 69ms/step
Epoch 5/50
2222/2222 - 114s - loss: 2.6365 - accuracy20: 0.5838 - val_loss: 2.8850 - val_accuracy20: 0.5963 - 114s/epoch - 51ms/step
Epoch 6/50
2222/2222 - 48s - loss: 2.6243 - accuracy20: 0.5861 - val_loss: 2.8749 - val_accuracy20: 0.5974 - 48s/epoch - 21ms/step
Epoch 7/50
2222/2222 - 48s - loss: 2.6148 - accuracy20: 0.5871 - val_loss: 2.8726 - val_accuracy20: 0.5984 - 48s/epoch - 22ms/step
Epoch 8/50
2222/2222 - 47s - loss: 2.6055 - accuracy20: 0.5888 - val_loss: 2.8580 - val_accuracy20: 0.5969 - 47s/epoch - 21ms/step
Epoch 9/50
2222/2222 - 48s - loss: 2.5988 - accuracy20: 0.5907 - val_loss: 2.8549 - val_accuracy20: 0.5995 - 48s/epoch - 21ms/step
Epoch 10/50
2222/2222 - 48s - loss: 2.5920 - accuracy20: 0.5911 - val_loss: 2.8519 - val_accuracy20: 0.5984 - 48s/epoch - 22ms/step
Epoch 11/50
2222/2222 - 48s - loss: 2.5867 - accuracy20: 0.5925 - val_loss: 2.8602 - val_accuracy20: 0.5984 - 48s/epoch - 22ms/step
Epoch 12/50
2222/2222 - 48s - loss: 2.5809 - accuracy20: 0.5939 - val_loss: 2.8501 - val_accuracy20: 0.5997 - 48s/epoch - 22ms/step
Epoch 13/50
2222/2222 - 48s - loss: 2.5752 - accuracy20: 0.5946 - val_loss: 2.8424 - val_accuracy20: 0.5996 - 48s/epoch - 22ms/step
Epoch 14/50
2222/2222 - 48s - loss: 2.5701 - accuracy20: 0.5948 - val_loss: 2.8568 - val_accuracy20: 0.6000 - 48s/epoch - 22ms/step
Epoch 15/50
2222/2222 - 48s - loss: 2.5648 - accuracy20: 0.5962 - val_loss: 2.8430 - val_accuracy20: 0.5986 - 48s/epoch - 22ms/step
Epoch 16/50
2222/2222 - 48s - loss: 2.5603 - accuracy20: 0.5973 - val_loss: 2.8526 - val_accuracy20: 0.5989 - 48s/epoch - 22ms/step
Epoch 17/50
2222/2222 - 48s - loss: 2.5560 - accuracy20: 0.5978 - val_loss: 2.8515 - val_accuracy20: 0.6004 - 48s/epoch - 22ms/step
Epoch 18/50
2222/2222 - 48s - loss: 2.5517 - accuracy20: 0.5987 - val_loss: 2.8342 - val_accuracy20: 0.5999 - 48s/epoch - 22ms/step
Epoch 19/50
2222/2222 - 48s - loss: 2.5476 - accuracy20: 0.5987 - val_loss: 2.8392 - val_accuracy20: 0.5997 - 48s/epoch - 22ms/step
Epoch 20/50
2222/2222 - 48s - loss: 2.5430 - accuracy20: 0.5997 - val_loss: 2.8418 - val_accuracy20: 0.5996 - 48s/epoch - 22ms/step
Epoch 21/50
2222/2222 - 48s - loss: 2.5389 - accuracy20: 0.6002 - val_loss: 2.8370 - val_accuracy20: 0.5993 - 48s/epoch - 21ms/step
Epoch 22/50
2222/2222 - 48s - loss: 2.5354 - accuracy20: 0.6006 - val_loss: 2.8422 - val_accuracy20: 0.5986 - 48s/epoch - 22ms/step
Epoch 23/50
2222/2222 - 48s - loss: 2.5311 - accuracy20: 0.6007 - val_loss: 2.8370 - val_accuracy20: 0.5979 - 48s/epoch - 22ms/step
Epoch 24/50
2222/2222 - 48s - loss: 2.5277 - accuracy20: 0.6014 - val_loss: 2.8349 - val_accuracy20: 0.5950 - 48s/epoch - 22ms/step
Epoch 25/50
2222/2222 - 48s - loss: 2.5244 - accuracy20: 0.6020 - val_loss: 2.8347 - val_accuracy20: 0.5984 - 48s/epoch - 22ms/step
Epoch 26/50
2222/2222 - 48s - loss: 2.5203 - accuracy20: 0.6028 - val_loss: 2.8295 - val_accuracy20: 0.5974 - 48s/epoch - 22ms/step
Epoch 27/50
2222/2222 - 48s - loss: 2.5181 - accuracy20: 0.6029 - val_loss: 2.8332 - val_accuracy20: 0.5959 - 48s/epoch - 22ms/step
Epoch 28/50
2222/2222 - 48s - loss: 2.5132 - accuracy20: 0.6040 - val_loss: 2.8439 - val_accuracy20: 0.5945 - 48s/epoch - 22ms/step
Epoch 29/50
2222/2222 - 48s - loss: 2.5103 - accuracy20: 0.6037 - val_loss: 2.8370 - val_accuracy20: 0.5983 - 48s/epoch - 22ms/step
Epoch 30/50
2222/2222 - 48s - loss: 2.5062 - accuracy20: 0.6050 - val_loss: 2.8436 - val_accuracy20: 0.5958 - 48s/epoch - 22ms/step
Epoch 31/50
2222/2222 - 48s - loss: 2.5038 - accuracy20: 0.6052 - val_loss: 2.8481 - val_accuracy20: 0.5956 - 48s/epoch - 21ms/step
Epoch 32/50
2222/2222 - 48s - loss: 2.4990 - accuracy20: 0.6058 - val_loss: 2.8372 - val_accuracy20: 0.5937 - 48s/epoch - 22ms/step
Epoch 33/50
2222/2222 - 48s - loss: 2.4967 - accuracy20: 0.6060 - val_loss: 2.8573 - val_accuracy20: 0.5921 - 48s/epoch - 21ms/step
Epoch 34/50
2222/2222 - 48s - loss: 2.4927 - accuracy20: 0.6065 - val_loss: 2.8405 - val_accuracy20: 0.5957 - 48s/epoch - 22ms/step
Epoch 35/50
2222/2222 - 48s - loss: 2.4888 - accuracy20: 0.6065 - val_loss: 2.8444 - val_accuracy20: 0.5905 - 48s/epoch - 22ms/step
Epoch 36/50
2222/2222 - 48s - loss: 2.4851 - accuracy20: 0.6074 - val_loss: 2.8760 - val_accuracy20: 0.5949 - 48s/epoch - 22ms/step
testing model: results/WBA/W1/deepOF_L2/h20
Evaluating performance on  test set...
5696/5696 - 43s - 43s/epoch - 8ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.97090906
{'0': {'precision': 0.49235245290929747, 'recall': 0.40245788891101675, 'f1-score': 0.4428896706645958, 'support': 431834}, '1': {'precision': 0.5638747985995536, 'recall': 0.6990084088639397, 'f1-score': 0.6242116823442557, 'support': 607811}, '2': {'precision': 0.49957048094755885, 'recall': 0.4197846902532184, 'f1-score': 0.45621550011039963, 'support': 418374}, 'accuracy': 0.5310541220656246, 'macro avg': {'precision': 0.5185992441521367, 'recall': 0.5070836626760583, 'f1-score': 0.5077722843730837, 'support': 1458019}, 'weighted avg': {'precision': 0.5242394884820986, 'recall': 0.5310541220656246, 'f1-score': 0.5223020060385413, 'support': 1458019}}
[[173795 173021  85018]
 [ 92035 424865  90911]
 [ 87159 155588 175627]]
Evaluating performance on  train set...
2222/2222 - 17s - 17s/epoch - 8ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.83844197
{'0': {'precision': 0.5196228840797086, 'recall': 0.44305999108428273, 'f1-score': 0.4782968853545394, 'support': 136837}, '1': {'precision': 0.6813246004595647, 'recall': 0.8014532659726131, 'f1-score': 0.7365227639116235, 'support': 296711}, '2': {'precision': 0.5278816910714459, 'recall': 0.402221070556008, 'f1-score': 0.4565627534277082, 'support': 135070}, 'accuracy': 0.6203725523989744, 'macro avg': {'precision': 0.5762763918702397, 'recall': 0.5489114425376346, 'f1-score': 0.5571274675646237, 'support': 568618}, 'weighted avg': {'precision': 0.605962386222021, 'recall': 0.6203725523989744, 'f1-score': 0.6078791874504876, 'support': 568618}}
[[ 60627  54999  21211]
 [ 31533 237800  27378]
 [ 24515  56227  54328]]
Evaluating performance on  val set...
641/641 - 5s - 5s/epoch - 8ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.8817596
{'0': {'precision': 0.48955322736030826, 'recall': 0.411942037797031, 'f1-score': 0.44740679598294125, 'support': 39474}, '1': {'precision': 0.6843305439330544, 'recall': 0.7574182344428365, 'f1-score': 0.7190218436598435, 'support': 86375}, '2': {'precision': 0.464259206394519, 'recall': 0.4280074742742848, 'f1-score': 0.44539690799293413, 'support': 37997}, 'accuracy': 0.5977930495709386, 'macro avg': {'precision': 0.5460476592292939, 'recall': 0.5324559155047174, 'f1-score': 0.5372751825452396, 'support': 163846}, 'weighted avg': {'precision': 0.5863684917203406, 'recall': 0.5977930495709386, 'f1-score': 0.5901284982468727, 'support': 163846}}
[[16261 15732  7481]
 [ 9667 65422 11286]
 [ 7288 14446 16263]]
training model: results/WBA/W1/deepOF_L2/h30
Epoch 1/50
2222/2222 - 51s - loss: 2.9849 - accuracy30: 0.4952 - val_loss: 3.2076 - val_accuracy30: 0.5284 - 51s/epoch - 23ms/step
Epoch 2/50
2222/2222 - 48s - loss: 2.8028 - accuracy30: 0.5474 - val_loss: 3.0324 - val_accuracy30: 0.5469 - 48s/epoch - 22ms/step
Epoch 3/50
2222/2222 - 48s - loss: 2.7515 - accuracy30: 0.5600 - val_loss: 2.9951 - val_accuracy30: 0.5519 - 48s/epoch - 22ms/step
Epoch 4/50
2222/2222 - 48s - loss: 2.7317 - accuracy30: 0.5639 - val_loss: 2.9684 - val_accuracy30: 0.5560 - 48s/epoch - 22ms/step
Epoch 5/50
2222/2222 - 49s - loss: 2.7192 - accuracy30: 0.5662 - val_loss: 2.9521 - val_accuracy30: 0.5570 - 49s/epoch - 22ms/step
Epoch 6/50
2222/2222 - 48s - loss: 2.7095 - accuracy30: 0.5679 - val_loss: 2.9413 - val_accuracy30: 0.5568 - 48s/epoch - 22ms/step
Epoch 7/50
2222/2222 - 48s - loss: 2.7003 - accuracy30: 0.5699 - val_loss: 2.9384 - val_accuracy30: 0.5565 - 48s/epoch - 22ms/step
Epoch 8/50
2222/2222 - 48s - loss: 2.6925 - accuracy30: 0.5712 - val_loss: 2.9274 - val_accuracy30: 0.5570 - 48s/epoch - 22ms/step
Epoch 9/50
2222/2222 - 48s - loss: 2.6852 - accuracy30: 0.5724 - val_loss: 2.9226 - val_accuracy30: 0.5584 - 48s/epoch - 22ms/step
Epoch 10/50
2222/2222 - 48s - loss: 2.6795 - accuracy30: 0.5737 - val_loss: 2.9278 - val_accuracy30: 0.5594 - 48s/epoch - 22ms/step
Epoch 11/50
2222/2222 - 48s - loss: 2.6733 - accuracy30: 0.5750 - val_loss: 2.9164 - val_accuracy30: 0.5584 - 48s/epoch - 22ms/step
Epoch 12/50
2222/2222 - 48s - loss: 2.6686 - accuracy30: 0.5761 - val_loss: 2.9195 - val_accuracy30: 0.5592 - 48s/epoch - 22ms/step
Epoch 13/50
2222/2222 - 48s - loss: 2.6620 - accuracy30: 0.5772 - val_loss: 2.9084 - val_accuracy30: 0.5585 - 48s/epoch - 22ms/step
Epoch 14/50
2222/2222 - 48s - loss: 2.6573 - accuracy30: 0.5780 - val_loss: 2.9147 - val_accuracy30: 0.5594 - 48s/epoch - 22ms/step
Epoch 15/50
2222/2222 - 48s - loss: 2.6522 - accuracy30: 0.5790 - val_loss: 2.9132 - val_accuracy30: 0.5602 - 48s/epoch - 22ms/step
Epoch 16/50
2222/2222 - 48s - loss: 2.6482 - accuracy30: 0.5804 - val_loss: 2.9033 - val_accuracy30: 0.5605 - 48s/epoch - 22ms/step
Epoch 17/50
2222/2222 - 48s - loss: 2.6434 - accuracy30: 0.5806 - val_loss: 2.9068 - val_accuracy30: 0.5596 - 48s/epoch - 22ms/step
Epoch 18/50
2222/2222 - 48s - loss: 2.6400 - accuracy30: 0.5813 - val_loss: 2.9066 - val_accuracy30: 0.5606 - 48s/epoch - 22ms/step
Epoch 19/50
2222/2222 - 48s - loss: 2.6346 - accuracy30: 0.5824 - val_loss: 2.9073 - val_accuracy30: 0.5604 - 48s/epoch - 22ms/step
Epoch 20/50
2222/2222 - 48s - loss: 2.6310 - accuracy30: 0.5837 - val_loss: 2.9112 - val_accuracy30: 0.5585 - 48s/epoch - 22ms/step
Epoch 21/50
2222/2222 - 48s - loss: 2.6273 - accuracy30: 0.5837 - val_loss: 2.9170 - val_accuracy30: 0.5605 - 48s/epoch - 22ms/step
Epoch 22/50
2222/2222 - 48s - loss: 2.6231 - accuracy30: 0.5850 - val_loss: 2.8993 - val_accuracy30: 0.5579 - 48s/epoch - 22ms/step
Epoch 23/50
2222/2222 - 48s - loss: 2.6199 - accuracy30: 0.5851 - val_loss: 2.9097 - val_accuracy30: 0.5584 - 48s/epoch - 22ms/step
Epoch 24/50
2222/2222 - 48s - loss: 2.6161 - accuracy30: 0.5865 - val_loss: 2.9097 - val_accuracy30: 0.5600 - 48s/epoch - 22ms/step
Epoch 25/50
2222/2222 - 48s - loss: 2.6113 - accuracy30: 0.5868 - val_loss: 2.9141 - val_accuracy30: 0.5562 - 48s/epoch - 22ms/step
Epoch 26/50
2222/2222 - 48s - loss: 2.6078 - accuracy30: 0.5877 - val_loss: 2.9077 - val_accuracy30: 0.5586 - 48s/epoch - 22ms/step
Epoch 27/50
2222/2222 - 48s - loss: 2.6036 - accuracy30: 0.5887 - val_loss: 2.9210 - val_accuracy30: 0.5575 - 48s/epoch - 21ms/step
Epoch 28/50
2222/2222 - 48s - loss: 2.6016 - accuracy30: 0.5891 - val_loss: 2.9145 - val_accuracy30: 0.5591 - 48s/epoch - 22ms/step
Epoch 29/50
2222/2222 - 48s - loss: 2.5973 - accuracy30: 0.5894 - val_loss: 2.9076 - val_accuracy30: 0.5568 - 48s/epoch - 22ms/step
Epoch 30/50
2222/2222 - 48s - loss: 2.5931 - accuracy30: 0.5908 - val_loss: 2.9120 - val_accuracy30: 0.5562 - 48s/epoch - 22ms/step
Epoch 31/50
2222/2222 - 48s - loss: 2.5909 - accuracy30: 0.5906 - val_loss: 2.9164 - val_accuracy30: 0.5583 - 48s/epoch - 22ms/step
Epoch 32/50
2222/2222 - 48s - loss: 2.5861 - accuracy30: 0.5912 - val_loss: 2.9222 - val_accuracy30: 0.5564 - 48s/epoch - 22ms/step
testing model: results/WBA/W1/deepOF_L2/h30
Evaluating performance on  test set...
5696/5696 - 44s - 44s/epoch - 8ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.008524
{'0': {'precision': 0.4935686075582449, 'recall': 0.42099776036526443, 'f1-score': 0.45440393536536006, 'support': 485347}, '1': {'precision': 0.4808760331737274, 'recall': 0.6868385057966168, 'f1-score': 0.5656933524004625, 'support': 499343}, '2': {'precision': 0.5260943295276269, 'recall': 0.3676977324440294, 'f1-score': 0.43286061769723977, 'support': 473329}, 'accuracy': 0.4947397804829704, 'macro avg': {'precision': 0.5001796567531996, 'recall': 0.4918446662019702, 'f1-score': 0.4843193018210208, 'support': 1458019}, 'weighted avg': {'precision': 0.49978074833498204, 'recall': 0.4947397804829704, 'f1-score': 0.4855245959068382, 'support': 1458019}}
[[204330 195149  85868]
 [ 85466 342968  70909]
 [124189 175098 174042]]
Evaluating performance on  train set...
2222/2222 - 19s - 19s/epoch - 9ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.89342505
{'0': {'precision': 0.5257053144624614, 'recall': 0.42983867877533816, 'f1-score': 0.47296300200274055, 'support': 156582}, '1': {'precision': 0.6051225662678865, 'recall': 0.8022975993779765, 'f1-score': 0.6898982892196602, 'support': 257225}, '2': {'precision': 0.5452837769964842, 'recall': 0.3506404583653616, 'f1-score': 0.4268185767472215, 'support': 154811}, 'accuracy': 0.5767650689918363, 'macro avg': {'precision': 0.558703885908944, 'recall': 0.5275922455062254, 'f1-score': 0.5298932893232075, 'support': 568618}, 'weighted avg': {'precision': 0.5669615954085536, 'recall': 0.5767650689918363, 'f1-score': 0.558534536206969, 'support': 568618}}
[[ 67305  67352  21925]
 [ 27512 206371  23342]
 [ 33211  67317  54283]]
Evaluating performance on  val set...
641/641 - 6s - 6s/epoch - 9ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.9306498
{'0': {'precision': 0.4943281881280431, 'recall': 0.4198913258684031, 'f1-score': 0.4540793871700627, 'support': 45457}, '1': {'precision': 0.6107579998902245, 'recall': 0.7469657913108856, 'f1-score': 0.6720296655976905, 'support': 74484}, '2': {'precision': 0.4848413837546501, 'recall': 0.37699578635690695, 'f1-score': 0.4241709804725539, 'support': 43905}, 'accuracy': 0.557084091158771, 'macro avg': {'precision': 0.5299758572576393, 'recall': 0.5146176345120652, 'f1-score': 0.5167600110801024, 'support': 163846}, 'weighted avg': {'precision': 0.5447147703655131, 'recall': 0.557084091158771, 'f1-score': 0.5451446554240896, 'support': 163846}}
[[19087 18427  7943]
 [ 9203 55637  9644]
 [10322 17031 16552]]
training model: results/WBA/W1/deepOF_L2/h50
Epoch 1/50
2222/2222 - 56s - loss: 3.0573 - accuracy50: 0.4734 - val_loss: 3.3100 - val_accuracy50: 0.4473 - 56s/epoch - 25ms/step
Epoch 2/50
2222/2222 - 50s - loss: 2.9157 - accuracy50: 0.5138 - val_loss: 3.1662 - val_accuracy50: 0.4729 - 50s/epoch - 23ms/step
Epoch 3/50
2222/2222 - 50s - loss: 2.8725 - accuracy50: 0.5243 - val_loss: 3.0899 - val_accuracy50: 0.4861 - 50s/epoch - 23ms/step
Epoch 4/50
2222/2222 - 50s - loss: 2.8535 - accuracy50: 0.5286 - val_loss: 3.0790 - val_accuracy50: 0.4881 - 50s/epoch - 23ms/step
Epoch 5/50
2222/2222 - 50s - loss: 2.8426 - accuracy50: 0.5316 - val_loss: 3.0614 - val_accuracy50: 0.4891 - 50s/epoch - 23ms/step
Epoch 6/50
2222/2222 - 50s - loss: 2.8341 - accuracy50: 0.5333 - val_loss: 3.0600 - val_accuracy50: 0.4896 - 50s/epoch - 23ms/step
Epoch 7/50
2222/2222 - 50s - loss: 2.8258 - accuracy50: 0.5354 - val_loss: 3.0456 - val_accuracy50: 0.4921 - 50s/epoch - 23ms/step
Epoch 8/50
2222/2222 - 51s - loss: 2.8208 - accuracy50: 0.5366 - val_loss: 3.0383 - val_accuracy50: 0.4923 - 51s/epoch - 23ms/step
Epoch 9/50
2222/2222 - 50s - loss: 2.8146 - accuracy50: 0.5383 - val_loss: 3.0496 - val_accuracy50: 0.4895 - 50s/epoch - 23ms/step
Epoch 10/50
2222/2222 - 50s - loss: 2.8093 - accuracy50: 0.5390 - val_loss: 3.0483 - val_accuracy50: 0.4908 - 50s/epoch - 22ms/step
Epoch 11/50
2222/2222 - 57s - loss: 2.8048 - accuracy50: 0.5403 - val_loss: 3.0365 - val_accuracy50: 0.4910 - 57s/epoch - 26ms/step
Epoch 12/50
2222/2222 - 78s - loss: 2.7996 - accuracy50: 0.5415 - val_loss: 3.0276 - val_accuracy50: 0.4954 - 78s/epoch - 35ms/step
Epoch 13/50
2222/2222 - 78s - loss: 2.7956 - accuracy50: 0.5427 - val_loss: 3.0269 - val_accuracy50: 0.4963 - 78s/epoch - 35ms/step
Epoch 14/50
2222/2222 - 80s - loss: 2.7912 - accuracy50: 0.5439 - val_loss: 3.0282 - val_accuracy50: 0.4928 - 80s/epoch - 36ms/step
Epoch 15/50
2222/2222 - 79s - loss: 2.7870 - accuracy50: 0.5447 - val_loss: 3.0408 - val_accuracy50: 0.4917 - 79s/epoch - 36ms/step
Epoch 16/50
2222/2222 - 76s - loss: 2.7825 - accuracy50: 0.5463 - val_loss: 3.0279 - val_accuracy50: 0.4949 - 76s/epoch - 34ms/step
Epoch 17/50
2222/2222 - 78s - loss: 2.7781 - accuracy50: 0.5475 - val_loss: 3.0387 - val_accuracy50: 0.4936 - 78s/epoch - 35ms/step
Epoch 18/50
2222/2222 - 76s - loss: 2.7737 - accuracy50: 0.5483 - val_loss: 3.0308 - val_accuracy50: 0.4947 - 76s/epoch - 34ms/step
Epoch 19/50
2222/2222 - 77s - loss: 2.7704 - accuracy50: 0.5492 - val_loss: 3.0351 - val_accuracy50: 0.4935 - 77s/epoch - 35ms/step
Epoch 20/50
2222/2222 - 78s - loss: 2.7657 - accuracy50: 0.5504 - val_loss: 3.0434 - val_accuracy50: 0.4907 - 78s/epoch - 35ms/step
Epoch 21/50
2222/2222 - 75s - loss: 2.7621 - accuracy50: 0.5514 - val_loss: 3.0546 - val_accuracy50: 0.4894 - 75s/epoch - 34ms/step
Epoch 22/50
2222/2222 - 77s - loss: 2.7584 - accuracy50: 0.5521 - val_loss: 3.0470 - val_accuracy50: 0.4915 - 77s/epoch - 35ms/step
Epoch 23/50
2222/2222 - 78s - loss: 2.7536 - accuracy50: 0.5534 - val_loss: 3.0419 - val_accuracy50: 0.4900 - 78s/epoch - 35ms/step
testing model: results/WBA/W1/deepOF_L2/h50
Evaluating performance on  test set...
5696/5696 - 79s - 79s/epoch - 14ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0680544
{'0': {'precision': 0.5028298525272558, 'recall': 0.33289384175377257, 'f1-score': 0.4005844575228551, 'support': 546844}, '1': {'precision': 0.3471654614659735, 'recall': 0.7577785356186711, 'f1-score': 0.47617713784803284, 'support': 372403}, '2': {'precision': 0.5425932466798531, 'recall': 0.2851280318947533, 'f1-score': 0.37381797121762955, 'support': 538772}, 'accuracy': 0.4237660826093487, 'macro avg': {'precision': 0.46419618689102743, 'recall': 0.458600136422399, 'f1-score': 0.41685985552950583, 'support': 1458019}, 'weighted avg': {'precision': 0.4777640043935816, 'recall': 0.4237660826093487, 'f1-score': 0.4100012810152089, 'support': 1458019}}
[[182041 275440  89363]
 [ 50066 282199  40138]
 [129926 255227 153619]]
Evaluating performance on  train set...
2222/2222 - 34s - 34s/epoch - 15ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.98570836
{'0': {'precision': 0.5459426831355803, 'recall': 0.33218763190641426, 'f1-score': 0.41304896086811305, 'support': 182421}, '1': {'precision': 0.47162504724973503, 'recall': 0.8661207093238317, 'f1-score': 0.6107053129513887, 'support': 205999}, '2': {'precision': 0.5640382287673996, 'recall': 0.24825469761040633, 'f1-score': 0.3447651342915495, 'support': 180198}, 'accuracy': 0.4990221906446859, 'macro avg': {'precision': 0.5272019863842382, 'recall': 0.48218767961355075, 'f1-score': 0.4561731360370171, 'support': 568618}, 'weighted avg': {'precision': 0.5247534532077804, 'recall': 0.4990221906446859, 'f1-score': 0.46301642917083846, 'support': 568618}}
[[ 60598  99080  22743]
 [ 15745 178420  11834]
 [ 34654 100809  44735]]
Evaluating performance on  val set...
641/641 - 9s - 9s/epoch - 14ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.99699897
{'0': {'precision': 0.5221091965953913, 'recall': 0.33203824899568096, 'f1-score': 0.4059257551302744, 'support': 53021}, '1': {'precision': 0.48126511479782247, 'recall': 0.8154393538269564, 'f1-score': 0.6052921443949332, 'support': 59303}, '2': {'precision': 0.5172029953450719, 'recall': 0.2976010248049377, 'f1-score': 0.377808988764045, 'support': 51522}, 'accuracy': 0.49617323584341394, 'macro avg': {'precision': 0.5068591022460952, 'recall': 0.48169287587585835, 'f1-score': 0.4630089627630842, 'support': 163846}, 'weighted avg': {'precision': 0.5057831716472071, 'recall': 0.49617323584341394, 'f1-score': 0.46924370580249825, 'support': 163846}}
[[17605 26676  8740]
 [ 5372 48358  5573]
 [10742 25447 15333]]
training model: results/WBA/W1/deepOF_L2/h100
Epoch 1/50
2222/2222 - 88s - loss: 3.1959 - accuracy100: 0.4242 - val_loss: 3.3929 - val_accuracy100: 0.3726 - 88s/epoch - 40ms/step
Epoch 2/50
2222/2222 - 82s - loss: 3.1355 - accuracy100: 0.4478 - val_loss: 3.3612 - val_accuracy100: 0.3833 - 82s/epoch - 37ms/step
Epoch 3/50
2222/2222 - 79s - loss: 3.1143 - accuracy100: 0.4549 - val_loss: 3.3178 - val_accuracy100: 0.3947 - 79s/epoch - 36ms/step
Epoch 4/50
2222/2222 - 80s - loss: 3.1016 - accuracy100: 0.4586 - val_loss: 3.2672 - val_accuracy100: 0.4082 - 80s/epoch - 36ms/step
Epoch 5/50
2222/2222 - 82s - loss: 3.0919 - accuracy100: 0.4614 - val_loss: 3.2395 - val_accuracy100: 0.4152 - 82s/epoch - 37ms/step
Epoch 6/50
2222/2222 - 81s - loss: 3.0851 - accuracy100: 0.4632 - val_loss: 3.2234 - val_accuracy100: 0.4243 - 81s/epoch - 37ms/step
Epoch 7/50
2222/2222 - 83s - loss: 3.0818 - accuracy100: 0.4643 - val_loss: 3.2251 - val_accuracy100: 0.4224 - 83s/epoch - 37ms/step
Epoch 8/50
2222/2222 - 84s - loss: 3.0766 - accuracy100: 0.4656 - val_loss: 3.2004 - val_accuracy100: 0.4275 - 84s/epoch - 38ms/step
Epoch 9/50
2222/2222 - 83s - loss: 3.0728 - accuracy100: 0.4675 - val_loss: 3.1990 - val_accuracy100: 0.4291 - 83s/epoch - 37ms/step
Epoch 10/50
2222/2222 - 79s - loss: 3.0685 - accuracy100: 0.4683 - val_loss: 3.2006 - val_accuracy100: 0.4271 - 79s/epoch - 36ms/step
Epoch 11/50
2222/2222 - 82s - loss: 3.0648 - accuracy100: 0.4702 - val_loss: 3.1898 - val_accuracy100: 0.4325 - 82s/epoch - 37ms/step
Epoch 12/50
2222/2222 - 80s - loss: 3.0609 - accuracy100: 0.4720 - val_loss: 3.1931 - val_accuracy100: 0.4314 - 80s/epoch - 36ms/step
Epoch 13/50
2222/2222 - 81s - loss: 3.0575 - accuracy100: 0.4729 - val_loss: 3.1905 - val_accuracy100: 0.4305 - 81s/epoch - 36ms/step
Epoch 14/50
2222/2222 - 81s - loss: 3.0538 - accuracy100: 0.4746 - val_loss: 3.1812 - val_accuracy100: 0.4331 - 81s/epoch - 36ms/step
Epoch 15/50
2222/2222 - 80s - loss: 3.0501 - accuracy100: 0.4762 - val_loss: 3.1904 - val_accuracy100: 0.4303 - 80s/epoch - 36ms/step
Epoch 16/50
2222/2222 - 82s - loss: 3.0468 - accuracy100: 0.4770 - val_loss: 3.1926 - val_accuracy100: 0.4311 - 82s/epoch - 37ms/step
Epoch 17/50
2222/2222 - 83s - loss: 3.0431 - accuracy100: 0.4786 - val_loss: 3.1901 - val_accuracy100: 0.4289 - 83s/epoch - 37ms/step
Epoch 18/50
2222/2222 - 85s - loss: 3.0393 - accuracy100: 0.4804 - val_loss: 3.1975 - val_accuracy100: 0.4285 - 85s/epoch - 38ms/step
Epoch 19/50
2222/2222 - 84s - loss: 3.0340 - accuracy100: 0.4824 - val_loss: 3.1893 - val_accuracy100: 0.4309 - 84s/epoch - 38ms/step
Epoch 20/50
2222/2222 - 85s - loss: 3.0303 - accuracy100: 0.4832 - val_loss: 3.1920 - val_accuracy100: 0.4302 - 85s/epoch - 38ms/step
Epoch 21/50
2222/2222 - 84s - loss: 3.0250 - accuracy100: 0.4854 - val_loss: 3.2060 - val_accuracy100: 0.4287 - 84s/epoch - 38ms/step
Epoch 22/50
2222/2222 - 81s - loss: 3.0208 - accuracy100: 0.4873 - val_loss: 3.1912 - val_accuracy100: 0.4316 - 81s/epoch - 36ms/step
Epoch 23/50
2222/2222 - 83s - loss: 3.0180 - accuracy100: 0.4880 - val_loss: 3.2046 - val_accuracy100: 0.4311 - 83s/epoch - 37ms/step
Epoch 24/50
2222/2222 - 83s - loss: 3.0126 - accuracy100: 0.4898 - val_loss: 3.2066 - val_accuracy100: 0.4285 - 83s/epoch - 37ms/step
testing model: results/WBA/W1/deepOF_L2/h100
Evaluating performance on  test set...
5696/5696 - 83s - 83s/epoch - 15ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.1054457
{'0': {'precision': 0.44566898530283844, 'recall': 0.40522034071202695, 'f1-score': 0.4244832613308502, 'support': 548968}, '1': {'precision': 0.30448358144966126, 'recall': 0.59762281740979, 'f1-score': 0.40342544079286663, 'support': 361268}, '2': {'precision': 0.4860347719566531, 'recall': 0.22164068618412766, 'f1-score': 0.3044476931525536, 'support': 547783}, 'accuracy': 0.3839222945654343, 'macro avg': {'precision': 0.41206244623638427, 'recall': 0.4081612814353148, 'f1-score': 0.37745213175875686, 'support': 1458019}, 'weighted avg': {'precision': 0.4258516326012324, 'recall': 0.3839222945654343, 'f1-score': 0.37416775765529586, 'support': 1458019}}
[[222453 249037  77478]
 [ 94456 215902  50910]
 [182235 244137 121411]]
Evaluating performance on  train set...
2222/2222 - 36s - 36s/epoch - 16ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0679727
{'0': {'precision': 0.4668446202465994, 'recall': 0.3530085390532266, 'f1-score': 0.4020235465064345, 'support': 191239}, '1': {'precision': 0.4048616618963872, 'recall': 0.7498177173421325, 'f1-score': 0.5258125374382095, 'support': 187895}, '2': {'precision': 0.4972442550280836, 'recall': 0.19949969390555403, 'f1-score': 0.2847533210047193, 'support': 189484}, 'accuracy': 0.43297609291299255, 'macro avg': {'precision': 0.4563168457236901, 'recall': 0.43410865010030436, 'f1-score': 0.40419646831645445, 'support': 568618}, 'weighted avg': {'precision': 0.4564931302088616, 'recall': 0.43297609291299255, 'f1-score': 0.40384990628076256, 'support': 568618}}
[[ 67509 101834  21896]
 [ 30683 140887  16325]
 [ 46415 105267  37802]]
Evaluating performance on  val set...
641/641 - 10s - 10s/epoch - 15ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0615103
{'0': {'precision': 0.4626670540383498, 'recall': 0.39009325844662573, 'f1-score': 0.42329197558405557, 'support': 57153}, '1': {'precision': 0.40377029110365464, 'recall': 0.6938946466141978, 'f1-score': 0.5104910138446985, 'support': 51332}, '2': {'precision': 0.47372640478099265, 'recall': 0.23482234786221348, 'f1-score': 0.31399828508628913, 'support': 55361}, 'accuracy': 0.43280885709751843, 'macro avg': {'precision': 0.4467212499743323, 'recall': 0.43960341764101235, 'f1-score': 0.41592709150501445, 'support': 163846}, 'weighted avg': {'precision': 0.4479518219393036, 'recall': 0.43280885709751843, 'f1-score': 0.41368229962216746, 'support': 163846}}
[[22295 26672  8186]
 [ 9457 35619  6256]
 [16436 25925 13000]]
training model: results/WBA/W1/deepOF_L2/h200
Epoch 1/50
2222/2222 - 93s - loss: 3.2620 - accuracy200: 0.3893 - val_loss: 3.2785 - val_accuracy200: 0.3722 - 93s/epoch - 42ms/step
Epoch 2/50
2222/2222 - 87s - loss: 3.2346 - accuracy200: 0.4026 - val_loss: 3.2643 - val_accuracy200: 0.3791 - 87s/epoch - 39ms/step
Epoch 3/50
2222/2222 - 84s - loss: 3.2243 - accuracy200: 0.4075 - val_loss: 3.2633 - val_accuracy200: 0.3802 - 84s/epoch - 38ms/step
Epoch 4/50
2222/2222 - 87s - loss: 3.2174 - accuracy200: 0.4103 - val_loss: 3.2601 - val_accuracy200: 0.3848 - 87s/epoch - 39ms/step
Epoch 5/50
2222/2222 - 87s - loss: 3.2121 - accuracy200: 0.4131 - val_loss: 3.2590 - val_accuracy200: 0.3847 - 87s/epoch - 39ms/step
Epoch 6/50
2222/2222 - 91s - loss: 3.2078 - accuracy200: 0.4153 - val_loss: 3.2572 - val_accuracy200: 0.3877 - 91s/epoch - 41ms/step
Epoch 7/50
2222/2222 - 90s - loss: 3.2039 - accuracy200: 0.4171 - val_loss: 3.2547 - val_accuracy200: 0.3919 - 90s/epoch - 41ms/step
Epoch 8/50
2222/2222 - 98s - loss: 3.2004 - accuracy200: 0.4189 - val_loss: 3.2545 - val_accuracy200: 0.3912 - 98s/epoch - 44ms/step
Epoch 9/50
2222/2222 - 86s - loss: 3.1978 - accuracy200: 0.4198 - val_loss: 3.2544 - val_accuracy200: 0.3903 - 86s/epoch - 39ms/step
Epoch 10/50
2222/2222 - 86s - loss: 3.1944 - accuracy200: 0.4213 - val_loss: 3.2532 - val_accuracy200: 0.3934 - 86s/epoch - 39ms/step
Epoch 11/50
2222/2222 - 83s - loss: 3.1916 - accuracy200: 0.4230 - val_loss: 3.2520 - val_accuracy200: 0.3949 - 83s/epoch - 37ms/step
Epoch 12/50
2222/2222 - 81s - loss: 3.1887 - accuracy200: 0.4246 - val_loss: 3.2509 - val_accuracy200: 0.3986 - 81s/epoch - 36ms/step
Epoch 13/50
2222/2222 - 79s - loss: 3.1855 - accuracy200: 0.4255 - val_loss: 3.2517 - val_accuracy200: 0.3987 - 79s/epoch - 36ms/step
Epoch 14/50
2222/2222 - 85s - loss: 3.1838 - accuracy200: 0.4260 - val_loss: 3.2499 - val_accuracy200: 0.3984 - 85s/epoch - 38ms/step
Epoch 15/50
2222/2222 - 88s - loss: 3.1794 - accuracy200: 0.4288 - val_loss: 3.2477 - val_accuracy200: 0.4005 - 88s/epoch - 40ms/step
Epoch 16/50
2222/2222 - 90s - loss: 3.1756 - accuracy200: 0.4306 - val_loss: 3.2505 - val_accuracy200: 0.3992 - 90s/epoch - 41ms/step
Epoch 17/50
2222/2222 - 91s - loss: 3.1727 - accuracy200: 0.4317 - val_loss: 3.2542 - val_accuracy200: 0.3986 - 91s/epoch - 41ms/step
Epoch 18/50
2222/2222 - 87s - loss: 3.1683 - accuracy200: 0.4341 - val_loss: 3.2541 - val_accuracy200: 0.3996 - 87s/epoch - 39ms/step
Epoch 19/50
2222/2222 - 92s - loss: 3.1651 - accuracy200: 0.4353 - val_loss: 3.2538 - val_accuracy200: 0.4001 - 92s/epoch - 41ms/step
Epoch 20/50
2222/2222 - 93s - loss: 3.1616 - accuracy200: 0.4369 - val_loss: 3.2558 - val_accuracy200: 0.4001 - 93s/epoch - 42ms/step
Epoch 21/50
2222/2222 - 90s - loss: 3.1557 - accuracy200: 0.4391 - val_loss: 3.2639 - val_accuracy200: 0.3985 - 90s/epoch - 41ms/step
Epoch 22/50
2222/2222 - 85s - loss: 3.1555 - accuracy200: 0.4387 - val_loss: 3.2606 - val_accuracy200: 0.4006 - 85s/epoch - 38ms/step
Epoch 23/50
2222/2222 - 92s - loss: 3.1474 - accuracy200: 0.4425 - val_loss: 3.2632 - val_accuracy200: 0.4002 - 92s/epoch - 41ms/step
Epoch 24/50
2222/2222 - 93s - loss: 3.1449 - accuracy200: 0.4435 - val_loss: 3.2645 - val_accuracy200: 0.3999 - 93s/epoch - 42ms/step
Epoch 25/50
2222/2222 - 89s - loss: 3.1391 - accuracy200: 0.4462 - val_loss: 3.2721 - val_accuracy200: 0.3992 - 89s/epoch - 40ms/step
testing model: results/WBA/W1/deepOF_L2/h200
Evaluating performance on  test set...
5696/5696 - 84s - 84s/epoch - 15ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0995207
{'0': {'precision': 0.3936254837108321, 'recall': 0.5142253276269243, 'f1-score': 0.44591510145867763, 'support': 511939}, '1': {'precision': 0.2955551331830894, 'recall': 0.12478219002201027, 'f1-score': 0.17547819217965357, 'support': 436160}, '2': {'precision': 0.3935341422541589, 'recall': 0.4669791339818011, 'f1-score': 0.4271223652608147, 'support': 509920}, 'accuracy': 0.3812014795417618, 'macro avg': {'precision': 0.3609049197160268, 'recall': 0.3686622172102452, 'f1-score': 0.34950521963304865, 'support': 1458019}, 'weighted avg': {'precision': 0.3642562224585665, 'recall': 0.3812014795417618, 'f1-score': 0.3584426100898042, 'support': 1458019}}
[[263252  66145 182542]
 [197313  54425 184422]
 [208223  63575 238122]]
Evaluating performance on  train set...
2222/2222 - 40s - 40s/epoch - 18ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0898706
{'0': {'precision': 0.4003290757989849, 'recall': 0.5194177517484505, 'f1-score': 0.4521636221687744, 'support': 193457}, '1': {'precision': 0.3518698611970648, 'recall': 0.19426637597214538, 'f1-score': 0.2503275853032129, 'support': 184386}, '2': {'precision': 0.399151116939202, 'recall': 0.45153715109422093, 'f1-score': 0.42373114799256256, 'support': 190775}, 'accuracy': 0.3912063986718676, 'macro avg': {'precision': 0.38378335131175056, 'recall': 0.3884070929382723, 'f1-score': 0.37540745182151664, 'support': 568618}, 'weighted avg': {'precision': 0.38421997294774785, 'recall': 0.3912063986718676, 'f1-score': 0.37717488675332816, 'support': 568618}}
[[100485  31788  61184]
 [ 80079  35820  68487]
 [ 70442  34191  86142]]
Evaluating performance on  val set...
641/641 - 10s - 10s/epoch - 15ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0832511
{'0': {'precision': 0.4272496532184281, 'recall': 0.48153876858596945, 'f1-score': 0.4527726519250618, 'support': 60126}, '1': {'precision': 0.323302168549539, 'recall': 0.21496255045435905, 'f1-score': 0.2582292922614186, 'support': 46329}, '2': {'precision': 0.4084809118205772, 'recall': 0.4646024638009444, 'f1-score': 0.43473794908166014, 'support': 57391}, 'accuracy': 0.40022948378355283, 'macro avg': {'precision': 0.3863442445295148, 'recall': 0.3870345942804243, 'f1-score': 0.3819132977560468, 'support': 163846}, 'weighted avg': {'precision': 0.39128331986400366, 'recall': 0.40022948378355283, 'f1-score': 0.3914465961120264, 'support': 163846}}
[[28953 10651 20522]
 [18280  9959 18090]
 [20533 10194 26664]]
training model: results/WBA/W1/deepOF_L2/h300
Epoch 1/50
2222/2222 - 100s - loss: 3.2823 - accuracy300: 0.3752 - val_loss: 3.2774 - val_accuracy300: 0.3670 - 100s/epoch - 45ms/step
Epoch 2/50
2222/2222 - 97s - loss: 3.2598 - accuracy300: 0.3863 - val_loss: 3.2700 - val_accuracy300: 0.3810 - 97s/epoch - 44ms/step
Epoch 3/50
2222/2222 - 93s - loss: 3.2519 - accuracy300: 0.3913 - val_loss: 3.2673 - val_accuracy300: 0.3854 - 93s/epoch - 42ms/step
Epoch 4/50
2222/2222 - 90s - loss: 3.2471 - accuracy300: 0.3940 - val_loss: 3.2650 - val_accuracy300: 0.3876 - 90s/epoch - 40ms/step
Epoch 5/50
2222/2222 - 91s - loss: 3.2431 - accuracy300: 0.3967 - val_loss: 3.2630 - val_accuracy300: 0.3905 - 91s/epoch - 41ms/step
Epoch 6/50
2222/2222 - 87s - loss: 3.2398 - accuracy300: 0.3976 - val_loss: 3.2624 - val_accuracy300: 0.3908 - 87s/epoch - 39ms/step
Epoch 7/50
2222/2222 - 90s - loss: 3.2369 - accuracy300: 0.3999 - val_loss: 3.2613 - val_accuracy300: 0.3935 - 90s/epoch - 40ms/step
Epoch 8/50
2222/2222 - 92s - loss: 3.2340 - accuracy300: 0.4024 - val_loss: 3.2616 - val_accuracy300: 0.3939 - 92s/epoch - 41ms/step
Epoch 9/50
2222/2222 - 91s - loss: 3.2312 - accuracy300: 0.4034 - val_loss: 3.2620 - val_accuracy300: 0.3929 - 91s/epoch - 41ms/step
Epoch 10/50
2222/2222 - 91s - loss: 3.2285 - accuracy300: 0.4058 - val_loss: 3.2602 - val_accuracy300: 0.3945 - 91s/epoch - 41ms/step
Epoch 11/50
2222/2222 - 96s - loss: 3.2258 - accuracy300: 0.4073 - val_loss: 3.2614 - val_accuracy300: 0.3947 - 96s/epoch - 43ms/step
Epoch 12/50
2222/2222 - 92s - loss: 3.2227 - accuracy300: 0.4097 - val_loss: 3.2603 - val_accuracy300: 0.3963 - 92s/epoch - 41ms/step
Epoch 13/50
2222/2222 - 93s - loss: 3.2202 - accuracy300: 0.4107 - val_loss: 3.2640 - val_accuracy300: 0.3953 - 93s/epoch - 42ms/step
Epoch 14/50
2222/2222 - 87s - loss: 3.2181 - accuracy300: 0.4130 - val_loss: 3.2649 - val_accuracy300: 0.3932 - 87s/epoch - 39ms/step
Epoch 15/50
2222/2222 - 88s - loss: 3.2153 - accuracy300: 0.4140 - val_loss: 3.2671 - val_accuracy300: 0.3947 - 88s/epoch - 40ms/step
Epoch 16/50
2222/2222 - 85s - loss: 3.2138 - accuracy300: 0.4153 - val_loss: 3.2693 - val_accuracy300: 0.3925 - 85s/epoch - 38ms/step
Epoch 17/50
2222/2222 - 90s - loss: 3.2119 - accuracy300: 0.4156 - val_loss: 3.2682 - val_accuracy300: 0.3947 - 90s/epoch - 40ms/step
Epoch 18/50
2222/2222 - 91s - loss: 3.2092 - accuracy300: 0.4178 - val_loss: 3.2752 - val_accuracy300: 0.3867 - 91s/epoch - 41ms/step
Epoch 19/50
2222/2222 - 91s - loss: 3.2083 - accuracy300: 0.4176 - val_loss: 3.2795 - val_accuracy300: 0.3916 - 91s/epoch - 41ms/step
Epoch 20/50
2222/2222 - 91s - loss: 3.2031 - accuracy300: 0.4210 - val_loss: 3.2753 - val_accuracy300: 0.3910 - 91s/epoch - 41ms/step
testing model: results/WBA/W1/deepOF_L2/h300
Evaluating performance on  test set...
5696/5696 - 100s - 100s/epoch - 18ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0968711
{'0': {'precision': 0.40281835788588105, 'recall': 0.4423405598497213, 'f1-score': 0.42165536967268535, 'support': 519568}, '1': {'precision': 0.3276694829512629, 'recall': 0.2647544576743084, 'f1-score': 0.2928712035626944, 'support': 422025}, '2': {'precision': 0.39835785690627856, 'recall': 0.42154151804905254, 'f1-score': 0.4096219142408508, 'support': 516426}, 'accuracy': 0.38357113316081615, 'macro avg': {'precision': 0.3762818992478076, 'recall': 0.3762121785243608, 'f1-score': 0.3747161624920769, 'support': 1458019}, 'weighted avg': {'precision': 0.37948654765352174, 'recall': 0.38357113316081615, 'f1-score': 0.38011645491409196, 'support': 1458019}}
[[229826 113538 176204]
 [157710 111733 152582]
 [183009 115722 217695]]
Evaluating performance on  train set...
2222/2222 - 47s - 47s/epoch - 21ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0855099
{'0': {'precision': 0.3977516427333711, 'recall': 0.4771055203992386, 'f1-score': 0.43382968670325, 'support': 194370}, '1': {'precision': 0.39439023135365037, 'recall': 0.25104116064167153, 'f1-score': 0.30679691955694455, 'support': 183209}, '2': {'precision': 0.3952808290534242, 'recall': 0.45282900350190275, 'f1-score': 0.4221024613860758, 'support': 191039}, 'accuracy': 0.3961112732977148, 'macro avg': {'precision': 0.39580756771348186, 'recall': 0.3936585615142709, 'f1-score': 0.3875763558820901, 'support': 568618}, 'weighted avg': {'precision': 0.39583847327325794, 'recall': 0.3961112732977148, 'f1-score': 0.3889596621287991, 'support': 568618}}
[[92735 35171 66464]
 [71336 45993 65880]
 [69077 35454 86508]]
Evaluating performance on  val set...
641/641 - 14s - 14s/epoch - 21ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0881671
{'0': {'precision': 0.41707078977201156, 'recall': 0.4516145531421557, 'f1-score': 0.4336558453252133, 'support': 58654}, '1': {'precision': 0.36135776812141823, 'recall': 0.23070582795569225, 'f1-score': 0.2816161764886321, 'support': 49743}, '2': {'precision': 0.38808037797480166, 'recall': 0.4799545528323324, 'f1-score': 0.4291554122152792, 'support': 55449}, 'accuracy': 0.39413839825201713, 'macro avg': {'precision': 0.38883631195607715, 'recall': 0.38742497797672676, 'f1-score': 0.3814758113430415, 'support': 163846}, 'weighted avg': {'precision': 0.39034555888624717, 'recall': 0.39413839825201713, 'f1-score': 0.38597415787205125, 'support': 163846}}
[[26489 10173 21992]
 [18296 11476 19971]
 [18727 10109 26613]]
training model: results/WBA/W1/deepOF_L2/h500
Epoch 1/50
2222/2222 - 102s - loss: 3.2326 - accuracy500: 0.4111 - val_loss: 3.2332 - val_accuracy500: 0.4013 - 102s/epoch - 46ms/step
Epoch 2/50
2222/2222 - 96s - loss: 3.2123 - accuracy500: 0.4162 - val_loss: 3.2301 - val_accuracy500: 0.4000 - 96s/epoch - 43ms/step
Epoch 3/50
2222/2222 - 94s - loss: 3.2044 - accuracy500: 0.4195 - val_loss: 3.2288 - val_accuracy500: 0.4011 - 94s/epoch - 42ms/step
Epoch 4/50
2222/2222 - 93s - loss: 3.2003 - accuracy500: 0.4204 - val_loss: 3.2285 - val_accuracy500: 0.4013 - 93s/epoch - 42ms/step
Epoch 5/50
2222/2222 - 97s - loss: 3.1978 - accuracy500: 0.4213 - val_loss: 3.2285 - val_accuracy500: 0.4021 - 97s/epoch - 44ms/step
Epoch 6/50
2222/2222 - 110s - loss: 3.1954 - accuracy500: 0.4216 - val_loss: 3.2284 - val_accuracy500: 0.4031 - 110s/epoch - 49ms/step
Epoch 7/50
2222/2222 - 109s - loss: 3.1948 - accuracy500: 0.4223 - val_loss: 3.2283 - val_accuracy500: 0.4037 - 109s/epoch - 49ms/step
Epoch 8/50
2222/2222 - 105s - loss: 3.1941 - accuracy500: 0.4225 - val_loss: 3.2268 - val_accuracy500: 0.4048 - 105s/epoch - 47ms/step
Epoch 9/50
2222/2222 - 104s - loss: 3.1923 - accuracy500: 0.4230 - val_loss: 3.2277 - val_accuracy500: 0.4044 - 104s/epoch - 47ms/step
Epoch 10/50
2222/2222 - 100s - loss: 3.1912 - accuracy500: 0.4242 - val_loss: 3.2279 - val_accuracy500: 0.4061 - 100s/epoch - 45ms/step
Epoch 11/50
2222/2222 - 98s - loss: 3.1912 - accuracy500: 0.4242 - val_loss: 3.2280 - val_accuracy500: 0.4047 - 98s/epoch - 44ms/step
Epoch 12/50
2222/2222 - 102s - loss: 3.1896 - accuracy500: 0.4253 - val_loss: 3.2291 - val_accuracy500: 0.4051 - 102s/epoch - 46ms/step
Epoch 13/50
2222/2222 - 107s - loss: 3.1884 - accuracy500: 0.4256 - val_loss: 3.2278 - val_accuracy500: 0.4059 - 107s/epoch - 48ms/step
Epoch 14/50
2222/2222 - 104s - loss: 3.1876 - accuracy500: 0.4268 - val_loss: 3.2277 - val_accuracy500: 0.4054 - 104s/epoch - 47ms/step
Epoch 15/50
2222/2222 - 107s - loss: 3.1865 - accuracy500: 0.4268 - val_loss: 3.2259 - val_accuracy500: 0.4064 - 107s/epoch - 48ms/step
Epoch 16/50
2222/2222 - 113s - loss: 3.1851 - accuracy500: 0.4279 - val_loss: 3.2274 - val_accuracy500: 0.4050 - 113s/epoch - 51ms/step
Epoch 17/50
2222/2222 - 108s - loss: 3.1838 - accuracy500: 0.4293 - val_loss: 3.2274 - val_accuracy500: 0.4059 - 108s/epoch - 49ms/step
Epoch 18/50
2222/2222 - 106s - loss: 3.1816 - accuracy500: 0.4304 - val_loss: 3.2280 - val_accuracy500: 0.4046 - 106s/epoch - 48ms/step
Epoch 19/50
2222/2222 - 105s - loss: 3.1804 - accuracy500: 0.4313 - val_loss: 3.2300 - val_accuracy500: 0.4034 - 105s/epoch - 47ms/step
Epoch 20/50
2222/2222 - 106s - loss: 3.1788 - accuracy500: 0.4321 - val_loss: 3.2304 - val_accuracy500: 0.4033 - 106s/epoch - 47ms/step
Epoch 21/50
2222/2222 - 105s - loss: 3.1758 - accuracy500: 0.4337 - val_loss: 3.2344 - val_accuracy500: 0.4005 - 105s/epoch - 47ms/step
Epoch 22/50
2222/2222 - 95s - loss: 3.1738 - accuracy500: 0.4353 - val_loss: 3.2360 - val_accuracy500: 0.3994 - 95s/epoch - 43ms/step
Epoch 23/50
2222/2222 - 102s - loss: 3.1705 - accuracy500: 0.4373 - val_loss: 3.2405 - val_accuracy500: 0.3985 - 102s/epoch - 46ms/step
Epoch 24/50
2222/2222 - 97s - loss: 3.1677 - accuracy500: 0.4379 - val_loss: 3.2424 - val_accuracy500: 0.3981 - 97s/epoch - 44ms/step
Epoch 25/50
2222/2222 - 99s - loss: 3.1666 - accuracy500: 0.4393 - val_loss: 3.2510 - val_accuracy500: 0.3948 - 99s/epoch - 45ms/step
testing model: results/WBA/W1/deepOF_L2/h500
Evaluating performance on  test set...
5696/5696 - 106s - 106s/epoch - 19ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0737314
{'0': {'precision': 0.41219668100397094, 'recall': 0.4512559396504667, 'f1-score': 0.43084286539375066, 'support': 558745}, '1': {'precision': 0.30198968312453944, 'recall': 0.030037822147946168, 'f1-score': 0.054640728543047246, 'support': 341070}, '2': {'precision': 0.40042318898379253, 'recall': 0.5827708149708709, 'f1-score': 0.4746874924759614, 'support': 558204}, 'accuracy': 0.4030722507731381, 'macro avg': {'precision': 0.371536517704101, 'recall': 0.35468819225642795, 'f1-score': 0.3200570288042531, 'support': 1458019}, 'weighted avg': {'precision': 0.38190879647957904, 'recall': 0.4030722507731381, 'f1-score': 0.3596249892207577, 'support': 1458019}}
[[252137  11749 294859]
 [138586  10245 192239]
 [220968  11931 325305]]
Evaluating performance on  train set...
2222/2222 - 42s - 42s/epoch - 19ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1201969
{'0': {'precision': 0.37652551048582705, 'recall': 0.46217900252887345, 'f1-score': 0.41497853454370104, 'support': 191785}, '1': {'precision': 0.37435367114788004, 'recall': 0.03031794055757373, 'f1-score': 0.05609304938163998, 'support': 191042}, '2': {'precision': 0.3558585353110945, 'recall': 0.608576303480793, 'f1-score': 0.44910669600654585, 'support': 185791}, 'accuracy': 0.36491809967324285, 'macro avg': {'precision': 0.36891257231493385, 'recall': 0.3670244155224134, 'f1-score': 0.306726093310629, 'support': 568618}, 'weighted avg': {'precision': 0.36904306969871026, 'recall': 0.36491809967324285, 'f1-score': 0.3055527062899576, 'support': 568618}}
[[ 88639   4876  98270]
 [ 78855   5792 106395]
 [ 67919   4804 113068]]
Evaluating performance on  val set...
641/641 - 11s - 11s/epoch - 17ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0756711
{'0': {'precision': 0.43000678494608136, 'recall': 0.46383469066787086, 'f1-score': 0.44628062027118137, 'support': 64219}, '1': {'precision': 0.3167834297898264, 'recall': 0.0261529950208721, 'f1-score': 0.04831703407744663, 'support': 39766}, '2': {'precision': 0.39295885729308155, 'recall': 0.5992883513472879, 'f1-score': 0.47467135948343736, 'support': 59861}, 'accuracy': 0.407095687413791, 'macro avg': {'precision': 0.37991635734299645, 'recall': 0.3630920123453436, 'f1-score': 0.32308967127735516, 'support': 163846}, 'weighted avg': {'precision': 0.38899164915772, 'recall': 0.407095687413791, 'f1-score': 0.36006599233644265, 'support': 163846}}
[[29787  1178 33254]
 [16562  1040 22164]
 [22922  1065 35874]]
training model: results/WBA/W1/deepOF_L2/h1000
Epoch 1/50
2222/2222 - 113s - loss: 3.2802 - accuracy1000: 0.3840 - val_loss: 3.2891 - val_accuracy1000: 0.3592 - 113s/epoch - 51ms/step
Epoch 2/50
2222/2222 - 114s - loss: 3.2526 - accuracy1000: 0.3949 - val_loss: 3.2826 - val_accuracy1000: 0.3634 - 114s/epoch - 52ms/step
Epoch 3/50
2222/2222 - 108s - loss: 3.2436 - accuracy1000: 0.3985 - val_loss: 3.2812 - val_accuracy1000: 0.3647 - 108s/epoch - 48ms/step
Epoch 4/50
2222/2222 - 105s - loss: 3.2396 - accuracy1000: 0.4002 - val_loss: 3.2808 - val_accuracy1000: 0.3666 - 105s/epoch - 47ms/step
Epoch 5/50
2222/2222 - 105s - loss: 3.2374 - accuracy1000: 0.4003 - val_loss: 3.2796 - val_accuracy1000: 0.3672 - 105s/epoch - 47ms/step
Epoch 6/50
2222/2222 - 110s - loss: 3.2356 - accuracy1000: 0.4016 - val_loss: 3.2802 - val_accuracy1000: 0.3677 - 110s/epoch - 49ms/step
Epoch 7/50
2222/2222 - 102s - loss: 3.2341 - accuracy1000: 0.4028 - val_loss: 3.2789 - val_accuracy1000: 0.3699 - 102s/epoch - 46ms/step
Epoch 8/50
2222/2222 - 104s - loss: 3.2331 - accuracy1000: 0.4035 - val_loss: 3.2782 - val_accuracy1000: 0.3697 - 104s/epoch - 47ms/step
Epoch 9/50
2222/2222 - 107s - loss: 3.2319 - accuracy1000: 0.4037 - val_loss: 3.2787 - val_accuracy1000: 0.3706 - 107s/epoch - 48ms/step
Epoch 10/50
2222/2222 - 100s - loss: 3.2307 - accuracy1000: 0.4042 - val_loss: 3.2788 - val_accuracy1000: 0.3709 - 100s/epoch - 45ms/step
Epoch 11/50
2222/2222 - 109s - loss: 3.2294 - accuracy1000: 0.4052 - val_loss: 3.2771 - val_accuracy1000: 0.3726 - 109s/epoch - 49ms/step
Epoch 12/50
2222/2222 - 110s - loss: 3.2288 - accuracy1000: 0.4059 - val_loss: 3.2769 - val_accuracy1000: 0.3718 - 110s/epoch - 49ms/step
Epoch 13/50
2222/2222 - 115s - loss: 3.2276 - accuracy1000: 0.4063 - val_loss: 3.2758 - val_accuracy1000: 0.3749 - 115s/epoch - 52ms/step
Epoch 14/50
2222/2222 - 111s - loss: 3.2264 - accuracy1000: 0.4077 - val_loss: 3.2761 - val_accuracy1000: 0.3752 - 111s/epoch - 50ms/step
Epoch 15/50
2222/2222 - 116s - loss: 3.2259 - accuracy1000: 0.4074 - val_loss: 3.2751 - val_accuracy1000: 0.3756 - 116s/epoch - 52ms/step
Epoch 16/50
2222/2222 - 107s - loss: 3.2248 - accuracy1000: 0.4087 - val_loss: 3.2765 - val_accuracy1000: 0.3745 - 107s/epoch - 48ms/step
Epoch 17/50
2222/2222 - 108s - loss: 3.2237 - accuracy1000: 0.4090 - val_loss: 3.2753 - val_accuracy1000: 0.3773 - 108s/epoch - 49ms/step
Epoch 18/50
2222/2222 - 108s - loss: 3.2226 - accuracy1000: 0.4099 - val_loss: 3.2754 - val_accuracy1000: 0.3766 - 108s/epoch - 49ms/step
Epoch 19/50
2222/2222 - 106s - loss: 3.2213 - accuracy1000: 0.4106 - val_loss: 3.2749 - val_accuracy1000: 0.3765 - 106s/epoch - 48ms/step
Epoch 20/50
2222/2222 - 115s - loss: 3.2198 - accuracy1000: 0.4117 - val_loss: 3.2733 - val_accuracy1000: 0.3788 - 115s/epoch - 52ms/step
Epoch 21/50
2222/2222 - 120s - loss: 3.2186 - accuracy1000: 0.4123 - val_loss: 3.2744 - val_accuracy1000: 0.3783 - 120s/epoch - 54ms/step
Epoch 22/50
2222/2222 - 121s - loss: 3.2174 - accuracy1000: 0.4132 - val_loss: 3.2754 - val_accuracy1000: 0.3780 - 121s/epoch - 54ms/step
Epoch 23/50
2222/2222 - 134s - loss: 3.2164 - accuracy1000: 0.4147 - val_loss: 3.2749 - val_accuracy1000: 0.3790 - 134s/epoch - 60ms/step
Epoch 24/50
2222/2222 - 149s - loss: 3.2149 - accuracy1000: 0.4150 - val_loss: 3.2760 - val_accuracy1000: 0.3788 - 149s/epoch - 67ms/step
Epoch 25/50
2222/2222 - 147s - loss: 3.2130 - accuracy1000: 0.4160 - val_loss: 3.2766 - val_accuracy1000: 0.3775 - 147s/epoch - 66ms/step
Epoch 26/50
2222/2222 - 150s - loss: 3.2117 - accuracy1000: 0.4172 - val_loss: 3.2753 - val_accuracy1000: 0.3792 - 150s/epoch - 67ms/step
Epoch 27/50
2222/2222 - 143s - loss: 3.2090 - accuracy1000: 0.4187 - val_loss: 3.2780 - val_accuracy1000: 0.3769 - 143s/epoch - 64ms/step
Epoch 28/50
2222/2222 - 146s - loss: 3.2071 - accuracy1000: 0.4195 - val_loss: 3.2785 - val_accuracy1000: 0.3770 - 146s/epoch - 66ms/step
Epoch 29/50
2222/2222 - 151s - loss: 3.2048 - accuracy1000: 0.4207 - val_loss: 3.2776 - val_accuracy1000: 0.3747 - 151s/epoch - 68ms/step
Epoch 30/50
2222/2222 - 152s - loss: 3.2031 - accuracy1000: 0.4212 - val_loss: 3.2802 - val_accuracy1000: 0.3716 - 152s/epoch - 68ms/step
testing model: results/WBA/W1/deepOF_L2/h1000
Evaluating performance on  test set...
5696/5696 - 169s - 169s/epoch - 30ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0929887
{'0': {'precision': 0.37392776297602115, 'recall': 0.36910315098425, 'f1-score': 0.37149979351281964, 'support': 505715}, '1': {'precision': 0.34697251498243437, 'recall': 0.3798152726910783, 'f1-score': 0.36265182940460516, 'support': 442057}, '2': {'precision': 0.37458651714256236, 'recall': 0.3486585908393386, 'f1-score': 0.36115780327575986, 'support': 510247}, 'accuracy': 0.36519620114689866, 'macro avg': {'precision': 0.3651622650336726, 'recall': 0.36585900483822237, 'f1-score': 0.36510314206439487, 'support': 1458019}, 'weighted avg': {'precision': 0.36598573428840747, 'recall': 0.36519620114689866, 'f1-score': 0.36519790446866174, 'support': 1458019}}
[[186661 156407 162647]
 [139777 167900 134380]
 [172752 159593 177902]]
Evaluating performance on  train set...
2222/2222 - 64s - 64s/epoch - 29ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.088086
{'0': {'precision': 0.3834109912555052, 'recall': 0.31654748291289664, 'f1-score': 0.34678566995638405, 'support': 189763}, '1': {'precision': 0.39587398513961264, 'recall': 0.5250050740815912, 'f1-score': 0.4513857684438298, 'support': 197080}, '2': {'precision': 0.3659069477095536, 'recall': 0.3031164901664145, 'f1-score': 0.33156515433705325, 'support': 181775}, 'accuracy': 0.3845041838281588, 'macro avg': {'precision': 0.3817306413682238, 'recall': 0.38155634905363417, 'f1-score': 0.3765788642457557, 'support': 568618}, 'weighted avg': {'precision': 0.38213493126288195, 'recall': 0.3845041838281588, 'f1-score': 0.3781738394888328, 'support': 568618}}
[[ 60069  79477  50217]
 [ 48346 103468  45266]
 [ 48255  78421  55099]]
Evaluating performance on  val set...
641/641 - 20s - 20s/epoch - 31ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0896722
{'0': {'precision': 0.4056901774123756, 'recall': 0.32135389888603255, 'f1-score': 0.3586305823850052, 'support': 58350}, '1': {'precision': 0.3680571046174437, 'recall': 0.5085431394833664, 'f1-score': 0.42704280942405837, 'support': 51913}, '2': {'precision': 0.36517931064534404, 'recall': 0.31280443424220367, 'f1-score': 0.33696886842713686, 'support': 53583}, 'accuracy': 0.3778670214713817, 'macro avg': {'precision': 0.37964219755838774, 'recall': 0.3809004908705342, 'f1-score': 0.3742140867454002, 'support': 163846}, 'weighted avg': {'precision': 0.38051812876925245, 'recall': 0.3778670214713817, 'f1-score': 0.3732222374957428, 'support': 163846}}
[[18751 23283 16316]
 [12692 26400 12821]
 [14777 22045 16761]]
training model: results/WBA/W1/deepVOL_L2/h10
Epoch 1/50
2222/2222 - 141s - loss: 2.8865 - accuracy10: 0.4980 - val_loss: 3.0365 - val_accuracy10: 0.5995 - 141s/epoch - 63ms/step
Epoch 2/50
2222/2222 - 137s - loss: 2.7099 - accuracy10: 0.5566 - val_loss: 3.0481 - val_accuracy10: 0.6095 - 137s/epoch - 62ms/step
Epoch 3/50
2222/2222 - 137s - loss: 2.6517 - accuracy10: 0.5729 - val_loss: 3.0530 - val_accuracy10: 0.6075 - 137s/epoch - 62ms/step
Epoch 4/50
2222/2222 - 137s - loss: 2.6212 - accuracy10: 0.5809 - val_loss: 3.0243 - val_accuracy10: 0.6174 - 137s/epoch - 62ms/step
Epoch 5/50
2222/2222 - 135s - loss: 2.6002 - accuracy10: 0.5846 - val_loss: 3.0126 - val_accuracy10: 0.6148 - 135s/epoch - 61ms/step
Epoch 6/50
2222/2222 - 134s - loss: 2.5827 - accuracy10: 0.5884 - val_loss: 2.9686 - val_accuracy10: 0.6123 - 134s/epoch - 60ms/step
Epoch 7/50
2222/2222 - 136s - loss: 2.5652 - accuracy10: 0.5902 - val_loss: 2.9486 - val_accuracy10: 0.6200 - 136s/epoch - 61ms/step
Epoch 8/50
2222/2222 - 134s - loss: 2.5509 - accuracy10: 0.5921 - val_loss: 2.9200 - val_accuracy10: 0.6200 - 134s/epoch - 61ms/step
Epoch 9/50
2222/2222 - 137s - loss: 2.5377 - accuracy10: 0.5951 - val_loss: 2.8766 - val_accuracy10: 0.6278 - 137s/epoch - 62ms/step
Epoch 10/50
2222/2222 - 135s - loss: 2.5276 - accuracy10: 0.5964 - val_loss: 2.8726 - val_accuracy10: 0.6290 - 135s/epoch - 61ms/step
Epoch 11/50
2222/2222 - 130s - loss: 2.5178 - accuracy10: 0.5980 - val_loss: 2.8771 - val_accuracy10: 0.6273 - 130s/epoch - 58ms/step
Epoch 12/50
2222/2222 - 140s - loss: 2.5101 - accuracy10: 0.5992 - val_loss: 2.8767 - val_accuracy10: 0.6291 - 140s/epoch - 63ms/step
Epoch 13/50
2222/2222 - 138s - loss: 2.5038 - accuracy10: 0.6007 - val_loss: 2.8356 - val_accuracy10: 0.6270 - 138s/epoch - 62ms/step
Epoch 14/50
2222/2222 - 140s - loss: 2.4972 - accuracy10: 0.6016 - val_loss: 2.8430 - val_accuracy10: 0.6296 - 140s/epoch - 63ms/step
Epoch 15/50
2222/2222 - 137s - loss: 2.4911 - accuracy10: 0.6025 - val_loss: 2.8251 - val_accuracy10: 0.6274 - 137s/epoch - 62ms/step
Epoch 16/50
2222/2222 - 135s - loss: 2.4849 - accuracy10: 0.6029 - val_loss: 2.7732 - val_accuracy10: 0.6341 - 135s/epoch - 61ms/step
Epoch 17/50
2222/2222 - 137s - loss: 2.4786 - accuracy10: 0.6035 - val_loss: 2.7771 - val_accuracy10: 0.6390 - 137s/epoch - 61ms/step
Epoch 18/50
2222/2222 - 138s - loss: 2.4741 - accuracy10: 0.6046 - val_loss: 2.7769 - val_accuracy10: 0.6332 - 138s/epoch - 62ms/step
Epoch 19/50
2222/2222 - 134s - loss: 2.4693 - accuracy10: 0.6056 - val_loss: 2.7561 - val_accuracy10: 0.6382 - 134s/epoch - 60ms/step
Epoch 20/50
2222/2222 - 135s - loss: 2.4650 - accuracy10: 0.6061 - val_loss: 2.7921 - val_accuracy10: 0.6326 - 135s/epoch - 61ms/step
Epoch 21/50
2222/2222 - 138s - loss: 2.4597 - accuracy10: 0.6062 - val_loss: 2.7611 - val_accuracy10: 0.6367 - 138s/epoch - 62ms/step
Epoch 22/50
2222/2222 - 135s - loss: 2.4559 - accuracy10: 0.6072 - val_loss: 2.7761 - val_accuracy10: 0.6390 - 135s/epoch - 61ms/step
Epoch 23/50
2222/2222 - 139s - loss: 2.4518 - accuracy10: 0.6079 - val_loss: 2.7600 - val_accuracy10: 0.6364 - 139s/epoch - 63ms/step
Epoch 24/50
2222/2222 - 137s - loss: 2.4479 - accuracy10: 0.6079 - val_loss: 2.7853 - val_accuracy10: 0.6299 - 137s/epoch - 62ms/step
Epoch 25/50
2222/2222 - 137s - loss: 2.4448 - accuracy10: 0.6086 - val_loss: 2.7608 - val_accuracy10: 0.6334 - 137s/epoch - 62ms/step
Epoch 26/50
2222/2222 - 139s - loss: 2.4411 - accuracy10: 0.6091 - val_loss: 2.7580 - val_accuracy10: 0.6353 - 139s/epoch - 63ms/step
Epoch 27/50
2222/2222 - 135s - loss: 2.4356 - accuracy10: 0.6102 - val_loss: 2.7752 - val_accuracy10: 0.6369 - 135s/epoch - 61ms/step
Epoch 28/50
2222/2222 - 140s - loss: 2.4330 - accuracy10: 0.6102 - val_loss: 2.7599 - val_accuracy10: 0.6339 - 140s/epoch - 63ms/step
Epoch 29/50
2222/2222 - 140s - loss: 2.4301 - accuracy10: 0.6107 - val_loss: 2.7545 - val_accuracy10: 0.6328 - 140s/epoch - 63ms/step
Epoch 30/50
2222/2222 - 140s - loss: 2.4259 - accuracy10: 0.6112 - val_loss: 2.7587 - val_accuracy10: 0.6330 - 140s/epoch - 63ms/step
Epoch 31/50
2222/2222 - 140s - loss: 2.4236 - accuracy10: 0.6113 - val_loss: 2.7512 - val_accuracy10: 0.6355 - 140s/epoch - 63ms/step
Epoch 32/50
2222/2222 - 141s - loss: 2.4189 - accuracy10: 0.6117 - val_loss: 2.7428 - val_accuracy10: 0.6344 - 141s/epoch - 64ms/step
Epoch 33/50
2222/2222 - 141s - loss: 2.4146 - accuracy10: 0.6127 - val_loss: 2.7399 - val_accuracy10: 0.6293 - 141s/epoch - 64ms/step
Epoch 34/50
2222/2222 - 134s - loss: 2.4137 - accuracy10: 0.6129 - val_loss: 2.7415 - val_accuracy10: 0.6305 - 134s/epoch - 61ms/step
Epoch 35/50
2222/2222 - 139s - loss: 2.4103 - accuracy10: 0.6129 - val_loss: 2.7682 - val_accuracy10: 0.6297 - 139s/epoch - 63ms/step
Epoch 36/50
2222/2222 - 139s - loss: 2.4078 - accuracy10: 0.6133 - val_loss: 2.7540 - val_accuracy10: 0.6295 - 139s/epoch - 63ms/step
Epoch 37/50
2222/2222 - 142s - loss: 2.4039 - accuracy10: 0.6140 - val_loss: 2.7468 - val_accuracy10: 0.6251 - 142s/epoch - 64ms/step
Epoch 38/50
2222/2222 - 141s - loss: 2.4014 - accuracy10: 0.6141 - val_loss: 2.7452 - val_accuracy10: 0.6281 - 141s/epoch - 63ms/step
Epoch 39/50
2222/2222 - 138s - loss: 2.3988 - accuracy10: 0.6144 - val_loss: 2.7473 - val_accuracy10: 0.6305 - 138s/epoch - 62ms/step
Epoch 40/50
2222/2222 - 136s - loss: 2.3952 - accuracy10: 0.6146 - val_loss: 2.7625 - val_accuracy10: 0.6202 - 136s/epoch - 61ms/step
Epoch 41/50
2222/2222 - 141s - loss: 2.3935 - accuracy10: 0.6151 - val_loss: 2.7509 - val_accuracy10: 0.6328 - 141s/epoch - 63ms/step
Epoch 42/50
2222/2222 - 142s - loss: 2.3900 - accuracy10: 0.6153 - val_loss: 2.7754 - val_accuracy10: 0.6324 - 142s/epoch - 64ms/step
Epoch 43/50
2222/2222 - 138s - loss: 2.3872 - accuracy10: 0.6163 - val_loss: 2.7566 - val_accuracy10: 0.6265 - 138s/epoch - 62ms/step
testing model: results/WBA/W1/deepVOL_L2/h10
Evaluating performance on  test set...
5696/5696 - 161s - 161s/epoch - 28ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.93503416
{'0': {'precision': 0.4049193859725833, 'recall': 0.5598424059050602, 'f1-score': 0.46994200050003837, 'support': 339099}, '1': {'precision': 0.7039225838704494, 'recall': 0.6499208740375544, 'f1-score': 0.6758447267910699, 'support': 788616}, '2': {'precision': 0.4780095607274733, 'recall': 0.3778068414726816, 'f1-score': 0.42204211526657276, 'support': 330309}, 'accuracy': 0.5673246805265209, 'macro avg': {'precision': 0.5289505101901687, 'recall': 0.5291900404717654, 'f1-score': 0.5226096141858937, 'support': 1458024}, 'weighted avg': {'precision': 0.5832024927297673, 'recall': 0.5673246805265209, 'f1-score': 0.5704591533076377, 'support': 1458024}}
[[189842 112831  36426]
 [176229 512538  99849]
 [102768 102748 124793]]
Evaluating performance on  train set...
2222/2222 - 64s - 64s/epoch - 29ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.784281
{'0': {'precision': 0.4347810801499075, 'recall': 0.5797502297061636, 'f1-score': 0.4969081360821926, 'support': 106658}, '1': {'precision': 0.7898437864576042, 'recall': 0.7583285962706482, 'f1-score': 0.7737654237210652, 'support': 357113}, '2': {'precision': 0.4816362199822827, 'recall': 0.38372691896841143, 'f1-score': 0.4271427206420995, 'support': 104848}, 'accuracy': 0.6557589528313335, 'macro avg': {'precision': 0.5687536955299315, 'recall': 0.5739352483150744, 'f1-score': 0.5659387601484523, 'support': 568619}, 'weighted avg': {'precision': 0.6664127631200605, 'recall': 0.6557589528313335, 'f1-score': 0.6579202941045552, 'support': 568619}}
[[ 61835  35084   9739]
 [ 52742 270809  33562]
 [ 27644  36971  40233]]
Evaluating performance on  val set...
641/641 - 17s - 17s/epoch - 27ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.8386494
{'0': {'precision': 0.39558381603588694, 'recall': 0.5963887065003283, 'f1-score': 0.475661805137336, 'support': 30460}, '1': {'precision': 0.7913768385281156, 'recall': 0.7163455992617372, 'f1-score': 0.7519942682133073, 'support': 104028}, '2': {'precision': 0.44587542087542087, 'recall': 0.36084335297523756, 'f1-score': 0.398877990926034, 'support': 29359}, 'accuracy': 0.6303441625418836, 'macro avg': {'precision': 0.5442786918131411, 'recall': 0.557859219579101, 'f1-score': 0.5421780214255592, 'support': 163847}, 'weighted avg': {'precision': 0.6558880496825539, 'recall': 0.6303441625418836, 'f1-score': 0.6373493396508609, 'support': 163847}}
[[18166  9364  2930]
 [19272 74520 10236]
 [ 8484 10281 10594]]
training model: results/WBA/W1/deepVOL_L2/h20
Epoch 1/50
2222/2222 - 150s - loss: 3.0173 - accuracy20: 0.4770 - val_loss: 3.0999 - val_accuracy20: 0.5550 - 150s/epoch - 67ms/step
Epoch 2/50
2222/2222 - 140s - loss: 2.8252 - accuracy20: 0.5420 - val_loss: 3.0331 - val_accuracy20: 0.5824 - 140s/epoch - 63ms/step
Epoch 3/50
2222/2222 - 139s - loss: 2.7548 - accuracy20: 0.5619 - val_loss: 3.0361 - val_accuracy20: 0.5876 - 139s/epoch - 62ms/step
Epoch 4/50
2222/2222 - 139s - loss: 2.7208 - accuracy20: 0.5691 - val_loss: 3.0370 - val_accuracy20: 0.5884 - 139s/epoch - 63ms/step
Epoch 5/50
2222/2222 - 142s - loss: 2.6967 - accuracy20: 0.5740 - val_loss: 2.9923 - val_accuracy20: 0.5930 - 142s/epoch - 64ms/step
Epoch 6/50
2222/2222 - 138s - loss: 2.6772 - accuracy20: 0.5773 - val_loss: 2.9981 - val_accuracy20: 0.5899 - 138s/epoch - 62ms/step
Epoch 7/50
2222/2222 - 137s - loss: 2.6622 - accuracy20: 0.5806 - val_loss: 2.9710 - val_accuracy20: 0.5936 - 137s/epoch - 62ms/step
Epoch 8/50
2222/2222 - 142s - loss: 2.6493 - accuracy20: 0.5825 - val_loss: 2.9914 - val_accuracy20: 0.5927 - 142s/epoch - 64ms/step
Epoch 9/50
2222/2222 - 137s - loss: 2.6414 - accuracy20: 0.5843 - val_loss: 2.9944 - val_accuracy20: 0.5932 - 137s/epoch - 62ms/step
Epoch 10/50
2222/2222 - 140s - loss: 2.6328 - accuracy20: 0.5862 - val_loss: 2.9728 - val_accuracy20: 0.5935 - 140s/epoch - 63ms/step
Epoch 11/50
2222/2222 - 145s - loss: 2.6260 - accuracy20: 0.5877 - val_loss: 2.9640 - val_accuracy20: 0.5958 - 145s/epoch - 65ms/step
Epoch 12/50
2222/2222 - 148s - loss: 2.6194 - accuracy20: 0.5886 - val_loss: 2.9781 - val_accuracy20: 0.5951 - 148s/epoch - 66ms/step
Epoch 13/50
2222/2222 - 137s - loss: 2.6134 - accuracy20: 0.5896 - val_loss: 2.9531 - val_accuracy20: 0.5962 - 137s/epoch - 62ms/step
Epoch 14/50
2222/2222 - 136s - loss: 2.6080 - accuracy20: 0.5908 - val_loss: 2.9396 - val_accuracy20: 0.5974 - 136s/epoch - 61ms/step
Epoch 15/50
2222/2222 - 135s - loss: 2.6018 - accuracy20: 0.5917 - val_loss: 2.9347 - val_accuracy20: 0.5983 - 135s/epoch - 61ms/step
Epoch 16/50
2222/2222 - 143s - loss: 2.5975 - accuracy20: 0.5925 - val_loss: 2.9431 - val_accuracy20: 0.5982 - 143s/epoch - 65ms/step
Epoch 17/50
2222/2222 - 141s - loss: 2.5928 - accuracy20: 0.5930 - val_loss: 2.9322 - val_accuracy20: 0.5990 - 141s/epoch - 64ms/step
Epoch 18/50
2222/2222 - 139s - loss: 2.5885 - accuracy20: 0.5933 - val_loss: 2.9310 - val_accuracy20: 0.5994 - 139s/epoch - 63ms/step
Epoch 19/50
2222/2222 - 142s - loss: 2.5831 - accuracy20: 0.5941 - val_loss: 2.9212 - val_accuracy20: 0.5986 - 142s/epoch - 64ms/step
Epoch 20/50
2222/2222 - 144s - loss: 2.5799 - accuracy20: 0.5949 - val_loss: 2.9370 - val_accuracy20: 0.5993 - 144s/epoch - 65ms/step
Epoch 21/50
2222/2222 - 142s - loss: 2.5758 - accuracy20: 0.5951 - val_loss: 2.9153 - val_accuracy20: 0.5999 - 142s/epoch - 64ms/step
Epoch 22/50
2222/2222 - 138s - loss: 2.5721 - accuracy20: 0.5955 - val_loss: 2.9284 - val_accuracy20: 0.6010 - 138s/epoch - 62ms/step
Epoch 23/50
2222/2222 - 138s - loss: 2.5680 - accuracy20: 0.5968 - val_loss: 2.9192 - val_accuracy20: 0.6004 - 138s/epoch - 62ms/step
Epoch 24/50
2222/2222 - 144s - loss: 2.5644 - accuracy20: 0.5964 - val_loss: 2.9185 - val_accuracy20: 0.6016 - 144s/epoch - 65ms/step
Epoch 25/50
2222/2222 - 142s - loss: 2.5622 - accuracy20: 0.5978 - val_loss: 2.9242 - val_accuracy20: 0.6000 - 142s/epoch - 64ms/step
Epoch 26/50
2222/2222 - 143s - loss: 2.5591 - accuracy20: 0.5975 - val_loss: 2.9159 - val_accuracy20: 0.6018 - 143s/epoch - 65ms/step
Epoch 27/50
2222/2222 - 136s - loss: 2.5560 - accuracy20: 0.5981 - val_loss: 2.9230 - val_accuracy20: 0.6001 - 136s/epoch - 61ms/step
Epoch 28/50
2222/2222 - 140s - loss: 2.5530 - accuracy20: 0.5985 - val_loss: 2.9087 - val_accuracy20: 0.6014 - 140s/epoch - 63ms/step
Epoch 29/50
2222/2222 - 137s - loss: 2.5499 - accuracy20: 0.5995 - val_loss: 2.9233 - val_accuracy20: 0.6014 - 137s/epoch - 62ms/step
Epoch 30/50
2222/2222 - 143s - loss: 2.5477 - accuracy20: 0.5991 - val_loss: 2.9272 - val_accuracy20: 0.6028 - 143s/epoch - 64ms/step
Epoch 31/50
2222/2222 - 142s - loss: 2.5432 - accuracy20: 0.5999 - val_loss: 2.9317 - val_accuracy20: 0.6021 - 142s/epoch - 64ms/step
Epoch 32/50
2222/2222 - 136s - loss: 2.5421 - accuracy20: 0.6004 - val_loss: 2.9240 - val_accuracy20: 0.6015 - 136s/epoch - 61ms/step
Epoch 33/50
2222/2222 - 144s - loss: 2.5374 - accuracy20: 0.6013 - val_loss: 2.9128 - val_accuracy20: 0.6016 - 144s/epoch - 65ms/step
Epoch 34/50
2222/2222 - 142s - loss: 2.5345 - accuracy20: 0.6012 - val_loss: 2.9281 - val_accuracy20: 0.6015 - 142s/epoch - 64ms/step
Epoch 35/50
2222/2222 - 145s - loss: 2.5348 - accuracy20: 0.6014 - val_loss: 2.9211 - val_accuracy20: 0.6025 - 145s/epoch - 65ms/step
Epoch 36/50
2222/2222 - 141s - loss: 2.5297 - accuracy20: 0.6024 - val_loss: 2.9327 - val_accuracy20: 0.6009 - 141s/epoch - 63ms/step
Epoch 37/50
2222/2222 - 141s - loss: 2.5253 - accuracy20: 0.6031 - val_loss: 2.9298 - val_accuracy20: 0.6001 - 141s/epoch - 63ms/step
Epoch 38/50
2222/2222 - 141s - loss: 2.5238 - accuracy20: 0.6030 - val_loss: 2.9161 - val_accuracy20: 0.6031 - 141s/epoch - 63ms/step
testing model: results/WBA/W1/deepVOL_L2/h20
Evaluating performance on  test set...
5696/5696 - 157s - 157s/epoch - 28ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.99221915
{'0': {'precision': 0.486484119250687, 'recall': 0.41158217471447495, 'f1-score': 0.44590960179833006, 'support': 431836}, '1': {'precision': 0.5428483438514987, 'recall': 0.7482177848048159, 'f1-score': 0.6291990414840394, 'support': 607811}, '2': {'precision': 0.5284502135972603, 'recall': 0.3219871073218652, 'f1-score': 0.4001568403792685, 'support': 418377}, 'accuracy': 0.5262073875327156, 'macro avg': {'precision': 0.5192608922331486, 'recall': 0.4939290222803854, 'f1-score': 0.49175516122054597, 'support': 1458024}, 'weighted avg': {'precision': 0.5220229336826032, 'recall': 0.5262073875327156, 'f1-score': 0.5091893794704315, 'support': 1458024}}
[[177736 194253  59847]
 [ 92676 454775  60360]
 [ 94936 188729 134712]]
Evaluating performance on  train set...
2222/2222 - 66s - 66s/epoch - 29ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.84669083
{'0': {'precision': 0.5243286130707004, 'recall': 0.44418954659029475, 'f1-score': 0.48094356637714175, 'support': 136874}, '1': {'precision': 0.6580182379099209, 'recall': 0.8460981539725622, 'f1-score': 0.7402991143246062, 'support': 296962}, '2': {'precision': 0.5590556740042076, 'recall': 0.29376108262911493, 'f1-score': 0.38514440240070813, 'support': 134783}, 'accuracy': 0.6184299152859823, 'macro avg': {'precision': 0.5804675083282763, 'recall': 0.5280162610639906, 'f1-score': 0.5354623610341521, 'support': 568619}, 'weighted avg': {'precision': 0.6023797436613164, 'recall': 0.6184299152859823, 'f1-score': 0.5936845115642341, 'support': 568619}}
[[ 60798  61331  14745]
 [ 29219 251259  16484]
 [ 25937  69252  39594]]
Evaluating performance on  val set...
641/641 - 19s - 19s/epoch - 29ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.88583654
{'0': {'precision': 0.4847785351546588, 'recall': 0.4531285696154334, 'f1-score': 0.4684195334435435, 'support': 39395}, '1': {'precision': 0.6626433886771652, 'recall': 0.8068413256804295, 'f1-score': 0.7276674128691223, 'support': 86416}, '2': {'precision': 0.5069944503050039, 'recall': 0.29061941318750656, 'f1-score': 0.36945804575611224, 'support': 38036}, 'accuracy': 0.6019579241609551, 'macro avg': {'precision': 0.5514721247122759, 'recall': 0.5168631028277898, 'f1-score': 0.5218483306895927, 'support': 163847}, 'weighted avg': {'precision': 0.5837450937773948, 'recall': 0.6019579241609551, 'f1-score': 0.5821785012779358, 'support': 163847}}
[[17851 16725  4819]
 [10762 69724  5930]
 [ 8210 18772 11054]]
training model: results/WBA/W1/deepVOL_L2/h30
Epoch 1/50
2222/2222 - 148s - loss: 3.0668 - accuracy30: 0.4703 - val_loss: 3.1909 - val_accuracy30: 0.5225 - 148s/epoch - 67ms/step
Epoch 2/50
2222/2222 - 143s - loss: 2.8741 - accuracy30: 0.5319 - val_loss: 3.1923 - val_accuracy30: 0.5328 - 143s/epoch - 64ms/step
Epoch 3/50
2222/2222 - 141s - loss: 2.8136 - accuracy30: 0.5475 - val_loss: 3.1000 - val_accuracy30: 0.5428 - 141s/epoch - 63ms/step
Epoch 4/50
2222/2222 - 142s - loss: 2.7838 - accuracy30: 0.5535 - val_loss: 3.1225 - val_accuracy30: 0.5463 - 142s/epoch - 64ms/step
Epoch 5/50
2222/2222 - 141s - loss: 2.7639 - accuracy30: 0.5568 - val_loss: 3.0810 - val_accuracy30: 0.5486 - 141s/epoch - 63ms/step
Epoch 6/50
2222/2222 - 142s - loss: 2.7483 - accuracy30: 0.5588 - val_loss: 3.0740 - val_accuracy30: 0.5486 - 142s/epoch - 64ms/step
Epoch 7/50
2222/2222 - 141s - loss: 2.7356 - accuracy30: 0.5617 - val_loss: 3.1010 - val_accuracy30: 0.5462 - 141s/epoch - 64ms/step
Epoch 8/50
2222/2222 - 142s - loss: 2.7255 - accuracy30: 0.5645 - val_loss: 3.1188 - val_accuracy30: 0.5449 - 142s/epoch - 64ms/step
Epoch 9/50
2222/2222 - 144s - loss: 2.7169 - accuracy30: 0.5669 - val_loss: 3.0905 - val_accuracy30: 0.5486 - 144s/epoch - 65ms/step
Epoch 10/50
2222/2222 - 145s - loss: 2.7098 - accuracy30: 0.5686 - val_loss: 3.0651 - val_accuracy30: 0.5487 - 145s/epoch - 65ms/step
Epoch 11/50
2222/2222 - 145s - loss: 2.7049 - accuracy30: 0.5693 - val_loss: 3.0880 - val_accuracy30: 0.5486 - 145s/epoch - 65ms/step
Epoch 12/50
2222/2222 - 142s - loss: 2.6996 - accuracy30: 0.5704 - val_loss: 3.0929 - val_accuracy30: 0.5468 - 142s/epoch - 64ms/step
Epoch 13/50
2222/2222 - 146s - loss: 2.6935 - accuracy30: 0.5722 - val_loss: 3.0740 - val_accuracy30: 0.5484 - 146s/epoch - 66ms/step
Epoch 14/50
2222/2222 - 145s - loss: 2.6882 - accuracy30: 0.5731 - val_loss: 3.0665 - val_accuracy30: 0.5480 - 145s/epoch - 65ms/step
Epoch 15/50
2222/2222 - 142s - loss: 2.6842 - accuracy30: 0.5741 - val_loss: 3.0618 - val_accuracy30: 0.5485 - 142s/epoch - 64ms/step
Epoch 16/50
2222/2222 - 142s - loss: 2.6806 - accuracy30: 0.5744 - val_loss: 3.0355 - val_accuracy30: 0.5510 - 142s/epoch - 64ms/step
Epoch 17/50
2222/2222 - 141s - loss: 2.6755 - accuracy30: 0.5758 - val_loss: 3.0584 - val_accuracy30: 0.5491 - 141s/epoch - 64ms/step
Epoch 18/50
2222/2222 - 136s - loss: 2.6712 - accuracy30: 0.5763 - val_loss: 3.0465 - val_accuracy30: 0.5492 - 136s/epoch - 61ms/step
Epoch 19/50
2222/2222 - 139s - loss: 2.6682 - accuracy30: 0.5771 - val_loss: 3.0430 - val_accuracy30: 0.5487 - 139s/epoch - 63ms/step
Epoch 20/50
2222/2222 - 139s - loss: 2.6644 - accuracy30: 0.5774 - val_loss: 3.0116 - val_accuracy30: 0.5531 - 139s/epoch - 63ms/step
Epoch 21/50
2222/2222 - 144s - loss: 2.6612 - accuracy30: 0.5789 - val_loss: 3.0024 - val_accuracy30: 0.5543 - 144s/epoch - 65ms/step
Epoch 22/50
2222/2222 - 137s - loss: 2.6583 - accuracy30: 0.5787 - val_loss: 3.0220 - val_accuracy30: 0.5538 - 137s/epoch - 62ms/step
Epoch 23/50
2222/2222 - 145s - loss: 2.6551 - accuracy30: 0.5790 - val_loss: 3.0123 - val_accuracy30: 0.5529 - 145s/epoch - 65ms/step
Epoch 24/50
2222/2222 - 142s - loss: 2.6529 - accuracy30: 0.5801 - val_loss: 3.0315 - val_accuracy30: 0.5515 - 142s/epoch - 64ms/step
Epoch 25/50
2222/2222 - 142s - loss: 2.6491 - accuracy30: 0.5806 - val_loss: 3.0099 - val_accuracy30: 0.5548 - 142s/epoch - 64ms/step
Epoch 26/50
2222/2222 - 146s - loss: 2.6463 - accuracy30: 0.5814 - val_loss: 3.0208 - val_accuracy30: 0.5524 - 146s/epoch - 66ms/step
Epoch 27/50
2222/2222 - 144s - loss: 2.6434 - accuracy30: 0.5814 - val_loss: 3.0229 - val_accuracy30: 0.5532 - 144s/epoch - 65ms/step
Epoch 28/50
2222/2222 - 142s - loss: 2.6404 - accuracy30: 0.5823 - val_loss: 3.0050 - val_accuracy30: 0.5544 - 142s/epoch - 64ms/step
Epoch 29/50
2222/2222 - 142s - loss: 2.6372 - accuracy30: 0.5827 - val_loss: 3.0052 - val_accuracy30: 0.5535 - 142s/epoch - 64ms/step
Epoch 30/50
2222/2222 - 145s - loss: 2.6344 - accuracy30: 0.5836 - val_loss: 3.0224 - val_accuracy30: 0.5530 - 145s/epoch - 65ms/step
Epoch 31/50
2222/2222 - 147s - loss: 2.6306 - accuracy30: 0.5840 - val_loss: 3.0412 - val_accuracy30: 0.5507 - 147s/epoch - 66ms/step
testing model: results/WBA/W1/deepVOL_L2/h30
Evaluating performance on  test set...
5696/5696 - 172s - 172s/epoch - 30ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.0505921
{'0': {'precision': 0.47557275726776027, 'recall': 0.44279065167539233, 'f1-score': 0.45859660578591227, 'support': 485349}, '1': {'precision': 0.45358781329833303, 'recall': 0.7488359704651912, 'f1-score': 0.5649636591507097, 'support': 499343}, '2': {'precision': 0.5804893346611134, 'recall': 0.22290485325310774, 'f1-score': 0.3221180633471177, 'support': 473332}, 'accuracy': 0.47622124189999615, 'macro avg': {'precision': 0.5032166350757356, 'recall': 0.4715104917978971, 'f1-score': 0.44855944276124654, 'support': 1458024}, 'weighted avg': {'precision': 0.5021034217384582, 'recall': 0.47622124189999615, 'f1-score': 0.45071880821790133, 'support': 1458024}}
[[214908 226902  43539]
 [ 92707 373926  32710]
 [144278 223546 105508]]
Evaluating performance on  train set...
2222/2222 - 63s - 63s/epoch - 28ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.9189166
{'0': {'precision': 0.5160585357121547, 'recall': 0.4418961123565366, 'f1-score': 0.4761065905142012, 'support': 156573}, '1': {'precision': 0.5776428946057567, 'recall': 0.8513015917406604, 'f1-score': 0.6882679073039221, 'support': 257454}, '2': {'precision': 0.5980698062549887, 'recall': 0.2132581246118816, 'f1-score': 0.31440614926853455, 'support': 154592}, 'accuracy': 0.5651024675573627, 'macro avg': {'precision': 0.5639237455243, 'recall': 0.5021519429030262, 'f1-score': 0.49292688236221927, 'support': 568619}, 'weighted avg': {'precision': 0.5662387545763699, 'recall': 0.5651024675573627, 'f1-score': 0.528205069530433, 'support': 568619}}
[[ 69189  75654  11730]
 [ 27857 219171  10426]
 [ 37026  84598  32968]]
Evaluating performance on  val set...
641/641 - 19s - 19s/epoch - 29ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.95305824
{'0': {'precision': 0.48150732728541523, 'recall': 0.47084461467344646, 'f1-score': 0.47611628010506163, 'support': 45429}, '1': {'precision': 0.5833963288170417, 'recall': 0.8079891545079931, 'f1-score': 0.6775662274950334, 'support': 74501}, '2': {'precision': 0.5638468168944711, 'recall': 0.2085297265295899, 'f1-score': 0.30445984806928306, 'support': 43917}, 'accuracy': 0.5538337595439647, 'macro avg': {'precision': 0.5429168243323094, 'recall': 0.4957878319036764, 'f1-score': 0.48604745188979265, 'support': 163847}, 'weighted avg': {'precision': 0.5499061131543577, 'recall': 0.5538337595439647, 'f1-score': 0.5217050733376811, 'support': 163847}}
[[21390 20371  3668]
 [10889 60196  3416]
 [12144 22615  9158]]
training model: results/WBA/W1/deepVOL_L2/h50
Epoch 1/50
2222/2222 - 152s - loss: 3.1696 - accuracy50: 0.4408 - val_loss: 3.2106 - val_accuracy50: 0.4553 - 152s/epoch - 68ms/step
Epoch 2/50
2222/2222 - 139s - loss: 3.0328 - accuracy50: 0.4813 - val_loss: 3.2810 - val_accuracy50: 0.4579 - 139s/epoch - 62ms/step
Epoch 3/50
2222/2222 - 142s - loss: 2.9484 - accuracy50: 0.5041 - val_loss: 3.2199 - val_accuracy50: 0.4714 - 142s/epoch - 64ms/step
Epoch 4/50
2222/2222 - 140s - loss: 2.9231 - accuracy50: 0.5112 - val_loss: 3.1773 - val_accuracy50: 0.4718 - 140s/epoch - 63ms/step
Epoch 5/50
2222/2222 - 141s - loss: 2.9080 - accuracy50: 0.5155 - val_loss: 3.1656 - val_accuracy50: 0.4731 - 141s/epoch - 63ms/step
Epoch 6/50
2222/2222 - 142s - loss: 2.8973 - accuracy50: 0.5181 - val_loss: 3.1692 - val_accuracy50: 0.4750 - 142s/epoch - 64ms/step
Epoch 7/50
2222/2222 - 142s - loss: 2.8878 - accuracy50: 0.5197 - val_loss: 3.1791 - val_accuracy50: 0.4751 - 142s/epoch - 64ms/step
Epoch 8/50
2222/2222 - 141s - loss: 2.8804 - accuracy50: 0.5214 - val_loss: 3.1768 - val_accuracy50: 0.4755 - 141s/epoch - 64ms/step
Epoch 9/50
2222/2222 - 138s - loss: 2.8718 - accuracy50: 0.5233 - val_loss: 3.1848 - val_accuracy50: 0.4731 - 138s/epoch - 62ms/step
Epoch 10/50
2222/2222 - 139s - loss: 2.8639 - accuracy50: 0.5247 - val_loss: 3.1737 - val_accuracy50: 0.4770 - 139s/epoch - 63ms/step
Epoch 11/50
2222/2222 - 138s - loss: 2.8573 - accuracy50: 0.5259 - val_loss: 3.1599 - val_accuracy50: 0.4793 - 138s/epoch - 62ms/step
Epoch 12/50
2222/2222 - 143s - loss: 2.8529 - accuracy50: 0.5269 - val_loss: 3.1493 - val_accuracy50: 0.4799 - 143s/epoch - 64ms/step
Epoch 13/50
2222/2222 - 141s - loss: 2.8483 - accuracy50: 0.5286 - val_loss: 3.1641 - val_accuracy50: 0.4796 - 141s/epoch - 63ms/step
Epoch 14/50
2222/2222 - 137s - loss: 2.8434 - accuracy50: 0.5298 - val_loss: 3.1517 - val_accuracy50: 0.4820 - 137s/epoch - 62ms/step
Epoch 15/50
2222/2222 - 141s - loss: 2.8389 - accuracy50: 0.5310 - val_loss: 3.1489 - val_accuracy50: 0.4823 - 141s/epoch - 63ms/step
Epoch 16/50
2222/2222 - 143s - loss: 2.8353 - accuracy50: 0.5318 - val_loss: 3.1477 - val_accuracy50: 0.4841 - 143s/epoch - 64ms/step
Epoch 17/50
2222/2222 - 133s - loss: 2.8312 - accuracy50: 0.5329 - val_loss: 3.1373 - val_accuracy50: 0.4831 - 133s/epoch - 60ms/step
Epoch 18/50
2222/2222 - 121s - loss: 2.8274 - accuracy50: 0.5340 - val_loss: 3.1470 - val_accuracy50: 0.4859 - 121s/epoch - 55ms/step
Epoch 19/50
2222/2222 - 127s - loss: 2.8246 - accuracy50: 0.5348 - val_loss: 3.1168 - val_accuracy50: 0.4889 - 127s/epoch - 57ms/step
Epoch 20/50
2222/2222 - 143s - loss: 2.8211 - accuracy50: 0.5352 - val_loss: 3.1245 - val_accuracy50: 0.4852 - 143s/epoch - 64ms/step
Epoch 21/50
2222/2222 - 138s - loss: 2.8170 - accuracy50: 0.5363 - val_loss: 3.1193 - val_accuracy50: 0.4881 - 138s/epoch - 62ms/step
Epoch 22/50
2222/2222 - 139s - loss: 2.8140 - accuracy50: 0.5369 - val_loss: 3.1248 - val_accuracy50: 0.4878 - 139s/epoch - 62ms/step
Epoch 23/50
2222/2222 - 143s - loss: 2.8108 - accuracy50: 0.5378 - val_loss: 3.1292 - val_accuracy50: 0.4861 - 143s/epoch - 64ms/step
Epoch 24/50
2222/2222 - 145s - loss: 2.8081 - accuracy50: 0.5380 - val_loss: 3.1150 - val_accuracy50: 0.4882 - 145s/epoch - 65ms/step
Epoch 25/50
2222/2222 - 127s - loss: 2.8070 - accuracy50: 0.5389 - val_loss: 3.1172 - val_accuracy50: 0.4900 - 127s/epoch - 57ms/step
Epoch 26/50
2222/2222 - 137s - loss: 2.8030 - accuracy50: 0.5400 - val_loss: 3.1301 - val_accuracy50: 0.4855 - 137s/epoch - 62ms/step
Epoch 27/50
2222/2222 - 133s - loss: 2.7997 - accuracy50: 0.5403 - val_loss: 3.1202 - val_accuracy50: 0.4880 - 133s/epoch - 60ms/step
Epoch 28/50
2222/2222 - 142s - loss: 2.7969 - accuracy50: 0.5412 - val_loss: 3.1154 - val_accuracy50: 0.4872 - 142s/epoch - 64ms/step
Epoch 29/50
2222/2222 - 141s - loss: 2.7947 - accuracy50: 0.5416 - val_loss: 3.1115 - val_accuracy50: 0.4904 - 141s/epoch - 64ms/step
Epoch 30/50
2222/2222 - 143s - loss: 2.7930 - accuracy50: 0.5416 - val_loss: 3.1123 - val_accuracy50: 0.4898 - 143s/epoch - 64ms/step
Epoch 31/50
2222/2222 - 139s - loss: 2.7886 - accuracy50: 0.5433 - val_loss: 3.1003 - val_accuracy50: 0.4903 - 139s/epoch - 63ms/step
Epoch 32/50
2222/2222 - 140s - loss: 2.7870 - accuracy50: 0.5431 - val_loss: 3.1030 - val_accuracy50: 0.4898 - 140s/epoch - 63ms/step
Epoch 33/50
2222/2222 - 144s - loss: 2.7846 - accuracy50: 0.5439 - val_loss: 3.1201 - val_accuracy50: 0.4855 - 144s/epoch - 65ms/step
Epoch 34/50
2222/2222 - 138s - loss: 2.7819 - accuracy50: 0.5443 - val_loss: 3.1132 - val_accuracy50: 0.4871 - 138s/epoch - 62ms/step
Epoch 35/50
2222/2222 - 138s - loss: 2.7798 - accuracy50: 0.5455 - val_loss: 3.1264 - val_accuracy50: 0.4858 - 138s/epoch - 62ms/step
Epoch 36/50
2222/2222 - 141s - loss: 2.7765 - accuracy50: 0.5462 - val_loss: 3.1107 - val_accuracy50: 0.4891 - 141s/epoch - 63ms/step
Epoch 37/50
2222/2222 - 136s - loss: 2.7741 - accuracy50: 0.5467 - val_loss: 3.1380 - val_accuracy50: 0.4889 - 136s/epoch - 61ms/step
Epoch 38/50
2222/2222 - 133s - loss: 2.7720 - accuracy50: 0.5466 - val_loss: 3.1310 - val_accuracy50: 0.4859 - 133s/epoch - 60ms/step
Epoch 39/50
2222/2222 - 140s - loss: 2.7698 - accuracy50: 0.5472 - val_loss: 3.1270 - val_accuracy50: 0.4857 - 140s/epoch - 63ms/step
Epoch 40/50
2222/2222 - 140s - loss: 2.7676 - accuracy50: 0.5481 - val_loss: 3.1202 - val_accuracy50: 0.4880 - 140s/epoch - 63ms/step
Epoch 41/50
2222/2222 - 134s - loss: 2.7647 - accuracy50: 0.5487 - val_loss: 3.1308 - val_accuracy50: 0.4886 - 134s/epoch - 61ms/step
testing model: results/WBA/W1/deepVOL_L2/h50
Evaluating performance on  test set...
5696/5696 - 156s - 156s/epoch - 27ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0950637
{'0': {'precision': 0.4895784173222551, 'recall': 0.4135507737996185, 'f1-score': 0.44836449825679314, 'support': 546847}, '1': {'precision': 0.34637705105555483, 'recall': 0.7318039865414618, 'f1-score': 0.4701995267397232, 'support': 372403}, '2': {'precision': 0.5570976742408317, 'recall': 0.21642655361988514, 'f1-score': 0.31174389973291694, 'support': 538774}, 'accuracy': 0.4219957970513517, 'macro avg': {'precision': 0.46435104753954715, 'recall': 0.4539271046536551, 'f1-score': 0.41010264157647774, 'support': 1458024}, 'weighted avg': {'precision': 0.4779524096058054, 'recall': 0.4219957970513517, 'f1-score': 0.40345700960298886, 'support': 1458024}}
[[226149 258084  62614]
 [ 69788 272526  30089]
 [165989 256180 116605]]
Evaluating performance on  train set...
2222/2222 - 56s - 56s/epoch - 25ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.99913615
{'0': {'precision': 0.5240183866100565, 'recall': 0.40917758975932667, 'f1-score': 0.45953172935199693, 'support': 182488}, '1': {'precision': 0.4726917070855888, 'recall': 0.8317426257840262, 'f1-score': 0.602802044887605, 'support': 205988}, '2': {'precision': 0.5684780901523481, 'recall': 0.2009237106076839, 'f1-score': 0.2969078761181726, 'support': 180143}, 'accuracy': 0.4962795826379351, 'macro avg': {'precision': 0.5217293946159978, 'recall': 0.48061464205034565, 'f1-score': 0.45308055011925824, 'support': 568619}, 'weighted avg': {'precision': 0.5195099623634748, 'recall': 0.4962795826379351, 'f1-score': 0.45991233035802737, 'support': 568619}}
[[ 74670  91433  16385]
 [ 23569 171329  11090]
 [ 44256  99692  36195]]
Evaluating performance on  val set...
641/641 - 18s - 18s/epoch - 28ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0218774
{'0': {'precision': 0.4917604084512889, 'recall': 0.44714096999433856, 'f1-score': 0.46839046376467797, 'support': 52990}, '1': {'precision': 0.4797516088043612, 'recall': 0.7896574406719628, 'f1-score': 0.5968752589608419, 'support': 59289}, '2': {'precision': 0.5514189301322122, 'recall': 0.19329816940738442, 'f1-score': 0.28625170507574127, 'support': 51568}, 'accuracy': 0.4911899516011889, 'macro avg': {'precision': 0.5076436491292874, 'recall': 0.4766988600245619, 'f1-score': 0.4505058092670871, 'support': 163847}, 'weighted avg': {'precision': 0.5061914381544581, 'recall': 0.4911899516011889, 'f1-score': 0.4575584284775764, 'support': 163847}}
[[23694 24427  4869]
 [ 9231 46818  3240]
 [15257 26343  9968]]
training model: results/WBA/W1/deepVOL_L2/h100
Epoch 1/50
2222/2222 - 155s - loss: 3.2505 - accuracy100: 0.3991 - val_loss: 3.3957 - val_accuracy100: 0.3355 - 155s/epoch - 70ms/step
Epoch 2/50
2222/2222 - 135s - loss: 3.1968 - accuracy100: 0.4222 - val_loss: 3.3640 - val_accuracy100: 0.3798 - 135s/epoch - 61ms/step
Epoch 3/50
2222/2222 - 130s - loss: 3.1604 - accuracy100: 0.4398 - val_loss: 3.3385 - val_accuracy100: 0.3901 - 130s/epoch - 59ms/step
Epoch 4/50
2222/2222 - 138s - loss: 3.1435 - accuracy100: 0.4453 - val_loss: 3.3375 - val_accuracy100: 0.3975 - 138s/epoch - 62ms/step
Epoch 5/50
2222/2222 - 132s - loss: 3.1314 - accuracy100: 0.4495 - val_loss: 3.3536 - val_accuracy100: 0.4033 - 132s/epoch - 59ms/step
Epoch 6/50
2222/2222 - 138s - loss: 3.1236 - accuracy100: 0.4508 - val_loss: 3.3279 - val_accuracy100: 0.4071 - 138s/epoch - 62ms/step
Epoch 7/50
2222/2222 - 143s - loss: 3.1158 - accuracy100: 0.4531 - val_loss: 3.3670 - val_accuracy100: 0.4032 - 143s/epoch - 64ms/step
Epoch 8/50
2222/2222 - 137s - loss: 3.1101 - accuracy100: 0.4552 - val_loss: 3.3516 - val_accuracy100: 0.4081 - 137s/epoch - 62ms/step
Epoch 9/50
2222/2222 - 138s - loss: 3.1060 - accuracy100: 0.4555 - val_loss: 3.3688 - val_accuracy100: 0.4055 - 138s/epoch - 62ms/step
Epoch 10/50
2222/2222 - 140s - loss: 3.1019 - accuracy100: 0.4575 - val_loss: 3.3488 - val_accuracy100: 0.4103 - 140s/epoch - 63ms/step
Epoch 11/50
2222/2222 - 142s - loss: 3.0982 - accuracy100: 0.4592 - val_loss: 3.3733 - val_accuracy100: 0.4107 - 142s/epoch - 64ms/step
Epoch 12/50
2222/2222 - 138s - loss: 3.0948 - accuracy100: 0.4600 - val_loss: 3.3575 - val_accuracy100: 0.4102 - 138s/epoch - 62ms/step
Epoch 13/50
2222/2222 - 139s - loss: 3.0911 - accuracy100: 0.4615 - val_loss: 3.3676 - val_accuracy100: 0.4103 - 139s/epoch - 62ms/step
Epoch 14/50
2222/2222 - 133s - loss: 3.0875 - accuracy100: 0.4630 - val_loss: 3.3680 - val_accuracy100: 0.4122 - 133s/epoch - 60ms/step
Epoch 15/50
2222/2222 - 137s - loss: 3.0847 - accuracy100: 0.4637 - val_loss: 3.3890 - val_accuracy100: 0.4125 - 137s/epoch - 62ms/step
Epoch 16/50
2222/2222 - 136s - loss: 3.0817 - accuracy100: 0.4646 - val_loss: 3.3993 - val_accuracy100: 0.4122 - 136s/epoch - 61ms/step
testing model: results/WBA/W1/deepVOL_L2/h100
Evaluating performance on  test set...
5696/5696 - 163s - 163s/epoch - 29ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.1663944
{'0': {'precision': 0.4343641961316787, 'recall': 0.35954489233453985, 'f1-score': 0.39342899684864524, 'support': 548969}, '1': {'precision': 0.29103815538991407, 'recall': 0.7164475323165499, 'f1-score': 0.41392859627364953, 'support': 361270}, '2': {'precision': 0.48139624424648664, 'recall': 0.10042808766213021, 'f1-score': 0.1661866015771913, 'support': 547785}, 'accuracy': 0.35062728734232085, 'macro avg': {'precision': 0.4022661985893598, 'recall': 0.39214017077107327, 'f1-score': 0.32451473156649535, 'support': 1458024}, 'weighted avg': {'precision': 0.41652090393470037, 'recall': 0.35062728734232085, 'f1-score': 0.3131325921190235, 'support': 1458024}}
[[197379 311296  40294]
 [ 83468 258831  18971]
 [173562 319210  55013]]
Evaluating performance on  train set...
2222/2222 - 65s - 65s/epoch - 29ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.1067169
{'0': {'precision': 0.4516888469733487, 'recall': 0.3377896892566819, 'f1-score': 0.3865230737960945, 'support': 191412}, '1': {'precision': 0.3894104975371797, 'recall': 0.8297151802686858, 'f1-score': 0.5300516707089329, 'support': 187803}, '2': {'precision': 0.5070489278521502, 'recall': 0.06779159891026589, 'f1-score': 0.11959371667279847, 'support': 189404}, 'accuracy': 0.4103274776256157, 'macro avg': {'precision': 0.4493827574542262, 'recall': 0.4117654894785446, 'f1-score': 0.3453894870592753, 'support': 568619}, 'weighted avg': {'precision': 0.4495597586024143, 'recall': 0.4103274776256157, 'f1-score': 0.34501481102161985, 'support': 568619}}
[[ 64657 118291   8464]
 [ 27961 155823   4019]
 [ 50527 126037  12840]]
Evaluating performance on  val set...
641/641 - 18s - 18s/epoch - 29ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.1104777
{'0': {'precision': 0.44286333714375814, 'recall': 0.3933341502266879, 'f1-score': 0.4166319009873452, 'support': 57127}, '1': {'precision': 0.3815988921533769, 'recall': 0.7945565773067331, 'f1-score': 0.5155813453685794, 'support': 51328}, '2': {'precision': 0.5257417802726544, 'recall': 0.059178220681686884, 'f1-score': 0.10638194297953818, 'support': 55392}, 'accuracy': 0.40605564947786654, 'macro avg': {'precision': 0.45006800318992984, 'recall': 0.41568964940503594, 'f1-score': 0.34619839644515427, 'support': 163847}, 'weighted avg': {'precision': 0.451689994264911, 'recall': 0.40605564947786654, 'f1-score': 0.3427429155755375, 'support': 163847}}
[[22470 32607  2050]
 [ 9638 40783   907]
 [18630 33484  3278]]
training model: results/WBA/W1/deepVOL_L2/h200
Epoch 1/50
2222/2222 - 149s - loss: 3.2747 - accuracy200: 0.3791 - val_loss: 3.2731 - val_accuracy200: 0.3840 - 149s/epoch - 67ms/step
Epoch 2/50
2222/2222 - 141s - loss: 3.2593 - accuracy200: 0.3855 - val_loss: 3.2662 - val_accuracy200: 0.3910 - 141s/epoch - 63ms/step
Epoch 3/50
2222/2222 - 137s - loss: 3.2504 - accuracy200: 0.3930 - val_loss: 3.2792 - val_accuracy200: 0.3840 - 137s/epoch - 62ms/step
Epoch 4/50
2222/2222 - 124s - loss: 3.2427 - accuracy200: 0.3986 - val_loss: 3.2750 - val_accuracy200: 0.3900 - 124s/epoch - 56ms/step
Epoch 5/50
2222/2222 - 134s - loss: 3.2381 - accuracy200: 0.4012 - val_loss: 3.2667 - val_accuracy200: 0.3890 - 134s/epoch - 60ms/step
Epoch 6/50
2222/2222 - 141s - loss: 3.2308 - accuracy200: 0.4050 - val_loss: 3.2672 - val_accuracy200: 0.3895 - 141s/epoch - 63ms/step
Epoch 7/50
2222/2222 - 138s - loss: 3.2245 - accuracy200: 0.4080 - val_loss: 3.2785 - val_accuracy200: 0.3840 - 138s/epoch - 62ms/step
Epoch 8/50
2222/2222 - 137s - loss: 3.2201 - accuracy200: 0.4102 - val_loss: 3.2817 - val_accuracy200: 0.3790 - 137s/epoch - 62ms/step
Epoch 9/50
2222/2222 - 131s - loss: 3.2165 - accuracy200: 0.4126 - val_loss: 3.2865 - val_accuracy200: 0.3794 - 131s/epoch - 59ms/step
Epoch 10/50
2222/2222 - 134s - loss: 3.2112 - accuracy200: 0.4140 - val_loss: 3.2945 - val_accuracy200: 0.3771 - 134s/epoch - 60ms/step
Epoch 11/50
2222/2222 - 131s - loss: 3.2085 - accuracy200: 0.4156 - val_loss: 3.3029 - val_accuracy200: 0.3762 - 131s/epoch - 59ms/step
Epoch 12/50
2222/2222 - 135s - loss: 3.2051 - accuracy200: 0.4180 - val_loss: 3.3128 - val_accuracy200: 0.3757 - 135s/epoch - 61ms/step
testing model: results/WBA/W1/deepVOL_L2/h200
Evaluating performance on  test set...
5696/5696 - 165s - 165s/epoch - 29ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0942324
{'0': {'precision': 0.36922384999221997, 'recall': 0.6767238348243935, 'f1-score': 0.47777261387441233, 'support': 511940}, '1': {'precision': 0.31789062381680777, 'recall': 0.048124541452677916, 'f1-score': 0.08359402535698711, 'support': 436160}, '2': {'precision': 0.38524169214255327, 'recall': 0.3427628430903429, 'f1-score': 0.36276295348482446, 'support': 509924}, 'accuracy': 0.3718834532216205, 'macro avg': {'precision': 0.35745205531719365, 'recall': 0.35587040645580476, 'f1-score': 0.3080431975720746, 'support': 1458024}, 'weighted avg': {'precision': 0.3594698145387561, 'recall': 0.3718834532216205, 'f1-score': 0.3196331599063978, 'support': 1458024}}
[[346442  21625 143873]
 [280129  20990 135041]
 [311727  23414 174783]]
Evaluating performance on  train set...
2222/2222 - 66s - 66s/epoch - 30ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0920866
{'0': {'precision': 0.37067729621238105, 'recall': 0.681467700258398, 'f1-score': 0.4801707092371613, 'support': 193500}, '1': {'precision': 0.3652603431627423, 'recall': 0.053341215648202885, 'f1-score': 0.09308819005702658, 'support': 184379}, '2': {'precision': 0.3810868220806109, 'recall': 0.37152668554052637, 'f1-score': 0.3762460345903184, 'support': 190740}, 'accuracy': 0.3738250040888539, 'macro avg': {'precision': 0.37234148715191145, 'recall': 0.3687785338157091, 'f1-score': 0.31650164462816877, 'support': 568619}, 'weighted avg': {'precision': 0.3724126243983312, 'recall': 0.3738250040888539, 'f1-score': 0.3197953432257321, 'support': 568619}}
[[131864   7994  53642]
 [113096   9835  61448]
 [110778   9097  70865]]
Evaluating performance on  val set...
641/641 - 19s - 19s/epoch - 30ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0896598
{'0': {'precision': 0.3902946154705342, 'recall': 0.7550864361702128, 'f1-score': 0.514599346357102, 'support': 60160}, '1': {'precision': 0.32235006973500696, 'recall': 0.039927443909391264, 'f1-score': 0.07105389566721107, 'support': 46309}, '2': {'precision': 0.3984708307367816, 'recall': 0.289745198508139, 'f1-score': 0.33551967709384456, 'support': 57378}, 'accuracy': 0.3899979859258943, 'macro avg': {'precision': 0.3703718386474409, 'recall': 0.36158635952924767, 'f1-score': 0.30705763970605254, 'support': 163847}, 'weighted avg': {'precision': 0.3739543157462805, 'recall': 0.3899979859258943, 'f1-score': 0.3265252312437014, 'support': 163847}}
[[45426  1814 12920]
 [32283  1849 12177]
 [38680  2073 16625]]
training model: results/WBA/W1/deepVOL_L2/h300
Epoch 1/50
2222/2222 - 148s - loss: 3.2903 - accuracy300: 0.3642 - val_loss: 3.2972 - val_accuracy300: 0.3305 - 148s/epoch - 66ms/step
Epoch 2/50
2222/2222 - 140s - loss: 3.2786 - accuracy300: 0.3699 - val_loss: 3.2957 - val_accuracy300: 0.3338 - 140s/epoch - 63ms/step
Epoch 3/50
2222/2222 - 138s - loss: 3.2743 - accuracy300: 0.3736 - val_loss: 3.2984 - val_accuracy300: 0.3391 - 138s/epoch - 62ms/step
Epoch 4/50
2222/2222 - 140s - loss: 3.2688 - accuracy300: 0.3792 - val_loss: 3.2975 - val_accuracy300: 0.3497 - 140s/epoch - 63ms/step
Epoch 5/50
2222/2222 - 140s - loss: 3.2626 - accuracy300: 0.3836 - val_loss: 3.3084 - val_accuracy300: 0.3380 - 140s/epoch - 63ms/step
Epoch 6/50
2222/2222 - 136s - loss: 3.2562 - accuracy300: 0.3888 - val_loss: 3.3077 - val_accuracy300: 0.3509 - 136s/epoch - 61ms/step
Epoch 7/50
2222/2222 - 136s - loss: 3.2492 - accuracy300: 0.3937 - val_loss: 3.3261 - val_accuracy300: 0.3551 - 136s/epoch - 61ms/step
Epoch 8/50
2222/2222 - 144s - loss: 3.2456 - accuracy300: 0.3964 - val_loss: 3.3399 - val_accuracy300: 0.3522 - 144s/epoch - 65ms/step
Epoch 9/50
2222/2222 - 139s - loss: 3.2415 - accuracy300: 0.4000 - val_loss: 3.3541 - val_accuracy300: 0.3536 - 139s/epoch - 63ms/step
Epoch 10/50
2222/2222 - 139s - loss: 3.2372 - accuracy300: 0.4031 - val_loss: 3.3523 - val_accuracy300: 0.3524 - 139s/epoch - 63ms/step
Epoch 11/50
2222/2222 - 140s - loss: 3.2343 - accuracy300: 0.4045 - val_loss: 3.3682 - val_accuracy300: 0.3548 - 140s/epoch - 63ms/step
Epoch 12/50
2222/2222 - 140s - loss: 3.2314 - accuracy300: 0.4064 - val_loss: 3.3749 - val_accuracy300: 0.3530 - 140s/epoch - 63ms/step
testing model: results/WBA/W1/deepVOL_L2/h300
Evaluating performance on  test set...
5696/5696 - 169s - 169s/epoch - 30ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1042517
{'0': {'precision': 0.3770040225548804, 'recall': 0.16252733039756104, 'f1-score': 0.22713585410628667, 'support': 519568}, '1': {'precision': 0.2905820052141952, 'recall': 0.6515419702624252, 'f1-score': 0.4019139245538951, 'support': 422025}, '2': {'precision': 0.3590873393704782, 'recall': 0.2000964310817902, 'f1-score': 0.25698920051479407, 'support': 516431}, 'accuracy': 0.3173795493078303, 'macro avg': {'precision': 0.3422244557131846, 'recall': 0.3380552439139255, 'f1-score': 0.29534632639165864, 'support': 1458024}, 'weighted avg': {'precision': 0.3456430967526943, 'recall': 0.3173795493078303, 'f1-score': 0.288299393746062, 'support': 1458024}}
[[ 84444 334238 100886]
 [ 63506 274967  83552]
 [ 76037 337058 103336]]
Evaluating performance on  train set...
2222/2222 - 66s - 66s/epoch - 30ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0981613
{'0': {'precision': 0.38218273090873883, 'recall': 0.26387567559228425, 'f1-score': 0.31219693236230006, 'support': 194459}, '1': {'precision': 0.32644446945775746, 'recall': 0.6015961482823938, 'f1-score': 0.42323090541466896, 'support': 183191}, '2': {'precision': 0.35784121209615743, 'recall': 0.18130691368756185, 'f1-score': 0.2406725819961283, 'support': 190969}, 'accuracy': 0.34494802319303436, 'macro avg': {'precision': 0.3554894708208846, 'recall': 0.34892624585408, 'f1-score': 0.3253668065910324, 'support': 568619}, 'weighted avg': {'precision': 0.3560506048989034, 'recall': 0.34494802319303436, 'f1-score': 0.3239473151183442, 'support': 568619}}
[[ 51313 112178  30968]
 [ 41818 110207  31166]
 [ 41132 115213  34624]]
Evaluating performance on  val set...
641/641 - 20s - 20s/epoch - 31ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1003506
{'0': {'precision': 0.3892686670984145, 'recall': 0.2768084053966467, 'f1-score': 0.3235446570972887, 'support': 58629}, '1': {'precision': 0.3029553882458703, 'recall': 0.5964361851896545, 'f1-score': 0.4018128730243681, 'support': 49722}, '2': {'precision': 0.35282482383483743, 'recall': 0.15428138964970448, 'f1-score': 0.21468600729661624, 'support': 55496}, 'accuracy': 0.33230391767929834, 'macro avg': {'precision': 0.3483496263930408, 'recall': 0.3425086600786685, 'f1-score': 0.31334784580609104, 'support': 163847}, 'weighted avg': {'precision': 0.35073176146778545, 'recall': 0.33230391767929834, 'f1-score': 0.3104252994220681, 'support': 163847}}
[[16229 34093  8307]
 [12668 29656  7398]
 [12794 34140  8562]]
training model: results/WBA/W1/deepVOL_L2/h500
Epoch 1/50
2222/2222 - 147s - loss: 3.2385 - accuracy500: 0.4068 - val_loss: 3.2401 - val_accuracy500: 0.3824 - 147s/epoch - 66ms/step
Epoch 2/50
2222/2222 - 137s - loss: 3.2421 - accuracy500: 0.4059 - val_loss: 3.2397 - val_accuracy500: 0.3806 - 137s/epoch - 62ms/step
Epoch 3/50
2222/2222 - 145s - loss: 3.2453 - accuracy500: 0.4031 - val_loss: 3.2391 - val_accuracy500: 0.3784 - 145s/epoch - 65ms/step
Epoch 4/50
2222/2222 - 135s - loss: 3.2447 - accuracy500: 0.4041 - val_loss: 3.2410 - val_accuracy500: 0.3803 - 135s/epoch - 61ms/step
Epoch 5/50
2222/2222 - 140s - loss: 3.2315 - accuracy500: 0.4094 - val_loss: 3.2465 - val_accuracy500: 0.3830 - 140s/epoch - 63ms/step
Epoch 6/50
2222/2222 - 141s - loss: 3.2262 - accuracy500: 0.4076 - val_loss: 3.2407 - val_accuracy500: 0.3825 - 141s/epoch - 63ms/step
Epoch 7/50
2222/2222 - 134s - loss: 3.2286 - accuracy500: 0.4072 - val_loss: 3.2406 - val_accuracy500: 0.3861 - 134s/epoch - 60ms/step
Epoch 8/50
2222/2222 - 140s - loss: 3.2277 - accuracy500: 0.4084 - val_loss: 3.2406 - val_accuracy500: 0.3868 - 140s/epoch - 63ms/step
Epoch 9/50
2222/2222 - 139s - loss: 3.2249 - accuracy500: 0.4075 - val_loss: 3.2397 - val_accuracy500: 0.3873 - 139s/epoch - 62ms/step
Epoch 10/50
2222/2222 - 140s - loss: 3.2209 - accuracy500: 0.4091 - val_loss: 3.2399 - val_accuracy500: 0.3923 - 140s/epoch - 63ms/step
Epoch 11/50
2222/2222 - 136s - loss: 3.2170 - accuracy500: 0.4138 - val_loss: 3.2389 - val_accuracy500: 0.3925 - 136s/epoch - 61ms/step
Epoch 12/50
2222/2222 - 138s - loss: 3.2125 - accuracy500: 0.4166 - val_loss: 3.2374 - val_accuracy500: 0.3926 - 138s/epoch - 62ms/step
Epoch 13/50
2222/2222 - 144s - loss: 3.2111 - accuracy500: 0.4166 - val_loss: 3.2364 - val_accuracy500: 0.3938 - 144s/epoch - 65ms/step
Epoch 14/50
2222/2222 - 143s - loss: 3.2112 - accuracy500: 0.4147 - val_loss: 3.2364 - val_accuracy500: 0.3971 - 143s/epoch - 64ms/step
Epoch 15/50
2222/2222 - 140s - loss: 3.2035 - accuracy500: 0.4181 - val_loss: 3.2401 - val_accuracy500: 0.3922 - 140s/epoch - 63ms/step
Epoch 16/50
2222/2222 - 137s - loss: 3.1987 - accuracy500: 0.4212 - val_loss: 3.2446 - val_accuracy500: 0.3912 - 137s/epoch - 62ms/step
Epoch 17/50
2222/2222 - 133s - loss: 3.1934 - accuracy500: 0.4235 - val_loss: 3.2458 - val_accuracy500: 0.3908 - 133s/epoch - 60ms/step
Epoch 18/50
2222/2222 - 141s - loss: 3.1890 - accuracy500: 0.4269 - val_loss: 3.2488 - val_accuracy500: 0.3885 - 141s/epoch - 64ms/step
Epoch 19/50
2222/2222 - 139s - loss: 3.1843 - accuracy500: 0.4301 - val_loss: 3.2530 - val_accuracy500: 0.3889 - 139s/epoch - 63ms/step
Epoch 20/50
2222/2222 - 141s - loss: 3.1804 - accuracy500: 0.4314 - val_loss: 3.2660 - val_accuracy500: 0.3872 - 141s/epoch - 63ms/step
Epoch 21/50
2222/2222 - 142s - loss: 3.1791 - accuracy500: 0.4306 - val_loss: 3.2695 - val_accuracy500: 0.3851 - 142s/epoch - 64ms/step
Epoch 22/50
2222/2222 - 141s - loss: 3.1747 - accuracy500: 0.4342 - val_loss: 3.2772 - val_accuracy500: 0.3838 - 141s/epoch - 63ms/step
Epoch 23/50
2222/2222 - 142s - loss: 3.1714 - accuracy500: 0.4356 - val_loss: 3.2890 - val_accuracy500: 0.3851 - 142s/epoch - 64ms/step
Epoch 24/50
2222/2222 - 141s - loss: 3.1671 - accuracy500: 0.4377 - val_loss: 3.3005 - val_accuracy500: 0.3859 - 141s/epoch - 63ms/step
testing model: results/WBA/W1/deepVOL_L2/h500
Evaluating performance on  test set...
5696/5696 - 155s - 155s/epoch - 27ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0795124
{'0': {'precision': 0.3923703914441832, 'recall': 0.5504407198274704, 'f1-score': 0.4581546359041431, 'support': 558745}, '1': {'precision': 0.23794747597063498, 'recall': 0.009218022054059126, 'f1-score': 0.017748472976482146, 'support': 341071}, '2': {'precision': 0.39115693601827617, 'recall': 0.46316605996331117, 'f1-score': 0.42412674769393804, 'support': 558208}, 'accuracy': 0.3904208709870345, 'macro avg': {'precision': 0.3404916011443648, 'recall': 0.3409416006149469, 'f1-score': 0.3000099521915211, 'support': 1458024}, 'weighted avg': {'precision': 0.3557821468543388, 'recall': 0.3904208709870345, 'f1-score': 0.3421041389178504, 'support': 1458024}}
[[307556   4978 246211]
 [181711   3144 156216]
 [294574   5091 258543]]
Evaluating performance on  train set...
2222/2222 - 63s - 63s/epoch - 28ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1183423
{'0': {'precision': 0.3564525139664804, 'recall': 0.5986614054200571, 'f1-score': 0.4468458864336252, 'support': 191843}, '1': {'precision': 0.35263407688656856, 'recall': 0.003889197139895939, 'f1-score': 0.0076935422911845255, 'support': 191042}, '2': {'precision': 0.34523887488129934, 'recall': 0.454122562374148, 'f1-score': 0.3922650135101826, 'support': 185734}, 'accuracy': 0.3516203292538589, 'macro avg': {'precision': 0.35144182191144946, 'recall': 0.352224388311367, 'f1-score': 0.2822681474116641, 'support': 568619}, 'weighted avg': {'precision': 0.35150678422746795, 'recall': 0.3516203292538589, 'f1-score': 0.28147317468600014, 'support': 568619}}
[[114849    669  76325]
 [106658    743  83641]
 [100693    695  84346]]
Evaluating performance on  val set...
641/641 - 20s - 20s/epoch - 31ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0785216
{'0': {'precision': 0.4036593296155438, 'recall': 0.6380271600323927, 'f1-score': 0.49447817218447127, 'support': 64212}, '1': {'precision': 0.30623818525519847, 'recall': 0.004070044971484561, 'f1-score': 0.008033323415650105, 'support': 39803}, '2': {'precision': 0.3833786231884058, 'recall': 0.3961425324241209, 'f1-score': 0.38965607943710134, 'support': 59832}, 'accuracy': 0.39569232271570426, 'macro avg': {'precision': 0.36442537935304936, 'recall': 0.3460799124759994, 'f1-score': 0.29738919167907424, 'support': 163847}, 'weighted avg': {'precision': 0.3725871156847221, 'recall': 0.39569232271570426, 'f1-score': 0.3380292914066357, 'support': 163847}}
[[40969   199 23044]
 [24563   162 15078]
 [35962   168 23702]]
training model: results/WBA/W1/deepVOL_L2/h1000
Epoch 1/50
2222/2222 - 151s - loss: 3.2819 - accuracy1000: 0.3822 - val_loss: 3.3006 - val_accuracy1000: 0.3501 - 151s/epoch - 68ms/step
Epoch 2/50
2222/2222 - 130s - loss: 3.2717 - accuracy1000: 0.3813 - val_loss: 3.3017 - val_accuracy1000: 0.3536 - 130s/epoch - 58ms/step
Epoch 3/50
2222/2222 - 146s - loss: 3.2612 - accuracy1000: 0.3873 - val_loss: 3.3010 - val_accuracy1000: 0.3475 - 146s/epoch - 66ms/step
Epoch 4/50
2222/2222 - 143s - loss: 3.2545 - accuracy1000: 0.3932 - val_loss: 3.3011 - val_accuracy1000: 0.3531 - 143s/epoch - 64ms/step
Epoch 5/50
2222/2222 - 142s - loss: 3.2475 - accuracy1000: 0.4000 - val_loss: 3.3039 - val_accuracy1000: 0.3457 - 142s/epoch - 64ms/step
Epoch 6/50
2222/2222 - 147s - loss: 3.2452 - accuracy1000: 0.4009 - val_loss: 3.3078 - val_accuracy1000: 0.3454 - 147s/epoch - 66ms/step
Epoch 7/50
2222/2222 - 145s - loss: 3.2411 - accuracy1000: 0.4045 - val_loss: 3.3222 - val_accuracy1000: 0.3472 - 145s/epoch - 65ms/step
Epoch 8/50
2222/2222 - 137s - loss: 3.2370 - accuracy1000: 0.4067 - val_loss: 3.3424 - val_accuracy1000: 0.3474 - 137s/epoch - 62ms/step
Epoch 9/50
2222/2222 - 139s - loss: 3.2332 - accuracy1000: 0.4093 - val_loss: 3.3448 - val_accuracy1000: 0.3480 - 139s/epoch - 62ms/step
Epoch 10/50
2222/2222 - 139s - loss: 3.2298 - accuracy1000: 0.4102 - val_loss: 3.3408 - val_accuracy1000: 0.3500 - 139s/epoch - 63ms/step
Epoch 11/50
2222/2222 - 141s - loss: 3.2263 - accuracy1000: 0.4132 - val_loss: 3.3500 - val_accuracy1000: 0.3476 - 141s/epoch - 64ms/step
testing model: results/WBA/W1/deepVOL_L2/h1000
Evaluating performance on  test set...
5696/5696 - 168s - 168s/epoch - 30ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.098681
{'0': {'precision': 0.34957851702958853, 'recall': 0.7916538136028918, 'f1-score': 0.4849935613140976, 'support': 505716}, '1': {'precision': 0.3095333785469678, 'recall': 0.16725671123859592, 'f1-score': 0.21716699244995397, 'support': 442057}, '2': {'precision': 0.3499107094539748, 'recall': 0.05068877865991443, 'f1-score': 0.0885500207988469, 'support': 510251}, 'accuracy': 0.343034819728619, 'macro avg': {'precision': 0.33634086834351035, 'recall': 0.33653310116713403, 'f1-score': 0.26357019152096617, 'support': 1458024}, 'weighted avg': {'precision': 0.33755352137418343, 'recall': 0.343034819728619, 'f1-score': 0.26505183021514184, 'support': 1458024}}
[[400352  80235  25129]
 [345197  73937  22923]
 [399693  84694  25864]]
Evaluating performance on  train set...
2222/2222 - 66s - 66s/epoch - 30ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0984051
{'0': {'precision': 0.3367098937359187, 'recall': 0.7997008495241507, 'f1-score': 0.4738906062984631, 'support': 189871}, '1': {'precision': 0.35703301377482577, 'recall': 0.16615403355970398, 'f1-score': 0.22677348628905722, 'support': 197022}, '2': {'precision': 0.3183462930171684, 'recall': 0.04550807259280455, 'f1-score': 0.07963255401918114, 'support': 181726}, 'accuracy': 0.3391480059582955, 'macro avg': {'precision': 0.33736306684263756, 'recall': 0.33712098522555306, 'f1-score': 0.2600988822022338, 'support': 568619}, 'weighted avg': {'precision': 0.33788283739782576, 'recall': 0.3391480059582955, 'f1-score': 0.26226481112278666, 'support': 568619}}
[[151840  29816   8215]
 [154793  32736   9493]
 [144319  29137   8270]]
Evaluating performance on  val set...
641/641 - 19s - 19s/epoch - 29ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.098268
{'0': {'precision': 0.35822243815047333, 'recall': 0.808626214507257, 'f1-score': 0.4964963595808257, 'support': 58357}, '1': {'precision': 0.33430424482504173, 'recall': 0.16581588426790977, 'f1-score': 0.22167855579305193, 'support': 51913}, '2': {'precision': 0.3211873723888802, 'recall': 0.03816936371950651, 'f1-score': 0.06823034832510344, 'support': 53577}, 'accuracy': 0.3530244679487571, 'macro avg': {'precision': 0.33790468512146504, 'recall': 0.33753715416489105, 'f1-score': 0.2621350878996604, 'support': 163847}, 'weighted avg': {'precision': 0.33853399168265885, 'recall': 0.3530244679487571, 'f1-score': 0.2693831092126009, 'support': 163847}}
[[47189  8970  2198]
 [41181  8608  2124]
 [43361  8171  2045]]
training model: results/WBA/W1/deepVOL_L3/h10
Epoch 1/50
2222/2222 - 207s - loss: 3.1070 - accuracy10: 0.4461 - val_loss: 3.0593 - val_accuracy10: 0.5758 - 207s/epoch - 93ms/step
Epoch 2/50
2222/2222 - 202s - loss: 2.7504 - accuracy10: 0.5377 - val_loss: 2.9658 - val_accuracy10: 0.6104 - 202s/epoch - 91ms/step
Epoch 3/50
2222/2222 - 176s - loss: 2.6610 - accuracy10: 0.5647 - val_loss: 3.0053 - val_accuracy10: 0.6343 - 176s/epoch - 79ms/step
Epoch 4/50
2222/2222 - 183s - loss: 2.6166 - accuracy10: 0.5744 - val_loss: 2.9197 - val_accuracy10: 0.6299 - 183s/epoch - 82ms/step
Epoch 5/50
2222/2222 - 201s - loss: 2.5891 - accuracy10: 0.5818 - val_loss: 2.8885 - val_accuracy10: 0.6368 - 201s/epoch - 91ms/step
Epoch 6/50
2222/2222 - 191s - loss: 2.5699 - accuracy10: 0.5863 - val_loss: 2.8751 - val_accuracy10: 0.6406 - 191s/epoch - 86ms/step
Epoch 7/50
2222/2222 - 197s - loss: 2.5554 - accuracy10: 0.5896 - val_loss: 2.8784 - val_accuracy10: 0.6420 - 197s/epoch - 89ms/step
Epoch 8/50
2222/2222 - 197s - loss: 2.5420 - accuracy10: 0.5921 - val_loss: 2.8734 - val_accuracy10: 0.6411 - 197s/epoch - 89ms/step
Epoch 9/50
2222/2222 - 193s - loss: 2.5286 - accuracy10: 0.5937 - val_loss: 2.7849 - val_accuracy10: 0.6433 - 193s/epoch - 87ms/step
Epoch 10/50
2222/2222 - 194s - loss: 2.5165 - accuracy10: 0.5964 - val_loss: 2.7826 - val_accuracy10: 0.6384 - 194s/epoch - 88ms/step
Epoch 11/50
2222/2222 - 190s - loss: 2.5077 - accuracy10: 0.5974 - val_loss: 2.7815 - val_accuracy10: 0.6411 - 190s/epoch - 86ms/step
Epoch 12/50
2222/2222 - 193s - loss: 2.4982 - accuracy10: 0.5992 - val_loss: 2.8042 - val_accuracy10: 0.6421 - 193s/epoch - 87ms/step
Epoch 13/50
2222/2222 - 181s - loss: 2.4899 - accuracy10: 0.6001 - val_loss: 2.8156 - val_accuracy10: 0.6347 - 181s/epoch - 82ms/step
Epoch 14/50
2222/2222 - 188s - loss: 2.4815 - accuracy10: 0.6018 - val_loss: 2.8080 - val_accuracy10: 0.6419 - 188s/epoch - 85ms/step
Epoch 15/50
2222/2222 - 201s - loss: 2.4750 - accuracy10: 0.6021 - val_loss: 2.8039 - val_accuracy10: 0.6376 - 201s/epoch - 91ms/step
Epoch 16/50
2222/2222 - 183s - loss: 2.4687 - accuracy10: 0.6033 - val_loss: 2.8064 - val_accuracy10: 0.6360 - 183s/epoch - 82ms/step
Epoch 17/50
2222/2222 - 188s - loss: 2.4613 - accuracy10: 0.6049 - val_loss: 2.7801 - val_accuracy10: 0.6317 - 188s/epoch - 85ms/step
Epoch 18/50
2222/2222 - 175s - loss: 2.4575 - accuracy10: 0.6053 - val_loss: 2.7695 - val_accuracy10: 0.6372 - 175s/epoch - 79ms/step
Epoch 19/50
2222/2222 - 187s - loss: 2.4531 - accuracy10: 0.6057 - val_loss: 2.7825 - val_accuracy10: 0.6373 - 187s/epoch - 84ms/step
Epoch 20/50
2222/2222 - 181s - loss: 2.4471 - accuracy10: 0.6070 - val_loss: 2.7492 - val_accuracy10: 0.6384 - 181s/epoch - 81ms/step
Epoch 21/50
2222/2222 - 195s - loss: 2.4430 - accuracy10: 0.6079 - val_loss: 2.7865 - val_accuracy10: 0.6318 - 195s/epoch - 88ms/step
Epoch 22/50
2222/2222 - 182s - loss: 2.4381 - accuracy10: 0.6091 - val_loss: 2.7663 - val_accuracy10: 0.6427 - 182s/epoch - 82ms/step
Epoch 23/50
2222/2222 - 181s - loss: 2.4337 - accuracy10: 0.6091 - val_loss: 2.7538 - val_accuracy10: 0.6360 - 181s/epoch - 81ms/step
Epoch 24/50
2222/2222 - 182s - loss: 2.4305 - accuracy10: 0.6099 - val_loss: 2.7593 - val_accuracy10: 0.6377 - 182s/epoch - 82ms/step
Epoch 25/50
2222/2222 - 156s - loss: 2.4260 - accuracy10: 0.6104 - val_loss: 2.7388 - val_accuracy10: 0.6406 - 156s/epoch - 70ms/step
Epoch 26/50
2222/2222 - 190s - loss: 2.4228 - accuracy10: 0.6110 - val_loss: 2.7693 - val_accuracy10: 0.6401 - 190s/epoch - 85ms/step
Epoch 27/50
2222/2222 - 176s - loss: 2.4191 - accuracy10: 0.6117 - val_loss: 2.7417 - val_accuracy10: 0.6359 - 176s/epoch - 79ms/step
Epoch 28/50
2222/2222 - 189s - loss: 2.4150 - accuracy10: 0.6119 - val_loss: 2.7348 - val_accuracy10: 0.6408 - 189s/epoch - 85ms/step
Epoch 29/50
2222/2222 - 185s - loss: 2.4109 - accuracy10: 0.6126 - val_loss: 2.7396 - val_accuracy10: 0.6437 - 185s/epoch - 83ms/step
Epoch 30/50
2222/2222 - 195s - loss: 2.4093 - accuracy10: 0.6124 - val_loss: 2.7231 - val_accuracy10: 0.6427 - 195s/epoch - 88ms/step
Epoch 31/50
2222/2222 - 183s - loss: 2.4047 - accuracy10: 0.6133 - val_loss: 2.7397 - val_accuracy10: 0.6429 - 183s/epoch - 82ms/step
Epoch 32/50
2222/2222 - 199s - loss: 2.4014 - accuracy10: 0.6138 - val_loss: 2.7236 - val_accuracy10: 0.6391 - 199s/epoch - 90ms/step
Epoch 33/50
2222/2222 - 173s - loss: 2.3984 - accuracy10: 0.6141 - val_loss: 2.7196 - val_accuracy10: 0.6433 - 173s/epoch - 78ms/step
Epoch 34/50
2222/2222 - 193s - loss: 2.3962 - accuracy10: 0.6145 - val_loss: 2.7461 - val_accuracy10: 0.6415 - 193s/epoch - 87ms/step
Epoch 35/50
2222/2222 - 185s - loss: 2.3927 - accuracy10: 0.6153 - val_loss: 2.7250 - val_accuracy10: 0.6384 - 185s/epoch - 83ms/step
Epoch 36/50
2222/2222 - 195s - loss: 2.3899 - accuracy10: 0.6153 - val_loss: 2.7169 - val_accuracy10: 0.6454 - 195s/epoch - 88ms/step
Epoch 37/50
2222/2222 - 200s - loss: 2.3873 - accuracy10: 0.6152 - val_loss: 2.7141 - val_accuracy10: 0.6392 - 200s/epoch - 90ms/step
Epoch 38/50
2222/2222 - 200s - loss: 2.3844 - accuracy10: 0.6162 - val_loss: 2.7210 - val_accuracy10: 0.6413 - 200s/epoch - 90ms/step
Epoch 39/50
2222/2222 - 178s - loss: 2.3811 - accuracy10: 0.6162 - val_loss: 2.7195 - val_accuracy10: 0.6441 - 178s/epoch - 80ms/step
Epoch 40/50
2222/2222 - 188s - loss: 2.3787 - accuracy10: 0.6165 - val_loss: 2.7143 - val_accuracy10: 0.6360 - 188s/epoch - 85ms/step
Epoch 41/50
2222/2222 - 195s - loss: 2.3768 - accuracy10: 0.6171 - val_loss: 2.7371 - val_accuracy10: 0.6393 - 195s/epoch - 88ms/step
Epoch 42/50
2222/2222 - 190s - loss: 2.3745 - accuracy10: 0.6174 - val_loss: 2.7126 - val_accuracy10: 0.6358 - 190s/epoch - 86ms/step
Epoch 43/50
2222/2222 - 193s - loss: 2.3721 - accuracy10: 0.6175 - val_loss: 2.7062 - val_accuracy10: 0.6346 - 193s/epoch - 87ms/step
Epoch 44/50
2222/2222 - 204s - loss: 2.3679 - accuracy10: 0.6178 - val_loss: 2.7219 - val_accuracy10: 0.6408 - 204s/epoch - 92ms/step
Epoch 45/50
2222/2222 - 191s - loss: 2.3657 - accuracy10: 0.6183 - val_loss: 2.7405 - val_accuracy10: 0.6371 - 191s/epoch - 86ms/step
Epoch 46/50
2222/2222 - 194s - loss: 2.3626 - accuracy10: 0.6184 - val_loss: 2.7326 - val_accuracy10: 0.6375 - 194s/epoch - 87ms/step
Epoch 47/50
2222/2222 - 183s - loss: 2.3606 - accuracy10: 0.6189 - val_loss: 2.7087 - val_accuracy10: 0.6331 - 183s/epoch - 82ms/step
Epoch 48/50
2222/2222 - 189s - loss: 2.3577 - accuracy10: 0.6190 - val_loss: 2.7091 - val_accuracy10: 0.6316 - 189s/epoch - 85ms/step
Epoch 49/50
2222/2222 - 191s - loss: 2.3548 - accuracy10: 0.6193 - val_loss: 2.7171 - val_accuracy10: 0.6326 - 191s/epoch - 86ms/step
Epoch 50/50
2222/2222 - 200s - loss: 2.3540 - accuracy10: 0.6200 - val_loss: 2.6836 - val_accuracy10: 0.6284 - 200s/epoch - 90ms/step
testing model: results/WBA/W1/deepVOL_L3/h10
Evaluating performance on  test set...
5696/5696 - 238s - 238s/epoch - 42ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.90867656
{'0': {'precision': 0.3967796280697207, 'recall': 0.5778607427329482, 'f1-score': 0.4704984062764495, 'support': 339099}, '1': {'precision': 0.7198600714710122, 'recall': 0.6421667833267395, 'f1-score': 0.6787975213756552, 'support': 788616}, '2': {'precision': 0.48043856889659564, 'recall': 0.37914195495732783, 'f1-score': 0.4238216506620415, 'support': 330309}, 'accuracy': 0.5676237153846576, 'macro avg': {'precision': 0.5323594228124429, 'recall': 0.5330564936723385, 'f1-score': 0.5243725261047154, 'support': 1458024}, 'weighted avg': {'precision': 0.5904799430432308, 'recall': 0.5676237153846576, 'f1-score': 0.5725888125268512, 'support': 1458024}}
[[195952 102933  40214]
 [186975 506423  95218]
 [110929  94146 125234]]
Evaluating performance on  train set...
2222/2222 - 91s - 91s/epoch - 41ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.7621841
{'0': {'precision': 0.43042890119726224, 'recall': 0.5996455962046916, 'f1-score': 0.5011381132785107, 'support': 106658}, '1': {'precision': 0.8002685683355566, 'recall': 0.7576369384480542, 'f1-score': 0.7783694523318402, 'support': 357113}, '2': {'precision': 0.49411161689508304, 'recall': 0.3861590111399359, 'f1-score': 0.433515892263463, 'support': 104848}, 'accuracy': 0.6595048705723868, 'macro avg': {'precision': 0.5749363621426339, 'recall': 0.5811471819308939, 'f1-score': 0.5710078192912712, 'support': 568619}, 'weighted avg': {'precision': 0.6744438891351305, 'recall': 0.6595048705723868, 'f1-score': 0.6627803738332335, 'support': 568619}}
[[ 63957  32358  10343]
 [ 55441 270562  31110]
 [ 29191  35169  40488]]
Evaluating performance on  val set...
641/641 - 24s - 24s/epoch - 38ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.81160665
{'0': {'precision': 0.38380259804835604, 'recall': 0.6081746552856205, 'f1-score': 0.470613639539167, 'support': 30460}, '1': {'precision': 0.8038886953492423, 'recall': 0.7098281231976007, 'f1-score': 0.7539360029405159, 'support': 104028}, '2': {'precision': 0.44992412746585736, 'recall': 0.3635682414251167, 'f1-score': 0.402162650942863, 'support': 29359}, 'accuracy': 0.6288854846289527, 'macro avg': {'precision': 0.5458718069544852, 'recall': 0.5605236733027793, 'f1-score': 0.5422374311408487, 'support': 163847}, 'weighted avg': {'precision': 0.6623672254884985, 'recall': 0.6288854846289527, 'f1-score': 0.638232248642273, 'support': 163847}}
[[18525  8695  3240]
 [20376 73842  9810]
 [ 9366  9319 10674]]
training model: results/WBA/W1/deepVOL_L3/h20
Epoch 1/50
2222/2222 - 193s - loss: 3.1973 - accuracy20: 0.4421 - val_loss: 3.2390 - val_accuracy20: 0.5125 - 193s/epoch - 87ms/step
Epoch 2/50
2222/2222 - 196s - loss: 2.9783 - accuracy20: 0.4998 - val_loss: 3.0485 - val_accuracy20: 0.5742 - 196s/epoch - 88ms/step
Epoch 3/50
2222/2222 - 196s - loss: 2.7898 - accuracy20: 0.5543 - val_loss: 3.0755 - val_accuracy20: 0.5766 - 196s/epoch - 88ms/step
Epoch 4/50
2222/2222 - 194s - loss: 2.7353 - accuracy20: 0.5645 - val_loss: 3.0933 - val_accuracy20: 0.5769 - 194s/epoch - 87ms/step
Epoch 5/50
2222/2222 - 200s - loss: 2.7079 - accuracy20: 0.5691 - val_loss: 3.0495 - val_accuracy20: 0.5785 - 200s/epoch - 90ms/step
Epoch 6/50
2222/2222 - 193s - loss: 2.6856 - accuracy20: 0.5725 - val_loss: 3.0424 - val_accuracy20: 0.5782 - 193s/epoch - 87ms/step
Epoch 7/50
2222/2222 - 204s - loss: 2.6696 - accuracy20: 0.5755 - val_loss: 3.0145 - val_accuracy20: 0.5776 - 204s/epoch - 92ms/step
Epoch 8/50
2222/2222 - 194s - loss: 2.6534 - accuracy20: 0.5782 - val_loss: 2.9857 - val_accuracy20: 0.5806 - 194s/epoch - 87ms/step
Epoch 9/50
2222/2222 - 194s - loss: 2.6403 - accuracy20: 0.5818 - val_loss: 2.9676 - val_accuracy20: 0.5817 - 194s/epoch - 87ms/step
Epoch 10/50
2222/2222 - 195s - loss: 2.6300 - accuracy20: 0.5838 - val_loss: 2.9382 - val_accuracy20: 0.5877 - 195s/epoch - 88ms/step
Epoch 11/50
2222/2222 - 197s - loss: 2.6191 - accuracy20: 0.5857 - val_loss: 2.9244 - val_accuracy20: 0.5872 - 197s/epoch - 88ms/step
Epoch 12/50
2222/2222 - 194s - loss: 2.6142 - accuracy20: 0.5859 - val_loss: 2.9173 - val_accuracy20: 0.5886 - 194s/epoch - 87ms/step
Epoch 13/50
2222/2222 - 197s - loss: 2.6071 - accuracy20: 0.5880 - val_loss: 2.9444 - val_accuracy20: 0.5892 - 197s/epoch - 89ms/step
Epoch 14/50
2222/2222 - 196s - loss: 2.5999 - accuracy20: 0.5893 - val_loss: 2.8894 - val_accuracy20: 0.5949 - 196s/epoch - 88ms/step
Epoch 15/50
2222/2222 - 199s - loss: 2.5947 - accuracy20: 0.5904 - val_loss: 2.9037 - val_accuracy20: 0.5946 - 199s/epoch - 90ms/step
Epoch 16/50
2222/2222 - 198s - loss: 2.5890 - accuracy20: 0.5912 - val_loss: 2.8606 - val_accuracy20: 0.5976 - 198s/epoch - 89ms/step
Epoch 17/50
2222/2222 - 202s - loss: 2.5835 - accuracy20: 0.5926 - val_loss: 2.8853 - val_accuracy20: 0.5973 - 202s/epoch - 91ms/step
Epoch 18/50
2222/2222 - 185s - loss: 2.5780 - accuracy20: 0.5940 - val_loss: 2.8988 - val_accuracy20: 0.5969 - 185s/epoch - 83ms/step
Epoch 19/50
2222/2222 - 194s - loss: 2.5744 - accuracy20: 0.5943 - val_loss: 2.8823 - val_accuracy20: 0.5998 - 194s/epoch - 87ms/step
Epoch 20/50
2222/2222 - 199s - loss: 2.5700 - accuracy20: 0.5959 - val_loss: 2.8347 - val_accuracy20: 0.5998 - 199s/epoch - 90ms/step
Epoch 21/50
2222/2222 - 194s - loss: 2.5680 - accuracy20: 0.5962 - val_loss: 2.8537 - val_accuracy20: 0.6001 - 194s/epoch - 87ms/step
Epoch 22/50
2222/2222 - 186s - loss: 2.5646 - accuracy20: 0.5967 - val_loss: 2.8755 - val_accuracy20: 0.5985 - 186s/epoch - 84ms/step
Epoch 23/50
2222/2222 - 195s - loss: 2.5601 - accuracy20: 0.5974 - val_loss: 2.8549 - val_accuracy20: 0.6007 - 195s/epoch - 88ms/step
Epoch 24/50
2222/2222 - 194s - loss: 2.5574 - accuracy20: 0.5979 - val_loss: 2.8410 - val_accuracy20: 0.5995 - 194s/epoch - 87ms/step
Epoch 25/50
2222/2222 - 193s - loss: 2.5524 - accuracy20: 0.5988 - val_loss: 2.8533 - val_accuracy20: 0.5997 - 193s/epoch - 87ms/step
Epoch 26/50
2222/2222 - 190s - loss: 2.5497 - accuracy20: 0.5990 - val_loss: 2.8449 - val_accuracy20: 0.6014 - 190s/epoch - 85ms/step
Epoch 27/50
2222/2222 - 198s - loss: 2.5462 - accuracy20: 0.6001 - val_loss: 2.8374 - val_accuracy20: 0.5995 - 198s/epoch - 89ms/step
Epoch 28/50
2222/2222 - 201s - loss: 2.5430 - accuracy20: 0.5999 - val_loss: 2.8427 - val_accuracy20: 0.6004 - 201s/epoch - 91ms/step
Epoch 29/50
2222/2222 - 206s - loss: 2.5398 - accuracy20: 0.6011 - val_loss: 2.8459 - val_accuracy20: 0.6025 - 206s/epoch - 93ms/step
Epoch 30/50
2222/2222 - 191s - loss: 2.5362 - accuracy20: 0.6013 - val_loss: 2.8506 - val_accuracy20: 0.5991 - 191s/epoch - 86ms/step
testing model: results/WBA/W1/deepVOL_L3/h20
Evaluating performance on  test set...
5696/5696 - 223s - 223s/epoch - 39ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.9813837
{'0': {'precision': 0.46025935008281893, 'recall': 0.4285469483785511, 'f1-score': 0.4438374036775798, 'support': 431836}, '1': {'precision': 0.5586776360328074, 'recall': 0.7304573296633329, 'f1-score': 0.6331224968966331, 'support': 607811}, '2': {'precision': 0.5252905329883174, 'recall': 0.3280032124136843, 'f1-score': 0.40383978717549923, 'support': 418377}, 'accuracy': 0.5255544490351325, 'macro avg': {'precision': 0.5147425063679812, 'recall': 0.49566916348518947, 'f1-score': 0.4935998959165708, 'support': 1458024}, 'weighted avg': {'precision': 0.5199478517892395, 'recall': 0.5255544490351325, 'f1-score': 0.5112680351317088, 'support': 1458024}}
[[185062 187479  59295]
 [ 99111 443980  64720]
 [117909 163239 137229]]
Evaluating performance on  train set...
2222/2222 - 95s - 95s/epoch - 43ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.84700185
{'0': {'precision': 0.5070390381249524, 'recall': 0.43811826935721904, 'f1-score': 0.470065806234151, 'support': 136874}, '1': {'precision': 0.669130252271527, 'recall': 0.8320020743394778, 'f1-score': 0.7417304231267459, 'support': 296962}, '2': {'precision': 0.5342210714505887, 'recall': 0.32146487316649724, 'f1-score': 0.40139331505224934, 'support': 134783}, 'accuracy': 0.6161735714072164, 'macro avg': {'precision': 0.5701301206156894, 'recall': 0.5305284056210647, 'f1-score': 0.5377298481377154, 'support': 568619}, 'weighted avg': {'precision': 0.5981344941915354, 'recall': 0.6161735714072164, 'f1-score': 0.5956651681666374, 'support': 568619}}
[[ 59967  61439  15468]
 [ 27580 247073  22309]
 [ 30722  60733  43328]]
Evaluating performance on  val set...
641/641 - 31s - 31s/epoch - 48ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.8828933
{'0': {'precision': 0.4680783984026063, 'recall': 0.45224013199644625, 'f1-score': 0.46002298049240226, 'support': 39395}, '1': {'precision': 0.6729855948184789, 'recall': 0.7887659692649509, 'f1-score': 0.7262904970191636, 'support': 86416}, '2': {'precision': 0.4991021141131336, 'recall': 0.3215111999158692, 'f1-score': 0.391090217147974, 'support': 38036}, 'accuracy': 0.599382350607579, 'macro avg': {'precision': 0.5467220357780729, 'recall': 0.5208391003924221, 'f1-score': 0.5258012315531799, 'support': 163847}, 'weighted avg': {'precision': 0.5833522718103565, 'recall': 0.599382350607579, 'f1-score': 0.5844552076409489, 'support': 163847}}
[[17816 16841  4738]
 [10719 68162  7535]
 [ 9527 16280 12229]]
training model: results/WBA/W1/deepVOL_L3/h30
Epoch 1/50
2222/2222 - 194s - loss: 3.1580 - accuracy30: 0.4494 - val_loss: 3.2556 - val_accuracy30: 0.5041 - 194s/epoch - 87ms/step
Epoch 2/50
2222/2222 - 184s - loss: 2.9776 - accuracy30: 0.5004 - val_loss: 3.1554 - val_accuracy30: 0.5239 - 184s/epoch - 83ms/step
Epoch 3/50
2222/2222 - 189s - loss: 2.8535 - accuracy30: 0.5371 - val_loss: 3.1554 - val_accuracy30: 0.5349 - 189s/epoch - 85ms/step
Epoch 4/50
2222/2222 - 187s - loss: 2.8076 - accuracy30: 0.5481 - val_loss: 3.1318 - val_accuracy30: 0.5438 - 187s/epoch - 84ms/step
Epoch 5/50
2222/2222 - 190s - loss: 2.7831 - accuracy30: 0.5536 - val_loss: 3.0965 - val_accuracy30: 0.5455 - 190s/epoch - 86ms/step
Epoch 6/50
2222/2222 - 192s - loss: 2.7644 - accuracy30: 0.5580 - val_loss: 3.0759 - val_accuracy30: 0.5459 - 192s/epoch - 86ms/step
Epoch 7/50
2222/2222 - 177s - loss: 2.7503 - accuracy30: 0.5613 - val_loss: 3.0598 - val_accuracy30: 0.5462 - 177s/epoch - 80ms/step
Epoch 8/50
2222/2222 - 186s - loss: 2.7364 - accuracy30: 0.5640 - val_loss: 3.0907 - val_accuracy30: 0.5443 - 186s/epoch - 84ms/step
Epoch 9/50
2222/2222 - 181s - loss: 2.7271 - accuracy30: 0.5659 - val_loss: 3.1011 - val_accuracy30: 0.5445 - 181s/epoch - 81ms/step
Epoch 10/50
2222/2222 - 192s - loss: 2.7175 - accuracy30: 0.5668 - val_loss: 3.0602 - val_accuracy30: 0.5471 - 192s/epoch - 87ms/step
Epoch 11/50
2222/2222 - 176s - loss: 2.7084 - accuracy30: 0.5687 - val_loss: 3.0433 - val_accuracy30: 0.5505 - 176s/epoch - 79ms/step
Epoch 12/50
2222/2222 - 175s - loss: 2.6989 - accuracy30: 0.5699 - val_loss: 3.0453 - val_accuracy30: 0.5500 - 175s/epoch - 79ms/step
Epoch 13/50
2222/2222 - 171s - loss: 2.6928 - accuracy30: 0.5708 - val_loss: 3.0798 - val_accuracy30: 0.5443 - 171s/epoch - 77ms/step
Epoch 14/50
2222/2222 - 174s - loss: 2.6860 - accuracy30: 0.5724 - val_loss: 3.0203 - val_accuracy30: 0.5488 - 174s/epoch - 78ms/step
Epoch 15/50
2222/2222 - 171s - loss: 2.6813 - accuracy30: 0.5737 - val_loss: 2.9836 - val_accuracy30: 0.5542 - 171s/epoch - 77ms/step
Epoch 16/50
2222/2222 - 187s - loss: 2.6752 - accuracy30: 0.5747 - val_loss: 3.0102 - val_accuracy30: 0.5493 - 187s/epoch - 84ms/step
Epoch 17/50
2222/2222 - 181s - loss: 2.6707 - accuracy30: 0.5757 - val_loss: 2.9548 - val_accuracy30: 0.5571 - 181s/epoch - 81ms/step
Epoch 18/50
2222/2222 - 196s - loss: 2.6656 - accuracy30: 0.5767 - val_loss: 2.9802 - val_accuracy30: 0.5555 - 196s/epoch - 88ms/step
Epoch 19/50
2222/2222 - 176s - loss: 2.6628 - accuracy30: 0.5769 - val_loss: 2.9590 - val_accuracy30: 0.5570 - 176s/epoch - 79ms/step
Epoch 20/50
2222/2222 - 190s - loss: 2.6593 - accuracy30: 0.5781 - val_loss: 2.9826 - val_accuracy30: 0.5566 - 190s/epoch - 86ms/step
Epoch 21/50
2222/2222 - 191s - loss: 2.6543 - accuracy30: 0.5788 - val_loss: 2.9432 - val_accuracy30: 0.5591 - 191s/epoch - 86ms/step
Epoch 22/50
2222/2222 - 199s - loss: 2.6501 - accuracy30: 0.5796 - val_loss: 2.9578 - val_accuracy30: 0.5579 - 199s/epoch - 89ms/step
Epoch 23/50
2222/2222 - 195s - loss: 2.6469 - accuracy30: 0.5802 - val_loss: 2.9685 - val_accuracy30: 0.5569 - 195s/epoch - 88ms/step
Epoch 24/50
2222/2222 - 191s - loss: 2.6444 - accuracy30: 0.5811 - val_loss: 2.9908 - val_accuracy30: 0.5559 - 191s/epoch - 86ms/step
Epoch 25/50
2222/2222 - 201s - loss: 2.6412 - accuracy30: 0.5817 - val_loss: 2.9735 - val_accuracy30: 0.5566 - 201s/epoch - 90ms/step
Epoch 26/50
2222/2222 - 203s - loss: 2.6393 - accuracy30: 0.5818 - val_loss: 2.9441 - val_accuracy30: 0.5595 - 203s/epoch - 91ms/step
Epoch 27/50
2222/2222 - 200s - loss: 2.6358 - accuracy30: 0.5828 - val_loss: 2.9546 - val_accuracy30: 0.5591 - 200s/epoch - 90ms/step
Epoch 28/50
2222/2222 - 193s - loss: 2.6327 - accuracy30: 0.5832 - val_loss: 2.9587 - val_accuracy30: 0.5603 - 193s/epoch - 87ms/step
Epoch 29/50
2222/2222 - 183s - loss: 2.6301 - accuracy30: 0.5840 - val_loss: 2.9554 - val_accuracy30: 0.5592 - 183s/epoch - 82ms/step
Epoch 30/50
2222/2222 - 177s - loss: 2.6270 - accuracy30: 0.5845 - val_loss: 2.9372 - val_accuracy30: 0.5613 - 177s/epoch - 80ms/step
Epoch 31/50
2222/2222 - 188s - loss: 2.6243 - accuracy30: 0.5846 - val_loss: 2.9286 - val_accuracy30: 0.5614 - 188s/epoch - 85ms/step
Epoch 32/50
2222/2222 - 188s - loss: 2.6225 - accuracy30: 0.5852 - val_loss: 2.9580 - val_accuracy30: 0.5597 - 188s/epoch - 85ms/step
Epoch 33/50
2222/2222 - 182s - loss: 2.6203 - accuracy30: 0.5856 - val_loss: 2.9493 - val_accuracy30: 0.5620 - 182s/epoch - 82ms/step
Epoch 34/50
2222/2222 - 186s - loss: 2.6175 - accuracy30: 0.5863 - val_loss: 2.9603 - val_accuracy30: 0.5603 - 186s/epoch - 84ms/step
Epoch 35/50
2222/2222 - 174s - loss: 2.6141 - accuracy30: 0.5870 - val_loss: 2.9341 - val_accuracy30: 0.5633 - 174s/epoch - 78ms/step
Epoch 36/50
2222/2222 - 185s - loss: 2.6118 - accuracy30: 0.5868 - val_loss: 2.9466 - val_accuracy30: 0.5612 - 185s/epoch - 83ms/step
Epoch 37/50
2222/2222 - 181s - loss: 2.6089 - accuracy30: 0.5874 - val_loss: 2.9519 - val_accuracy30: 0.5602 - 181s/epoch - 81ms/step
Epoch 38/50
2222/2222 - 180s - loss: 2.6062 - accuracy30: 0.5883 - val_loss: 2.9517 - val_accuracy30: 0.5607 - 180s/epoch - 81ms/step
Epoch 39/50
2222/2222 - 179s - loss: 2.6052 - accuracy30: 0.5881 - val_loss: 2.9360 - val_accuracy30: 0.5630 - 179s/epoch - 80ms/step
Epoch 40/50
2222/2222 - 185s - loss: 2.6025 - accuracy30: 0.5886 - val_loss: 2.9543 - val_accuracy30: 0.5617 - 185s/epoch - 83ms/step
Epoch 41/50
2222/2222 - 183s - loss: 2.5992 - accuracy30: 0.5893 - val_loss: 2.9395 - val_accuracy30: 0.5606 - 183s/epoch - 83ms/step
testing model: results/WBA/W1/deepVOL_L3/h30
Evaluating performance on  test set...
5696/5696 - 189s - 189s/epoch - 33ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.0192578
{'0': {'precision': 0.5039350456208047, 'recall': 0.3874758163713122, 'f1-score': 0.4380979669995597, 'support': 485349}, '1': {'precision': 0.46465208727620244, 'recall': 0.7438994839218733, 'f1-score': 0.572014395025493, 'support': 499343}, '2': {'precision': 0.5239733707077786, 'recall': 0.31593469277378244, 'f1-score': 0.3941892525951192, 'support': 473332}, 'accuracy': 0.48631846938047657, 'macro avg': {'precision': 0.4975201678682619, 'recall': 0.48243666435565596, 'f1-score': 0.468100538206724, 'support': 1458024}, 'weighted avg': {'precision': 0.4969866759241459, 'recall': 0.48631846938047657, 'f1-score': 0.46970707035675485, 'support': 1458024}}
[[188061 214038  83250]
 [ 75274 371461  52608]
 [109850 213940 149542]]
Evaluating performance on  train set...
2222/2222 - 30s - 30s/epoch - 14ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.9001383
{'0': {'precision': 0.5392580101180439, 'recall': 0.40847400254194527, 'f1-score': 0.46484211750426097, 'support': 156573}, '1': {'precision': 0.5872143562637759, 'recall': 0.8475028548789298, 'f1-score': 0.6937476451726238, 'support': 257454}, '2': {'precision': 0.5504168472579863, 'recall': 0.27930293935003103, 'f1-score': 0.37056617375706963, 'support': 154592}, 'accuracy': 0.5721352962176782, 'macro avg': {'precision': 0.5589630712132686, 'recall': 0.5117599322569687, 'f1-score': 0.5097186454779848, 'support': 568619}, 'weighted avg': {'precision': 0.5640050201401171, 'recall': 0.5721352962176782, 'f1-score': 0.5428527661539981, 'support': 568619}}
[[ 63956  71478  21139]
 [ 25132 218193  14129]
 [ 29512  81902  43178]]
Evaluating performance on  val set...
641/641 - 9s - 9s/epoch - 14ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.9264469
{'0': {'precision': 0.5092134470861972, 'recall': 0.41911554293512954, 'f1-score': 0.4597923206954842, 'support': 45429}, '1': {'precision': 0.5937752627324171, 'recall': 0.8084321015825291, 'f1-score': 0.684673316849973, 'support': 74501}, '2': {'precision': 0.5086324034849332, 'recall': 0.28979666188491926, 'f1-score': 0.3692249669998114, 'support': 43917}, 'accuracy': 0.5614750346359714, 'macro avg': {'precision': 0.5372070377678492, 'recall': 0.505781435467526, 'f1-score': 0.5045635348484229, 'support': 163847}, 'weighted avg': {'precision': 0.5475078445156425, 'recall': 0.5614750346359714, 'f1-score': 0.5377700231999714, 'support': 163847}}
[[19040 19535  6854]
 [ 8831 60229  5441]
 [ 9520 21670 12727]]
training model: results/WBA/W1/deepVOL_L3/h50
Epoch 1/50
2222/2222 - 77s - loss: 3.2432 - accuracy50: 0.3972 - val_loss: 3.5103 - val_accuracy50: 0.3622 - 77s/epoch - 34ms/step
Epoch 2/50
2222/2222 - 71s - loss: 3.1736 - accuracy50: 0.4347 - val_loss: 3.3230 - val_accuracy50: 0.4430 - 71s/epoch - 32ms/step
Epoch 3/50
2222/2222 - 73s - loss: 3.0646 - accuracy50: 0.4736 - val_loss: 3.1836 - val_accuracy50: 0.4660 - 73s/epoch - 33ms/step
Epoch 4/50
2222/2222 - 72s - loss: 2.9609 - accuracy50: 0.5046 - val_loss: 3.2451 - val_accuracy50: 0.4688 - 72s/epoch - 33ms/step
Epoch 5/50
2222/2222 - 72s - loss: 2.9226 - accuracy50: 0.5135 - val_loss: 3.2004 - val_accuracy50: 0.4724 - 72s/epoch - 32ms/step
Epoch 6/50
2222/2222 - 73s - loss: 2.8986 - accuracy50: 0.5193 - val_loss: 3.2185 - val_accuracy50: 0.4675 - 73s/epoch - 33ms/step
Epoch 7/50
2222/2222 - 72s - loss: 2.8808 - accuracy50: 0.5230 - val_loss: 3.1644 - val_accuracy50: 0.4686 - 72s/epoch - 33ms/step
Epoch 8/50
2222/2222 - 73s - loss: 2.8694 - accuracy50: 0.5254 - val_loss: 3.1481 - val_accuracy50: 0.4686 - 73s/epoch - 33ms/step
Epoch 9/50
2222/2222 - 74s - loss: 2.8575 - accuracy50: 0.5283 - val_loss: 3.1553 - val_accuracy50: 0.4701 - 74s/epoch - 33ms/step
Epoch 10/50
2222/2222 - 75s - loss: 2.8490 - accuracy50: 0.5298 - val_loss: 3.1167 - val_accuracy50: 0.4752 - 75s/epoch - 34ms/step
Epoch 11/50
2222/2222 - 73s - loss: 2.8393 - accuracy50: 0.5317 - val_loss: 3.1104 - val_accuracy50: 0.4753 - 73s/epoch - 33ms/step
Epoch 12/50
2222/2222 - 72s - loss: 2.8331 - accuracy50: 0.5331 - val_loss: 3.1021 - val_accuracy50: 0.4710 - 72s/epoch - 32ms/step
Epoch 13/50
2222/2222 - 74s - loss: 2.8257 - accuracy50: 0.5349 - val_loss: 3.1029 - val_accuracy50: 0.4775 - 74s/epoch - 33ms/step
Epoch 14/50
2222/2222 - 75s - loss: 2.8215 - accuracy50: 0.5357 - val_loss: 3.0615 - val_accuracy50: 0.4818 - 75s/epoch - 34ms/step
Epoch 15/50
2222/2222 - 74s - loss: 2.8161 - accuracy50: 0.5372 - val_loss: 3.0690 - val_accuracy50: 0.4799 - 74s/epoch - 33ms/step
Epoch 16/50
2222/2222 - 74s - loss: 2.8107 - accuracy50: 0.5389 - val_loss: 3.0539 - val_accuracy50: 0.4816 - 74s/epoch - 33ms/step
Epoch 17/50
2222/2222 - 72s - loss: 2.8072 - accuracy50: 0.5389 - val_loss: 3.0518 - val_accuracy50: 0.4859 - 72s/epoch - 32ms/step
Epoch 18/50
2222/2222 - 74s - loss: 2.8027 - accuracy50: 0.5402 - val_loss: 3.0608 - val_accuracy50: 0.4816 - 74s/epoch - 33ms/step
Epoch 19/50
2222/2222 - 73s - loss: 2.8001 - accuracy50: 0.5407 - val_loss: 3.0497 - val_accuracy50: 0.4861 - 73s/epoch - 33ms/step
Epoch 20/50
2222/2222 - 72s - loss: 2.7972 - accuracy50: 0.5414 - val_loss: 3.0376 - val_accuracy50: 0.4872 - 72s/epoch - 33ms/step
Epoch 21/50
2222/2222 - 73s - loss: 2.7943 - accuracy50: 0.5422 - val_loss: 3.0284 - val_accuracy50: 0.4885 - 73s/epoch - 33ms/step
Epoch 22/50
2222/2222 - 74s - loss: 2.7912 - accuracy50: 0.5430 - val_loss: 3.0634 - val_accuracy50: 0.4887 - 74s/epoch - 34ms/step
Epoch 23/50
2222/2222 - 72s - loss: 2.7886 - accuracy50: 0.5433 - val_loss: 3.0317 - val_accuracy50: 0.4898 - 72s/epoch - 32ms/step
Epoch 24/50
2222/2222 - 72s - loss: 2.7843 - accuracy50: 0.5446 - val_loss: 3.0380 - val_accuracy50: 0.4888 - 72s/epoch - 33ms/step
Epoch 25/50
2222/2222 - 74s - loss: 2.7832 - accuracy50: 0.5443 - val_loss: 3.0294 - val_accuracy50: 0.4936 - 74s/epoch - 33ms/step
Epoch 26/50
2222/2222 - 74s - loss: 2.7792 - accuracy50: 0.5458 - val_loss: 3.0264 - val_accuracy50: 0.4946 - 74s/epoch - 33ms/step
Epoch 27/50
2222/2222 - 76s - loss: 2.7771 - accuracy50: 0.5463 - val_loss: 3.0219 - val_accuracy50: 0.4953 - 76s/epoch - 34ms/step
Epoch 28/50
2222/2222 - 76s - loss: 2.7743 - accuracy50: 0.5467 - val_loss: 3.0230 - val_accuracy50: 0.4973 - 76s/epoch - 34ms/step
Epoch 29/50
2222/2222 - 76s - loss: 2.7715 - accuracy50: 0.5471 - val_loss: 3.0144 - val_accuracy50: 0.5021 - 76s/epoch - 34ms/step
Epoch 30/50
2222/2222 - 75s - loss: 2.7687 - accuracy50: 0.5483 - val_loss: 3.0334 - val_accuracy50: 0.4979 - 75s/epoch - 34ms/step
Epoch 31/50
2222/2222 - 75s - loss: 2.7656 - accuracy50: 0.5490 - val_loss: 3.0281 - val_accuracy50: 0.5007 - 75s/epoch - 34ms/step
Epoch 32/50
2222/2222 - 76s - loss: 2.7635 - accuracy50: 0.5494 - val_loss: 3.0411 - val_accuracy50: 0.4999 - 76s/epoch - 34ms/step
Epoch 33/50
2222/2222 - 76s - loss: 2.7613 - accuracy50: 0.5500 - val_loss: 3.0685 - val_accuracy50: 0.4964 - 76s/epoch - 34ms/step
Epoch 34/50
2222/2222 - 77s - loss: 2.7591 - accuracy50: 0.5501 - val_loss: 3.0502 - val_accuracy50: 0.4990 - 77s/epoch - 34ms/step
Epoch 35/50
2222/2222 - 76s - loss: 2.7565 - accuracy50: 0.5509 - val_loss: 3.0686 - val_accuracy50: 0.4966 - 76s/epoch - 34ms/step
Epoch 36/50
2222/2222 - 76s - loss: 2.7549 - accuracy50: 0.5517 - val_loss: 3.0425 - val_accuracy50: 0.5005 - 76s/epoch - 34ms/step
Epoch 37/50
2222/2222 - 76s - loss: 2.7507 - accuracy50: 0.5523 - val_loss: 3.0662 - val_accuracy50: 0.4964 - 76s/epoch - 34ms/step
Epoch 38/50
2222/2222 - 78s - loss: 2.7506 - accuracy50: 0.5524 - val_loss: 3.0608 - val_accuracy50: 0.4983 - 78s/epoch - 35ms/step
Epoch 39/50
2222/2222 - 74s - loss: 2.7456 - accuracy50: 0.5539 - val_loss: 3.0681 - val_accuracy50: 0.4986 - 74s/epoch - 33ms/step
testing model: results/WBA/W1/deepVOL_L3/h50
Evaluating performance on  test set...
5696/5696 - 77s - 77s/epoch - 14ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0741589
{'0': {'precision': 0.49507975587678216, 'recall': 0.3570559955526866, 'f1-score': 0.41488975158249025, 'support': 546847}, '1': {'precision': 0.3571208549506387, 'recall': 0.7533961863894759, 'f1-score': 0.48455535608040834, 'support': 372403}, '2': {'precision': 0.5212106605466965, 'recall': 0.26893465534714, 'f1-score': 0.3547995705038499, 'support': 538774}, 'accuracy': 0.42572481660109845, 'macro avg': {'precision': 0.4578037571247058, 'recall': 0.4597956124297675, 'f1-score': 0.41808155938891617, 'support': 1458024}, 'weighted avg': {'precision': 0.4694987938700043, 'recall': 0.42572481660109845, 'f1-score': 0.41047874935713236, 'support': 1458024}}
[[195255 254028  97564]
 [ 56298 280567  35538]
 [142838 251041 144895]]
Evaluating performance on  train set...
2222/2222 - 38s - 38s/epoch - 17ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.97941583
{'0': {'precision': 0.5396632598428972, 'recall': 0.37007364867826925, 'f1-score': 0.43906133687006105, 'support': 182488}, '1': {'precision': 0.48416707822790467, 'recall': 0.8519039944074412, 'f1-score': 0.6174280341080416, 'support': 205988}, '2': {'precision': 0.5460221873958809, 'recall': 0.2456270851490205, 'f1-score': 0.3388314572325599, 'support': 180143}, 'accuracy': 0.5051959220497381, 'macro avg': {'precision': 0.5232841751555609, 'recall': 0.4892015760782437, 'f1-score': 0.4651069427368875, 'support': 568619}, 'weighted avg': {'precision': 0.5215737637614578, 'recall': 0.5051959220497381, 'f1-score': 0.4719228628182246, 'support': 568619}}
[[ 67534  89528  25426]
 [ 19143 175482  11363]
 [ 38464  97431  44248]]
Evaluating performance on  val set...
641/641 - 11s - 11s/epoch - 17ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.99247843
{'0': {'precision': 0.5130018305373756, 'recall': 0.3860728439328175, 'f1-score': 0.4405775877849444, 'support': 52990}, '1': {'precision': 0.4942599064577349, 'recall': 0.8038590632326401, 'f1-score': 0.6121400498343137, 'support': 59289}, '2': {'precision': 0.5134163610616899, 'recall': 0.27420105491777846, 'f1-score': 0.35748144964542594, 'support': 51568}, 'accuracy': 0.5020415387526168, 'macro avg': {'precision': 0.5068926993522668, 'recall': 0.488044320694412, 'f1-score': 0.47006636242156136, 'support': 163847}, 'weighted avg': {'precision': 0.5063504214381551, 'recall': 0.5020415387526168, 'f1-score': 0.47650540557145477, 'support': 163847}}
[[20458 23774  8758]
 [ 6986 47660  4643]
 [12435 24993 14140]]
training model: results/WBA/W1/deepVOL_L3/h100
Epoch 1/50
2222/2222 - 78s - loss: 3.2776 - accuracy100: 0.3750 - val_loss: 3.4630 - val_accuracy100: 0.3133 - 78s/epoch - 35ms/step
Epoch 2/50
2222/2222 - 76s - loss: 3.2692 - accuracy100: 0.3792 - val_loss: 3.3244 - val_accuracy100: 0.3345 - 76s/epoch - 34ms/step
Epoch 3/50
2222/2222 - 77s - loss: 3.2425 - accuracy100: 0.3978 - val_loss: 3.3256 - val_accuracy100: 0.3532 - 77s/epoch - 35ms/step
Epoch 4/50
2222/2222 - 76s - loss: 3.2166 - accuracy100: 0.4117 - val_loss: 3.3513 - val_accuracy100: 0.3627 - 76s/epoch - 34ms/step
Epoch 5/50
2222/2222 - 74s - loss: 3.1704 - accuracy100: 0.4340 - val_loss: 3.3146 - val_accuracy100: 0.3996 - 74s/epoch - 34ms/step
Epoch 6/50
2222/2222 - 74s - loss: 3.1413 - accuracy100: 0.4442 - val_loss: 3.3050 - val_accuracy100: 0.4056 - 74s/epoch - 33ms/step
Epoch 7/50
2222/2222 - 73s - loss: 3.1247 - accuracy100: 0.4500 - val_loss: 3.3120 - val_accuracy100: 0.4071 - 73s/epoch - 33ms/step
Epoch 8/50
2222/2222 - 73s - loss: 3.1141 - accuracy100: 0.4535 - val_loss: 3.3236 - val_accuracy100: 0.4027 - 73s/epoch - 33ms/step
Epoch 9/50
2222/2222 - 74s - loss: 3.1062 - accuracy100: 0.4565 - val_loss: 3.3153 - val_accuracy100: 0.4044 - 74s/epoch - 33ms/step
Epoch 10/50
2222/2222 - 75s - loss: 3.1001 - accuracy100: 0.4583 - val_loss: 3.3024 - val_accuracy100: 0.4030 - 75s/epoch - 34ms/step
Epoch 11/50
2222/2222 - 75s - loss: 3.0941 - accuracy100: 0.4606 - val_loss: 3.3037 - val_accuracy100: 0.4044 - 75s/epoch - 34ms/step
Epoch 12/50
2222/2222 - 74s - loss: 3.0900 - accuracy100: 0.4620 - val_loss: 3.2818 - val_accuracy100: 0.4059 - 74s/epoch - 33ms/step
Epoch 13/50
2222/2222 - 74s - loss: 3.0865 - accuracy100: 0.4623 - val_loss: 3.2880 - val_accuracy100: 0.4039 - 74s/epoch - 33ms/step
Epoch 14/50
2222/2222 - 74s - loss: 3.0818 - accuracy100: 0.4647 - val_loss: 3.2891 - val_accuracy100: 0.4053 - 74s/epoch - 33ms/step
Epoch 15/50
2222/2222 - 74s - loss: 3.0774 - accuracy100: 0.4664 - val_loss: 3.2877 - val_accuracy100: 0.4074 - 74s/epoch - 33ms/step
Epoch 16/50
2222/2222 - 75s - loss: 3.0741 - accuracy100: 0.4675 - val_loss: 3.2849 - val_accuracy100: 0.4105 - 75s/epoch - 34ms/step
Epoch 17/50
2222/2222 - 74s - loss: 3.0710 - accuracy100: 0.4685 - val_loss: 3.2963 - val_accuracy100: 0.4071 - 74s/epoch - 33ms/step
Epoch 18/50
2222/2222 - 75s - loss: 3.0679 - accuracy100: 0.4697 - val_loss: 3.2840 - val_accuracy100: 0.4096 - 75s/epoch - 34ms/step
Epoch 19/50
2222/2222 - 74s - loss: 3.0653 - accuracy100: 0.4708 - val_loss: 3.3202 - val_accuracy100: 0.4059 - 74s/epoch - 33ms/step
Epoch 20/50
2222/2222 - 75s - loss: 3.0610 - accuracy100: 0.4725 - val_loss: 3.3057 - val_accuracy100: 0.4094 - 75s/epoch - 34ms/step
Epoch 21/50
2222/2222 - 77s - loss: 3.0592 - accuracy100: 0.4725 - val_loss: 3.2956 - val_accuracy100: 0.4098 - 77s/epoch - 35ms/step
Epoch 22/50
2222/2222 - 73s - loss: 3.0543 - accuracy100: 0.4734 - val_loss: 3.3055 - val_accuracy100: 0.4080 - 73s/epoch - 33ms/step
testing model: results/WBA/W1/deepVOL_L3/h100
Evaluating performance on  test set...
5696/5696 - 78s - 78s/epoch - 14ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.1449103
{'0': {'precision': 0.43179080316976304, 'recall': 0.3342957434754968, 'f1-score': 0.37683947904741866, 'support': 548969}, '1': {'precision': 0.29212154950534175, 'recall': 0.7059263154981039, 'f1-score': 0.41323927709457287, 'support': 361270}, '2': {'precision': 0.46767428632150065, 'recall': 0.13658460892503446, 'f1-score': 0.211422984432708, 'support': 547785}, 'accuracy': 0.3520977706814154, 'macro avg': {'precision': 0.39719554633220183, 'recall': 0.392268889299545, 'f1-score': 0.33383391352489983, 'support': 1458024}, 'weighted avg': {'precision': 0.4106650346960816, 'recall': 0.3520977706814154, 'f1-score': 0.3237110535468618, 'support': 1458024}}
[[183518 307498  57953]
 [ 79031 255030  27209]
 [162467 310499  74819]]
Evaluating performance on  train set...
2222/2222 - 37s - 37s/epoch - 17ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0926969
{'0': {'precision': 0.46200612993451357, 'recall': 0.2882264434831672, 'f1-score': 0.3549896083339232, 'support': 191412}, '1': {'precision': 0.38908748448081615, 'recall': 0.8293584234543644, 'f1-score': 0.5296796199376311, 'support': 187803}, '2': {'precision': 0.4858469341841535, 'recall': 0.12541973770353318, 'f1-score': 0.19937221462202787, 'support': 189404}, 'accuracy': 0.41272099595687095, 'macro avg': {'precision': 0.4456468495331611, 'recall': 0.41433486821368826, 'f1-score': 0.361347147631194, 'support': 568619}, 'weighted avg': {'precision': 0.44586386827241303, 'recall': 0.41272099595687095, 'f1-score': 0.360850741026646, 'support': 568619}}
[[ 55170 119442  16800]
 [ 23708 155756   8339]
 [ 40536 125113  23755]]
Evaluating performance on  val set...
641/641 - 11s - 11s/epoch - 18ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.095202
{'0': {'precision': 0.45028004073319755, 'recall': 0.3096084163355331, 'f1-score': 0.36692356364164425, 'support': 57127}, '1': {'precision': 0.3786189089710487, 'recall': 0.805642144638404, 'f1-score': 0.5151420776599853, 'support': 51328}, '2': {'precision': 0.48367971854843966, 'recall': 0.1340265742345465, 'f1-score': 0.20989242447802547, 'support': 55392}, 'accuracy': 0.4056406281469908, 'macro avg': {'precision': 0.4375262227508953, 'recall': 0.4164257117361612, 'f1-score': 0.36398602192655166, 'support': 163847}, 'weighted avg': {'precision': 0.4391223898909747, 'recall': 0.4056406281469908, 'f1-score': 0.36026790944585324, 'support': 163847}}
[[17687 34004  5436]
 [ 7487 41352  2489]
 [14106 33862  7424]]
training model: results/WBA/W1/deepVOL_L3/h200
Epoch 1/50
2222/2222 - 78s - loss: 3.2796 - accuracy200: 0.3731 - val_loss: 3.2834 - val_accuracy200: 0.3597 - 78s/epoch - 35ms/step
Epoch 2/50
2222/2222 - 80s - loss: 3.2768 - accuracy200: 0.3721 - val_loss: 3.2810 - val_accuracy200: 0.3592 - 80s/epoch - 36ms/step
Epoch 3/50
2222/2222 - 80s - loss: 3.2736 - accuracy200: 0.3747 - val_loss: 3.2781 - val_accuracy200: 0.3700 - 80s/epoch - 36ms/step
Epoch 4/50
2222/2222 - 72s - loss: 3.2595 - accuracy200: 0.3856 - val_loss: 3.2716 - val_accuracy200: 0.3776 - 72s/epoch - 33ms/step
Epoch 5/50
2222/2222 - 73s - loss: 3.2529 - accuracy200: 0.3902 - val_loss: 3.2658 - val_accuracy200: 0.3819 - 73s/epoch - 33ms/step
Epoch 6/50
2222/2222 - 72s - loss: 3.2446 - accuracy200: 0.3977 - val_loss: 3.2794 - val_accuracy200: 0.3723 - 72s/epoch - 32ms/step
Epoch 7/50
2222/2222 - 72s - loss: 3.2375 - accuracy200: 0.4015 - val_loss: 3.2687 - val_accuracy200: 0.3819 - 72s/epoch - 32ms/step
Epoch 8/50
2222/2222 - 71s - loss: 3.2309 - accuracy200: 0.4047 - val_loss: 3.2789 - val_accuracy200: 0.3784 - 71s/epoch - 32ms/step
Epoch 9/50
2222/2222 - 72s - loss: 3.2259 - accuracy200: 0.4086 - val_loss: 3.2865 - val_accuracy200: 0.3739 - 72s/epoch - 32ms/step
Epoch 10/50
2222/2222 - 72s - loss: 3.2216 - accuracy200: 0.4111 - val_loss: 3.2855 - val_accuracy200: 0.3745 - 72s/epoch - 32ms/step
Epoch 11/50
2222/2222 - 72s - loss: 3.2180 - accuracy200: 0.4138 - val_loss: 3.2939 - val_accuracy200: 0.3682 - 72s/epoch - 32ms/step
Epoch 12/50
2222/2222 - 72s - loss: 3.2139 - accuracy200: 0.4151 - val_loss: 3.3011 - val_accuracy200: 0.3650 - 72s/epoch - 32ms/step
Epoch 13/50
2222/2222 - 72s - loss: 3.2091 - accuracy200: 0.4180 - val_loss: 3.2987 - val_accuracy200: 0.3649 - 72s/epoch - 33ms/step
Epoch 14/50
2222/2222 - 72s - loss: 3.2061 - accuracy200: 0.4198 - val_loss: 3.3025 - val_accuracy200: 0.3702 - 72s/epoch - 33ms/step
Epoch 15/50
2222/2222 - 74s - loss: 3.2032 - accuracy200: 0.4215 - val_loss: 3.3003 - val_accuracy200: 0.3731 - 74s/epoch - 33ms/step
testing model: results/WBA/W1/deepVOL_L3/h200
Evaluating performance on  test set...
5696/5696 - 75s - 75s/epoch - 13ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0937898
{'0': {'precision': 0.36710396568255454, 'recall': 0.47341094659530414, 'f1-score': 0.41353468773488244, 'support': 511940}, '1': {'precision': 0.32527939146065077, 'recall': 0.05725651137197359, 'f1-score': 0.09737315132161253, 'support': 436160}, '2': {'precision': 0.3711294883511936, 'recall': 0.5247978130074286, 'f1-score': 0.4347851517280876, 'support': 509924}, 'accuracy': 0.3668924517017553, 'macro avg': {'precision': 0.3545042818314663, 'recall': 0.35182175699156876, 'f1-score': 0.3152309969281942, 'support': 1458024}, 'weighted avg': {'precision': 0.3560002419637801, 'recall': 0.3668924517017553, 'f1-score': 0.32638873257862944, 'support': 1458024}}
[[242358  25261 244321]
 [202054  24973 209133]
 [215777  26540 267607]]
Evaluating performance on  train set...
2222/2222 - 30s - 30s/epoch - 14ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0925777
{'0': {'precision': 0.3678626279214756, 'recall': 0.5000878552971576, 'f1-score': 0.42390352029998773, 'support': 193500}, '1': {'precision': 0.37534158495418746, 'recall': 0.06332066016194902, 'f1-score': 0.10836071355645895, 'support': 184379}, '2': {'precision': 0.36762101857452034, 'recall': 0.5289818601237286, 'f1-score': 0.43378145407801344, 'support': 190740}, 'accuracy': 0.3681551267192971, 'macro avg': {'precision': 0.37027507715006114, 'recall': 0.3641301251942784, 'f1-score': 0.3220152293114867, 'support': 568619}, 'weighted avg': {'precision': 0.3702066896779349, 'recall': 0.3681551267192971, 'f1-score': 0.32489988152649535, 'support': 568619}}
[[ 96767   8856  87877]
 [ 87017  11675  85687]
 [ 79268  10574 100898]]
Evaluating performance on  val set...
641/641 - 9s - 9s/epoch - 13ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0897453
{'0': {'precision': 0.386956033956196, 'recall': 0.5159906914893617, 'f1-score': 0.4422535813251081, 'support': 60160}, '1': {'precision': 0.32769250951069134, 'recall': 0.05394199831566218, 'f1-score': 0.09263517021434399, 'support': 46309}, '2': {'precision': 0.38176124626659474, 'recall': 0.5056816201331521, 'f1-score': 0.4350694626670965, 'support': 57378}, 'accuracy': 0.38178910813136646, 'macro avg': {'precision': 0.36546992991116073, 'recall': 0.3585381033127253, 'f1-score': 0.3233194047355162, 'support': 163847}, 'weighted avg': {'precision': 0.3683868744256534, 'recall': 0.38178910813136646, 'f1-score': 0.3409231367000142, 'support': 163847}}
[[31042  2489 26629]
 [23452  2498 20359]
 [25727  2636 29015]]
training model: results/WBA/W1/deepVOL_L3/h300
Epoch 1/50
2222/2222 - 78s - loss: 3.2953 - accuracy300: 0.3606 - val_loss: 3.2994 - val_accuracy300: 0.3093 - 78s/epoch - 35ms/step
Epoch 2/50
2222/2222 - 80s - loss: 3.2859 - accuracy300: 0.3597 - val_loss: 3.2940 - val_accuracy300: 0.3239 - 80s/epoch - 36ms/step
Epoch 3/50
2222/2222 - 80s - loss: 3.2816 - accuracy300: 0.3674 - val_loss: 3.2939 - val_accuracy300: 0.3464 - 80s/epoch - 36ms/step
Epoch 4/50
2222/2222 - 71s - loss: 3.2798 - accuracy300: 0.3699 - val_loss: 3.2891 - val_accuracy300: 0.3610 - 71s/epoch - 32ms/step
Epoch 5/50
2222/2222 - 72s - loss: 3.2766 - accuracy300: 0.3730 - val_loss: 3.2932 - val_accuracy300: 0.3533 - 72s/epoch - 33ms/step
Epoch 6/50
2222/2222 - 73s - loss: 3.2727 - accuracy300: 0.3757 - val_loss: 3.2906 - val_accuracy300: 0.3579 - 73s/epoch - 33ms/step
Epoch 7/50
2222/2222 - 73s - loss: 3.2690 - accuracy300: 0.3789 - val_loss: 3.2987 - val_accuracy300: 0.3493 - 73s/epoch - 33ms/step
Epoch 8/50
2222/2222 - 72s - loss: 3.2641 - accuracy300: 0.3840 - val_loss: 3.2978 - val_accuracy300: 0.3555 - 72s/epoch - 32ms/step
Epoch 9/50
2222/2222 - 71s - loss: 3.2597 - accuracy300: 0.3872 - val_loss: 3.3021 - val_accuracy300: 0.3510 - 71s/epoch - 32ms/step
Epoch 10/50
2222/2222 - 73s - loss: 3.2573 - accuracy300: 0.3882 - val_loss: 3.3026 - val_accuracy300: 0.3507 - 73s/epoch - 33ms/step
Epoch 11/50
2222/2222 - 72s - loss: 3.2531 - accuracy300: 0.3919 - val_loss: 3.3112 - val_accuracy300: 0.3465 - 72s/epoch - 32ms/step
Epoch 12/50
2222/2222 - 73s - loss: 3.2493 - accuracy300: 0.3954 - val_loss: 3.3142 - val_accuracy300: 0.3439 - 73s/epoch - 33ms/step
Epoch 13/50
2222/2222 - 72s - loss: 3.2430 - accuracy300: 0.4002 - val_loss: 3.3201 - val_accuracy300: 0.3481 - 72s/epoch - 32ms/step
Epoch 14/50
2222/2222 - 72s - loss: 3.2395 - accuracy300: 0.4009 - val_loss: 3.3194 - val_accuracy300: 0.3478 - 72s/epoch - 32ms/step
testing model: results/WBA/W1/deepVOL_L3/h300
Evaluating performance on  test set...
5696/5696 - 86s - 86s/epoch - 15ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1013842
{'0': {'precision': 0.36827313553364666, 'recall': 0.488018892618483, 'f1-score': 0.4197732592982561, 'support': 519568}, '1': {'precision': 0.29417549096175066, 'recall': 0.22045613411527754, 'f1-score': 0.2520357798811311, 'support': 422025}, '2': {'precision': 0.3591094519789343, 'recall': 0.3151747280856494, 'f1-score': 0.33571074993812394, 'support': 516431}, 'accuracy': 0.349351588176875, 'macro avg': {'precision': 0.3405193594914439, 'recall': 0.3412165849398033, 'f1-score': 0.33583992970583704, 'support': 1458024}, 'weighted avg': {'precision': 0.34357980489416606, 'recall': 0.349351588176875, 'f1-score': 0.34144677391641426, 'support': 1458024}}
[[253559 108199 157810]
 [196314  93038 132673]
 [238635 115030 162766]]
Evaluating performance on  train set...
2222/2222 - 37s - 37s/epoch - 17ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0969614
{'0': {'precision': 0.36596112580987894, 'recall': 0.5420114265732108, 'f1-score': 0.4369187402194977, 'support': 194459}, '1': {'precision': 0.3238589267092703, 'recall': 0.19835035563974213, 'f1-score': 0.24602218099584275, 'support': 183191}, '2': {'precision': 0.36421717651529545, 'recall': 0.3212039650414465, 'f1-score': 0.3413609360435188, 'support': 190969}, 'accuracy': 0.3571372043494853, 'macro avg': {'precision': 0.3513457430114815, 'recall': 0.35385524908479976, 'f1-score': 0.34143395241961977, 'support': 568619}, 'weighted avg': {'precision': 0.35181143294299105, 'recall': 0.3571372043494853, 'f1-score': 0.3433251214933857, 'support': 568619}}
[[105399  36659  52401]
 [ 92180  36336  54675]
 [ 90427  39202  61340]]
Evaluating performance on  val set...
641/641 - 11s - 11s/epoch - 17ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0974814
{'0': {'precision': 0.37926110811297, 'recall': 0.5753637278479933, 'f1-score': 0.4571703495896946, 'support': 58629}, '1': {'precision': 0.3037888621051981, 'recall': 0.19769920759422388, 'f1-score': 0.23952241715399614, 'support': 49722}, '2': {'precision': 0.3641791044776119, 'recall': 0.2791912930661669, 'f1-score': 0.31607184749237566, 'support': 55496}, 'accuracy': 0.3604399226107283, 'macro avg': {'precision': 0.3490763582319267, 'recall': 0.35075140950279465, 'f1-score': 0.3375882047453555, 'support': 163847}, 'weighted avg': {'precision': 0.35124947598210243, 'recall': 0.3604399226107283, 'f1-score': 0.34333065176818667, 'support': 163847}}
[[33733 10943 13953]
 [26794  9830 13098]
 [28417 11585 15494]]
training model: results/WBA/W1/deepVOL_L3/h500
Epoch 1/50
2222/2222 - 77s - loss: 3.2251 - accuracy500: 0.4141 - val_loss: 3.2399 - val_accuracy500: 0.3738 - 77s/epoch - 35ms/step
Epoch 2/50
2222/2222 - 82s - loss: 3.2511 - accuracy500: 0.3980 - val_loss: 3.2386 - val_accuracy500: 0.3760 - 82s/epoch - 37ms/step
Epoch 3/50
2222/2222 - 81s - loss: 3.2589 - accuracy500: 0.3926 - val_loss: 3.2438 - val_accuracy500: 0.3683 - 81s/epoch - 36ms/step
Epoch 4/50
2222/2222 - 74s - loss: 3.2541 - accuracy500: 0.3965 - val_loss: 3.2397 - val_accuracy500: 0.3728 - 74s/epoch - 33ms/step
Epoch 5/50
2222/2222 - 73s - loss: 3.2464 - accuracy500: 0.3990 - val_loss: 3.2404 - val_accuracy500: 0.3656 - 73s/epoch - 33ms/step
Epoch 6/50
2222/2222 - 73s - loss: 3.2463 - accuracy500: 0.4028 - val_loss: 3.2392 - val_accuracy500: 0.3824 - 73s/epoch - 33ms/step
Epoch 7/50
2222/2222 - 72s - loss: 3.2496 - accuracy500: 0.3999 - val_loss: 3.2414 - val_accuracy500: 0.3853 - 72s/epoch - 32ms/step
Epoch 8/50
2222/2222 - 72s - loss: 3.2424 - accuracy500: 0.4083 - val_loss: 3.2397 - val_accuracy500: 0.3926 - 72s/epoch - 32ms/step
Epoch 9/50
2222/2222 - 72s - loss: 3.2337 - accuracy500: 0.4110 - val_loss: 3.2394 - val_accuracy500: 0.3942 - 72s/epoch - 32ms/step
Epoch 10/50
2222/2222 - 72s - loss: 3.2372 - accuracy500: 0.4078 - val_loss: 3.2391 - val_accuracy500: 0.3904 - 72s/epoch - 32ms/step
Epoch 11/50
2222/2222 - 72s - loss: 3.2373 - accuracy500: 0.4079 - val_loss: 3.2394 - val_accuracy500: 0.3947 - 72s/epoch - 32ms/step
Epoch 12/50
2222/2222 - 73s - loss: 3.2369 - accuracy500: 0.4103 - val_loss: 3.2411 - val_accuracy500: 0.3937 - 73s/epoch - 33ms/step
testing model: results/WBA/W1/deepVOL_L3/h500
Evaluating performance on  test set...
5696/5696 - 75s - 75s/epoch - 13ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0757375
{'0': {'precision': 0.3854212016489571, 'recall': 0.4594868857886871, 'f1-score': 0.4192076991467617, 'support': 558745}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 341071}, '2': {'precision': 0.38458099824979225, 'recall': 0.5455887411144233, 'f1-score': 0.45115005103272754, 'support': 558208}, 'accuracy': 0.3849648565455713, 'macro avg': {'precision': 0.2566673999662498, 'recall': 0.3350252089677035, 'f1-score': 0.29011925005982975, 'support': 1458024}, 'weighted avg': {'precision': 0.2949391499634893, 'recall': 0.3849648565455713, 'f1-score': 0.3333729578845301, 'support': 1458024}}
[[256736      0 302009]
 [155726      0 185345]
 [253656      0 304552]]
Evaluating performance on  train set...
2222/2222 - 30s - 30s/epoch - 14ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1172407
{'0': {'precision': 0.3347840166815421, 'recall': 0.4418821640612376, 'f1-score': 0.38094895709987714, 'support': 191843}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 191042}, '2': {'precision': 0.3265103596962635, 'recall': 0.5544649875628587, 'f1-score': 0.41099575167767827, 'support': 185734}, 'accuracy': 0.33019473496312995, 'macro avg': {'precision': 0.22043145879260187, 'recall': 0.33211571720803207, 'f1-score': 0.26398156959251845, 'support': 568619}, 'weighted avg': {'precision': 0.21960230885718363, 'recall': 0.33019473496312995, 'f1-score': 0.26277397645701894, 'support': 568619}}
[[ 84772      0 107071]
 [ 85691      0 105351]
 [ 82751      0 102983]]
Evaluating performance on  val set...
641/641 - 11s - 11s/epoch - 17ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0794013
{'0': {'precision': 0.38984780086931, 'recall': 0.43440478415249484, 'f1-score': 0.41092197432290095, 'support': 64212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 39803}, '2': {'precision': 0.36245341076536364, 'recall': 0.5591155234657039, 'f1-score': 0.43980069415229284, 'support': 59832}, 'accuracy': 0.374416376253456, 'macro avg': {'precision': 0.2507670705448912, 'recall': 0.3311734358727329, 'f1-score': 0.2835742228250646, 'support': 163847}, 'weighted avg': {'precision': 0.2851393035107958, 'recall': 0.374416376253456, 'f1-score': 0.32164322171136545, 'support': 163847}}
[[27894     0 36318]
 [17278     0 22525]
 [26379     0 33453]]
training model: results/WBA/W1/deepVOL_L3/h1000
Epoch 1/50
2222/2222 - 85s - loss: 3.2800 - accuracy1000: 0.3800 - val_loss: 3.3046 - val_accuracy1000: 0.3339 - 85s/epoch - 38ms/step
Epoch 2/50
2222/2222 - 83s - loss: 3.2737 - accuracy1000: 0.3767 - val_loss: 3.2994 - val_accuracy1000: 0.3510 - 83s/epoch - 37ms/step
Epoch 3/50
2222/2222 - 83s - loss: 3.2700 - accuracy1000: 0.3814 - val_loss: 3.3028 - val_accuracy1000: 0.3467 - 83s/epoch - 37ms/step
Epoch 4/50
2222/2222 - 82s - loss: 3.2621 - accuracy1000: 0.3845 - val_loss: 3.3030 - val_accuracy1000: 0.3506 - 82s/epoch - 37ms/step
Epoch 5/50
2222/2222 - 75s - loss: 3.2539 - accuracy1000: 0.3907 - val_loss: 3.3117 - val_accuracy1000: 0.3406 - 75s/epoch - 34ms/step
Epoch 6/50
2222/2222 - 74s - loss: 3.2454 - accuracy1000: 0.3951 - val_loss: 3.3135 - val_accuracy1000: 0.3420 - 74s/epoch - 33ms/step
Epoch 7/50
2222/2222 - 74s - loss: 3.2349 - accuracy1000: 0.4045 - val_loss: 3.3305 - val_accuracy1000: 0.3443 - 74s/epoch - 33ms/step
Epoch 8/50
2222/2222 - 74s - loss: 3.2232 - accuracy1000: 0.4084 - val_loss: 3.3396 - val_accuracy1000: 0.3480 - 74s/epoch - 33ms/step
Epoch 9/50
2222/2222 - 75s - loss: 3.2138 - accuracy1000: 0.4161 - val_loss: 3.3390 - val_accuracy1000: 0.3510 - 75s/epoch - 34ms/step
Epoch 10/50
2222/2222 - 73s - loss: 3.1970 - accuracy1000: 0.4228 - val_loss: 3.3557 - val_accuracy1000: 0.3552 - 73s/epoch - 33ms/step
Epoch 11/50
2222/2222 - 73s - loss: 3.1849 - accuracy1000: 0.4270 - val_loss: 3.3464 - val_accuracy1000: 0.3527 - 73s/epoch - 33ms/step
Epoch 12/50
2222/2222 - 72s - loss: 3.1793 - accuracy1000: 0.4303 - val_loss: 3.3558 - val_accuracy1000: 0.3564 - 72s/epoch - 33ms/step
testing model: results/WBA/W1/deepVOL_L3/h1000
Evaluating performance on  test set...
5696/5696 - 79s - 79s/epoch - 14ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0979177
{'0': {'precision': 0.3497227077776977, 'recall': 0.6139987661058776, 'f1-score': 0.4456252493563377, 'support': 505716}, '1': {'precision': 0.3072991625398049, 'recall': 0.06134276801407963, 'f1-score': 0.10227041297378843, 'support': 442057}, '2': {'precision': 0.37288575228933263, 'recall': 0.35217373410341185, 'f1-score': 0.3622339138848573, 'support': 510251}, 'accuracy': 0.35481103191717006, 'macro avg': {'precision': 0.343302540868945, 'recall': 0.3425050894077897, 'f1-score': 0.3033765254049945, 'support': 1458024}, 'weighted avg': {'precision': 0.34496650451072747, 'recall': 0.35481103191717006, 'f1-score': 0.3123401174089768, 'support': 1458024}}
[[310509  31078 164129]
 [276857  27117 138083]
 [300506  30048 179697]]
Evaluating performance on  train set...
2222/2222 - 30s - 30s/epoch - 13ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0976259
{'0': {'precision': 0.34585072803176864, 'recall': 0.6261145725255568, 'f1-score': 0.4455759492959224, 'support': 189871}, '1': {'precision': 0.38970771921059205, 'recall': 0.07917897493680909, 'f1-score': 0.13161669169633666, 'support': 197022}, '2': {'precision': 0.32114533631947373, 'recall': 0.3266731232734997, 'f1-score': 0.32388564569807404, 'support': 181726}, 'accuracy': 0.34090665278508103, 'macro avg': {'precision': 0.3522345945206114, 'recall': 0.3439888902452885, 'f1-score': 0.3003594288967777, 'support': 568619}, 'weighted avg': {'precision': 0.3531511877450839, 'recall': 0.34090665278508103, 'f1-score': 0.29790031242411863, 'support': 568619}}
[[118881  11884  59106]
 [115039  15600  66383]
 [109815  12546  59365]]
Evaluating performance on  val set...
641/641 - 9s - 9s/epoch - 13ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0980152
{'0': {'precision': 0.36113535496091065, 'recall': 0.6665010195863392, 'f1-score': 0.4684479612667787, 'support': 58357}, '1': {'precision': 0.3395714419388042, 'recall': 0.06990541868125517, 'f1-score': 0.11594249201277955, 'support': 51913}, '2': {'precision': 0.32817105899951604, 'recall': 0.27844037553427775, 'f1-score': 0.30126722875750994, 'support': 53577}, 'accuracy': 0.3505831660024291, 'macro avg': {'precision': 0.3429592852997436, 'recall': 0.33828227126729077, 'f1-score': 0.29521922734568934, 'support': 163847}, 'weighted avg': {'precision': 0.3435239522410546, 'recall': 0.3505831660024291, 'f1-score': 0.30209362746126533, 'support': 163847}}
[[38895  3696 15766]
 [33510  3629 14774]
 [35297  3362 14918]]

============================================

        Job resource usage summary 

                 Memory (GB)    NCPUs
 Requested  :        96            32
 Used       :        27 (peak)  19.26 (ave)

============================================
