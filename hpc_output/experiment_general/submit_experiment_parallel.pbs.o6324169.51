This machine has 1 visible gpus.
This machine has 1 physical gpus.
getting alphas...
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-07-31.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-07-23.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-07-10.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-07-11.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-07-19.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-07-15.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-07-17.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-07-12.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-08-02.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-07-16.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-07-29.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-07-18.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-07-09.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-07-25.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-07-24.csv
training model: results/QRTEA/W5/deepLOB_L1/h10
Epoch 1/50
589/589 - 32s - loss: 2.8834 - accuracy10: 0.4486 - val_loss: 3.3655 - val_accuracy10: 0.5290 - 32s/epoch - 55ms/step
Epoch 2/50
589/589 - 12s - loss: 2.7536 - accuracy10: 0.4862 - val_loss: 3.2866 - val_accuracy10: 0.5105 - 12s/epoch - 20ms/step
Epoch 3/50
589/589 - 11s - loss: 2.6866 - accuracy10: 0.5102 - val_loss: 3.1684 - val_accuracy10: 0.4741 - 11s/epoch - 19ms/step
Epoch 4/50
589/589 - 11s - loss: 2.6105 - accuracy10: 0.5330 - val_loss: 3.2018 - val_accuracy10: 0.4681 - 11s/epoch - 18ms/step
Epoch 5/50
589/589 - 11s - loss: 2.5449 - accuracy10: 0.5562 - val_loss: 3.2785 - val_accuracy10: 0.5288 - 11s/epoch - 18ms/step
Epoch 6/50
589/589 - 11s - loss: 2.4806 - accuracy10: 0.5916 - val_loss: 3.0641 - val_accuracy10: 0.4943 - 11s/epoch - 19ms/step
Epoch 7/50
589/589 - 10s - loss: 2.4302 - accuracy10: 0.6143 - val_loss: 3.0653 - val_accuracy10: 0.5499 - 10s/epoch - 18ms/step
Epoch 8/50
589/589 - 11s - loss: 2.3914 - accuracy10: 0.6320 - val_loss: 3.0898 - val_accuracy10: 0.5105 - 11s/epoch - 18ms/step
Epoch 9/50
589/589 - 10s - loss: 2.3524 - accuracy10: 0.6451 - val_loss: 3.0088 - val_accuracy10: 0.5650 - 10s/epoch - 18ms/step
Epoch 10/50
589/589 - 10s - loss: 2.3127 - accuracy10: 0.6543 - val_loss: 3.0078 - val_accuracy10: 0.5814 - 10s/epoch - 18ms/step
Epoch 11/50
589/589 - 11s - loss: 2.2749 - accuracy10: 0.6641 - val_loss: 2.9017 - val_accuracy10: 0.6108 - 11s/epoch - 19ms/step
Epoch 12/50
589/589 - 11s - loss: 2.2570 - accuracy10: 0.6670 - val_loss: 3.0211 - val_accuracy10: 0.5774 - 11s/epoch - 19ms/step
Epoch 13/50
589/589 - 11s - loss: 2.2342 - accuracy10: 0.6686 - val_loss: 2.8692 - val_accuracy10: 0.6008 - 11s/epoch - 19ms/step
Epoch 14/50
589/589 - 10s - loss: 2.2257 - accuracy10: 0.6717 - val_loss: 2.9237 - val_accuracy10: 0.6038 - 10s/epoch - 17ms/step
Epoch 15/50
589/589 - 11s - loss: 2.2029 - accuracy10: 0.6731 - val_loss: 2.9180 - val_accuracy10: 0.6207 - 11s/epoch - 18ms/step
Epoch 16/50
589/589 - 11s - loss: 2.1906 - accuracy10: 0.6759 - val_loss: 2.9227 - val_accuracy10: 0.6284 - 11s/epoch - 19ms/step
Epoch 17/50
589/589 - 11s - loss: 2.1756 - accuracy10: 0.6779 - val_loss: 2.9395 - val_accuracy10: 0.5968 - 11s/epoch - 19ms/step
Epoch 18/50
589/589 - 11s - loss: 2.1682 - accuracy10: 0.6762 - val_loss: 3.0162 - val_accuracy10: 0.6032 - 11s/epoch - 19ms/step
Epoch 19/50
589/589 - 11s - loss: 2.1501 - accuracy10: 0.6787 - val_loss: 2.9241 - val_accuracy10: 0.6199 - 11s/epoch - 18ms/step
Epoch 20/50
589/589 - 11s - loss: 2.1412 - accuracy10: 0.6798 - val_loss: 2.9984 - val_accuracy10: 0.5852 - 11s/epoch - 18ms/step
Epoch 21/50
589/589 - 11s - loss: 2.1312 - accuracy10: 0.6790 - val_loss: 2.9093 - val_accuracy10: 0.6096 - 11s/epoch - 18ms/step
Epoch 22/50
589/589 - 10s - loss: 2.1194 - accuracy10: 0.6808 - val_loss: 2.9594 - val_accuracy10: 0.6325 - 10s/epoch - 18ms/step
Epoch 23/50
589/589 - 11s - loss: 2.1096 - accuracy10: 0.6811 - val_loss: 2.9478 - val_accuracy10: 0.6317 - 11s/epoch - 18ms/step
testing model: results/QRTEA/W5/deepLOB_L1/h10
Evaluating performance on  test set...
2185/2185 - 13s - 13s/epoch - 6ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 1.2376887
{'0': {'precision': 0.2900528043385186, 'recall': 0.5031128934437389, 'f1-score': 0.36796675915322746, 'support': 80793}, '1': {'precision': 0.8528341345500964, 'recall': 0.3163037374116391, 'f1-score': 0.4614590470801975, 'support': 397093}, '2': {'precision': 0.2269068030464697, 'recall': 0.7583743236596163, 'f1-score': 0.3493019172495823, 'support': 81320}, 'accuracy': 0.40757967546843205, 'macro avg': {'precision': 0.4565979139783615, 'recall': 0.5259303181716648, 'f1-score': 0.39290924116100245, 'support': 559206}, 'weighted avg': {'precision': 0.6805019303003943, 'recall': 0.40757967546843205, 'f1-score': 0.4316415196997522, 'support': 559206}}
[[ 40648  13455  26690]
 [ 88062 125602 183429]
 [ 11430   8219  61671]]
Evaluating performance on  train set...
589/589 - 4s - 4s/epoch - 7ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 1.0327127
{'0': {'precision': 0.25733530474782323, 'recall': 0.6396602417510617, 'f1-score': 0.3670189085967337, 'support': 12244}, '1': {'precision': 0.9479407854443332, 'recall': 0.5035310174091061, 'f1-score': 0.6577014960952278, 'support': 126026}, '2': {'precision': 0.1755856920450922, 'recall': 0.7536430239111183, 'f1-score': 0.28481455563331, 'support': 12421}, 'accuracy': 0.5352078093582231, 'macro avg': {'precision': 0.46028726074574955, 'recall': 0.6322780943570954, 'f1-score': 0.4365116534417572, 'support': 150691}, 'weighted avg': {'precision': 0.828164580357367, 'recall': 0.5352078093582231, 'f1-score': 0.6033469142767446, 'support': 150691}}
[[ 7832  1917  2495]
 [21111 63458 41457]
 [ 1492  1568  9361]]
Evaluating performance on  val set...
222/222 - 1s - 1s/epoch - 6ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.90396297
{'0': {'precision': 0.2595833936062491, 'recall': 0.6492402315484804, 'f1-score': 0.3708794047742069, 'support': 5528}, '1': {'precision': 0.9260574412532637, 'recall': 0.5859380162558646, 'f1-score': 0.7177432410555286, 'support': 45399}, '2': {'precision': 0.2753777399446691, 'recall': 0.6785527005768223, 'f1-score': 0.39176506206478956, 'support': 5721}, 'accuracy': 0.6014687191074707, 'macro avg': {'precision': 0.48700619160139397, 'recall': 0.6379103161270557, 'f1-score': 0.49346256929817506, 'support': 56648}, 'weighted avg': {'precision': 0.7953060094890502, 'recall': 0.6014687191074707, 'f1-score': 0.6509732853824393, 'support': 56648}}
[[ 3589  1026   913]
 [ 9496 26601  9302]
 [  741  1098  3882]]
training model: results/QRTEA/W5/deepLOB_L1/h20
Epoch 1/50
589/589 - 13s - loss: 2.8657 - accuracy20: 0.4657 - val_loss: 3.3746 - val_accuracy20: 0.5646 - 13s/epoch - 21ms/step
Epoch 2/50
589/589 - 11s - loss: 2.7467 - accuracy20: 0.5013 - val_loss: 3.3609 - val_accuracy20: 0.5213 - 11s/epoch - 18ms/step
Epoch 3/50
589/589 - 10s - loss: 2.7054 - accuracy20: 0.5059 - val_loss: 3.1692 - val_accuracy20: 0.4759 - 10s/epoch - 18ms/step
Epoch 4/50
589/589 - 11s - loss: 2.6178 - accuracy20: 0.5448 - val_loss: 3.2241 - val_accuracy20: 0.5461 - 11s/epoch - 18ms/step
Epoch 5/50
589/589 - 11s - loss: 2.5603 - accuracy20: 0.5712 - val_loss: 3.2152 - val_accuracy20: 0.5989 - 11s/epoch - 19ms/step
Epoch 6/50
589/589 - 10s - loss: 2.5199 - accuracy20: 0.5887 - val_loss: 3.2211 - val_accuracy20: 0.6030 - 10s/epoch - 17ms/step
Epoch 7/50
589/589 - 11s - loss: 2.4814 - accuracy20: 0.6048 - val_loss: 3.1919 - val_accuracy20: 0.6258 - 11s/epoch - 18ms/step
Epoch 8/50
589/589 - 11s - loss: 2.4536 - accuracy20: 0.6141 - val_loss: 3.1442 - val_accuracy20: 0.5998 - 11s/epoch - 18ms/step
Epoch 9/50
589/589 - 10s - loss: 2.4178 - accuracy20: 0.6266 - val_loss: 3.1807 - val_accuracy20: 0.6440 - 10s/epoch - 18ms/step
Epoch 10/50
589/589 - 11s - loss: 2.3856 - accuracy20: 0.6382 - val_loss: 3.1208 - val_accuracy20: 0.6375 - 11s/epoch - 18ms/step
Epoch 11/50
589/589 - 11s - loss: 2.3691 - accuracy20: 0.6400 - val_loss: 3.1070 - val_accuracy20: 0.6282 - 11s/epoch - 18ms/step
Epoch 12/50
589/589 - 11s - loss: 2.3453 - accuracy20: 0.6429 - val_loss: 3.0960 - val_accuracy20: 0.6181 - 11s/epoch - 18ms/step
Epoch 13/50
589/589 - 10s - loss: 2.3245 - accuracy20: 0.6466 - val_loss: 3.0672 - val_accuracy20: 0.6244 - 10s/epoch - 17ms/step
Epoch 14/50
589/589 - 11s - loss: 2.3060 - accuracy20: 0.6495 - val_loss: 3.0862 - val_accuracy20: 0.6335 - 11s/epoch - 19ms/step
Epoch 15/50
589/589 - 11s - loss: 2.2942 - accuracy20: 0.6500 - val_loss: 3.0723 - val_accuracy20: 0.6446 - 11s/epoch - 19ms/step
Epoch 16/50
589/589 - 11s - loss: 2.2829 - accuracy20: 0.6540 - val_loss: 3.0709 - val_accuracy20: 0.6635 - 11s/epoch - 18ms/step
Epoch 17/50
589/589 - 10s - loss: 2.2662 - accuracy20: 0.6546 - val_loss: 3.0808 - val_accuracy20: 0.6349 - 10s/epoch - 17ms/step
Epoch 18/50
589/589 - 11s - loss: 2.2561 - accuracy20: 0.6565 - val_loss: 3.0606 - val_accuracy20: 0.6586 - 11s/epoch - 19ms/step
Epoch 19/50
589/589 - 11s - loss: 2.2387 - accuracy20: 0.6574 - val_loss: 3.0722 - val_accuracy20: 0.6534 - 11s/epoch - 18ms/step
Epoch 20/50
589/589 - 11s - loss: 2.2326 - accuracy20: 0.6571 - val_loss: 3.0549 - val_accuracy20: 0.6228 - 11s/epoch - 19ms/step
Epoch 21/50
589/589 - 11s - loss: 2.2229 - accuracy20: 0.6595 - val_loss: 3.0388 - val_accuracy20: 0.6273 - 11s/epoch - 19ms/step
Epoch 22/50
589/589 - 11s - loss: 2.2169 - accuracy20: 0.6595 - val_loss: 3.0388 - val_accuracy20: 0.6223 - 11s/epoch - 19ms/step
Epoch 23/50
589/589 - 11s - loss: 2.2056 - accuracy20: 0.6619 - val_loss: 3.0842 - val_accuracy20: 0.6402 - 11s/epoch - 18ms/step
Epoch 24/50
589/589 - 10s - loss: 2.1971 - accuracy20: 0.6624 - val_loss: 3.0891 - val_accuracy20: 0.6494 - 10s/epoch - 17ms/step
Epoch 25/50
589/589 - 11s - loss: 2.1887 - accuracy20: 0.6628 - val_loss: 3.0704 - val_accuracy20: 0.6448 - 11s/epoch - 18ms/step
Epoch 26/50
589/589 - 11s - loss: 2.1810 - accuracy20: 0.6647 - val_loss: 3.0963 - val_accuracy20: 0.6141 - 11s/epoch - 18ms/step
Epoch 27/50
589/589 - 10s - loss: 2.1730 - accuracy20: 0.6648 - val_loss: 3.1233 - val_accuracy20: 0.6344 - 10s/epoch - 17ms/step
Epoch 28/50
589/589 - 11s - loss: 2.1650 - accuracy20: 0.6684 - val_loss: 3.0920 - val_accuracy20: 0.6476 - 11s/epoch - 18ms/step
Epoch 29/50
589/589 - 10s - loss: 2.1613 - accuracy20: 0.6668 - val_loss: 3.1212 - val_accuracy20: 0.6240 - 10s/epoch - 17ms/step
Epoch 30/50
589/589 - 11s - loss: 2.1527 - accuracy20: 0.6696 - val_loss: 3.1218 - val_accuracy20: 0.6346 - 11s/epoch - 18ms/step
Epoch 31/50
589/589 - 11s - loss: 2.1461 - accuracy20: 0.6683 - val_loss: 3.0892 - val_accuracy20: 0.6072 - 11s/epoch - 18ms/step
Epoch 32/50
589/589 - 10s - loss: 2.1399 - accuracy20: 0.6703 - val_loss: 3.1227 - val_accuracy20: 0.6240 - 10s/epoch - 17ms/step
testing model: results/QRTEA/W5/deepLOB_L1/h20
Evaluating performance on  test set...
2185/2185 - 13s - 13s/epoch - 6ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 1.3416986
{'0': {'precision': 0.41246368466511374, 'recall': 0.3077388740260501, 'f1-score': 0.35248725060391883, 'support': 102418}, '1': {'precision': 0.7448023570222145, 'recall': 0.2778886150924628, 'f1-score': 0.4047597977374085, 'support': 353872}, '2': {'precision': 0.24422612548145317, 'recall': 0.8323778615569979, 'f1-score': 0.37764753337727064, 'support': 102916}, 'accuracy': 0.38540359009023506, 'macro avg': {'precision': 0.4671640557229271, 'recall': 0.4726684502251703, 'f1-score': 0.37829819390619934, 'support': 559206}, 'weighted avg': {'precision': 0.5918090672672431, 'recall': 0.38540359009023506, 'f1-score': 0.3901964069096891, 'support': 559206}}
[[ 31518  22982  47918]
 [ 38357  98337 217178]
 [  6539  10712  85665]]
Evaluating performance on  train set...
589/589 - 5s - 5s/epoch - 8ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 1.0388454
{'0': {'precision': 0.3941792888848213, 'recall': 0.5144836648151466, 'f1-score': 0.44636749922271735, 'support': 16743}, '1': {'precision': 0.8984052874120786, 'recall': 0.5074230723128821, 'f1-score': 0.6485451342153356, 'support': 116798}, '2': {'precision': 0.21095912199777317, 'recall': 0.7733527696793003, 'f1-score': 0.3314921269682579, 'support': 17150}, 'accuracy': 0.5384727687784937, 'macro avg': {'precision': 0.501181232764891, 'recall': 0.598419835602443, 'f1-score': 0.47546825346877036, 'support': 150691}, 'weighted avg': {'precision': 0.7641440665681184, 'recall': 0.5384727687784937, 'f1-score': 0.5899980463536265, 'support': 150691}}
[[ 8614  3938  4191]
 [12116 59266 45416]
 [ 1123  2764 13263]]
Evaluating performance on  val set...
222/222 - 2s - 2s/epoch - 7ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.8946617
{'0': {'precision': 0.38982716049382715, 'recall': 0.5267583077539036, 'f1-score': 0.4480644795095925, 'support': 7493}, '1': {'precision': 0.8635003124691643, 'recall': 0.6357428260079913, 'f1-score': 0.7323216826131832, 'support': 41295}, '2': {'precision': 0.3181761786600496, 'recall': 0.6525445292620865, 'f1-score': 0.4277731442869057, 'support': 7860}, 'accuracy': 0.6236583815845219, 'macro avg': {'precision': 0.5238345505410137, 'recall': 0.6050152210079939, 'f1-score': 0.5360531021365604, 'support': 56648}, 'weighted avg': {'precision': 0.7251815612424514, 'recall': 0.6236583815845219, 'f1-score': 0.6524655405763992, 'support': 56648}}
[[ 3947  2039  1507]
 [ 5558 26253  9484]
 [  620  2111  5129]]
training model: results/QRTEA/W5/deepLOB_L1/h30
Epoch 1/50
589/589 - 13s - loss: 2.9121 - accuracy30: 0.4493 - val_loss: 3.4372 - val_accuracy30: 0.4118 - 13s/epoch - 21ms/step
Epoch 2/50
589/589 - 11s - loss: 2.7661 - accuracy30: 0.5054 - val_loss: 3.4040 - val_accuracy30: 0.4482 - 11s/epoch - 19ms/step
Epoch 3/50
589/589 - 11s - loss: 2.7168 - accuracy30: 0.5254 - val_loss: 3.2810 - val_accuracy30: 0.4842 - 11s/epoch - 19ms/step
Epoch 4/50
589/589 - 11s - loss: 2.6764 - accuracy30: 0.5442 - val_loss: 3.2772 - val_accuracy30: 0.4898 - 11s/epoch - 19ms/step
Epoch 5/50
589/589 - 10s - loss: 2.6337 - accuracy30: 0.5593 - val_loss: 3.2594 - val_accuracy30: 0.5031 - 10s/epoch - 17ms/step
Epoch 6/50
589/589 - 11s - loss: 2.5945 - accuracy30: 0.5703 - val_loss: 3.2414 - val_accuracy30: 0.5213 - 11s/epoch - 18ms/step
Epoch 7/50
589/589 - 11s - loss: 2.5614 - accuracy30: 0.5842 - val_loss: 3.2760 - val_accuracy30: 0.5469 - 11s/epoch - 19ms/step
Epoch 8/50
589/589 - 11s - loss: 2.5327 - accuracy30: 0.5897 - val_loss: 3.2754 - val_accuracy30: 0.5696 - 11s/epoch - 19ms/step
Epoch 9/50
589/589 - 11s - loss: 2.5170 - accuracy30: 0.5932 - val_loss: 3.3098 - val_accuracy30: 0.5744 - 11s/epoch - 19ms/step
Epoch 10/50
589/589 - 11s - loss: 2.4862 - accuracy30: 0.6009 - val_loss: 3.3847 - val_accuracy30: 0.5720 - 11s/epoch - 19ms/step
Epoch 11/50
589/589 - 11s - loss: 2.4614 - accuracy30: 0.6054 - val_loss: 3.2434 - val_accuracy30: 0.5690 - 11s/epoch - 18ms/step
Epoch 12/50
589/589 - 11s - loss: 2.4409 - accuracy30: 0.6115 - val_loss: 3.3709 - val_accuracy30: 0.5717 - 11s/epoch - 18ms/step
Epoch 13/50
589/589 - 11s - loss: 2.4230 - accuracy30: 0.6135 - val_loss: 3.3332 - val_accuracy30: 0.5819 - 11s/epoch - 18ms/step
Epoch 14/50
589/589 - 10s - loss: 2.4083 - accuracy30: 0.6177 - val_loss: 3.3664 - val_accuracy30: 0.5875 - 10s/epoch - 18ms/step
Epoch 15/50
589/589 - 11s - loss: 2.3925 - accuracy30: 0.6212 - val_loss: 3.3752 - val_accuracy30: 0.6181 - 11s/epoch - 18ms/step
Epoch 16/50
589/589 - 11s - loss: 2.3728 - accuracy30: 0.6246 - val_loss: 3.3287 - val_accuracy30: 0.5909 - 11s/epoch - 18ms/step
testing model: results/QRTEA/W5/deepLOB_L1/h30
Evaluating performance on  test set...
2185/2185 - 14s - 14s/epoch - 6ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.0728
{'0': {'precision': 0.43756790820983094, 'recall': 0.17067588872501652, 'f1-score': 0.245566965047928, 'support': 117978}, '1': {'precision': 0.6470179233621756, 'recall': 0.5450311136453788, 'f1-score': 0.5916617326479534, 'support': 322688}, '2': {'precision': 0.31713097230738635, 'recall': 0.6457229627130082, 'f1-score': 0.42535787321063395, 'support': 118540}, 'accuracy': 0.4873964156321642, 'macro avg': {'precision': 0.46723893462646426, 'recall': 0.45380998836113456, 'f1-score': 0.4208621903021718, 'support': 559206}, 'weighted avg': {'precision': 0.5329002403157168, 'recall': 0.4873964156321642, 'f1-score': 0.4833917427164868, 'support': 559206}}
[[ 20136  58578  39264]
 [ 21257 175875 125556]
 [  4625  37371  76544]]
Evaluating performance on  train set...
589/589 - 4s - 4s/epoch - 7ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.93996304
{'0': {'precision': 0.3856259330347622, 'recall': 0.4468000988386459, 'f1-score': 0.4139652014652015, 'support': 20235}, '1': {'precision': 0.8285928559524471, 'recall': 0.5439345039476323, 'f1-score': 0.6567450052286863, 'support': 109686}, '2': {'precision': 0.2512943050577459, 'recall': 0.6683678382282138, 'f1-score': 0.365258117139399, 'support': 20770}, 'accuracy': 0.548042019762295, 'macro avg': {'precision': 0.48850436468165176, 'recall': 0.5530341470048307, 'f1-score': 0.4786561079444289, 'support': 150691}, 'weighted avg': {'precision': 0.6895405795237135, 'recall': 0.548042019762295, 'f1-score': 0.58396805109892, 'support': 150691}}
[[ 9041  7133  4061]
 [12725 59662 37299]
 [ 1679  5209 13882]]
Evaluating performance on  val set...
222/222 - 1s - 1s/epoch - 7ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.9755327
{'0': {'precision': 0.30862689201113147, 'recall': 0.503376508358242, 'f1-score': 0.3826474795926954, 'support': 9033}, '1': {'precision': 0.7727850615812475, 'recall': 0.5100965068708696, 'f1-score': 0.6145461438817099, 'support': 38132}, '2': {'precision': 0.32666467602269333, 'recall': 0.5768216809026679, 'f1-score': 0.4171114839103248, 'support': 9483}, 'accuracy': 0.520194887727722, 'macro avg': {'precision': 0.46935887653835745, 'recall': 0.5300982320439265, 'f1-score': 0.47143503579491003, 'support': 56648}, 'weighted avg': {'precision': 0.624089602571598, 'recall': 0.520194887727722, 'f1-score': 0.5445169545893904, 'support': 56648}}
[[ 4547  2973  1513]
 [ 8919 19451  9762]
 [ 1267  2746  5470]]
training model: results/QRTEA/W5/deepLOB_L1/h50
Epoch 1/50
589/589 - 14s - loss: 2.9702 - accuracy50: 0.4593 - val_loss: 3.5035 - val_accuracy50: 0.4729 - 14s/epoch - 23ms/step
Epoch 2/50
589/589 - 10s - loss: 2.8857 - accuracy50: 0.4848 - val_loss: 3.4336 - val_accuracy50: 0.4942 - 10s/epoch - 17ms/step
Epoch 3/50
589/589 - 10s - loss: 2.8241 - accuracy50: 0.5183 - val_loss: 3.3554 - val_accuracy50: 0.5052 - 10s/epoch - 18ms/step
Epoch 4/50
589/589 - 10s - loss: 2.7834 - accuracy50: 0.5353 - val_loss: 3.4348 - val_accuracy50: 0.5007 - 10s/epoch - 18ms/step
Epoch 5/50
589/589 - 10s - loss: 2.7605 - accuracy50: 0.5383 - val_loss: 3.4371 - val_accuracy50: 0.5101 - 10s/epoch - 18ms/step
Epoch 6/50
589/589 - 10s - loss: 2.7313 - accuracy50: 0.5507 - val_loss: 3.5059 - val_accuracy50: 0.5295 - 10s/epoch - 18ms/step
Epoch 7/50
589/589 - 10s - loss: 2.7078 - accuracy50: 0.5579 - val_loss: 3.5085 - val_accuracy50: 0.5301 - 10s/epoch - 17ms/step
Epoch 8/50
589/589 - 10s - loss: 2.6882 - accuracy50: 0.5626 - val_loss: 3.4874 - val_accuracy50: 0.5115 - 10s/epoch - 18ms/step
Epoch 9/50
589/589 - 11s - loss: 2.6688 - accuracy50: 0.5699 - val_loss: 3.3788 - val_accuracy50: 0.5294 - 11s/epoch - 18ms/step
Epoch 10/50
589/589 - 10s - loss: 2.6491 - accuracy50: 0.5746 - val_loss: 3.4663 - val_accuracy50: 0.5487 - 10s/epoch - 17ms/step
Epoch 11/50
589/589 - 11s - loss: 2.6310 - accuracy50: 0.5777 - val_loss: 3.4950 - val_accuracy50: 0.5492 - 11s/epoch - 19ms/step
Epoch 12/50
589/589 - 11s - loss: 2.6098 - accuracy50: 0.5810 - val_loss: 3.5551 - val_accuracy50: 0.5510 - 11s/epoch - 18ms/step
Epoch 13/50
589/589 - 11s - loss: 2.5951 - accuracy50: 0.5882 - val_loss: 3.5219 - val_accuracy50: 0.5395 - 11s/epoch - 18ms/step
testing model: results/QRTEA/W5/deepLOB_L1/h50
Evaluating performance on  test set...
2185/2185 - 14s - 14s/epoch - 6ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.1491573
{'0': {'precision': 0.48517827529021557, 'recall': 0.19649628499867072, 'f1-score': 0.2797103902958839, 'support': 142934}, '1': {'precision': 0.5421305294080768, 'recall': 0.4437785011510433, 'f1-score': 0.4880488286682981, 'support': 272796}, '2': {'precision': 0.34870077550609324, 'recall': 0.6756739803172656, 'f1-score': 0.4600036062711156, 'support': 143476}, 'accuracy': 0.44007038551088506, 'macro avg': {'precision': 0.45866986006812854, 'recall': 0.4386495888223265, 'f1-score': 0.40925427507843254, 'support': 559206}, 'weighted avg': {'precision': 0.47794498622555837, 'recall': 0.44007038551088506, 'f1-score': 0.42760158261052905, 'support': 559206}}
[[ 28086  62330  52518]
 [ 23184 121061 128551]
 [  6618  39915  96943]]
Evaluating performance on  train set...
589/589 - 4s - 4s/epoch - 8ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.9935519
{'0': {'precision': 0.4261515720506572, 'recall': 0.40488119638654824, 'f1-score': 0.4152441754092298, 'support': 26346}, '1': {'precision': 0.7400031452385377, 'recall': 0.531061795274298, 'f1-score': 0.6183592770019234, 'support': 97467}, '2': {'precision': 0.29081183924757237, 'recall': 0.6027978272192871, 'f1-score': 0.3923429913670981, 'support': 26878}, 'accuracy': 0.5217962585688595, 'macro avg': {'precision': 0.4856555188455891, 'recall': 0.5129136062933778, 'f1-score': 0.47531548125941714, 'support': 150691}, 'weighted avg': {'precision': 0.60501102580451, 'recall': 0.5217962585688595, 'f1-score': 0.5425343359513369, 'support': 150691}}
[[10667  9596  6083]
 [12278 51761 33428]
 [ 2086  8590 16202]]
Evaluating performance on  val set...
222/222 - 2s - 2s/epoch - 7ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.007793
{'0': {'precision': 0.37292033004193154, 'recall': 0.47448584459168747, 'f1-score': 0.417616541068656, 'support': 11621}, '1': {'precision': 0.6728021216799271, 'recall': 0.518059069157853, 'f1-score': 0.5853767736602837, 'support': 32809}, '2': {'precision': 0.37170913910476533, 'recall': 0.5049926338189556, 'f1-score': 0.4282194537946351, 'support': 12218}, 'accuracy': 0.5063020759779692, 'macro avg': {'precision': 0.47247719694220797, 'recall': 0.49917918252283205, 'f1-score': 0.4770709228411916, 'support': 56648}, 'weighted avg': {'precision': 0.546342575681331, 'recall': 0.5063020759779692, 'f1-score': 0.517065627687508, 'support': 56648}}
[[ 5514  3885  2222]
 [ 7605 16997  8207]
 [ 1667  4381  6170]]
training model: results/QRTEA/W5/deepLOB_L1/h100
Epoch 1/50
589/589 - 13s - loss: 3.0891 - accuracy100: 0.4466 - val_loss: 3.6269 - val_accuracy100: 0.4235 - 13s/epoch - 22ms/step
Epoch 2/50
589/589 - 11s - loss: 3.0326 - accuracy100: 0.4682 - val_loss: 3.4938 - val_accuracy100: 0.4278 - 11s/epoch - 19ms/step
Epoch 3/50
589/589 - 11s - loss: 2.9960 - accuracy100: 0.4863 - val_loss: 3.5175 - val_accuracy100: 0.4496 - 11s/epoch - 19ms/step
Epoch 4/50
589/589 - 11s - loss: 2.9703 - accuracy100: 0.4930 - val_loss: 3.5564 - val_accuracy100: 0.4294 - 11s/epoch - 19ms/step
Epoch 5/50
589/589 - 11s - loss: 2.9495 - accuracy100: 0.5027 - val_loss: 3.4853 - val_accuracy100: 0.4437 - 11s/epoch - 19ms/step
Epoch 6/50
589/589 - 11s - loss: 2.9326 - accuracy100: 0.5088 - val_loss: 3.5548 - val_accuracy100: 0.4412 - 11s/epoch - 19ms/step
Epoch 7/50
589/589 - 11s - loss: 2.9201 - accuracy100: 0.5104 - val_loss: 3.5409 - val_accuracy100: 0.4395 - 11s/epoch - 19ms/step
Epoch 8/50
589/589 - 10s - loss: 2.9049 - accuracy100: 0.5186 - val_loss: 3.6067 - val_accuracy100: 0.4405 - 10s/epoch - 17ms/step
Epoch 9/50
589/589 - 11s - loss: 2.8950 - accuracy100: 0.5238 - val_loss: 3.6415 - val_accuracy100: 0.4221 - 11s/epoch - 18ms/step
Epoch 10/50
589/589 - 10s - loss: 2.8842 - accuracy100: 0.5266 - val_loss: 3.6376 - val_accuracy100: 0.4284 - 10s/epoch - 17ms/step
Epoch 11/50
589/589 - 11s - loss: 2.8746 - accuracy100: 0.5291 - val_loss: 3.6484 - val_accuracy100: 0.4260 - 11s/epoch - 18ms/step
Epoch 12/50
589/589 - 10s - loss: 2.8682 - accuracy100: 0.5304 - val_loss: 3.6491 - val_accuracy100: 0.4255 - 10s/epoch - 17ms/step
Epoch 13/50
589/589 - 10s - loss: 2.8608 - accuracy100: 0.5316 - val_loss: 3.6717 - val_accuracy100: 0.4205 - 10s/epoch - 18ms/step
Epoch 14/50
589/589 - 11s - loss: 2.8547 - accuracy100: 0.5312 - val_loss: 3.6132 - val_accuracy100: 0.4233 - 11s/epoch - 19ms/step
Epoch 15/50
589/589 - 11s - loss: 2.8467 - accuracy100: 0.5357 - val_loss: 3.6351 - val_accuracy100: 0.4249 - 11s/epoch - 18ms/step
testing model: results/QRTEA/W5/deepLOB_L1/h100
Evaluating performance on  test set...
2185/2185 - 13s - 13s/epoch - 6ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.2297958
{'0': {'precision': 0.526677468014973, 'recall': 0.1527959371116754, 'f1-score': 0.23687219153471506, 'support': 185090}, '1': {'precision': 0.3189149142303528, 'recall': 0.26122677621137147, 'f1-score': 0.28720264825887243, 'support': 192798}, '2': {'precision': 0.3670516073719885, 'recall': 0.7036367045742838, 'f1-score': 0.4824391572005505, 'support': 181318}, 'accuracy': 0.36878538499229263, 'macro avg': {'precision': 0.40421466320577143, 'recall': 0.3725531392991102, 'f1-score': 0.33550466566471265, 'support': 559206}, 'weighted avg': {'precision': 0.40328958118144137, 'recall': 0.36878538499229263, 'f1-score': 0.33384776489426776, 'support': 559206}}
[[ 28281  64312  92497]
 [ 14927  50364 127507]
 [ 10489  43247 127582]]
Evaluating performance on  train set...
589/589 - 4s - 4s/epoch - 7ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0835078
{'0': {'precision': 0.48805076916897616, 'recall': 0.3284941876182752, 'f1-score': 0.392683439171393, 'support': 36990}, '1': {'precision': 0.5167699530516432, 'recall': 0.3624270681048902, 'f1-score': 0.42605107720414626, 'support': 75927}, '2': {'precision': 0.3039396779885311, 'recall': 0.5837083708370837, 'f1-score': 0.39973531064740114, 'support': 37774}, 'accuracy': 0.40956659654524824, 'macro avg': {'precision': 0.4362534667363835, 'recall': 0.4248765421867497, 'f1-score': 0.4061566090076468, 'support': 150691}, 'weighted avg': {'precision': 0.45636970736972554, 'recall': 0.40956659654524824, 'f1-score': 0.4112637262890549, 'support': 150691}}
[[12151 13883 10956]
 [ 8870 27518 39539]
 [ 3876 11849 22049]]
Evaluating performance on  val set...
222/222 - 2s - 2s/epoch - 7ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0802472
{'0': {'precision': 0.4270610446821901, 'recall': 0.4186821322803554, 'f1-score': 0.42283008287120694, 'support': 16208}, '1': {'precision': 0.472838594815233, 'recall': 0.46030605343253295, 'f1-score': 0.46648816536360715, 'support': 23656}, '2': {'precision': 0.41564668057984094, 'recall': 0.4390490943755958, 'f1-score': 0.42702749688523167, 'support': 16784}, 'accuracy': 0.44209857364778987, 'macro avg': {'precision': 0.43851544002575465, 'recall': 0.4393457600294947, 'f1-score': 0.43878191504001524, 'support': 56648}, 'weighted avg': {'precision': 0.4427956697149086, 'recall': 0.44209857364778987, 'f1-score': 0.4423051745999813, 'support': 56648}}
[[ 6786  5901  3521]
 [ 5928 10889  6839]
 [ 3176  6239  7369]]
training model: results/QRTEA/W5/deepLOB_L1/h200
Epoch 1/50
589/589 - 12s - loss: 3.2114 - accuracy200: 0.4254 - val_loss: 3.4257 - val_accuracy200: 0.3614 - 12s/epoch - 21ms/step
Epoch 2/50
589/589 - 11s - loss: 3.1622 - accuracy200: 0.4425 - val_loss: 3.3601 - val_accuracy200: 0.3927 - 11s/epoch - 19ms/step
Epoch 3/50
589/589 - 11s - loss: 3.1424 - accuracy200: 0.4464 - val_loss: 3.3214 - val_accuracy200: 0.3882 - 11s/epoch - 19ms/step
Epoch 4/50
589/589 - 11s - loss: 3.1193 - accuracy200: 0.4552 - val_loss: 3.3212 - val_accuracy200: 0.4000 - 11s/epoch - 18ms/step
Epoch 5/50
589/589 - 12s - loss: 3.1054 - accuracy200: 0.4608 - val_loss: 3.3312 - val_accuracy200: 0.3976 - 12s/epoch - 20ms/step
Epoch 6/50
589/589 - 11s - loss: 3.0977 - accuracy200: 0.4611 - val_loss: 3.3382 - val_accuracy200: 0.4062 - 11s/epoch - 19ms/step
Epoch 7/50
589/589 - 11s - loss: 3.0861 - accuracy200: 0.4671 - val_loss: 3.3164 - val_accuracy200: 0.4080 - 11s/epoch - 18ms/step
Epoch 8/50
589/589 - 11s - loss: 3.0744 - accuracy200: 0.4702 - val_loss: 3.3202 - val_accuracy200: 0.4095 - 11s/epoch - 18ms/step
Epoch 9/50
589/589 - 11s - loss: 3.0647 - accuracy200: 0.4729 - val_loss: 3.3545 - val_accuracy200: 0.4026 - 11s/epoch - 18ms/step
Epoch 10/50
589/589 - 10s - loss: 3.0555 - accuracy200: 0.4774 - val_loss: 3.3881 - val_accuracy200: 0.3899 - 10s/epoch - 18ms/step
Epoch 11/50
589/589 - 10s - loss: 3.0488 - accuracy200: 0.4781 - val_loss: 3.4091 - val_accuracy200: 0.3870 - 10s/epoch - 17ms/step
Epoch 12/50
589/589 - 10s - loss: 3.0455 - accuracy200: 0.4784 - val_loss: 3.4019 - val_accuracy200: 0.3909 - 10s/epoch - 18ms/step
Epoch 13/50
589/589 - 10s - loss: 3.0406 - accuracy200: 0.4810 - val_loss: 3.3898 - val_accuracy200: 0.3971 - 10s/epoch - 18ms/step
Epoch 14/50
589/589 - 10s - loss: 3.0347 - accuracy200: 0.4824 - val_loss: 3.4338 - val_accuracy200: 0.3928 - 10s/epoch - 17ms/step
Epoch 15/50
589/589 - 11s - loss: 3.0300 - accuracy200: 0.4846 - val_loss: 3.4139 - val_accuracy200: 0.3890 - 11s/epoch - 18ms/step
Epoch 16/50
589/589 - 10s - loss: 3.0220 - accuracy200: 0.4867 - val_loss: 3.4030 - val_accuracy200: 0.3839 - 10s/epoch - 18ms/step
Epoch 17/50
589/589 - 11s - loss: 3.0207 - accuracy200: 0.4888 - val_loss: 3.3748 - val_accuracy200: 0.3860 - 11s/epoch - 19ms/step
testing model: results/QRTEA/W5/deepLOB_L1/h200
Evaluating performance on  test set...
2185/2185 - 13s - 13s/epoch - 6ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.131976
{'0': {'precision': 0.514769642205924, 'recall': 0.23175398030711417, 'f1-score': 0.31961457059025167, 'support': 219267}, '1': {'precision': 0.24902684433394195, 'recall': 0.25855086960730533, 'f1-score': 0.2536995040942894, 'support': 123964}, '2': {'precision': 0.42847024428470243, 'recall': 0.6582243315198518, 'f1-score': 0.5190594420914268, 'support': 215975}, 'accuracy': 0.4024044806386198, 'macro avg': {'precision': 0.3974222436081895, 'recall': 0.3828430604780904, 'f1-score': 0.36412450559198933, 'support': 559206}, 'weighted avg': {'precision': 0.42252983672916195, 'recall': 0.4024044806386198, 'f1-score': 0.3820316598549606, 'support': 559206}}
[[ 50816  50436 118015]
 [ 20303  32051  71610]
 [ 27597  46218 142160]]
Evaluating performance on  train set...
589/589 - 4s - 4s/epoch - 7ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0683464
{'0': {'precision': 0.49479731194450466, 'recall': 0.29471894637169666, 'f1-score': 0.36940630647641143, 'support': 46468}, '1': {'precision': 0.44957466918714556, 'recall': 0.34539348279931015, 'f1-score': 0.3906575637800934, 'support': 55085}, '2': {'precision': 0.38408536056411335, 'recall': 0.6307338516016118, 'f1-score': 0.4774360514823116, 'support': 49138}, 'accuracy': 0.42281224492504527, 'macro avg': {'precision': 0.4428191138985878, 'recall': 0.42361542692420623, 'f1-score': 0.41249997391293886, 'support': 150691}, 'weighted avg': {'precision': 0.44216475165079905, 'recall': 0.42281224492504527, 'f1-score': 0.41240151600235025, 'support': 150691}}
[[13695 11456 21317]
 [ 7676 19026 28383]
 [ 6307 11838 30993]]
Evaluating performance on  val set...
222/222 - 1s - 1s/epoch - 6ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0949576
{'0': {'precision': 0.41175667682788114, 'recall': 0.46095859012886464, 'f1-score': 0.43497068153417284, 'support': 19633}, '1': {'precision': 0.35056056877221764, 'recall': 0.3102426039082824, 'f1-score': 0.32917161472542283, 'support': 16529}, '2': {'precision': 0.44339104835088067, 'recall': 0.4337596407302548, 'f1-score': 0.4385224665038122, 'support': 20486}, 'accuracy': 0.40714588334980933, 'macro avg': {'precision': 0.40190276465032654, 'recall': 0.401653611589134, 'f1-score': 0.40088825425446933, 'support': 56648}, 'weighted avg': {'precision': 0.4053407621436576, 'recall': 0.40714588334980933, 'f1-score': 0.4053846253910823, 'support': 56648}}
[[9050 4392 6191]
 [6437 5128 4964]
 [6492 5108 8886]]
training model: results/QRTEA/W5/deepLOB_L1/h300
Epoch 1/50
589/589 - 13s - loss: 3.2512 - accuracy300: 0.4069 - val_loss: 3.3160 - val_accuracy300: 0.3839 - 13s/epoch - 22ms/step
Epoch 2/50
589/589 - 11s - loss: 3.2139 - accuracy300: 0.4230 - val_loss: 3.3446 - val_accuracy300: 0.3886 - 11s/epoch - 19ms/step
Epoch 3/50
589/589 - 11s - loss: 3.1896 - accuracy300: 0.4316 - val_loss: 3.3649 - val_accuracy300: 0.3805 - 11s/epoch - 19ms/step
Epoch 4/50
589/589 - 11s - loss: 3.1766 - accuracy300: 0.4359 - val_loss: 3.3338 - val_accuracy300: 0.3918 - 11s/epoch - 19ms/step
Epoch 5/50
589/589 - 11s - loss: 3.1563 - accuracy300: 0.4468 - val_loss: 3.3690 - val_accuracy300: 0.3838 - 11s/epoch - 18ms/step
Epoch 6/50
589/589 - 10s - loss: 3.1452 - accuracy300: 0.4479 - val_loss: 3.3656 - val_accuracy300: 0.3825 - 10s/epoch - 17ms/step
Epoch 7/50
589/589 - 11s - loss: 3.1379 - accuracy300: 0.4503 - val_loss: 3.4112 - val_accuracy300: 0.3779 - 11s/epoch - 18ms/step
Epoch 8/50
589/589 - 11s - loss: 3.1293 - accuracy300: 0.4537 - val_loss: 3.3766 - val_accuracy300: 0.3883 - 11s/epoch - 18ms/step
Epoch 9/50
589/589 - 10s - loss: 3.1247 - accuracy300: 0.4547 - val_loss: 3.3972 - val_accuracy300: 0.3886 - 10s/epoch - 17ms/step
Epoch 10/50
589/589 - 11s - loss: 3.1154 - accuracy300: 0.4596 - val_loss: 3.3297 - val_accuracy300: 0.3931 - 11s/epoch - 18ms/step
Epoch 11/50
589/589 - 11s - loss: 3.1100 - accuracy300: 0.4616 - val_loss: 3.3879 - val_accuracy300: 0.3869 - 11s/epoch - 18ms/step
testing model: results/QRTEA/W5/deepLOB_L1/h300
Evaluating performance on  test set...
2185/2185 - 13s - 13s/epoch - 6ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1098682
{'0': {'precision': 0.47817229336437717, 'recall': 0.14016253591954023, 'f1-score': 0.21678171136511995, 'support': 222720}, '1': {'precision': 0.2369856858591694, 'recall': 0.03173375278272006, 'f1-score': 0.05597246857991844, 'support': 116343}, '2': {'precision': 0.4065848146622821, 'recall': 0.8834575707608237, 'f1-score': 0.5568815981995343, 'support': 220143}, 'accuracy': 0.410217343876854, 'macro avg': {'precision': 0.37391426462860955, 'recall': 0.351784619821028, 'f1-score': 0.27654525938152424, 'support': 559206}, 'weighted avg': {'precision': 0.3998114463761587, 'recall': 0.410217343876854, 'f1-score': 0.317212643175633, 'support': 559206}}
[[ 31217   6453 185050]
 [ 13845   3692  98806]
 [ 20222   5434 194487]]
Evaluating performance on  train set...
589/589 - 4s - 4s/epoch - 6ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.131781
{'0': {'precision': 0.41842209499117783, 'recall': 0.2380025807508756, 'f1-score': 0.30341802229939685, 'support': 48823}, '1': {'precision': 0.35271867612293145, 'recall': 0.10622673366016396, 'f1-score': 0.16327934463135516, 'support': 49159}, '2': {'precision': 0.36635064514637194, 'recall': 0.75144662201901, 'f1-score': 0.492563299010098, 'support': 52709}, 'accuracy': 0.374607640801375, 'macro avg': {'precision': 0.3791638054201604, 'recall': 0.3652253121433498, 'f1-score': 0.31975355531361666, 'support': 150691}, 'weighted avg': {'precision': 0.3787744158463451, 'recall': 0.374607640801375, 'f1-score': 0.32386105562362383, 'support': 150691}}
[[11620  4679 32524]
 [ 7954  5222 35983]
 [ 8197  4904 39608]]
Evaluating performance on  val set...
222/222 - 1s - 1s/epoch - 6ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1020355
{'0': {'precision': 0.3839710104004894, 'recall': 0.4050136510300323, 'f1-score': 0.3942117215055322, 'support': 20145}, '1': {'precision': 0.29322065037663053, 'recall': 0.10549973558963512, 'f1-score': 0.1551698993729036, 'support': 15128}, '2': {'precision': 0.3996862064361063, 'recall': 0.5601403508771929, 'f1-score': 0.46650172410434243, 'support': 21375}, 'accuracy': 0.3835616438356164, 'macro avg': {'precision': 0.3589592890710754, 'recall': 0.3568845791656201, 'f1-score': 0.33862778166092605, 'support': 56648}, 'weighted avg': {'precision': 0.36566570163090134, 'recall': 0.3835616438356164, 'f1-score': 0.35765216283315476, 'support': 56648}}
[[ 8159  1645 10341]
 [ 5890  1596  7642]
 [ 7200  2202 11973]]
training model: results/QRTEA/W5/deepLOB_L1/h500
Epoch 1/50
589/589 - 14s - loss: 3.2890 - accuracy500: 0.3868 - val_loss: 3.4729 - val_accuracy500: 0.3485 - 14s/epoch - 24ms/step
Epoch 2/50
589/589 - 12s - loss: 3.2569 - accuracy500: 0.4009 - val_loss: 3.4254 - val_accuracy500: 0.3561 - 12s/epoch - 20ms/step
Epoch 3/50
589/589 - 12s - loss: 3.2424 - accuracy500: 0.4092 - val_loss: 3.3838 - val_accuracy500: 0.3631 - 12s/epoch - 20ms/step
Epoch 4/50
589/589 - 11s - loss: 3.2324 - accuracy500: 0.4169 - val_loss: 3.3558 - val_accuracy500: 0.3732 - 11s/epoch - 19ms/step
Epoch 5/50
589/589 - 11s - loss: 3.2168 - accuracy500: 0.4217 - val_loss: 3.3890 - val_accuracy500: 0.3631 - 11s/epoch - 19ms/step
Epoch 6/50
589/589 - 11s - loss: 3.2062 - accuracy500: 0.4265 - val_loss: 3.4035 - val_accuracy500: 0.3555 - 11s/epoch - 18ms/step
Epoch 7/50
589/589 - 10s - loss: 3.1944 - accuracy500: 0.4309 - val_loss: 3.3821 - val_accuracy500: 0.3540 - 10s/epoch - 17ms/step
Epoch 8/50
589/589 - 11s - loss: 3.1855 - accuracy500: 0.4353 - val_loss: 3.4130 - val_accuracy500: 0.3534 - 11s/epoch - 19ms/step
Epoch 9/50
589/589 - 11s - loss: 3.1896 - accuracy500: 0.4331 - val_loss: 3.3999 - val_accuracy500: 0.3578 - 11s/epoch - 18ms/step
Epoch 10/50
589/589 - 10s - loss: 3.1845 - accuracy500: 0.4338 - val_loss: 3.4285 - val_accuracy500: 0.3628 - 10s/epoch - 18ms/step
Epoch 11/50
589/589 - 10s - loss: 3.1842 - accuracy500: 0.4359 - val_loss: 3.4594 - val_accuracy500: 0.3625 - 10s/epoch - 17ms/step
Epoch 12/50
589/589 - 11s - loss: 3.1703 - accuracy500: 0.4432 - val_loss: 3.4913 - val_accuracy500: 0.3628 - 11s/epoch - 18ms/step
Epoch 13/50
589/589 - 11s - loss: 3.1652 - accuracy500: 0.4426 - val_loss: 3.5196 - val_accuracy500: 0.3627 - 11s/epoch - 19ms/step
Epoch 14/50
589/589 - 11s - loss: 3.1537 - accuracy500: 0.4485 - val_loss: 3.5477 - val_accuracy500: 0.3643 - 11s/epoch - 18ms/step
testing model: results/QRTEA/W5/deepLOB_L1/h500
Evaluating performance on  test set...
2185/2185 - 15s - 15s/epoch - 7ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1330411
{'0': {'precision': 0.40317757009345795, 'recall': 0.010097747317566429, 'f1-score': 0.019702048757318624, 'support': 213612}, '1': {'precision': 0.3066276560424967, 'recall': 0.10799216568981393, 'f1-score': 0.1597289029649887, 'support': 136834}, '2': {'precision': 0.3795484748765979, 'recall': 0.9193523663537077, 'f1-score': 0.5372831819759694, 'support': 208760}, 'accuracy': 0.37349027013301, 'macro avg': {'precision': 0.3631179003375175, 'recall': 0.34581409312036265, 'f1-score': 0.23890471123275892, 'support': 559206}, 'weighted avg': {'precision': 0.3707313501732122, 'recall': 0.37349027013301, 'f1-score': 0.24718650339367418, 'support': 559206}}
[[  2157  18536 192919]
 [  1236  14777 120821]
 [  1957  14879 191924]]
Evaluating performance on  train set...
589/589 - 4s - 4s/epoch - 7ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1146042
{'0': {'precision': 0.3711576193590582, 'recall': 0.06943028424615635, 'f1-score': 0.11697815033667719, 'support': 49042}, '1': {'precision': 0.3823081241478868, 'recall': 0.10027345393352965, 'f1-score': 0.1588761685747138, 'support': 47540}, '2': {'precision': 0.3684752960138863, 'recall': 0.8788001995971095, 'f1-score': 0.5192375939767521, 'support': 54109}, 'accuracy': 0.3697831987311784, 'macro avg': {'precision': 0.37398034650694373, 'recall': 0.3495013125922652, 'f1-score': 0.265030637629381, 'support': 150691}, 'weighted avg': {'precision': 0.3737122322010793, 'recall': 0.3697831987311784, 'f1-score': 0.27463645788627916, 'support': 150691}}
[[ 3405  4223 41414]
 [ 2690  4767 40083]
 [ 3079  3479 47551]]
Evaluating performance on  val set...
222/222 - 2s - 2s/epoch - 7ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1156578
{'0': {'precision': 0.36340318707705743, 'recall': 0.33271709803137806, 'f1-score': 0.34738379675517767, 'support': 20014}, '1': {'precision': 0.36369131573644975, 'recall': 0.11286893446723362, 'f1-score': 0.17227392030541638, 'support': 15992}, '2': {'precision': 0.3824225892509217, 'recall': 0.6180602654781513, 'f1-score': 0.4724922689480214, 'support': 20642}, 'accuracy': 0.37462928964835474, 'macro avg': {'precision': 0.36983903068814294, 'recall': 0.3545487659922543, 'f1-score': 0.3307166620028718, 'support': 56648}, 'weighted avg': {'precision': 0.3704150189721624, 'recall': 0.37462928964835474, 'f1-score': 0.3435377993469743, 'support': 56648}}
[[ 6659  1701 11654]
 [ 5238  1805  8949]
 [ 6427  1457 12758]]
training model: results/QRTEA/W5/deepLOB_L1/h1000
Epoch 1/50
589/589 - 14s - loss: 3.2596 - accuracy1000: 0.4089 - val_loss: 3.5167 - val_accuracy1000: 0.3916 - 14s/epoch - 24ms/step
Epoch 2/50
589/589 - 11s - loss: 3.2256 - accuracy1000: 0.4193 - val_loss: 3.4924 - val_accuracy1000: 0.3806 - 11s/epoch - 19ms/step
Epoch 3/50
589/589 - 12s - loss: 3.2118 - accuracy1000: 0.4265 - val_loss: 3.4701 - val_accuracy1000: 0.3671 - 12s/epoch - 20ms/step
Epoch 4/50
589/589 - 11s - loss: 3.1939 - accuracy1000: 0.4348 - val_loss: 3.4524 - val_accuracy1000: 0.3792 - 11s/epoch - 19ms/step
Epoch 5/50
589/589 - 11s - loss: 3.1828 - accuracy1000: 0.4409 - val_loss: 3.4457 - val_accuracy1000: 0.3730 - 11s/epoch - 19ms/step
Epoch 6/50
589/589 - 11s - loss: 3.1669 - accuracy1000: 0.4491 - val_loss: 3.4796 - val_accuracy1000: 0.3588 - 11s/epoch - 19ms/step
Epoch 7/50
589/589 - 10s - loss: 3.1513 - accuracy1000: 0.4540 - val_loss: 3.4610 - val_accuracy1000: 0.3592 - 10s/epoch - 17ms/step
Epoch 8/50
589/589 - 10s - loss: 3.1403 - accuracy1000: 0.4572 - val_loss: 3.4515 - val_accuracy1000: 0.3601 - 10s/epoch - 17ms/step
Epoch 9/50
589/589 - 10s - loss: 3.1320 - accuracy1000: 0.4618 - val_loss: 3.4963 - val_accuracy1000: 0.3604 - 10s/epoch - 17ms/step
Epoch 10/50
589/589 - 11s - loss: 3.1183 - accuracy1000: 0.4650 - val_loss: 3.5118 - val_accuracy1000: 0.3517 - 11s/epoch - 18ms/step
Epoch 11/50
589/589 - 10s - loss: 3.1033 - accuracy1000: 0.4719 - val_loss: 3.5740 - val_accuracy1000: 0.3461 - 10s/epoch - 17ms/step
Epoch 12/50
589/589 - 10s - loss: 3.0974 - accuracy1000: 0.4704 - val_loss: 3.6043 - val_accuracy1000: 0.3483 - 10s/epoch - 17ms/step
Epoch 13/50
589/589 - 11s - loss: 3.0846 - accuracy1000: 0.4762 - val_loss: 3.5427 - val_accuracy1000: 0.3518 - 11s/epoch - 18ms/step
Epoch 14/50
589/589 - 11s - loss: 3.0852 - accuracy1000: 0.4771 - val_loss: 3.5335 - val_accuracy1000: 0.3489 - 11s/epoch - 18ms/step
Epoch 15/50
589/589 - 11s - loss: 3.0776 - accuracy1000: 0.4793 - val_loss: 3.5704 - val_accuracy1000: 0.3473 - 11s/epoch - 19ms/step
testing model: results/QRTEA/W5/deepLOB_L1/h1000
Evaluating performance on  test set...
2185/2185 - 14s - 14s/epoch - 6ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1499287
{'0': {'precision': 0.3141891891891892, 'recall': 0.0009980200569837258, 'f1-score': 0.0019897197811308237, 'support': 186369}, '1': {'precision': 0.3111777363362502, 'recall': 0.5858418360457391, 'f1-score': 0.4064592167319046, 'support': 185137}, '2': {'precision': 0.3152658237489527, 'recall': 0.3528289824187533, 'f1-score': 0.33299142204925536, 'support': 187700}, 'accuracy': 0.3127166017532001, 'macro avg': {'precision': 0.31354424975813067, 'recall': 0.3132229461738254, 'f1-score': 0.24714678618743027, 'support': 559206}, 'weighted avg': {'precision': 0.3135535611022821, 'recall': 0.3127166017532001, 'f1-score': 0.24700012520006837, 'support': 559206}}
[[   186 118785  67398]
 [   236 108461  76440]
 [   170 121304  66226]]
Evaluating performance on  train set...
589/589 - 4s - 4s/epoch - 7ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1450183
{'0': {'precision': 0.25925925925925924, 'recall': 0.0002892083953065609, 'f1-score': 0.0005777722751846809, 'support': 48408}, '1': {'precision': 0.3374654577335834, 'recall': 0.6229488046217196, 'f1-score': 0.4377771379211056, 'support': 48813}, '2': {'precision': 0.38214108706426564, 'recall': 0.4325977183467365, 'f1-score': 0.40580701754385967, 'support': 53470}, 'accuracy': 0.3553828695807978, 'macro avg': {'precision': 0.3262886013523694, 'recall': 0.3519452437879209, 'f1-score': 0.2813873092467167, 'support': 150691}, 'weighted avg': {'precision': 0.3281948327099688, 'recall': 0.3553828695807978, 'f1-score': 0.285987122400875, 'support': 150691}}
[[   14 29382 19012]
 [   18 30408 18387]
 [   22 30317 23131]]
Evaluating performance on  val set...
222/222 - 2s - 2s/epoch - 8ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1457875
{'0': {'precision': 0.23076923076923078, 'recall': 0.00017590149516270889, 'f1-score': 0.00035153503632528706, 'support': 17055}, '1': {'precision': 0.3877929641632615, 'recall': 0.7414242097701149, 'f1-score': 0.5092361303851729, 'support': 22272}, '2': {'precision': 0.3281149932398776, 'recall': 0.26620864846140524, 'f1-score': 0.2939376553834385, 'support': 17321}, 'accuracy': 0.3729522666290072, 'macro avg': {'precision': 0.31555906272412326, 'recall': 0.3359362532422276, 'f1-score': 0.26784177360164557, 'support': 56648}, 'weighted avg': {'precision': 0.3222704054251043, 'recall': 0.3729522666290072, 'f1-score': 0.2901955347916897, 'support': 56648}}
[[    3 13363  3689]
 [    6 16513  5753]
 [    4 12706  4611]]
training model: results/QRTEA/W5/deepOF_L1/h10
Epoch 1/50
589/589 - 12s - loss: 3.0007 - accuracy10: 0.4466 - val_loss: 3.3131 - val_accuracy10: 0.5664 - 12s/epoch - 21ms/step
Epoch 2/50
589/589 - 9s - loss: 2.8572 - accuracy10: 0.4850 - val_loss: 3.2561 - val_accuracy10: 0.5779 - 9s/epoch - 15ms/step
Epoch 3/50
589/589 - 10s - loss: 2.8109 - accuracy10: 0.5057 - val_loss: 3.2105 - val_accuracy10: 0.5828 - 10s/epoch - 16ms/step
Epoch 4/50
589/589 - 10s - loss: 2.7574 - accuracy10: 0.5180 - val_loss: 3.1927 - val_accuracy10: 0.6126 - 10s/epoch - 18ms/step
Epoch 5/50
589/589 - 10s - loss: 2.7209 - accuracy10: 0.5222 - val_loss: 3.1887 - val_accuracy10: 0.6053 - 10s/epoch - 17ms/step
Epoch 6/50
589/589 - 10s - loss: 2.6926 - accuracy10: 0.5326 - val_loss: 3.2021 - val_accuracy10: 0.6279 - 10s/epoch - 17ms/step
Epoch 7/50
589/589 - 10s - loss: 2.6609 - accuracy10: 0.5361 - val_loss: 3.1933 - val_accuracy10: 0.6205 - 10s/epoch - 16ms/step
Epoch 8/50
589/589 - 10s - loss: 2.6393 - accuracy10: 0.5428 - val_loss: 3.2005 - val_accuracy10: 0.6360 - 10s/epoch - 17ms/step
Epoch 9/50
589/589 - 10s - loss: 2.6173 - accuracy10: 0.5479 - val_loss: 3.2301 - val_accuracy10: 0.6536 - 10s/epoch - 17ms/step
Epoch 10/50
589/589 - 10s - loss: 2.6035 - accuracy10: 0.5552 - val_loss: 3.2029 - val_accuracy10: 0.6328 - 10s/epoch - 16ms/step
Epoch 11/50
589/589 - 10s - loss: 2.5801 - accuracy10: 0.5615 - val_loss: 3.2258 - val_accuracy10: 0.6364 - 10s/epoch - 17ms/step
Epoch 12/50
589/589 - 10s - loss: 2.5752 - accuracy10: 0.5622 - val_loss: 3.2532 - val_accuracy10: 0.6655 - 10s/epoch - 17ms/step
Epoch 13/50
589/589 - 10s - loss: 2.5522 - accuracy10: 0.5698 - val_loss: 3.2239 - val_accuracy10: 0.6596 - 10s/epoch - 18ms/step
Epoch 14/50
589/589 - 10s - loss: 2.5393 - accuracy10: 0.5699 - val_loss: 3.2420 - val_accuracy10: 0.6585 - 10s/epoch - 18ms/step
Epoch 15/50
589/589 - 10s - loss: 2.5240 - accuracy10: 0.5734 - val_loss: 3.2496 - val_accuracy10: 0.6597 - 10s/epoch - 16ms/step
testing model: results/QRTEA/W5/deepOF_L1/h10
Evaluating performance on  test set...
2185/2185 - 13s - 13s/epoch - 6ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.9522502
{'0': {'precision': 0.28047178948405205, 'recall': 0.4229607624706028, 'f1-score': 0.33728482312065694, 'support': 80790}, '1': {'precision': 0.7811337056808714, 'recall': 0.6374879436303335, 'f1-score': 0.7020382354613313, 'support': 397093}, '2': {'precision': 0.28886907861637995, 'recall': 0.40246931798617774, 'f1-score': 0.33633584256095367, 'support': 81318}, 'accuracy': 0.5723183613763209, 'macro avg': {'precision': 0.45015819126043444, 'recall': 0.48763934136237136, 'f1-score': 0.4585529670476473, 'support': 559201}, 'weighted avg': {'precision': 0.6372168472468354, 'recall': 0.5723183613763209, 'f1-score': 0.5961610725648486, 'support': 559201}}
[[ 34171  34628  11991]
 [ 75373 253142  68578]
 [ 12290  36300  32728]]
Evaluating performance on  train set...
589/589 - 4s - 4s/epoch - 7ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.9021837
{'0': {'precision': 0.20632779446931143, 'recall': 0.5500163452108532, 'f1-score': 0.3000847193115441, 'support': 12236}, '1': {'precision': 0.904073723789532, 'recall': 0.6220982373155769, 'f1-score': 0.7370370892747163, 'support': 126001}, '2': {'precision': 0.21597067261715014, 'recall': 0.5440456114992371, 'f1-score': 0.3091983661547589, 'support': 12453}, 'accuracy': 0.6097949432609994, 'macro avg': {'precision': 0.4421240636253312, 'recall': 0.5720533980085557, 'f1-score': 0.4487733915803398, 'support': 150690}, 'weighted avg': {'precision': 0.7905521464624904, 'recall': 0.6097949432609994, 'f1-score': 0.6662001072727108, 'support': 150690}}
[[ 6730  4148  1358]
 [24379 78385 23237]
 [ 1509  4169  6775]]
Evaluating performance on  val set...
222/222 - 2s - 2s/epoch - 7ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.9034694
{'0': {'precision': 0.2262987012987013, 'recall': 0.5061728395061729, 'f1-score': 0.3127664348216289, 'support': 5508}, '1': {'precision': 0.8700694635698767, 'recall': 0.6263189197524065, 'f1-score': 0.7283416158614683, 'support': 45397}, '2': {'precision': 0.2544424414112799, 'recall': 0.5161065645133206, 'f1-score': 0.34084636614535413, 'support': 5743}, 'accuracy': 0.6034634938567999, 'macro avg': {'precision': 0.450270202093286, 'recall': 0.5495327745906334, 'f1-score': 0.4606514722761504, 'support': 56648}, 'weighted avg': {'precision': 0.7450617784468987, 'recall': 0.6034634938567999, 'f1-score': 0.6486499530262918, 'support': 56648}}
[[ 2788  2119   601]
 [ 8880 28433  8084]
 [  652  2127  2964]]
training model: results/QRTEA/W5/deepOF_L1/h20
Epoch 1/50
589/589 - 12s - loss: 3.0143 - accuracy20: 0.4368 - val_loss: 3.3071 - val_accuracy20: 0.5264 - 12s/epoch - 20ms/step
Epoch 2/50
589/589 - 10s - loss: 2.8756 - accuracy20: 0.4565 - val_loss: 3.2432 - val_accuracy20: 0.5419 - 10s/epoch - 18ms/step
Epoch 3/50
589/589 - 10s - loss: 2.8216 - accuracy20: 0.4767 - val_loss: 3.2090 - val_accuracy20: 0.5442 - 10s/epoch - 18ms/step
Epoch 4/50
589/589 - 10s - loss: 2.7736 - accuracy20: 0.4851 - val_loss: 3.1779 - val_accuracy20: 0.5583 - 10s/epoch - 16ms/step
Epoch 5/50
589/589 - 10s - loss: 2.7357 - accuracy20: 0.4998 - val_loss: 3.1774 - val_accuracy20: 0.5680 - 10s/epoch - 17ms/step
Epoch 6/50
589/589 - 9s - loss: 2.7075 - accuracy20: 0.5138 - val_loss: 3.1572 - val_accuracy20: 0.5810 - 9s/epoch - 16ms/step
Epoch 7/50
589/589 - 9s - loss: 2.6848 - accuracy20: 0.5211 - val_loss: 3.1420 - val_accuracy20: 0.5921 - 9s/epoch - 16ms/step
Epoch 8/50
589/589 - 10s - loss: 2.6642 - accuracy20: 0.5298 - val_loss: 3.1561 - val_accuracy20: 0.5956 - 10s/epoch - 17ms/step
Epoch 9/50
589/589 - 10s - loss: 2.6479 - accuracy20: 0.5345 - val_loss: 3.1779 - val_accuracy20: 0.6223 - 10s/epoch - 17ms/step
Epoch 10/50
589/589 - 10s - loss: 2.6302 - accuracy20: 0.5425 - val_loss: 3.1509 - val_accuracy20: 0.6068 - 10s/epoch - 17ms/step
Epoch 11/50
589/589 - 10s - loss: 2.6151 - accuracy20: 0.5461 - val_loss: 3.1932 - val_accuracy20: 0.6252 - 10s/epoch - 16ms/step
Epoch 12/50
589/589 - 10s - loss: 2.6068 - accuracy20: 0.5511 - val_loss: 3.1899 - val_accuracy20: 0.6272 - 10s/epoch - 17ms/step
Epoch 13/50
589/589 - 10s - loss: 2.5886 - accuracy20: 0.5543 - val_loss: 3.1935 - val_accuracy20: 0.6246 - 10s/epoch - 18ms/step
Epoch 14/50
589/589 - 10s - loss: 2.5735 - accuracy20: 0.5550 - val_loss: 3.1998 - val_accuracy20: 0.6359 - 10s/epoch - 17ms/step
Epoch 15/50
589/589 - 10s - loss: 2.5644 - accuracy20: 0.5582 - val_loss: 3.2049 - val_accuracy20: 0.6252 - 10s/epoch - 16ms/step
Epoch 16/50
589/589 - 10s - loss: 2.5478 - accuracy20: 0.5636 - val_loss: 3.2624 - val_accuracy20: 0.6412 - 10s/epoch - 17ms/step
Epoch 17/50
589/589 - 10s - loss: 2.5280 - accuracy20: 0.5645 - val_loss: 3.2696 - val_accuracy20: 0.6388 - 10s/epoch - 17ms/step
testing model: results/QRTEA/W5/deepOF_L1/h20
Evaluating performance on  test set...
2185/2185 - 13s - 13s/epoch - 6ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.9642347
{'0': {'precision': 0.33814006519419393, 'recall': 0.4517360568661147, 'f1-score': 0.3867696603382406, 'support': 102416}, '1': {'precision': 0.7075174027436627, 'recall': 0.6178098798714786, 'f1-score': 0.6596276215389351, 'support': 353871}, '2': {'precision': 0.3533287468247248, 'recall': 0.3892473327244107, 'f1-score': 0.370419344398724, 'support': 102914}, 'accuracy': 0.5453298545603459, 'macro avg': {'precision': 0.46632873825419385, 'recall': 0.48626442315400126, 'f1-score': 0.47227220875863324, 'support': 559201}, 'weighted avg': {'precision': 0.5746830180810675, 'recall': 0.5453298545603459, 'f1-score': 0.5564293053915427, 'support': 559201}}
[[ 46265  43472  12679]
 [ 74608 218625  60638]
 [ 15949  46906  40059]]
Evaluating performance on  train set...
589/589 - 3s - 3s/epoch - 6ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.88507813
{'0': {'precision': 0.269250660061515, 'recall': 0.5918391767380639, 'f1-score': 0.37011954427253846, 'support': 16714}, '1': {'precision': 0.8608153818764465, 'recall': 0.620927007174289, 'f1-score': 0.7214526934611883, 'support': 116806}, '2': {'precision': 0.2989291487068966, 'recall': 0.5170064065230052, 'f1-score': 0.37882473434899505, 'support': 17170}, 'accuracy': 0.6058597119915058, 'macro avg': {'precision': 0.4763317302149526, 'recall': 0.5765908634784527, 'f1-score': 0.4901323240275739, 'support': 150690}, 'weighted avg': {'precision': 0.7311783828457481, 'recall': 0.6058597119915058, 'f1-score': 0.6434441705764882, 'support': 150690}}
[[ 9892  5387  1435]
 [24894 72528 19384]
 [ 1953  6340  8877]]
Evaluating performance on  val set...
222/222 - 1s - 1s/epoch - 6ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.8972785
{'0': {'precision': 0.290875052003883, 'recall': 0.5594825286743131, 'f1-score': 0.38275547445255476, 'support': 7498}, '1': {'precision': 0.8145220647060706, 'recall': 0.6166537455179766, 'f1-score': 0.7019096863150639, 'support': 41276}, '2': {'precision': 0.345813974674319, 'recall': 0.4820929641859284, 'f1-score': 0.40273725531802024, 'support': 7874}, 'accuracy': 0.590382714305889, 'macro avg': {'precision': 0.4837370304614242, 'recall': 0.552743079459406, 'f1-score': 0.4958008053618796, 'support': 56648}, 'weighted avg': {'precision': 0.6800616635948044, 'recall': 0.590382714305889, 'f1-score': 0.6180814487388774, 'support': 56648}}
[[ 4195  2676   627]
 [ 9269 25453  6554]
 [  958  3120  3796]]
training model: results/QRTEA/W5/deepOF_L1/h30
Epoch 1/50
589/589 - 11s - loss: 3.0406 - accuracy30: 0.4284 - val_loss: 3.3358 - val_accuracy30: 0.5117 - 11s/epoch - 19ms/step
Epoch 2/50
589/589 - 10s - loss: 2.9085 - accuracy30: 0.4459 - val_loss: 3.2766 - val_accuracy30: 0.5088 - 10s/epoch - 16ms/step
Epoch 3/50
589/589 - 10s - loss: 2.8598 - accuracy30: 0.4516 - val_loss: 3.2717 - val_accuracy30: 0.5246 - 10s/epoch - 16ms/step
Epoch 4/50
589/589 - 10s - loss: 2.8179 - accuracy30: 0.4721 - val_loss: 3.2545 - val_accuracy30: 0.5244 - 10s/epoch - 16ms/step
Epoch 5/50
589/589 - 9s - loss: 2.7798 - accuracy30: 0.4799 - val_loss: 3.2501 - val_accuracy30: 0.5396 - 9s/epoch - 16ms/step
Epoch 6/50
589/589 - 9s - loss: 2.7539 - accuracy30: 0.4921 - val_loss: 3.2309 - val_accuracy30: 0.5511 - 9s/epoch - 16ms/step
Epoch 7/50
589/589 - 10s - loss: 2.7334 - accuracy30: 0.5019 - val_loss: 3.2443 - val_accuracy30: 0.5755 - 10s/epoch - 17ms/step
Epoch 8/50
589/589 - 9s - loss: 2.7097 - accuracy30: 0.5140 - val_loss: 3.2473 - val_accuracy30: 0.5603 - 9s/epoch - 16ms/step
Epoch 9/50
589/589 - 10s - loss: 2.6958 - accuracy30: 0.5155 - val_loss: 3.2372 - val_accuracy30: 0.5679 - 10s/epoch - 17ms/step
Epoch 10/50
589/589 - 9s - loss: 2.6778 - accuracy30: 0.5241 - val_loss: 3.2535 - val_accuracy30: 0.5783 - 9s/epoch - 16ms/step
Epoch 11/50
589/589 - 9s - loss: 2.6640 - accuracy30: 0.5291 - val_loss: 3.2659 - val_accuracy30: 0.5824 - 9s/epoch - 16ms/step
Epoch 12/50
589/589 - 10s - loss: 2.6494 - accuracy30: 0.5327 - val_loss: 3.2854 - val_accuracy30: 0.5831 - 10s/epoch - 17ms/step
Epoch 13/50
589/589 - 10s - loss: 2.6353 - accuracy30: 0.5384 - val_loss: 3.3302 - val_accuracy30: 0.6072 - 10s/epoch - 16ms/step
Epoch 14/50
589/589 - 9s - loss: 2.6233 - accuracy30: 0.5411 - val_loss: 3.3171 - val_accuracy30: 0.6033 - 9s/epoch - 16ms/step
Epoch 15/50
589/589 - 9s - loss: 2.6112 - accuracy30: 0.5429 - val_loss: 3.3272 - val_accuracy30: 0.6040 - 9s/epoch - 16ms/step
Epoch 16/50
589/589 - 9s - loss: 2.5989 - accuracy30: 0.5460 - val_loss: 3.3083 - val_accuracy30: 0.6059 - 9s/epoch - 16ms/step
testing model: results/QRTEA/W5/deepOF_L1/h30
Evaluating performance on  test set...
2185/2185 - 12s - 12s/epoch - 6ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.0049139
{'0': {'precision': 0.36043769197016234, 'recall': 0.4456198347107438, 'f1-score': 0.39852784547683934, 'support': 117975}, '1': {'precision': 0.6403387226340105, 'recall': 0.5656919377231258, 'f1-score': 0.6007052137442638, 'support': 322688}, '2': {'precision': 0.3715406083851755, 'recall': 0.4020567244259225, 'f1-score': 0.3861967813558498, 'support': 118538}, 'accuracy': 0.5056732731164644, 'macro avg': {'precision': 0.4574390076631161, 'recall': 0.4711228322865974, 'f1-score': 0.4618099468589843, 'support': 559201}, 'weighted avg': {'precision': 0.524308681630157, 'recall': 0.5056732731164644, 'f1-score': 0.5125807726581298, 'support': 559201}}
[[ 52572  50373  15030]
 [ 74561 182542  65585]
 [ 18723  52156  47659]]
Evaluating performance on  train set...
589/589 - 4s - 4s/epoch - 6ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.93221515
{'0': {'precision': 0.29210453365590583, 'recall': 0.5725929951094205, 'f1-score': 0.38685668513450366, 'support': 20243}, '1': {'precision': 0.807461778450943, 'recall': 0.568669997447212, 'f1-score': 0.6673478449267376, 'support': 109684}, '2': {'precision': 0.31076358035661394, 'recall': 0.5053219669604585, 'f1-score': 0.38485098578633653, 'support': 20763}, 'accuracy': 0.5604685115137036, 'macro avg': {'precision': 0.47010996415448764, 'recall': 0.5488616531723637, 'f1-score': 0.4796851719491926, 'support': 150690}, 'weighted avg': {'precision': 0.6697929126110166, 'recall': 0.5604685115137036, 'f1-score': 0.5907437913464978, 'support': 150690}}
[[11591  7031  1621]
 [25661 62374 21649]
 [ 2429  7842 10492]]
Evaluating performance on  val set...
222/222 - 1s - 1s/epoch - 6ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.94385386
{'0': {'precision': 0.31867121848739494, 'recall': 0.5361758533082956, 'f1-score': 0.39975293390982086, 'support': 9053}, '1': {'precision': 0.7472302710073291, 'recall': 0.5750714904111026, 'f1-score': 0.6499436636422936, 'support': 38117}, '2': {'precision': 0.3614766989487625, 'recall': 0.4607512133361469, 'f1-score': 0.40512083120738435, 'support': 9478}, 'accuracy': 0.5497281457421268, 'macro avg': {'precision': 0.4757927294811622, 'recall': 0.523999519018515, 'f1-score': 0.4849391429198329, 'support': 56648}, 'weighted avg': {'precision': 0.6141996704842028, 'recall': 0.5497281457421268, 'f1-score': 0.5689980436365363, 'support': 56648}}
[[ 4854  3481   718]
 [ 9201 21920  6996]
 [ 1177  3934  4367]]
training model: results/QRTEA/W5/deepOF_L1/h50
Epoch 1/50
589/589 - 12s - loss: 3.0964 - accuracy50: 0.4215 - val_loss: 3.3611 - val_accuracy50: 0.4723 - 12s/epoch - 20ms/step
Epoch 2/50
589/589 - 9s - loss: 2.9889 - accuracy50: 0.4352 - val_loss: 3.3289 - val_accuracy50: 0.4709 - 9s/epoch - 16ms/step
Epoch 3/50
589/589 - 11s - loss: 2.9505 - accuracy50: 0.4441 - val_loss: 3.2966 - val_accuracy50: 0.4578 - 11s/epoch - 18ms/step
Epoch 4/50
589/589 - 10s - loss: 2.9222 - accuracy50: 0.4524 - val_loss: 3.2973 - val_accuracy50: 0.4786 - 10s/epoch - 17ms/step
Epoch 5/50
589/589 - 10s - loss: 2.8912 - accuracy50: 0.4637 - val_loss: 3.3256 - val_accuracy50: 0.4993 - 10s/epoch - 16ms/step
Epoch 6/50
589/589 - 9s - loss: 2.8650 - accuracy50: 0.4783 - val_loss: 3.2817 - val_accuracy50: 0.4956 - 9s/epoch - 16ms/step
Epoch 7/50
589/589 - 9s - loss: 2.8455 - accuracy50: 0.4893 - val_loss: 3.3214 - val_accuracy50: 0.5313 - 9s/epoch - 15ms/step
Epoch 8/50
589/589 - 10s - loss: 2.8258 - accuracy50: 0.4968 - val_loss: 3.3477 - val_accuracy50: 0.5365 - 10s/epoch - 17ms/step
Epoch 9/50
589/589 - 10s - loss: 2.8126 - accuracy50: 0.4998 - val_loss: 3.3384 - val_accuracy50: 0.5402 - 10s/epoch - 17ms/step
Epoch 10/50
589/589 - 10s - loss: 2.7945 - accuracy50: 0.5095 - val_loss: 3.3368 - val_accuracy50: 0.5390 - 10s/epoch - 17ms/step
Epoch 11/50
589/589 - 9s - loss: 2.7836 - accuracy50: 0.5114 - val_loss: 3.3555 - val_accuracy50: 0.5516 - 9s/epoch - 16ms/step
Epoch 12/50
589/589 - 10s - loss: 2.7719 - accuracy50: 0.5154 - val_loss: 3.4033 - val_accuracy50: 0.5560 - 10s/epoch - 17ms/step
Epoch 13/50
589/589 - 9s - loss: 2.7589 - accuracy50: 0.5168 - val_loss: 3.3931 - val_accuracy50: 0.5541 - 9s/epoch - 16ms/step
Epoch 14/50
589/589 - 9s - loss: 2.7454 - accuracy50: 0.5219 - val_loss: 3.4065 - val_accuracy50: 0.5579 - 9s/epoch - 16ms/step
Epoch 15/50
589/589 - 10s - loss: 2.7355 - accuracy50: 0.5252 - val_loss: 3.4263 - val_accuracy50: 0.5658 - 10s/epoch - 17ms/step
Epoch 16/50
589/589 - 9s - loss: 2.7207 - accuracy50: 0.5285 - val_loss: 3.4810 - val_accuracy50: 0.5646 - 9s/epoch - 16ms/step
testing model: results/QRTEA/W5/deepOF_L1/h50
Evaluating performance on  test set...
2185/2185 - 13s - 13s/epoch - 6ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0413004
{'0': {'precision': 0.3965762644185253, 'recall': 0.43080625752105894, 'f1-score': 0.4129831891911831, 'support': 142932}, '1': {'precision': 0.532103090356286, 'recall': 0.4805129107464919, 'f1-score': 0.5049938071013189, 'support': 272796}, '2': {'precision': 0.3969730621569312, 'recall': 0.436019320708426, 'f1-score': 0.4155810508274153, 'support': 143473}, 'accuracy': 0.45639224536436807, 'macro avg': {'precision': 0.4418841389772475, 'recall': 0.4491128296586589, 'f1-score': 0.4445193490399724, 'support': 559201}, 'weighted avg': {'precision': 0.46279235804217705, 'recall': 0.45639224536436807, 'f1-score': 0.45853541732730685, 'support': 559201}}
[[ 61576  58133  23223]
 [ 69909 131082  71805]
 [ 23784  57132  62557]]
Evaluating performance on  train set...
589/589 - 4s - 4s/epoch - 6ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.9732153
{'0': {'precision': 0.33754790207229857, 'recall': 0.5242030249042872, 'f1-score': 0.41066072754268745, 'support': 26381}, '1': {'precision': 0.7176878783404695, 'recall': 0.49889667771699525, 'f1-score': 0.5886185162536403, 'support': 97433}, '2': {'precision': 0.33661975185158727, 'recall': 0.5259339187379074, 'f1-score': 0.410501401251688, 'support': 26876}, 'accuracy': 0.508149180436658, 'macro avg': {'precision': 0.46395184408811846, 'recall': 0.5163445404530633, 'f1-score': 0.4699268816826719, 'support': 150690}, 'weighted avg': {'precision': 0.5831729159577911, 'recall': 0.508149180436658, 'f1-score': 0.5256960926901914, 'support': 150690}}
[[13829  9758  2794]
 [23762 48609 25062]
 [ 3378  9363 14135]]
Evaluating performance on  val set...
222/222 - 2s - 2s/epoch - 7ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.9900707
{'0': {'precision': 0.36461725084594265, 'recall': 0.4906357388316151, 'f1-score': 0.41834230670622274, 'support': 11640}, '1': {'precision': 0.6416394208313873, 'recall': 0.5026680896478122, 'f1-score': 0.5637150135927643, 'support': 32795}, '2': {'precision': 0.3848165827502779, 'recall': 0.48186358798002127, 'f1-score': 0.4279066385515888, 'support': 12213}, 'accuracy': 0.49571035164524785, 'macro avg': {'precision': 0.46369108480920257, 'recall': 0.4917224721531495, 'f1-score': 0.4699879862835253, 'support': 56648}, 'weighted avg': {'precision': 0.5293474532400307, 'recall': 0.49571035164524785, 'f1-score': 0.5045643640987448, 'support': 56648}}
[[ 5711  4591  1338]
 [ 8240 16485  8070]
 [ 1712  4616  5885]]
training model: results/QRTEA/W5/deepOF_L1/h100
Epoch 1/50
589/589 - 12s - loss: 3.2047 - accuracy100: 0.4152 - val_loss: 3.3917 - val_accuracy100: 0.4274 - 12s/epoch - 20ms/step
Epoch 2/50
589/589 - 10s - loss: 3.1272 - accuracy100: 0.4370 - val_loss: 3.3603 - val_accuracy100: 0.4316 - 10s/epoch - 17ms/step
Epoch 3/50
589/589 - 10s - loss: 3.1005 - accuracy100: 0.4462 - val_loss: 3.3587 - val_accuracy100: 0.4402 - 10s/epoch - 16ms/step
Epoch 4/50
589/589 - 10s - loss: 3.0784 - accuracy100: 0.4534 - val_loss: 3.3509 - val_accuracy100: 0.4442 - 10s/epoch - 17ms/step
Epoch 5/50
589/589 - 10s - loss: 3.0560 - accuracy100: 0.4639 - val_loss: 3.3690 - val_accuracy100: 0.4531 - 10s/epoch - 17ms/step
Epoch 6/50
589/589 - 10s - loss: 3.0348 - accuracy100: 0.4709 - val_loss: 3.3780 - val_accuracy100: 0.4585 - 10s/epoch - 17ms/step
Epoch 7/50
589/589 - 10s - loss: 3.0175 - accuracy100: 0.4775 - val_loss: 3.3787 - val_accuracy100: 0.4627 - 10s/epoch - 17ms/step
Epoch 8/50
589/589 - 10s - loss: 3.0042 - accuracy100: 0.4801 - val_loss: 3.3948 - val_accuracy100: 0.4643 - 10s/epoch - 17ms/step
Epoch 9/50
589/589 - 9s - loss: 2.9892 - accuracy100: 0.4841 - val_loss: 3.3996 - val_accuracy100: 0.4668 - 9s/epoch - 16ms/step
Epoch 10/50
589/589 - 9s - loss: 2.9754 - accuracy100: 0.4884 - val_loss: 3.4035 - val_accuracy100: 0.4680 - 9s/epoch - 16ms/step
Epoch 11/50
589/589 - 10s - loss: 2.9659 - accuracy100: 0.4924 - val_loss: 3.4123 - val_accuracy100: 0.4693 - 10s/epoch - 17ms/step
Epoch 12/50
589/589 - 10s - loss: 2.9554 - accuracy100: 0.4935 - val_loss: 3.4174 - val_accuracy100: 0.4704 - 10s/epoch - 17ms/step
Epoch 13/50
589/589 - 10s - loss: 2.9434 - accuracy100: 0.4999 - val_loss: 3.4651 - val_accuracy100: 0.4712 - 10s/epoch - 17ms/step
Epoch 14/50
589/589 - 10s - loss: 2.9371 - accuracy100: 0.5009 - val_loss: 3.4318 - val_accuracy100: 0.4725 - 10s/epoch - 17ms/step
testing model: results/QRTEA/W5/deepOF_L1/h100
Evaluating performance on  test set...
2185/2185 - 12s - 12s/epoch - 6ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0781325
{'0': {'precision': 0.458393527882115, 'recall': 0.3771482908222531, 'f1-score': 0.413820904458863, 'support': 185089}, '1': {'precision': 0.3664281739406948, 'recall': 0.4781481135696428, 'f1-score': 0.414899027404597, 'support': 192798}, '2': {'precision': 0.44267624583969045, 'recall': 0.3792536704280971, 'f1-score': 0.40851802014549193, 'support': 181314}, 'accuracy': 0.4126530531955415, 'macro avg': {'precision': 0.4224993158875001, 'recall': 0.4115166916066643, 'f1-score': 0.4124126506696506, 'support': 559201}, 'weighted avg': {'precision': 0.4215901251960718, 'recall': 0.4126530531955415, 'f1-score': 0.4124732187095476, 'support': 559201}}
[[69806 80455 34828]
 [48867 92186 51745]
 [33611 78939 68764]]
Evaluating performance on  train set...
589/589 - 4s - 4s/epoch - 6ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0303297
{'0': {'precision': 0.40176427470110965, 'recall': 0.4294205052005943, 'f1-score': 0.4151322834234375, 'support': 37015}, '1': {'precision': 0.5502704445845121, 'recall': 0.49453951441858013, 'f1-score': 0.5209186151391105, 'support': 75909}, '2': {'precision': 0.3953759380972358, 'recall': 0.4491870995074935, 'f1-score': 0.4205672352241175, 'support': 37766}, 'accuracy': 0.467177649479063, 'macro avg': {'precision': 0.44913688579428585, 'recall': 0.457715706375556, 'f1-score': 0.45220604459555513, 'support': 150690}, 'weighted avg': {'precision': 0.47497213805964233, 'recall': 0.467177649479063, 'f1-score': 0.4697834948104539, 'support': 150690}}
[[15895 15418  5702]
 [18129 37540 20240]
 [ 5539 15263 16964]]
Evaluating performance on  val set...
222/222 - 1s - 1s/epoch - 6ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0495962
{'0': {'precision': 0.43506845601192895, 'recall': 0.3959412780656304, 'f1-score': 0.414583737001873, 'support': 16212}, '1': {'precision': 0.45403825717322, 'recall': 0.5060276638044076, 'f1-score': 0.4786252975654644, 'support': 23641}, '2': {'precision': 0.4398559114884858, 'recall': 0.4071449836260792, 'f1-score': 0.42286880430413404, 'support': 16795}, 'accuracy': 0.4452054794520548, 'macro avg': {'precision': 0.4429875415578783, 'recall': 0.4363713084987057, 'f1-score': 0.4386926129571571, 'support': 56648}, 'weighted avg': {'precision': 0.44440453820340703, 'recall': 0.4452054794520548, 'f1-score': 0.4437666602935221, 'support': 56648}}
[[ 6419  7237  2556]
 [ 5526 11963  6152]
 [ 2809  7148  6838]]
training model: results/QRTEA/W5/deepOF_L1/h200
Epoch 1/50
589/589 - 12s - loss: 3.2699 - accuracy200: 0.3933 - val_loss: 3.2781 - val_accuracy200: 0.3982 - 12s/epoch - 20ms/step
Epoch 2/50
589/589 - 10s - loss: 3.2189 - accuracy200: 0.4182 - val_loss: 3.2637 - val_accuracy200: 0.4092 - 10s/epoch - 16ms/step
Epoch 3/50
589/589 - 9s - loss: 3.1937 - accuracy200: 0.4260 - val_loss: 3.2621 - val_accuracy200: 0.4105 - 9s/epoch - 16ms/step
Epoch 4/50
589/589 - 10s - loss: 3.1763 - accuracy200: 0.4328 - val_loss: 3.2577 - val_accuracy200: 0.4100 - 10s/epoch - 17ms/step
Epoch 5/50
589/589 - 10s - loss: 3.1652 - accuracy200: 0.4384 - val_loss: 3.2671 - val_accuracy200: 0.4072 - 10s/epoch - 17ms/step
Epoch 6/50
589/589 - 9s - loss: 3.1504 - accuracy200: 0.4447 - val_loss: 3.2699 - val_accuracy200: 0.4078 - 9s/epoch - 16ms/step
Epoch 7/50
589/589 - 10s - loss: 3.1398 - accuracy200: 0.4487 - val_loss: 3.2684 - val_accuracy200: 0.4071 - 10s/epoch - 17ms/step
Epoch 8/50
589/589 - 9s - loss: 3.1290 - accuracy200: 0.4533 - val_loss: 3.2684 - val_accuracy200: 0.4103 - 9s/epoch - 16ms/step
Epoch 9/50
589/589 - 10s - loss: 3.1180 - accuracy200: 0.4573 - val_loss: 3.2622 - val_accuracy200: 0.4159 - 10s/epoch - 16ms/step
Epoch 10/50
589/589 - 10s - loss: 3.1105 - accuracy200: 0.4603 - val_loss: 3.2673 - val_accuracy200: 0.4163 - 10s/epoch - 16ms/step
Epoch 11/50
589/589 - 10s - loss: 3.1018 - accuracy200: 0.4620 - val_loss: 3.2681 - val_accuracy200: 0.4155 - 10s/epoch - 17ms/step
Epoch 12/50
589/589 - 10s - loss: 3.0948 - accuracy200: 0.4638 - val_loss: 3.2826 - val_accuracy200: 0.4171 - 10s/epoch - 17ms/step
Epoch 13/50
589/589 - 10s - loss: 3.0882 - accuracy200: 0.4663 - val_loss: 3.2701 - val_accuracy200: 0.4198 - 10s/epoch - 16ms/step
Epoch 14/50
589/589 - 10s - loss: 3.0818 - accuracy200: 0.4682 - val_loss: 3.2653 - val_accuracy200: 0.4236 - 10s/epoch - 17ms/step
testing model: results/QRTEA/W5/deepOF_L1/h200
Evaluating performance on  test set...
2185/2185 - 13s - 13s/epoch - 6ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0895681
{'0': {'precision': 0.4852113211297744, 'recall': 0.3785009007365517, 'f1-score': 0.4252641503633029, 'support': 219265}, '1': {'precision': 0.23522344792700248, 'recall': 0.3901213255461263, 'f1-score': 0.293488287413521, 'support': 123964}, '2': {'precision': 0.46978560708142986, 'recall': 0.3971116626229326, 'f1-score': 0.4304024248872117, 'support': 215972}, 'accuracy': 0.3882646847913362, 'macro avg': {'precision': 0.39674012537940223, 'recall': 0.38857796296853686, 'f1-score': 0.38305162088801187, 'support': 559201}, 'weighted avg': {'precision': 0.42383621803060706, 'recall': 0.3882646847913362, 'f1-score': 0.39803648151215787, 'support': 559201}}
[[82992 80194 56079]
 [34885 48361 40718]
 [53166 77041 85765]]
Evaluating performance on  train set...
589/589 - 4s - 4s/epoch - 6ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0646951
{'0': {'precision': 0.4348755399207374, 'recall': 0.4203232262368461, 'f1-score': 0.4274755698543493, 'support': 46469}, '1': {'precision': 0.40303112805154734, 'recall': 0.4032726744397225, 'f1-score': 0.4031518650653158, 'support': 55062}, '2': {'precision': 0.4287405536591622, 'recall': 0.4420146870359446, 'f1-score': 0.4352764423076923, 'support': 49159}, 'accuracy': 0.4211692879421329, 'macro avg': {'precision': 0.4222157405438156, 'recall': 0.421870195904171, 'f1-score': 0.4219679590757858, 'support': 150690}, 'weighted avg': {'precision': 0.421238226257096, 'recall': 0.4211692879421329, 'f1-score': 0.42113255608993316, 'support': 150690}}
[[19532 15927 11010]
 [14915 22205 17942]
 [10467 16963 21729]]
Evaluating performance on  val set...
222/222 - 1s - 1s/epoch - 6ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0751967
{'0': {'precision': 0.45886859163229227, 'recall': 0.39721485411140584, 'f1-score': 0.42582162191720896, 'support': 19604}, '1': {'precision': 0.32873876840570165, 'recall': 0.42205713595458116, 'f1-score': 0.36959856137938335, 'support': 16557}, '2': {'precision': 0.460832745236415, 'recall': 0.41436032606042855, 'f1-score': 0.43636270175799324, 'support': 20487}, 'accuracy': 0.4106764581273831, 'macro avg': {'precision': 0.41614670175813634, 'recall': 0.4112107720421385, 'f1-score': 0.41059429501819517, 'support': 56648}, 'weighted avg': {'precision': 0.421544769639018, 'recall': 0.4106764581273831, 'f1-score': 0.4132010508356768, 'support': 56648}}
[[7787 7033 4784]
 [4421 6988 5148]
 [4762 7236 8489]]
training model: results/QRTEA/W5/deepOF_L1/h300
Epoch 1/50
589/589 - 13s - loss: 3.2938 - accuracy300: 0.3814 - val_loss: 3.2490 - val_accuracy300: 0.4063 - 13s/epoch - 21ms/step
Epoch 2/50
589/589 - 10s - loss: 3.2545 - accuracy300: 0.3969 - val_loss: 3.2405 - val_accuracy300: 0.4132 - 10s/epoch - 17ms/step
Epoch 3/50
589/589 - 10s - loss: 3.2389 - accuracy300: 0.4054 - val_loss: 3.2371 - val_accuracy300: 0.4117 - 10s/epoch - 17ms/step
Epoch 4/50
589/589 - 10s - loss: 3.2245 - accuracy300: 0.4131 - val_loss: 3.2339 - val_accuracy300: 0.4136 - 10s/epoch - 17ms/step
Epoch 5/50
589/589 - 9s - loss: 3.2162 - accuracy300: 0.4168 - val_loss: 3.2326 - val_accuracy300: 0.4130 - 9s/epoch - 16ms/step
Epoch 6/50
589/589 - 10s - loss: 3.2126 - accuracy300: 0.4188 - val_loss: 3.2308 - val_accuracy300: 0.4139 - 10s/epoch - 17ms/step
Epoch 7/50
589/589 - 10s - loss: 3.2024 - accuracy300: 0.4231 - val_loss: 3.2296 - val_accuracy300: 0.4076 - 10s/epoch - 18ms/step
Epoch 8/50
589/589 - 10s - loss: 3.1960 - accuracy300: 0.4248 - val_loss: 3.2282 - val_accuracy300: 0.4095 - 10s/epoch - 17ms/step
Epoch 9/50
589/589 - 10s - loss: 3.1906 - accuracy300: 0.4273 - val_loss: 3.2272 - val_accuracy300: 0.4076 - 10s/epoch - 17ms/step
Epoch 10/50
589/589 - 10s - loss: 3.1853 - accuracy300: 0.4300 - val_loss: 3.2270 - val_accuracy300: 0.4084 - 10s/epoch - 16ms/step
Epoch 11/50
589/589 - 10s - loss: 3.1802 - accuracy300: 0.4315 - val_loss: 3.2249 - val_accuracy300: 0.4115 - 10s/epoch - 16ms/step
Epoch 12/50
589/589 - 9s - loss: 3.1751 - accuracy300: 0.4341 - val_loss: 3.2283 - val_accuracy300: 0.4053 - 9s/epoch - 16ms/step
Epoch 13/50
589/589 - 10s - loss: 3.1717 - accuracy300: 0.4347 - val_loss: 3.2270 - val_accuracy300: 0.4074 - 10s/epoch - 16ms/step
Epoch 14/50
589/589 - 10s - loss: 3.1670 - accuracy300: 0.4377 - val_loss: 3.2292 - val_accuracy300: 0.4089 - 10s/epoch - 17ms/step
Epoch 15/50
589/589 - 10s - loss: 3.1634 - accuracy300: 0.4386 - val_loss: 3.2321 - val_accuracy300: 0.4113 - 10s/epoch - 18ms/step
Epoch 16/50
589/589 - 10s - loss: 3.1583 - accuracy300: 0.4413 - val_loss: 3.2373 - val_accuracy300: 0.4065 - 10s/epoch - 17ms/step
Epoch 17/50
589/589 - 10s - loss: 3.1542 - accuracy300: 0.4425 - val_loss: 3.2358 - val_accuracy300: 0.4092 - 10s/epoch - 17ms/step
Epoch 18/50
589/589 - 10s - loss: 3.1488 - accuracy300: 0.4442 - val_loss: 3.2404 - val_accuracy300: 0.4064 - 10s/epoch - 17ms/step
Epoch 19/50
589/589 - 10s - loss: 3.1450 - accuracy300: 0.4462 - val_loss: 3.2450 - val_accuracy300: 0.4082 - 10s/epoch - 16ms/step
Epoch 20/50
589/589 - 10s - loss: 3.1432 - accuracy300: 0.4474 - val_loss: 3.2455 - val_accuracy300: 0.4069 - 10s/epoch - 16ms/step
Epoch 21/50
589/589 - 10s - loss: 3.1394 - accuracy300: 0.4480 - val_loss: 3.2339 - val_accuracy300: 0.4118 - 10s/epoch - 17ms/step
testing model: results/QRTEA/W5/deepOF_L1/h300
Evaluating performance on  test set...
2185/2185 - 13s - 13s/epoch - 6ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0772378
{'0': {'precision': 0.47206757827579904, 'recall': 0.4172784295765478, 'f1-score': 0.44298533074347274, 'support': 222717}, '1': {'precision': 0.21689427726629945, 'recall': 0.18852015162063898, 'f1-score': 0.20171429096962282, 'support': 116343}, '2': {'precision': 0.4475556066000536, 'recall': 0.5310505539631418, 'f1-score': 0.4857411743197791, 'support': 220141}, 'accuracy': 0.4144735077369318, 'macro avg': {'precision': 0.37883915404738405, 'recall': 0.3789497117201095, 'f1-score': 0.3768135986776249, 'support': 559201}, 'weighted avg': {'precision': 0.4093285679449547, 'recall': 0.4144735077369318, 'f1-score': 0.4096200785002232, 'support': 559201}}
[[ 92935  40672  89110]
 [ 39216  21933  55194]
 [ 64717  38518 116906]]
Evaluating performance on  train set...
589/589 - 4s - 4s/epoch - 7ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.070493
{'0': {'precision': 0.4294213719085394, 'recall': 0.4520539533741327, 'f1-score': 0.4404471078582895, 'support': 48857}, '1': {'precision': 0.3715191383482736, 'recall': 0.2219688021830326, 'f1-score': 0.2779017145770922, 'support': 49106}, '2': {'precision': 0.4136071740156467, 'recall': 0.5484666299998103, 'f1-score': 0.47158488658415276, 'support': 52727}, 'accuracy': 0.4108102727453713, 'macro avg': {'precision': 0.40484922809081986, 'recall': 0.4074964618523252, 'f1-score': 0.3966445696731782, 'support': 150690}, 'weighted avg': {'precision': 0.40501907385618713, 'recall': 0.4108102727453713, 'f1-score': 0.3983729660865204, 'support': 150690}}
[[22086  8658 18113]
 [15319 10900 22887]
 [14027  9781 28919]]
Evaluating performance on  val set...
222/222 - 1s - 1s/epoch - 6ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0751007
{'0': {'precision': 0.4402789005658852, 'recall': 0.43234929297940955, 'f1-score': 0.4362780684406839, 'support': 20155}, '1': {'precision': 0.3015315315315315, 'recall': 0.2211576582529404, 'f1-score': 0.25516505298467634, 'support': 15134}, '2': {'precision': 0.43617021276595747, 'recall': 0.5259609532281474, 'f1-score': 0.4768757295977926, 'support': 21359}, 'accuracy': 0.4112236972179071, 'macro avg': {'precision': 0.392660214954458, 'recall': 0.3931559681534991, 'f1-score': 0.3894396170077176, 'support': 56648}, 'weighted avg': {'precision': 0.4016621771919873, 'recall': 0.4112236972179071, 'f1-score': 0.4031994261010332, 'support': 56648}}
[[ 8714  3757  7684]
 [ 4949  3347  6838]
 [ 6129  3996 11234]]
training model: results/QRTEA/W5/deepOF_L1/h500
Epoch 1/50
589/589 - 12s - loss: 3.3131 - accuracy500: 0.3624 - val_loss: 3.2963 - val_accuracy500: 0.3705 - 12s/epoch - 20ms/step
Epoch 2/50
589/589 - 10s - loss: 3.2849 - accuracy500: 0.3767 - val_loss: 3.2891 - val_accuracy500: 0.3770 - 10s/epoch - 16ms/step
Epoch 3/50
589/589 - 11s - loss: 3.2718 - accuracy500: 0.3834 - val_loss: 3.2848 - val_accuracy500: 0.3793 - 11s/epoch - 19ms/step
Epoch 4/50
589/589 - 10s - loss: 3.2651 - accuracy500: 0.3853 - val_loss: 3.2821 - val_accuracy500: 0.3801 - 10s/epoch - 16ms/step
Epoch 5/50
589/589 - 10s - loss: 3.2585 - accuracy500: 0.3896 - val_loss: 3.2813 - val_accuracy500: 0.3800 - 10s/epoch - 17ms/step
Epoch 6/50
589/589 - 10s - loss: 3.2547 - accuracy500: 0.3908 - val_loss: 3.2837 - val_accuracy500: 0.3779 - 10s/epoch - 17ms/step
Epoch 7/50
589/589 - 10s - loss: 3.2517 - accuracy500: 0.3918 - val_loss: 3.2836 - val_accuracy500: 0.3793 - 10s/epoch - 17ms/step
Epoch 8/50
589/589 - 10s - loss: 3.2489 - accuracy500: 0.3920 - val_loss: 3.2826 - val_accuracy500: 0.3797 - 10s/epoch - 17ms/step
Epoch 9/50
589/589 - 10s - loss: 3.2454 - accuracy500: 0.3955 - val_loss: 3.2808 - val_accuracy500: 0.3809 - 10s/epoch - 16ms/step
Epoch 10/50
589/589 - 10s - loss: 3.2431 - accuracy500: 0.3967 - val_loss: 3.2834 - val_accuracy500: 0.3826 - 10s/epoch - 16ms/step
Epoch 11/50
589/589 - 10s - loss: 3.2409 - accuracy500: 0.3983 - val_loss: 3.2831 - val_accuracy500: 0.3833 - 10s/epoch - 16ms/step
Epoch 12/50
589/589 - 10s - loss: 3.2403 - accuracy500: 0.3980 - val_loss: 3.2824 - val_accuracy500: 0.3821 - 10s/epoch - 16ms/step
Epoch 13/50
589/589 - 9s - loss: 3.2383 - accuracy500: 0.3979 - val_loss: 3.2829 - val_accuracy500: 0.3825 - 9s/epoch - 15ms/step
Epoch 14/50
589/589 - 10s - loss: 3.2366 - accuracy500: 0.3991 - val_loss: 3.2826 - val_accuracy500: 0.3821 - 10s/epoch - 16ms/step
Epoch 15/50
589/589 - 10s - loss: 3.2348 - accuracy500: 0.4021 - val_loss: 3.2851 - val_accuracy500: 0.3801 - 10s/epoch - 17ms/step
Epoch 16/50
589/589 - 9s - loss: 3.2329 - accuracy500: 0.4009 - val_loss: 3.2843 - val_accuracy500: 0.3808 - 9s/epoch - 16ms/step
Epoch 17/50
589/589 - 9s - loss: 3.2316 - accuracy500: 0.4021 - val_loss: 3.2853 - val_accuracy500: 0.3805 - 9s/epoch - 16ms/step
Epoch 18/50
589/589 - 10s - loss: 3.2293 - accuracy500: 0.4026 - val_loss: 3.2885 - val_accuracy500: 0.3755 - 10s/epoch - 16ms/step
Epoch 19/50
589/589 - 9s - loss: 3.2272 - accuracy500: 0.4049 - val_loss: 3.2886 - val_accuracy500: 0.3791 - 9s/epoch - 16ms/step
testing model: results/QRTEA/W5/deepOF_L1/h500
Evaluating performance on  test set...
2185/2185 - 12s - 12s/epoch - 5ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0975652
{'0': {'precision': 0.4217701133588984, 'recall': 0.25796076962689013, 'f1-score': 0.3201271143360919, 'support': 213610}, '1': {'precision': 0.2631655856929285, 'recall': 0.1710978265635734, 'f1-score': 0.20737210857540184, 'support': 136834}, '2': {'precision': 0.39710710825669704, 'recall': 0.6459855238387215, 'f1-score': 0.49185553699475515, 'support': 208757}, 'accuracy': 0.3815604764655285, 'macro avg': {'precision': 0.360680935769508, 'recall': 0.3583480400097283, 'f1-score': 0.33978491996874965, 'support': 559201}, 'weighted avg': {'precision': 0.3737532698719132, 'recall': 0.3815604764655285, 'f1-score': 0.35664491718461383, 'support': 559201}}
[[ 55103  34142 124365]
 [ 33050  23412  80372]
 [ 42494  31409 134854]]
Evaluating performance on  train set...
589/589 - 3s - 3s/epoch - 6ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0847337
{'0': {'precision': 0.4077111668904326, 'recall': 0.2849536942597201, 'f1-score': 0.33545458911675713, 'support': 49022}, '1': {'precision': 0.3474833232261977, 'recall': 0.16875631100639515, 'f1-score': 0.22718133159638643, 'support': 47536}, '2': {'precision': 0.3943562383492961, 'recall': 0.6800044336067391, 'f1-score': 0.49920663981447577, 'support': 54132}, 'accuracy': 0.3902116928794213, 'macro avg': {'precision': 0.3831835761553088, 'recall': 0.37790481295761813, 'f1-score': 0.3539475201758731, 'support': 150690}, 'weighted avg': {'precision': 0.38391449977110237, 'recall': 0.3902116928794213, 'f1-score': 0.36012343534995483, 'support': 150690}}
[[13969  7283 27770]
 [10752  8022 28762]
 [ 9541  7781 36810]]
Evaluating performance on  val set...
222/222 - 1s - 1s/epoch - 6ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0940477
{'0': {'precision': 0.41480611045828436, 'recall': 0.2643930693563689, 'f1-score': 0.3229446206391803, 'support': 20027}, '1': {'precision': 0.2884661402249342, 'recall': 0.15086665415180528, 'f1-score': 0.19811824643576156, 'support': 15981}, '2': {'precision': 0.38969739619985927, 'recall': 0.6707364341085271, 'f1-score': 0.49297605270186057, 'support': 20640}, 'accuracy': 0.3804194322835758, 'macro avg': {'precision': 0.3643232156276926, 'recall': 0.3619987192055671, 'f1-score': 0.33801297325893415, 'support': 56648}, 'weighted avg': {'precision': 0.370015774937294, 'recall': 0.3804194322835758, 'f1-score': 0.3496816364496041, 'support': 56648}}
[[ 5295  3019 11713]
 [ 3602  2411  9968]
 [ 3868  2928 13844]]
training model: results/QRTEA/W5/deepOF_L1/h1000
Epoch 1/50
589/589 - 12s - loss: 3.2873 - accuracy1000: 0.3884 - val_loss: 3.4055 - val_accuracy1000: 0.3917 - 12s/epoch - 20ms/step
Epoch 2/50
589/589 - 10s - loss: 3.2752 - accuracy1000: 0.3939 - val_loss: 3.3665 - val_accuracy1000: 0.3928 - 10s/epoch - 16ms/step
Epoch 3/50
589/589 - 9s - loss: 3.2705 - accuracy1000: 0.3909 - val_loss: 3.2893 - val_accuracy1000: 0.3924 - 9s/epoch - 16ms/step
Epoch 4/50
589/589 - 10s - loss: 3.2668 - accuracy1000: 0.3904 - val_loss: 3.2762 - val_accuracy1000: 0.3931 - 10s/epoch - 17ms/step
Epoch 5/50
589/589 - 9s - loss: 3.2697 - accuracy1000: 0.3837 - val_loss: 3.2764 - val_accuracy1000: 0.3924 - 9s/epoch - 16ms/step
Epoch 6/50
589/589 - 9s - loss: 3.2674 - accuracy1000: 0.3840 - val_loss: 3.2742 - val_accuracy1000: 0.3926 - 9s/epoch - 16ms/step
Epoch 7/50
589/589 - 10s - loss: 3.2679 - accuracy1000: 0.3851 - val_loss: 3.2742 - val_accuracy1000: 0.3924 - 10s/epoch - 16ms/step
Epoch 8/50
589/589 - 10s - loss: 3.2675 - accuracy1000: 0.3846 - val_loss: 3.2747 - val_accuracy1000: 0.3930 - 10s/epoch - 16ms/step
Epoch 9/50
589/589 - 9s - loss: 3.2691 - accuracy1000: 0.3838 - val_loss: 3.2751 - val_accuracy1000: 0.3926 - 9s/epoch - 16ms/step
Epoch 10/50
589/589 - 10s - loss: 3.2659 - accuracy1000: 0.3881 - val_loss: 3.2736 - val_accuracy1000: 0.3929 - 10s/epoch - 16ms/step
Epoch 11/50
589/589 - 9s - loss: 3.2671 - accuracy1000: 0.3883 - val_loss: 3.2754 - val_accuracy1000: 0.3928 - 9s/epoch - 16ms/step
Epoch 12/50
589/589 - 9s - loss: 3.2672 - accuracy1000: 0.3875 - val_loss: 3.2761 - val_accuracy1000: 0.3932 - 9s/epoch - 16ms/step
Epoch 13/50
589/589 - 9s - loss: 3.2656 - accuracy1000: 0.3861 - val_loss: 3.2762 - val_accuracy1000: 0.3926 - 9s/epoch - 16ms/step
Epoch 14/50
589/589 - 10s - loss: 3.2651 - accuracy1000: 0.3855 - val_loss: 3.2750 - val_accuracy1000: 0.3918 - 10s/epoch - 17ms/step
Epoch 15/50
589/589 - 10s - loss: 3.2652 - accuracy1000: 0.3864 - val_loss: 3.2746 - val_accuracy1000: 0.3912 - 10s/epoch - 17ms/step
Epoch 16/50
589/589 - 9s - loss: 3.2641 - accuracy1000: 0.3862 - val_loss: 3.2761 - val_accuracy1000: 0.3908 - 9s/epoch - 16ms/step
Epoch 17/50
589/589 - 9s - loss: 3.2609 - accuracy1000: 0.3891 - val_loss: 3.2744 - val_accuracy1000: 0.3921 - 9s/epoch - 15ms/step
Epoch 18/50
589/589 - 9s - loss: 3.2600 - accuracy1000: 0.3911 - val_loss: 3.2749 - val_accuracy1000: 0.3924 - 9s/epoch - 15ms/step
Epoch 19/50
589/589 - 10s - loss: 3.2589 - accuracy1000: 0.3925 - val_loss: 3.2738 - val_accuracy1000: 0.3923 - 10s/epoch - 17ms/step
Epoch 20/50
589/589 - 10s - loss: 3.2564 - accuracy1000: 0.3948 - val_loss: 3.2737 - val_accuracy1000: 0.3919 - 10s/epoch - 17ms/step
testing model: results/QRTEA/W5/deepOF_L1/h1000
Evaluating performance on  test set...
2185/2185 - 13s - 13s/epoch - 6ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1088077
{'0': {'precision': 0.3559155621011291, 'recall': 0.003890173689548042, 'f1-score': 0.007696227256321521, 'support': 186367}, '1': {'precision': 0.33036730321496266, 'recall': 0.9894887514516434, 'f1-score': 0.4953490635934433, 'support': 185135}, '2': {'precision': 0.31956440105144573, 'recall': 0.004533854735507382, 'f1-score': 0.008940860045597337, 'support': 187699}, 'accuracy': 0.3304089227308249, 'macro avg': {'precision': 0.3352824221225125, 'recall': 0.3326375932922329, 'f1-score': 0.17066205029845405, 'support': 559201}, 'weighted avg': {'precision': 0.33525581097987767, 'recall': 0.3304089227308249, 'f1-score': 0.16956150322182822, 'support': 559201}}
[[   725 184950    692]
 [   826 183189   1120]
 [   486 186362    851]]
Evaluating performance on  train set...
589/589 - 4s - 4s/epoch - 6ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1059706
{'0': {'precision': 0.48268839103869654, 'recall': 0.004894166236448116, 'f1-score': 0.009690080955106713, 'support': 48425}, '1': {'precision': 0.3240790319126151, 'recall': 0.9921317924760266, 'f1-score': 0.4885677960971081, 'support': 48804}, '2': {'precision': 0.44374209860935526, 'recall': 0.006565533753577374, 'f1-score': 0.012939615129396152, 'support': 53461}, 'accuracy': 0.3252239697391997, 'macro avg': {'precision': 0.41683650718688897, 'recall': 0.334530497488684, 'f1-score': 0.17039916406053698, 'support': 150690}, 'weighted avg': {'precision': 0.4175023873068345, 'recall': 0.3252239697391997, 'f1-score': 0.16593715346344784, 'support': 150690}}
[[  237 47993   195]
 [  139 48420   245]
 [  115 52995   351]]
Evaluating performance on  val set...
222/222 - 1s - 1s/epoch - 6ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0884616
{'0': {'precision': 0.3464052287581699, 'recall': 0.003104862331575864, 'f1-score': 0.006154560761772049, 'support': 17070}, '1': {'precision': 0.39277519876207245, 'recall': 0.9916475818402263, 'f1-score': 0.5626815471640422, 'support': 22269}, '2': {'precision': 0.36764705882352944, 'recall': 0.005777341267548674, 'f1-score': 0.011375917183322906, 'support': 17309}, 'accuracy': 0.39252930377065387, 'macro avg': {'precision': 0.36894249544792396, 'recall': 0.33350992847978356, 'f1-score': 0.19340400836971236, 'support': 56648}, 'weighted avg': {'precision': 0.37112433090861147, 'recall': 0.39252930377065387, 'f1-score': 0.22652731740795154, 'support': 56648}}
[[   53 16960    57]
 [   71 22083   115]
 [   29 17180   100]]
training model: results/QRTEA/W5/deepLOB_L2/h10
Epoch 1/50
589/589 - 29s - loss: 2.9907 - accuracy10: 0.4425 - val_loss: 3.3149 - val_accuracy10: 0.4378 - 29s/epoch - 50ms/step
Epoch 2/50
589/589 - 26s - loss: 2.7146 - accuracy10: 0.4935 - val_loss: 3.2027 - val_accuracy10: 0.4089 - 26s/epoch - 45ms/step
Epoch 3/50
589/589 - 26s - loss: 2.6037 - accuracy10: 0.5346 - val_loss: 3.1495 - val_accuracy10: 0.4738 - 26s/epoch - 44ms/step
Epoch 4/50
589/589 - 26s - loss: 2.4968 - accuracy10: 0.5793 - val_loss: 3.0752 - val_accuracy10: 0.4915 - 26s/epoch - 45ms/step
Epoch 5/50
589/589 - 26s - loss: 2.4109 - accuracy10: 0.6083 - val_loss: 3.0031 - val_accuracy10: 0.5393 - 26s/epoch - 45ms/step
Epoch 6/50
589/589 - 26s - loss: 2.3456 - accuracy10: 0.6288 - val_loss: 3.0098 - val_accuracy10: 0.5260 - 26s/epoch - 44ms/step
Epoch 7/50
589/589 - 26s - loss: 2.2789 - accuracy10: 0.6513 - val_loss: 2.9620 - val_accuracy10: 0.5806 - 26s/epoch - 45ms/step
Epoch 8/50
589/589 - 26s - loss: 2.2338 - accuracy10: 0.6626 - val_loss: 2.8796 - val_accuracy10: 0.6227 - 26s/epoch - 44ms/step
Epoch 9/50
589/589 - 26s - loss: 2.1850 - accuracy10: 0.6763 - val_loss: 2.8457 - val_accuracy10: 0.5865 - 26s/epoch - 44ms/step
Epoch 10/50
589/589 - 26s - loss: 2.1474 - accuracy10: 0.6837 - val_loss: 2.8754 - val_accuracy10: 0.6038 - 26s/epoch - 45ms/step
Epoch 11/50
589/589 - 27s - loss: 2.1256 - accuracy10: 0.6859 - val_loss: 2.8851 - val_accuracy10: 0.6030 - 27s/epoch - 45ms/step
Epoch 12/50
589/589 - 26s - loss: 2.0977 - accuracy10: 0.6933 - val_loss: 2.8575 - val_accuracy10: 0.6401 - 26s/epoch - 45ms/step
Epoch 13/50
589/589 - 26s - loss: 2.0681 - accuracy10: 0.6979 - val_loss: 2.8827 - val_accuracy10: 0.6186 - 26s/epoch - 44ms/step
Epoch 14/50
589/589 - 26s - loss: 2.0487 - accuracy10: 0.6994 - val_loss: 2.8971 - val_accuracy10: 0.6232 - 26s/epoch - 44ms/step
Epoch 15/50
589/589 - 26s - loss: 2.0229 - accuracy10: 0.7016 - val_loss: 2.8988 - val_accuracy10: 0.6049 - 26s/epoch - 45ms/step
Epoch 16/50
589/589 - 27s - loss: 2.0002 - accuracy10: 0.7044 - val_loss: 2.9889 - val_accuracy10: 0.5837 - 27s/epoch - 45ms/step
Epoch 17/50
589/589 - 26s - loss: 1.9815 - accuracy10: 0.7053 - val_loss: 2.9606 - val_accuracy10: 0.5906 - 26s/epoch - 45ms/step
Epoch 18/50
589/589 - 26s - loss: 1.9599 - accuracy10: 0.7055 - val_loss: 2.9802 - val_accuracy10: 0.5797 - 26s/epoch - 45ms/step
Epoch 19/50
589/589 - 26s - loss: 1.9345 - accuracy10: 0.7083 - val_loss: 3.0291 - val_accuracy10: 0.6003 - 26s/epoch - 44ms/step
testing model: results/QRTEA/W5/deepLOB_L2/h10
Evaluating performance on  test set...
2185/2185 - 33s - 33s/epoch - 15ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 1.3600774
{'0': {'precision': 0.33396825396825397, 'recall': 0.3841174359164779, 'f1-score': 0.3572917026445158, 'support': 80793}, '1': {'precision': 0.8698245118079415, 'recall': 0.4029257629824751, 'f1-score': 0.5507360116481393, 'support': 397093}, '2': {'precision': 0.22411869503465717, 'recall': 0.7781234628627643, 'f1-score': 0.34800375078714285, 'support': 81320}, 'accuracy': 0.4547697986073111, 'macro avg': {'precision': 0.47597048693695093, 'recall': 0.5217222205872392, 'f1-score': 0.4186771550265993, 'support': 559206}, 'weighted avg': {'precision': 0.698506193228303, 'recall': 0.4547697986073111, 'f1-score': 0.4933061315850749, 'support': 559206}}
[[ 31034  15295  34464]
 [ 52498 159999 184596]
 [  9393   8650  63277]]
Evaluating performance on  train set...
589/589 - 9s - 9s/epoch - 15ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.9448464
{'0': {'precision': 0.29990659760550226, 'recall': 0.5769356419470761, 'f1-score': 0.39465891949270915, 'support': 12244}, '1': {'precision': 0.950884111436204, 'recall': 0.5931236411534128, 'f1-score': 0.7305557184464121, 'support': 126026}, '2': {'precision': 0.1946751293094566, 'recall': 0.7605667820626358, 'f1-score': 0.3100019688915141, 'support': 12421}, 'accuracy': 0.605610155881904, 'macro avg': {'precision': 0.4818219461170543, 'recall': 0.6435420217210416, 'f1-score': 0.47840553561021176, 'support': 150691}, 'weighted avg': {'precision': 0.8356586470996514, 'recall': 0.605610155881904, 'f1-score': 0.6685983452150278, 'support': 150691}}
[[ 7064  2162  3018]
 [15215 74749 36062]
 [ 1275  1699  9447]]
Evaluating performance on  val set...
222/222 - 3s - 3s/epoch - 15ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.95718193
{'0': {'precision': 0.2771523178807947, 'recall': 0.605643994211288, 'f1-score': 0.38028169014084506, 'support': 5528}, '1': {'precision': 0.9333790465191815, 'recall': 0.5696821515892421, 'f1-score': 0.7075285878426437, 'support': 45399}, '2': {'precision': 0.24082092650809656, 'recall': 0.7096661422828177, 'f1-score': 0.3596102745792737, 'support': 5721}, 'accuracy': 0.5873287671232876, 'macro avg': {'precision': 0.4837840969693576, 'recall': 0.6283307626944492, 'f1-score': 0.4824735175209209, 'support': 56648}, 'weighted avg': {'precision': 0.7993982111764258, 'recall': 0.5873287671232876, 'f1-score': 0.6404571727763522, 'support': 56648}}
[[ 3348   950  1230]
 [ 7967 25863 11569]
 [  765   896  4060]]
training model: results/QRTEA/W5/deepLOB_L2/h20
Epoch 1/50
589/589 - 29s - loss: 2.9879 - accuracy20: 0.4466 - val_loss: 3.4622 - val_accuracy20: 0.4236 - 29s/epoch - 48ms/step
Epoch 2/50
589/589 - 26s - loss: 2.7243 - accuracy20: 0.4946 - val_loss: 3.2092 - val_accuracy20: 0.4270 - 26s/epoch - 44ms/step
Epoch 3/50
589/589 - 26s - loss: 2.6434 - accuracy20: 0.5342 - val_loss: 3.1793 - val_accuracy20: 0.4357 - 26s/epoch - 45ms/step
Epoch 4/50
589/589 - 26s - loss: 2.5783 - accuracy20: 0.5561 - val_loss: 3.2363 - val_accuracy20: 0.4148 - 26s/epoch - 44ms/step
Epoch 5/50
589/589 - 26s - loss: 2.5265 - accuracy20: 0.5789 - val_loss: 3.2969 - val_accuracy20: 0.5030 - 26s/epoch - 45ms/step
Epoch 6/50
589/589 - 26s - loss: 2.4738 - accuracy20: 0.5960 - val_loss: 3.2539 - val_accuracy20: 0.4809 - 26s/epoch - 44ms/step
Epoch 7/50
589/589 - 26s - loss: 2.4212 - accuracy20: 0.6178 - val_loss: 3.1959 - val_accuracy20: 0.4537 - 26s/epoch - 45ms/step
Epoch 8/50
589/589 - 26s - loss: 2.3718 - accuracy20: 0.6332 - val_loss: 3.1510 - val_accuracy20: 0.4961 - 26s/epoch - 44ms/step
Epoch 9/50
589/589 - 26s - loss: 2.3309 - accuracy20: 0.6468 - val_loss: 3.1318 - val_accuracy20: 0.4774 - 26s/epoch - 45ms/step
Epoch 10/50
589/589 - 26s - loss: 2.2910 - accuracy20: 0.6565 - val_loss: 3.2091 - val_accuracy20: 0.4997 - 26s/epoch - 45ms/step
Epoch 11/50
589/589 - 27s - loss: 2.2599 - accuracy20: 0.6651 - val_loss: 3.1611 - val_accuracy20: 0.5266 - 27s/epoch - 45ms/step
Epoch 12/50
589/589 - 26s - loss: 2.2260 - accuracy20: 0.6694 - val_loss: 3.1327 - val_accuracy20: 0.4917 - 26s/epoch - 45ms/step
Epoch 13/50
589/589 - 26s - loss: 2.1880 - accuracy20: 0.6776 - val_loss: 3.0957 - val_accuracy20: 0.4956 - 26s/epoch - 44ms/step
Epoch 14/50
589/589 - 27s - loss: 2.1662 - accuracy20: 0.6800 - val_loss: 3.1230 - val_accuracy20: 0.5503 - 27s/epoch - 45ms/step
Epoch 15/50
589/589 - 26s - loss: 2.1424 - accuracy20: 0.6823 - val_loss: 3.0194 - val_accuracy20: 0.5247 - 26s/epoch - 45ms/step
Epoch 16/50
589/589 - 26s - loss: 2.1162 - accuracy20: 0.6831 - val_loss: 3.0564 - val_accuracy20: 0.5444 - 26s/epoch - 44ms/step
Epoch 17/50
589/589 - 26s - loss: 2.0933 - accuracy20: 0.6869 - val_loss: 3.1047 - val_accuracy20: 0.5418 - 26s/epoch - 44ms/step
Epoch 18/50
589/589 - 26s - loss: 2.0754 - accuracy20: 0.6883 - val_loss: 3.1172 - val_accuracy20: 0.5460 - 26s/epoch - 45ms/step
Epoch 19/50
589/589 - 26s - loss: 2.0497 - accuracy20: 0.6922 - val_loss: 3.1592 - val_accuracy20: 0.5182 - 26s/epoch - 45ms/step
Epoch 20/50
589/589 - 26s - loss: 2.0314 - accuracy20: 0.6914 - val_loss: 3.1679 - val_accuracy20: 0.4914 - 26s/epoch - 44ms/step
Epoch 21/50
589/589 - 26s - loss: 2.0101 - accuracy20: 0.6936 - val_loss: 3.2255 - val_accuracy20: 0.5007 - 26s/epoch - 44ms/step
Epoch 22/50
589/589 - 26s - loss: 1.9886 - accuracy20: 0.6945 - val_loss: 3.2067 - val_accuracy20: 0.5146 - 26s/epoch - 45ms/step
Epoch 23/50
589/589 - 26s - loss: 1.9724 - accuracy20: 0.6944 - val_loss: 3.2620 - val_accuracy20: 0.5054 - 26s/epoch - 44ms/step
Epoch 24/50
589/589 - 26s - loss: 1.9563 - accuracy20: 0.6975 - val_loss: 3.2797 - val_accuracy20: 0.5229 - 26s/epoch - 45ms/step
Epoch 25/50
589/589 - 26s - loss: 1.9333 - accuracy20: 0.6968 - val_loss: 3.4321 - val_accuracy20: 0.5181 - 26s/epoch - 45ms/step
testing model: results/QRTEA/W5/deepLOB_L2/h20
Evaluating performance on  test set...
2185/2185 - 33s - 33s/epoch - 15ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 1.2046881
{'0': {'precision': 0.3731188172201143, 'recall': 0.3715850729363979, 'f1-score': 0.3723503656776656, 'support': 102418}, '1': {'precision': 0.7834393219549874, 'recall': 0.41845921689198357, 'f1-score': 0.5455325795839274, 'support': 353872}, '2': {'precision': 0.26835325043345326, 'recall': 0.6993178903183178, 'f1-score': 0.38786778079873674, 'support': 102916}, 'accuracy': 0.46156335947754495, 'macro avg': {'precision': 0.4749704632028517, 'recall': 0.49645406004889975, 'f1-score': 0.4352502420201099, 'support': 559206}, 'weighted avg': {'precision': 0.6134933564420166, 'recall': 0.46156335947754495, 'f1-score': 0.4847978835763234, 'support': 559206}}
[[ 38057  25043  39318]
 [ 48885 148081 156906]
 [ 15055  15890  71971]]
Evaluating performance on  train set...
589/589 - 10s - 10s/epoch - 16ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.9097072
{'0': {'precision': 0.36537308960143844, 'recall': 0.5825718210595473, 'f1-score': 0.44908952784364287, 'support': 16743}, '1': {'precision': 0.9142465311390772, 'recall': 0.5821846264490831, 'f1-score': 0.7113728854342118, 'support': 116798}, '2': {'precision': 0.24637739575565812, 'recall': 0.7128279883381924, 'f1-score': 0.3661879015710884, 'support': 17150}, 'accuracy': 0.5970960442229463, 'macro avg': {'precision': 0.5086656721653913, 'recall': 0.6258614786156076, 'f1-score': 0.508883438282981, 'support': 150691}, 'weighted avg': {'precision': 0.7772526582237053, 'recall': 0.5970960442229463, 'f1-score': 0.6429458876082537, 'support': 150691}}
[[ 9754  3470  3519]
 [14925 67998 33875]
 [ 2017  2908 12225]]
Evaluating performance on  val set...
222/222 - 3s - 3s/epoch - 16ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 1.0449344
{'0': {'precision': 0.2903368514188207, 'recall': 0.6131055651941812, 'f1-score': 0.39406416194887633, 'support': 7493}, '1': {'precision': 0.8812571731261587, 'recall': 0.48344835936554065, 'f1-score': 0.6243725468732897, 'support': 41295}, '2': {'precision': 0.2829233393869352, 'recall': 0.6540712468193384, 'f1-score': 0.39499058814490406, 'support': 7860}, 'accuracy': 0.5242727015958198, 'macro avg': {'precision': 0.4848391213106382, 'recall': 0.58354172379302, 'f1-score': 0.4711424323223567, 'support': 56648}, 'weighted avg': {'precision': 0.7200746088036164, 'recall': 0.5242727015958198, 'f1-score': 0.562081858343355, 'support': 56648}}
[[ 4594  1383  1516]
 [ 9817 19964 11514]
 [ 1412  1307  5141]]
training model: results/QRTEA/W5/deepLOB_L2/h30
Epoch 1/50
589/589 - 29s - loss: 3.0220 - accuracy30: 0.4346 - val_loss: 3.4112 - val_accuracy30: 0.4404 - 29s/epoch - 50ms/step
Epoch 2/50
589/589 - 27s - loss: 2.7409 - accuracy30: 0.5086 - val_loss: 3.2762 - val_accuracy30: 0.4995 - 27s/epoch - 46ms/step
Epoch 3/50
589/589 - 26s - loss: 2.6710 - accuracy30: 0.5340 - val_loss: 3.2524 - val_accuracy30: 0.4646 - 26s/epoch - 45ms/step
Epoch 4/50
589/589 - 26s - loss: 2.6142 - accuracy30: 0.5597 - val_loss: 3.1836 - val_accuracy30: 0.4383 - 26s/epoch - 44ms/step
Epoch 5/50
589/589 - 26s - loss: 2.5658 - accuracy30: 0.5741 - val_loss: 3.1784 - val_accuracy30: 0.4091 - 26s/epoch - 44ms/step
Epoch 6/50
589/589 - 26s - loss: 2.5239 - accuracy30: 0.5881 - val_loss: 3.1863 - val_accuracy30: 0.4935 - 26s/epoch - 45ms/step
Epoch 7/50
589/589 - 27s - loss: 2.4753 - accuracy30: 0.5992 - val_loss: 3.1768 - val_accuracy30: 0.5074 - 27s/epoch - 45ms/step
Epoch 8/50
589/589 - 26s - loss: 2.4318 - accuracy30: 0.6115 - val_loss: 3.1411 - val_accuracy30: 0.5184 - 26s/epoch - 45ms/step
Epoch 9/50
589/589 - 26s - loss: 2.3923 - accuracy30: 0.6195 - val_loss: 3.1219 - val_accuracy30: 0.5453 - 26s/epoch - 45ms/step
Epoch 10/50
589/589 - 26s - loss: 2.3548 - accuracy30: 0.6245 - val_loss: 3.1605 - val_accuracy30: 0.5232 - 26s/epoch - 45ms/step
Epoch 11/50
589/589 - 26s - loss: 2.3262 - accuracy30: 0.6331 - val_loss: 3.1218 - val_accuracy30: 0.5583 - 26s/epoch - 45ms/step
Epoch 12/50
589/589 - 26s - loss: 2.2906 - accuracy30: 0.6379 - val_loss: 3.1191 - val_accuracy30: 0.5504 - 26s/epoch - 44ms/step
Epoch 13/50
589/589 - 26s - loss: 2.2610 - accuracy30: 0.6444 - val_loss: 3.1656 - val_accuracy30: 0.5190 - 26s/epoch - 45ms/step
Epoch 14/50
589/589 - 26s - loss: 2.2316 - accuracy30: 0.6494 - val_loss: 3.1517 - val_accuracy30: 0.5476 - 26s/epoch - 44ms/step
Epoch 15/50
589/589 - 26s - loss: 2.2102 - accuracy30: 0.6520 - val_loss: 3.1391 - val_accuracy30: 0.5702 - 26s/epoch - 45ms/step
Epoch 16/50
589/589 - 26s - loss: 2.1857 - accuracy30: 0.6563 - val_loss: 3.1594 - val_accuracy30: 0.5612 - 26s/epoch - 45ms/step
Epoch 17/50
589/589 - 26s - loss: 2.1653 - accuracy30: 0.6583 - val_loss: 3.1144 - val_accuracy30: 0.5536 - 26s/epoch - 44ms/step
Epoch 18/50
589/589 - 26s - loss: 2.1543 - accuracy30: 0.6593 - val_loss: 3.1767 - val_accuracy30: 0.5294 - 26s/epoch - 45ms/step
Epoch 19/50
589/589 - 27s - loss: 2.1332 - accuracy30: 0.6612 - val_loss: 3.2207 - val_accuracy30: 0.5564 - 27s/epoch - 45ms/step
Epoch 20/50
589/589 - 26s - loss: 2.1059 - accuracy30: 0.6653 - val_loss: 3.2267 - val_accuracy30: 0.5481 - 26s/epoch - 45ms/step
Epoch 21/50
589/589 - 26s - loss: 2.0846 - accuracy30: 0.6657 - val_loss: 3.3219 - val_accuracy30: 0.5554 - 26s/epoch - 45ms/step
Epoch 22/50
589/589 - 26s - loss: 2.0787 - accuracy30: 0.6673 - val_loss: 3.3036 - val_accuracy30: 0.5468 - 26s/epoch - 45ms/step
Epoch 23/50
589/589 - 26s - loss: 2.0539 - accuracy30: 0.6673 - val_loss: 3.3811 - val_accuracy30: 0.5381 - 26s/epoch - 44ms/step
Epoch 24/50
589/589 - 26s - loss: 2.0314 - accuracy30: 0.6700 - val_loss: 3.4692 - val_accuracy30: 0.5391 - 26s/epoch - 44ms/step
Epoch 25/50
589/589 - 26s - loss: 2.0129 - accuracy30: 0.6742 - val_loss: 3.4369 - val_accuracy30: 0.5388 - 26s/epoch - 45ms/step
Epoch 26/50
589/589 - 26s - loss: 1.9911 - accuracy30: 0.6772 - val_loss: 3.5651 - val_accuracy30: 0.5555 - 26s/epoch - 45ms/step
Epoch 27/50
589/589 - 26s - loss: 1.9684 - accuracy30: 0.6767 - val_loss: 3.5727 - val_accuracy30: 0.5188 - 26s/epoch - 44ms/step
testing model: results/QRTEA/W5/deepLOB_L2/h30
Evaluating performance on  test set...
2185/2185 - 33s - 33s/epoch - 15ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.2055762
{'0': {'precision': 0.4000773673984333, 'recall': 0.3857159809456, 'f1-score': 0.39276543774625516, 'support': 117978}, '1': {'precision': 0.7236272143442093, 'recall': 0.4162255801269338, 'f1-score': 0.5284755339408534, 'support': 322688}, '2': {'precision': 0.30557041426949644, 'recall': 0.6698498397165513, 'f1-score': 0.41968842083008495, 'support': 118540}, 'accuracy': 0.4635518932200298, 'macro avg': {'precision': 0.476424998670713, 'recall': 0.4905971335963617, 'f1-score': 0.44697646417239784, 'support': 559206}, 'weighted avg': {'precision': 0.5667472507461341, 'recall': 0.4635518932200298, 'f1-score': 0.47678361697823707, 'support': 559206}}
[[ 45506  30154  42318]
 [ 50244 134311 138133]
 [ 17993  21143  79404]]
Evaluating performance on  train set...
589/589 - 10s - 10s/epoch - 16ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.8887418
{'0': {'precision': 0.41741398406516844, 'recall': 0.5773659500864838, 'f1-score': 0.4845305242203052, 'support': 20235}, '1': {'precision': 0.8772653401253705, 'recall': 0.585635359116022, 'f1-score': 0.7023820588380013, 'support': 109686}, '2': {'precision': 0.2891731845833586, 'recall': 0.6888781896966779, 'f1-score': 0.40735099432020383, 'support': 20770}, 'accuracy': 0.5987550683186122, 'macro avg': {'precision': 0.5279508362579658, 'recall': 0.6172931662997279, 'f1-score': 0.5314211924595035, 'support': 150691}, 'weighted avg': {'precision': 0.734458097088389, 'recall': 0.5987550683186122, 'f1-score': 0.632464007905804, 'support': 150691}}
[[11683  4884  3668]
 [13947 64236 31503]
 [ 2359  4103 14308]]
Evaluating performance on  val set...
222/222 - 3s - 3s/epoch - 15ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.99051845
{'0': {'precision': 0.3302267785026406, 'recall': 0.5883980958706964, 'f1-score': 0.42303406558420886, 'support': 9033}, '1': {'precision': 0.8251994653922482, 'recall': 0.5343281233609567, 'f1-score': 0.6486477882304252, 'support': 38132}, '2': {'precision': 0.351721094439541, 'recall': 0.5883159337762311, 'f1-score': 0.44024462418623, 'support': 9483}, 'accuracy': 0.551987713599774, 'macro avg': {'precision': 0.5023824461114766, 'recall': 0.5703473843359613, 'f1-score': 0.5039754926669547, 'support': 56648}, 'weighted avg': {'precision': 0.6670105854244056, 'recall': 0.551987713599774, 'f1-score': 0.5777846339920695, 'support': 56648}}
[[ 5315  2165  1553]
 [ 9027 20375  8730]
 [ 1753  2151  5579]]
training model: results/QRTEA/W5/deepLOB_L2/h50
Epoch 1/50
589/589 - 28s - loss: 3.1032 - accuracy50: 0.4253 - val_loss: 3.5595 - val_accuracy50: 0.4094 - 28s/epoch - 48ms/step
Epoch 2/50
589/589 - 26s - loss: 2.8641 - accuracy50: 0.4721 - val_loss: 3.5717 - val_accuracy50: 0.4319 - 26s/epoch - 44ms/step
Epoch 3/50
589/589 - 26s - loss: 2.7988 - accuracy50: 0.4994 - val_loss: 3.5734 - val_accuracy50: 0.4601 - 26s/epoch - 45ms/step
Epoch 4/50
589/589 - 27s - loss: 2.7565 - accuracy50: 0.5198 - val_loss: 3.5002 - val_accuracy50: 0.4663 - 27s/epoch - 45ms/step
Epoch 5/50
589/589 - 26s - loss: 2.7124 - accuracy50: 0.5373 - val_loss: 3.5833 - val_accuracy50: 0.4625 - 26s/epoch - 45ms/step
Epoch 6/50
589/589 - 26s - loss: 2.6795 - accuracy50: 0.5485 - val_loss: 3.4613 - val_accuracy50: 0.4631 - 26s/epoch - 45ms/step
Epoch 7/50
589/589 - 26s - loss: 2.6435 - accuracy50: 0.5578 - val_loss: 3.5074 - val_accuracy50: 0.4424 - 26s/epoch - 45ms/step
Epoch 8/50
589/589 - 26s - loss: 2.6089 - accuracy50: 0.5701 - val_loss: 3.4566 - val_accuracy50: 0.4401 - 26s/epoch - 44ms/step
Epoch 9/50
589/589 - 26s - loss: 2.5873 - accuracy50: 0.5732 - val_loss: 3.4221 - val_accuracy50: 0.4505 - 26s/epoch - 44ms/step
Epoch 10/50
589/589 - 26s - loss: 2.5532 - accuracy50: 0.5837 - val_loss: 3.4800 - val_accuracy50: 0.4376 - 26s/epoch - 44ms/step
Epoch 11/50
589/589 - 26s - loss: 2.5255 - accuracy50: 0.5903 - val_loss: 3.4274 - val_accuracy50: 0.4516 - 26s/epoch - 44ms/step
Epoch 12/50
589/589 - 26s - loss: 2.4949 - accuracy50: 0.5971 - val_loss: 3.4787 - val_accuracy50: 0.4537 - 26s/epoch - 45ms/step
Epoch 13/50
589/589 - 26s - loss: 2.4745 - accuracy50: 0.5997 - val_loss: 3.4324 - val_accuracy50: 0.4464 - 26s/epoch - 44ms/step
Epoch 14/50
589/589 - 26s - loss: 2.4425 - accuracy50: 0.6054 - val_loss: 3.4823 - val_accuracy50: 0.4345 - 26s/epoch - 44ms/step
Epoch 15/50
589/589 - 26s - loss: 2.4145 - accuracy50: 0.6102 - val_loss: 3.5213 - val_accuracy50: 0.4510 - 26s/epoch - 45ms/step
Epoch 16/50
589/589 - 27s - loss: 2.3877 - accuracy50: 0.6149 - val_loss: 3.5832 - val_accuracy50: 0.4404 - 27s/epoch - 45ms/step
Epoch 17/50
589/589 - 26s - loss: 2.3621 - accuracy50: 0.6173 - val_loss: 3.5592 - val_accuracy50: 0.4312 - 26s/epoch - 44ms/step
Epoch 18/50
589/589 - 26s - loss: 2.3311 - accuracy50: 0.6215 - val_loss: 3.6836 - val_accuracy50: 0.4376 - 26s/epoch - 45ms/step
Epoch 19/50
589/589 - 26s - loss: 2.3101 - accuracy50: 0.6247 - val_loss: 3.7390 - val_accuracy50: 0.4503 - 26s/epoch - 45ms/step
testing model: results/QRTEA/W5/deepLOB_L2/h50
Evaluating performance on  test set...
2185/2185 - 33s - 33s/epoch - 15ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.178672
{'0': {'precision': 0.406186939005779, 'recall': 0.3929016189290162, 'f1-score': 0.3994338408139605, 'support': 142934}, '1': {'precision': 0.5610639971752287, 'recall': 0.3320136658895292, 'f1-score': 0.41716621567159884, 'support': 272796}, '2': {'precision': 0.3277730253778158, 'recall': 0.5928726755694332, 'f1-score': 0.4221551685633036, 'support': 143476}, 'accuracy': 0.4145055668215291, 'macro avg': {'precision': 0.4316746538529412, 'recall': 0.4392626534626595, 'f1-score': 0.41291840834962096, 'support': 559206}, 'weighted avg': {'precision': 0.4616214788510373, 'recall': 0.4145055668215291, 'f1-score': 0.41391381089981266, 'support': 559206}}
[[ 56159  39926  46849]
 [ 54618  90572 127606]
 [ 27482  30931  85063]]
Evaluating performance on  train set...
589/589 - 9s - 9s/epoch - 16ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.9833645
{'0': {'precision': 0.4084845900840541, 'recall': 0.5091095422455022, 'f1-score': 0.4532797134263797, 'support': 26346}, '1': {'precision': 0.7599231138875541, 'recall': 0.4867493613222937, 'f1-score': 0.593407005759958, 'support': 97467}, '2': {'precision': 0.2897970230040595, 'recall': 0.5975891063323164, 'f1-score': 0.390313840321738, 'support': 26878}, 'accuracy': 0.5104286254653563, 'macro avg': {'precision': 0.4860682423252225, 'recall': 0.5311493366333707, 'f1-score': 0.4790001865026919, 'support': 150691}, 'weighted avg': {'precision': 0.6146254622766842, 'recall': 0.5104286254653563, 'f1-score': 0.5326831951510368, 'support': 150691}}
[[13413  8045  4888]
 [15550 47442 34475]
 [ 3873  6943 16062]]
Evaluating performance on  val set...
222/222 - 3s - 3s/epoch - 16ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.099109
{'0': {'precision': 0.33928841024608725, 'recall': 0.5801566130281387, 'f1-score': 0.42817223421821415, 'support': 11621}, '1': {'precision': 0.6831536091549296, 'recall': 0.3784632265536895, 'f1-score': 0.4870844365989998, 'support': 32809}, '2': {'precision': 0.34240094618568895, 'recall': 0.5212800785725978, 'f1-score': 0.41331646062493915, 'support': 12218}, 'accuracy': 0.4506425646095184, 'macro avg': {'precision': 0.4549476551955686, 'recall': 0.49329997271814197, 'f1-score': 0.4428577104807177, 'support': 56648}, 'weighted avg': {'precision': 0.5391172175316095, 'recall': 0.4506425646095184, 'f1-score': 0.4590884643790064, 'support': 56648}}
[[ 6742  2768  2111]
 [10271 12417 10121]
 [ 2858  2991  6369]]
training model: results/QRTEA/W5/deepLOB_L2/h100
Epoch 1/50
589/589 - 29s - loss: 3.1995 - accuracy100: 0.4271 - val_loss: 3.7533 - val_accuracy100: 0.3578 - 29s/epoch - 49ms/step
Epoch 2/50
589/589 - 26s - loss: 3.0448 - accuracy100: 0.4679 - val_loss: 3.6494 - val_accuracy100: 0.3986 - 26s/epoch - 44ms/step
Epoch 3/50
589/589 - 26s - loss: 2.9653 - accuracy100: 0.4925 - val_loss: 3.4812 - val_accuracy100: 0.4192 - 26s/epoch - 44ms/step
Epoch 4/50
589/589 - 26s - loss: 2.9216 - accuracy100: 0.5086 - val_loss: 3.5016 - val_accuracy100: 0.4107 - 26s/epoch - 45ms/step
Epoch 5/50
589/589 - 26s - loss: 2.8962 - accuracy100: 0.5181 - val_loss: 3.4528 - val_accuracy100: 0.4163 - 26s/epoch - 44ms/step
Epoch 6/50
589/589 - 26s - loss: 2.8596 - accuracy100: 0.5266 - val_loss: 3.4625 - val_accuracy100: 0.4181 - 26s/epoch - 45ms/step
Epoch 7/50
589/589 - 26s - loss: 2.8264 - accuracy100: 0.5361 - val_loss: 3.4850 - val_accuracy100: 0.4187 - 26s/epoch - 44ms/step
Epoch 8/50
589/589 - 26s - loss: 2.8053 - accuracy100: 0.5406 - val_loss: 3.4444 - val_accuracy100: 0.4023 - 26s/epoch - 44ms/step
Epoch 9/50
589/589 - 26s - loss: 2.7779 - accuracy100: 0.5478 - val_loss: 3.4647 - val_accuracy100: 0.4067 - 26s/epoch - 44ms/step
Epoch 10/50
589/589 - 26s - loss: 2.7483 - accuracy100: 0.5555 - val_loss: 3.4930 - val_accuracy100: 0.4017 - 26s/epoch - 44ms/step
Epoch 11/50
589/589 - 26s - loss: 2.7215 - accuracy100: 0.5604 - val_loss: 3.5547 - val_accuracy100: 0.3921 - 26s/epoch - 45ms/step
Epoch 12/50
589/589 - 26s - loss: 2.6925 - accuracy100: 0.5674 - val_loss: 3.5787 - val_accuracy100: 0.4002 - 26s/epoch - 44ms/step
Epoch 13/50
589/589 - 26s - loss: 2.6671 - accuracy100: 0.5712 - val_loss: 3.5883 - val_accuracy100: 0.4051 - 26s/epoch - 44ms/step
Epoch 14/50
589/589 - 26s - loss: 2.6314 - accuracy100: 0.5783 - val_loss: 3.6463 - val_accuracy100: 0.4036 - 26s/epoch - 44ms/step
Epoch 15/50
589/589 - 26s - loss: 2.6069 - accuracy100: 0.5829 - val_loss: 3.7329 - val_accuracy100: 0.3955 - 26s/epoch - 44ms/step
Epoch 16/50
589/589 - 27s - loss: 2.5777 - accuracy100: 0.5866 - val_loss: 3.7576 - val_accuracy100: 0.3862 - 27s/epoch - 45ms/step
Epoch 17/50
589/589 - 26s - loss: 2.5462 - accuracy100: 0.5920 - val_loss: 3.8654 - val_accuracy100: 0.3864 - 26s/epoch - 44ms/step
Epoch 18/50
589/589 - 26s - loss: 2.5304 - accuracy100: 0.5966 - val_loss: 3.8415 - val_accuracy100: 0.3927 - 26s/epoch - 45ms/step
testing model: results/QRTEA/W5/deepLOB_L2/h100
Evaluating performance on  test set...
2185/2185 - 33s - 33s/epoch - 15ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.1893109
{'0': {'precision': 0.4745215474355723, 'recall': 0.26282889405154247, 'f1-score': 0.33828683485855743, 'support': 185090}, '1': {'precision': 0.4239123617586185, 'recall': 0.21034450564839885, 'f1-score': 0.28117200066559433, 'support': 192798}, '2': {'precision': 0.36818254843195153, 'recall': 0.7330877243296308, 'f1-score': 0.4901795921377734, 'support': 181318}, 'accuracy': 0.39721140331112326, 'macro avg': {'precision': 0.42220548587538076, 'recall': 0.4020870413431907, 'f1-score': 0.36987947588730835, 'support': 559206}, 'weighted avg': {'precision': 0.42259341289931224, 'recall': 0.39721140331112326, 'f1-score': 0.36784528945600087, 'support': 559206}}
[[ 48647  32874 103569]
 [ 27713  40554 124531]
 [ 26158  22238 132922]]
Evaluating performance on  train set...
589/589 - 9s - 9s/epoch - 16ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0627675
{'0': {'precision': 0.46075301204819274, 'recall': 0.413544201135442, 'f1-score': 0.4358740561333523, 'support': 36990}, '1': {'precision': 0.6459339202877971, 'recall': 0.3594505248462339, 'f1-score': 0.4618756293419305, 'support': 75927}, '2': {'precision': 0.3276890974095881, 'recall': 0.6526976227034468, 'f1-score': 0.4363214851388778, 'support': 37774}, 'accuracy': 0.44623766515584873, 'macro avg': {'precision': 0.47812534324852596, 'recall': 0.4752307828950409, 'f1-score': 0.4446903902047202, 'support': 150691}, 'weighted avg': {'precision': 0.520702673994492, 'recall': 0.44623766515584873, 'f1-score': 0.4490873378307492, 'support': 150691}}
[[15297  8147 13546]
 [11597 27292 37038]
 [ 6306  6813 24655]]
Evaluating performance on  val set...
222/222 - 3s - 3s/epoch - 16ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.1337082
{'0': {'precision': 0.36708279403782723, 'recall': 0.5424481737413623, 'f1-score': 0.43785950845389576, 'support': 16208}, '1': {'precision': 0.5450959488272921, 'recall': 0.21613966858302333, 'f1-score': 0.30954110667150986, 'support': 23656}, '2': {'precision': 0.38474074709439465, 'recall': 0.5344971401334604, 'f1-score': 0.4474202638338196, 'support': 16784}, 'accuracy': 0.40382714305889, 'macro avg': {'precision': 0.43230649665317133, 'recall': 0.4310283274859487, 'f1-score': 0.3982736263197417, 'support': 56648}, 'weighted avg': {'precision': 0.44665224527707675, 'recall': 0.40382714305889, 'f1-score': 0.38710692417435405, 'support': 56648}}
[[8792 2284 5132]
 [9329 5113 9214]
 [5830 1983 8971]]
training model: results/QRTEA/W5/deepLOB_L2/h200
Epoch 1/50
589/589 - 31s - loss: 3.2579 - accuracy200: 0.4052 - val_loss: 3.4488 - val_accuracy200: 0.3485 - 31s/epoch - 52ms/step
Epoch 2/50
589/589 - 27s - loss: 3.1689 - accuracy200: 0.4316 - val_loss: 3.4670 - val_accuracy200: 0.3734 - 27s/epoch - 46ms/step
Epoch 3/50
589/589 - 27s - loss: 3.1144 - accuracy200: 0.4575 - val_loss: 3.4393 - val_accuracy200: 0.3841 - 27s/epoch - 45ms/step
Epoch 4/50
589/589 - 26s - loss: 3.0680 - accuracy200: 0.4735 - val_loss: 3.4363 - val_accuracy200: 0.3854 - 26s/epoch - 45ms/step
Epoch 5/50
589/589 - 27s - loss: 3.0289 - accuracy200: 0.4856 - val_loss: 3.5024 - val_accuracy200: 0.3754 - 27s/epoch - 45ms/step
Epoch 6/50
589/589 - 26s - loss: 2.9964 - accuracy200: 0.4938 - val_loss: 3.5253 - val_accuracy200: 0.3861 - 26s/epoch - 44ms/step
Epoch 7/50
589/589 - 26s - loss: 2.9643 - accuracy200: 0.5027 - val_loss: 3.5930 - val_accuracy200: 0.3683 - 26s/epoch - 44ms/step
Epoch 8/50
589/589 - 26s - loss: 2.9249 - accuracy200: 0.5157 - val_loss: 3.5997 - val_accuracy200: 0.3776 - 26s/epoch - 45ms/step
Epoch 9/50
589/589 - 26s - loss: 2.8843 - accuracy200: 0.5257 - val_loss: 3.6316 - val_accuracy200: 0.3755 - 26s/epoch - 44ms/step
Epoch 10/50
589/589 - 26s - loss: 2.8516 - accuracy200: 0.5358 - val_loss: 3.6302 - val_accuracy200: 0.3785 - 26s/epoch - 44ms/step
Epoch 11/50
589/589 - 26s - loss: 2.8142 - accuracy200: 0.5424 - val_loss: 3.6911 - val_accuracy200: 0.3747 - 26s/epoch - 45ms/step
Epoch 12/50
589/589 - 26s - loss: 2.7791 - accuracy200: 0.5503 - val_loss: 3.7796 - val_accuracy200: 0.3756 - 26s/epoch - 44ms/step
Epoch 13/50
589/589 - 26s - loss: 2.7419 - accuracy200: 0.5589 - val_loss: 3.8273 - val_accuracy200: 0.3777 - 26s/epoch - 45ms/step
Epoch 14/50
589/589 - 26s - loss: 2.7166 - accuracy200: 0.5665 - val_loss: 3.9364 - val_accuracy200: 0.3771 - 26s/epoch - 45ms/step
testing model: results/QRTEA/W5/deepLOB_L2/h200
Evaluating performance on  test set...
2185/2185 - 33s - 33s/epoch - 15ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.2088819
{'0': {'precision': 0.5929535232383808, 'recall': 0.021644843957367047, 'f1-score': 0.041765117414892354, 'support': 219267}, '1': {'precision': 0.2534389197375063, 'recall': 0.32400535639379174, 'f1-score': 0.2844103609919134, 'support': 123964}, '2': {'precision': 0.4065980515479143, 'recall': 0.7393448315777289, 'f1-score': 0.5246616953919602, 'support': 215975}, 'accuracy': 0.36585980837115484, 'macro avg': {'precision': 0.4176634981746005, 'recall': 0.3616650106429626, 'f1-score': 0.2836123912662553, 'support': 559206}, 'weighted avg': {'precision': 0.44571670656128703, 'recall': 0.36585980837115484, 'f1-score': 0.28205735927813963, 'support': 559206}}
[[  4746  64018 150503]
 [  1260  40165  82539]
 [  1998  54297 159680]]
Evaluating performance on  train set...
589/589 - 9s - 9s/epoch - 16ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1092397
{'0': {'precision': 0.49082949656577857, 'recall': 0.1399457691314453, 'f1-score': 0.21779392802719494, 'support': 46468}, '1': {'precision': 0.4391833778461817, 'recall': 0.3522556049741309, 'f1-score': 0.3909456314787392, 'support': 55085}, '2': {'precision': 0.37187432983058116, 'recall': 0.7057877813504824, 'f1-score': 0.4870995379148583, 'support': 49138}, 'accuracy': 0.40206780763283806, 'macro avg': {'precision': 0.43396240141418047, 'recall': 0.3993297184853528, 'f1-score': 0.3652796991402642, 'support': 150691}, 'weighted avg': {'precision': 0.4331608538949945, 'recall': 0.40206780763283806, 'f1-score': 0.36890581024503355, 'support': 150691}}
[[ 6503 13821 26144]
 [ 3246 19404 32435]
 [ 3500 10957 34681]]
Evaluating performance on  val set...
222/222 - 3s - 3s/epoch - 15ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.131879
{'0': {'precision': 0.37883410061567474, 'recall': 0.34788366525747466, 'f1-score': 0.3626998035154798, 'support': 19633}, '1': {'precision': 0.3337517115472387, 'recall': 0.17696170367233346, 'f1-score': 0.23128928952674652, 'support': 16529}, '2': {'precision': 0.40261262770055267, 'recall': 0.5867421653812359, 'f1-score': 0.4775431556782742, 'support': 20486}, 'accuracy': 0.38439132890834626, 'macro avg': {'precision': 0.371732813287822, 'recall': 0.3705291781036813, 'f1-score': 0.35717741624016686, 'support': 56648}, 'weighted avg': {'precision': 0.374278954749071, 'recall': 0.38439132890834626, 'f1-score': 0.3658878512256767, 'support': 56648}}
[[ 6830  3194  9609]
 [ 5378  2925  8226]
 [ 5821  2645 12020]]
training model: results/QRTEA/W5/deepLOB_L2/h300
Epoch 1/50
589/589 - 29s - loss: 3.2886 - accuracy300: 0.3872 - val_loss: 3.3126 - val_accuracy300: 0.3733 - 29s/epoch - 49ms/step
Epoch 2/50
589/589 - 26s - loss: 3.2013 - accuracy300: 0.4224 - val_loss: 3.4326 - val_accuracy300: 0.3771 - 26s/epoch - 44ms/step
Epoch 3/50
589/589 - 26s - loss: 3.1685 - accuracy300: 0.4410 - val_loss: 3.4624 - val_accuracy300: 0.3721 - 26s/epoch - 44ms/step
Epoch 4/50
589/589 - 26s - loss: 3.1290 - accuracy300: 0.4566 - val_loss: 3.5231 - val_accuracy300: 0.3625 - 26s/epoch - 44ms/step
Epoch 5/50
589/589 - 26s - loss: 3.0889 - accuracy300: 0.4704 - val_loss: 3.5066 - val_accuracy300: 0.3624 - 26s/epoch - 44ms/step
Epoch 6/50
589/589 - 26s - loss: 3.0629 - accuracy300: 0.4771 - val_loss: 3.5296 - val_accuracy300: 0.3665 - 26s/epoch - 44ms/step
Epoch 7/50
589/589 - 26s - loss: 3.0222 - accuracy300: 0.4901 - val_loss: 3.5890 - val_accuracy300: 0.3664 - 26s/epoch - 45ms/step
Epoch 8/50
589/589 - 26s - loss: 2.9875 - accuracy300: 0.4985 - val_loss: 3.6427 - val_accuracy300: 0.3733 - 26s/epoch - 45ms/step
Epoch 9/50
589/589 - 26s - loss: 2.9392 - accuracy300: 0.5143 - val_loss: 3.6090 - val_accuracy300: 0.3780 - 26s/epoch - 45ms/step
Epoch 10/50
589/589 - 26s - loss: 2.8991 - accuracy300: 0.5242 - val_loss: 3.6229 - val_accuracy300: 0.3706 - 26s/epoch - 45ms/step
Epoch 11/50
589/589 - 26s - loss: 2.8678 - accuracy300: 0.5316 - val_loss: 3.6745 - val_accuracy300: 0.3701 - 26s/epoch - 45ms/step
testing model: results/QRTEA/W5/deepLOB_L2/h300
Evaluating performance on  test set...
2185/2185 - 33s - 33s/epoch - 15ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1281502
{'0': {'precision': 0.4185650968974798, 'recall': 0.1878412356321839, 'f1-score': 0.2593105671101525, 'support': 222720}, '1': {'precision': 0.211357586512866, 'recall': 0.13308063226837885, 'f1-score': 0.16332450764248568, 'support': 116343}, '2': {'precision': 0.395440414507772, 'recall': 0.6933674929477658, 'f1-score': 0.5036435296621424, 'support': 220143}, 'accuracy': 0.37545913312804224, 'macro avg': {'precision': 0.3417876993060392, 'recall': 0.3380964536161095, 'f1-score': 0.30875953480492685, 'support': 559206}, 'weighted avg': {'precision': 0.36635199414823433, 'recall': 0.37545913312804224, 'f1-score': 0.3355273553034765, 'support': 559206}}
[[ 41836  27938 152946]
 [ 20446  15483  80414]
 [ 37669  29834 152640]]
Evaluating performance on  train set...
589/589 - 9s - 9s/epoch - 16ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1094979
{'0': {'precision': 0.3758238928939238, 'recall': 0.29897794072465844, 'f1-score': 0.33302533566042686, 'support': 48823}, '1': {'precision': 0.3811775088250126, 'recall': 0.12300901157468622, 'f1-score': 0.18599572458976055, 'support': 49159}, '2': {'precision': 0.3687165970391824, 'recall': 0.671460281925288, 'f1-score': 0.47603163501371937, 'support': 52709}, 'accuracy': 0.37186029689895217, 'macro avg': {'precision': 0.3752393329193729, 'recall': 0.36448241140821086, 'f1-score': 0.33168423175463563, 'support': 150691}, 'weighted avg': {'precision': 0.37508436597027767, 'recall': 0.37186029689895217, 'f1-score': 0.33508179810337174, 'support': 150691}}
[[14597  4631 29595]
 [12112  6047 31000]
 [12131  5186 35392]]
Evaluating performance on  val set...
222/222 - 3s - 3s/epoch - 15ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.104452
{'0': {'precision': 0.3722330729166667, 'recall': 0.4541077190369819, 'f1-score': 0.4091142863531675, 'support': 20145}, '1': {'precision': 0.27870216306156403, 'recall': 0.06643310417768376, 'f1-score': 0.10729155546065976, 'support': 15128}, '2': {'precision': 0.38888498559685236, 'recall': 0.5178947368421053, 'f1-score': 0.4442125960554564, 'support': 21375}, 'accuracy': 0.3746469425222426, 'macro avg': {'precision': 0.3466067405250277, 'recall': 0.3461451866855903, 'f1-score': 0.3202061459564279, 'support': 56648}, 'weighted avg': {'precision': 0.3535386623329034, 'recall': 0.3746469425222426, 'f1-score': 0.3417553698326296, 'support': 56648}}
[[ 9148  1265  9732]
 [ 6459  1005  7664]
 [ 8969  1336 11070]]
training model: results/QRTEA/W5/deepLOB_L2/h500
Epoch 1/50
589/589 - 29s - loss: 3.3030 - accuracy500: 0.3817 - val_loss: 3.4276 - val_accuracy500: 0.3503 - 29s/epoch - 49ms/step
Epoch 2/50
589/589 - 26s - loss: 3.2752 - accuracy500: 0.3827 - val_loss: 3.3253 - val_accuracy500: 0.3612 - 26s/epoch - 44ms/step
Epoch 3/50
589/589 - 26s - loss: 3.2530 - accuracy500: 0.3889 - val_loss: 3.3618 - val_accuracy500: 0.3651 - 26s/epoch - 44ms/step
Epoch 4/50
589/589 - 26s - loss: 3.2172 - accuracy500: 0.4128 - val_loss: 3.3559 - val_accuracy500: 0.3669 - 26s/epoch - 45ms/step
Epoch 5/50
589/589 - 26s - loss: 3.1878 - accuracy500: 0.4306 - val_loss: 3.4122 - val_accuracy500: 0.3619 - 26s/epoch - 44ms/step
Epoch 6/50
589/589 - 26s - loss: 3.1730 - accuracy500: 0.4370 - val_loss: 3.4151 - val_accuracy500: 0.3614 - 26s/epoch - 44ms/step
Epoch 7/50
589/589 - 26s - loss: 3.1349 - accuracy500: 0.4517 - val_loss: 3.3973 - val_accuracy500: 0.3644 - 26s/epoch - 45ms/step
Epoch 8/50
589/589 - 26s - loss: 3.1164 - accuracy500: 0.4570 - val_loss: 3.4097 - val_accuracy500: 0.3555 - 26s/epoch - 44ms/step
Epoch 9/50
589/589 - 26s - loss: 3.0830 - accuracy500: 0.4692 - val_loss: 3.4373 - val_accuracy500: 0.3649 - 26s/epoch - 44ms/step
Epoch 10/50
589/589 - 26s - loss: 3.0542 - accuracy500: 0.4768 - val_loss: 3.4312 - val_accuracy500: 0.3630 - 26s/epoch - 43ms/step
Epoch 11/50
589/589 - 26s - loss: 3.0050 - accuracy500: 0.4917 - val_loss: 3.5113 - val_accuracy500: 0.3613 - 26s/epoch - 44ms/step
Epoch 12/50
589/589 - 26s - loss: 2.9635 - accuracy500: 0.5025 - val_loss: 3.5370 - val_accuracy500: 0.3599 - 26s/epoch - 44ms/step
testing model: results/QRTEA/W5/deepLOB_L2/h500
Evaluating performance on  test set...
2185/2185 - 33s - 33s/epoch - 15ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1020349
{'0': {'precision': 0.3973671564784137, 'recall': 0.14710315899855814, 'f1-score': 0.2147186442994294, 'support': 213612}, '1': {'precision': 0.2973229542434023, 'recall': 0.04577809608722978, 'f1-score': 0.07934035034388419, 'support': 136834}, '2': {'precision': 0.3753104169389622, 'recall': 0.8253017819505652, 'f1-score': 0.5159773591686382, 'support': 208760}, 'accuracy': 0.37549132162387383, 'macro avg': {'precision': 0.35666684255359277, 'recall': 0.3393943456787844, 'f1-score': 0.2700121179373172, 'support': 559206}, 'weighted avg': {'precision': 0.3646528914045743, 'recall': 0.37549132162387383, 'f1-score': 0.294056877152766, 'support': 559206}}
[[ 31423   7362 174827]
 [ 18627   6264 111943]
 [ 29028   7442 172290]]
Evaluating performance on  train set...
589/589 - 9s - 9s/epoch - 15ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1167415
{'0': {'precision': 0.37126053533388903, 'recall': 0.16347212593287386, 'f1-score': 0.22699473356362196, 'support': 49042}, '1': {'precision': 0.37103684661525277, 'recall': 0.04554059739167017, 'f1-score': 0.08112412177985949, 'support': 47540}, '2': {'precision': 0.36331553925784105, 'recall': 0.8276441996710344, 'f1-score': 0.5049641711440991, 'support': 54109}, 'accuracy': 0.3647530376731192, 'macro avg': {'precision': 0.36853764040232767, 'recall': 0.3455523076651928, 'f1-score': 0.2710276754958602, 'support': 150691}, 'weighted avg': {'precision': 0.36833713609728663, 'recall': 0.3647530376731192, 'f1-score': 0.2807866615078387, 'support': 150691}}
[[ 8017  1646 39379]
 [ 6275  2165 39100]
 [ 7302  2024 44783]]
Evaluating performance on  val set...
222/222 - 3s - 3s/epoch - 16ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1031481
{'0': {'precision': 0.3628057158560044, 'recall': 0.2638652942939942, 'f1-score': 0.30552502169511137, 'support': 20014}, '1': {'precision': 0.2929447852760736, 'recall': 0.023886943471735866, 'f1-score': 0.044172062904717854, 'support': 15992}, '2': {'precision': 0.363489261547514, 'recall': 0.7182443561670381, 'f1-score': 0.4826957512615986, 'support': 20642}, 'accuracy': 0.3616897330885468, 'macro avg': {'precision': 0.339746587559864, 'recall': 0.3353321979775894, 'f1-score': 0.27746427862047596, 'support': 56648}, 'weighted avg': {'precision': 0.3433327203103521, 'recall': 0.3616897330885468, 'f1-score': 0.2963031900812054, 'support': 56648}}
[[ 5281   455 14278]
 [ 3926   382 11684]
 [ 5349   467 14826]]
training model: results/QRTEA/W5/deepLOB_L2/h1000
Epoch 1/50
589/589 - 29s - loss: 3.2512 - accuracy1000: 0.4157 - val_loss: 3.5599 - val_accuracy1000: 0.3807 - 29s/epoch - 49ms/step
Epoch 2/50
589/589 - 27s - loss: 3.2222 - accuracy1000: 0.4225 - val_loss: 3.5074 - val_accuracy1000: 0.3753 - 27s/epoch - 46ms/step
Epoch 3/50
589/589 - 26s - loss: 3.1679 - accuracy1000: 0.4497 - val_loss: 3.5445 - val_accuracy1000: 0.3536 - 26s/epoch - 45ms/step
Epoch 4/50
589/589 - 27s - loss: 3.1581 - accuracy1000: 0.4528 - val_loss: 3.5724 - val_accuracy1000: 0.3657 - 27s/epoch - 45ms/step
Epoch 5/50
589/589 - 26s - loss: 3.1527 - accuracy1000: 0.4551 - val_loss: 3.7206 - val_accuracy1000: 0.3470 - 26s/epoch - 45ms/step
Epoch 6/50
589/589 - 26s - loss: 3.1115 - accuracy1000: 0.4681 - val_loss: 3.6731 - val_accuracy1000: 0.3413 - 26s/epoch - 45ms/step
Epoch 7/50
589/589 - 26s - loss: 3.0742 - accuracy1000: 0.4818 - val_loss: 3.7250 - val_accuracy1000: 0.3460 - 26s/epoch - 44ms/step
Epoch 8/50
589/589 - 26s - loss: 3.0496 - accuracy1000: 0.4885 - val_loss: 3.5816 - val_accuracy1000: 0.3435 - 26s/epoch - 44ms/step
Epoch 9/50
589/589 - 27s - loss: 3.0055 - accuracy1000: 0.5018 - val_loss: 3.7473 - val_accuracy1000: 0.3385 - 27s/epoch - 45ms/step
Epoch 10/50
589/589 - 26s - loss: 2.9583 - accuracy1000: 0.5170 - val_loss: 3.7877 - val_accuracy1000: 0.3390 - 26s/epoch - 44ms/step
Epoch 11/50
589/589 - 26s - loss: 2.9185 - accuracy1000: 0.5272 - val_loss: 3.7370 - val_accuracy1000: 0.3323 - 26s/epoch - 44ms/step
Epoch 12/50
589/589 - 27s - loss: 2.8988 - accuracy1000: 0.5334 - val_loss: 3.8320 - val_accuracy1000: 0.3268 - 27s/epoch - 45ms/step
testing model: results/QRTEA/W5/deepLOB_L2/h1000
Evaluating performance on  test set...
2185/2185 - 33s - 33s/epoch - 15ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1270707
{'0': {'precision': 0.34473479638820786, 'recall': 0.06186651213452881, 'f1-score': 0.1049063985624275, 'support': 186369}, '1': {'precision': 0.339075557604749, 'recall': 0.6355617731733797, 'f1-score': 0.4422228778349247, 'support': 185137}, '2': {'precision': 0.3454347096341054, 'recall': 0.3289451251997869, 'f1-score': 0.33698832005239604, 'support': 187700}, 'accuracy': 0.3414466225326624, 'macro avg': {'precision': 0.34308168787568744, 'recall': 0.3421244701692318, 'f1-score': 0.29470586548324945, 'support': 559206}, 'weighted avg': {'precision': 0.3430961144455995, 'recall': 0.3414466225326624, 'f1-score': 0.2944815062807628, 'support': 559206}}
[[ 11530 115229  59610]
 [ 10084 117666  57387]
 [ 11832 114125  61743]]
Evaluating performance on  train set...
589/589 - 9s - 9s/epoch - 16ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.150348
{'0': {'precision': 0.3189922480620155, 'recall': 0.017001322095521403, 'f1-score': 0.03228210559347297, 'support': 48408}, '1': {'precision': 0.3485072363077706, 'recall': 0.7296212074652244, 'f1-score': 0.4717031111346569, 'support': 48813}, '2': {'precision': 0.3909795722810227, 'recall': 0.3357583691789789, 'f1-score': 0.3612709783877329, 'support': 53470}, 'accuracy': 0.3609439183494701, 'macro avg': {'precision': 0.3528263522169363, 'recall': 0.36079363291324157, 'f1-score': 0.2884187317052876, 'support': 150691}, 'weighted avg': {'precision': 0.3540963839907064, 'recall': 0.3609439183494701, 'f1-score': 0.29135857712654983, 'support': 150691}}
[[  823 31952 15633]
 [  866 35615 12332]
 [  891 34626 17953]]
Evaluating performance on  val set...
222/222 - 3s - 3s/epoch - 15ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1691378
{'0': {'precision': 0.3352318958502848, 'recall': 0.02415713866901202, 'f1-score': 0.04506672500546926, 'support': 17055}, '1': {'precision': 0.3930090663000043, 'recall': 0.8213451867816092, 'f1-score': 0.5316341654799616, 'support': 22272}, '2': {'precision': 0.291671362560577, 'recall': 0.14941400611973904, 'f1-score': 0.19760250439031837, 'support': 17321}, 'accuracy': 0.37588264369439345, 'macro avg': {'precision': 0.33997077490362204, 'recall': 0.3316387771901201, 'f1-score': 0.2581011316252497, 'support': 56648}, 'weighted avg': {'precision': 0.3446285408005942, 'recall': 0.37588264369439345, 'f1-score': 0.2830080869065578, 'support': 56648}}
[[  412 13886  2757]
 [  451 18293  3528]
 [  366 14367  2588]]
training model: results/QRTEA/W5/deepOF_L2/h10
Epoch 1/50
589/589 - 17s - loss: 2.8633 - accuracy10: 0.5071 - val_loss: 3.0311 - val_accuracy10: 0.6537 - 17s/epoch - 28ms/step
Epoch 2/50
589/589 - 15s - loss: 2.5105 - accuracy10: 0.6071 - val_loss: 2.9911 - val_accuracy10: 0.7285 - 15s/epoch - 25ms/step
Epoch 3/50
589/589 - 15s - loss: 2.3500 - accuracy10: 0.6354 - val_loss: 2.8874 - val_accuracy10: 0.7289 - 15s/epoch - 25ms/step
Epoch 4/50
589/589 - 15s - loss: 2.2331 - accuracy10: 0.6547 - val_loss: 2.8173 - val_accuracy10: 0.7228 - 15s/epoch - 25ms/step
Epoch 5/50
589/589 - 14s - loss: 2.1574 - accuracy10: 0.6634 - val_loss: 2.7851 - val_accuracy10: 0.7263 - 14s/epoch - 24ms/step
Epoch 6/50
589/589 - 15s - loss: 2.1242 - accuracy10: 0.6678 - val_loss: 2.8008 - val_accuracy10: 0.7341 - 15s/epoch - 25ms/step
Epoch 7/50
589/589 - 15s - loss: 2.0899 - accuracy10: 0.6698 - val_loss: 2.7448 - val_accuracy10: 0.7226 - 15s/epoch - 25ms/step
Epoch 8/50
589/589 - 14s - loss: 2.0662 - accuracy10: 0.6744 - val_loss: 2.7765 - val_accuracy10: 0.7219 - 14s/epoch - 25ms/step
Epoch 9/50
589/589 - 15s - loss: 2.0416 - accuracy10: 0.6789 - val_loss: 2.7736 - val_accuracy10: 0.7256 - 15s/epoch - 25ms/step
Epoch 10/50
589/589 - 15s - loss: 2.0240 - accuracy10: 0.6763 - val_loss: 2.7762 - val_accuracy10: 0.7084 - 15s/epoch - 25ms/step
Epoch 11/50
589/589 - 14s - loss: 1.9997 - accuracy10: 0.6797 - val_loss: 2.7433 - val_accuracy10: 0.7008 - 14s/epoch - 24ms/step
Epoch 12/50
589/589 - 14s - loss: 1.9817 - accuracy10: 0.6813 - val_loss: 2.7802 - val_accuracy10: 0.7111 - 14s/epoch - 24ms/step
Epoch 13/50
589/589 - 14s - loss: 1.9728 - accuracy10: 0.6851 - val_loss: 2.7837 - val_accuracy10: 0.7060 - 14s/epoch - 24ms/step
Epoch 14/50
589/589 - 14s - loss: 1.9498 - accuracy10: 0.6852 - val_loss: 2.7715 - val_accuracy10: 0.7078 - 14s/epoch - 25ms/step
Epoch 15/50
589/589 - 15s - loss: 1.9390 - accuracy10: 0.6856 - val_loss: 2.8326 - val_accuracy10: 0.7061 - 15s/epoch - 25ms/step
Epoch 16/50
589/589 - 15s - loss: 1.9213 - accuracy10: 0.6838 - val_loss: 2.8329 - val_accuracy10: 0.7049 - 15s/epoch - 25ms/step
Epoch 17/50
589/589 - 15s - loss: 1.9067 - accuracy10: 0.6858 - val_loss: 2.8465 - val_accuracy10: 0.6998 - 15s/epoch - 25ms/step
Epoch 18/50
589/589 - 15s - loss: 1.8938 - accuracy10: 0.6863 - val_loss: 2.8980 - val_accuracy10: 0.7065 - 15s/epoch - 25ms/step
Epoch 19/50
589/589 - 15s - loss: 1.8778 - accuracy10: 0.6875 - val_loss: 2.9219 - val_accuracy10: 0.7080 - 15s/epoch - 25ms/step
Epoch 20/50
589/589 - 15s - loss: 1.8607 - accuracy10: 0.6893 - val_loss: 2.9177 - val_accuracy10: 0.7051 - 15s/epoch - 25ms/step
Epoch 21/50
589/589 - 15s - loss: 1.8614 - accuracy10: 0.6883 - val_loss: 2.9253 - val_accuracy10: 0.7029 - 15s/epoch - 25ms/step
testing model: results/QRTEA/W5/deepOF_L2/h10
Evaluating performance on  test set...
2185/2185 - 18s - 18s/epoch - 8ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.9112976
{'0': {'precision': 0.33245033966252885, 'recall': 0.638457729917069, 'f1-score': 0.43723086834164043, 'support': 80790}, '1': {'precision': 0.8880665441673394, 'recall': 0.6122041939797478, 'f1-score': 0.7247732679820402, 'support': 397093}, '2': {'precision': 0.3250015348722986, 'recall': 0.5207826065569738, 'f1-score': 0.400232490005765, 'support': 81318}, 'accuracy': 0.6027027848662645, 'macro avg': {'precision': 0.5151728062340556, 'recall': 0.5904815101512636, 'f1-score': 0.5207455421098152, 'support': 559201}, 'weighted avg': {'precision': 0.7259145566211838, 'recall': 0.6027027848662645, 'f1-score': 0.6360367359471858, 'support': 559201}}
[[ 51581  16615  12594]
 [ 78630 243102  75361]
 [ 24943  14026  42349]]
Evaluating performance on  train set...
589/589 - 5s - 5s/epoch - 9ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.6418641
{'0': {'precision': 0.30491884965831434, 'recall': 0.700147106897679, 'f1-score': 0.4248239611226817, 'support': 12236}, '1': {'precision': 0.9479650680384998, 'recall': 0.7253831318799057, 'f1-score': 0.821870630392461, 'support': 126001}, '2': {'precision': 0.2982275192910077, 'recall': 0.6269172087047298, 'f1-score': 0.40418316895757295, 'support': 12453}, 'accuracy': 0.7151967615634747, 'macro avg': {'precision': 0.5170371456626073, 'recall': 0.6841491491607714, 'f1-score': 0.5502925868242386, 'support': 150690}, 'weighted avg': {'precision': 0.8420556166969877, 'recall': 0.7151967615634747, 'f1-score': 0.7551128826823695, 'support': 150690}}
[[ 8567  2404  1265]
 [17496 91399 17106]
 [ 2033  2613  7807]]
Evaluating performance on  val set...
222/222 - 2s - 2s/epoch - 9ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.69373035
{'0': {'precision': 0.3105384026537382, 'recall': 0.6628540305010894, 'f1-score': 0.4229365768896612, 'support': 5508}, '1': {'precision': 0.9231443269828707, 'recall': 0.7194087715047249, 'f1-score': 0.8086412875270814, 'support': 45397}, '2': {'precision': 0.3340691685062546, 'recall': 0.5533693191711649, 'f1-score': 0.41662296801258525, 'support': 5743}, 'accuracy': 0.6970766840841689, 'macro avg': {'precision': 0.5225839660476211, 'recall': 0.6452107070589931, 'f1-score': 0.5494002774764426, 'support': 56648}, 'weighted avg': {'precision': 0.8038587023123429, 'recall': 0.6970766840841689, 'f1-score': 0.7313954402745276, 'support': 56648}}
[[ 3651  1315   542]
 [ 6945 32659  5793]
 [ 1161  1404  3178]]
training model: results/QRTEA/W5/deepOF_L2/h20
Epoch 1/50
589/589 - 17s - loss: 2.8958 - accuracy20: 0.4869 - val_loss: 3.0761 - val_accuracy20: 0.6190 - 17s/epoch - 29ms/step
Epoch 2/50
589/589 - 15s - loss: 2.5578 - accuracy20: 0.5658 - val_loss: 3.0161 - val_accuracy20: 0.6939 - 15s/epoch - 25ms/step
Epoch 3/50
589/589 - 14s - loss: 2.4120 - accuracy20: 0.5987 - val_loss: 3.0270 - val_accuracy20: 0.6942 - 14s/epoch - 25ms/step
Epoch 4/50
589/589 - 15s - loss: 2.3051 - accuracy20: 0.6233 - val_loss: 2.9441 - val_accuracy20: 0.6864 - 15s/epoch - 25ms/step
Epoch 5/50
589/589 - 15s - loss: 2.2344 - accuracy20: 0.6386 - val_loss: 2.9428 - val_accuracy20: 0.7000 - 15s/epoch - 25ms/step
Epoch 6/50
589/589 - 14s - loss: 2.1948 - accuracy20: 0.6480 - val_loss: 2.9606 - val_accuracy20: 0.7110 - 14s/epoch - 24ms/step
Epoch 7/50
589/589 - 15s - loss: 2.1659 - accuracy20: 0.6525 - val_loss: 2.9163 - val_accuracy20: 0.7016 - 15s/epoch - 25ms/step
Epoch 8/50
589/589 - 15s - loss: 2.1346 - accuracy20: 0.6567 - val_loss: 2.9443 - val_accuracy20: 0.7014 - 15s/epoch - 25ms/step
Epoch 9/50
589/589 - 14s - loss: 2.1246 - accuracy20: 0.6590 - val_loss: 2.9229 - val_accuracy20: 0.7099 - 14s/epoch - 24ms/step
Epoch 10/50
589/589 - 15s - loss: 2.0994 - accuracy20: 0.6625 - val_loss: 2.9224 - val_accuracy20: 0.7155 - 15s/epoch - 25ms/step
Epoch 11/50
589/589 - 15s - loss: 2.0801 - accuracy20: 0.6612 - val_loss: 2.9193 - val_accuracy20: 0.7014 - 15s/epoch - 25ms/step
Epoch 12/50
589/589 - 15s - loss: 2.0604 - accuracy20: 0.6652 - val_loss: 2.9524 - val_accuracy20: 0.6984 - 15s/epoch - 25ms/step
Epoch 13/50
589/589 - 15s - loss: 2.0448 - accuracy20: 0.6655 - val_loss: 2.9752 - val_accuracy20: 0.6953 - 15s/epoch - 25ms/step
Epoch 14/50
589/589 - 14s - loss: 2.0252 - accuracy20: 0.6672 - val_loss: 2.9967 - val_accuracy20: 0.7060 - 14s/epoch - 24ms/step
Epoch 15/50
589/589 - 14s - loss: 2.0078 - accuracy20: 0.6665 - val_loss: 3.0050 - val_accuracy20: 0.6998 - 14s/epoch - 24ms/step
Epoch 16/50
589/589 - 15s - loss: 1.9874 - accuracy20: 0.6682 - val_loss: 2.9927 - val_accuracy20: 0.6872 - 15s/epoch - 25ms/step
Epoch 17/50
589/589 - 14s - loss: 1.9748 - accuracy20: 0.6708 - val_loss: 3.0737 - val_accuracy20: 0.7016 - 14s/epoch - 25ms/step
testing model: results/QRTEA/W5/deepOF_L2/h20
Evaluating performance on  test set...
2185/2185 - 18s - 18s/epoch - 8ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.9490073
{'0': {'precision': 0.4162711972918684, 'recall': 0.5078893922824559, 'f1-score': 0.4575389338223975, 'support': 102416}, '1': {'precision': 0.8151604144733197, 'recall': 0.6235831701382707, 'f1-score': 0.7066169689517368, 'support': 353871}, '2': {'precision': 0.36366860504222237, 'recall': 0.5778999941698895, 'f1-score': 0.44641268816639335, 'support': 102914}, 'accuracy': 0.5939867775629872, 'macro avg': {'precision': 0.5317000722691368, 'recall': 0.569790852196872, 'f1-score': 0.5368561969801758, 'support': 559201}, 'weighted avg': {'precision': 0.6590135797168591, 'recall': 0.5939867775629872, 'f1-score': 0.6131117009022353, 'support': 559201}}
[[ 52016  27423  22977]
 [ 52115 220668  81088]
 [ 20826  22614  59474]]
Evaluating performance on  train set...
589/589 - 5s - 5s/epoch - 9ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.6658364
{'0': {'precision': 0.4056338028169014, 'recall': 0.5772406365920785, 'f1-score': 0.4764562087952789, 'support': 16714}, '1': {'precision': 0.8984754976090245, 'recall': 0.7528037943256339, 'f1-score': 0.8192142504448606, 'support': 116806}, '2': {'precision': 0.3598856631194683, 'recall': 0.6086196854979615, 'f1-score': 0.45231242019607426, 'support': 17170}, 'accuracy': 0.7169022496516027, 'macro avg': {'precision': 0.5546649878484647, 'recall': 0.646221372138558, 'f1-score': 0.5826609598120712, 'support': 150690}, 'weighted avg': {'precision': 0.7824429569962351, 'recall': 0.7169022496516027, 'f1-score': 0.7393910217402169, 'support': 150690}}
[[ 9648  5185  1881]
 [12168 87932 16706]
 [ 1969  4751 10450]]
Evaluating performance on  val set...
222/222 - 2s - 2s/epoch - 9ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.7167797
{'0': {'precision': 0.42720204494621367, 'recall': 0.5349426513736997, 'f1-score': 0.4750399715757683, 'support': 7498}, '1': {'precision': 0.861491042188403, 'recall': 0.7584068223665084, 'f1-score': 0.80666898586577, 'support': 41276}, '2': {'precision': 0.406885185863395, 'recall': 0.5643891287782575, 'f1-score': 0.47286656735475635, 'support': 7874}, 'accuracy': 0.7018606129077813, 'macro avg': {'precision': 0.565192757666004, 'recall': 0.6192462008394886, 'f1-score': 0.5848585082654315, 'support': 56648}, 'weighted avg': {'precision': 0.7408183721201738, 'recall': 0.7018606129077813, 'f1-score': 0.7163760436171089, 'support': 56648}}
[[ 4011  2649   838]
 [ 4332 31304  5640]
 [ 1046  2384  4444]]
training model: results/QRTEA/W5/deepOF_L2/h30
Epoch 1/50
589/589 - 17s - loss: 2.9307 - accuracy30: 0.4694 - val_loss: 3.1231 - val_accuracy30: 0.5845 - 17s/epoch - 29ms/step
Epoch 2/50
589/589 - 15s - loss: 2.6225 - accuracy30: 0.5408 - val_loss: 3.0646 - val_accuracy30: 0.6403 - 15s/epoch - 25ms/step
Epoch 3/50
589/589 - 15s - loss: 2.4930 - accuracy30: 0.5737 - val_loss: 3.0790 - val_accuracy30: 0.6548 - 15s/epoch - 25ms/step
Epoch 4/50
589/589 - 14s - loss: 2.4033 - accuracy30: 0.5969 - val_loss: 3.0738 - val_accuracy30: 0.6512 - 14s/epoch - 24ms/step
Epoch 5/50
589/589 - 15s - loss: 2.3445 - accuracy30: 0.6090 - val_loss: 3.0056 - val_accuracy30: 0.6501 - 15s/epoch - 25ms/step
Epoch 6/50
589/589 - 14s - loss: 2.3043 - accuracy30: 0.6190 - val_loss: 3.0200 - val_accuracy30: 0.6456 - 14s/epoch - 25ms/step
Epoch 7/50
589/589 - 14s - loss: 2.2707 - accuracy30: 0.6254 - val_loss: 2.9622 - val_accuracy30: 0.6443 - 14s/epoch - 24ms/step
Epoch 8/50
589/589 - 15s - loss: 2.2447 - accuracy30: 0.6319 - val_loss: 3.0060 - val_accuracy30: 0.6188 - 15s/epoch - 25ms/step
Epoch 9/50
589/589 - 15s - loss: 2.2246 - accuracy30: 0.6341 - val_loss: 3.0082 - val_accuracy30: 0.6329 - 15s/epoch - 25ms/step
Epoch 10/50
589/589 - 15s - loss: 2.2058 - accuracy30: 0.6363 - val_loss: 3.0570 - val_accuracy30: 0.6264 - 15s/epoch - 25ms/step
Epoch 11/50
589/589 - 15s - loss: 2.1873 - accuracy30: 0.6374 - val_loss: 2.9600 - val_accuracy30: 0.6460 - 15s/epoch - 25ms/step
Epoch 12/50
589/589 - 14s - loss: 2.1723 - accuracy30: 0.6394 - val_loss: 3.0354 - val_accuracy30: 0.6403 - 14s/epoch - 24ms/step
Epoch 13/50
589/589 - 14s - loss: 2.1509 - accuracy30: 0.6446 - val_loss: 3.0593 - val_accuracy30: 0.6236 - 14s/epoch - 24ms/step
Epoch 14/50
589/589 - 15s - loss: 2.1643 - accuracy30: 0.6389 - val_loss: 3.0492 - val_accuracy30: 0.6318 - 15s/epoch - 25ms/step
Epoch 15/50
589/589 - 14s - loss: 2.1245 - accuracy30: 0.6434 - val_loss: 3.0226 - val_accuracy30: 0.6386 - 14s/epoch - 24ms/step
Epoch 16/50
589/589 - 15s - loss: 2.1077 - accuracy30: 0.6460 - val_loss: 3.0383 - val_accuracy30: 0.6354 - 15s/epoch - 25ms/step
Epoch 17/50
589/589 - 15s - loss: 2.0807 - accuracy30: 0.6510 - val_loss: 3.1487 - val_accuracy30: 0.6244 - 15s/epoch - 26ms/step
Epoch 18/50
589/589 - 15s - loss: 2.0672 - accuracy30: 0.6523 - val_loss: 3.0898 - val_accuracy30: 0.6297 - 15s/epoch - 25ms/step
Epoch 19/50
589/589 - 15s - loss: 2.0528 - accuracy30: 0.6538 - val_loss: 3.1218 - val_accuracy30: 0.6411 - 15s/epoch - 25ms/step
Epoch 20/50
589/589 - 15s - loss: 2.0329 - accuracy30: 0.6559 - val_loss: 3.1699 - val_accuracy30: 0.6347 - 15s/epoch - 25ms/step
Epoch 21/50
589/589 - 15s - loss: 2.0172 - accuracy30: 0.6580 - val_loss: 3.1725 - val_accuracy30: 0.6231 - 15s/epoch - 25ms/step
testing model: results/QRTEA/W5/deepOF_L2/h30
Evaluating performance on  test set...
2185/2185 - 18s - 18s/epoch - 8ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.0090146
{'0': {'precision': 0.43688016061104656, 'recall': 0.4906463233735961, 'f1-score': 0.4622049036008448, 'support': 117975}, '1': {'precision': 0.7574487114986863, 'recall': 0.5458833300277668, 'f1-score': 0.6344946825275328, 'support': 322688}, '2': {'precision': 0.36676281225856294, 'recall': 0.6007103207410281, 'f1-score': 0.4554508007982397, 'support': 118538}, 'accuracy': 0.5458520281616092, 'macro avg': {'precision': 0.5203638947894319, 'recall': 0.5457466580474636, 'f1-score': 0.5173834623088724, 'support': 559201}, 'weighted avg': {'precision': 0.6070015557977934, 'recall': 0.5458520281616092, 'f1-score': 0.5601933305605246, 'support': 559201}}
[[ 57884  32289  27802]
 [ 51397 176150  95141]
 [ 23213  24118  71207]]
Evaluating performance on  train set...
589/589 - 5s - 5s/epoch - 9ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.73417795
{'0': {'precision': 0.44393714568352166, 'recall': 0.5763967791335276, 'f1-score': 0.5015690151743111, 'support': 20243}, '1': {'precision': 0.8672014990923465, 'recall': 0.6750847890303052, 'f1-score': 0.7591775217999784, 'support': 109684}, '2': {'precision': 0.35444108451642664, 'recall': 0.6661368781004672, 'f1-score': 0.462691310529397, 'support': 20763}, 'accuracy': 0.6605945981816975, 'macro avg': {'precision': 0.5551932430974316, 'recall': 0.6392061487547668, 'f1-score': 0.5744792825012289, 'support': 150690}, 'weighted avg': {'precision': 0.739690816274013, 'recall': 0.6605945981816975, 'f1-score': 0.6837198789289554, 'support': 150690}}
[[11668  6377  2198]
 [12645 74046 22993]
 [ 1970  4962 13831]]
Evaluating performance on  val set...
222/222 - 2s - 2s/epoch - 9ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.79152113
{'0': {'precision': 0.45584702604016525, 'recall': 0.5240251850215398, 'f1-score': 0.4875642343268242, 'support': 9053}, '1': {'precision': 0.8158033908850522, 'recall': 0.6879869874334287, 'f1-score': 0.7464632375964249, 'support': 38117}, '2': {'precision': 0.3957860385925085, 'recall': 0.5886262924667651, 'f1-score': 0.4733180622719945, 'support': 9478}, 'accuracy': 0.6451595819799464, 'macro avg': {'precision': 0.5558121518392419, 'recall': 0.6002128216405779, 'f1-score': 0.5691151780650813, 'support': 56648}, 'weighted avg': {'precision': 0.6880034785144569, 'recall': 0.6451595819799464, 'f1-score': 0.6593872128766703, 'support': 56648}}
[[ 4744  3182  1127]
 [ 4503 26224  7390]
 [ 1160  2739  5579]]
training model: results/QRTEA/W5/deepOF_L2/h50
Epoch 1/50
589/589 - 17s - loss: 3.0223 - accuracy50: 0.4491 - val_loss: 3.2118 - val_accuracy50: 0.5180 - 17s/epoch - 29ms/step
Epoch 2/50
589/589 - 15s - loss: 2.7781 - accuracy50: 0.5106 - val_loss: 3.1680 - val_accuracy50: 0.5705 - 15s/epoch - 25ms/step
Epoch 3/50
589/589 - 15s - loss: 2.6731 - accuracy50: 0.5402 - val_loss: 3.1940 - val_accuracy50: 0.6039 - 15s/epoch - 25ms/step
Epoch 4/50
589/589 - 15s - loss: 2.6006 - accuracy50: 0.5612 - val_loss: 3.2087 - val_accuracy50: 0.6127 - 15s/epoch - 25ms/step
Epoch 5/50
589/589 - 15s - loss: 2.5409 - accuracy50: 0.5748 - val_loss: 3.2049 - val_accuracy50: 0.6046 - 15s/epoch - 25ms/step
Epoch 6/50
589/589 - 15s - loss: 2.5070 - accuracy50: 0.5829 - val_loss: 3.1975 - val_accuracy50: 0.6105 - 15s/epoch - 25ms/step
Epoch 7/50
589/589 - 15s - loss: 2.4754 - accuracy50: 0.5907 - val_loss: 3.1817 - val_accuracy50: 0.6107 - 15s/epoch - 25ms/step
Epoch 8/50
589/589 - 15s - loss: 2.4477 - accuracy50: 0.5988 - val_loss: 3.1350 - val_accuracy50: 0.6085 - 15s/epoch - 25ms/step
Epoch 9/50
589/589 - 15s - loss: 2.4226 - accuracy50: 0.6041 - val_loss: 3.1338 - val_accuracy50: 0.6151 - 15s/epoch - 25ms/step
Epoch 10/50
589/589 - 15s - loss: 2.4036 - accuracy50: 0.6058 - val_loss: 3.1362 - val_accuracy50: 0.6114 - 15s/epoch - 25ms/step
Epoch 11/50
589/589 - 15s - loss: 2.3848 - accuracy50: 0.6089 - val_loss: 3.1767 - val_accuracy50: 0.6042 - 15s/epoch - 25ms/step
Epoch 12/50
589/589 - 15s - loss: 2.3637 - accuracy50: 0.6132 - val_loss: 3.1741 - val_accuracy50: 0.5978 - 15s/epoch - 25ms/step
Epoch 13/50
589/589 - 15s - loss: 2.3424 - accuracy50: 0.6158 - val_loss: 3.1618 - val_accuracy50: 0.6028 - 15s/epoch - 25ms/step
Epoch 14/50
589/589 - 15s - loss: 2.3228 - accuracy50: 0.6182 - val_loss: 3.1909 - val_accuracy50: 0.6002 - 15s/epoch - 25ms/step
Epoch 15/50
589/589 - 14s - loss: 2.3036 - accuracy50: 0.6211 - val_loss: 3.1619 - val_accuracy50: 0.5987 - 14s/epoch - 25ms/step
Epoch 16/50
589/589 - 15s - loss: 2.2883 - accuracy50: 0.6206 - val_loss: 3.2113 - val_accuracy50: 0.6036 - 15s/epoch - 25ms/step
Epoch 17/50
589/589 - 14s - loss: 2.2716 - accuracy50: 0.6259 - val_loss: 3.2289 - val_accuracy50: 0.6028 - 14s/epoch - 25ms/step
Epoch 18/50
589/589 - 15s - loss: 2.2494 - accuracy50: 0.6287 - val_loss: 3.3081 - val_accuracy50: 0.5850 - 15s/epoch - 25ms/step
Epoch 19/50
589/589 - 14s - loss: 2.2293 - accuracy50: 0.6301 - val_loss: 3.2662 - val_accuracy50: 0.5869 - 14s/epoch - 24ms/step
testing model: results/QRTEA/W5/deepOF_L2/h50
Evaluating performance on  test set...
2185/2185 - 18s - 18s/epoch - 8ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0005077
{'0': {'precision': 0.45641977592220695, 'recall': 0.4833837069375647, 'f1-score': 0.46951492993734456, 'support': 142932}, '1': {'precision': 0.6449140808208543, 'recall': 0.5907527969618322, 'f1-score': 0.6166464504230105, 'support': 272796}, '2': {'precision': 0.4338193859654677, 'recall': 0.47756023781478046, 'f1-score': 0.45464016031213095, 'support': 143473}, 'accuracy': 0.5342676425828995, 'macro avg': {'precision': 0.5117177475695097, 'recall': 0.5172322472380592, 'f1-score': 0.5136005135574954, 'support': 559201}, 'weighted avg': {'precision': 0.5425747481966988, 'recall': 0.5342676425828995, 'f1-score': 0.5374739687086798, 'support': 559201}}
[[ 69091  47356  26485]
 [ 48704 161155  62937]
 [ 33581  41375  68517]]
Evaluating performance on  train set...
589/589 - 5s - 5s/epoch - 9ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.7773266
{'0': {'precision': 0.48963215452350517, 'recall': 0.5227246882225844, 'f1-score': 0.5056375469795582, 'support': 26381}, '1': {'precision': 0.7767618074149788, 'recall': 0.7175597590138865, 'f1-score': 0.7459880495091762, 'support': 97433}, '2': {'precision': 0.44060395461115043, 'recall': 0.5331150468819765, 'f1-score': 0.4824648539439347, 'support': 26876}, 'accuracy': 0.650554117725131, 'macro avg': {'precision': 0.5689993055165448, 'recall': 0.5911331647061492, 'f1-score': 0.578030150144223, 'support': 150690}, 'weighted avg': {'precision': 0.6665398562245504, 'recall': 0.650554117725131, 'f1-score': 0.6569102340519775, 'support': 150690}}
[[13790 10347  2244]
 [11572 69914 15947]
 [ 2802  9746 14328]]
Evaluating performance on  val set...
222/222 - 2s - 2s/epoch - 9ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.84978837
{'0': {'precision': 0.48817703221201036, 'recall': 0.4700171821305842, 'f1-score': 0.4789250229789469, 'support': 11640}, '1': {'precision': 0.7048999761848059, 'recall': 0.7220307973776491, 'f1-score': 0.7133625559220932, 'support': 32795}, '2': {'precision': 0.4762427209047177, 'recall': 0.46204863669859986, 'f1-score': 0.46903831767932835, 'support': 12213}, 'accuracy': 0.6141964411806242, 'macro avg': {'precision': 0.556439909767178, 'recall': 0.551365538735611, 'f1-score': 0.5537752988601228, 'support': 56648}, 'weighted avg': {'precision': 0.611070606629322, 'recall': 0.6141964411806242, 'f1-score': 0.6125154862088269, 'support': 56648}}
[[ 5471  5011  1158]
 [ 4068 23679  5048]
 [ 1668  4902  5643]]
training model: results/QRTEA/W5/deepOF_L2/h100
Epoch 1/50
589/589 - 17s - loss: 3.1607 - accuracy100: 0.4270 - val_loss: 3.3297 - val_accuracy100: 0.4451 - 17s/epoch - 29ms/step
Epoch 2/50
589/589 - 15s - loss: 3.0029 - accuracy100: 0.4730 - val_loss: 3.3311 - val_accuracy100: 0.4791 - 15s/epoch - 25ms/step
Epoch 3/50
589/589 - 15s - loss: 2.9276 - accuracy100: 0.5013 - val_loss: 3.3571 - val_accuracy100: 0.4873 - 15s/epoch - 25ms/step
Epoch 4/50
589/589 - 15s - loss: 2.8800 - accuracy100: 0.5155 - val_loss: 3.3359 - val_accuracy100: 0.4912 - 15s/epoch - 25ms/step
Epoch 5/50
589/589 - 15s - loss: 2.8436 - accuracy100: 0.5246 - val_loss: 3.3355 - val_accuracy100: 0.4924 - 15s/epoch - 25ms/step
Epoch 6/50
589/589 - 15s - loss: 2.8135 - accuracy100: 0.5315 - val_loss: 3.3279 - val_accuracy100: 0.4955 - 15s/epoch - 25ms/step
Epoch 7/50
589/589 - 15s - loss: 2.7897 - accuracy100: 0.5393 - val_loss: 3.3234 - val_accuracy100: 0.4999 - 15s/epoch - 25ms/step
Epoch 8/50
589/589 - 15s - loss: 2.7674 - accuracy100: 0.5445 - val_loss: 3.3396 - val_accuracy100: 0.4986 - 15s/epoch - 25ms/step
Epoch 9/50
589/589 - 15s - loss: 2.7517 - accuracy100: 0.5489 - val_loss: 3.3249 - val_accuracy100: 0.4989 - 15s/epoch - 26ms/step
Epoch 10/50
589/589 - 14s - loss: 2.7342 - accuracy100: 0.5529 - val_loss: 3.3113 - val_accuracy100: 0.4991 - 14s/epoch - 24ms/step
Epoch 11/50
589/589 - 15s - loss: 2.7183 - accuracy100: 0.5563 - val_loss: 3.3219 - val_accuracy100: 0.4996 - 15s/epoch - 25ms/step
Epoch 12/50
589/589 - 15s - loss: 2.6989 - accuracy100: 0.5616 - val_loss: 3.3295 - val_accuracy100: 0.5004 - 15s/epoch - 25ms/step
Epoch 13/50
589/589 - 14s - loss: 2.6801 - accuracy100: 0.5664 - val_loss: 3.3679 - val_accuracy100: 0.5010 - 14s/epoch - 24ms/step
Epoch 14/50
589/589 - 15s - loss: 2.6674 - accuracy100: 0.5679 - val_loss: 3.3476 - val_accuracy100: 0.5020 - 15s/epoch - 25ms/step
Epoch 15/50
589/589 - 15s - loss: 2.6463 - accuracy100: 0.5710 - val_loss: 3.3730 - val_accuracy100: 0.4936 - 15s/epoch - 25ms/step
Epoch 16/50
589/589 - 15s - loss: 2.6305 - accuracy100: 0.5742 - val_loss: 3.4457 - val_accuracy100: 0.4951 - 15s/epoch - 25ms/step
Epoch 17/50
589/589 - 14s - loss: 2.6129 - accuracy100: 0.5782 - val_loss: 3.4709 - val_accuracy100: 0.4986 - 14s/epoch - 24ms/step
Epoch 18/50
589/589 - 15s - loss: 2.5850 - accuracy100: 0.5840 - val_loss: 3.5826 - val_accuracy100: 0.5008 - 15s/epoch - 25ms/step
Epoch 19/50
589/589 - 15s - loss: 2.5684 - accuracy100: 0.5870 - val_loss: 3.5886 - val_accuracy100: 0.4996 - 15s/epoch - 25ms/step
Epoch 20/50
589/589 - 15s - loss: 2.5469 - accuracy100: 0.5913 - val_loss: 3.5540 - val_accuracy100: 0.4941 - 15s/epoch - 25ms/step
testing model: results/QRTEA/W5/deepOF_L2/h100
Evaluating performance on  test set...
2185/2185 - 18s - 18s/epoch - 8ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.067067
{'0': {'precision': 0.49506923405380127, 'recall': 0.394642577354678, 'f1-score': 0.4391880516606941, 'support': 185089}, '1': {'precision': 0.4459691718855578, 'recall': 0.5100779053724623, 'f1-score': 0.4758740996489326, 'support': 192798}, '2': {'precision': 0.4423238902403934, 'recall': 0.46630706950373385, 'f1-score': 0.4539989636443206, 'support': 181314}, 'accuracy': 0.45767800844419093, 'macro avg': {'precision': 0.4611207653932508, 'recall': 0.45700918407695806, 'f1-score': 0.45635370498464906, 'support': 559201}, 'weighted avg': {'precision': 0.4610387815794723, 'recall': 0.45767800844419093, 'f1-score': 0.45663870424435477, 'support': 559201}}
[[73044 62855 49190]
 [37049 98342 57407]
 [37450 59316 84548]]
Evaluating performance on  train set...
589/589 - 6s - 6s/epoch - 10ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 0.91463083
{'0': {'precision': 0.5124710413093841, 'recall': 0.4601647980548426, 'f1-score': 0.4849114615953995, 'support': 37015}, '1': {'precision': 0.62000703411546, 'recall': 0.6502522757512285, 'f1-score': 0.6347695809569125, 'support': 75909}, '2': {'precision': 0.4720805475542401, 'recall': 0.4730180585712016, 'f1-score': 0.47254883807054904, 'support': 37766}, 'accuracy': 0.5591412834295574, 'macro avg': {'precision': 0.5348528743263614, 'recall': 0.5278117107924242, 'f1-score': 0.5307432935409536, 'support': 150690}, 'weighted avg': {'precision': 0.556518836722216, 'recall': 0.5591412834295574, 'f1-score': 0.5573030810961864, 'support': 150690}}
[[17033 14876  5106]
 [11678 49360 14871]
 [ 4526 15376 17864]]
Evaluating performance on  val set...
222/222 - 2s - 2s/epoch - 9ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 0.99873435
{'0': {'precision': 0.4961814744801512, 'recall': 0.40476190476190477, 'f1-score': 0.4458334748785542, 'support': 16212}, '1': {'precision': 0.5101395476730597, 'recall': 0.6278076223510004, 'f1-score': 0.5628899213046363, 'support': 23641}, '2': {'precision': 0.48475120385232745, 'recall': 0.41357546888955043, 'f1-score': 0.4463436576275543, 'support': 16795}, 'accuracy': 0.5004589747210846, 'macro avg': {'precision': 0.4970240753351794, 'recall': 0.4820483320008185, 'f1-score': 0.4850223512702483, 'support': 56648}, 'weighted avg': {'precision': 0.49861777255173806, 'recall': 0.5004589747210846, 'f1-score': 0.49483608696068354, 'support': 56648}}
[[ 6562  7126  2524]
 [ 3940 14842  4859]
 [ 2723  7126  6946]]
training model: results/QRTEA/W5/deepOF_L2/h200
Epoch 1/50
589/589 - 17s - loss: 3.2423 - accuracy200: 0.3984 - val_loss: 3.2401 - val_accuracy200: 0.4072 - 17s/epoch - 30ms/step
Epoch 2/50
589/589 - 15s - loss: 3.1452 - accuracy200: 0.4354 - val_loss: 3.2351 - val_accuracy200: 0.4071 - 15s/epoch - 25ms/step
Epoch 3/50
589/589 - 15s - loss: 3.0979 - accuracy200: 0.4541 - val_loss: 3.2276 - val_accuracy200: 0.4082 - 15s/epoch - 25ms/step
Epoch 4/50
589/589 - 15s - loss: 3.0664 - accuracy200: 0.4627 - val_loss: 3.2089 - val_accuracy200: 0.4140 - 15s/epoch - 26ms/step
Epoch 5/50
589/589 - 15s - loss: 3.0459 - accuracy200: 0.4688 - val_loss: 3.2096 - val_accuracy200: 0.4155 - 15s/epoch - 25ms/step
Epoch 6/50
589/589 - 15s - loss: 3.0282 - accuracy200: 0.4744 - val_loss: 3.1959 - val_accuracy200: 0.4201 - 15s/epoch - 25ms/step
Epoch 7/50
589/589 - 15s - loss: 3.0126 - accuracy200: 0.4778 - val_loss: 3.1929 - val_accuracy200: 0.4223 - 15s/epoch - 25ms/step
Epoch 8/50
589/589 - 15s - loss: 2.9960 - accuracy200: 0.4842 - val_loss: 3.1837 - val_accuracy200: 0.4286 - 15s/epoch - 25ms/step
Epoch 9/50
589/589 - 15s - loss: 2.9832 - accuracy200: 0.4876 - val_loss: 3.1837 - val_accuracy200: 0.4276 - 15s/epoch - 25ms/step
Epoch 10/50
589/589 - 15s - loss: 2.9709 - accuracy200: 0.4931 - val_loss: 3.1800 - val_accuracy200: 0.4310 - 15s/epoch - 25ms/step
Epoch 11/50
589/589 - 15s - loss: 2.9575 - accuracy200: 0.4969 - val_loss: 3.1742 - val_accuracy200: 0.4343 - 15s/epoch - 25ms/step
Epoch 12/50
589/589 - 15s - loss: 2.9438 - accuracy200: 0.5016 - val_loss: 3.1965 - val_accuracy200: 0.4302 - 15s/epoch - 25ms/step
Epoch 13/50
589/589 - 15s - loss: 2.9289 - accuracy200: 0.5083 - val_loss: 3.2015 - val_accuracy200: 0.4356 - 15s/epoch - 25ms/step
Epoch 14/50
589/589 - 15s - loss: 2.9147 - accuracy200: 0.5117 - val_loss: 3.2089 - val_accuracy200: 0.4315 - 15s/epoch - 25ms/step
Epoch 15/50
589/589 - 14s - loss: 2.9001 - accuracy200: 0.5176 - val_loss: 3.2155 - val_accuracy200: 0.4333 - 14s/epoch - 24ms/step
Epoch 16/50
589/589 - 15s - loss: 2.8888 - accuracy200: 0.5215 - val_loss: 3.2472 - val_accuracy200: 0.4286 - 15s/epoch - 25ms/step
Epoch 17/50
589/589 - 15s - loss: 2.8737 - accuracy200: 0.5244 - val_loss: 3.2285 - val_accuracy200: 0.4327 - 15s/epoch - 26ms/step
Epoch 18/50
589/589 - 15s - loss: 2.8597 - accuracy200: 0.5301 - val_loss: 3.2964 - val_accuracy200: 0.4249 - 15s/epoch - 25ms/step
Epoch 19/50
589/589 - 15s - loss: 2.8371 - accuracy200: 0.5375 - val_loss: 3.3154 - val_accuracy200: 0.4255 - 15s/epoch - 25ms/step
Epoch 20/50
589/589 - 15s - loss: 2.8310 - accuracy200: 0.5377 - val_loss: 3.3595 - val_accuracy200: 0.4240 - 15s/epoch - 25ms/step
Epoch 21/50
589/589 - 15s - loss: 2.8069 - accuracy200: 0.5432 - val_loss: 3.3496 - val_accuracy200: 0.4292 - 15s/epoch - 25ms/step
testing model: results/QRTEA/W5/deepOF_L2/h200
Evaluating performance on  test set...
2185/2185 - 18s - 18s/epoch - 8ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.057025
{'0': {'precision': 0.48504837940075457, 'recall': 0.44970697557749756, 'f1-score': 0.46670958031399534, 'support': 219265}, '1': {'precision': 0.28916904669359333, 'recall': 0.2760640185860411, 'f1-score': 0.28246461144814494, 'support': 123964}, '2': {'precision': 0.460036368840659, 'recall': 0.5060331894875262, 'f1-score': 0.48193977130912957, 'support': 215972}, 'accuracy': 0.43296775220359046, 'macro avg': {'precision': 0.41141793164500234, 'recall': 0.410601394550355, 'f1-score': 0.4103713210237567, 'support': 559201}, 'weighted avg': {'precision': 0.431965714054313, 'recall': 0.43296775220359046, 'f1-score': 0.4317481826933095, 'support': 559201}}
[[ 98605  44387  76273]
 [ 37738  34222  52004]
 [ 66946  39737 109289]]
Evaluating performance on  train set...
589/589 - 5s - 5s/epoch - 9ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0045882
{'0': {'precision': 0.49022024983563445, 'recall': 0.5134605866276443, 'f1-score': 0.5015713519933571, 'support': 46469}, '1': {'precision': 0.4894283476898982, 'recall': 0.3859285895899168, 'f1-score': 0.43155970755483347, 'support': 55062}, '2': {'precision': 0.4523037542662116, 'recall': 0.5391688195447426, 'f1-score': 0.4919310684026392, 'support': 49159}, 'accuracy': 0.47524719623067224, 'macro avg': {'precision': 0.4773174505972481, 'recall': 0.47951933192076784, 'f1-score': 0.47502070931694323, 'support': 150690}, 'weighted avg': {'precision': 0.4775615417485298, 'recall': 0.47524719623067224, 'f1-score': 0.47284424424161453, 'support': 150690}}
[[23860 10373 12236]
 [13953 21250 19859]
 [10859 11795 26505]]
Evaluating performance on  val set...
222/222 - 2s - 2s/epoch - 10ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0487735
{'0': {'precision': 0.4619540520070689, 'recall': 0.4666904713323812, 'f1-score': 0.46431018295313253, 'support': 19604}, '1': {'precision': 0.3621211146148401, 'recall': 0.3398562541523223, 'f1-score': 0.350635593220339, 'support': 16557}, '2': {'precision': 0.4592564776567781, 'recall': 0.4775711426758432, 'f1-score': 0.46823478739441504, 'support': 20487}, 'accuracy': 0.4335545826860613, 'macro avg': {'precision': 0.4277772147595624, 'recall': 0.42803928938684893, 'f1-score': 0.4277268545226289, 'support': 56648}, 'weighted avg': {'precision': 0.431799427834679, 'recall': 0.4335545826860613, 'f1-score': 0.4325048798353295, 'support': 56648}}
[[9149 4925 5530]
 [4940 5627 5990]
 [5716 4987 9784]]
training model: results/QRTEA/W5/deepOF_L2/h300
Epoch 1/50
589/589 - 17s - loss: 3.2712 - accuracy300: 0.3813 - val_loss: 3.2312 - val_accuracy300: 0.4061 - 17s/epoch - 28ms/step
Epoch 2/50
589/589 - 15s - loss: 3.2020 - accuracy300: 0.4126 - val_loss: 3.2163 - val_accuracy300: 0.4092 - 15s/epoch - 25ms/step
Epoch 3/50
589/589 - 15s - loss: 3.1692 - accuracy300: 0.4250 - val_loss: 3.2094 - val_accuracy300: 0.4050 - 15s/epoch - 25ms/step
Epoch 4/50
589/589 - 15s - loss: 3.1492 - accuracy300: 0.4338 - val_loss: 3.2023 - val_accuracy300: 0.4093 - 15s/epoch - 25ms/step
Epoch 5/50
589/589 - 14s - loss: 3.1350 - accuracy300: 0.4394 - val_loss: 3.2019 - val_accuracy300: 0.4074 - 14s/epoch - 25ms/step
Epoch 6/50
589/589 - 15s - loss: 3.1226 - accuracy300: 0.4431 - val_loss: 3.1975 - val_accuracy300: 0.4128 - 15s/epoch - 25ms/step
Epoch 7/50
589/589 - 15s - loss: 3.1135 - accuracy300: 0.4470 - val_loss: 3.1935 - val_accuracy300: 0.4124 - 15s/epoch - 25ms/step
Epoch 8/50
589/589 - 15s - loss: 3.1035 - accuracy300: 0.4507 - val_loss: 3.1944 - val_accuracy300: 0.4145 - 15s/epoch - 25ms/step
Epoch 9/50
589/589 - 15s - loss: 3.0934 - accuracy300: 0.4539 - val_loss: 3.1917 - val_accuracy300: 0.4172 - 15s/epoch - 25ms/step
Epoch 10/50
589/589 - 15s - loss: 3.0851 - accuracy300: 0.4575 - val_loss: 3.1905 - val_accuracy300: 0.4156 - 15s/epoch - 25ms/step
Epoch 11/50
589/589 - 15s - loss: 3.0767 - accuracy300: 0.4612 - val_loss: 3.1941 - val_accuracy300: 0.4179 - 15s/epoch - 25ms/step
Epoch 12/50
589/589 - 15s - loss: 3.0668 - accuracy300: 0.4648 - val_loss: 3.1910 - val_accuracy300: 0.4173 - 15s/epoch - 25ms/step
Epoch 13/50
589/589 - 15s - loss: 3.0590 - accuracy300: 0.4678 - val_loss: 3.2073 - val_accuracy300: 0.4111 - 15s/epoch - 25ms/step
Epoch 14/50
589/589 - 15s - loss: 3.0490 - accuracy300: 0.4715 - val_loss: 3.2002 - val_accuracy300: 0.4154 - 15s/epoch - 25ms/step
Epoch 15/50
589/589 - 15s - loss: 3.0365 - accuracy300: 0.4767 - val_loss: 3.2080 - val_accuracy300: 0.4157 - 15s/epoch - 25ms/step
Epoch 16/50
589/589 - 15s - loss: 3.0258 - accuracy300: 0.4806 - val_loss: 3.2084 - val_accuracy300: 0.4193 - 15s/epoch - 25ms/step
Epoch 17/50
589/589 - 15s - loss: 3.0119 - accuracy300: 0.4868 - val_loss: 3.2112 - val_accuracy300: 0.4173 - 15s/epoch - 25ms/step
Epoch 18/50
589/589 - 15s - loss: 2.9978 - accuracy300: 0.4934 - val_loss: 3.2153 - val_accuracy300: 0.4186 - 15s/epoch - 25ms/step
Epoch 19/50
589/589 - 15s - loss: 2.9837 - accuracy300: 0.4982 - val_loss: 3.2371 - val_accuracy300: 0.4164 - 15s/epoch - 26ms/step
Epoch 20/50
589/589 - 15s - loss: 2.9690 - accuracy300: 0.5017 - val_loss: 3.2649 - val_accuracy300: 0.4127 - 15s/epoch - 25ms/step
testing model: results/QRTEA/W5/deepOF_L2/h300
Evaluating performance on  test set...
2185/2185 - 18s - 18s/epoch - 8ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.055913
{'0': {'precision': 0.47349413457057765, 'recall': 0.41972997121908073, 'f1-score': 0.44499399017006036, 'support': 222717}, '1': {'precision': 0.26814757952310125, 'recall': 0.1441169644929218, 'f1-score': 0.18747484234536427, 'support': 116343}, '2': {'precision': 0.4368274718958442, 'recall': 0.5937921604789658, 'f1-score': 0.5033568547416656, 'support': 220141}, 'accuracy': 0.43091124658217705, 'macro avg': {'precision': 0.3928230619965077, 'recall': 0.38587969873032274, 'f1-score': 0.37860856241903007, 'support': 559201}, 'weighted avg': {'precision': 0.41633674386175024, 'recall': 0.43091124658217705, 'f1-score': 0.41439230876085176, 'support': 559201}}
[[ 93481  24092 105144]
 [ 36194  16767  63382]
 [ 67753  21670 130718]]
Evaluating performance on  train set...
589/589 - 6s - 6s/epoch - 9ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0421686
{'0': {'precision': 0.4679937462841037, 'recall': 0.43500419591870154, 'f1-score': 0.450896361514798, 'support': 48857}, '1': {'precision': 0.4351062448608647, 'recall': 0.20474076487598256, 'f1-score': 0.2784540179746029, 'support': 49106}, '2': {'precision': 0.41400754533284656, 'recall': 0.6451912682306977, 'f1-score': 0.5043700008154369, 'support': 52727}, 'accuracy': 0.4335125091246931, 'macro avg': {'precision': 0.43903584549260505, 'recall': 0.42831207634179397, 'f1-score': 0.41124012676827926, 'support': 150690}, 'weighted avg': {'precision': 0.4383865788380455, 'recall': 0.4335125091246931, 'f1-score': 0.4134124598459412, 'support': 150690}}
[[21253  6303 21301]
 [12202 10054 26850]
 [11958  6750 34019]]
Evaluating performance on  val set...
222/222 - 2s - 2s/epoch - 9ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.062385
{'0': {'precision': 0.44808533916849014, 'recall': 0.4064003969238402, 'f1-score': 0.4262260960062443, 'support': 20155}, '1': {'precision': 0.31420765027322406, 'recall': 0.17477203647416414, 'f1-score': 0.224609375, 'support': 15134}, '2': {'precision': 0.423906510851419, 'recall': 0.5944098506484385, 'f1-score': 0.4948839384903233, 'support': 21359}, 'accuracy': 0.41540742832933203, 'macro avg': {'precision': 0.3953998334310444, 'recall': 0.3918607613488143, 'f1-score': 0.3819064698321892, 'support': 56648}, 'weighted avg': {'precision': 0.4032021917005252, 'recall': 0.41540742832933203, 'f1-score': 0.39824974029922805, 'support': 56648}}
[[ 8191  2922  9042]
 [ 4277  2645  8212]
 [ 5812  2851 12696]]
training model: results/QRTEA/W5/deepOF_L2/h500
Epoch 1/50
589/589 - 17s - loss: 3.2995 - accuracy500: 0.3681 - val_loss: 3.2973 - val_accuracy500: 0.3790 - 17s/epoch - 30ms/step
Epoch 2/50
589/589 - 15s - loss: 3.2655 - accuracy500: 0.3876 - val_loss: 3.2916 - val_accuracy500: 0.3861 - 15s/epoch - 25ms/step
Epoch 3/50
589/589 - 15s - loss: 3.2492 - accuracy500: 0.3971 - val_loss: 3.2856 - val_accuracy500: 0.3859 - 15s/epoch - 25ms/step
Epoch 4/50
589/589 - 15s - loss: 3.2385 - accuracy500: 0.4025 - val_loss: 3.2863 - val_accuracy500: 0.3856 - 15s/epoch - 25ms/step
Epoch 5/50
589/589 - 15s - loss: 3.2314 - accuracy500: 0.4073 - val_loss: 3.2870 - val_accuracy500: 0.3853 - 15s/epoch - 25ms/step
Epoch 6/50
589/589 - 14s - loss: 3.2247 - accuracy500: 0.4098 - val_loss: 3.2905 - val_accuracy500: 0.3839 - 14s/epoch - 25ms/step
Epoch 7/50
589/589 - 14s - loss: 3.2188 - accuracy500: 0.4127 - val_loss: 3.2920 - val_accuracy500: 0.3856 - 14s/epoch - 25ms/step
Epoch 8/50
589/589 - 14s - loss: 3.2132 - accuracy500: 0.4170 - val_loss: 3.2921 - val_accuracy500: 0.3871 - 14s/epoch - 24ms/step
Epoch 9/50
589/589 - 15s - loss: 3.2082 - accuracy500: 0.4202 - val_loss: 3.2924 - val_accuracy500: 0.3856 - 15s/epoch - 25ms/step
Epoch 10/50
589/589 - 15s - loss: 3.2036 - accuracy500: 0.4212 - val_loss: 3.2941 - val_accuracy500: 0.3872 - 15s/epoch - 25ms/step
Epoch 11/50
589/589 - 15s - loss: 3.1990 - accuracy500: 0.4246 - val_loss: 3.2979 - val_accuracy500: 0.3853 - 15s/epoch - 25ms/step
Epoch 12/50
589/589 - 14s - loss: 3.1939 - accuracy500: 0.4272 - val_loss: 3.3002 - val_accuracy500: 0.3883 - 14s/epoch - 25ms/step
Epoch 13/50
589/589 - 14s - loss: 3.1884 - accuracy500: 0.4300 - val_loss: 3.3050 - val_accuracy500: 0.3847 - 14s/epoch - 24ms/step
testing model: results/QRTEA/W5/deepOF_L2/h500
Evaluating performance on  test set...
2185/2185 - 18s - 18s/epoch - 8ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1011412
{'0': {'precision': 0.43292500484010066, 'recall': 0.23030288844155236, 'f1-score': 0.30066250259745025, 'support': 213610}, '1': {'precision': 0.2796271974136189, 'recall': 0.24272476138971308, 'f1-score': 0.2598724619537577, 'support': 136834}, '2': {'precision': 0.3996070883225058, 'recall': 0.6255502809486628, 'f1-score': 0.48767990917714193, 'support': 208757}, 'accuracy': 0.38089345333788743, 'macro avg': {'precision': 0.3707197635254085, 'recall': 0.36619264359330944, 'f1-score': 0.34940495790945, 'support': 559201}, 'weighted avg': {'precision': 0.3829757013162179, 'recall': 0.38089345333788743, 'f1-score': 0.3604973890227565, 'support': 559201}}
[[ 49195  45113 119302]
 [ 26720  33213  76901]
 [ 37719  40450 130588]]
Evaluating performance on  train set...
589/589 - 5s - 5s/epoch - 9ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0829673
{'0': {'precision': 0.419708145735543, 'recall': 0.26812451552364247, 'f1-score': 0.32721343307733486, 'support': 49022}, '1': {'precision': 0.37376108502869065, 'recall': 0.1808734432850892, 'f1-score': 0.24377658066345337, 'support': 47536}, '2': {'precision': 0.3962685095829572, 'recall': 0.7054607256336363, 'f1-score': 0.507478355625544, 'support': 54132}, 'accuracy': 0.39770389541442697, 'macro avg': {'precision': 0.396579246782397, 'recall': 0.3848195614807893, 'f1-score': 0.35948945645544406, 'support': 150690}, 'weighted avg': {'precision': 0.3967937263183772, 'recall': 0.39770389541442697, 'f1-score': 0.3656489402180435, 'support': 150690}}
[[13144  7268 28610]
 [ 9367  8598 29571]
 [ 8806  7138 38188]]
Evaluating performance on  val set...
222/222 - 2s - 2s/epoch - 9ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0941566
{'0': {'precision': 0.42307355132813185, 'recall': 0.24097468417636192, 'f1-score': 0.307056053954317, 'support': 20027}, '1': {'precision': 0.328569916375569, 'recall': 0.1942306488955635, 'f1-score': 0.24414031775994965, 'support': 15981}, '2': {'precision': 0.3913225680281611, 'recall': 0.6786337209302326, 'f1-score': 0.49640287769784175, 'support': 20640}, 'accuracy': 0.38725109447818107, 'macro avg': {'precision': 0.3809886785772873, 'recall': 0.371279684667386, 'f1-score': 0.3491997498040362, 'support': 56648}, 'weighted avg': {'precision': 0.3848444366994017, 'recall': 0.38725109447818107, 'f1-score': 0.35829638127291896, 'support': 56648}}
[[ 4826  3280 11921]
 [ 3011  3104  9866]
 [ 3570  3063 14007]]
training model: results/QRTEA/W5/deepOF_L2/h1000
Epoch 1/50
589/589 - 17s - loss: 3.2848 - accuracy1000: 0.3876 - val_loss: 3.3979 - val_accuracy1000: 0.3916 - 17s/epoch - 29ms/step
Epoch 2/50
589/589 - 15s - loss: 3.2660 - accuracy1000: 0.3967 - val_loss: 3.3885 - val_accuracy1000: 0.3924 - 15s/epoch - 25ms/step
Epoch 3/50
589/589 - 14s - loss: 3.2566 - accuracy1000: 0.3978 - val_loss: 3.3531 - val_accuracy1000: 0.3919 - 14s/epoch - 24ms/step
Epoch 4/50
589/589 - 15s - loss: 3.2534 - accuracy1000: 0.3988 - val_loss: 3.3229 - val_accuracy1000: 0.3921 - 15s/epoch - 25ms/step
Epoch 5/50
589/589 - 15s - loss: 3.2485 - accuracy1000: 0.4013 - val_loss: 3.3153 - val_accuracy1000: 0.3921 - 15s/epoch - 25ms/step
Epoch 6/50
589/589 - 15s - loss: 3.2454 - accuracy1000: 0.4022 - val_loss: 3.3151 - val_accuracy1000: 0.3932 - 15s/epoch - 25ms/step
Epoch 7/50
589/589 - 15s - loss: 3.2420 - accuracy1000: 0.4045 - val_loss: 3.3174 - val_accuracy1000: 0.3931 - 15s/epoch - 25ms/step
Epoch 8/50
589/589 - 15s - loss: 3.2381 - accuracy1000: 0.4057 - val_loss: 3.3254 - val_accuracy1000: 0.3929 - 15s/epoch - 25ms/step
Epoch 9/50
589/589 - 15s - loss: 3.2345 - accuracy1000: 0.4089 - val_loss: 3.3379 - val_accuracy1000: 0.3926 - 15s/epoch - 25ms/step
Epoch 10/50
589/589 - 15s - loss: 3.2285 - accuracy1000: 0.4126 - val_loss: 3.3545 - val_accuracy1000: 0.3922 - 15s/epoch - 25ms/step
Epoch 11/50
589/589 - 15s - loss: 3.2223 - accuracy1000: 0.4175 - val_loss: 3.3786 - val_accuracy1000: 0.3925 - 15s/epoch - 26ms/step
Epoch 12/50
589/589 - 15s - loss: 3.2169 - accuracy1000: 0.4210 - val_loss: 3.3820 - val_accuracy1000: 0.3929 - 15s/epoch - 25ms/step
Epoch 13/50
589/589 - 15s - loss: 3.2100 - accuracy1000: 0.4242 - val_loss: 3.4030 - val_accuracy1000: 0.3935 - 15s/epoch - 25ms/step
Epoch 14/50
589/589 - 15s - loss: 3.2058 - accuracy1000: 0.4263 - val_loss: 3.4126 - val_accuracy1000: 0.3934 - 15s/epoch - 26ms/step
Epoch 15/50
589/589 - 15s - loss: 3.2006 - accuracy1000: 0.4297 - val_loss: 3.4152 - val_accuracy1000: 0.3924 - 15s/epoch - 25ms/step
Epoch 16/50
589/589 - 15s - loss: 3.1956 - accuracy1000: 0.4316 - val_loss: 3.4043 - val_accuracy1000: 0.3938 - 15s/epoch - 25ms/step
testing model: results/QRTEA/W5/deepOF_L2/h1000
Evaluating performance on  test set...
2185/2185 - 19s - 19s/epoch - 9ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1292546
{'0': {'precision': 0.4321246762525677, 'recall': 0.05192442868104332, 'f1-score': 0.0927088871963633, 'support': 186367}, '1': {'precision': 0.3368555782189675, 'recall': 0.9339725065492749, 'f1-score': 0.49513203635509784, 'support': 185135}, '2': {'precision': 0.35254064175674527, 'recall': 0.044134491925902644, 'f1-score': 0.07844808401634494, 'support': 187699}, 'accuracy': 0.34132986171340896, 'macro avg': {'precision': 0.3738402987427601, 'recall': 0.34334380905207357, 'f1-score': 0.22209633585593536, 'support': 559201}, 'weighted avg': {'precision': 0.37387104624246054, 'recall': 0.34132986171340896, 'f1-score': 0.22115263322581613, 'support': 559201}}
[[  9677 168591   8099]
 [  5109 172911   7115]
 [  7608 171807   8284]]
Evaluating performance on  train set...
589/589 - 5s - 5s/epoch - 9ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1325421
{'0': {'precision': 0.42980054751662106, 'recall': 0.022694889003613834, 'f1-score': 0.043113255658859984, 'support': 48425}, '1': {'precision': 0.32500173623168277, 'recall': 0.9588763216129825, 'f1-score': 0.485461165803915, 'support': 48804}, '2': {'precision': 0.4318126961139271, 'recall': 0.03346364639643853, 'f1-score': 0.06211374210124298, 'support': 53461}, 'accuracy': 0.3297166368040348, 'macro avg': {'precision': 0.3955383266207437, 'recall': 0.3383449523376783, 'f1-score': 0.19689605452133932, 'support': 150690}, 'weighted avg': {'precision': 0.39657319527168405, 'recall': 0.3297166368040348, 'f1-score': 0.19311745243645306, 'support': 150690}}
[[ 1099 46239  1087]
 [  740 46797  1267]
 [  718 50954  1789]]
Evaluating performance on  val set...
222/222 - 2s - 2s/epoch - 9ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1026865
{'0': {'precision': 0.339607201309329, 'recall': 0.024311657879320447, 'f1-score': 0.04537502733435382, 'support': 17070}, '1': {'precision': 0.39490670326816785, 'recall': 0.9560824464502223, 'f1-score': 0.5589435963403909, 'support': 22269}, '2': {'precision': 0.35978835978835977, 'recall': 0.031428736495464786, 'f1-score': 0.05780776791881409, 'support': 17309}, 'accuracy': 0.39277644400508405, 'macro avg': {'precision': 0.36476742145528557, 'recall': 0.33727428027500256, 'f1-score': 0.22070879719785297, 'support': 56648}, 'weighted avg': {'precision': 0.36751251625839915, 'recall': 0.39277644400508405, 'f1-score': 0.2510637854541791, 'support': 56648}}
[[  415 16242   413]
 [  423 21291   555]
 [  384 16381   544]]
training model: results/QRTEA/W5/deepVOL_L2/h10
Epoch 1/50
589/589 - 17s - loss: 2.6543 - accuracy10: 0.5738 - val_loss: 2.9311 - val_accuracy10: 0.6690 - 17s/epoch - 29ms/step
Epoch 2/50
589/589 - 14s - loss: 2.3423 - accuracy10: 0.6621 - val_loss: 2.9079 - val_accuracy10: 0.6816 - 14s/epoch - 24ms/step
Epoch 3/50
589/589 - 14s - loss: 2.2685 - accuracy10: 0.6799 - val_loss: 2.8433 - val_accuracy10: 0.6993 - 14s/epoch - 23ms/step
Epoch 4/50
589/589 - 15s - loss: 2.2338 - accuracy10: 0.6912 - val_loss: 2.8292 - val_accuracy10: 0.7121 - 15s/epoch - 25ms/step
Epoch 5/50
589/589 - 13s - loss: 2.2016 - accuracy10: 0.6992 - val_loss: 2.7761 - val_accuracy10: 0.6938 - 13s/epoch - 23ms/step
Epoch 6/50
589/589 - 14s - loss: 2.1734 - accuracy10: 0.7025 - val_loss: 2.7913 - val_accuracy10: 0.7016 - 14s/epoch - 24ms/step
Epoch 7/50
589/589 - 14s - loss: 2.1539 - accuracy10: 0.7052 - val_loss: 2.7684 - val_accuracy10: 0.6843 - 14s/epoch - 24ms/step
Epoch 8/50
589/589 - 14s - loss: 2.1410 - accuracy10: 0.7079 - val_loss: 2.7564 - val_accuracy10: 0.6945 - 14s/epoch - 23ms/step
Epoch 9/50
589/589 - 14s - loss: 2.1249 - accuracy10: 0.7095 - val_loss: 2.7584 - val_accuracy10: 0.6940 - 14s/epoch - 23ms/step
Epoch 10/50
589/589 - 14s - loss: 2.1075 - accuracy10: 0.7110 - val_loss: 2.7483 - val_accuracy10: 0.6812 - 14s/epoch - 23ms/step
Epoch 11/50
589/589 - 14s - loss: 2.0990 - accuracy10: 0.7103 - val_loss: 2.7406 - val_accuracy10: 0.6706 - 14s/epoch - 24ms/step
Epoch 12/50
589/589 - 14s - loss: 2.0876 - accuracy10: 0.7114 - val_loss: 2.7676 - val_accuracy10: 0.6810 - 14s/epoch - 23ms/step
Epoch 13/50
589/589 - 15s - loss: 2.0799 - accuracy10: 0.7088 - val_loss: 2.7672 - val_accuracy10: 0.6904 - 15s/epoch - 25ms/step
Epoch 14/50
589/589 - 14s - loss: 2.0672 - accuracy10: 0.7091 - val_loss: 2.7463 - val_accuracy10: 0.6787 - 14s/epoch - 23ms/step
Epoch 15/50
589/589 - 14s - loss: 2.0556 - accuracy10: 0.7101 - val_loss: 2.7694 - val_accuracy10: 0.6972 - 14s/epoch - 23ms/step
Epoch 16/50
589/589 - 14s - loss: 2.0488 - accuracy10: 0.7099 - val_loss: 2.7494 - val_accuracy10: 0.6857 - 14s/epoch - 24ms/step
Epoch 17/50
589/589 - 14s - loss: 2.0403 - accuracy10: 0.7104 - val_loss: 2.7315 - val_accuracy10: 0.6894 - 14s/epoch - 23ms/step
Epoch 18/50
589/589 - 14s - loss: 2.0264 - accuracy10: 0.7125 - val_loss: 2.7510 - val_accuracy10: 0.6763 - 14s/epoch - 24ms/step
Epoch 19/50
589/589 - 14s - loss: 2.0185 - accuracy10: 0.7115 - val_loss: 2.7833 - val_accuracy10: 0.6707 - 14s/epoch - 23ms/step
Epoch 20/50
589/589 - 14s - loss: 2.0140 - accuracy10: 0.7122 - val_loss: 2.7552 - val_accuracy10: 0.6797 - 14s/epoch - 24ms/step
Epoch 21/50
589/589 - 14s - loss: 1.9976 - accuracy10: 0.7143 - val_loss: 2.7785 - val_accuracy10: 0.6717 - 14s/epoch - 24ms/step
Epoch 22/50
589/589 - 14s - loss: 1.9968 - accuracy10: 0.7147 - val_loss: 2.7975 - val_accuracy10: 0.6775 - 14s/epoch - 24ms/step
Epoch 23/50
589/589 - 14s - loss: 1.9922 - accuracy10: 0.7142 - val_loss: 2.7671 - val_accuracy10: 0.6898 - 14s/epoch - 23ms/step
Epoch 24/50
589/589 - 14s - loss: 1.9733 - accuracy10: 0.7166 - val_loss: 2.7937 - val_accuracy10: 0.6818 - 14s/epoch - 23ms/step
Epoch 25/50
589/589 - 14s - loss: 1.9642 - accuracy10: 0.7167 - val_loss: 2.8064 - val_accuracy10: 0.6827 - 14s/epoch - 24ms/step
Epoch 26/50
589/589 - 14s - loss: 1.9542 - accuracy10: 0.7166 - val_loss: 2.8187 - val_accuracy10: 0.6962 - 14s/epoch - 23ms/step
Epoch 27/50
589/589 - 14s - loss: 1.9410 - accuracy10: 0.7169 - val_loss: 2.8260 - val_accuracy10: 0.6859 - 14s/epoch - 24ms/step
testing model: results/QRTEA/W5/deepVOL_L2/h10
Evaluating performance on  test set...
2185/2185 - 24s - 24s/epoch - 11ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.93505436
{'0': {'precision': 0.3346206084011062, 'recall': 0.5062072209226047, 'f1-score': 0.40290618919784255, 'support': 80793}, '1': {'precision': 0.8954397468818782, 'recall': 0.5901212058636138, 'f1-score': 0.7114053209753047, 'support': 397093}, '2': {'precision': 0.3086805714024919, 'recall': 0.665371372356124, 'f1-score': 0.4217171717171717, 'support': 81320}, 'accuracy': 0.5889403904822195, 'macro avg': {'precision': 0.512913642228492, 'recall': 0.5872332663807809, 'f1-score': 0.5120095606301064, 'support': 559206}, 'weighted avg': {'precision': 0.729086887997566, 'recall': 0.5889403904822195, 'f1-score': 0.6247073766553799, 'support': 559206}}
[[ 40898  15554  24341]
 [ 65921 234333  96839]
 [ 15403  11809  54108]]
Evaluating performance on  train set...
589/589 - 5s - 5s/epoch - 8ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.66810155
{'0': {'precision': 0.32615697575860314, 'recall': 0.6285527605357726, 'f1-score': 0.4294642857142857, 'support': 12244}, '1': {'precision': 0.9505855180517849, 'recall': 0.7445923856981893, 'f1-score': 0.8350731060504935, 'support': 126026}, '2': {'precision': 0.2975439585609077, 'recall': 0.679816439900169, 'f1-score': 0.41392156862745094, 'support': 12421}, 'accuracy': 0.7298246079726062, 'macro avg': {'precision': 0.524762150790432, 'recall': 0.6843205287113769, 'f1-score': 0.5594863201307433, 'support': 150691}, 'weighted avg': {'precision': 0.8460209967315078, 'recall': 0.7298246079726062, 'f1-score': 0.7674021924423274, 'support': 150691}}
[[ 7696  2438  2110]
 [14363 93838 17825]
 [ 1537  2440  8444]]
Evaluating performance on  val set...
222/222 - 2s - 2s/epoch - 9ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.74679774
{'0': {'precision': 0.3010293091416609, 'recall': 0.6242764109985528, 'f1-score': 0.4061911487758945, 'support': 5528}, '1': {'precision': 0.9309052888385466, 'recall': 0.7060067402365691, 'f1-score': 0.8030063885757233, 'support': 45399}, '2': {'precision': 0.3372082209615921, 'recall': 0.633805278797413, 'f1-score': 0.44020881388855165, 'support': 5721}, 'accuracy': 0.690739302358424, 'macro avg': {'precision': 0.5230476063139332, 'recall': 0.6546961433441782, 'f1-score': 0.5498021170800564, 'support': 56648}, 'weighted avg': {'precision': 0.8094800780440182, 'recall': 0.690739302358424, 'f1-score': 0.7276434530722852, 'support': 56648}}
[[ 3451  1163   914]
 [ 7134 32052  6213]
 [  879  1216  3626]]
training model: results/QRTEA/W5/deepVOL_L2/h20
Epoch 1/50
589/589 - 17s - loss: 2.7132 - accuracy20: 0.5483 - val_loss: 3.0623 - val_accuracy20: 0.6524 - 17s/epoch - 29ms/step
Epoch 2/50
589/589 - 14s - loss: 2.4430 - accuracy20: 0.6315 - val_loss: 2.9607 - val_accuracy20: 0.6084 - 14s/epoch - 24ms/step
Epoch 3/50
589/589 - 14s - loss: 2.3680 - accuracy20: 0.6575 - val_loss: 2.9803 - val_accuracy20: 0.6639 - 14s/epoch - 24ms/step
Epoch 4/50
589/589 - 14s - loss: 2.3224 - accuracy20: 0.6661 - val_loss: 2.9472 - val_accuracy20: 0.6696 - 14s/epoch - 23ms/step
Epoch 5/50
589/589 - 14s - loss: 2.2950 - accuracy20: 0.6799 - val_loss: 2.8877 - val_accuracy20: 0.6687 - 14s/epoch - 24ms/step
Epoch 6/50
589/589 - 13s - loss: 2.2753 - accuracy20: 0.6769 - val_loss: 2.9215 - val_accuracy20: 0.6813 - 13s/epoch - 23ms/step
Epoch 7/50
589/589 - 14s - loss: 2.2565 - accuracy20: 0.6824 - val_loss: 2.9137 - val_accuracy20: 0.6797 - 14s/epoch - 24ms/step
Epoch 8/50
589/589 - 14s - loss: 2.2429 - accuracy20: 0.6832 - val_loss: 2.9163 - val_accuracy20: 0.6489 - 14s/epoch - 23ms/step
Epoch 9/50
589/589 - 14s - loss: 2.2307 - accuracy20: 0.6815 - val_loss: 2.9521 - val_accuracy20: 0.6674 - 14s/epoch - 23ms/step
Epoch 10/50
589/589 - 14s - loss: 2.2151 - accuracy20: 0.6846 - val_loss: 2.9167 - val_accuracy20: 0.6494 - 14s/epoch - 24ms/step
Epoch 11/50
589/589 - 14s - loss: 2.2068 - accuracy20: 0.6851 - val_loss: 2.9024 - val_accuracy20: 0.6374 - 14s/epoch - 24ms/step
Epoch 12/50
589/589 - 14s - loss: 2.1891 - accuracy20: 0.6855 - val_loss: 2.9364 - val_accuracy20: 0.6484 - 14s/epoch - 23ms/step
Epoch 13/50
589/589 - 14s - loss: 2.1781 - accuracy20: 0.6874 - val_loss: 2.9203 - val_accuracy20: 0.6279 - 14s/epoch - 23ms/step
Epoch 14/50
589/589 - 13s - loss: 2.1654 - accuracy20: 0.6873 - val_loss: 2.9107 - val_accuracy20: 0.6351 - 13s/epoch - 23ms/step
Epoch 15/50
589/589 - 14s - loss: 2.1519 - accuracy20: 0.6871 - val_loss: 2.8773 - val_accuracy20: 0.6331 - 14s/epoch - 23ms/step
Epoch 16/50
589/589 - 14s - loss: 2.1488 - accuracy20: 0.6872 - val_loss: 2.8604 - val_accuracy20: 0.6132 - 14s/epoch - 24ms/step
Epoch 17/50
589/589 - 13s - loss: 2.1352 - accuracy20: 0.6875 - val_loss: 2.8866 - val_accuracy20: 0.6605 - 13s/epoch - 22ms/step
Epoch 18/50
589/589 - 14s - loss: 2.1290 - accuracy20: 0.6897 - val_loss: 2.9198 - val_accuracy20: 0.6512 - 14s/epoch - 23ms/step
Epoch 19/50
589/589 - 14s - loss: 2.1208 - accuracy20: 0.6890 - val_loss: 2.9067 - val_accuracy20: 0.6468 - 14s/epoch - 23ms/step
Epoch 20/50
589/589 - 14s - loss: 2.1055 - accuracy20: 0.6911 - val_loss: 2.8735 - val_accuracy20: 0.6592 - 14s/epoch - 24ms/step
Epoch 21/50
589/589 - 14s - loss: 2.1018 - accuracy20: 0.6888 - val_loss: 2.8463 - val_accuracy20: 0.6133 - 14s/epoch - 24ms/step
Epoch 22/50
589/589 - 14s - loss: 2.0850 - accuracy20: 0.6923 - val_loss: 2.8924 - val_accuracy20: 0.6419 - 14s/epoch - 24ms/step
Epoch 23/50
589/589 - 14s - loss: 2.0752 - accuracy20: 0.6933 - val_loss: 2.8734 - val_accuracy20: 0.6416 - 14s/epoch - 23ms/step
Epoch 24/50
589/589 - 14s - loss: 2.0646 - accuracy20: 0.6925 - val_loss: 2.8849 - val_accuracy20: 0.6339 - 14s/epoch - 24ms/step
Epoch 25/50
589/589 - 15s - loss: 2.0571 - accuracy20: 0.6926 - val_loss: 2.9458 - val_accuracy20: 0.6702 - 15s/epoch - 25ms/step
Epoch 26/50
589/589 - 15s - loss: 2.0414 - accuracy20: 0.6946 - val_loss: 2.9211 - val_accuracy20: 0.6564 - 15s/epoch - 25ms/step
Epoch 27/50
589/589 - 14s - loss: 2.0276 - accuracy20: 0.6960 - val_loss: 2.9307 - val_accuracy20: 0.6511 - 14s/epoch - 23ms/step
Epoch 28/50
589/589 - 14s - loss: 2.0178 - accuracy20: 0.6945 - val_loss: 2.9383 - val_accuracy20: 0.6565 - 14s/epoch - 24ms/step
Epoch 29/50
589/589 - 14s - loss: 2.0106 - accuracy20: 0.6967 - val_loss: 2.9225 - val_accuracy20: 0.6476 - 14s/epoch - 23ms/step
Epoch 30/50
589/589 - 14s - loss: 1.9989 - accuracy20: 0.6964 - val_loss: 2.9474 - val_accuracy20: 0.6537 - 14s/epoch - 24ms/step
Epoch 31/50
589/589 - 14s - loss: 1.9907 - accuracy20: 0.6977 - val_loss: 2.9609 - val_accuracy20: 0.6432 - 14s/epoch - 25ms/step
testing model: results/QRTEA/W5/deepVOL_L2/h20
Evaluating performance on  test set...
2185/2185 - 20s - 20s/epoch - 9ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.9753221
{'0': {'precision': 0.3748074348157853, 'recall': 0.5083676697455526, 'f1-score': 0.43148857176006505, 'support': 102418}, '1': {'precision': 0.8239375191093685, 'recall': 0.5178341321155672, 'f1-score': 0.6359695701365318, 'support': 353872}, '2': {'precision': 0.32417832309184996, 'recall': 0.6233335924443235, 'f1-score': 0.42653023231074055, 'support': 102916}, 'accuracy': 0.5355164286506225, 'macro avg': {'precision': 0.5076410923390012, 'recall': 0.5498451314351477, 'f1-score': 0.49799612473577914, 'support': 559206}, 'weighted avg': {'precision': 0.6497043699827155, 'recall': 0.5355164286506225, 'f1-score': 0.5599739731947964, 'support': 559206}}
[[ 52066  23107  27245]
 [ 64133 183247 106492]
 [ 22715  16050  64151]]
Evaluating performance on  train set...
589/589 - 5s - 5s/epoch - 8ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.747189
{'0': {'precision': 0.37067245423040573, 'recall': 0.6324434091859285, 'f1-score': 0.4674023394394174, 'support': 16743}, '1': {'precision': 0.9127188222526306, 'recall': 0.6624514118392438, 'f1-score': 0.7677035273106116, 'support': 116798}, '2': {'precision': 0.3003319768687085, 'recall': 0.6541107871720117, 'f1-score': 0.4116546181791494, 'support': 17150}, 'accuracy': 0.6581680392326018, 'macro avg': {'precision': 0.5279077511172483, 'recall': 0.6496685360657279, 'f1-score': 0.5489201616430595, 'support': 150691}, 'weighted avg': {'precision': 0.7827978798066294, 'recall': 0.6581680392326018, 'f1-score': 0.6938160252027752, 'support': 150691}}
[[10589  3851  2303]
 [15594 77373 23831]
 [ 2384  3548 11218]]
Evaluating performance on  val set...
222/222 - 2s - 2s/epoch - 8ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.8197265
{'0': {'precision': 0.34792491567678546, 'recall': 0.6332577071933805, 'f1-score': 0.4491032132885335, 'support': 7493}, '1': {'precision': 0.8783244911404695, 'recall': 0.6133914517496065, 'f1-score': 0.7223315367724642, 'support': 41295}, '2': {'precision': 0.33342742220026816, 'recall': 0.601145038167939, 'f1-score': 0.4289410376287958, 'support': 7860}, 'accuracy': 0.6143200112978393, 'macro avg': {'precision': 0.5198922763391743, 'recall': 0.6159313990369752, 'f1-score': 0.5334585958965978, 'support': 56648}, 'weighted avg': {'precision': 0.7325616225339985, 'recall': 0.6143200112978393, 'f1-score': 0.6454824132176286, 'support': 56648}}
[[ 4745  1735  1013]
 [ 7532 25330  8433]
 [ 1361  1774  4725]]
training model: results/QRTEA/W5/deepVOL_L2/h30
Epoch 1/50
589/589 - 16s - loss: 2.7975 - accuracy30: 0.5223 - val_loss: 3.2074 - val_accuracy30: 0.5879 - 16s/epoch - 28ms/step
Epoch 2/50
589/589 - 13s - loss: 2.5429 - accuracy30: 0.6132 - val_loss: 3.0575 - val_accuracy30: 0.6173 - 13s/epoch - 23ms/step
Epoch 3/50
589/589 - 14s - loss: 2.4770 - accuracy30: 0.6319 - val_loss: 2.9992 - val_accuracy30: 0.6336 - 14s/epoch - 23ms/step
Epoch 4/50
589/589 - 14s - loss: 2.4299 - accuracy30: 0.6423 - val_loss: 3.0126 - val_accuracy30: 0.6494 - 14s/epoch - 24ms/step
Epoch 5/50
589/589 - 14s - loss: 2.3998 - accuracy30: 0.6457 - val_loss: 2.9878 - val_accuracy30: 0.6339 - 14s/epoch - 24ms/step
Epoch 6/50
589/589 - 14s - loss: 2.3731 - accuracy30: 0.6507 - val_loss: 2.9568 - val_accuracy30: 0.6098 - 14s/epoch - 24ms/step
Epoch 7/50
589/589 - 15s - loss: 2.3507 - accuracy30: 0.6524 - val_loss: 2.9669 - val_accuracy30: 0.6370 - 15s/epoch - 26ms/step
Epoch 8/50
589/589 - 14s - loss: 2.3348 - accuracy30: 0.6530 - val_loss: 2.9659 - val_accuracy30: 0.6051 - 14s/epoch - 23ms/step
Epoch 9/50
589/589 - 14s - loss: 2.3217 - accuracy30: 0.6537 - val_loss: 2.9839 - val_accuracy30: 0.6080 - 14s/epoch - 24ms/step
Epoch 10/50
589/589 - 13s - loss: 2.3140 - accuracy30: 0.6540 - val_loss: 2.9690 - val_accuracy30: 0.6134 - 13s/epoch - 23ms/step
Epoch 11/50
589/589 - 14s - loss: 2.2975 - accuracy30: 0.6577 - val_loss: 2.9793 - val_accuracy30: 0.6131 - 14s/epoch - 24ms/step
Epoch 12/50
589/589 - 14s - loss: 2.2874 - accuracy30: 0.6568 - val_loss: 2.9623 - val_accuracy30: 0.6255 - 14s/epoch - 23ms/step
Epoch 13/50
589/589 - 14s - loss: 2.2794 - accuracy30: 0.6587 - val_loss: 2.9628 - val_accuracy30: 0.6207 - 14s/epoch - 24ms/step
Epoch 14/50
589/589 - 14s - loss: 2.2670 - accuracy30: 0.6603 - val_loss: 2.9754 - val_accuracy30: 0.6242 - 14s/epoch - 24ms/step
Epoch 15/50
589/589 - 15s - loss: 2.2615 - accuracy30: 0.6604 - val_loss: 2.9755 - val_accuracy30: 0.6245 - 15s/epoch - 26ms/step
Epoch 16/50
589/589 - 14s - loss: 2.2492 - accuracy30: 0.6612 - val_loss: 2.9723 - val_accuracy30: 0.6224 - 14s/epoch - 24ms/step
testing model: results/QRTEA/W5/deepVOL_L2/h30
Evaluating performance on  test set...
2185/2185 - 21s - 21s/epoch - 10ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.97182447
{'0': {'precision': 0.417398801464472, 'recall': 0.5827018596687518, 'f1-score': 0.4863891551901627, 'support': 117978}, '1': {'precision': 0.761960534577891, 'recall': 0.5302304393097977, 'f1-score': 0.6253172745363543, 'support': 322688}, '2': {'precision': 0.34632312272732624, 'recall': 0.49653281592711324, 'f1-score': 0.4080431482110547, 'support': 118540}, 'accuracy': 0.5341573588266221, 'macro avg': {'precision': 0.5085608195898964, 'recall': 0.5364883716352209, 'f1-score': 0.5065831926458572, 'support': 559206}, 'weighted avg': {'precision': 0.601160466356125, 'recall': 0.5341573588266221, 'f1-score': 0.5499494555236363, 'support': 559206}}
[[ 68746  29607  19625]
 [ 60119 171099  91470]
 [ 35836  23845  58859]]
Evaluating performance on  train set...
589/589 - 5s - 5s/epoch - 8ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.794991
{'0': {'precision': 0.4171059745877264, 'recall': 0.6099827032369657, 'f1-score': 0.4954342023400967, 'support': 20235}, '1': {'precision': 0.8670499250655677, 'recall': 0.6751362981602027, 'f1-score': 0.7591519985237886, 'support': 109686}, '2': {'precision': 0.3307276344176403, 'recall': 0.5683196918632644, 'f1-score': 0.4181293282088521, 'support': 20770}, 'accuracy': 0.6516646647775912, 'macro avg': {'precision': 0.5382945113569781, 'recall': 0.6178128977534776, 'f1-score': 0.5575718430242458, 'support': 150691}, 'weighted avg': {'precision': 0.7327085920418531, 'recall': 0.6516646647775912, 'f1-score': 0.6767358590846831, 'support': 150691}}
[[12343  5686  2206]
 [13952 74053 21681]
 [ 3297  5669 11804]]
Evaluating performance on  val set...
222/222 - 2s - 2s/epoch - 8ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.8570396
{'0': {'precision': 0.3846046381670858, 'recall': 0.6095427875567364, 'f1-score': 0.471626193841278, 'support': 9033}, '1': {'precision': 0.8226512401180742, 'recall': 0.6358439106262457, 'f1-score': 0.7172842245396052, 'support': 38132}, '2': {'precision': 0.3729683490162532, 'recall': 0.5057471264367817, 'f1-score': 0.42932593321994456, 'support': 9483}, 'accuracy': 0.6098714870780964, 'macro avg': {'precision': 0.5267414091004711, 'recall': 0.5837112748732546, 'f1-score': 0.5394121172002759, 'support': 56648}, 'weighted avg': {'precision': 0.6775231188826935, 'recall': 0.6098714870780964, 'f1-score': 0.6299071332410187, 'support': 56648}}
[[ 5506  2538   989]
 [ 6812 24246  7074]
 [ 1998  2689  4796]]
training model: results/QRTEA/W5/deepVOL_L2/h50
Epoch 1/50
589/589 - 16s - loss: 2.9125 - accuracy50: 0.5003 - val_loss: 3.2571 - val_accuracy50: 0.5203 - 16s/epoch - 28ms/step
Epoch 2/50
589/589 - 14s - loss: 2.7173 - accuracy50: 0.5722 - val_loss: 3.2095 - val_accuracy50: 0.5585 - 14s/epoch - 24ms/step
Epoch 3/50
589/589 - 14s - loss: 2.6394 - accuracy50: 0.5973 - val_loss: 3.2007 - val_accuracy50: 0.6028 - 14s/epoch - 24ms/step
Epoch 4/50
589/589 - 14s - loss: 2.5960 - accuracy50: 0.6069 - val_loss: 3.1657 - val_accuracy50: 0.5978 - 14s/epoch - 24ms/step
Epoch 5/50
589/589 - 15s - loss: 2.5604 - accuracy50: 0.6117 - val_loss: 3.1210 - val_accuracy50: 0.5855 - 15s/epoch - 25ms/step
Epoch 6/50
589/589 - 14s - loss: 2.5393 - accuracy50: 0.6146 - val_loss: 3.1096 - val_accuracy50: 0.5785 - 14s/epoch - 24ms/step
Epoch 7/50
589/589 - 14s - loss: 2.5230 - accuracy50: 0.6172 - val_loss: 3.1648 - val_accuracy50: 0.6016 - 14s/epoch - 24ms/step
Epoch 8/50
589/589 - 15s - loss: 2.5091 - accuracy50: 0.6195 - val_loss: 3.1645 - val_accuracy50: 0.5960 - 15s/epoch - 25ms/step
Epoch 9/50
589/589 - 14s - loss: 2.5006 - accuracy50: 0.6176 - val_loss: 3.1883 - val_accuracy50: 0.5978 - 14s/epoch - 24ms/step
Epoch 10/50
589/589 - 13s - loss: 2.4878 - accuracy50: 0.6211 - val_loss: 3.2344 - val_accuracy50: 0.6008 - 13s/epoch - 23ms/step
Epoch 11/50
589/589 - 14s - loss: 2.4798 - accuracy50: 0.6236 - val_loss: 3.2258 - val_accuracy50: 0.5896 - 14s/epoch - 23ms/step
Epoch 12/50
589/589 - 14s - loss: 2.4687 - accuracy50: 0.6238 - val_loss: 3.2621 - val_accuracy50: 0.6121 - 14s/epoch - 24ms/step
Epoch 13/50
589/589 - 14s - loss: 2.4631 - accuracy50: 0.6224 - val_loss: 3.2224 - val_accuracy50: 0.6072 - 14s/epoch - 23ms/step
Epoch 14/50
589/589 - 14s - loss: 2.4531 - accuracy50: 0.6240 - val_loss: 3.2571 - val_accuracy50: 0.6126 - 14s/epoch - 24ms/step
Epoch 15/50
589/589 - 14s - loss: 2.4411 - accuracy50: 0.6254 - val_loss: 3.3256 - val_accuracy50: 0.5930 - 14s/epoch - 23ms/step
Epoch 16/50
589/589 - 14s - loss: 2.4298 - accuracy50: 0.6281 - val_loss: 3.3204 - val_accuracy50: 0.6051 - 14s/epoch - 23ms/step
testing model: results/QRTEA/W5/deepVOL_L2/h50
Evaluating performance on  test set...
2185/2185 - 19s - 19s/epoch - 9ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0094067
{'0': {'precision': 0.4408428741677092, 'recall': 0.5201911371682035, 'f1-score': 0.47724129077809335, 'support': 142934}, '1': {'precision': 0.6557394440908126, 'recall': 0.5211330078153639, 'f1-score': 0.5807383260415774, 'support': 272796}, '2': {'precision': 0.4007493654566698, 'recall': 0.48530067746522065, 'f1-score': 0.43899086762309164, 'support': 143476}, 'accuracy': 0.5116987299850144, 'macro avg': {'precision': 0.49911056123839725, 'recall': 0.5088749408162626, 'f1-score': 0.49899016148092074, 'support': 559206}, 'weighted avg': {'precision': 0.535388477099219, 'recall': 0.5116987299850144, 'f1-score': 0.5179160323208349, 'support': 559206}}
[[ 74353  39204  29377]
 [ 55892 142163  74741]
 [ 38416  35431  69629]]
Evaluating performance on  train set...
589/589 - 5s - 5s/epoch - 8ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.86937606
{'0': {'precision': 0.4363315485627113, 'recall': 0.5536703863964169, 'f1-score': 0.4880472422503639, 'support': 26346}, '1': {'precision': 0.7876122256370545, 'recall': 0.6678465531923625, 'f1-score': 0.7228017966498809, 'support': 97467}, '2': {'precision': 0.39810481308141216, 'recall': 0.512686955874693, 'f1-score': 0.44818838222858265, 'support': 26878}, 'accuracy': 0.6202095679237645, 'macro avg': {'precision': 0.5406828624270593, 'recall': 0.5780679651544909, 'f1-score': 0.5530124737096092, 'support': 150691}, 'weighted avg': {'precision': 0.6567217215401197, 'recall': 0.6202095679237645, 'f1-score': 0.6327771578657111, 'support': 150691}}
[[14587  8390  3369]
 [14909 65093 17465]
 [ 3935  9163 13780]]
Evaluating performance on  val set...
222/222 - 2s - 2s/epoch - 8ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.92837346
{'0': {'precision': 0.4115077857956703, 'recall': 0.5594182944669134, 'f1-score': 0.47419672489879283, 'support': 11621}, '1': {'precision': 0.7254778847495466, 'recall': 0.6339114267426621, 'f1-score': 0.6766107650015454, 'support': 32809}, '2': {'precision': 0.45903792480709243, 'recall': 0.45768538222294974, 'f1-score': 0.4583606557377049, 'support': 12218}, 'accuracy': 0.5806206750458974, 'macro avg': {'precision': 0.5320078651174364, 'recall': 0.5503383678108418, 'f1-score': 0.5363893818793477, 'support': 56648}, 'weighted avg': {'precision': 0.6036022677724264, 'recall': 0.5806206750458974, 'f1-score': 0.5880139320150376, 'support': 56648}}
[[ 6501  3719  1401]
 [ 6822 20798  5189]
 [ 2475  4151  5592]]
training model: results/QRTEA/W5/deepVOL_L2/h100
Epoch 1/50
589/589 - 17s - loss: 3.1130 - accuracy100: 0.4529 - val_loss: 3.3336 - val_accuracy100: 0.4567 - 17s/epoch - 28ms/step
Epoch 2/50
589/589 - 14s - loss: 2.9633 - accuracy100: 0.5110 - val_loss: 3.2969 - val_accuracy100: 0.4821 - 14s/epoch - 24ms/step
Epoch 3/50
589/589 - 14s - loss: 2.9095 - accuracy100: 0.5251 - val_loss: 3.2664 - val_accuracy100: 0.4716 - 14s/epoch - 24ms/step
Epoch 4/50
589/589 - 14s - loss: 2.8674 - accuracy100: 0.5374 - val_loss: 3.2722 - val_accuracy100: 0.4794 - 14s/epoch - 23ms/step
Epoch 5/50
589/589 - 14s - loss: 2.8336 - accuracy100: 0.5438 - val_loss: 3.2901 - val_accuracy100: 0.4904 - 14s/epoch - 24ms/step
Epoch 6/50
589/589 - 15s - loss: 2.8118 - accuracy100: 0.5465 - val_loss: 3.3038 - val_accuracy100: 0.4884 - 15s/epoch - 25ms/step
Epoch 7/50
589/589 - 14s - loss: 2.7910 - accuracy100: 0.5498 - val_loss: 3.3411 - val_accuracy100: 0.4913 - 14s/epoch - 24ms/step
Epoch 8/50
589/589 - 14s - loss: 2.7760 - accuracy100: 0.5501 - val_loss: 3.3807 - val_accuracy100: 0.4935 - 14s/epoch - 23ms/step
Epoch 9/50
589/589 - 14s - loss: 2.7583 - accuracy100: 0.5559 - val_loss: 3.3487 - val_accuracy100: 0.4962 - 14s/epoch - 24ms/step
Epoch 10/50
589/589 - 14s - loss: 2.7402 - accuracy100: 0.5594 - val_loss: 3.3710 - val_accuracy100: 0.4951 - 14s/epoch - 24ms/step
Epoch 11/50
589/589 - 14s - loss: 2.7264 - accuracy100: 0.5646 - val_loss: 3.3784 - val_accuracy100: 0.4948 - 14s/epoch - 23ms/step
Epoch 12/50
589/589 - 14s - loss: 2.7165 - accuracy100: 0.5654 - val_loss: 3.3674 - val_accuracy100: 0.4943 - 14s/epoch - 24ms/step
Epoch 13/50
589/589 - 14s - loss: 2.7070 - accuracy100: 0.5648 - val_loss: 3.3995 - val_accuracy100: 0.4964 - 14s/epoch - 23ms/step
testing model: results/QRTEA/W5/deepVOL_L2/h100
Evaluating performance on  test set...
2185/2185 - 23s - 23s/epoch - 11ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0540243
{'0': {'precision': 0.46521635068314565, 'recall': 0.49357069533740344, 'f1-score': 0.478974259491796, 'support': 185090}, '1': {'precision': 0.46015650901084054, 'recall': 0.38154960113694125, 'f1-score': 0.4171825067132458, 'support': 192798}, '2': {'precision': 0.39931616183512997, 'recall': 0.44700470995709196, 'f1-score': 0.4218168570610737, 'support': 181318}, 'accuracy': 0.4398504307893692, 'macro avg': {'precision': 0.44156300717637204, 'recall': 0.44070833547714555, 'f1-score': 0.43932454108870517, 'support': 559206}, 'weighted avg': {'precision': 0.4421042635519604, 'recall': 0.4398504307893692, 'f1-score': 0.43913743326651833, 'support': 559206}}
[[91355 45028 48707]
 [46021 73562 73215]
 [58995 41273 81050]]
Evaluating performance on  train set...
589/589 - 5s - 5s/epoch - 8ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 0.97371113
{'0': {'precision': 0.4508237525186678, 'recall': 0.5141389564747229, 'f1-score': 0.48040416798231766, 'support': 36990}, '1': {'precision': 0.6432021453276653, 'recall': 0.5559814031899061, 'f1-score': 0.5964198420435439, 'support': 75927}, '2': {'precision': 0.4067871720116618, 'recall': 0.4617197013819029, 'f1-score': 0.43251621222829795, 'support': 37774}, 'accuracy': 0.522081610713314, 'macro avg': {'precision': 0.5002710232859983, 'recall': 0.5106133536821772, 'f1-score': 0.5031134074180532, 'support': 150691}, 'weighted avg': {'precision': 0.5367165824735894, 'recall': 0.522081610713314, 'f1-score': 0.5268555316589432, 'support': 150691}}
[[19018 11207  6765]
 [15044 42214 18669]
 [ 8123 12210 17441]]
Evaluating performance on  val set...
222/222 - 2s - 2s/epoch - 8ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0228574
{'0': {'precision': 0.4313317320523085, 'recall': 0.4985809476801579, 'f1-score': 0.46252468305526145, 'support': 16208}, '1': {'precision': 0.5400172312157077, 'recall': 0.5034240784578965, 'f1-score': 0.5210789997593471, 'support': 23656}, '2': {'precision': 0.42818411097099623, 'recall': 0.4046115347950429, 'f1-score': 0.4160642078176694, 'support': 16784}, 'accuracy': 0.4727616155910182, 'macro avg': {'precision': 0.4665110247463375, 'recall': 0.4688721869776991, 'f1-score': 0.46655596354409273, 'support': 56648}, 'weighted avg': {'precision': 0.47578580802993575, 'recall': 0.4727616155910182, 'f1-score': 0.47321117330318024, 'support': 56648}}
[[ 8081  4840  3287]
 [ 5965 11909  5782]
 [ 4689  5304  6791]]
training model: results/QRTEA/W5/deepVOL_L2/h200
Epoch 1/50
589/589 - 18s - loss: 3.2306 - accuracy200: 0.4193 - val_loss: 3.2869 - val_accuracy200: 0.4071 - 18s/epoch - 30ms/step
Epoch 2/50
589/589 - 15s - loss: 3.1233 - accuracy200: 0.4474 - val_loss: 3.2659 - val_accuracy200: 0.4079 - 15s/epoch - 25ms/step
Epoch 3/50
589/589 - 14s - loss: 3.0606 - accuracy200: 0.4646 - val_loss: 3.2340 - val_accuracy200: 0.4143 - 14s/epoch - 23ms/step
Epoch 4/50
589/589 - 15s - loss: 3.0271 - accuracy200: 0.4749 - val_loss: 3.2492 - val_accuracy200: 0.4113 - 15s/epoch - 25ms/step
Epoch 5/50
589/589 - 14s - loss: 3.0051 - accuracy200: 0.4809 - val_loss: 3.2432 - val_accuracy200: 0.4156 - 14s/epoch - 23ms/step
Epoch 6/50
589/589 - 14s - loss: 2.9848 - accuracy200: 0.4879 - val_loss: 3.2463 - val_accuracy200: 0.4178 - 14s/epoch - 23ms/step
Epoch 7/50
589/589 - 14s - loss: 2.9652 - accuracy200: 0.4933 - val_loss: 3.2665 - val_accuracy200: 0.4141 - 14s/epoch - 23ms/step
Epoch 8/50
589/589 - 14s - loss: 2.9477 - accuracy200: 0.4980 - val_loss: 3.2747 - val_accuracy200: 0.4143 - 14s/epoch - 23ms/step
Epoch 9/50
589/589 - 14s - loss: 2.9320 - accuracy200: 0.5030 - val_loss: 3.2828 - val_accuracy200: 0.4162 - 14s/epoch - 23ms/step
Epoch 10/50
589/589 - 14s - loss: 2.9140 - accuracy200: 0.5077 - val_loss: 3.3245 - val_accuracy200: 0.4119 - 14s/epoch - 24ms/step
Epoch 11/50
589/589 - 14s - loss: 2.8982 - accuracy200: 0.5119 - val_loss: 3.3256 - val_accuracy200: 0.4145 - 14s/epoch - 24ms/step
Epoch 12/50
589/589 - 14s - loss: 2.8872 - accuracy200: 0.5141 - val_loss: 3.3555 - val_accuracy200: 0.4059 - 14s/epoch - 23ms/step
Epoch 13/50
589/589 - 15s - loss: 2.8728 - accuracy200: 0.5184 - val_loss: 3.3575 - val_accuracy200: 0.4074 - 15s/epoch - 25ms/step
testing model: results/QRTEA/W5/deepVOL_L2/h200
Evaluating performance on  test set...
2185/2185 - 16s - 16s/epoch - 7ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0639397
{'0': {'precision': 0.4906278343242971, 'recall': 0.3996634240446579, 'f1-score': 0.44049854102105906, 'support': 219267}, '1': {'precision': 0.2710590441818996, 'recall': 0.3077829047142719, 'f1-score': 0.28825602611031154, 'support': 123964}, '2': {'precision': 0.4302785688374827, 'recall': 0.4778099317050585, 'f1-score': 0.45280030188149395, 'support': 215975}, 'accuracy': 0.4094770084727274, 'macro avg': {'precision': 0.39732181578122644, 'recall': 0.39508542015466275, 'f1-score': 0.39385162300428816, 'support': 559206}, 'weighted avg': {'precision': 0.41864620659725743, 'recall': 0.4094770084727274, 'f1-score': 0.41150078649667365, 'support': 559206}}
[[ 87633  51843  79791]
 [ 28963  38154  56847]
 [ 62018  50762 103195]]
Evaluating performance on  train set...
589/589 - 5s - 5s/epoch - 8ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0381674
{'0': {'precision': 0.45714626296340444, 'recall': 0.4126495652922441, 'f1-score': 0.4337597412145272, 'support': 46468}, '1': {'precision': 0.44627766599597585, 'recall': 0.4630480167014614, 'f1-score': 0.4545081967213115, 'support': 55085}, '2': {'precision': 0.42201159116900233, 'recall': 0.44307867638080506, 'f1-score': 0.432288615989437, 'support': 49138}, 'accuracy': 0.44099514901354425, 'macro avg': {'precision': 0.4418118400427942, 'recall': 0.43959208612483686, 'f1-score': 0.4401855179750919, 'support': 150691}, 'weighted avg': {'precision': 0.44171638217036346, 'recall': 0.44099514901354425, 'f1-score': 0.44086461489829554, 'support': 150691}}
[[19175 14943 12350]
 [12109 25507 17469]
 [10661 16705 21772]]
Evaluating performance on  val set...
222/222 - 2s - 2s/epoch - 11ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.065583
{'0': {'precision': 0.4366969333561761, 'recall': 0.3894972749961799, 'f1-score': 0.4117488692655611, 'support': 19633}, '1': {'precision': 0.3597244408945687, 'recall': 0.4359610381753282, 'f1-score': 0.39419053089357514, 'support': 16529}, '2': {'precision': 0.44485736718136615, 'recall': 0.4148686908132383, 'f1-score': 0.42934000151549595, 'support': 20486}, 'accuracy': 0.4122299110295156, 'macro avg': {'precision': 0.4137595804773703, 'recall': 0.41344233466158214, 'f1-score': 0.41175980055821076, 'support': 56648}, 'weighted avg': {'precision': 0.41718867745031774, 'recall': 0.4122299110295156, 'f1-score': 0.4129872211989323, 'support': 56648}}
[[7647 6230 5756]
 [4473 7206 4850]
 [5391 6596 8499]]
training model: results/QRTEA/W5/deepVOL_L2/h300
Epoch 1/50
589/589 - 17s - loss: 3.2750 - accuracy300: 0.3969 - val_loss: 3.2795 - val_accuracy300: 0.3857 - 17s/epoch - 28ms/step
Epoch 2/50
589/589 - 14s - loss: 3.1857 - accuracy300: 0.4258 - val_loss: 3.2355 - val_accuracy300: 0.4002 - 14s/epoch - 24ms/step
Epoch 3/50
589/589 - 14s - loss: 3.1403 - accuracy300: 0.4397 - val_loss: 3.2196 - val_accuracy300: 0.4008 - 14s/epoch - 24ms/step
Epoch 4/50
589/589 - 14s - loss: 3.1126 - accuracy300: 0.4477 - val_loss: 3.2433 - val_accuracy300: 0.4043 - 14s/epoch - 24ms/step
Epoch 5/50
589/589 - 14s - loss: 3.0887 - accuracy300: 0.4554 - val_loss: 3.2299 - val_accuracy300: 0.3998 - 14s/epoch - 23ms/step
Epoch 6/50
589/589 - 14s - loss: 3.0720 - accuracy300: 0.4614 - val_loss: 3.2500 - val_accuracy300: 0.3949 - 14s/epoch - 24ms/step
Epoch 7/50
589/589 - 14s - loss: 3.0551 - accuracy300: 0.4668 - val_loss: 3.2481 - val_accuracy300: 0.3929 - 14s/epoch - 24ms/step
Epoch 8/50
589/589 - 14s - loss: 3.0424 - accuracy300: 0.4717 - val_loss: 3.2538 - val_accuracy300: 0.3961 - 14s/epoch - 25ms/step
Epoch 9/50
589/589 - 14s - loss: 3.0293 - accuracy300: 0.4748 - val_loss: 3.2595 - val_accuracy300: 0.3924 - 14s/epoch - 23ms/step
Epoch 10/50
589/589 - 14s - loss: 3.0142 - accuracy300: 0.4798 - val_loss: 3.2875 - val_accuracy300: 0.3882 - 14s/epoch - 24ms/step
Epoch 11/50
589/589 - 14s - loss: 2.9966 - accuracy300: 0.4854 - val_loss: 3.3043 - val_accuracy300: 0.3871 - 14s/epoch - 24ms/step
Epoch 12/50
589/589 - 14s - loss: 2.9792 - accuracy300: 0.4921 - val_loss: 3.3072 - val_accuracy300: 0.3855 - 14s/epoch - 24ms/step
Epoch 13/50
589/589 - 14s - loss: 2.9596 - accuracy300: 0.4979 - val_loss: 3.3303 - val_accuracy300: 0.3876 - 14s/epoch - 24ms/step
testing model: results/QRTEA/W5/deepVOL_L2/h300
Evaluating performance on  test set...
2185/2185 - 24s - 24s/epoch - 11ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0652889
{'0': {'precision': 0.45243247450766716, 'recall': 0.2609734195402299, 'f1-score': 0.331011703066716, 'support': 222720}, '1': {'precision': 0.2400460908425593, 'recall': 0.1325047488890608, 'f1-score': 0.17075386012715715, 'support': 116343}, '2': {'precision': 0.4107362590889868, 'recall': 0.6838327814193501, 'f1-score': 0.5132155361386019, 'support': 220143}, 'accuracy': 0.40071279635769286, 'macro avg': {'precision': 0.3677382748130711, 'recall': 0.35910364994954697, 'f1-score': 0.338327033110825, 'support': 559206}, 'weighted avg': {'precision': 0.3918308375694651, 'recall': 0.40071279635769286, 'f1-score': 0.36939830872335616, 'support': 559206}}
[[ 58124  24821 139775]
 [ 24728  15416  76199]
 [ 45618  23984 150541]]
Evaluating performance on  train set...
589/589 - 5s - 5s/epoch - 9ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0599196
{'0': {'precision': 0.42119044405452827, 'recall': 0.3195829834299408, 'f1-score': 0.36341826990264126, 'support': 48823}, '1': {'precision': 0.43255549231644846, 'recall': 0.2937407188917594, 'f1-score': 0.34988248406871647, 'support': 49159}, '2': {'precision': 0.40594047070256534, 'recall': 0.6181487032575083, 'f1-score': 0.49005805733537894, 'support': 52709}, 'accuracy': 0.41558553596432435, 'macro avg': {'precision': 0.419895469024514, 'recall': 0.4104908018597362, 'f1-score': 0.4011196037689122, 'support': 150691}, 'weighted avg': {'precision': 0.4195638277476428, 'recall': 0.41558553596432435, 'f1-score': 0.4032988922356423, 'support': 150691}}
[[15603  9169 24051]
 [11089 14440 23630]
 [10353  9774 32582]]
Evaluating performance on  val set...
222/222 - 2s - 2s/epoch - 9ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.07194
{'0': {'precision': 0.4020227560050569, 'recall': 0.29992553983618764, 'f1-score': 0.34354921248649567, 'support': 20145}, '1': {'precision': 0.34793971600313617, 'recall': 0.2640137493389741, 'f1-score': 0.30022174615702635, 'support': 15128}, '2': {'precision': 0.41728599867286, 'recall': 0.5883976608187135, 'f1-score': 0.4882849655440163, 'support': 21375}, 'accuracy': 0.3991844372263805, 'macro avg': {'precision': 0.389082823560351, 'recall': 0.38411231666462503, 'f1-score': 0.3773519747291794, 'support': 56648}, 'weighted avg': {'precision': 0.3933390175301811, 'recall': 0.3991844372263805, 'f1-score': 0.38659166431131364, 'support': 56648}}
[[ 6042  3742 10361]
 [ 3932  3994  7202]
 [ 5055  3743 12577]]
training model: results/QRTEA/W5/deepVOL_L2/h500
Epoch 1/50
589/589 - 16s - loss: 3.3006 - accuracy500: 0.3829 - val_loss: 3.3859 - val_accuracy500: 0.3642 - 16s/epoch - 28ms/step
Epoch 2/50
589/589 - 14s - loss: 3.2689 - accuracy500: 0.3930 - val_loss: 3.3413 - val_accuracy500: 0.3612 - 14s/epoch - 24ms/step
Epoch 3/50
589/589 - 14s - loss: 3.2554 - accuracy500: 0.3940 - val_loss: 3.2965 - val_accuracy500: 0.3724 - 14s/epoch - 24ms/step
Epoch 4/50
589/589 - 14s - loss: 3.2337 - accuracy500: 0.4061 - val_loss: 3.3298 - val_accuracy500: 0.3751 - 14s/epoch - 23ms/step
Epoch 5/50
589/589 - 15s - loss: 3.2195 - accuracy500: 0.4128 - val_loss: 3.3263 - val_accuracy500: 0.3719 - 15s/epoch - 26ms/step
Epoch 6/50
589/589 - 15s - loss: 3.1912 - accuracy500: 0.4260 - val_loss: 3.3566 - val_accuracy500: 0.3723 - 15s/epoch - 25ms/step
Epoch 7/50
589/589 - 14s - loss: 3.1828 - accuracy500: 0.4301 - val_loss: 3.3572 - val_accuracy500: 0.3681 - 14s/epoch - 24ms/step
Epoch 8/50
589/589 - 14s - loss: 3.1679 - accuracy500: 0.4381 - val_loss: 3.3715 - val_accuracy500: 0.3639 - 14s/epoch - 24ms/step
Epoch 9/50
589/589 - 14s - loss: 3.1458 - accuracy500: 0.4458 - val_loss: 3.3677 - val_accuracy500: 0.3630 - 14s/epoch - 24ms/step
Epoch 10/50
589/589 - 14s - loss: 3.1279 - accuracy500: 0.4525 - val_loss: 3.4013 - val_accuracy500: 0.3597 - 14s/epoch - 24ms/step
Epoch 11/50
589/589 - 14s - loss: 3.1017 - accuracy500: 0.4609 - val_loss: 3.4321 - val_accuracy500: 0.3615 - 14s/epoch - 23ms/step
Epoch 12/50
589/589 - 14s - loss: 3.0879 - accuracy500: 0.4663 - val_loss: 3.4263 - val_accuracy500: 0.3675 - 14s/epoch - 23ms/step
Epoch 13/50
589/589 - 14s - loss: 3.0650 - accuracy500: 0.4746 - val_loss: 3.4814 - val_accuracy500: 0.3563 - 14s/epoch - 23ms/step
testing model: results/QRTEA/W5/deepVOL_L2/h500
Evaluating performance on  test set...
2185/2185 - 21s - 21s/epoch - 9ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0920469
{'0': {'precision': 0.42928215123385416, 'recall': 0.304168305151396, 'f1-score': 0.3560541090016357, 'support': 213612}, '1': {'precision': 0.2559526129145396, 'recall': 0.047999766139994446, 'f1-score': 0.08083941044339825, 'support': 136834}, '2': {'precision': 0.3783327664250765, 'recall': 0.6926374784441464, 'f1-score': 0.4893645824519841, 'support': 208760}, 'accuracy': 0.38650694019735127, 'macro avg': {'precision': 0.3545225101911568, 'recall': 0.34826851657851227, 'f1-score': 0.30875270063233934, 'support': 559206}, 'weighted avg': {'precision': 0.3678493918946026, 'recall': 0.38650694019735127, 'f1-score': 0.33847769954783313, 'support': 559206}}
[[ 64974   9665 138973]
 [ 31644   6568  98622]
 [ 54737   9428 144595]]
Evaluating performance on  train set...
589/589 - 6s - 6s/epoch - 9ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0895054
{'0': {'precision': 0.39149763823284245, 'recall': 0.3447657110232046, 'f1-score': 0.3666485959015504, 'support': 49042}, '1': {'precision': 0.37880228136882127, 'recall': 0.06705931846865797, 'f1-score': 0.1139466723854457, 'support': 47540}, '2': {'precision': 0.38184625632020347, 'recall': 0.6992552070820012, 'f1-score': 0.49395545575602495, 'support': 54109}, 'accuracy': 0.38444233564048286, 'macro avg': {'precision': 0.38404872530728906, 'recall': 0.3703600788579546, 'f1-score': 0.3248502413476737, 'support': 150691}, 'weighted avg': {'precision': 0.3840269605598125, 'recall': 0.38444233564048286, 'f1-score': 0.3326385849248507, 'support': 150691}}
[[16908  2399 29735]
 [12836  3188 31516]
 [13444  2829 37836]]
Evaluating performance on  val set...
222/222 - 2s - 2s/epoch - 8ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0951574
{'0': {'precision': 0.3782103103040856, 'recall': 0.3038872789047667, 'f1-score': 0.33699958442997646, 'support': 20014}, '1': {'precision': 0.2966872952311613, 'recall': 0.05096298149074537, 'f1-score': 0.08698436416030739, 'support': 15992}, '2': {'precision': 0.37802749867794816, 'recall': 0.6926169944772793, 'f1-score': 0.4891040333892101, 'support': 20642}, 'accuracy': 0.37413500917949444, 'macro avg': {'precision': 0.3509750347377317, 'recall': 0.3491557516242638, 'f1-score': 0.3043626606598313, 'support': 56648}, 'weighted avg': {'precision': 0.35512936032115705, 'recall': 0.37413500917949444, 'f1-score': 0.321844532757613, 'support': 56648}}
[[ 6082   939 12993]
 [ 4647   815 10530]
 [ 5352   993 14297]]
training model: results/QRTEA/W5/deepVOL_L2/h1000
Epoch 1/50
589/589 - 16s - loss: 3.2664 - accuracy1000: 0.4084 - val_loss: 3.4057 - val_accuracy1000: 0.3912 - 16s/epoch - 28ms/step
Epoch 2/50
589/589 - 14s - loss: 3.2549 - accuracy1000: 0.4006 - val_loss: 3.3591 - val_accuracy1000: 0.3920 - 14s/epoch - 24ms/step
Epoch 3/50
589/589 - 14s - loss: 3.2442 - accuracy1000: 0.4036 - val_loss: 3.3731 - val_accuracy1000: 0.3927 - 14s/epoch - 24ms/step
Epoch 4/50
589/589 - 15s - loss: 3.2364 - accuracy1000: 0.4107 - val_loss: 3.4466 - val_accuracy1000: 0.3933 - 15s/epoch - 25ms/step
Epoch 5/50
589/589 - 14s - loss: 3.2387 - accuracy1000: 0.4076 - val_loss: 3.3626 - val_accuracy1000: 0.3800 - 14s/epoch - 24ms/step
Epoch 6/50
589/589 - 14s - loss: 3.2318 - accuracy1000: 0.4089 - val_loss: 3.3836 - val_accuracy1000: 0.3559 - 14s/epoch - 24ms/step
Epoch 7/50
589/589 - 14s - loss: 3.2143 - accuracy1000: 0.4190 - val_loss: 3.3819 - val_accuracy1000: 0.3517 - 14s/epoch - 23ms/step
Epoch 8/50
589/589 - 14s - loss: 3.1972 - accuracy1000: 0.4245 - val_loss: 3.4080 - val_accuracy1000: 0.3451 - 14s/epoch - 23ms/step
Epoch 9/50
589/589 - 14s - loss: 3.1793 - accuracy1000: 0.4372 - val_loss: 3.3915 - val_accuracy1000: 0.3563 - 14s/epoch - 24ms/step
Epoch 10/50
589/589 - 14s - loss: 3.1666 - accuracy1000: 0.4407 - val_loss: 3.4040 - val_accuracy1000: 0.3515 - 14s/epoch - 24ms/step
Epoch 11/50
589/589 - 15s - loss: 3.1542 - accuracy1000: 0.4438 - val_loss: 3.4520 - val_accuracy1000: 0.3358 - 15s/epoch - 25ms/step
Epoch 12/50
589/589 - 14s - loss: 3.1450 - accuracy1000: 0.4521 - val_loss: 3.4549 - val_accuracy1000: 0.3454 - 14s/epoch - 23ms/step
testing model: results/QRTEA/W5/deepVOL_L2/h1000
Evaluating performance on  test set...
2185/2185 - 24s - 24s/epoch - 11ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1619527
{'0': {'precision': 0.23684210526315788, 'recall': 4.82912930798577e-05, 'f1-score': 9.656289731608793e-05, 'support': 186369}, '1': {'precision': 0.33023844501382804, 'recall': 0.982299594354451, 'f1-score': 0.4942989549216531, 'support': 185137}, '2': {'precision': 0.30666666666666664, 'recall': 0.013846563665423549, 'f1-score': 0.026496750350452403, 'support': 187700}, 'accuracy': 0.32987485828120583, 'macro avg': {'precision': 0.2912490723145508, 'recall': 0.33206481643765146, 'f1-score': 0.17363075605647385, 'support': 559206}, 'weighted avg': {'precision': 0.29119987025112015, 'recall': 0.32987485828120583, 'f1-score': 0.17257408180298478, 'support': 559206}}
[[     9 183750   2610]
 [    11 181860   3266]
 [    18 185083   2599]]
Evaluating performance on  train set...
589/589 - 5s - 5s/epoch - 9ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1571363
{'0': {'precision': 0.18181818181818182, 'recall': 4.1315485043794416e-05, 'f1-score': 8.261219769098908e-05, 'support': 48408}, '1': {'precision': 0.3245457132403756, 'recall': 0.9813164525843525, 'f1-score': 0.4877728390535979, 'support': 48813}, '2': {'precision': 0.37265068049254696, 'recall': 0.021507387319992518, 'f1-score': 0.04066765683570266, 'support': 53470}, 'accuracy': 0.3255204358588104, 'macro avg': {'precision': 0.2930048585170348, 'recall': 0.33428838512979625, 'f1-score': 0.17617436936233052, 'support': 150691}, 'weighted avg': {'precision': 0.29576508438986726, 'recall': 0.3255204358588104, 'f1-score': 0.1724598967091208, 'support': 150691}}
[[    2 47380  1026]
 [    2 47901   910]
 [    7 52313  1150]]
Evaluating performance on  val set...
222/222 - 2s - 2s/epoch - 8ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1176249
{'0': {'precision': 0.75, 'recall': 0.00017590149516270889, 'f1-score': 0.00035172049944310924, 'support': 17055}, '1': {'precision': 0.39407313997477933, 'recall': 0.9821749281609196, 'f1-score': 0.5624694659432774, 'support': 22272}, '2': {'precision': 0.2980599647266314, 'recall': 0.019513884879625888, 'f1-score': 0.03662963966404768, 'support': 17321}, 'accuracy': 0.3921762462928965, 'macro avg': {'precision': 0.48071103490047024, 'recall': 0.333954904845236, 'f1-score': 0.1998169420355894, 'support': 56648}, 'weighted avg': {'precision': 0.47187444609780166, 'recall': 0.3921762462928965, 'f1-score': 0.23244916903028606, 'support': 56648}}
[[    3 16653   399]
 [    0 21875   397]
 [    1 16982   338]]
training model: results/QRTEA/W5/deepVOL_L3/h10
Epoch 1/50
589/589 - 25s - loss: 2.9377 - accuracy10: 0.5023 - val_loss: 3.0092 - val_accuracy10: 0.6435 - 25s/epoch - 43ms/step
Epoch 2/50
589/589 - 23s - loss: 2.4111 - accuracy10: 0.6300 - val_loss: 2.9032 - val_accuracy10: 0.6937 - 23s/epoch - 38ms/step
Epoch 3/50
589/589 - 22s - loss: 2.2606 - accuracy10: 0.6758 - val_loss: 2.7833 - val_accuracy10: 0.6956 - 22s/epoch - 38ms/step
Epoch 4/50
589/589 - 22s - loss: 2.1874 - accuracy10: 0.6879 - val_loss: 2.6764 - val_accuracy10: 0.6668 - 22s/epoch - 38ms/step
Epoch 5/50
589/589 - 22s - loss: 2.1507 - accuracy10: 0.6970 - val_loss: 2.6920 - val_accuracy10: 0.6943 - 22s/epoch - 38ms/step
Epoch 6/50
589/589 - 22s - loss: 2.1215 - accuracy10: 0.7000 - val_loss: 2.6910 - val_accuracy10: 0.7037 - 22s/epoch - 38ms/step
Epoch 7/50
589/589 - 22s - loss: 2.1010 - accuracy10: 0.7070 - val_loss: 2.6207 - val_accuracy10: 0.6751 - 22s/epoch - 38ms/step
Epoch 8/50
589/589 - 22s - loss: 2.0859 - accuracy10: 0.7095 - val_loss: 2.6485 - val_accuracy10: 0.6816 - 22s/epoch - 38ms/step
Epoch 9/50
589/589 - 22s - loss: 2.0664 - accuracy10: 0.7113 - val_loss: 2.6252 - val_accuracy10: 0.7015 - 22s/epoch - 38ms/step
Epoch 10/50
589/589 - 23s - loss: 2.0624 - accuracy10: 0.7127 - val_loss: 2.6167 - val_accuracy10: 0.6803 - 23s/epoch - 39ms/step
Epoch 11/50
589/589 - 23s - loss: 2.0427 - accuracy10: 0.7148 - val_loss: 2.6481 - val_accuracy10: 0.6866 - 23s/epoch - 39ms/step
Epoch 12/50
589/589 - 23s - loss: 2.0331 - accuracy10: 0.7141 - val_loss: 2.5878 - val_accuracy10: 0.6933 - 23s/epoch - 38ms/step
Epoch 13/50
589/589 - 22s - loss: 2.0337 - accuracy10: 0.7138 - val_loss: 2.6249 - val_accuracy10: 0.6829 - 22s/epoch - 38ms/step
Epoch 14/50
589/589 - 22s - loss: 2.0224 - accuracy10: 0.7158 - val_loss: 2.6221 - val_accuracy10: 0.6685 - 22s/epoch - 37ms/step
Epoch 15/50
589/589 - 22s - loss: 2.0090 - accuracy10: 0.7133 - val_loss: 2.6130 - val_accuracy10: 0.6644 - 22s/epoch - 37ms/step
Epoch 16/50
589/589 - 22s - loss: 1.9988 - accuracy10: 0.7174 - val_loss: 2.6198 - val_accuracy10: 0.6651 - 22s/epoch - 38ms/step
Epoch 17/50
589/589 - 22s - loss: 1.9878 - accuracy10: 0.7178 - val_loss: 2.6073 - val_accuracy10: 0.6745 - 22s/epoch - 38ms/step
Epoch 18/50
589/589 - 22s - loss: 1.9750 - accuracy10: 0.7180 - val_loss: 2.6104 - val_accuracy10: 0.6630 - 22s/epoch - 38ms/step
Epoch 19/50
589/589 - 22s - loss: 1.9650 - accuracy10: 0.7173 - val_loss: 2.6285 - val_accuracy10: 0.6556 - 22s/epoch - 37ms/step
Epoch 20/50
589/589 - 23s - loss: 1.9555 - accuracy10: 0.7177 - val_loss: 2.6401 - val_accuracy10: 0.6648 - 23s/epoch - 38ms/step
Epoch 21/50
589/589 - 22s - loss: 1.9423 - accuracy10: 0.7175 - val_loss: 2.6339 - val_accuracy10: 0.6643 - 22s/epoch - 38ms/step
Epoch 22/50
589/589 - 23s - loss: 1.9387 - accuracy10: 0.7174 - val_loss: 2.6514 - val_accuracy10: 0.6568 - 23s/epoch - 38ms/step
testing model: results/QRTEA/W5/deepVOL_L3/h10
Evaluating performance on  test set...
2185/2185 - 34s - 34s/epoch - 16ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 1.011469
{'0': {'precision': 0.30943149640601175, 'recall': 0.6154122263067345, 'f1-score': 0.4118056303265722, 'support': 80793}, '1': {'precision': 0.9086502286936418, 'recall': 0.5017892533990778, 'f1-score': 0.6465373745501978, 'support': 397093}, '2': {'precision': 0.29090787359400105, 'recall': 0.6411706837186424, 'f1-score': 0.4002272099235469, 'support': 81320}, 'accuracy': 0.5384741937675919, 'macro avg': {'precision': 0.5029965328978848, 'recall': 0.5861240544748182, 'f1-score': 0.4861900716001056, 'support': 559206}, 'weighted avg': {'precision': 0.7322438822767269, 'recall': 0.5384741937675919, 'f1-score': 0.5768052464998933, 'support': 559206}}
[[ 49721  11493  19579]
 [ 90323 199257 107513]
 [ 20641   8539  52140]]
Evaluating performance on  train set...
589/589 - 11s - 11s/epoch - 19ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.6551092
{'0': {'precision': 0.33378723404255317, 'recall': 0.640640313622999, 'f1-score': 0.43889883616830794, 'support': 12244}, '1': {'precision': 0.9517168462390494, 'recall': 0.7499642930823798, 'f1-score': 0.8388806049632548, 'support': 126026}, '2': {'precision': 0.30206950970194757, 'recall': 0.678045245954432, 'f1-score': 0.4179445188824376, 'support': 12421}, 'accuracy': 0.7351533933678853, 'macro avg': {'precision': 0.5291911966611834, 'recall': 0.6895499508866036, 'f1-score': 0.5652413200046668, 'support': 150691}, 'weighted avg': {'precision': 0.8479601538097653, 'recall': 0.7351533933678853, 'f1-score': 0.7716846615934772, 'support': 150691}}
[[ 7844  2350  2050]
 [14102 94515 17409]
 [ 1554  2445  8422]]
Evaluating performance on  val set...
222/222 - 4s - 4s/epoch - 19ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.72800714
{'0': {'precision': 0.3078351908139142, 'recall': 0.6595513748191028, 'f1-score': 0.4197559290812802, 'support': 5528}, '1': {'precision': 0.9359780161955156, 'recall': 0.7052357981453335, 'f1-score': 0.8043866040248223, 'support': 45399}, '2': {'precision': 0.344059639520619, 'recall': 0.6373011711239294, 'f1-score': 0.44686848878539037, 'support': 5721}, 'accuracy': 0.6939168196582404, 'macro avg': {'precision': 0.5292909488433496, 'recall': 0.6673627813627885, 'f1-score': 0.557003673963831, 'support': 56648}, 'weighted avg': {'precision': 0.8149015691600231, 'recall': 0.6939168196582404, 'f1-score': 0.7307458839928231, 'support': 56648}}
[[ 3646  1019   863]
 [ 7294 32017  6088]
 [  904  1171  3646]]
training model: results/QRTEA/W5/deepVOL_L3/h20
Epoch 1/50
589/589 - 24s - loss: 2.9795 - accuracy20: 0.4600 - val_loss: 3.1768 - val_accuracy20: 0.5566 - 24s/epoch - 42ms/step
Epoch 2/50
589/589 - 23s - loss: 2.4948 - accuracy20: 0.6162 - val_loss: 2.9837 - val_accuracy20: 0.6511 - 23s/epoch - 39ms/step
Epoch 3/50
589/589 - 22s - loss: 2.3736 - accuracy20: 0.6546 - val_loss: 2.8566 - val_accuracy20: 0.6654 - 22s/epoch - 38ms/step
Epoch 4/50
589/589 - 23s - loss: 2.2914 - accuracy20: 0.6671 - val_loss: 2.9158 - val_accuracy20: 0.6805 - 23s/epoch - 39ms/step
Epoch 5/50
589/589 - 23s - loss: 2.2471 - accuracy20: 0.6750 - val_loss: 2.8579 - val_accuracy20: 0.6835 - 23s/epoch - 38ms/step
Epoch 6/50
589/589 - 23s - loss: 2.2187 - accuracy20: 0.6779 - val_loss: 2.8120 - val_accuracy20: 0.6606 - 23s/epoch - 39ms/step
Epoch 7/50
589/589 - 23s - loss: 2.1912 - accuracy20: 0.6830 - val_loss: 2.7773 - val_accuracy20: 0.6684 - 23s/epoch - 39ms/step
Epoch 8/50
589/589 - 22s - loss: 2.1724 - accuracy20: 0.6849 - val_loss: 2.7730 - val_accuracy20: 0.6593 - 22s/epoch - 38ms/step
Epoch 9/50
589/589 - 22s - loss: 2.1593 - accuracy20: 0.6854 - val_loss: 2.7797 - val_accuracy20: 0.6671 - 22s/epoch - 38ms/step
Epoch 10/50
589/589 - 22s - loss: 2.1447 - accuracy20: 0.6858 - val_loss: 2.7338 - val_accuracy20: 0.6576 - 22s/epoch - 37ms/step
Epoch 11/50
589/589 - 22s - loss: 2.1245 - accuracy20: 0.6874 - val_loss: 2.7973 - val_accuracy20: 0.6741 - 22s/epoch - 37ms/step
Epoch 12/50
589/589 - 22s - loss: 2.1175 - accuracy20: 0.6878 - val_loss: 2.7822 - val_accuracy20: 0.6710 - 22s/epoch - 38ms/step
Epoch 13/50
589/589 - 22s - loss: 2.0996 - accuracy20: 0.6913 - val_loss: 2.7456 - val_accuracy20: 0.6582 - 22s/epoch - 37ms/step
Epoch 14/50
589/589 - 22s - loss: 2.0943 - accuracy20: 0.6896 - val_loss: 2.7813 - val_accuracy20: 0.6579 - 22s/epoch - 37ms/step
Epoch 15/50
589/589 - 22s - loss: 2.0857 - accuracy20: 0.6914 - val_loss: 2.7598 - val_accuracy20: 0.6549 - 22s/epoch - 37ms/step
Epoch 16/50
589/589 - 22s - loss: 2.0740 - accuracy20: 0.6917 - val_loss: 2.7891 - val_accuracy20: 0.6505 - 22s/epoch - 38ms/step
Epoch 17/50
589/589 - 22s - loss: 2.0698 - accuracy20: 0.6927 - val_loss: 2.7985 - val_accuracy20: 0.6475 - 22s/epoch - 38ms/step
Epoch 18/50
589/589 - 22s - loss: 2.0579 - accuracy20: 0.6923 - val_loss: 2.7517 - val_accuracy20: 0.6368 - 22s/epoch - 37ms/step
Epoch 19/50
589/589 - 22s - loss: 2.0493 - accuracy20: 0.6940 - val_loss: 2.7548 - val_accuracy20: 0.6548 - 22s/epoch - 38ms/step
Epoch 20/50
589/589 - 22s - loss: 2.0378 - accuracy20: 0.6956 - val_loss: 2.7796 - val_accuracy20: 0.6412 - 22s/epoch - 38ms/step
testing model: results/QRTEA/W5/deepVOL_L3/h20
Evaluating performance on  test set...
2185/2185 - 40s - 40s/epoch - 18ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.99729884
{'0': {'precision': 0.35676977001924903, 'recall': 0.656915776523658, 'f1-score': 0.46240708730957836, 'support': 102418}, '1': {'precision': 0.8387149692412851, 'recall': 0.5201202694759687, 'f1-score': 0.6420685060053513, 'support': 353872}, '2': {'precision': 0.34571853811807507, 'recall': 0.5078316296785729, 'f1-score': 0.4113801748192577, 'support': 102916}, 'accuracy': 0.5429126296928145, 'macro avg': {'precision': 0.5137344257928698, 'recall': 0.5616225585593998, 'f1-score': 0.5052852560447291, 'support': 559206}, 'weighted avg': {'precision': 0.6597163817450873, 'recall': 0.5429126296928145, 'f1-score': 0.566707934995148, 'support': 559206}}
[[ 67280  19367  15771]
 [ 86676 184056  83140]
 [ 34625  16027  52264]]
Evaluating performance on  train set...
589/589 - 11s - 11s/epoch - 19ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.722563
{'0': {'precision': 0.3841765191091559, 'recall': 0.6676222899122021, 'f1-score': 0.4877069744104365, 'support': 16743}, '1': {'precision': 0.9162030905077263, 'recall': 0.7106971009777565, 'f1-score': 0.8004705927733151, 'support': 116798}, '2': {'precision': 0.34160348443297306, 'recall': 0.6173760932944606, 'f1-score': 0.4398379894069997, 'support': 17150}, 'accuracy': 0.6952903623972234, 'macro avg': {'precision': 0.5473276980166184, 'recall': 0.6652318280614731, 'f1-score': 0.5760051855302505, 'support': 150691}, 'weighted avg': {'precision': 0.791695959165388, 'recall': 0.6952903623972234, 'f1-score': 0.724676747022859, 'support': 150691}}
[[11178  3782  1783]
 [15166 83008 18624]
 [ 2752  3810 10588]]
Evaluating performance on  val set...
222/222 - 4s - 4s/epoch - 18ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.7905239
{'0': {'precision': 0.3598682797623309, 'recall': 0.6708928333110904, 'f1-score': 0.4684558755008853, 'support': 7493}, '1': {'precision': 0.8861079145889272, 'recall': 0.6712919239617388, 'f1-score': 0.7638848702792819, 'support': 41295}, '2': {'precision': 0.38560772268538834, 'recall': 0.5590330788804071, 'f1-score': 0.4564009348221241, 'support': 7860}, 'accuracy': 0.6556630419432283, 'macro avg': {'precision': 0.5438613056788822, 'recall': 0.6337392787177455, 'f1-score': 0.562913893534097, 'support': 56648}, 'weighted avg': {'precision': 0.74705543096872, 'recall': 0.6556630419432283, 'f1-score': 0.6821437110050306, 'support': 56648}}
[[ 5027  1701   765]
 [ 7338 27721  6236]
 [ 1604  1862  4394]]
training model: results/QRTEA/W5/deepVOL_L3/h30
Epoch 1/50
589/589 - 25s - loss: 3.0162 - accuracy30: 0.4633 - val_loss: 3.2775 - val_accuracy30: 0.5801 - 25s/epoch - 42ms/step
Epoch 2/50
589/589 - 22s - loss: 2.5788 - accuracy30: 0.5824 - val_loss: 3.0925 - val_accuracy30: 0.6241 - 22s/epoch - 38ms/step
Epoch 3/50
589/589 - 22s - loss: 2.4713 - accuracy30: 0.6264 - val_loss: 3.0173 - val_accuracy30: 0.6386 - 22s/epoch - 38ms/step
Epoch 4/50
589/589 - 22s - loss: 2.4019 - accuracy30: 0.6391 - val_loss: 2.9859 - val_accuracy30: 0.6452 - 22s/epoch - 38ms/step
Epoch 5/50
589/589 - 23s - loss: 2.3612 - accuracy30: 0.6464 - val_loss: 3.0284 - val_accuracy30: 0.6425 - 23s/epoch - 39ms/step
Epoch 6/50
589/589 - 22s - loss: 2.3243 - accuracy30: 0.6504 - val_loss: 2.9954 - val_accuracy30: 0.6505 - 22s/epoch - 38ms/step
Epoch 7/50
589/589 - 22s - loss: 2.2994 - accuracy30: 0.6592 - val_loss: 2.9807 - val_accuracy30: 0.6477 - 22s/epoch - 38ms/step
Epoch 8/50
589/589 - 22s - loss: 2.2779 - accuracy30: 0.6592 - val_loss: 2.9968 - val_accuracy30: 0.6394 - 22s/epoch - 37ms/step
Epoch 9/50
589/589 - 22s - loss: 2.2622 - accuracy30: 0.6605 - val_loss: 2.9782 - val_accuracy30: 0.6452 - 22s/epoch - 38ms/step
Epoch 10/50
589/589 - 22s - loss: 2.2463 - accuracy30: 0.6628 - val_loss: 2.9695 - val_accuracy30: 0.6237 - 22s/epoch - 37ms/step
Epoch 11/50
589/589 - 22s - loss: 2.2324 - accuracy30: 0.6648 - val_loss: 2.9334 - val_accuracy30: 0.6044 - 22s/epoch - 37ms/step
Epoch 12/50
589/589 - 23s - loss: 2.2196 - accuracy30: 0.6648 - val_loss: 2.9495 - val_accuracy30: 0.6107 - 23s/epoch - 39ms/step
Epoch 13/50
589/589 - 22s - loss: 2.2075 - accuracy30: 0.6647 - val_loss: 2.9609 - val_accuracy30: 0.6178 - 22s/epoch - 38ms/step
Epoch 14/50
589/589 - 22s - loss: 2.1980 - accuracy30: 0.6674 - val_loss: 2.9300 - val_accuracy30: 0.6218 - 22s/epoch - 38ms/step
Epoch 15/50
589/589 - 22s - loss: 2.1843 - accuracy30: 0.6690 - val_loss: 2.9283 - val_accuracy30: 0.6248 - 22s/epoch - 38ms/step
Epoch 16/50
589/589 - 22s - loss: 2.1776 - accuracy30: 0.6688 - val_loss: 2.8879 - val_accuracy30: 0.6074 - 22s/epoch - 38ms/step
Epoch 17/50
589/589 - 22s - loss: 2.1717 - accuracy30: 0.6699 - val_loss: 2.9472 - val_accuracy30: 0.6182 - 22s/epoch - 37ms/step
Epoch 18/50
589/589 - 22s - loss: 2.1606 - accuracy30: 0.6705 - val_loss: 2.9166 - val_accuracy30: 0.6221 - 22s/epoch - 38ms/step
Epoch 19/50
589/589 - 22s - loss: 2.1514 - accuracy30: 0.6714 - val_loss: 2.8973 - val_accuracy30: 0.6319 - 22s/epoch - 37ms/step
Epoch 20/50
589/589 - 22s - loss: 2.1385 - accuracy30: 0.6709 - val_loss: 2.8977 - val_accuracy30: 0.6234 - 22s/epoch - 37ms/step
Epoch 21/50
589/589 - 22s - loss: 2.1292 - accuracy30: 0.6756 - val_loss: 2.9132 - val_accuracy30: 0.6177 - 22s/epoch - 37ms/step
Epoch 22/50
589/589 - 22s - loss: 2.1149 - accuracy30: 0.6744 - val_loss: 2.9802 - val_accuracy30: 0.6303 - 22s/epoch - 37ms/step
Epoch 23/50
589/589 - 22s - loss: 2.1095 - accuracy30: 0.6738 - val_loss: 3.0012 - val_accuracy30: 0.6082 - 22s/epoch - 37ms/step
Epoch 24/50
589/589 - 22s - loss: 2.0969 - accuracy30: 0.6747 - val_loss: 2.9339 - val_accuracy30: 0.6053 - 22s/epoch - 38ms/step
Epoch 25/50
589/589 - 22s - loss: 2.0807 - accuracy30: 0.6766 - val_loss: 2.9914 - val_accuracy30: 0.5957 - 22s/epoch - 37ms/step
Epoch 26/50
589/589 - 23s - loss: 2.0708 - accuracy30: 0.6775 - val_loss: 3.0115 - val_accuracy30: 0.6162 - 23s/epoch - 38ms/step
testing model: results/QRTEA/W5/deepVOL_L3/h30
Evaluating performance on  test set...
2185/2185 - 33s - 33s/epoch - 15ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.0344841
{'0': {'precision': 0.36663258388254777, 'recall': 0.5592313821220906, 'f1-score': 0.442899722084234, 'support': 117978}, '1': {'precision': 0.783539628351102, 'recall': 0.3819478877429591, 'f1-score': 0.5135555754635021, 'support': 322688}, '2': {'precision': 0.33758047875000563, 'recall': 0.6320819976379282, 'f1-score': 0.44010890091719945, 'support': 118540}, 'accuracy': 0.47237332932765386, 'macro avg': {'precision': 0.4959175636612185, 'recall': 0.5244204225009926, 'f1-score': 0.46552139948831184, 'support': 559206}, 'weighted avg': {'precision': 0.6010489954072047, 'recall': 0.47237332932765386, 'f1-score': 0.48307985619243204, 'support': 559206}}
[[ 65977  19819  32182]
 [ 84594 123250 114844]
 [ 29383  14230  74927]]
Evaluating performance on  train set...
589/589 - 9s - 9s/epoch - 16ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.77376705
{'0': {'precision': 0.43910825199645076, 'recall': 0.5869532987398073, 'f1-score': 0.5023792906541462, 'support': 20235}, '1': {'precision': 0.8796077606994027, 'recall': 0.6485148514851485, 'f1-score': 0.7465875993807561, 'support': 109686}, '2': {'precision': 0.32889138261560763, 'recall': 0.6773230621088108, 'f1-score': 0.442779806118595, 'support': 20770}, 'accuracy': 0.6442189646362424, 'macro avg': {'precision': 0.5492024651038204, 'recall': 0.6375970707779222, 'f1-score': 0.5639155653844992, 'support': 150691}, 'weighted avg': {'precision': 0.7445506787807437, 'recall': 0.6442189646362424, 'f1-score': 0.6719206120149676, 'support': 150691}}
[[11877  5311  3047]
 [12894 71133 25659]
 [ 2277  4425 14068]]
Evaluating performance on  val set...
222/222 - 3s - 3s/epoch - 15ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.8356718
{'0': {'precision': 0.40337796713329277, 'recall': 0.5869589283737408, 'f1-score': 0.478153041439329, 'support': 9033}, '1': {'precision': 0.8350227443676349, 'recall': 0.6113762718976188, 'f1-score': 0.705909070263887, 'support': 38132}, '2': {'precision': 0.3660571061918511, 'recall': 0.6016028682906254, 'f1-score': 0.4551619594702409, 'support': 9483}, 'accuracy': 0.6058466318316622, 'macro avg': {'precision': 0.5348192725642597, 'recall': 0.5999793561873283, 'f1-score': 0.5464080237244856, 'support': 56648}, 'weighted avg': {'precision': 0.6876874735799854, 'recall': 0.6058466318316622, 'f1-score': 0.6276158373160623, 'support': 56648}}
[[ 5302  2372  1359]
 [ 6298 23313  8521]
 [ 1544  2234  5705]]
training model: results/QRTEA/W5/deepVOL_L3/h50
Epoch 1/50
589/589 - 25s - loss: 3.1180 - accuracy50: 0.4359 - val_loss: 3.4831 - val_accuracy50: 0.4720 - 25s/epoch - 42ms/step
Epoch 2/50
589/589 - 22s - loss: 2.8986 - accuracy50: 0.4626 - val_loss: 3.3637 - val_accuracy50: 0.5428 - 22s/epoch - 38ms/step
Epoch 3/50
589/589 - 23s - loss: 2.7372 - accuracy50: 0.5414 - val_loss: 3.1860 - val_accuracy50: 0.5714 - 23s/epoch - 39ms/step
Epoch 4/50
589/589 - 22s - loss: 2.6235 - accuracy50: 0.5811 - val_loss: 3.1780 - val_accuracy50: 0.5930 - 22s/epoch - 38ms/step
Epoch 5/50
589/589 - 24s - loss: 2.5663 - accuracy50: 0.5992 - val_loss: 3.1650 - val_accuracy50: 0.5927 - 24s/epoch - 41ms/step
Epoch 6/50
589/589 - 22s - loss: 2.5280 - accuracy50: 0.6076 - val_loss: 3.1277 - val_accuracy50: 0.5969 - 22s/epoch - 38ms/step
Epoch 7/50
589/589 - 23s - loss: 2.5082 - accuracy50: 0.6103 - val_loss: 3.1742 - val_accuracy50: 0.6018 - 23s/epoch - 38ms/step
Epoch 8/50
589/589 - 22s - loss: 2.4870 - accuracy50: 0.6119 - val_loss: 3.1972 - val_accuracy50: 0.6081 - 22s/epoch - 38ms/step
Epoch 9/50
589/589 - 23s - loss: 2.4742 - accuracy50: 0.6127 - val_loss: 3.2165 - val_accuracy50: 0.6070 - 23s/epoch - 38ms/step
Epoch 10/50
589/589 - 22s - loss: 2.4559 - accuracy50: 0.6195 - val_loss: 3.1420 - val_accuracy50: 0.6046 - 22s/epoch - 38ms/step
Epoch 11/50
589/589 - 23s - loss: 2.4405 - accuracy50: 0.6215 - val_loss: 3.1579 - val_accuracy50: 0.6078 - 23s/epoch - 39ms/step
Epoch 12/50
589/589 - 23s - loss: 2.4230 - accuracy50: 0.6264 - val_loss: 3.1270 - val_accuracy50: 0.6009 - 23s/epoch - 39ms/step
Epoch 13/50
589/589 - 22s - loss: 2.4099 - accuracy50: 0.6277 - val_loss: 3.1513 - val_accuracy50: 0.5864 - 22s/epoch - 38ms/step
Epoch 14/50
589/589 - 22s - loss: 2.3980 - accuracy50: 0.6302 - val_loss: 3.1452 - val_accuracy50: 0.5954 - 22s/epoch - 38ms/step
Epoch 15/50
589/589 - 22s - loss: 2.3836 - accuracy50: 0.6316 - val_loss: 3.1246 - val_accuracy50: 0.5873 - 22s/epoch - 38ms/step
Epoch 16/50
589/589 - 23s - loss: 2.3699 - accuracy50: 0.6333 - val_loss: 3.1393 - val_accuracy50: 0.5933 - 23s/epoch - 39ms/step
Epoch 17/50
589/589 - 23s - loss: 2.3587 - accuracy50: 0.6341 - val_loss: 3.1782 - val_accuracy50: 0.5945 - 23s/epoch - 38ms/step
Epoch 18/50
589/589 - 22s - loss: 2.3485 - accuracy50: 0.6355 - val_loss: 3.1941 - val_accuracy50: 0.5806 - 22s/epoch - 38ms/step
Epoch 19/50
589/589 - 23s - loss: 2.3399 - accuracy50: 0.6383 - val_loss: 3.1749 - val_accuracy50: 0.5917 - 23s/epoch - 38ms/step
Epoch 20/50
589/589 - 23s - loss: 2.3289 - accuracy50: 0.6384 - val_loss: 3.1761 - val_accuracy50: 0.5910 - 23s/epoch - 38ms/step
Epoch 21/50
589/589 - 23s - loss: 2.3151 - accuracy50: 0.6401 - val_loss: 3.2119 - val_accuracy50: 0.5794 - 23s/epoch - 38ms/step
Epoch 22/50
589/589 - 23s - loss: 2.3006 - accuracy50: 0.6395 - val_loss: 3.1931 - val_accuracy50: 0.5766 - 23s/epoch - 39ms/step
Epoch 23/50
589/589 - 23s - loss: 2.2863 - accuracy50: 0.6426 - val_loss: 3.3016 - val_accuracy50: 0.5897 - 23s/epoch - 38ms/step
Epoch 24/50
589/589 - 23s - loss: 2.2787 - accuracy50: 0.6435 - val_loss: 3.2324 - val_accuracy50: 0.5806 - 23s/epoch - 38ms/step
Epoch 25/50
589/589 - 23s - loss: 2.2588 - accuracy50: 0.6464 - val_loss: 3.2970 - val_accuracy50: 0.5997 - 23s/epoch - 38ms/step
testing model: results/QRTEA/W5/deepVOL_L3/h50
Evaluating performance on  test set...
2185/2185 - 34s - 34s/epoch - 16ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.019309
{'0': {'precision': 0.42827836026436683, 'recall': 0.5798480417535365, 'f1-score': 0.4926691098013691, 'support': 142934}, '1': {'precision': 0.6606859545054923, 'recall': 0.4793288757899676, 'f1-score': 0.55558199315927, 'support': 272796}, '2': {'precision': 0.39746562319324324, 'recall': 0.46477459644818647, 'f1-score': 0.4284929429492143, 'support': 143476}, 'accuracy': 0.5012875398332636, 'macro avg': {'precision': 0.49547664598770075, 'recall': 0.5079838379972302, 'f1-score': 0.4922480153032845, 'support': 559206}, 'weighted avg': {'precision': 0.5337474965300463, 'recall': 0.5012875398332636, 'f1-score': 0.5068939986852906, 'support': 559206}}
[[ 82880  35694  24360]
 [ 65308 130759  76729]
 [ 45331  31461  66684]]
Evaluating performance on  train set...
589/589 - 10s - 10s/epoch - 16ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.8130843
{'0': {'precision': 0.4612240026258467, 'recall': 0.5866924770363623, 'f1-score': 0.5164469837451344, 'support': 26346}, '1': {'precision': 0.798303521152072, 'recall': 0.683636512871023, 'f1-score': 0.7365337636928383, 'support': 97467}, '2': {'precision': 0.42312598261694995, 'recall': 0.5306942480839348, 'f1-score': 0.47084454273878096, 'support': 26878}, 'accuracy': 0.639407794758811, 'macro avg': {'precision': 0.5608845021316229, 'recall': 0.6003410793304401, 'f1-score': 0.5746084300589179, 'support': 150691}, 'weighted avg': {'precision': 0.6724518188218802, 'recall': 0.639407794758811, 'f1-score': 0.6506653230739204, 'support': 150691}}
[[15457  8264  2625]
 [14013 66632 16822]
 [ 4043  8571 14264]]
Evaluating performance on  val set...
222/222 - 3s - 3s/epoch - 16ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.90129673
{'0': {'precision': 0.425163762204919, 'recall': 0.5920316668100852, 'f1-score': 0.4949106211559904, 'support': 11621}, '1': {'precision': 0.7297629068462402, 'recall': 0.6341857417172118, 'f1-score': 0.678625593189935, 'support': 32809}, '2': {'precision': 0.4595114605989627, 'recall': 0.4495825830741529, 'f1-score': 0.45449280158861494, 'support': 12218}, 'accuracy': 0.5857223555994916, 'macro avg': {'precision': 0.5381460432167073, 'recall': 0.5585999972004833, 'f1-score': 0.5426763386448468, 'support': 56648}, 'weighted avg': {'precision': 0.6089876132767227, 'recall': 0.5857223555994916, 'f1-score': 0.5925959692351369, 'support': 56648}}
[[ 6880  3641  1100]
 [ 6641 20807  5361]
 [ 2661  4064  5493]]
training model: results/QRTEA/W5/deepVOL_L3/h100
Epoch 1/50
589/589 - 25s - loss: 3.2030 - accuracy100: 0.4198 - val_loss: 3.4125 - val_accuracy100: 0.4177 - 25s/epoch - 42ms/step
Epoch 2/50
589/589 - 22s - loss: 3.0271 - accuracy100: 0.4712 - val_loss: 3.3592 - val_accuracy100: 0.4860 - 22s/epoch - 38ms/step
Epoch 3/50
589/589 - 22s - loss: 2.9230 - accuracy100: 0.5151 - val_loss: 3.3556 - val_accuracy100: 0.5017 - 22s/epoch - 38ms/step
Epoch 4/50
589/589 - 22s - loss: 2.8677 - accuracy100: 0.5317 - val_loss: 3.3237 - val_accuracy100: 0.4992 - 22s/epoch - 38ms/step
Epoch 5/50
589/589 - 22s - loss: 2.8407 - accuracy100: 0.5408 - val_loss: 3.3134 - val_accuracy100: 0.5045 - 22s/epoch - 38ms/step
Epoch 6/50
589/589 - 22s - loss: 2.8146 - accuracy100: 0.5453 - val_loss: 3.3071 - val_accuracy100: 0.5046 - 22s/epoch - 37ms/step
Epoch 7/50
589/589 - 22s - loss: 2.7907 - accuracy100: 0.5487 - val_loss: 3.3007 - val_accuracy100: 0.5032 - 22s/epoch - 38ms/step
Epoch 8/50
589/589 - 22s - loss: 2.7663 - accuracy100: 0.5541 - val_loss: 3.3217 - val_accuracy100: 0.5006 - 22s/epoch - 37ms/step
Epoch 9/50
589/589 - 22s - loss: 2.7466 - accuracy100: 0.5571 - val_loss: 3.3263 - val_accuracy100: 0.5015 - 22s/epoch - 37ms/step
Epoch 10/50
589/589 - 22s - loss: 2.7293 - accuracy100: 0.5612 - val_loss: 3.3001 - val_accuracy100: 0.5016 - 22s/epoch - 37ms/step
Epoch 11/50
589/589 - 22s - loss: 2.7133 - accuracy100: 0.5655 - val_loss: 3.2712 - val_accuracy100: 0.4959 - 22s/epoch - 38ms/step
Epoch 12/50
589/589 - 22s - loss: 2.7001 - accuracy100: 0.5689 - val_loss: 3.3200 - val_accuracy100: 0.4980 - 22s/epoch - 38ms/step
Epoch 13/50
589/589 - 22s - loss: 2.6849 - accuracy100: 0.5717 - val_loss: 3.3297 - val_accuracy100: 0.4848 - 22s/epoch - 37ms/step
Epoch 14/50
589/589 - 22s - loss: 2.6717 - accuracy100: 0.5737 - val_loss: 3.3444 - val_accuracy100: 0.4832 - 22s/epoch - 37ms/step
Epoch 15/50
589/589 - 22s - loss: 2.6561 - accuracy100: 0.5779 - val_loss: 3.3336 - val_accuracy100: 0.4943 - 22s/epoch - 37ms/step
Epoch 16/50
589/589 - 22s - loss: 2.6380 - accuracy100: 0.5813 - val_loss: 3.3673 - val_accuracy100: 0.4892 - 22s/epoch - 37ms/step
Epoch 17/50
589/589 - 22s - loss: 2.6181 - accuracy100: 0.5853 - val_loss: 3.3808 - val_accuracy100: 0.4865 - 22s/epoch - 37ms/step
Epoch 18/50
589/589 - 22s - loss: 2.6075 - accuracy100: 0.5857 - val_loss: 3.4254 - val_accuracy100: 0.4823 - 22s/epoch - 37ms/step
Epoch 19/50
589/589 - 22s - loss: 2.5906 - accuracy100: 0.5877 - val_loss: 3.4813 - val_accuracy100: 0.4850 - 22s/epoch - 38ms/step
Epoch 20/50
589/589 - 22s - loss: 2.5744 - accuracy100: 0.5912 - val_loss: 3.4975 - val_accuracy100: 0.4757 - 22s/epoch - 37ms/step
Epoch 21/50
589/589 - 22s - loss: 2.5621 - accuracy100: 0.5939 - val_loss: 3.4837 - val_accuracy100: 0.4641 - 22s/epoch - 37ms/step
testing model: results/QRTEA/W5/deepVOL_L3/h100
Evaluating performance on  test set...
2185/2185 - 34s - 34s/epoch - 16ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0665193
{'0': {'precision': 0.46639324228460377, 'recall': 0.42269706629207415, 'f1-score': 0.4434713849659476, 'support': 185090}, '1': {'precision': 0.45350803936699896, 'recall': 0.445030550109441, 'f1-score': 0.44922930323148125, 'support': 192798}, '2': {'precision': 0.41730321413209537, 'recall': 0.4655081128183633, 'f1-score': 0.4400895769081367, 'support': 181318}, 'accuracy': 0.44427813721598125, 'macro avg': {'precision': 0.44573483192789937, 'recall': 0.4444119097399595, 'f1-score': 0.44426342170185523, 'support': 559206}, 'weighted avg': {'precision': 0.4460337556613113, 'recall': 0.44427813721598125, 'f1-score': 0.4443600243087519, 'support': 559206}}
[[78237 53113 53740]
 [42879 85801 64118]
 [46633 50280 84405]]
Evaluating performance on  train set...
589/589 - 11s - 11s/epoch - 18ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 0.9238113
{'0': {'precision': 0.5184007555485597, 'recall': 0.4451743714517437, 'f1-score': 0.4790051632608537, 'support': 36990}, '1': {'precision': 0.6407109768894121, 'recall': 0.6594360372463024, 'f1-score': 0.649938665437812, 'support': 75927}, '2': {'precision': 0.45316331535066207, 'recall': 0.48922539312754804, 'f1-score': 0.47050436642309745, 'support': 37774}, 'accuracy': 0.5641743700685509, 'macro avg': {'precision': 0.5374250159295446, 'recall': 0.5312786006085314, 'f1-score': 0.5331493983739211, 'support': 150691}, 'weighted avg': {'precision': 0.563674654518714, 'recall': 0.5641743700685509, 'f1-score': 0.5630006170042126, 'support': 150691}}
[[16467 13877  6646]
 [10204 50069 15654]
 [ 5094 14200 18480]]
Evaluating performance on  val set...
222/222 - 4s - 4s/epoch - 19ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.006786
{'0': {'precision': 0.4657075285770595, 'recall': 0.4373766041461007, 'f1-score': 0.451097677378301, 'support': 16208}, '1': {'precision': 0.5319586059960432, 'recall': 0.5910551234359148, 'f1-score': 0.5599519423307969, 'support': 23656}, '2': {'precision': 0.4638753136970017, 'recall': 0.4184938036224976, 'f1-score': 0.4400175405625509, 'support': 16784}, 'accuracy': 0.495957491879678, 'macro avg': {'precision': 0.48718048275670145, 'recall': 0.48230851040150435, 'f1-score': 0.4836890534238829, 'support': 56648}, 'weighted avg': {'precision': 0.49283087967288963, 'recall': 0.495957491879678, 'f1-score': 0.49327193728863655, 'support': 56648}}
[[ 7089  6003  3116]
 [ 4672 13982  5002]
 [ 3461  6299  7024]]
training model: results/QRTEA/W5/deepVOL_L3/h200
Epoch 1/50
589/589 - 26s - loss: 3.2763 - accuracy200: 0.3932 - val_loss: 3.3314 - val_accuracy200: 0.3786 - 26s/epoch - 43ms/step
Epoch 2/50
589/589 - 22s - loss: 3.1940 - accuracy200: 0.4209 - val_loss: 3.3322 - val_accuracy200: 0.3974 - 22s/epoch - 38ms/step
Epoch 3/50
589/589 - 22s - loss: 3.1442 - accuracy200: 0.4456 - val_loss: 3.2631 - val_accuracy200: 0.4215 - 22s/epoch - 38ms/step
Epoch 4/50
589/589 - 22s - loss: 3.0870 - accuracy200: 0.4672 - val_loss: 3.2461 - val_accuracy200: 0.4274 - 22s/epoch - 38ms/step
Epoch 5/50
589/589 - 22s - loss: 3.0582 - accuracy200: 0.4762 - val_loss: 3.2363 - val_accuracy200: 0.4259 - 22s/epoch - 37ms/step
Epoch 6/50
589/589 - 22s - loss: 3.0357 - accuracy200: 0.4831 - val_loss: 3.2381 - val_accuracy200: 0.4268 - 22s/epoch - 37ms/step
Epoch 7/50
589/589 - 22s - loss: 3.0206 - accuracy200: 0.4880 - val_loss: 3.2627 - val_accuracy200: 0.4253 - 22s/epoch - 38ms/step
Epoch 8/50
589/589 - 23s - loss: 2.9979 - accuracy200: 0.4927 - val_loss: 3.2560 - val_accuracy200: 0.4233 - 23s/epoch - 38ms/step
Epoch 9/50
589/589 - 22s - loss: 2.9692 - accuracy200: 0.5002 - val_loss: 3.2821 - val_accuracy200: 0.4156 - 22s/epoch - 38ms/step
Epoch 10/50
589/589 - 22s - loss: 2.9501 - accuracy200: 0.5062 - val_loss: 3.2530 - val_accuracy200: 0.4201 - 22s/epoch - 38ms/step
Epoch 11/50
589/589 - 22s - loss: 2.9264 - accuracy200: 0.5134 - val_loss: 3.2938 - val_accuracy200: 0.4165 - 22s/epoch - 38ms/step
Epoch 12/50
589/589 - 22s - loss: 2.9034 - accuracy200: 0.5186 - val_loss: 3.2887 - val_accuracy200: 0.4204 - 22s/epoch - 38ms/step
Epoch 13/50
589/589 - 22s - loss: 2.8772 - accuracy200: 0.5261 - val_loss: 3.3346 - val_accuracy200: 0.4196 - 22s/epoch - 38ms/step
Epoch 14/50
589/589 - 22s - loss: 2.8599 - accuracy200: 0.5301 - val_loss: 3.3504 - val_accuracy200: 0.4206 - 22s/epoch - 38ms/step
Epoch 15/50
589/589 - 22s - loss: 2.8331 - accuracy200: 0.5351 - val_loss: 3.3513 - val_accuracy200: 0.4174 - 22s/epoch - 38ms/step
testing model: results/QRTEA/W5/deepVOL_L3/h200
Evaluating performance on  test set...
2185/2185 - 34s - 34s/epoch - 15ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0743814
{'0': {'precision': 0.4848763753503744, 'recall': 0.31714758718822256, 'f1-score': 0.3834732619215021, 'support': 219267}, '1': {'precision': 0.3001178297895131, 'recall': 0.0904052789519538, 'f1-score': 0.1389532937398485, 'support': 123964}, '2': {'precision': 0.4135702319485475, 'recall': 0.7246857275147587, 'f1-score': 0.5266099279803372, 'support': 215975}, 'accuracy': 0.4242819283054903, 'macro avg': {'precision': 0.3995214790294783, 'recall': 0.377412864551645, 'f1-score': 0.34967882788056254, 'support': 559206}, 'weighted avg': {'precision': 0.4163796985208766, 'recall': 0.4242819283054903, 'f1-score': 0.38455026774115786, 'support': 559206}}
[[ 69540  14149 135578]
 [ 26403  11207  86354]
 [ 47475  11986 156514]]
Evaluating performance on  train set...
589/589 - 11s - 11s/epoch - 18ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0392073
{'0': {'precision': 0.4704872573616797, 'recall': 0.3833821124214513, 'f1-score': 0.42249178850509295, 'support': 46468}, '1': {'precision': 0.5333656291631343, 'recall': 0.3197966778614868, 'f1-score': 0.3998501923666201, 'support': 55085}, '2': {'precision': 0.4051229354119151, 'recall': 0.6579022345231796, 'f1-score': 0.5014580877334491, 'support': 49138}, 'accuracy': 0.4496552547929206, 'macro avg': {'precision': 0.469658607312243, 'recall': 0.45369367493537255, 'f1-score': 0.4412666895350541, 'support': 150691}, 'weighted avg': {'precision': 0.4721581140068383, 'recall': 0.4496552547929206, 'f1-score': 0.43996485383875716, 'support': 150691}}
[[17815  7289 21364]
 [11363 17616 26106]
 [ 8687  8123 32328]]
Evaluating performance on  val set...
222/222 - 4s - 4s/epoch - 19ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0697919
{'0': {'precision': 0.44763640935378424, 'recall': 0.3627056486527785, 'f1-score': 0.40072029487071265, 'support': 19633}, '1': {'precision': 0.4086751254057244, 'recall': 0.25137636880634034, 'f1-score': 0.31128258915193285, 'support': 16529}, '2': {'precision': 0.4194877833382396, 'recall': 0.6260372937615933, 'f1-score': 0.5023600148847411, 'support': 20486}, 'accuracy': 0.42545191357152945, 'macro avg': {'precision': 0.42526643936591607, 'recall': 0.41337310374023745, 'f1-score': 0.4047876329691289, 'support': 56648}, 'weighted avg': {'precision': 0.4260885380267836, 'recall': 0.42545191357152945, 'f1-score': 0.4113804323227265, 'support': 56648}}
[[ 7121  2891  9621]
 [ 4247  4155  8127]
 [ 4540  3121 12825]]
training model: results/QRTEA/W5/deepVOL_L3/h300
Epoch 1/50
589/589 - 25s - loss: 3.2970 - accuracy300: 0.3778 - val_loss: 3.2716 - val_accuracy300: 0.3949 - 25s/epoch - 43ms/step
Epoch 2/50
589/589 - 22s - loss: 3.2470 - accuracy300: 0.3996 - val_loss: 3.2427 - val_accuracy300: 0.4103 - 22s/epoch - 38ms/step
Epoch 3/50
589/589 - 22s - loss: 3.2028 - accuracy300: 0.4191 - val_loss: 3.2278 - val_accuracy300: 0.4155 - 22s/epoch - 38ms/step
Epoch 4/50
589/589 - 23s - loss: 3.1649 - accuracy300: 0.4356 - val_loss: 3.2210 - val_accuracy300: 0.4189 - 23s/epoch - 39ms/step
Epoch 5/50
589/589 - 22s - loss: 3.1368 - accuracy300: 0.4486 - val_loss: 3.2389 - val_accuracy300: 0.4167 - 22s/epoch - 38ms/step
Epoch 6/50
589/589 - 22s - loss: 3.1171 - accuracy300: 0.4536 - val_loss: 3.2559 - val_accuracy300: 0.4155 - 22s/epoch - 38ms/step
Epoch 7/50
589/589 - 23s - loss: 3.0930 - accuracy300: 0.4633 - val_loss: 3.2542 - val_accuracy300: 0.4166 - 23s/epoch - 38ms/step
Epoch 8/50
589/589 - 23s - loss: 3.0726 - accuracy300: 0.4717 - val_loss: 3.2476 - val_accuracy300: 0.4145 - 23s/epoch - 38ms/step
Epoch 9/50
589/589 - 22s - loss: 3.0523 - accuracy300: 0.4783 - val_loss: 3.2695 - val_accuracy300: 0.4049 - 22s/epoch - 38ms/step
Epoch 10/50
589/589 - 23s - loss: 3.0404 - accuracy300: 0.4822 - val_loss: 3.2609 - val_accuracy300: 0.4088 - 23s/epoch - 38ms/step
Epoch 11/50
589/589 - 23s - loss: 3.0149 - accuracy300: 0.4916 - val_loss: 3.2856 - val_accuracy300: 0.4041 - 23s/epoch - 38ms/step
Epoch 12/50
589/589 - 22s - loss: 2.9885 - accuracy300: 0.5010 - val_loss: 3.3091 - val_accuracy300: 0.3990 - 22s/epoch - 38ms/step
Epoch 13/50
589/589 - 22s - loss: 2.9610 - accuracy300: 0.5086 - val_loss: 3.3396 - val_accuracy300: 0.4007 - 22s/epoch - 38ms/step
Epoch 14/50
589/589 - 23s - loss: 2.9285 - accuracy300: 0.5176 - val_loss: 3.3589 - val_accuracy300: 0.3989 - 23s/epoch - 38ms/step
testing model: results/QRTEA/W5/deepVOL_L3/h300
Evaluating performance on  test set...
2185/2185 - 34s - 34s/epoch - 16ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0654056
{'0': {'precision': 0.4503047407887921, 'recall': 0.4176499640804598, 'f1-score': 0.4333630724290629, 'support': 222720}, '1': {'precision': 0.23602526658968961, 'recall': 0.02986857825567503, 'f1-score': 0.0530267193627638, 'support': 116343}, '2': {'precision': 0.41372656948217595, 'recall': 0.6350599383128239, 'f1-score': 0.5010384243903401, 'support': 220143}, 'accuracy': 0.42255984377850025, 'macro avg': {'precision': 0.3666855256202192, 'recall': 0.3608594935496529, 'f1-score': 0.3291427387273889, 'support': 559206}, 'weighted avg': {'precision': 0.3913240695644158, 'recall': 0.42255984377850025, 'f1-score': 0.3808757648572897, 'support': 559206}}
[[ 93019   5075 124626]
 [ 39384   3475  73484]
 [ 74166   6173 139804]]
Evaluating performance on  train set...
589/589 - 10s - 10s/epoch - 16ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0609157
{'0': {'precision': 0.42956726591615657, 'recall': 0.4556459045941462, 'f1-score': 0.4422224430971076, 'support': 48823}, '1': {'precision': 0.5052390757263784, 'recall': 0.22461807603897557, 'f1-score': 0.3109809333370885, 'support': 49159}, '2': {'precision': 0.4094277667458371, 'recall': 0.5984936158910243, 'f1-score': 0.4862282094360271, 'support': 52709}, 'accuracy': 0.43024467287362883, 'macro avg': {'precision': 0.44807803612945735, 'recall': 0.4262525321747154, 'f1-score': 0.4131438619567411, 'support': 150691}, 'weighted avg': {'precision': 0.4472087815786203, 'recall': 0.43024467287362883, 'f1-score': 0.4148007560664643, 'support': 150691}}
[[22246  4180 22397]
 [15011 11042 23106]
 [14530  6633 31546]]
Evaluating performance on  val set...
222/222 - 4s - 4s/epoch - 16ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0730909
{'0': {'precision': 0.4223155929038282, 'recall': 0.44904442789774135, 'f1-score': 0.435270058943823, 'support': 20145}, '1': {'precision': 0.3725698126546483, 'recall': 0.13934426229508196, 'f1-score': 0.20282882709516023, 'support': 15128}, '2': {'precision': 0.42458572877916806, 'recall': 0.5873684210526315, 'f1-score': 0.4928844832662675, 'support': 21375}, 'accuracy': 0.41853198700748484, 'macro avg': {'precision': 0.4064903781125482, 'recall': 0.39191903708181824, 'f1-score': 0.37699445643508356, 'support': 56648}, 'weighted avg': {'precision': 0.40988743993683546, 'recall': 0.41853198700748484, 'f1-score': 0.3949356669879849, 'support': 56648}}
[[ 9046  1622  9477]
 [ 5482  2108  7538]
 [ 6892  1928 12555]]
training model: results/QRTEA/W5/deepVOL_L3/h500
Epoch 1/50
589/589 - 24s - loss: 3.3107 - accuracy500: 0.3708 - val_loss: 3.3432 - val_accuracy500: 0.3585 - 24s/epoch - 41ms/step
Epoch 2/50
589/589 - 22s - loss: 3.2793 - accuracy500: 0.3783 - val_loss: 3.3080 - val_accuracy500: 0.3677 - 22s/epoch - 37ms/step
Epoch 3/50
589/589 - 22s - loss: 3.2762 - accuracy500: 0.3799 - val_loss: 3.3148 - val_accuracy500: 0.3715 - 22s/epoch - 37ms/step
Epoch 4/50
589/589 - 22s - loss: 3.2550 - accuracy500: 0.3931 - val_loss: 3.3060 - val_accuracy500: 0.3758 - 22s/epoch - 38ms/step
Epoch 5/50
589/589 - 22s - loss: 3.2254 - accuracy500: 0.4109 - val_loss: 3.3171 - val_accuracy500: 0.3693 - 22s/epoch - 38ms/step
Epoch 6/50
589/589 - 22s - loss: 3.2110 - accuracy500: 0.4190 - val_loss: 3.3186 - val_accuracy500: 0.3767 - 22s/epoch - 38ms/step
Epoch 7/50
589/589 - 22s - loss: 3.1920 - accuracy500: 0.4278 - val_loss: 3.3385 - val_accuracy500: 0.3695 - 22s/epoch - 38ms/step
Epoch 8/50
589/589 - 21s - loss: 3.1727 - accuracy500: 0.4358 - val_loss: 3.3562 - val_accuracy500: 0.3662 - 21s/epoch - 36ms/step
Epoch 9/50
589/589 - 22s - loss: 3.1592 - accuracy500: 0.4428 - val_loss: 3.3500 - val_accuracy500: 0.3672 - 22s/epoch - 38ms/step
Epoch 10/50
589/589 - 22s - loss: 3.1365 - accuracy500: 0.4522 - val_loss: 3.3886 - val_accuracy500: 0.3663 - 22s/epoch - 38ms/step
Epoch 11/50
589/589 - 22s - loss: 3.0971 - accuracy500: 0.4659 - val_loss: 3.4108 - val_accuracy500: 0.3697 - 22s/epoch - 38ms/step
Epoch 12/50
589/589 - 22s - loss: 3.0689 - accuracy500: 0.4771 - val_loss: 3.5077 - val_accuracy500: 0.3653 - 22s/epoch - 37ms/step
Epoch 13/50
589/589 - 22s - loss: 3.0458 - accuracy500: 0.4867 - val_loss: 3.5150 - val_accuracy500: 0.3633 - 22s/epoch - 38ms/step
Epoch 14/50
589/589 - 22s - loss: 3.0133 - accuracy500: 0.4961 - val_loss: 3.5655 - val_accuracy500: 0.3643 - 22s/epoch - 37ms/step
testing model: results/QRTEA/W5/deepVOL_L3/h500
Evaluating performance on  test set...
2185/2185 - 34s - 34s/epoch - 16ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0977473
{'0': {'precision': 0.3941338524225078, 'recall': 0.22369529801696533, 'f1-score': 0.2854054054054054, 'support': 213612}, '1': {'precision': 0.2738036180838046, 'recall': 0.06050396831196925, 'f1-score': 0.09910756504719549, 'support': 136834}, '2': {'precision': 0.3777809389033456, 'recall': 0.7378472887526346, 'f1-score': 0.4997088359765188, 'support': 208760}, 'accuracy': 0.37570412334631603, 'macro avg': {'precision': 0.34857280313655264, 'recall': 0.3406821850271897, 'f1-score': 0.2947406021430399, 'support': 559206}, 'weighted avg': {'precision': 0.3585850537476681, 'recall': 0.37570412334631603, 'f1-score': 0.31982224907026297, 'support': 559206}}
[[ 47784  12109 153719]
 [ 28576   8279  99979]
 [ 44878   9849 154033]]
Evaluating performance on  train set...
589/589 - 11s - 11s/epoch - 18ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.08587
{'0': {'precision': 0.42155880585053096, 'recall': 0.2145100118265976, 'f1-score': 0.2843358514534373, 'support': 49042}, '1': {'precision': 0.38427167113494193, 'recall': 0.1356752208666386, 'f1-score': 0.20054411193159735, 'support': 47540}, '2': {'precision': 0.3829611476718892, 'recall': 0.7711101665157367, 'f1-score': 0.5117625413958052, 'support': 54109}, 'accuracy': 0.3894990410840727, 'macro avg': {'precision': 0.3962638748857874, 'recall': 0.37376513306965764, 'f1-score': 0.33221416826028, 'support': 150691}, 'weighted avg': {'precision': 0.39593610064074924, 'recall': 0.3894990410840727, 'f1-score': 0.3395639106555351, 'support': 150691}}
[[10520  5133 33389]
 [ 7252  6450 33838]
 [ 7183  5202 41724]]
Evaluating performance on  val set...
222/222 - 4s - 4s/epoch - 18ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.09903
{'0': {'precision': 0.39849056603773586, 'recall': 0.21105226341560906, 'f1-score': 0.27595217874175215, 'support': 20014}, '1': {'precision': 0.30601973021944834, 'recall': 0.09504752376188094, 'f1-score': 0.14504508802900903, 'support': 15992}, '2': {'precision': 0.3760862685913196, 'recall': 0.7484739850789652, 'f1-score': 0.5006237545161448, 'support': 20642}, 'accuracy': 0.37413500917949444, 'macro avg': {'precision': 0.36019885494950127, 'recall': 0.35152459075215176, 'f1-score': 0.30720700709563536, 'support': 56648}, 'weighted avg': {'precision': 0.36422169309791486, 'recall': 0.37413500917949444, 'f1-score': 0.3208646994389846, 'support': 56648}}
[[ 4224  1815 13975]
 [ 2816  1520 11656]
 [ 3560  1632 15450]]
training model: results/QRTEA/W5/deepVOL_L3/h1000
Epoch 1/50
589/589 - 24s - loss: 3.2643 - accuracy1000: 0.4100 - val_loss: 3.5049 - val_accuracy1000: 0.3929 - 24s/epoch - 42ms/step
Epoch 2/50
589/589 - 22s - loss: 3.2556 - accuracy1000: 0.4038 - val_loss: 3.5719 - val_accuracy1000: 0.3931 - 22s/epoch - 38ms/step
Epoch 3/50
589/589 - 22s - loss: 3.2493 - accuracy1000: 0.4066 - val_loss: 3.4309 - val_accuracy1000: 0.3926 - 22s/epoch - 38ms/step
Epoch 4/50
589/589 - 22s - loss: 3.2468 - accuracy1000: 0.4064 - val_loss: 3.4304 - val_accuracy1000: 0.3922 - 22s/epoch - 38ms/step
Epoch 5/50
589/589 - 22s - loss: 3.2421 - accuracy1000: 0.4075 - val_loss: 3.4184 - val_accuracy1000: 0.3931 - 22s/epoch - 37ms/step
Epoch 6/50
589/589 - 22s - loss: 3.2331 - accuracy1000: 0.4156 - val_loss: 3.3721 - val_accuracy1000: 0.3922 - 22s/epoch - 38ms/step
Epoch 7/50
589/589 - 22s - loss: 3.2219 - accuracy1000: 0.4158 - val_loss: 3.4101 - val_accuracy1000: 0.3811 - 22s/epoch - 37ms/step
Epoch 8/50
589/589 - 22s - loss: 3.2121 - accuracy1000: 0.4209 - val_loss: 3.4689 - val_accuracy1000: 0.3911 - 22s/epoch - 38ms/step
Epoch 9/50
589/589 - 22s - loss: 3.2130 - accuracy1000: 0.4171 - val_loss: 3.3500 - val_accuracy1000: 0.3804 - 22s/epoch - 37ms/step
Epoch 10/50
589/589 - 22s - loss: 3.1932 - accuracy1000: 0.4251 - val_loss: 3.3826 - val_accuracy1000: 0.3764 - 22s/epoch - 38ms/step
Epoch 11/50
589/589 - 22s - loss: 3.1758 - accuracy1000: 0.4367 - val_loss: 3.3751 - val_accuracy1000: 0.3572 - 22s/epoch - 37ms/step
Epoch 12/50
589/589 - 22s - loss: 3.1473 - accuracy1000: 0.4446 - val_loss: 3.4075 - val_accuracy1000: 0.3686 - 22s/epoch - 37ms/step
Epoch 13/50
589/589 - 22s - loss: 3.1326 - accuracy1000: 0.4545 - val_loss: 3.4165 - val_accuracy1000: 0.3644 - 22s/epoch - 38ms/step
Epoch 14/50
589/589 - 22s - loss: 3.1065 - accuracy1000: 0.4664 - val_loss: 3.4248 - val_accuracy1000: 0.3743 - 22s/epoch - 37ms/step
Epoch 15/50
589/589 - 22s - loss: 3.0806 - accuracy1000: 0.4750 - val_loss: 3.4603 - val_accuracy1000: 0.3785 - 22s/epoch - 38ms/step
Epoch 16/50
589/589 - 22s - loss: 3.0554 - accuracy1000: 0.4845 - val_loss: 3.5238 - val_accuracy1000: 0.3760 - 22s/epoch - 38ms/step
Epoch 17/50
589/589 - 22s - loss: 3.0407 - accuracy1000: 0.4893 - val_loss: 3.5612 - val_accuracy1000: 0.3705 - 22s/epoch - 38ms/step
Epoch 18/50
589/589 - 22s - loss: 3.0186 - accuracy1000: 0.4935 - val_loss: 3.6013 - val_accuracy1000: 0.3676 - 22s/epoch - 37ms/step
Epoch 19/50
589/589 - 22s - loss: 3.0182 - accuracy1000: 0.4987 - val_loss: 3.5766 - val_accuracy1000: 0.3561 - 22s/epoch - 37ms/step
testing model: results/QRTEA/W5/deepVOL_L3/h1000
Evaluating performance on  test set...
2185/2185 - 35s - 35s/epoch - 16ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1318544
{'0': {'precision': 0.36845466155810985, 'recall': 0.015480042281709941, 'f1-score': 0.029711790482958203, 'support': 186369}, '1': {'precision': 0.3316373886344189, 'recall': 0.8896978993934221, 'f1-score': 0.48317131408658104, 'support': 185137}, '2': {'precision': 0.31650244054039234, 'recall': 0.09223761321257326, 'f1-score': 0.1428459453550109, 'support': 187700}, 'accuracy': 0.33067241767792194, 'macro avg': {'precision': 0.33886483024430697, 'recall': 0.33247185162923515, 'f1-score': 0.21857634997485006, 'support': 559206}, 'weighted avg': {'precision': 0.3388275271169576, 'recall': 0.33067241767792194, 'f1-score': 0.21781316402131118, 'support': 559206}}
[[  2885 164548  18936]
 [  1969 164716  18452]
 [  2976 167411  17313]]
Evaluating performance on  train set...
589/589 - 10s - 10s/epoch - 16ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1195968
{'0': {'precision': 0.3450777202072539, 'recall': 0.00687902825979177, 'f1-score': 0.01348915399104774, 'support': 48408}, '1': {'precision': 0.3265439016264349, 'recall': 0.8834941511482597, 'f1-score': 0.4768438918404918, 'support': 48813}, '2': {'precision': 0.4288707667912561, 'recall': 0.14163082102113334, 'f1-score': 0.2129400517377123, 'support': 53470}, 'accuracy': 0.3386532706001022, 'macro avg': {'precision': 0.366830796208315, 'recall': 0.34400133347639494, 'f1-score': 0.23442436585641727, 'support': 150691}, 'weighted avg': {'precision': 0.36880656210531737, 'recall': 0.3386532706001022, 'f1-score': 0.23435419783015607, 'support': 150691}}
[[  333 43389  4686]
 [  288 43126  5399]
 [  344 45553  7573]]
Evaluating performance on  val set...
222/222 - 3s - 3s/epoch - 16ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1119207
{'0': {'precision': 0.2393617021276596, 'recall': 0.005277044854881266, 'f1-score': 0.010326429923699157, 'support': 17055}, '1': {'precision': 0.3925278892901091, 'recall': 0.8736530172413793, 'f1-score': 0.5416811658755898, 'support': 22272}, '2': {'precision': 0.2905536487091479, 'recall': 0.11240690491311126, 'f1-score': 0.16210140704354342, 'support': 17321}, 'accuracy': 0.37944852421974296, 'macro avg': {'precision': 0.3074810800423055, 'recall': 0.3304456556697906, 'f1-score': 0.2380363342809441, 'support': 56648}, 'weighted avg': {'precision': 0.3152339840655927, 'recall': 0.37944852421974296, 'f1-score': 0.26564395318689166, 'support': 56648}}
[[   90 14864  2101]
 [  161 19458  2653]
 [  125 15249  1947]]

============================================

        Job resource usage summary 

                 Memory (GB)    NCPUs
 Requested  :        96            32
 Used       :        16 (peak)  15.49 (ave)

============================================
