This machine has 1 visible gpus.
This machine has 1 physical gpus.
getting alphas...
data/ATVI_orderbooks/ATVI_orderbooks_2019-11-13.csv
data/ATVI_orderbooks/ATVI_orderbooks_2019-11-05.csv
data/ATVI_orderbooks/ATVI_orderbooks_2019-10-23.csv
data/ATVI_orderbooks/ATVI_orderbooks_2019-10-24.csv
data/ATVI_orderbooks/ATVI_orderbooks_2019-11-01.csv
data/ATVI_orderbooks/ATVI_orderbooks_2019-10-28.csv
data/ATVI_orderbooks/ATVI_orderbooks_2019-10-30.csv
data/ATVI_orderbooks/ATVI_orderbooks_2019-10-25.csv
data/ATVI_orderbooks/ATVI_orderbooks_2019-11-15.csv
data/ATVI_orderbooks/ATVI_orderbooks_2019-10-29.csv
data/ATVI_orderbooks/ATVI_orderbooks_2019-11-11.csv
data/ATVI_orderbooks/ATVI_orderbooks_2019-10-31.csv
data/ATVI_orderbooks/ATVI_orderbooks_2019-10-22.csv
data/ATVI_orderbooks/ATVI_orderbooks_2019-11-07.csv
data/ATVI_orderbooks/ATVI_orderbooks_2019-11-06.csv
training model: results/ATVI/W8/deepLOB_L1/h10
Epoch 1/50
1691/1691 - 37s - loss: 3.0082 - accuracy10: 0.4579 - val_loss: 3.2570 - val_accuracy10: 0.4216 - 37s/epoch - 22ms/step
Epoch 2/50
1691/1691 - 27s - loss: 2.8909 - accuracy10: 0.4912 - val_loss: 3.6809 - val_accuracy10: 0.4861 - 27s/epoch - 16ms/step
Epoch 3/50
1691/1691 - 26s - loss: 2.8282 - accuracy10: 0.5184 - val_loss: 3.6760 - val_accuracy10: 0.4929 - 26s/epoch - 16ms/step
Epoch 4/50
1691/1691 - 27s - loss: 2.7903 - accuracy10: 0.5318 - val_loss: 3.7945 - val_accuracy10: 0.5033 - 27s/epoch - 16ms/step
Epoch 5/50
1691/1691 - 27s - loss: 2.7634 - accuracy10: 0.5401 - val_loss: 3.6625 - val_accuracy10: 0.5051 - 27s/epoch - 16ms/step
Epoch 6/50
1691/1691 - 27s - loss: 2.7444 - accuracy10: 0.5455 - val_loss: 3.6511 - val_accuracy10: 0.5093 - 27s/epoch - 16ms/step
Epoch 7/50
1691/1691 - 26s - loss: 2.7294 - accuracy10: 0.5498 - val_loss: 3.6871 - val_accuracy10: 0.5100 - 26s/epoch - 16ms/step
Epoch 8/50
1691/1691 - 26s - loss: 2.7190 - accuracy10: 0.5506 - val_loss: 3.5753 - val_accuracy10: 0.5165 - 26s/epoch - 15ms/step
Epoch 9/50
1691/1691 - 26s - loss: 2.7085 - accuracy10: 0.5544 - val_loss: 3.5301 - val_accuracy10: 0.5090 - 26s/epoch - 15ms/step
Epoch 10/50
1691/1691 - 26s - loss: 2.6988 - accuracy10: 0.5563 - val_loss: 3.5211 - val_accuracy10: 0.5105 - 26s/epoch - 16ms/step
Epoch 11/50
1691/1691 - 26s - loss: 2.6917 - accuracy10: 0.5575 - val_loss: 3.5609 - val_accuracy10: 0.5136 - 26s/epoch - 15ms/step
testing model: results/ATVI/W8/deepLOB_L1/h10
Evaluating performance on  test set...
4960/4960 - 34s - 34s/epoch - 7ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.9937317
{'0': {'precision': 0.3053000710583682, 'recall': 0.609684725312168, 'f1-score': 0.4068631319325831, 'support': 249465}, '1': {'precision': 0.7254420377942314, 'recall': 0.33902023035935386, 'f1-score': 0.4620915820566675, 'support': 774529}, '2': {'precision': 0.321420722863324, 'recall': 0.5357814446081584, 'f1-score': 0.4017984689205523, 'support': 245686}, 'accuracy': 0.43027376976876064, 'macro avg': {'precision': 0.45072094390530787, 'recall': 0.4948288000932268, 'f1-score': 0.4235843943032676, 'support': 1269680}, 'weighted avg': {'precision': 0.5647140618381817, 'recall': 0.43027376976876064, 'f1-score': 0.43957351521764954, 'support': 1269680}}
[[152095  44653  52717]
 [286761 262581 225187]
 [ 59326  54726 131634]]
Evaluating performance on  train set...
1691/1691 - 11s - 11s/epoch - 7ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 1.0214726
{'0': {'precision': 0.3390796036205674, 'recall': 0.5791696776623139, 'f1-score': 0.42773706167549885, 'support': 98251}, '1': {'precision': 0.6902718598091581, 'recall': 0.2899127892322428, 'f1-score': 0.4083284519942489, 'support': 238044}, '2': {'precision': 0.3449199318981866, 'recall': 0.5896280645061057, 'f1-score': 0.4352360127830701, 'support': 96549}, 'accuracy': 0.42242470728484166, 'macro avg': {'precision': 0.458090465109304, 'recall': 0.48623684380022086, 'f1-score': 0.4237671754842726, 'support': 432844}, 'weighted avg': {'precision': 0.5335216827230448, 'recall': 0.42242470728484166, 'f1-score': 0.41873592765844286, 'support': 432844}}
[[56904 14626 26721]
 [87634 69012 81398]
 [23281 16340 56928]]
Evaluating performance on  val set...
591/591 - 4s - 4s/epoch - 7ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 1.038404
{'0': {'precision': 0.3402630391550661, 'recall': 0.5595064713802863, 'f1-score': 0.4231736464719942, 'support': 36391}, '1': {'precision': 0.6493356603986038, 'recall': 0.2971594202898551, 'f1-score': 0.4077278632599493, 'support': 77625}, '2': {'precision': 0.3631995122913342, 'recall': 0.5457190581389083, 'f1-score': 0.4361334496011368, 'support': 37118}, 'accuracy': 0.42137440946444876, 'macro avg': {'precision': 0.45093273728166805, 'recall': 0.4674616499363499, 'f1-score': 0.4223449864443601, 'support': 151134}, 'weighted avg': {'precision': 0.5046411290216852, 'recall': 0.42137440946444876, 'f1-score': 0.41842331266697697, 'support': 151134}}
[[20361  6356  9674]
 [28717 23067 25841]
 [10761  6101 20256]]
training model: results/ATVI/W8/deepLOB_L1/h20
Epoch 1/50
1691/1691 - 28s - loss: 3.0701 - accuracy20: 0.4580 - val_loss: 3.4315 - val_accuracy20: 0.3975 - 28s/epoch - 17ms/step
Epoch 2/50
1691/1691 - 26s - loss: 2.9620 - accuracy20: 0.4961 - val_loss: 3.8128 - val_accuracy20: 0.4218 - 26s/epoch - 16ms/step
Epoch 3/50
1691/1691 - 26s - loss: 2.8929 - accuracy20: 0.5210 - val_loss: 3.8710 - val_accuracy20: 0.4271 - 26s/epoch - 15ms/step
Epoch 4/50
1691/1691 - 26s - loss: 2.8544 - accuracy20: 0.5335 - val_loss: 3.9309 - val_accuracy20: 0.4272 - 26s/epoch - 15ms/step
Epoch 5/50
1691/1691 - 26s - loss: 2.8310 - accuracy20: 0.5379 - val_loss: 3.8479 - val_accuracy20: 0.4354 - 26s/epoch - 15ms/step
Epoch 6/50
1691/1691 - 26s - loss: 2.8133 - accuracy20: 0.5419 - val_loss: 3.8296 - val_accuracy20: 0.4358 - 26s/epoch - 15ms/step
Epoch 7/50
1691/1691 - 27s - loss: 2.8018 - accuracy20: 0.5446 - val_loss: 3.8330 - val_accuracy20: 0.4352 - 27s/epoch - 16ms/step
Epoch 8/50
1691/1691 - 27s - loss: 2.7902 - accuracy20: 0.5478 - val_loss: 3.8769 - val_accuracy20: 0.4345 - 27s/epoch - 16ms/step
Epoch 9/50
1691/1691 - 26s - loss: 2.7811 - accuracy20: 0.5499 - val_loss: 3.7817 - val_accuracy20: 0.4386 - 26s/epoch - 15ms/step
Epoch 10/50
1691/1691 - 26s - loss: 2.7717 - accuracy20: 0.5516 - val_loss: 3.8013 - val_accuracy20: 0.4395 - 26s/epoch - 15ms/step
Epoch 11/50
1691/1691 - 26s - loss: 2.7644 - accuracy20: 0.5529 - val_loss: 3.7105 - val_accuracy20: 0.4452 - 26s/epoch - 15ms/step
testing model: results/ATVI/W8/deepLOB_L1/h20
Evaluating performance on  test set...
4960/4960 - 34s - 34s/epoch - 7ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 1.0217242
{'0': {'precision': 0.3741563025158638, 'recall': 0.3887365870103106, 'f1-score': 0.3813071167533118, 'support': 314434}, '1': {'precision': 0.5299164605692729, 'recall': 0.4260347222761174, 'f1-score': 0.4723312574104253, 'support': 644255}, '2': {'precision': 0.3668153606535007, 'recall': 0.501329620471332, 'f1-score': 0.42365137053768553, 'support': 310991}, 'accuracy': 0.435240375527692, 'macro avg': {'precision': 0.4236293745795458, 'recall': 0.4387003099192533, 'f1-score': 0.42576324823380757, 'support': 1269680}, 'weighted avg': {'precision': 0.4513933179654108, 'recall': 0.435240375527692, 'f1-score': 0.43786580836671424, 'support': 1269680}}
[[122232 128093  64109]
 [164764 274475 205016]
 [ 39691 115391 155909]]
Evaluating performance on  train set...
1691/1691 - 10s - 10s/epoch - 6ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 1.0379056
{'0': {'precision': 0.4203122552347136, 'recall': 0.3317671109792187, 'f1-score': 0.3708273059806695, 'support': 121311}, '1': {'precision': 0.47572539397123975, 'recall': 0.5129559264591986, 'f1-score': 0.49363966965299566, 'support': 192383}, '2': {'precision': 0.4122715001928268, 'recall': 0.4486026017624843, 'f1-score': 0.42967041800643085, 'support': 119150}, 'accuracy': 0.44446035985251037, 'macro avg': {'precision': 0.4361030497995934, 'recall': 0.43110854640030055, 'f1-score': 0.4313791312133653, 'support': 432844}, 'weighted avg': {'precision': 0.44272792902552116, 'recall': 0.44446035985251037, 'f1-score': 0.4416107008255619, 'support': 432844}}
[[40247 56752 24312]
 [41812 98684 51887]
 [13696 52003 53451]]
Evaluating performance on  val set...
591/591 - 3s - 3s/epoch - 5ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 1.0846621
{'0': {'precision': 0.39651505235602097, 'recall': 0.22047351543132662, 'f1-score': 0.28337986173027174, 'support': 43969}, '1': {'precision': 0.3905634378969578, 'recall': 0.5862648460854811, 'f1-score': 0.4688103683316212, 'support': 61885}, '2': {'precision': 0.4161635890151515, 'recall': 0.3105786219081272, 'f1-score': 0.35570113314447593, 'support': 45280}, 'accuracy': 0.3972501224079294, 'macro avg': {'precision': 0.4010806930893767, 'recall': 0.37243899447497836, 'f1-score': 0.36929712106878965, 'support': 151134}, 'weighted avg': {'precision': 0.3999647729954952, 'recall': 0.3972501224079294, 'f1-score': 0.3809758630976654, 'support': 151134}}
[[ 9694 29023  5252]
 [11127 36281 14477]
 [ 3627 27590 14063]]
training model: results/ATVI/W8/deepLOB_L1/h30
Epoch 1/50
1691/1691 - 29s - loss: 3.1051 - accuracy30: 0.4538 - val_loss: 3.4728 - val_accuracy30: 0.3599 - 29s/epoch - 17ms/step
Epoch 2/50
1691/1691 - 27s - loss: 3.0420 - accuracy30: 0.4766 - val_loss: 3.4531 - val_accuracy30: 0.3817 - 27s/epoch - 16ms/step
Epoch 3/50
1691/1691 - 26s - loss: 2.9725 - accuracy30: 0.5048 - val_loss: 3.6361 - val_accuracy30: 0.3690 - 26s/epoch - 16ms/step
Epoch 4/50
1691/1691 - 27s - loss: 2.9286 - accuracy30: 0.5169 - val_loss: 3.5642 - val_accuracy30: 0.3811 - 27s/epoch - 16ms/step
Epoch 5/50
1691/1691 - 26s - loss: 2.9039 - accuracy30: 0.5227 - val_loss: 3.6163 - val_accuracy30: 0.3793 - 26s/epoch - 16ms/step
Epoch 6/50
1691/1691 - 26s - loss: 2.8871 - accuracy30: 0.5270 - val_loss: 3.6082 - val_accuracy30: 0.3854 - 26s/epoch - 15ms/step
Epoch 7/50
1691/1691 - 26s - loss: 2.8750 - accuracy30: 0.5302 - val_loss: 3.6683 - val_accuracy30: 0.3830 - 26s/epoch - 16ms/step
Epoch 8/50
1691/1691 - 26s - loss: 2.8648 - accuracy30: 0.5318 - val_loss: 3.6805 - val_accuracy30: 0.3780 - 26s/epoch - 15ms/step
Epoch 9/50
1691/1691 - 26s - loss: 2.8562 - accuracy30: 0.5338 - val_loss: 3.6901 - val_accuracy30: 0.3824 - 26s/epoch - 16ms/step
Epoch 10/50
1691/1691 - 27s - loss: 2.8485 - accuracy30: 0.5362 - val_loss: 3.7255 - val_accuracy30: 0.3812 - 27s/epoch - 16ms/step
Epoch 11/50
1691/1691 - 27s - loss: 2.8412 - accuracy30: 0.5374 - val_loss: 3.7347 - val_accuracy30: 0.3838 - 27s/epoch - 16ms/step
Epoch 12/50
1691/1691 - 26s - loss: 2.8339 - accuracy30: 0.5386 - val_loss: 3.7224 - val_accuracy30: 0.3855 - 26s/epoch - 15ms/step
testing model: results/ATVI/W8/deepLOB_L1/h30
Evaluating performance on  test set...
4960/4960 - 29s - 29s/epoch - 6ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.0118173
{'0': {'precision': 0.41788159484494564, 'recall': 0.3768652859150483, 'f1-score': 0.396315029432461, 'support': 357921}, '1': {'precision': 0.5789533555981009, 'recall': 0.48426153163941105, 'f1-score': 0.5273907318174753, 'support': 557011}, '2': {'precision': 0.4159157723158039, 'recall': 0.5639157937465469, 'f1-score': 0.4787383485096861, 'support': 354748}, 'accuracy': 0.47624204523974545, 'macro avg': {'precision': 0.4709169075862835, 'recall': 0.47501420376700204, 'f1-score': 0.4674813699198741, 'support': 1269680}, 'weighted avg': {'precision': 0.4879948288238284, 'recall': 0.47624204523974545, 'f1-score': 0.47684722310109146, 'support': 1269680}}
[[134888 106473 116560]
 [122898 269739 164374]
 [ 65004  89696 200048]]
Evaluating performance on  train set...
1691/1691 - 12s - 12s/epoch - 7ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.0462773
{'0': {'precision': 0.47581006420785427, 'recall': 0.23321428048655532, 'f1-score': 0.31300956759199233, 'support': 136634}, '1': {'precision': 0.45261345151149424, 'recall': 0.5834209571596353, 'f1-score': 0.5097594653113197, 'support': 162627}, '2': {'precision': 0.43646918020826, 'recall': 0.5105215484006198, 'f1-score': 0.47060000690059683, 'support': 133583}, 'accuracy': 0.4503747308499136, 'macro avg': {'precision': 0.45496423197586955, 'recall': 0.4423855953489368, 'f1-score': 0.4311230132679696, 'support': 432844}, 'weighted avg': {'precision': 0.45495343031599317, 'recall': 0.4503747308499136, 'f1-score': 0.4355669999938793, 'support': 432844}}
[[31865 62512 42257]
 [21954 94880 45793]
 [13151 52235 68197]]
Evaluating performance on  val set...
591/591 - 4s - 4s/epoch - 7ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.122887
{'0': {'precision': 0.43928597135247965, 'recall': 0.1250153631857102, 'f1-score': 0.194638899076717, 'support': 48818}, '1': {'precision': 0.3492346811586977, 'recall': 0.6744530888923125, 'f1-score': 0.4601840841452438, 'support': 51928}, '2': {'precision': 0.4492910488148068, 'recall': 0.32952290227832026, 'f1-score': 0.3801978384319472, 'support': 50388}, 'accuracy': 0.38197890613627644, 'macro avg': {'precision': 0.41260390044199474, 'recall': 0.37633045145211436, 'f1-score': 0.3450069405513026, 'support': 151134}, 'weighted avg': {'precision': 0.4116810144664648, 'recall': 0.38197890613627644, 'f1-score': 0.3477425965006573, 'support': 151134}}
[[ 6103 34000  8715]
 [ 5268 35023 11637]
 [ 2522 31262 16604]]
training model: results/ATVI/W8/deepLOB_L1/h50
Epoch 1/50
1691/1691 - 29s - loss: 3.1514 - accuracy50: 0.4408 - val_loss: 3.4951 - val_accuracy50: 0.3201 - 29s/epoch - 17ms/step
Epoch 2/50
1691/1691 - 27s - loss: 3.0976 - accuracy50: 0.4636 - val_loss: 3.7037 - val_accuracy50: 0.3070 - 27s/epoch - 16ms/step
Epoch 3/50
1691/1691 - 27s - loss: 3.0569 - accuracy50: 0.4763 - val_loss: 3.9618 - val_accuracy50: 0.3087 - 27s/epoch - 16ms/step
Epoch 4/50
1691/1691 - 27s - loss: 3.0358 - accuracy50: 0.4817 - val_loss: 3.9099 - val_accuracy50: 0.3166 - 27s/epoch - 16ms/step
Epoch 5/50
1691/1691 - 27s - loss: 3.0222 - accuracy50: 0.4856 - val_loss: 4.1005 - val_accuracy50: 0.3144 - 27s/epoch - 16ms/step
Epoch 6/50
1691/1691 - 28s - loss: 3.0116 - accuracy50: 0.4882 - val_loss: 4.0691 - val_accuracy50: 0.3182 - 28s/epoch - 16ms/step
Epoch 7/50
1691/1691 - 27s - loss: 3.0025 - accuracy50: 0.4911 - val_loss: 4.1098 - val_accuracy50: 0.3161 - 27s/epoch - 16ms/step
Epoch 8/50
1691/1691 - 27s - loss: 2.9947 - accuracy50: 0.4931 - val_loss: 4.1794 - val_accuracy50: 0.3159 - 27s/epoch - 16ms/step
Epoch 9/50
1691/1691 - 27s - loss: 2.9862 - accuracy50: 0.4956 - val_loss: 4.1896 - val_accuracy50: 0.3152 - 27s/epoch - 16ms/step
Epoch 10/50
1691/1691 - 26s - loss: 2.9800 - accuracy50: 0.4978 - val_loss: 4.1869 - val_accuracy50: 0.3164 - 26s/epoch - 15ms/step
Epoch 11/50
1691/1691 - 28s - loss: 2.9737 - accuracy50: 0.4992 - val_loss: 4.2142 - val_accuracy50: 0.3167 - 28s/epoch - 16ms/step
testing model: results/ATVI/W8/deepLOB_L1/h50
Evaluating performance on  test set...
4960/4960 - 33s - 33s/epoch - 7ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0699862
{'0': {'precision': 0.4062480851052493, 'recall': 0.38918736807716164, 'f1-score': 0.39753476513006614, 'support': 391801}, '1': {'precision': 0.41793285136625413, 'recall': 0.533287112661858, 'f1-score': 0.4686154875215807, 'support': 486074}, '2': {'precision': 0.4324928766093755, 'recall': 0.30256122305738825, 'f1-score': 0.35604338175887745, 'support': 391805}, 'accuracy': 0.4176217629638964, 'macro avg': {'precision': 0.4188912710269596, 'recall': 0.4083452345988026, 'f1-score': 0.4073978781368415, 'support': 1269680}, 'weighted avg': {'precision': 0.4188201517762418, 'recall': 0.4176217629638964, 'f1-score': 0.4119430881673546, 'support': 1269680}}
[[152484 185716  53601]
 [124906 259217 101951]
 [ 97957 175303 118545]]
Evaluating performance on  train set...
1691/1691 - 12s - 12s/epoch - 7ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.1000859
{'0': {'precision': 0.4617089798820528, 'recall': 0.2261904761904762, 'f1-score': 0.3036320877972302, 'support': 146412}, '1': {'precision': 0.3488495936738594, 'recall': 0.666462263164863, 'f1-score': 0.4579776905746389, 'support': 143507}, '2': {'precision': 0.46107667360528104, 'recall': 0.2805107573902396, 'f1-score': 0.348811108501031, 'support': 142925}, 'accuracy': 0.39009666300098883, 'macro avg': {'precision': 0.4238784157203977, 'recall': 0.39105449891519295, 'f1-score': 0.37014029562430006, 'support': 432844}, 'weighted avg': {'precision': 0.42408229610871456, 'recall': 0.39009666300098883, 'f1-score': 0.3697226099065082, 'support': 432844}}
[[33117 93859 19436]
 [20440 95642 27425]
 [18170 84663 40092]]
Evaluating performance on  val set...
591/591 - 4s - 4s/epoch - 7ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.1655208
{'0': {'precision': 0.43009118541033436, 'recall': 0.11299338352726443, 'f1-score': 0.17896828981841176, 'support': 52596}, '1': {'precision': 0.2843584876622377, 'recall': 0.7404982967069668, 'f1-score': 0.41091980651259336, 'support': 44913}, '2': {'precision': 0.4553001277139208, 'recall': 0.17284848484848483, 'f1-score': 0.25057107713934285, 'support': 53625}, 'accuracy': 0.32070877499437583, 'macro avg': {'precision': 0.3899166002621643, 'recall': 0.3421133883609053, 'f1-score': 0.2801530578234493, 'support': 151134}, 'weighted avg': {'precision': 0.395727884479171, 'recall': 0.32070877499437583, 'f1-score': 0.27330403120930136, 'support': 151134}}
[[ 5943 42356  4297]
 [ 4863 33258  6792]
 [ 3012 41344  9269]]
training model: results/ATVI/W8/deepLOB_L1/h100
Epoch 1/50
1691/1691 - 29s - loss: 3.2435 - accuracy100: 0.4010 - val_loss: 3.4562 - val_accuracy100: 0.2987 - 29s/epoch - 17ms/step
Epoch 2/50
1691/1691 - 27s - loss: 3.2144 - accuracy100: 0.4109 - val_loss: 3.3544 - val_accuracy100: 0.3152 - 27s/epoch - 16ms/step
Epoch 3/50
1691/1691 - 27s - loss: 3.1908 - accuracy100: 0.4220 - val_loss: 3.3897 - val_accuracy100: 0.3182 - 27s/epoch - 16ms/step
Epoch 4/50
1691/1691 - 28s - loss: 3.1771 - accuracy100: 0.4279 - val_loss: 3.4165 - val_accuracy100: 0.3023 - 28s/epoch - 16ms/step
Epoch 5/50
1691/1691 - 28s - loss: 3.1689 - accuracy100: 0.4309 - val_loss: 3.3881 - val_accuracy100: 0.3301 - 28s/epoch - 16ms/step
Epoch 6/50
1691/1691 - 27s - loss: 3.1634 - accuracy100: 0.4326 - val_loss: 3.4849 - val_accuracy100: 0.3126 - 27s/epoch - 16ms/step
Epoch 7/50
1691/1691 - 26s - loss: 3.1584 - accuracy100: 0.4351 - val_loss: 3.5399 - val_accuracy100: 0.3045 - 26s/epoch - 16ms/step
Epoch 8/50
1691/1691 - 26s - loss: 3.1554 - accuracy100: 0.4357 - val_loss: 3.5347 - val_accuracy100: 0.2959 - 26s/epoch - 15ms/step
Epoch 9/50
1691/1691 - 26s - loss: 3.1524 - accuracy100: 0.4375 - val_loss: 3.5568 - val_accuracy100: 0.3097 - 26s/epoch - 15ms/step
Epoch 10/50
1691/1691 - 26s - loss: 3.1485 - accuracy100: 0.4387 - val_loss: 3.6647 - val_accuracy100: 0.3028 - 26s/epoch - 15ms/step
Epoch 11/50
1691/1691 - 25s - loss: 3.1452 - accuracy100: 0.4398 - val_loss: 3.6549 - val_accuracy100: 0.2990 - 25s/epoch - 15ms/step
Epoch 12/50
1691/1691 - 26s - loss: 3.1418 - accuracy100: 0.4409 - val_loss: 3.6755 - val_accuracy100: 0.2916 - 26s/epoch - 15ms/step
testing model: results/ATVI/W8/deepLOB_L1/h100
Evaluating performance on  test set...
4960/4960 - 29s - 29s/epoch - 6ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.1005104
{'0': {'precision': 0.4442293212864365, 'recall': 0.0096426386742189, 'f1-score': 0.01887555615477956, 'support': 428306}, '1': {'precision': 0.32960202691397567, 'recall': 0.8359903194203292, 'f1-score': 0.47279669367762533, 'support': 412372}, '2': {'precision': 0.4201382088800604, 'recall': 0.21002699288115206, 'f1-score': 0.28005470425512075, 'support': 429002}, 'accuracy': 0.34573357066347427, 'macro avg': {'precision': 0.39798985236015755, 'recall': 0.35188665032523336, 'f1-score': 0.2572423180291752, 'support': 1269680}, 'weighted avg': {'precision': 0.3988602345562993, 'recall': 0.34573357066347427, 'f1-score': 0.25454969784080556, 'support': 1269680}}
[[  4130 363664  60512]
 [  3789 344739  63844]
 [  1378 337522  90102]]
Evaluating performance on  train set...
1691/1691 - 12s - 12s/epoch - 7ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.101179
{'0': {'precision': 0.4079351161771153, 'recall': 0.012628935939196525, 'f1-score': 0.024499414173062492, 'support': 147360}, '1': {'precision': 0.33436219994632, 'recall': 0.7992050486384714, 'f1-score': 0.4714743807296519, 'support': 143405}, '2': {'precision': 0.41004560870073675, 'recall': 0.246785239197911, 'f1-score': 0.30812561239778724, 'support': 142079}, 'accuracy': 0.3500891776251952, 'macro avg': {'precision': 0.38411430827472404, 'recall': 0.3528730745918596, 'f1-score': 0.2680331357668339, 'support': 432844}, 'weighted avg': {'precision': 0.3842525252556434, 'recall': 0.3500891776251952, 'f1-score': 0.2656850877566593, 'support': 432844}}
[[  1861 122133  23366]
 [  1714 114610  27081]
 [   987 106029  35063]]
Evaluating performance on  val set...
591/591 - 4s - 4s/epoch - 7ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.1198741
{'0': {'precision': 0.40707964601769914, 'recall': 0.012052928075461811, 'f1-score': 0.023412647919582644, 'support': 53431}, '1': {'precision': 0.28842108722802867, 'recall': 0.812226670060393, 'f1-score': 0.4256825995476622, 'support': 43217}, '2': {'precision': 0.43012065498419993, 'recall': 0.21983628822082737, 'f1-score': 0.29096120679184784, 'support': 54486}, 'accuracy': 0.3157727579498988, 'macro avg': {'precision': 0.3752071294099759, 'recall': 0.34803862878556074, 'f1-score': 0.24668548475303087, 'support': 151134}, 'weighted avg': {'precision': 0.38145566649843526, 'recall': 0.3157727579498988, 'f1-score': 0.23489749764383366, 'support': 151134}}
[[  644 44516  8271]
 [  516 35102  7599]
 [  422 42086 11978]]
training model: results/ATVI/W8/deepLOB_L1/h200
Epoch 1/50
1691/1691 - 28s - loss: 3.2775 - accuracy200: 0.3826 - val_loss: 3.3302 - val_accuracy200: 0.3265 - 28s/epoch - 16ms/step
Epoch 2/50
1691/1691 - 25s - loss: 3.2539 - accuracy200: 0.3906 - val_loss: 3.4359 - val_accuracy200: 0.3030 - 25s/epoch - 15ms/step
Epoch 3/50
1691/1691 - 25s - loss: 3.2380 - accuracy200: 0.4001 - val_loss: 3.4405 - val_accuracy200: 0.3046 - 25s/epoch - 15ms/step
Epoch 4/50
1691/1691 - 25s - loss: 3.2308 - accuracy200: 0.4038 - val_loss: 3.4565 - val_accuracy200: 0.3004 - 25s/epoch - 15ms/step
Epoch 5/50
1691/1691 - 26s - loss: 3.2252 - accuracy200: 0.4070 - val_loss: 3.5314 - val_accuracy200: 0.2993 - 26s/epoch - 16ms/step
Epoch 6/50
1691/1691 - 27s - loss: 3.2195 - accuracy200: 0.4103 - val_loss: 3.6351 - val_accuracy200: 0.3001 - 27s/epoch - 16ms/step
Epoch 7/50
1691/1691 - 26s - loss: 3.2165 - accuracy200: 0.4117 - val_loss: 3.6467 - val_accuracy200: 0.2998 - 26s/epoch - 16ms/step
Epoch 8/50
1691/1691 - 26s - loss: 3.2136 - accuracy200: 0.4130 - val_loss: 3.6074 - val_accuracy200: 0.3007 - 26s/epoch - 15ms/step
Epoch 9/50
1691/1691 - 26s - loss: 3.2106 - accuracy200: 0.4152 - val_loss: 3.6669 - val_accuracy200: 0.3002 - 26s/epoch - 16ms/step
Epoch 10/50
1691/1691 - 26s - loss: 3.2091 - accuracy200: 0.4156 - val_loss: 3.6526 - val_accuracy200: 0.2998 - 26s/epoch - 15ms/step
Epoch 11/50
1691/1691 - 25s - loss: 3.2071 - accuracy200: 0.4170 - val_loss: 3.5991 - val_accuracy200: 0.3017 - 25s/epoch - 15ms/step
testing model: results/ATVI/W8/deepLOB_L1/h200
Evaluating performance on  test set...
4960/4960 - 28s - 28s/epoch - 6ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1085987
{'0': {'precision': 0.3390583247892307, 'recall': 0.15416760267735288, 'f1-score': 0.2119588861398469, 'support': 413991}, '1': {'precision': 0.3409602494414246, 'recall': 0.5625206316021126, 'f1-score': 0.42457384299150797, 'support': 436224}, '2': {'precision': 0.34849469112903003, 'recall': 0.3005471255051077, 'f1-score': 0.3227498598342588, 'support': 419465}, 'accuracy': 0.34282496377039884, 'macro avg': {'precision': 0.3428377551198951, 'recall': 0.33907845326152436, 'f1-score': 0.31976086298853784, 'support': 1269680}, 'weighted avg': {'precision': 0.342829267535594, 'recall': 0.34282496377039884, 'f1-score': 0.3216090993576541, 'support': 1269680}}
[[ 63824 239643 110524]
 [ 65679 245385 125160]
 [ 58736 234660 126069]]
Evaluating performance on  train set...
1691/1691 - 9s - 9s/epoch - 5ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1037316
{'0': {'precision': 0.36795755506751615, 'recall': 0.11438111717947332, 'f1-score': 0.17451387850443195, 'support': 147944}, '1': {'precision': 0.32692746395223526, 'recall': 0.5832286674572156, 'f1-score': 0.41899068209485263, 'support': 142517}, '2': {'precision': 0.3551342669049612, 'recall': 0.33075577842860454, 'f1-score': 0.34251178216093564, 'support': 142383}, 'accuracy': 0.33992847307575014, 'macro avg': {'precision': 0.3500064286415709, 'recall': 0.3427885210217645, 'f1-score': 0.31200544758674004, 'support': 432844}, 'weighted avg': {'precision': 0.3502299124666587, 'recall': 0.33992847307575014, 'f1-score': 0.31027213351921773, 'support': 432844}}
[[16922 88137 42885]
 [16767 83120 42630]
 [12300 82989 47094]]
Evaluating performance on  val set...
591/591 - 3s - 3s/epoch - 6ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1118747
{'0': {'precision': 0.36078842838941766, 'recall': 0.0911638828920956, 'f1-score': 0.14555019728189392, 'support': 52806}, '1': {'precision': 0.2916172329079034, 'recall': 0.5389829006822008, 'f1-score': 0.37846539080665353, 'support': 45148}, '2': {'precision': 0.3701836381702425, 'recall': 0.37830011282437004, 'f1-score': 0.3741978684225211, 'support': 53180}, 'accuracy': 0.32597562428043986, 'macro avg': {'precision': 0.3408630998225212, 'recall': 0.3361489654662222, 'f1-score': 0.29940448550368953, 'support': 151134}, 'weighted avg': {'precision': 0.343430958346574, 'recall': 0.32597562428043986, 'f1-score': 0.29558353397988646, 'support': 151134}}
[[ 4814 29843 18149]
 [ 4735 24334 16079]
 [ 3794 29268 20118]]
training model: results/ATVI/W8/deepLOB_L1/h300
Epoch 1/50
1691/1691 - 28s - loss: 3.2859 - accuracy300: 0.3772 - val_loss: 4.1206 - val_accuracy300: 0.2760 - 28s/epoch - 16ms/step
Epoch 2/50
1691/1691 - 26s - loss: 3.2668 - accuracy300: 0.3848 - val_loss: 3.6227 - val_accuracy300: 0.2760 - 26s/epoch - 15ms/step
Epoch 3/50
1691/1691 - 26s - loss: 3.2553 - accuracy300: 0.3910 - val_loss: 3.6648 - val_accuracy300: 0.2760 - 26s/epoch - 15ms/step
Epoch 4/50
1691/1691 - 25s - loss: 3.2449 - accuracy300: 0.3972 - val_loss: 3.9538 - val_accuracy300: 0.2798 - 25s/epoch - 15ms/step
Epoch 5/50
1691/1691 - 25s - loss: 3.2381 - accuracy300: 0.4030 - val_loss: 4.0246 - val_accuracy300: 0.2778 - 25s/epoch - 15ms/step
Epoch 6/50
1691/1691 - 26s - loss: 3.2318 - accuracy300: 0.4052 - val_loss: 3.8504 - val_accuracy300: 0.2809 - 26s/epoch - 15ms/step
Epoch 7/50
1691/1691 - 26s - loss: 3.2261 - accuracy300: 0.4094 - val_loss: 3.9354 - val_accuracy300: 0.2801 - 26s/epoch - 15ms/step
Epoch 8/50
1691/1691 - 26s - loss: 3.2222 - accuracy300: 0.4123 - val_loss: 3.8530 - val_accuracy300: 0.2861 - 26s/epoch - 15ms/step
Epoch 9/50
1691/1691 - 26s - loss: 3.2176 - accuracy300: 0.4152 - val_loss: 3.7923 - val_accuracy300: 0.2898 - 26s/epoch - 15ms/step
Epoch 10/50
1691/1691 - 26s - loss: 3.2144 - accuracy300: 0.4164 - val_loss: 3.7624 - val_accuracy300: 0.2960 - 26s/epoch - 15ms/step
Epoch 11/50
1691/1691 - 26s - loss: 3.2101 - accuracy300: 0.4191 - val_loss: 3.6608 - val_accuracy300: 0.2989 - 26s/epoch - 15ms/step
Epoch 12/50
1691/1691 - 26s - loss: 3.2080 - accuracy300: 0.4208 - val_loss: 3.4910 - val_accuracy300: 0.3221 - 26s/epoch - 16ms/step
Epoch 13/50
1691/1691 - 26s - loss: 3.2065 - accuracy300: 0.4213 - val_loss: 3.6087 - val_accuracy300: 0.3114 - 26s/epoch - 16ms/step
Epoch 14/50
1691/1691 - 25s - loss: 3.2024 - accuracy300: 0.4233 - val_loss: 3.5607 - val_accuracy300: 0.3204 - 25s/epoch - 15ms/step
Epoch 15/50
1691/1691 - 26s - loss: 3.1992 - accuracy300: 0.4242 - val_loss: 3.4414 - val_accuracy300: 0.3159 - 26s/epoch - 15ms/step
Epoch 16/50
1691/1691 - 26s - loss: 3.1961 - accuracy300: 0.4254 - val_loss: 3.4522 - val_accuracy300: 0.3117 - 26s/epoch - 15ms/step
Epoch 17/50
1691/1691 - 25s - loss: 3.1932 - accuracy300: 0.4271 - val_loss: 3.4550 - val_accuracy300: 0.3068 - 25s/epoch - 15ms/step
Epoch 18/50
1691/1691 - 27s - loss: 3.1914 - accuracy300: 0.4284 - val_loss: 3.4318 - val_accuracy300: 0.3175 - 27s/epoch - 16ms/step
Epoch 19/50
1691/1691 - 27s - loss: 3.1882 - accuracy300: 0.4300 - val_loss: 3.4088 - val_accuracy300: 0.3225 - 27s/epoch - 16ms/step
Epoch 20/50
1691/1691 - 27s - loss: 3.1862 - accuracy300: 0.4306 - val_loss: 3.4636 - val_accuracy300: 0.3259 - 27s/epoch - 16ms/step
Epoch 21/50
1691/1691 - 27s - loss: 3.1850 - accuracy300: 0.4308 - val_loss: 3.4995 - val_accuracy300: 0.3022 - 27s/epoch - 16ms/step
Epoch 22/50
1691/1691 - 26s - loss: 3.1820 - accuracy300: 0.4328 - val_loss: 3.4287 - val_accuracy300: 0.3202 - 26s/epoch - 15ms/step
Epoch 23/50
1691/1691 - 26s - loss: 3.1800 - accuracy300: 0.4332 - val_loss: 3.4166 - val_accuracy300: 0.3157 - 26s/epoch - 16ms/step
Epoch 24/50
1691/1691 - 25s - loss: 3.1777 - accuracy300: 0.4341 - val_loss: 3.4122 - val_accuracy300: 0.3152 - 25s/epoch - 15ms/step
Epoch 25/50
1691/1691 - 25s - loss: 3.1759 - accuracy300: 0.4343 - val_loss: 3.3983 - val_accuracy300: 0.3356 - 25s/epoch - 15ms/step
Epoch 26/50
1691/1691 - 25s - loss: 3.1745 - accuracy300: 0.4353 - val_loss: 3.4287 - val_accuracy300: 0.3177 - 25s/epoch - 15ms/step
Epoch 27/50
1691/1691 - 26s - loss: 3.1725 - accuracy300: 0.4354 - val_loss: 3.4120 - val_accuracy300: 0.3391 - 26s/epoch - 15ms/step
Epoch 28/50
1691/1691 - 27s - loss: 3.1696 - accuracy300: 0.4378 - val_loss: 3.3927 - val_accuracy300: 0.3333 - 27s/epoch - 16ms/step
Epoch 29/50
1691/1691 - 26s - loss: 3.1691 - accuracy300: 0.4381 - val_loss: 3.3961 - val_accuracy300: 0.3390 - 26s/epoch - 15ms/step
Epoch 30/50
1691/1691 - 26s - loss: 3.1671 - accuracy300: 0.4389 - val_loss: 3.5093 - val_accuracy300: 0.3191 - 26s/epoch - 15ms/step
Epoch 31/50
1691/1691 - 26s - loss: 3.1656 - accuracy300: 0.4394 - val_loss: 3.3735 - val_accuracy300: 0.3393 - 26s/epoch - 15ms/step
Epoch 32/50
1691/1691 - 25s - loss: 3.1624 - accuracy300: 0.4408 - val_loss: 3.4243 - val_accuracy300: 0.3338 - 25s/epoch - 15ms/step
Epoch 33/50
1691/1691 - 25s - loss: 3.1595 - accuracy300: 0.4422 - val_loss: 3.3910 - val_accuracy300: 0.3425 - 25s/epoch - 15ms/step
Epoch 34/50
1691/1691 - 25s - loss: 3.1579 - accuracy300: 0.4424 - val_loss: 3.4044 - val_accuracy300: 0.3539 - 25s/epoch - 15ms/step
Epoch 35/50
1691/1691 - 25s - loss: 3.1567 - accuracy300: 0.4430 - val_loss: 3.4076 - val_accuracy300: 0.3425 - 25s/epoch - 15ms/step
Epoch 36/50
1691/1691 - 26s - loss: 3.1553 - accuracy300: 0.4439 - val_loss: 3.4320 - val_accuracy300: 0.3492 - 26s/epoch - 15ms/step
Epoch 37/50
1691/1691 - 26s - loss: 3.1523 - accuracy300: 0.4447 - val_loss: 3.4484 - val_accuracy300: 0.3486 - 26s/epoch - 16ms/step
Epoch 38/50
1691/1691 - 25s - loss: 3.1516 - accuracy300: 0.4454 - val_loss: 3.4937 - val_accuracy300: 0.3576 - 25s/epoch - 15ms/step
Epoch 39/50
1691/1691 - 25s - loss: 3.1502 - accuracy300: 0.4450 - val_loss: 3.5429 - val_accuracy300: 0.3605 - 25s/epoch - 15ms/step
Epoch 40/50
1691/1691 - 25s - loss: 3.1478 - accuracy300: 0.4468 - val_loss: 3.5110 - val_accuracy300: 0.3605 - 25s/epoch - 15ms/step
Epoch 41/50
1691/1691 - 26s - loss: 3.1468 - accuracy300: 0.4478 - val_loss: 3.4284 - val_accuracy300: 0.3606 - 26s/epoch - 15ms/step
testing model: results/ATVI/W8/deepLOB_L1/h300
Evaluating performance on  test set...
4960/4960 - 31s - 31s/epoch - 6ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1559517
{'0': {'precision': 0.34490941907881545, 'recall': 0.11860755943596181, 'f1-score': 0.17651506339420728, 'support': 435006}, '1': {'precision': 0.3111523194456395, 'recall': 0.616168269218543, 'f1-score': 0.41349709793963096, 'support': 393227}, '2': {'precision': 0.3415233559174085, 'recall': 0.26411551103529984, 'f1-score': 0.2978726122135103, 'support': 441447}, 'accuracy': 0.32329563354546026, 'macro avg': {'precision': 0.3325283648139545, 'recall': 0.33296377989660153, 'f1-score': 0.2959615911824495, 'support': 1269680}, 'weighted avg': {'precision': 0.3332773775865745, 'recall': 0.32329563354546026, 'f1-score': 0.29210376318614556, 'support': 1269680}}
[[ 51595 265073 118338]
 [ 44473 242294 106460]
 [ 53522 271332 116593]]
Evaluating performance on  train set...
1691/1691 - 9s - 9s/epoch - 5ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1563522
{'0': {'precision': 0.35787444846206534, 'recall': 0.1483959603431991, 'f1-score': 0.20979745818898302, 'support': 151399}, '1': {'precision': 0.3251625608610621, 'recall': 0.5249166758231696, 'f1-score': 0.40157021412520244, 'support': 136515}, '2': {'precision': 0.3418890210173296, 'recall': 0.35310839715724834, 'f1-score': 0.3474081516278817, 'support': 144930}, 'accuracy': 0.3356913807283918, 'macro avg': {'precision': 0.34164201011348566, 'recall': 0.34214034444120567, 'f1-score': 0.3195919413140224, 'support': 432844}, 'weighted avg': {'precision': 0.34220498940657074, 'recall': 0.3356913807283918, 'f1-score': 0.31635727090842136, 'support': 432844}}
[[22467 75871 53061]
 [19407 71659 45449]
 [20905 72849 51176]]
Evaluating performance on  val set...
591/591 - 3s - 3s/epoch - 5ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1315972
{'0': {'precision': 0.36581890409775897, 'recall': 0.15583842248546834, 'f1-score': 0.21856739290275148, 'support': 54364}, '1': {'precision': 0.293390735868612, 'recall': 0.441088337528467, 'f1-score': 0.3523891602030068, 'support': 41715}, '2': {'precision': 0.37261722341403614, 'recall': 0.4416855871401326, 'f1-score': 0.40422224992727424, 'support': 55055}, 'accuracy': 0.33869943229187344, 'macro avg': {'precision': 0.343942287793469, 'recall': 0.3462041157180226, 'f1-score': 0.3250596010110109, 'support': 151134}, 'weighted avg': {'precision': 0.3483042510896918, 'recall': 0.33869943229187344, 'f1-score': 0.3231342221828291, 'support': 151134}}
[[ 8472 21941 23951]
 [ 6323 18400 16992]
 [ 8364 22374 24317]]
training model: results/ATVI/W8/deepLOB_L1/h500
Epoch 1/50
1691/1691 - 28s - loss: 3.2539 - accuracy500: 0.4036 - val_loss: 3.4675 - val_accuracy500: 0.2734 - 28s/epoch - 16ms/step
Epoch 2/50
1691/1691 - 26s - loss: 3.2389 - accuracy500: 0.4029 - val_loss: 3.3391 - val_accuracy500: 0.3562 - 26s/epoch - 15ms/step
Epoch 3/50
1691/1691 - 26s - loss: 3.2197 - accuracy500: 0.4166 - val_loss: 3.3558 - val_accuracy500: 0.2957 - 26s/epoch - 15ms/step
Epoch 4/50
1691/1691 - 25s - loss: 3.2115 - accuracy500: 0.4232 - val_loss: 3.4003 - val_accuracy500: 0.2907 - 25s/epoch - 15ms/step
Epoch 5/50
1691/1691 - 25s - loss: 3.2032 - accuracy500: 0.4258 - val_loss: 3.4514 - val_accuracy500: 0.2880 - 25s/epoch - 15ms/step
Epoch 6/50
1691/1691 - 25s - loss: 3.1956 - accuracy500: 0.4301 - val_loss: 3.3418 - val_accuracy500: 0.3291 - 25s/epoch - 15ms/step
Epoch 7/50
1691/1691 - 25s - loss: 3.1842 - accuracy500: 0.4363 - val_loss: 3.3675 - val_accuracy500: 0.3164 - 25s/epoch - 15ms/step
Epoch 8/50
1691/1691 - 25s - loss: 3.1740 - accuracy500: 0.4415 - val_loss: 3.3704 - val_accuracy500: 0.3656 - 25s/epoch - 15ms/step
Epoch 9/50
1691/1691 - 27s - loss: 3.1701 - accuracy500: 0.4420 - val_loss: 3.4193 - val_accuracy500: 0.3462 - 27s/epoch - 16ms/step
Epoch 10/50
1691/1691 - 26s - loss: 3.1628 - accuracy500: 0.4456 - val_loss: 3.4599 - val_accuracy500: 0.3153 - 26s/epoch - 15ms/step
Epoch 11/50
1691/1691 - 26s - loss: 3.1614 - accuracy500: 0.4451 - val_loss: 3.4547 - val_accuracy500: 0.3372 - 26s/epoch - 16ms/step
Epoch 12/50
1691/1691 - 26s - loss: 3.1541 - accuracy500: 0.4482 - val_loss: 3.3764 - val_accuracy500: 0.3440 - 26s/epoch - 15ms/step
testing model: results/ATVI/W8/deepLOB_L1/h500
Evaluating performance on  test set...
4960/4960 - 34s - 34s/epoch - 7ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1490752
{'0': {'precision': 0.3523495592919757, 'recall': 0.15545335867702526, 'f1-score': 0.21572905740431755, 'support': 470334}, '1': {'precision': 0.25461676572723424, 'recall': 0.6108082371896943, 'f1-score': 0.3594118896694778, 'support': 317147}, '2': {'precision': 0.3793017630135486, 'recall': 0.23705150777998296, 'f1-score': 0.2917614267227187, 'support': 482199}, 'accuracy': 0.30018351080587236, 'macro avg': {'precision': 0.32875602934425285, 'recall': 0.33443770121556754, 'f1-score': 0.2889674579321713, 'support': 1269680}, 'weighted avg': {'precision': 0.3381732813334835, 'recall': 0.30018351080587236, 'f1-score': 0.2804944405381485, 'support': 1269680}}
[[ 73115 284824 112395]
 [ 48773 193716  74658]
 [ 85619 282274 114306]]
Evaluating performance on  train set...
1691/1691 - 12s - 12s/epoch - 7ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1188285
{'0': {'precision': 0.3528044871794872, 'recall': 0.05953097219499334, 'f1-score': 0.10187236454712145, 'support': 147923}, '1': {'precision': 0.3493488320320575, 'recall': 0.6202350284080884, 'f1-score': 0.44695129859396343, 'support': 141685}, '2': {'precision': 0.3509428410602804, 'recall': 0.3830391800943897, 'f1-score': 0.36628923931475565, 'support': 143236}, 'accuracy': 0.3501238321427581, 'macro avg': {'precision': 0.3510320534239417, 'recall': 0.3542683935658238, 'f1-score': 0.30503763415194685, 'support': 432844}, 'weighted avg': {'precision': 0.3510572774616806, 'recall': 0.3501238321427581, 'f1-score': 0.30232916710102925, 'support': 432844}}
[[ 8806 83457 55660]
 [ 7996 87878 45811]
 [ 8158 80213 54865]]
Evaluating performance on  val set...
591/591 - 4s - 4s/epoch - 7ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1171805
{'0': {'precision': 0.38760233918128656, 'recall': 0.030483654359144175, 'f1-score': 0.05652203574839678, 'support': 54357}, '1': {'precision': 0.3268741198136713, 'recall': 0.5701632142097929, 'f1-score': 0.4155269613117012, 'support': 42337}, '2': {'precision': 0.3852296229335306, 'recall': 0.5166421748714181, 'f1-score': 0.44136177825203415, 'support': 54440}, 'accuracy': 0.3567827226170154, 'macro avg': {'precision': 0.3665686939761628, 'recall': 0.37242968114678504, 'f1-score': 0.30447025843737735, 'support': 151134}, 'weighted avg': {'precision': 0.36973593389925496, 'recall': 0.3567827226170154, 'f1-score': 0.2957128671660238, 'support': 151134}}
[[ 1657 25013 27687]
 [ 1000 24139 17198]
 [ 1618 24696 28126]]
training model: results/ATVI/W8/deepLOB_L1/h1000
Epoch 1/50
1691/1691 - 30s - loss: 3.2489 - accuracy1000: 0.4102 - val_loss: 3.4014 - val_accuracy1000: 0.3284 - 30s/epoch - 18ms/step
Epoch 2/50
1691/1691 - 27s - loss: 3.2212 - accuracy1000: 0.4195 - val_loss: 3.4629 - val_accuracy1000: 0.3074 - 27s/epoch - 16ms/step
Epoch 3/50
1691/1691 - 26s - loss: 3.1897 - accuracy1000: 0.4326 - val_loss: 3.4475 - val_accuracy1000: 0.3103 - 26s/epoch - 16ms/step
Epoch 4/50
1691/1691 - 26s - loss: 3.1746 - accuracy1000: 0.4380 - val_loss: 3.5858 - val_accuracy1000: 0.3114 - 26s/epoch - 15ms/step
Epoch 5/50
1691/1691 - 26s - loss: 3.1572 - accuracy1000: 0.4461 - val_loss: 3.6561 - val_accuracy1000: 0.2999 - 26s/epoch - 15ms/step
Epoch 6/50
1691/1691 - 26s - loss: 3.1453 - accuracy1000: 0.4512 - val_loss: 3.6463 - val_accuracy1000: 0.3243 - 26s/epoch - 15ms/step
Epoch 7/50
1691/1691 - 26s - loss: 3.1361 - accuracy1000: 0.4559 - val_loss: 3.6454 - val_accuracy1000: 0.3293 - 26s/epoch - 16ms/step
Epoch 8/50
1691/1691 - 26s - loss: 3.1229 - accuracy1000: 0.4608 - val_loss: 3.7049 - val_accuracy1000: 0.3336 - 26s/epoch - 15ms/step
Epoch 9/50
1691/1691 - 27s - loss: 3.1156 - accuracy1000: 0.4652 - val_loss: 3.6623 - val_accuracy1000: 0.3300 - 27s/epoch - 16ms/step
Epoch 10/50
1691/1691 - 27s - loss: 3.1062 - accuracy1000: 0.4669 - val_loss: 3.7552 - val_accuracy1000: 0.3227 - 27s/epoch - 16ms/step
Epoch 11/50
1691/1691 - 27s - loss: 3.0972 - accuracy1000: 0.4705 - val_loss: 3.7607 - val_accuracy1000: 0.3147 - 27s/epoch - 16ms/step
testing model: results/ATVI/W8/deepLOB_L1/h1000
Evaluating performance on  test set...
4960/4960 - 33s - 33s/epoch - 7ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1338266
{'0': {'precision': 0.3140246201619164, 'recall': 0.1734875684683912, 'f1-score': 0.22349951062419096, 'support': 408035}, '1': {'precision': 0.33098707415138773, 'recall': 0.1493782384621989, 'f1-score': 0.20585277409596656, 'support': 430953}, '2': {'precision': 0.3287359622293798, 'recall': 0.6486003919274098, 'f1-score': 0.43632526926017584, 'support': 430692}, 'accuracy': 0.326468874047004, 'macro avg': {'precision': 0.32458255218089466, 'recall': 0.32382206628599997, 'f1-score': 0.28855918466011116, 'support': 1269680}, 'weighted avg': {'precision': 0.32477227135894604, 'recall': 0.326468874047004, 'f1-score': 0.2897031505896954, 'support': 1269680}}
[[ 70789  62323 274923]
 [ 71087  64375 295491]
 [ 83549  67796 279347]]
Evaluating performance on  train set...
1691/1691 - 11s - 11s/epoch - 6ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1385813
{'0': {'precision': 0.36522281084449987, 'recall': 0.10990836503938696, 'f1-score': 0.16896825151636855, 'support': 149288}, '1': {'precision': 0.325102640664365, 'recall': 0.20073747056239333, 'f1-score': 0.24821340314975354, 'support': 138853}, '2': {'precision': 0.3376872216081699, 'recall': 0.7051892497045673, 'f1-score': 0.4566857245152556, 'support': 144703}, 'accuracy': 0.33805250852501134, 'macro avg': {'precision': 0.34267089103901155, 'recall': 0.33861169510211586, 'f1-score': 0.29128912639379256, 'support': 432844}, 'weighted avg': {'precision': 0.3431472169601283, 'recall': 0.33805250852501134, 'f1-score': 0.29057559396563054, 'support': 432844}}
[[ 16408  30259 102621]
 [ 13462  27873  97518]
 [ 15056  27604 102043]]
Evaluating performance on  val set...
591/591 - 3s - 3s/epoch - 6ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1396677
{'0': {'precision': 0.3898168825368468, 'recall': 0.08278635656561824, 'f1-score': 0.13656918430893925, 'support': 52714}, '1': {'precision': 0.26172409792319296, 'recall': 0.24916055491738093, 'f1-score': 0.25528784672317595, 'support': 45268}, '2': {'precision': 0.347259510140019, 'recall': 0.6327137266706803, 'f1-score': 0.44841195765220404, 'support': 53152}, 'accuracy': 0.32602194079426206, 'macro avg': {'precision': 0.3329334968666863, 'recall': 0.3215535460512265, 'f1-score': 0.2800896628947731, 'support': 151134}, 'weighted avg': {'precision': 0.3364833266756437, 'recall': 0.32602194079426206, 'f1-score': 0.28179940053367275, 'support': 151134}}
[[ 4364 16333 32017]
 [ 2792 11279 31197]
 [ 4039 15483 33630]]
training model: results/ATVI/W8/deepOF_L1/h10
Epoch 1/50
1691/1691 - 27s - loss: 3.1735 - accuracy10: 0.4208 - val_loss: 3.3287 - val_accuracy10: 0.4377 - 27s/epoch - 16ms/step
Epoch 2/50
1691/1691 - 24s - loss: 3.1381 - accuracy10: 0.4269 - val_loss: 3.3103 - val_accuracy10: 0.4150 - 24s/epoch - 14ms/step
Epoch 3/50
1691/1691 - 23s - loss: 3.1238 - accuracy10: 0.4309 - val_loss: 3.3068 - val_accuracy10: 0.4100 - 23s/epoch - 14ms/step
Epoch 4/50
1691/1691 - 23s - loss: 3.1134 - accuracy10: 0.4370 - val_loss: 3.3098 - val_accuracy10: 0.4187 - 23s/epoch - 14ms/step
Epoch 5/50
1691/1691 - 24s - loss: 3.1031 - accuracy10: 0.4437 - val_loss: 3.3092 - val_accuracy10: 0.4218 - 24s/epoch - 14ms/step
Epoch 6/50
1691/1691 - 24s - loss: 3.0928 - accuracy10: 0.4485 - val_loss: 3.3144 - val_accuracy10: 0.4312 - 24s/epoch - 14ms/step
Epoch 7/50
1691/1691 - 22s - loss: 3.0841 - accuracy10: 0.4529 - val_loss: 3.3184 - val_accuracy10: 0.4380 - 22s/epoch - 13ms/step
Epoch 8/50
1691/1691 - 23s - loss: 3.0761 - accuracy10: 0.4572 - val_loss: 3.3187 - val_accuracy10: 0.4433 - 23s/epoch - 14ms/step
Epoch 9/50
1691/1691 - 23s - loss: 3.0681 - accuracy10: 0.4600 - val_loss: 3.3180 - val_accuracy10: 0.4456 - 23s/epoch - 13ms/step
Epoch 10/50
1691/1691 - 23s - loss: 3.0607 - accuracy10: 0.4637 - val_loss: 3.3164 - val_accuracy10: 0.4456 - 23s/epoch - 14ms/step
Epoch 11/50
1691/1691 - 23s - loss: 3.0558 - accuracy10: 0.4631 - val_loss: 3.3186 - val_accuracy10: 0.4493 - 23s/epoch - 13ms/step
Epoch 12/50
1691/1691 - 24s - loss: 3.0485 - accuracy10: 0.4672 - val_loss: 3.3216 - val_accuracy10: 0.4524 - 24s/epoch - 14ms/step
Epoch 13/50
1691/1691 - 24s - loss: 3.0429 - accuracy10: 0.4686 - val_loss: 3.3280 - val_accuracy10: 0.4618 - 24s/epoch - 14ms/step
testing model: results/ATVI/W8/deepOF_L1/h10
Evaluating performance on  test set...
4960/4960 - 36s - 36s/epoch - 7ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 1.0585593
{'0': {'precision': 0.256964219710655, 'recall': 0.5935974216513938, 'f1-score': 0.3586648888436763, 'support': 249462}, '1': {'precision': 0.6466144766517959, 'recall': 0.37090202032721864, 'f1-score': 0.47140388676749795, 'support': 774528}, '2': {'precision': 0.32498575064021773, 'recall': 0.329547998453304, 'f1-score': 0.3272509745987927, 'support': 245685}, 'accuracy': 0.4066544588182015, 'macro avg': {'precision': 0.40952148233422286, 'recall': 0.4313491468106388, 'f1-score': 0.3857732500699889, 'support': 1269675}, 'weighted avg': {'precision': 0.50782125323068, 'recall': 0.4066544588182015, 'f1-score': 0.4213593445608382, 'support': 1269675}}
[[148080  68463  32919]
 [352004 287274 135250]
 [ 76183  88537  80965]]
Evaluating performance on  train set...
1691/1691 - 11s - 11s/epoch - 7ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 1.0549194
{'0': {'precision': 0.2961016748321819, 'recall': 0.5865137352545002, 'f1-score': 0.39352972390065216, 'support': 97996}, '1': {'precision': 0.6011416339636104, 'recall': 0.3609895233854504, 'f1-score': 0.45109407438708476, 'support': 238054}, '2': {'precision': 0.36398375426763696, 'recall': 0.3601781157339009, 'f1-score': 0.36207093524432676, 'support': 96791}, 'accuracy': 0.4118671752444893, 'macro avg': {'precision': 0.4204090210211431, 'recall': 0.43589379145795054, 'f1-score': 0.40223157784402125, 'support': 432841}, 'weighted avg': {'precision': 0.4790472755994618, 'recall': 0.4118671752444893, 'f1-score': 0.4181542310010951, 'support': 432841}}
[[ 57476  25523  14997]
 [106199  85935  45920]
 [ 30434  31495  34862]]
Evaluating performance on  val set...
591/591 - 4s - 4s/epoch - 7ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 1.0646836
{'0': {'precision': 0.3104109629152453, 'recall': 0.5819609134826527, 'f1-score': 0.4048694323769514, 'support': 36432}, '1': {'precision': 0.5673786407766991, 'recall': 0.37607145615073745, 'f1-score': 0.45232898342079597, 'support': 77698}, '2': {'precision': 0.367124162144909, 'recall': 0.31083966164905547, 'f1-score': 0.33664554461241275, 'support': 37003}, 'accuracy': 0.40973182561055493, 'macro avg': {'precision': 0.4149712552789511, 'recall': 0.4229573437608152, 'f1-score': 0.39794798680338667, 'support': 151133}, 'weighted avg': {'precision': 0.45640444644018346, 'recall': 0.40973182561055493, 'f1-score': 0.4125647979030338, 'support': 151133}}
[[21202  9682  5548]
 [34198 29220 14280]
 [12903 12598 11502]]
training model: results/ATVI/W8/deepOF_L1/h20
Epoch 1/50
1691/1691 - 25s - loss: 3.2031 - accuracy20: 0.4183 - val_loss: 3.2916 - val_accuracy20: 0.4079 - 25s/epoch - 15ms/step
Epoch 2/50
1691/1691 - 23s - loss: 3.1750 - accuracy20: 0.4232 - val_loss: 3.2707 - val_accuracy20: 0.4001 - 23s/epoch - 14ms/step
Epoch 3/50
1691/1691 - 24s - loss: 3.1633 - accuracy20: 0.4264 - val_loss: 3.2674 - val_accuracy20: 0.3918 - 24s/epoch - 14ms/step
Epoch 4/50
1691/1691 - 23s - loss: 3.1514 - accuracy20: 0.4320 - val_loss: 3.2663 - val_accuracy20: 0.3984 - 23s/epoch - 14ms/step
Epoch 5/50
1691/1691 - 23s - loss: 3.1407 - accuracy20: 0.4371 - val_loss: 3.2680 - val_accuracy20: 0.4012 - 23s/epoch - 14ms/step
Epoch 6/50
1691/1691 - 22s - loss: 3.1298 - accuracy20: 0.4424 - val_loss: 3.2673 - val_accuracy20: 0.4052 - 22s/epoch - 13ms/step
Epoch 7/50
1691/1691 - 23s - loss: 3.1205 - accuracy20: 0.4475 - val_loss: 3.2688 - val_accuracy20: 0.4084 - 23s/epoch - 13ms/step
Epoch 8/50
1691/1691 - 23s - loss: 3.1109 - accuracy20: 0.4519 - val_loss: 3.2688 - val_accuracy20: 0.4122 - 23s/epoch - 13ms/step
Epoch 9/50
1691/1691 - 23s - loss: 3.1024 - accuracy20: 0.4550 - val_loss: 3.2703 - val_accuracy20: 0.4165 - 23s/epoch - 14ms/step
Epoch 10/50
1691/1691 - 22s - loss: 3.0953 - accuracy20: 0.4581 - val_loss: 3.2738 - val_accuracy20: 0.4222 - 22s/epoch - 13ms/step
Epoch 11/50
1691/1691 - 23s - loss: 3.0902 - accuracy20: 0.4600 - val_loss: 3.2805 - val_accuracy20: 0.4212 - 23s/epoch - 14ms/step
Epoch 12/50
1691/1691 - 22s - loss: 3.0833 - accuracy20: 0.4624 - val_loss: 3.2846 - val_accuracy20: 0.4259 - 22s/epoch - 13ms/step
Epoch 13/50
1691/1691 - 23s - loss: 3.0771 - accuracy20: 0.4635 - val_loss: 3.2869 - val_accuracy20: 0.4248 - 23s/epoch - 14ms/step
Epoch 14/50
1691/1691 - 23s - loss: 3.0709 - accuracy20: 0.4660 - val_loss: 3.2914 - val_accuracy20: 0.4289 - 23s/epoch - 14ms/step
testing model: results/ATVI/W8/deepOF_L1/h20
Evaluating performance on  test set...
4960/4960 - 29s - 29s/epoch - 6ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 1.0682893
{'0': {'precision': 0.3108961074334166, 'recall': 0.5844538723794016, 'f1-score': 0.40588471099341494, 'support': 314432}, '1': {'precision': 0.5376904615113617, 'recall': 0.30323133422532106, 'f1-score': 0.3877758832531744, 'support': 644254}, '2': {'precision': 0.36317352163072647, 'recall': 0.36814485399805136, 'f1-score': 0.3656422908333134, 'support': 310989}, 'accuracy': 0.3887750802370685, 'macro avg': {'precision': 0.4039200301918349, 'recall': 0.4186100202009247, 'f1-score': 0.38643429502663423, 'support': 1269675}, 'weighted avg': {'precision': 0.43877991278198186, 'recall': 0.3887750802370685, 'f1-score': 0.3868391798849574, 'support': 1269675}}
[[183771  76188  54473]
 [302612 195358 146284]
 [104718  91782 114489]]
Evaluating performance on  train set...
1691/1691 - 8s - 8s/epoch - 5ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 1.0635937
{'0': {'precision': 0.35260048940949934, 'recall': 0.5808921933085501, 'f1-score': 0.43883123123872764, 'support': 121050}, '1': {'precision': 0.4874718961847201, 'recall': 0.29629110030344596, 'f1-score': 0.3685644388284378, 'support': 192456}, '2': {'precision': 0.4022844383373411, 'recall': 0.39252524406083716, 'f1-score': 0.39734492630686036, 'support': 119335}, 'accuracy': 0.40241566764701125, 'macro avg': {'precision': 0.4141189413105202, 'recall': 0.42323617922427775, 'f1-score': 0.40158019879134194, 'support': 432841}, 'weighted avg': {'precision': 0.42626690619449864, 'recall': 0.40241566764701125, 'f1-score': 0.3961503530429026, 'support': 432841}}
[[70317 27609 23124]
 [88959 57023 46474]
 [40148 32345 46842]]
Evaluating performance on  val set...
591/591 - 3s - 3s/epoch - 5ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 1.0723544
{'0': {'precision': 0.36298403350533887, 'recall': 0.5777009350046637, 'f1-score': 0.4458372836124865, 'support': 43957}, '1': {'precision': 0.4537851792596902, 'recall': 0.30184785062401237, 'f1-score': 0.36254127489808363, 'support': 62018}, '2': {'precision': 0.40354700533553767, 'recall': 0.35674742016918376, 'f1-score': 0.3787068489286428, 'support': 45158}, 'accuracy': 0.39848345497012566, 'macro avg': {'precision': 0.4067720727001889, 'recall': 0.4120987352659533, 'f1-score': 0.3956951358130709, 'support': 151133}, 'weighted avg': {'precision': 0.41236469913959134, 'recall': 0.39848345497012566, 'f1-score': 0.3915981165351251, 'support': 151133}}
[[25394 10067  8496]
 [27983 18720 15315]
 [16582 12466 16110]]
training model: results/ATVI/W8/deepOF_L1/h30
Epoch 1/50
1691/1691 - 26s - loss: 3.2232 - accuracy30: 0.4141 - val_loss: 3.2722 - val_accuracy30: 0.3923 - 26s/epoch - 15ms/step
Epoch 2/50
1691/1691 - 23s - loss: 3.2015 - accuracy30: 0.4186 - val_loss: 3.2572 - val_accuracy30: 0.3915 - 23s/epoch - 13ms/step
Epoch 3/50
1691/1691 - 23s - loss: 3.1902 - accuracy30: 0.4222 - val_loss: 3.2533 - val_accuracy30: 0.3948 - 23s/epoch - 14ms/step
Epoch 4/50
1691/1691 - 23s - loss: 3.1809 - accuracy30: 0.4256 - val_loss: 3.2506 - val_accuracy30: 0.3983 - 23s/epoch - 14ms/step
Epoch 5/50
1691/1691 - 24s - loss: 3.1717 - accuracy30: 0.4294 - val_loss: 3.2505 - val_accuracy30: 0.4028 - 24s/epoch - 14ms/step
Epoch 6/50
1691/1691 - 23s - loss: 3.1617 - accuracy30: 0.4342 - val_loss: 3.2499 - val_accuracy30: 0.4011 - 23s/epoch - 14ms/step
Epoch 7/50
1691/1691 - 23s - loss: 3.1537 - accuracy30: 0.4382 - val_loss: 3.2532 - val_accuracy30: 0.4023 - 23s/epoch - 14ms/step
Epoch 8/50
1691/1691 - 24s - loss: 3.1460 - accuracy30: 0.4419 - val_loss: 3.2584 - val_accuracy30: 0.4038 - 24s/epoch - 14ms/step
Epoch 9/50
1691/1691 - 23s - loss: 3.1378 - accuracy30: 0.4456 - val_loss: 3.2544 - val_accuracy30: 0.4037 - 23s/epoch - 14ms/step
Epoch 10/50
1691/1691 - 22s - loss: 3.1303 - accuracy30: 0.4490 - val_loss: 3.2587 - val_accuracy30: 0.4030 - 22s/epoch - 13ms/step
Epoch 11/50
1691/1691 - 23s - loss: 3.1245 - accuracy30: 0.4517 - val_loss: 3.2602 - val_accuracy30: 0.4043 - 23s/epoch - 14ms/step
Epoch 12/50
1691/1691 - 22s - loss: 3.1178 - accuracy30: 0.4542 - val_loss: 3.2677 - val_accuracy30: 0.4058 - 22s/epoch - 13ms/step
Epoch 13/50
1691/1691 - 22s - loss: 3.1115 - accuracy30: 0.4564 - val_loss: 3.2662 - val_accuracy30: 0.4066 - 22s/epoch - 13ms/step
Epoch 14/50
1691/1691 - 22s - loss: 3.1058 - accuracy30: 0.4582 - val_loss: 3.2670 - val_accuracy30: 0.4052 - 22s/epoch - 13ms/step
Epoch 15/50
1691/1691 - 24s - loss: 3.1002 - accuracy30: 0.4601 - val_loss: 3.2705 - val_accuracy30: 0.4065 - 24s/epoch - 14ms/step
Epoch 16/50
1691/1691 - 24s - loss: 3.0943 - accuracy30: 0.4621 - val_loss: 3.2737 - val_accuracy30: 0.4075 - 24s/epoch - 14ms/step
testing model: results/ATVI/W8/deepOF_L1/h30
Evaluating performance on  test set...
4960/4960 - 32s - 32s/epoch - 6ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.0739079
{'0': {'precision': 0.34305951632012416, 'recall': 0.6002827463273711, 'f1-score': 0.43660231660231663, 'support': 357918}, '1': {'precision': 0.46512433864471264, 'recall': 0.21685388618896215, 'f1-score': 0.2957983604851201, 'support': 557011}, '2': {'precision': 0.3856773147701714, 'recall': 0.4171548093565537, 'f1-score': 0.4007989762270718, 'support': 354746}, 'accuracy': 0.3809053497942387, 'macro avg': {'precision': 0.3979537232450028, 'recall': 0.41143048062429566, 'f1-score': 0.37773321777150287, 'support': 1269675}, 'weighted avg': {'precision': 0.4085171667242054, 'recall': 0.3809053497942387, 'f1-score': 0.3648276938165231, 'support': 1269675}}
[[214852  63605  79461]
 [279967 120790 156254]
 [131463  75299 147984]]
Evaluating performance on  train set...
1691/1691 - 12s - 12s/epoch - 7ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.068652
{'0': {'precision': 0.38651726128292097, 'recall': 0.5941280851750282, 'f1-score': 0.468346199087307, 'support': 136378}, '1': {'precision': 0.41494398750396605, 'recall': 0.20891625040704354, 'f1-score': 0.2779101366952044, 'support': 162759}, '2': {'precision': 0.41982387586363124, 'recall': 0.44356189792377193, 'f1-score': 0.43136655901777665, 'support': 133704}, 'accuracy': 0.4027691461760785, 'macro avg': {'precision': 0.4070950415501728, 'recall': 0.41553541116861453, 'f1-score': 0.3925409649334293, 'support': 432841}, 'weighted avg': {'precision': 0.40749478681518425, 'recall': 0.4027691461760785, 'f1-score': 0.3853145341693978, 'support': 432841}}
[[81026 22488 32864]
 [79662 34003 49094]
 [48943 25455 59306]]
Evaluating performance on  val set...
591/591 - 3s - 3s/epoch - 6ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.0779821
{'0': {'precision': 0.3928737455221636, 'recall': 0.5879319869866798, 'f1-score': 0.47100671250952786, 'support': 48873}, '1': {'precision': 0.38173353217182554, 'recall': 0.20202506304259948, 'f1-score': 0.2642179199919438, 'support': 51949}, '2': {'precision': 0.42287434161023324, 'recall': 0.4244797360418199, 'f1-score': 0.4236755180383482, 'support': 50311}, 'accuracy': 0.4008720795590639, 'macro avg': {'precision': 0.39916053976807414, 'recall': 0.40481226202369974, 'f1-score': 0.3863000501799399, 'support': 151133}, 'weighted avg': {'precision': 0.3990314810693317, 'recall': 0.4008720795590639, 'f1-score': 0.3841709406560247, 'support': 151133}}
[[28734  7714 12425]
 [24733 10495 16721]
 [19671  9284 21356]]
training model: results/ATVI/W8/deepOF_L1/h50
Epoch 1/50
1691/1691 - 25s - loss: 3.2477 - accuracy50: 0.4025 - val_loss: 3.2564 - val_accuracy50: 0.3958 - 25s/epoch - 15ms/step
Epoch 2/50
1691/1691 - 23s - loss: 3.2291 - accuracy50: 0.4108 - val_loss: 3.2426 - val_accuracy50: 0.4127 - 23s/epoch - 13ms/step
Epoch 3/50
1691/1691 - 23s - loss: 3.2212 - accuracy50: 0.4125 - val_loss: 3.2388 - val_accuracy50: 0.4143 - 23s/epoch - 14ms/step
Epoch 4/50
1691/1691 - 24s - loss: 3.2136 - accuracy50: 0.4153 - val_loss: 3.2374 - val_accuracy50: 0.4148 - 24s/epoch - 14ms/step
Epoch 5/50
1691/1691 - 23s - loss: 3.2064 - accuracy50: 0.4189 - val_loss: 3.2375 - val_accuracy50: 0.4152 - 23s/epoch - 13ms/step
Epoch 6/50
1691/1691 - 24s - loss: 3.1988 - accuracy50: 0.4225 - val_loss: 3.2404 - val_accuracy50: 0.4140 - 24s/epoch - 14ms/step
Epoch 7/50
1691/1691 - 23s - loss: 3.1924 - accuracy50: 0.4262 - val_loss: 3.2422 - val_accuracy50: 0.4108 - 23s/epoch - 14ms/step
Epoch 8/50
1691/1691 - 22s - loss: 3.1858 - accuracy50: 0.4294 - val_loss: 3.2464 - val_accuracy50: 0.4079 - 22s/epoch - 13ms/step
Epoch 9/50
1691/1691 - 22s - loss: 3.1802 - accuracy50: 0.4315 - val_loss: 3.2448 - val_accuracy50: 0.4078 - 22s/epoch - 13ms/step
Epoch 10/50
1691/1691 - 22s - loss: 3.1745 - accuracy50: 0.4338 - val_loss: 3.2468 - val_accuracy50: 0.4052 - 22s/epoch - 13ms/step
Epoch 11/50
1691/1691 - 22s - loss: 3.1695 - accuracy50: 0.4366 - val_loss: 3.2508 - val_accuracy50: 0.4007 - 22s/epoch - 13ms/step
Epoch 12/50
1691/1691 - 22s - loss: 3.1653 - accuracy50: 0.4377 - val_loss: 3.2530 - val_accuracy50: 0.3994 - 22s/epoch - 13ms/step
Epoch 13/50
1691/1691 - 23s - loss: 3.1617 - accuracy50: 0.4388 - val_loss: 3.2527 - val_accuracy50: 0.3987 - 23s/epoch - 14ms/step
Epoch 14/50
1691/1691 - 23s - loss: 3.1573 - accuracy50: 0.4409 - val_loss: 3.2541 - val_accuracy50: 0.3978 - 23s/epoch - 14ms/step
testing model: results/ATVI/W8/deepOF_L1/h50
Evaluating performance on  test set...
4960/4960 - 28s - 28s/epoch - 6ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0826004
{'0': {'precision': 0.37039311131723895, 'recall': 0.5758375489410359, 'f1-score': 0.45081240827124835, 'support': 391798}, '1': {'precision': 0.41913967848675127, 'recall': 0.03309578376954949, 'f1-score': 0.06134749406526775, 'support': 486074}, '2': {'precision': 0.3810993299355973, 'recall': 0.605181685694086, 'f1-score': 0.46768483069719186, 'support': 391803}, 'accuracy': 0.3771130407387717, 'macro avg': {'precision': 0.3902107065798625, 'recall': 0.40470500613489047, 'f1-score': 0.32661491101123596, 'support': 1269675}, 'weighted avg': {'precision': 0.39235870681504914, 'recall': 0.3771130407387717, 'f1-score': 0.3069188111034646, 'support': 1269675}}
[[225612  10489 155697]
 [240617  16087 229370]
 [142886  11805 237112]]
Evaluating performance on  train set...
1691/1691 - 10s - 10s/epoch - 6ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0769005
{'0': {'precision': 0.40769776979147043, 'recall': 0.5766778947656106, 'f1-score': 0.4776840794612032, 'support': 146359}, '1': {'precision': 0.36709758789216457, 'recall': 0.03243578313924333, 'f1-score': 0.05960502233428473, 'support': 143576}, '2': {'precision': 0.40306098510796023, 'recall': 0.6011364113473192, 'f1-score': 0.48256375688124925, 'support': 142906}, 'accuracy': 0.4042246460016496, 'macro avg': {'precision': 0.39261878093053176, 'recall': 0.40341669641739103, 'f1-score': 0.33995095289224575, 'support': 432841}, 'weighted avg': {'precision': 0.3926995693706312, 'recall': 0.4042246460016496, 'f1-score': 0.3406157714112141, 'support': 432841}}
[[84402  3983 57974]
 [69665  4657 69254]
 [52954  4046 85906]]
Evaluating performance on  val set...
591/591 - 3s - 3s/epoch - 6ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0793018
{'0': {'precision': 0.4154458070931389, 'recall': 0.5957450853644626, 'f1-score': 0.4895214141209002, 'support': 52598}, '1': {'precision': 0.33470773708464713, 'recall': 0.030651681400204345, 'f1-score': 0.05616034184555906, 'support': 45022}, '2': {'precision': 0.42049312006705314, 'recall': 0.5624988320594996, 'f1-score': 0.48123870885225983, 'support': 53513}, 'accuracy': 0.41563391185247434, 'macro avg': {'precision': 0.39021555474827974, 'recall': 0.39629853294138884, 'f1-score': 0.3423068216062397, 'support': 151133}, 'weighted avg': {'precision': 0.3931813610175019, 'recall': 0.41563391185247434, 'f1-score': 0.3574919129330646, 'support': 151133}}
[[31335  1257 20006]
 [22164  1380 21478]
 [21926  1486 30101]]
training model: results/ATVI/W8/deepOF_L1/h100
Epoch 1/50
1691/1691 - 25s - loss: 3.2771 - accuracy100: 0.3843 - val_loss: 3.3641 - val_accuracy100: 0.2968 - 25s/epoch - 15ms/step
Epoch 2/50
1691/1691 - 23s - loss: 3.2619 - accuracy100: 0.3896 - val_loss: 3.3294 - val_accuracy100: 0.3071 - 23s/epoch - 14ms/step
Epoch 3/50
1691/1691 - 23s - loss: 3.2558 - accuracy100: 0.3928 - val_loss: 3.3102 - val_accuracy100: 0.3247 - 23s/epoch - 13ms/step
Epoch 4/50
1691/1691 - 24s - loss: 3.2509 - accuracy100: 0.3967 - val_loss: 3.3101 - val_accuracy100: 0.3266 - 24s/epoch - 14ms/step
Epoch 5/50
1691/1691 - 23s - loss: 3.2467 - accuracy100: 0.3995 - val_loss: 3.3152 - val_accuracy100: 0.3247 - 23s/epoch - 14ms/step
Epoch 6/50
1691/1691 - 23s - loss: 3.2429 - accuracy100: 0.4018 - val_loss: 3.3223 - val_accuracy100: 0.3204 - 23s/epoch - 14ms/step
Epoch 7/50
1691/1691 - 23s - loss: 3.2385 - accuracy100: 0.4047 - val_loss: 3.3280 - val_accuracy100: 0.3201 - 23s/epoch - 13ms/step
Epoch 8/50
1691/1691 - 23s - loss: 3.2353 - accuracy100: 0.4072 - val_loss: 3.3324 - val_accuracy100: 0.3193 - 23s/epoch - 13ms/step
Epoch 9/50
1691/1691 - 22s - loss: 3.2332 - accuracy100: 0.4085 - val_loss: 3.3312 - val_accuracy100: 0.3211 - 22s/epoch - 13ms/step
Epoch 10/50
1691/1691 - 22s - loss: 3.2307 - accuracy100: 0.4095 - val_loss: 3.3344 - val_accuracy100: 0.3185 - 22s/epoch - 13ms/step
Epoch 11/50
1691/1691 - 22s - loss: 3.2280 - accuracy100: 0.4111 - val_loss: 3.3395 - val_accuracy100: 0.3172 - 22s/epoch - 13ms/step
Epoch 12/50
1691/1691 - 22s - loss: 3.2258 - accuracy100: 0.4126 - val_loss: 3.3370 - val_accuracy100: 0.3186 - 22s/epoch - 13ms/step
Epoch 13/50
1691/1691 - 23s - loss: 3.2236 - accuracy100: 0.4143 - val_loss: 3.3390 - val_accuracy100: 0.3204 - 23s/epoch - 13ms/step
Epoch 14/50
1691/1691 - 23s - loss: 3.2221 - accuracy100: 0.4150 - val_loss: 3.3375 - val_accuracy100: 0.3216 - 23s/epoch - 13ms/step
testing model: results/ATVI/W8/deepOF_L1/h100
Evaluating performance on  test set...
4960/4960 - 27s - 27s/epoch - 6ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0944613
{'0': {'precision': 0.4312681311697231, 'recall': 0.1964567140552366, 'f1-score': 0.26994477141010154, 'support': 428303}, '1': {'precision': 0.3267308425447221, 'recall': 0.7627409232440612, 'f1-score': 0.4574895693867592, 'support': 412372}, '2': {'precision': 0.44408500294900893, 'recall': 0.11583682983682983, 'f1-score': 0.18374492976546583, 'support': 429000}, 'accuracy': 0.3531376139563274, 'macro avg': {'precision': 0.400694658887818, 'recall': 0.3583448223787092, 'f1-score': 0.30372642352077556, 'support': 1269675}, 'weighted avg': {'precision': 0.40164652501731773, 'recall': 0.3531376139563274, 'f1-score': 0.30173124540201407, 'support': 1269675}}
[[ 84143 315853  28307]
 [ 63938 314533  33901]
 [ 47025 332281  49694]]
Evaluating performance on  train set...
1691/1691 - 11s - 11s/epoch - 6ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.092346
{'0': {'precision': 0.4317582817619221, 'recall': 0.20142795032743677, 'f1-score': 0.27470017926708945, 'support': 147204}, '1': {'precision': 0.33488687086347546, 'recall': 0.7572022189585929, 'f1-score': 0.46438900284085455, 'support': 143671}, '2': {'precision': 0.44111811984942517, 'recall': 0.12216305312539621, 'f1-score': 0.19133725356075065, 'support': 141966}, 'accuracy': 0.3599058314716027, 'macro avg': {'precision': 0.4025877574916075, 'recall': 0.3602644074704753, 'f1-score': 0.31014214522289824, 'support': 432841}, 'weighted avg': {'precision': 0.40267408294235496, 'recall': 0.3599058314716027, 'f1-score': 0.31032083872596766, 'support': 432841}}
[[ 29651 107792   9761]
 [ 22671 108788  12212]
 [ 16353 108270  17343]]
Evaluating performance on  val set...
591/591 - 3s - 3s/epoch - 5ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.1040986
{'0': {'precision': 0.43963701803423055, 'recall': 0.21529288232205804, 'f1-score': 0.2890407682916084, 'support': 53332}, '1': {'precision': 0.28593560794928413, 'recall': 0.7411151112341918, 'f1-score': 0.4126596592223279, 'support': 43332}, '2': {'precision': 0.44670969773299746, 'recall': 0.10418770309717454, 'f1-score': 0.1689666979292275, 'support': 54469}, 'accuracy': 0.32601086460270096, 'macro avg': {'precision': 0.3907607745721707, 'recall': 0.35353189888447484, 'f1-score': 0.29022237514772126, 'support': 151133}, 'weighted avg': {'precision': 0.3981176429719426, 'recall': 0.32601086460270096, 'f1-score': 0.28120885364187215, 'support': 151133}}
[[11482 38522  3328]
 [ 7517 32114  3701]
 [ 7118 41676  5675]]
training model: results/ATVI/W8/deepOF_L1/h200
Epoch 1/50
1691/1691 - 25s - loss: 3.2957 - accuracy200: 0.3663 - val_loss: 3.2943 - val_accuracy200: 0.3456 - 25s/epoch - 15ms/step
Epoch 2/50
1691/1691 - 22s - loss: 3.2794 - accuracy200: 0.3708 - val_loss: 3.2872 - val_accuracy200: 0.3596 - 22s/epoch - 13ms/step
Epoch 3/50
1691/1691 - 22s - loss: 3.2754 - accuracy200: 0.3741 - val_loss: 3.2814 - val_accuracy200: 0.3764 - 22s/epoch - 13ms/step
Epoch 4/50
1691/1691 - 23s - loss: 3.2732 - accuracy200: 0.3756 - val_loss: 3.2800 - val_accuracy200: 0.3788 - 23s/epoch - 13ms/step
Epoch 5/50
1691/1691 - 23s - loss: 3.2719 - accuracy200: 0.3762 - val_loss: 3.2784 - val_accuracy200: 0.3829 - 23s/epoch - 13ms/step
Epoch 6/50
1691/1691 - 23s - loss: 3.2704 - accuracy200: 0.3776 - val_loss: 3.2777 - val_accuracy200: 0.3835 - 23s/epoch - 14ms/step
Epoch 7/50
1691/1691 - 23s - loss: 3.2688 - accuracy200: 0.3784 - val_loss: 3.2797 - val_accuracy200: 0.3808 - 23s/epoch - 14ms/step
Epoch 8/50
1691/1691 - 23s - loss: 3.2678 - accuracy200: 0.3797 - val_loss: 3.2792 - val_accuracy200: 0.3829 - 23s/epoch - 14ms/step
Epoch 9/50
1691/1691 - 23s - loss: 3.2671 - accuracy200: 0.3800 - val_loss: 3.2790 - val_accuracy200: 0.3829 - 23s/epoch - 13ms/step
Epoch 10/50
1691/1691 - 23s - loss: 3.2653 - accuracy200: 0.3810 - val_loss: 3.2810 - val_accuracy200: 0.3808 - 23s/epoch - 13ms/step
Epoch 11/50
1691/1691 - 23s - loss: 3.2645 - accuracy200: 0.3823 - val_loss: 3.2815 - val_accuracy200: 0.3785 - 23s/epoch - 13ms/step
Epoch 12/50
1691/1691 - 22s - loss: 3.2630 - accuracy200: 0.3844 - val_loss: 3.2821 - val_accuracy200: 0.3778 - 22s/epoch - 13ms/step
Epoch 13/50
1691/1691 - 23s - loss: 3.2620 - accuracy200: 0.3842 - val_loss: 3.2831 - val_accuracy200: 0.3757 - 23s/epoch - 13ms/step
Epoch 14/50
1691/1691 - 22s - loss: 3.2607 - accuracy200: 0.3851 - val_loss: 3.2830 - val_accuracy200: 0.3766 - 22s/epoch - 13ms/step
Epoch 15/50
1691/1691 - 23s - loss: 3.2597 - accuracy200: 0.3853 - val_loss: 3.2844 - val_accuracy200: 0.3735 - 23s/epoch - 13ms/step
Epoch 16/50
1691/1691 - 24s - loss: 3.2592 - accuracy200: 0.3859 - val_loss: 3.2838 - val_accuracy200: 0.3751 - 24s/epoch - 14ms/step
testing model: results/ATVI/W8/deepOF_L1/h200
Evaluating performance on  test set...
4960/4960 - 32s - 32s/epoch - 6ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0923446
{'0': {'precision': 0.3633370879042868, 'recall': 0.463613767515562, 'f1-score': 0.407395615101981, 'support': 413989}, '1': {'precision': 0.37166153649295164, 'recall': 0.119851818569444, 'f1-score': 0.18125371602706222, 'support': 436222}, '2': {'precision': 0.36855710859096574, 'recall': 0.5278498273987756, 'f1-score': 0.434050202749791, 'support': 419464}, 'accuracy': 0.36672928111524605, 'macro avg': {'precision': 0.36785191099606807, 'recall': 0.37043847116126055, 'f1-score': 0.3408998446262781, 'support': 1269675}, 'weighted avg': {'precision': 0.36792166141291033, 'recall': 0.36672928111524605, 'f1-score': 0.33850599252521274, 'support': 1269675}}
[[191931  43482 178576]
 [183171  52282 200769]
 [153143  44907 221414]]
Evaluating performance on  train set...
1691/1691 - 11s - 11s/epoch - 7ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0918767
{'0': {'precision': 0.38483931989895903, 'recall': 0.45954902676892695, 'f1-score': 0.41888909438382343, 'support': 147858}, '1': {'precision': 0.35930919987042437, 'recall': 0.1244888081425936, 'f1-score': 0.18491177435908124, 'support': 142559}, '2': {'precision': 0.3691193743444489, 'recall': 0.5361877211705892, 'f1-score': 0.43723787684899695, 'support': 142424}, 'accuracy': 0.3744123130664609, 'macro avg': {'precision': 0.3710892980379441, 'recall': 0.3734085186940366, 'f1-score': 0.3470129151973005, 'support': 432841}, 'weighted avg': {'precision': 0.37125824530851265, 'recall': 0.3744123130664609, 'f1-score': 0.3478647095136578, 'support': 432841}}
[[67948 16180 63730]
 [58021 17747 66791]
 [50593 15465 76366]]
Evaluating performance on  val set...
591/591 - 4s - 4s/epoch - 6ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0929626
{'0': {'precision': 0.3891558914993974, 'recall': 0.4947693006186035, 'f1-score': 0.4356531298930606, 'support': 52861}, '1': {'precision': 0.3286619718309859, 'recall': 0.10363971486309431, 'f1-score': 0.15758639901402982, 'support': 45031}, '2': {'precision': 0.3909588962510398, 'recall': 0.5120114197704776, 'f1-score': 0.44337098571161365, 'support': 53241}, 'accuracy': 0.3843038912745727, 'macro avg': {'precision': 0.3695922531938077, 'recall': 0.3701401450840585, 'f1-score': 0.3455368382062347, 'support': 151133}, 'weighted avg': {'precision': 0.3717665197499711, 'recall': 0.3843038912745727, 'f1-score': 0.3555202893051146, 'support': 151133}}
[[26154  4829 21878]
 [19776  4667 20588]
 [21277  4704 27260]]
training model: results/ATVI/W8/deepOF_L1/h300
Epoch 1/50
1691/1691 - 26s - loss: 3.2962 - accuracy300: 0.3655 - val_loss: 3.7264 - val_accuracy300: 0.2773 - 26s/epoch - 15ms/step
Epoch 2/50
1691/1691 - 22s - loss: 3.2879 - accuracy300: 0.3678 - val_loss: 3.5567 - val_accuracy300: 0.2771 - 22s/epoch - 13ms/step
Epoch 3/50
1691/1691 - 23s - loss: 3.2835 - accuracy300: 0.3678 - val_loss: 3.5189 - val_accuracy300: 0.2767 - 23s/epoch - 13ms/step
Epoch 4/50
1691/1691 - 24s - loss: 3.2858 - accuracy300: 0.3651 - val_loss: 3.3633 - val_accuracy300: 0.2767 - 24s/epoch - 14ms/step
Epoch 5/50
1691/1691 - 24s - loss: 3.2823 - accuracy300: 0.3665 - val_loss: 3.3536 - val_accuracy300: 0.2768 - 24s/epoch - 14ms/step
Epoch 6/50
1691/1691 - 22s - loss: 3.2815 - accuracy300: 0.3667 - val_loss: 3.3512 - val_accuracy300: 0.2769 - 22s/epoch - 13ms/step
Epoch 7/50
1691/1691 - 22s - loss: 3.2800 - accuracy300: 0.3690 - val_loss: 3.3529 - val_accuracy300: 0.2768 - 22s/epoch - 13ms/step
Epoch 8/50
1691/1691 - 23s - loss: 3.2789 - accuracy300: 0.3699 - val_loss: 3.3568 - val_accuracy300: 0.2768 - 23s/epoch - 13ms/step
Epoch 9/50
1691/1691 - 22s - loss: 3.2784 - accuracy300: 0.3700 - val_loss: 3.3537 - val_accuracy300: 0.2767 - 22s/epoch - 13ms/step
Epoch 10/50
1691/1691 - 23s - loss: 3.2771 - accuracy300: 0.3715 - val_loss: 3.3587 - val_accuracy300: 0.2770 - 23s/epoch - 14ms/step
Epoch 11/50
1691/1691 - 22s - loss: 3.2763 - accuracy300: 0.3719 - val_loss: 3.3692 - val_accuracy300: 0.2767 - 22s/epoch - 13ms/step
Epoch 12/50
1691/1691 - 22s - loss: 3.2761 - accuracy300: 0.3724 - val_loss: 3.3608 - val_accuracy300: 0.2768 - 22s/epoch - 13ms/step
Epoch 13/50
1691/1691 - 22s - loss: 3.2748 - accuracy300: 0.3740 - val_loss: 3.3654 - val_accuracy300: 0.2769 - 22s/epoch - 13ms/step
Epoch 14/50
1691/1691 - 23s - loss: 3.2741 - accuracy300: 0.3745 - val_loss: 3.3725 - val_accuracy300: 0.2769 - 23s/epoch - 14ms/step
Epoch 15/50
1691/1691 - 23s - loss: 3.2734 - accuracy300: 0.3749 - val_loss: 3.3810 - val_accuracy300: 0.2771 - 23s/epoch - 14ms/step
Epoch 16/50
1691/1691 - 23s - loss: 3.2722 - accuracy300: 0.3761 - val_loss: 3.3872 - val_accuracy300: 0.2767 - 23s/epoch - 14ms/step
testing model: results/ATVI/W8/deepOF_L1/h300
Evaluating performance on  test set...
4960/4960 - 30s - 30s/epoch - 6ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1146443
{'0': {'precision': 0.4069506726457399, 'recall': 0.0008344750852865721, 'f1-score': 0.001665534898232606, 'support': 435004}, '1': {'precision': 0.30957982025350245, 'recall': 0.9969661212635991, 'f1-score': 0.4724527210443701, 'support': 393226}, '2': {'precision': 0.396481178396072, 'recall': 0.0021950639377498896, 'f1-score': 0.0043659563539533534, 'support': 441445}, 'accuracy': 0.30981550396755075, 'macro avg': {'precision': 0.37100389043177145, 'recall': 0.33333188676221187, 'f1-score': 0.15949473743218537, 'support': 1269675}, 'weighted avg': {'precision': 0.37315426278350383, 'recall': 0.30981550396755075, 'f1-score': 0.14841005582604616, 'support': 1269675}}
[[   363 434038    603]
 [   321 392033    872]
 [   208 440268    969]]
Evaluating performance on  train set...
1691/1691 - 9s - 9s/epoch - 5ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1124936
{'0': {'precision': 0.4043887147335423, 'recall': 0.000852419152338536, 'f1-score': 0.0017012522007477597, 'support': 151334}, '1': {'precision': 0.31554748464893484, 'recall': 0.9972694796638458, 'f1-score': 0.4794055597686567, 'support': 136604}, '2': {'precision': 0.4274905422446406, 'recall': 0.002339496076685783, 'f1-score': 0.004653525148253899, 'support': 144903}, 'accuracy': 0.31581804865990054, 'macro avg': {'precision': 0.3824755805423726, 'recall': 0.3334871316309567, 'f1-score': 0.16192011237255277, 'support': 432841}, 'weighted avg': {'precision': 0.384084392170206, 'recall': 0.31581804865990054, 'f1-score': 0.153452385845479, 'support': 432841}}
[[   129 151007    198]
 [   117 136231    256]
 [    73 144491    339]]
Evaluating performance on  val set...
591/591 - 3s - 3s/epoch - 6ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1255546
{'0': {'precision': 0.4536082474226804, 'recall': 0.0008100743795566684, 'f1-score': 0.0016172605811111316, 'support': 54316}, '1': {'precision': 0.27647601414796974, 'recall': 0.9964125989524789, 'f1-score': 0.4328488462697267, 'support': 41813}, '2': {'precision': 0.37026239067055394, 'recall': 0.0023089229874190967, 'f1-score': 0.0045892279617684795, 'support': 55004}, 'accuracy': 0.27680255139512877, 'macro avg': {'precision': 0.36678221741373473, 'recall': 0.3331771987731516, 'f1-score': 0.14635177827086876, 'support': 151133}, 'weighted avg': {'precision': 0.37426895306135993, 'recall': 0.27680255139512877, 'f1-score': 0.1220049746224109, 'support': 151133}}
[[   44 54184    88]
 [   22 41663   128]
 [   31 54846   127]]
training model: results/ATVI/W8/deepOF_L1/h500
Epoch 1/50
1691/1691 - 25s - loss: 3.2822 - accuracy500: 0.3859 - val_loss: 3.4102 - val_accuracy500: 0.2807 - 25s/epoch - 15ms/step
Epoch 2/50
1691/1691 - 23s - loss: 3.2755 - accuracy500: 0.3837 - val_loss: 3.3315 - val_accuracy500: 0.2849 - 23s/epoch - 13ms/step
Epoch 3/50
1691/1691 - 23s - loss: 3.2774 - accuracy500: 0.3777 - val_loss: 3.3050 - val_accuracy500: 0.2936 - 23s/epoch - 14ms/step
Epoch 4/50
1691/1691 - 23s - loss: 3.2792 - accuracy500: 0.3730 - val_loss: 3.2980 - val_accuracy500: 0.3143 - 23s/epoch - 14ms/step
Epoch 5/50
1691/1691 - 23s - loss: 3.2765 - accuracy500: 0.3756 - val_loss: 3.3019 - val_accuracy500: 0.3063 - 23s/epoch - 14ms/step
Epoch 6/50
1691/1691 - 22s - loss: 3.2743 - accuracy500: 0.3772 - val_loss: 3.3048 - val_accuracy500: 0.2993 - 22s/epoch - 13ms/step
Epoch 7/50
1691/1691 - 22s - loss: 3.2716 - accuracy500: 0.3798 - val_loss: 3.3098 - val_accuracy500: 0.2927 - 22s/epoch - 13ms/step
Epoch 8/50
1691/1691 - 22s - loss: 3.2699 - accuracy500: 0.3814 - val_loss: 3.3117 - val_accuracy500: 0.2901 - 22s/epoch - 13ms/step
Epoch 9/50
1691/1691 - 23s - loss: 3.2690 - accuracy500: 0.3818 - val_loss: 3.3143 - val_accuracy500: 0.2873 - 23s/epoch - 13ms/step
Epoch 10/50
1691/1691 - 22s - loss: 3.2676 - accuracy500: 0.3830 - val_loss: 3.3174 - val_accuracy500: 0.2898 - 22s/epoch - 13ms/step
Epoch 11/50
1691/1691 - 22s - loss: 3.2652 - accuracy500: 0.3848 - val_loss: 3.3171 - val_accuracy500: 0.2886 - 22s/epoch - 13ms/step
Epoch 12/50
1691/1691 - 22s - loss: 3.2645 - accuracy500: 0.3847 - val_loss: 3.3166 - val_accuracy500: 0.2874 - 22s/epoch - 13ms/step
Epoch 13/50
1691/1691 - 23s - loss: 3.2638 - accuracy500: 0.3855 - val_loss: 3.3163 - val_accuracy500: 0.2880 - 23s/epoch - 14ms/step
Epoch 14/50
1691/1691 - 23s - loss: 3.2622 - accuracy500: 0.3859 - val_loss: 3.3177 - val_accuracy500: 0.2874 - 23s/epoch - 14ms/step
testing model: results/ATVI/W8/deepOF_L1/h500
Evaluating performance on  test set...
4960/4960 - 28s - 28s/epoch - 6ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.102192
{'0': {'precision': 0.4028717960824122, 'recall': 0.14513790258795914, 'f1-score': 0.2133975644486404, 'support': 470332}, '1': {'precision': 0.2466812009205853, 'recall': 0.6282804395465796, 'f1-score': 0.354266898511146, 'support': 317145}, '2': {'precision': 0.4084967878914276, 'recall': 0.2477820314476626, 'f1-score': 0.3084608582843349, 'support': 482198}, 'accuracy': 0.3048016224624412, 'macro avg': {'precision': 0.352683261631475, 'recall': 0.3404001245274004, 'f1-score': 0.29204177374804047, 'support': 1269675}, 'weighted avg': {'precision': 0.36599408603671235, 'recall': 0.3048016224624412, 'f1-score': 0.2846877254049777, 'support': 1269675}}
[[ 68263 301967 100102]
 [ 44984 199256  72905]
 [ 56194 306524 119480]]
Evaluating performance on  train set...
1691/1691 - 9s - 9s/epoch - 5ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0980256
{'0': {'precision': 0.3760874598921637, 'recall': 0.15374265565945247, 'f1-score': 0.21826122429390732, 'support': 147903}, '1': {'precision': 0.3264592607778819, 'recall': 0.6298506830157228, 'f1-score': 0.430029175608227, 'support': 141578}, '2': {'precision': 0.35763451479939934, 'recall': 0.24753766741071428, 'f1-score': 0.2925713249267273, 'support': 143360}, 'accuracy': 0.34053844252277393, 'macro avg': {'precision': 0.35339374515648164, 'recall': 0.3437103353619632, 'f1-score': 0.31362057494295387, 'support': 432841}, 'weighted avg': {'precision': 0.35374282206279806, 'recall': 0.34053844252277393, 'f1-score': 0.31214045255070333, 'support': 432841}}
[[22739 93799 31365]
 [20030 89173 32375]
 [17693 90180 35487]]
Evaluating performance on  val set...
591/591 - 4s - 4s/epoch - 6ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1011459
{'0': {'precision': 0.391893619741721, 'recall': 0.16909100939700988, 'f1-score': 0.23624778397266258, 'support': 54379}, '1': {'precision': 0.2772443009885011, 'recall': 0.649326718639263, 'f1-score': 0.3885770834805966, 'support': 42330}, '2': {'precision': 0.3740974412898703, 'recall': 0.1961083345582831, 'f1-score': 0.25732333582467387, 'support': 54424}, 'accuracy': 0.3133266725334639, 'macro avg': {'precision': 0.34774512067336416, 'recall': 0.3381753541981853, 'f1-score': 0.2940494010926444, 'support': 151133}, 'weighted avg': {'precision': 0.3533736083683789, 'recall': 0.3133266725334639, 'f1-score': 0.2865022954437821, 'support': 151133}}
[[ 9195 35512  9672]
 [ 6659 27486  8185]
 [ 7609 36142 10673]]
training model: results/ATVI/W8/deepOF_L1/h1000
Epoch 1/50
1691/1691 - 25s - loss: 3.3028 - accuracy1000: 0.3700 - val_loss: 3.2954 - val_accuracy1000: 0.3496 - 25s/epoch - 15ms/step
Epoch 2/50
1691/1691 - 23s - loss: 3.2882 - accuracy1000: 0.3681 - val_loss: 3.2905 - val_accuracy1000: 0.3571 - 23s/epoch - 14ms/step
Epoch 3/50
1691/1691 - 23s - loss: 3.2837 - accuracy1000: 0.3672 - val_loss: 3.2896 - val_accuracy1000: 0.3584 - 23s/epoch - 14ms/step
Epoch 4/50
1691/1691 - 23s - loss: 3.2816 - accuracy1000: 0.3671 - val_loss: 3.2880 - val_accuracy1000: 0.3610 - 23s/epoch - 14ms/step
Epoch 5/50
1691/1691 - 24s - loss: 3.2790 - accuracy1000: 0.3692 - val_loss: 3.2876 - val_accuracy1000: 0.3624 - 24s/epoch - 14ms/step
Epoch 6/50
1691/1691 - 23s - loss: 3.2755 - accuracy1000: 0.3716 - val_loss: 3.2872 - val_accuracy1000: 0.3639 - 23s/epoch - 13ms/step
Epoch 7/50
1691/1691 - 22s - loss: 3.2727 - accuracy1000: 0.3747 - val_loss: 3.2878 - val_accuracy1000: 0.3631 - 22s/epoch - 13ms/step
Epoch 8/50
1691/1691 - 23s - loss: 3.2708 - accuracy1000: 0.3760 - val_loss: 3.2875 - val_accuracy1000: 0.3633 - 23s/epoch - 13ms/step
Epoch 9/50
1691/1691 - 22s - loss: 3.2684 - accuracy1000: 0.3776 - val_loss: 3.2880 - val_accuracy1000: 0.3631 - 22s/epoch - 13ms/step
Epoch 10/50
1691/1691 - 23s - loss: 3.2670 - accuracy1000: 0.3788 - val_loss: 3.2886 - val_accuracy1000: 0.3616 - 23s/epoch - 13ms/step
Epoch 11/50
1691/1691 - 22s - loss: 3.2656 - accuracy1000: 0.3799 - val_loss: 3.2884 - val_accuracy1000: 0.3618 - 22s/epoch - 13ms/step
Epoch 12/50
1691/1691 - 22s - loss: 3.2632 - accuracy1000: 0.3815 - val_loss: 3.2899 - val_accuracy1000: 0.3580 - 22s/epoch - 13ms/step
Epoch 13/50
1691/1691 - 22s - loss: 3.2621 - accuracy1000: 0.3818 - val_loss: 3.2891 - val_accuracy1000: 0.3597 - 22s/epoch - 13ms/step
Epoch 14/50
1691/1691 - 23s - loss: 3.2608 - accuracy1000: 0.3829 - val_loss: 3.2897 - val_accuracy1000: 0.3590 - 23s/epoch - 14ms/step
Epoch 15/50
1691/1691 - 24s - loss: 3.2596 - accuracy1000: 0.3833 - val_loss: 3.2906 - val_accuracy1000: 0.3576 - 24s/epoch - 14ms/step
Epoch 16/50
1691/1691 - 23s - loss: 3.2580 - accuracy1000: 0.3851 - val_loss: 3.2906 - val_accuracy1000: 0.3573 - 23s/epoch - 13ms/step
testing model: results/ATVI/W8/deepOF_L1/h1000
Evaluating performance on  test set...
4960/4960 - 31s - 31s/epoch - 6ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0993751
{'0': {'precision': 0.33763165535992395, 'recall': 0.2507750636593788, 'f1-score': 0.2877927703049522, 'support': 408031}, '1': {'precision': 0.37507753380473885, 'recall': 0.014031692551159871, 'f1-score': 0.027051389587876753, 'support': 430953}, '2': {'precision': 0.346997177242451, 'recall': 0.7657856792921143, 'f1-score': 0.4775872804413618, 'support': 430691}, 'accuracy': 0.3451182389194085, 'macro avg': {'precision': 0.35323545546903795, 'recall': 0.3435308118342177, 'f1-score': 0.26414381344473026, 'support': 1269675}, 'weighted avg': {'precision': 0.35351844500178964, 'recall': 0.3451182389194085, 'f1-score': 0.26367282395726055, 'support': 1269675}}
[[102324   4858 300849]
 [105083   6047 319823]
 [ 95657   5217 329817]]
Evaluating performance on  train set...
1691/1691 - 11s - 11s/epoch - 7ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0980105
{'0': {'precision': 0.3653533174368873, 'recall': 0.2586808695943456, 'f1-score': 0.3028997956454036, 'support': 149265}, '1': {'precision': 0.35922483062864347, 'recall': 0.016418942274455582, 'f1-score': 0.03140257969437577, 'support': 138864}, '2': {'precision': 0.34195941523019857, 'recall': 0.7580850240477638, 'f1-score': 0.4713160709912742, 'support': 144712}, 'accuracy': 0.3479245265582512, 'macro avg': {'precision': 0.3555125210985765, 'recall': 0.34439494530552167, 'f1-score': 0.2685394821103512, 'support': 432841}, 'weighted avg': {'precision': 0.3555658791667735, 'recall': 0.3479245265582512, 'f1-score': 0.2721048077445996, 'support': 432841}}
[[ 38612   2185 108468]
 [ 33946   2280 102638]
 [ 33126   1882 109704]]
Evaluating performance on  val set...
591/591 - 3s - 3s/epoch - 5ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.096168
{'0': {'precision': 0.3751273390166747, 'recall': 0.26520478365521294, 'f1-score': 0.3107311386221063, 'support': 52763}, '1': {'precision': 0.36251236399604353, 'recall': 0.01621466177056143, 'f1-score': 0.031040907935970186, 'support': 45206}, '2': {'precision': 0.36169718001234247, 'recall': 0.7606839214506057, 'f1-score': 0.4902741660756609, 'support': 53164}, 'accuracy': 0.3650228606591545, 'macro avg': {'precision': 0.36644562767502026, 'recall': 0.34736778895879333, 'f1-score': 0.2773487375445791, 'support': 151133}, 'weighted avg': {'precision': 0.3666297009489531, 'recall': 0.3650228606591545, 'f1-score': 0.29022965279930985, 'support': 151133}}
[[13993   662 38108]
 [11213   733 33260]
 [12096   627 40441]]
training model: results/ATVI/W8/deepLOB_L2/h10
Epoch 1/50
1691/1691 - 74s - loss: 3.0274 - accuracy10: 0.4650 - val_loss: 3.6573 - val_accuracy10: 0.4693 - 74s/epoch - 44ms/step
Epoch 2/50
1691/1691 - 71s - loss: 2.8365 - accuracy10: 0.5157 - val_loss: 3.3122 - val_accuracy10: 0.5139 - 71s/epoch - 42ms/step
Epoch 3/50
1691/1691 - 69s - loss: 2.7560 - accuracy10: 0.5453 - val_loss: 3.1359 - val_accuracy10: 0.5133 - 69s/epoch - 41ms/step
Epoch 4/50
1691/1691 - 70s - loss: 2.7020 - accuracy10: 0.5630 - val_loss: 3.0751 - val_accuracy10: 0.5167 - 70s/epoch - 41ms/step
Epoch 5/50
1691/1691 - 70s - loss: 2.6625 - accuracy10: 0.5725 - val_loss: 3.0791 - val_accuracy10: 0.5139 - 70s/epoch - 41ms/step
Epoch 6/50
1691/1691 - 69s - loss: 2.6357 - accuracy10: 0.5794 - val_loss: 3.0409 - val_accuracy10: 0.5121 - 69s/epoch - 41ms/step
Epoch 7/50
1691/1691 - 69s - loss: 2.6165 - accuracy10: 0.5837 - val_loss: 3.0267 - val_accuracy10: 0.5234 - 69s/epoch - 41ms/step
Epoch 8/50
1691/1691 - 70s - loss: 2.6002 - accuracy10: 0.5867 - val_loss: 3.0608 - val_accuracy10: 0.5260 - 70s/epoch - 42ms/step
Epoch 9/50
1691/1691 - 69s - loss: 2.5876 - accuracy10: 0.5894 - val_loss: 3.0579 - val_accuracy10: 0.5267 - 69s/epoch - 41ms/step
Epoch 10/50
1691/1691 - 69s - loss: 2.5755 - accuracy10: 0.5909 - val_loss: 3.0395 - val_accuracy10: 0.5343 - 69s/epoch - 41ms/step
Epoch 11/50
1691/1691 - 70s - loss: 2.5646 - accuracy10: 0.5922 - val_loss: 3.0953 - val_accuracy10: 0.5310 - 70s/epoch - 42ms/step
Epoch 12/50
1691/1691 - 69s - loss: 2.5546 - accuracy10: 0.5939 - val_loss: 3.0706 - val_accuracy10: 0.5484 - 69s/epoch - 41ms/step
Epoch 13/50
1691/1691 - 69s - loss: 2.5456 - accuracy10: 0.5955 - val_loss: 3.0647 - val_accuracy10: 0.5405 - 69s/epoch - 41ms/step
Epoch 14/50
1691/1691 - 70s - loss: 2.5373 - accuracy10: 0.5963 - val_loss: 3.0978 - val_accuracy10: 0.5412 - 70s/epoch - 41ms/step
Epoch 15/50
1691/1691 - 70s - loss: 2.5293 - accuracy10: 0.5979 - val_loss: 3.0650 - val_accuracy10: 0.5450 - 70s/epoch - 41ms/step
Epoch 16/50
1691/1691 - 70s - loss: 2.5223 - accuracy10: 0.5992 - val_loss: 3.0525 - val_accuracy10: 0.5422 - 70s/epoch - 41ms/step
Epoch 17/50
1691/1691 - 70s - loss: 2.5163 - accuracy10: 0.6000 - val_loss: 3.0694 - val_accuracy10: 0.5475 - 70s/epoch - 41ms/step
testing model: results/ATVI/W8/deepLOB_L2/h10
Evaluating performance on  test set...
4960/4960 - 69s - 69s/epoch - 14ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 1.0054451
{'0': {'precision': 0.3572974983062244, 'recall': 0.5623233720161145, 'f1-score': 0.43695557711745747, 'support': 249465}, '1': {'precision': 0.8676780274375907, 'recall': 0.38355310130414744, 'f1-score': 0.5319570312989633, 'support': 774529}, '2': {'precision': 0.3305136256777304, 'recall': 0.7193002450282068, 'f1-score': 0.45291558545571037, 'support': 245686}, 'accuracy': 0.48364548547665553, 'macro avg': {'precision': 0.5184963838071818, 'recall': 0.5550589061161563, 'f1-score': 0.47394273129071035, 'support': 1269680}, 'weighted avg': {'precision': 0.6634566079377724, 'recall': 0.48364548547665553, 'f1-score': 0.4979965732065032, 'support': 1269680}}
[[140280  23986  85199]
 [204688 297073 272768]
 [ 47646  21318 176722]]
Evaluating performance on  train set...
1691/1691 - 23s - 23s/epoch - 14ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.972305
{'0': {'precision': 0.4163520160731606, 'recall': 0.48932835289208254, 'f1-score': 0.44990010434066524, 'support': 98251}, '1': {'precision': 0.7998101013813593, 'recall': 0.43879282821663224, 'f1-score': 0.5666883680555554, 'support': 238044}, '2': {'precision': 0.3670171756542597, 'recall': 0.7100021750613678, 'f1-score': 0.4838965851936822, 'support': 96549}, 'accuracy': 0.5107590725526979, 'macro avg': {'precision': 0.5277264310362598, 'recall': 0.5460411187233608, 'f1-score': 0.500161685863301, 'support': 432844}, 'weighted avg': {'precision': 0.6162315730301715, 'recall': 0.5107590725526979, 'f1-score': 0.5217113612314279, 'support': 432844}}
[[ 48077  13460  36714]
 [ 52080 104452  81512]
 [ 15315  12684  68550]]
Evaluating performance on  val set...
591/591 - 8s - 8s/epoch - 14ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.96007514
{'0': {'precision': 0.4273959478118748, 'recall': 0.4167788738973922, 'f1-score': 0.42202064609477163, 'support': 36391}, '1': {'precision': 0.7439929260697398, 'recall': 0.4986022544283414, 'f1-score': 0.5970674215369427, 'support': 77625}, '2': {'precision': 0.39976424361493124, 'recall': 0.6852470499488119, 'f1-score': 0.5049482346167972, 'support': 37118}, 'accuracy': 0.5247396350258711, 'macro avg': {'precision': 0.5237177058321819, 'recall': 0.5335427260915152, 'f1-score': 0.5080121007495039, 'support': 151134}, 'weighted avg': {'precision': 0.5832193021919918, 'recall': 0.5247396350258711, 'f1-score': 0.5322943910790839, 'support': 151134}}
[[15167  6825 14399]
 [15130 38704 23791]
 [ 5190  6493 25435]]
training model: results/ATVI/W8/deepLOB_L2/h20
Epoch 1/50
1691/1691 - 73s - loss: 3.0580 - accuracy20: 0.4683 - val_loss: 3.6025 - val_accuracy20: 0.4252 - 73s/epoch - 43ms/step
Epoch 2/50
1691/1691 - 71s - loss: 2.8993 - accuracy20: 0.5133 - val_loss: 3.3581 - val_accuracy20: 0.4756 - 71s/epoch - 42ms/step
Epoch 3/50
1691/1691 - 71s - loss: 2.8376 - accuracy20: 0.5338 - val_loss: 3.2379 - val_accuracy20: 0.4858 - 71s/epoch - 42ms/step
Epoch 4/50
1691/1691 - 72s - loss: 2.8024 - accuracy20: 0.5449 - val_loss: 3.2039 - val_accuracy20: 0.4870 - 72s/epoch - 42ms/step
Epoch 5/50
1691/1691 - 70s - loss: 2.7719 - accuracy20: 0.5527 - val_loss: 3.2391 - val_accuracy20: 0.4918 - 70s/epoch - 41ms/step
Epoch 6/50
1691/1691 - 70s - loss: 2.7421 - accuracy20: 0.5599 - val_loss: 3.1707 - val_accuracy20: 0.4950 - 70s/epoch - 41ms/step
Epoch 7/50
1691/1691 - 70s - loss: 2.7181 - accuracy20: 0.5670 - val_loss: 3.1722 - val_accuracy20: 0.4969 - 70s/epoch - 41ms/step
Epoch 8/50
1691/1691 - 70s - loss: 2.6999 - accuracy20: 0.5709 - val_loss: 3.1442 - val_accuracy20: 0.4959 - 70s/epoch - 42ms/step
Epoch 9/50
1691/1691 - 69s - loss: 2.6838 - accuracy20: 0.5735 - val_loss: 3.1169 - val_accuracy20: 0.4992 - 69s/epoch - 41ms/step
Epoch 10/50
1691/1691 - 69s - loss: 2.6711 - accuracy20: 0.5759 - val_loss: 3.0891 - val_accuracy20: 0.5084 - 69s/epoch - 41ms/step
Epoch 11/50
1691/1691 - 70s - loss: 2.6594 - accuracy20: 0.5781 - val_loss: 3.0685 - val_accuracy20: 0.5148 - 70s/epoch - 41ms/step
Epoch 12/50
1691/1691 - 70s - loss: 2.6505 - accuracy20: 0.5791 - val_loss: 3.1136 - val_accuracy20: 0.5119 - 70s/epoch - 41ms/step
Epoch 13/50
1691/1691 - 69s - loss: 2.6421 - accuracy20: 0.5817 - val_loss: 3.0848 - val_accuracy20: 0.5067 - 69s/epoch - 41ms/step
Epoch 14/50
1691/1691 - 70s - loss: 2.6331 - accuracy20: 0.5825 - val_loss: 3.0462 - val_accuracy20: 0.5206 - 70s/epoch - 41ms/step
Epoch 15/50
1691/1691 - 69s - loss: 2.6268 - accuracy20: 0.5837 - val_loss: 3.0271 - val_accuracy20: 0.5194 - 69s/epoch - 41ms/step
Epoch 16/50
1691/1691 - 70s - loss: 2.6206 - accuracy20: 0.5846 - val_loss: 3.0251 - val_accuracy20: 0.5208 - 70s/epoch - 41ms/step
Epoch 17/50
1691/1691 - 70s - loss: 2.6148 - accuracy20: 0.5862 - val_loss: 3.0282 - val_accuracy20: 0.5175 - 70s/epoch - 41ms/step
Epoch 18/50
1691/1691 - 70s - loss: 2.6091 - accuracy20: 0.5872 - val_loss: 3.0129 - val_accuracy20: 0.5231 - 70s/epoch - 42ms/step
Epoch 19/50
1691/1691 - 69s - loss: 2.6039 - accuracy20: 0.5885 - val_loss: 3.0340 - val_accuracy20: 0.5203 - 69s/epoch - 41ms/step
Epoch 20/50
1691/1691 - 70s - loss: 2.5980 - accuracy20: 0.5890 - val_loss: 3.0428 - val_accuracy20: 0.5221 - 70s/epoch - 41ms/step
Epoch 21/50
1691/1691 - 71s - loss: 2.5926 - accuracy20: 0.5900 - val_loss: 3.0275 - val_accuracy20: 0.5223 - 71s/epoch - 42ms/step
Epoch 22/50
1691/1691 - 70s - loss: 2.5873 - accuracy20: 0.5910 - val_loss: 3.0386 - val_accuracy20: 0.5262 - 70s/epoch - 42ms/step
Epoch 23/50
1691/1691 - 70s - loss: 2.5824 - accuracy20: 0.5922 - val_loss: 3.0267 - val_accuracy20: 0.5307 - 70s/epoch - 42ms/step
Epoch 24/50
1691/1691 - 71s - loss: 2.5773 - accuracy20: 0.5926 - val_loss: 3.0514 - val_accuracy20: 0.5271 - 71s/epoch - 42ms/step
Epoch 25/50
1691/1691 - 70s - loss: 2.5724 - accuracy20: 0.5938 - val_loss: 3.0783 - val_accuracy20: 0.5238 - 70s/epoch - 41ms/step
Epoch 26/50
1691/1691 - 69s - loss: 2.5688 - accuracy20: 0.5945 - val_loss: 3.0617 - val_accuracy20: 0.5235 - 69s/epoch - 41ms/step
Epoch 27/50
1691/1691 - 70s - loss: 2.5641 - accuracy20: 0.5955 - val_loss: 3.1123 - val_accuracy20: 0.5203 - 70s/epoch - 41ms/step
Epoch 28/50
1691/1691 - 69s - loss: 2.5609 - accuracy20: 0.5962 - val_loss: 3.0740 - val_accuracy20: 0.5275 - 69s/epoch - 41ms/step
testing model: results/ATVI/W8/deepLOB_L2/h20
Evaluating performance on  test set...
4960/4960 - 68s - 68s/epoch - 14ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.99922746
{'0': {'precision': 0.3776029684601113, 'recall': 0.6472836906950267, 'f1-score': 0.47696248333204444, 'support': 314434}, '1': {'precision': 0.7972173197627357, 'recall': 0.37300447804052744, 'f1-score': 0.5082209728124726, 'support': 644255}, '2': {'precision': 0.41284211311049196, 'recall': 0.5698235640259686, 'f1-score': 0.47879389653285775, 'support': 310991}, 'accuracy': 0.48913742045239744, 'macro avg': {'precision': 0.5292208004444463, 'recall': 0.5300372442538409, 'f1-score': 0.48799245089245824, 'support': 1269680}, 'weighted avg': {'precision': 0.5991530446465826, 'recall': 0.48913742045239744, 'f1-score': 0.49327209769388947, 'support': 1269680}}
[[203528  31124  79782]
 [231693 240310 172252]
 [103779  30002 177210]]
Evaluating performance on  train set...
1691/1691 - 25s - 25s/epoch - 15ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.9555203
{'0': {'precision': 0.4662783106513333, 'recall': 0.5357716942404234, 'f1-score': 0.4986152772130632, 'support': 121311}, '1': {'precision': 0.7171165070458869, 'recall': 0.46237973209691086, 'f1-score': 0.5622402639471347, 'support': 192383}, '2': {'precision': 0.4415704006280658, 'recall': 0.6278304657994125, 'f1-score': 0.5184797563063359, 'support': 119150}, 'accuracy': 0.5284929443402242, 'macro avg': {'precision': 0.5416550727750954, 'recall': 0.5419939640455822, 'f1-score': 0.5264450991555113, 'support': 432844}, 'weighted avg': {'precision': 0.5709651198890751, 'recall': 0.5284929443402242, 'f1-score': 0.5323623512323965, 'support': 432844}}
[[64995 17604 38712]
 [47538 88954 55891]
 [26858 17486 74806]]
Evaluating performance on  val set...
591/591 - 8s - 8s/epoch - 14ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.9804497
{'0': {'precision': 0.46258296718706177, 'recall': 0.450158065910073, 'f1-score': 0.45628594810793366, 'support': 43969}, '1': {'precision': 0.6477598584531533, 'recall': 0.5146804556839298, 'f1-score': 0.5736025068433943, 'support': 61885}, '2': {'precision': 0.462644697929869, 'recall': 0.6046157243816255, 'f1-score': 0.5241874491407783, 'support': 45280}, 'accuracy': 0.5228538912488255, 'macro avg': {'precision': 0.5243291745233614, 'recall': 0.5231514153252094, 'f1-score': 0.5180253013640354, 'support': 151134}, 'weighted avg': {'precision': 0.5384260407776262, 'recall': 0.5228538912488255, 'f1-score': 0.5246670880507075, 'support': 151134}}
[[19793  8551 15625]
 [13861 31851 16173]
 [ 9134  8769 27377]]
training model: results/ATVI/W8/deepLOB_L2/h30
Epoch 1/50
1691/1691 - 71s - loss: 3.0953 - accuracy30: 0.4590 - val_loss: 3.4871 - val_accuracy30: 0.4006 - 71s/epoch - 42ms/step
Epoch 2/50
1691/1691 - 69s - loss: 2.9594 - accuracy30: 0.4992 - val_loss: 3.2033 - val_accuracy30: 0.4503 - 69s/epoch - 41ms/step
Epoch 3/50
1691/1691 - 71s - loss: 2.9152 - accuracy30: 0.5119 - val_loss: 3.1634 - val_accuracy30: 0.4622 - 71s/epoch - 42ms/step
Epoch 4/50
1691/1691 - 69s - loss: 2.8845 - accuracy30: 0.5215 - val_loss: 3.1093 - val_accuracy30: 0.4736 - 69s/epoch - 41ms/step
Epoch 5/50
1691/1691 - 69s - loss: 2.8628 - accuracy30: 0.5266 - val_loss: 3.1112 - val_accuracy30: 0.4713 - 69s/epoch - 41ms/step
Epoch 6/50
1691/1691 - 70s - loss: 2.8444 - accuracy30: 0.5312 - val_loss: 3.1523 - val_accuracy30: 0.4713 - 70s/epoch - 42ms/step
Epoch 7/50
1691/1691 - 70s - loss: 2.8298 - accuracy30: 0.5357 - val_loss: 3.1073 - val_accuracy30: 0.4727 - 70s/epoch - 41ms/step
Epoch 8/50
1691/1691 - 70s - loss: 2.8151 - accuracy30: 0.5390 - val_loss: 3.1195 - val_accuracy30: 0.4683 - 70s/epoch - 41ms/step
Epoch 9/50
1691/1691 - 70s - loss: 2.8021 - accuracy30: 0.5423 - val_loss: 3.1379 - val_accuracy30: 0.4665 - 70s/epoch - 41ms/step
Epoch 10/50
1691/1691 - 70s - loss: 2.7905 - accuracy30: 0.5450 - val_loss: 3.1931 - val_accuracy30: 0.4586 - 70s/epoch - 41ms/step
Epoch 11/50
1691/1691 - 69s - loss: 2.7784 - accuracy30: 0.5479 - val_loss: 3.2119 - val_accuracy30: 0.4584 - 69s/epoch - 41ms/step
Epoch 12/50
1691/1691 - 70s - loss: 2.7677 - accuracy30: 0.5506 - val_loss: 3.1584 - val_accuracy30: 0.4654 - 70s/epoch - 41ms/step
Epoch 13/50
1691/1691 - 70s - loss: 2.7587 - accuracy30: 0.5525 - val_loss: 3.1689 - val_accuracy30: 0.4663 - 70s/epoch - 42ms/step
Epoch 14/50
1691/1691 - 70s - loss: 2.7484 - accuracy30: 0.5550 - val_loss: 3.1526 - val_accuracy30: 0.4688 - 70s/epoch - 41ms/step
Epoch 15/50
1691/1691 - 69s - loss: 2.7401 - accuracy30: 0.5569 - val_loss: 3.1278 - val_accuracy30: 0.4682 - 69s/epoch - 41ms/step
Epoch 16/50
1691/1691 - 70s - loss: 2.7312 - accuracy30: 0.5588 - val_loss: 3.1199 - val_accuracy30: 0.4732 - 70s/epoch - 41ms/step
Epoch 17/50
1691/1691 - 70s - loss: 2.7231 - accuracy30: 0.5602 - val_loss: 3.1293 - val_accuracy30: 0.4692 - 70s/epoch - 41ms/step
testing model: results/ATVI/W8/deepLOB_L2/h30
Evaluating performance on  test set...
4960/4960 - 67s - 67s/epoch - 14ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.035932
{'0': {'precision': 0.40890135947566153, 'recall': 0.5309328036075, 'f1-score': 0.46199458098677576, 'support': 357921}, '1': {'precision': 0.7126819427008338, 'recall': 0.3190026767873525, 'f1-score': 0.44073051613847364, 'support': 557011}, '2': {'precision': 0.40026169011498886, 'recall': 0.6269041685929166, 'f1-score': 0.4885787819637574, 'support': 354748}, 'accuracy': 0.46477301367273643, 'macro avg': {'precision': 0.5072816640971615, 'recall': 0.492279882995923, 'f1-score': 0.4637679596963356, 'support': 1269680}, 'weighted avg': {'precision': 0.5397565521356046, 'recall': 0.46477301367273643, 'f1-score': 0.4600936091694396, 'support': 1269680}}
[[190032  38581 129308]
 [175405 177688 203918]
 [ 99301  33054 222393]]
Evaluating performance on  train set...
1691/1691 - 24s - 24s/epoch - 14ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.0027139
{'0': {'precision': 0.4670482562886974, 'recall': 0.4311737927602207, 'f1-score': 0.44839462197409935, 'support': 136634}, '1': {'precision': 0.5880229654668683, 'recall': 0.42572881501841636, 'f1-score': 0.49388484461548887, 'support': 162627}, '2': {'precision': 0.43820218772987307, 'recall': 0.6198692947455889, 'f1-score': 0.5134399434499266, 'support': 133583}, 'accuracy': 0.48736265259539235, 'macro avg': {'precision': 0.4977578031618129, 'recall': 0.4922573008414086, 'f1-score': 0.4852398033465049, 'support': 432844}, 'weighted avg': {'precision': 0.5035981672340379, 'recall': 0.48736265259539235, 'f1-score': 0.48556017726932515, 'support': 432844}}
[[58913 26029 51692]
 [38925 69235 54467]
 [28301 22478 82804]]
Evaluating performance on  val set...
591/591 - 8s - 8s/epoch - 14ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.0296788
{'0': {'precision': 0.463762799938866, 'recall': 0.31078700479331395, 'f1-score': 0.37216832448211157, 'support': 48818}, '1': {'precision': 0.5123791705643904, 'recall': 0.4746572176860268, 'f1-score': 0.4927973768656344, 'support': 51928}, '2': {'precision': 0.448232215490514, 'recall': 0.6254862268794157, 'f1-score': 0.5222282977912545, 'support': 50388}, 'accuracy': 0.4720115923617452, 'macro avg': {'precision': 0.4747913953312568, 'recall': 0.47031014978625213, 'f1-score': 0.4623979997130001, 'support': 151134}, 'weighted avg': {'precision': 0.4752889674766714, 'recall': 0.4720115923617452, 'f1-score': 0.4636450760222856, 'support': 151134}}
[[15172 12259 21387]
 [ 9870 24648 17410]
 [ 7673 11198 31517]]
training model: results/ATVI/W8/deepLOB_L2/h50
Epoch 1/50
1691/1691 - 72s - loss: 3.1635 - accuracy50: 0.4320 - val_loss: 3.4570 - val_accuracy50: 0.3587 - 72s/epoch - 42ms/step
Epoch 2/50
1691/1691 - 69s - loss: 3.0543 - accuracy50: 0.4686 - val_loss: 3.3504 - val_accuracy50: 0.4024 - 69s/epoch - 41ms/step
Epoch 3/50
1691/1691 - 70s - loss: 3.0162 - accuracy50: 0.4816 - val_loss: 3.4471 - val_accuracy50: 0.4040 - 70s/epoch - 42ms/step
Epoch 4/50
1691/1691 - 70s - loss: 2.9898 - accuracy50: 0.4907 - val_loss: 3.3241 - val_accuracy50: 0.4204 - 70s/epoch - 41ms/step
Epoch 5/50
1691/1691 - 69s - loss: 2.9729 - accuracy50: 0.4956 - val_loss: 3.3599 - val_accuracy50: 0.4267 - 69s/epoch - 41ms/step
Epoch 6/50
1691/1691 - 70s - loss: 2.9589 - accuracy50: 0.4993 - val_loss: 3.3860 - val_accuracy50: 0.4277 - 70s/epoch - 41ms/step
Epoch 7/50
1691/1691 - 69s - loss: 2.9482 - accuracy50: 0.5020 - val_loss: 3.3294 - val_accuracy50: 0.4338 - 69s/epoch - 41ms/step
Epoch 8/50
1691/1691 - 69s - loss: 2.9391 - accuracy50: 0.5050 - val_loss: 3.3854 - val_accuracy50: 0.4279 - 69s/epoch - 41ms/step
Epoch 9/50
1691/1691 - 70s - loss: 2.9303 - accuracy50: 0.5073 - val_loss: 3.4239 - val_accuracy50: 0.4292 - 70s/epoch - 41ms/step
Epoch 10/50
1691/1691 - 70s - loss: 2.9216 - accuracy50: 0.5090 - val_loss: 3.4076 - val_accuracy50: 0.4286 - 70s/epoch - 41ms/step
Epoch 11/50
1691/1691 - 69s - loss: 2.9136 - accuracy50: 0.5121 - val_loss: 3.4457 - val_accuracy50: 0.4276 - 69s/epoch - 41ms/step
Epoch 12/50
1691/1691 - 69s - loss: 2.9051 - accuracy50: 0.5138 - val_loss: 3.4561 - val_accuracy50: 0.4227 - 69s/epoch - 41ms/step
Epoch 13/50
1691/1691 - 70s - loss: 2.8971 - accuracy50: 0.5162 - val_loss: 3.4994 - val_accuracy50: 0.4170 - 70s/epoch - 41ms/step
Epoch 14/50
1691/1691 - 69s - loss: 2.8893 - accuracy50: 0.5181 - val_loss: 3.4423 - val_accuracy50: 0.4209 - 69s/epoch - 41ms/step
testing model: results/ATVI/W8/deepLOB_L2/h50
Evaluating performance on  test set...
4960/4960 - 72s - 72s/epoch - 15ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0398884
{'0': {'precision': 0.40263400486546025, 'recall': 0.3890546476400009, 'f1-score': 0.39572786699688983, 'support': 391801}, '1': {'precision': 0.5999526040432397, 'recall': 0.33854515979048455, 'f1-score': 0.43284290710046175, 'support': 486074}, '2': {'precision': 0.3910276779808303, 'recall': 0.6155842829979199, 'f1-score': 0.47825875732317547, 'support': 391805}, 'accuracy': 0.4396217944678974, 'macro avg': {'precision': 0.46453809562984344, 'recall': 0.44772803014280177, 'f1-score': 0.43560984380684237, 'support': 1269680}, 'weighted avg': {'precision': 0.4745923123694829, 'recall': 0.4396217944678974, 'f1-score': 0.43540453473017215, 'support': 1269680}}
[[152432  61695 177674]
 [123571 164558 197945]
 [102584  48032 241189]]
Evaluating performance on  train set...
1691/1691 - 24s - 24s/epoch - 14ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0617428
{'0': {'precision': 0.47960792377818906, 'recall': 0.23894899325191923, 'f1-score': 0.31897773948403746, 'support': 146412}, '1': {'precision': 0.47057572621461075, 'recall': 0.4625976433205349, 'f1-score': 0.46655258081178996, 'support': 143507}, '2': {'precision': 0.41462812749914313, 'recall': 0.6348154626552388, 'f1-score': 0.5016226675881134, 'support': 142925}, 'accuracy': 0.4438134755246694, 'macro avg': {'precision': 0.4549372591639809, 'recall': 0.44545403307589765, 'f1-score': 0.4290509959613136, 'support': 432844}, 'weighted avg': {'precision': 0.45515703394504115, 'recall': 0.4438134755246694, 'f1-score': 0.42821466803958363, 'support': 432844}}
[[34985 40248 71179]
 [20206 66386 56915]
 [17754 34440 90731]]
Evaluating performance on  val set...
591/591 - 8s - 8s/epoch - 14ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.1099447
{'0': {'precision': 0.4628353613839613, 'recall': 0.12004715187466727, 'f1-score': 0.19064585283372082, 'support': 52596}, '1': {'precision': 0.4056150119314484, 'recall': 0.4995658272660477, 'f1-score': 0.44771473326083266, 'support': 44913}, '2': {'precision': 0.42590294003115264, 'recall': 0.6526620046620046, 'f1-score': 0.5154453943638118, 'support': 53625}, 'accuracy': 0.42181110802334354, 'macro avg': {'precision': 0.4314511044488541, 'recall': 0.4240916612675732, 'f1-score': 0.3846019934861218, 'support': 151134}, 'weighted avg': {'precision': 0.43272672500826104, 'recall': 0.42181110802334354, 'f1-score': 0.38228446519873466, 'support': 151134}}
[[ 6314 17168 29114]
 [ 4413 22437 18063]
 [ 2915 15711 34999]]
training model: results/ATVI/W8/deepLOB_L2/h100
Epoch 1/50
1691/1691 - 71s - loss: 3.2421 - accuracy100: 0.4013 - val_loss: 3.5197 - val_accuracy100: 0.3309 - 71s/epoch - 42ms/step
Epoch 2/50
1691/1691 - 69s - loss: 3.1881 - accuracy100: 0.4236 - val_loss: 3.4387 - val_accuracy100: 0.3494 - 69s/epoch - 41ms/step
Epoch 3/50
1691/1691 - 70s - loss: 3.1615 - accuracy100: 0.4333 - val_loss: 3.4961 - val_accuracy100: 0.3773 - 70s/epoch - 41ms/step
Epoch 4/50
1691/1691 - 69s - loss: 3.1496 - accuracy100: 0.4378 - val_loss: 3.5567 - val_accuracy100: 0.3639 - 69s/epoch - 41ms/step
Epoch 5/50
1691/1691 - 69s - loss: 3.1393 - accuracy100: 0.4413 - val_loss: 3.5818 - val_accuracy100: 0.3843 - 69s/epoch - 41ms/step
Epoch 6/50
1691/1691 - 71s - loss: 3.1307 - accuracy100: 0.4447 - val_loss: 3.6065 - val_accuracy100: 0.3823 - 71s/epoch - 42ms/step
Epoch 7/50
1691/1691 - 70s - loss: 3.1244 - accuracy100: 0.4471 - val_loss: 3.5852 - val_accuracy100: 0.3948 - 70s/epoch - 42ms/step
Epoch 8/50
1691/1691 - 70s - loss: 3.1179 - accuracy100: 0.4498 - val_loss: 3.5578 - val_accuracy100: 0.3923 - 70s/epoch - 41ms/step
Epoch 9/50
1691/1691 - 71s - loss: 3.1117 - accuracy100: 0.4518 - val_loss: 3.6330 - val_accuracy100: 0.3735 - 71s/epoch - 42ms/step
Epoch 10/50
1691/1691 - 70s - loss: 3.1048 - accuracy100: 0.4542 - val_loss: 3.6338 - val_accuracy100: 0.3755 - 70s/epoch - 41ms/step
Epoch 11/50
1691/1691 - 70s - loss: 3.0994 - accuracy100: 0.4563 - val_loss: 3.6246 - val_accuracy100: 0.3803 - 70s/epoch - 42ms/step
Epoch 12/50
1691/1691 - 71s - loss: 3.0936 - accuracy100: 0.4582 - val_loss: 3.6256 - val_accuracy100: 0.3686 - 71s/epoch - 42ms/step
testing model: results/ATVI/W8/deepLOB_L2/h100
Evaluating performance on  test set...
4960/4960 - 71s - 71s/epoch - 14ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0908202
{'0': {'precision': 0.4107366275845168, 'recall': 0.22304613990931718, 'f1-score': 0.289099748370765, 'support': 428306}, '1': {'precision': 0.38868899603342477, 'recall': 0.639456607141125, 'f1-score': 0.48349133793733173, 'support': 412372}, '2': {'precision': 0.40098808388676066, 'recall': 0.3352525163052853, 'f1-score': 0.3651856854848948, 'support': 429002}, 'accuracy': 0.3962021926784702, 'macro avg': {'precision': 0.4001379025015674, 'recall': 0.39925175445190914, 'f1-score': 0.37925892393099714, 'support': 1269680}, 'weighted avg': {'precision': 0.40028204795704236, 'recall': 0.3962021926784702, 'f1-score': 0.37794313234671184, 'support': 1269680}}
[[ 95532 213116 119658]
 [ 53486 263694  95192]
 [ 83569 201609 143824]]
Evaluating performance on  train set...
1691/1691 - 25s - 25s/epoch - 15ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.1091704
{'0': {'precision': 0.4086751532296087, 'recall': 0.0882328990228013, 'f1-score': 0.14513185433235665, 'support': 147360}, '1': {'precision': 0.3707854884657481, 'recall': 0.677988912520484, 'f1-score': 0.4793947103721673, 'support': 143405}, '2': {'precision': 0.3967725668179526, 'recall': 0.38764349411243043, 'f1-score': 0.39215490816657117, 'support': 142079}, 'accuracy': 0.381904335049117, 'macro avg': {'precision': 0.39207773617110314, 'recall': 0.3846217685519053, 'f1-score': 0.338893824290365, 'support': 432844}, 'weighted avg': {'precision': 0.39221500835006057, 'recall': 0.381904335049117, 'f1-score': 0.3369602112833608, 'support': 432844}}
[[13002 87850 46508]
 [ 8952 97227 37226]
 [ 9861 77142 55076]]
Evaluating performance on  val set...
591/591 - 8s - 8s/epoch - 14ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.1505845
{'0': {'precision': 0.43807919123841615, 'recall': 0.019464355898261308, 'f1-score': 0.037272645820267, 'support': 53431}, '1': {'precision': 0.3127908685641503, 'recall': 0.7387139320174931, 'f1-score': 0.43949009512534243, 'support': 43217}, '2': {'precision': 0.4209658421672556, 'recall': 0.3607715743493741, 'f1-score': 0.38855121020745, 'support': 54486}, 'accuracy': 0.348181084335755, 'macro avg': {'precision': 0.39061196732327397, 'recall': 0.37298328742170955, 'f1-score': 0.2884379837176865, 'support': 151134}, 'weighted avg': {'precision': 0.39608319180410617, 'recall': 0.348181084335755, 'f1-score': 0.2789283643602216, 'support': 151134}}
[[ 1040 35995 16396]
 [  650 31925 10642]
 [  684 34145 19657]]
training model: results/ATVI/W8/deepLOB_L2/h200
Epoch 1/50
1691/1691 - 72s - loss: 3.2829 - accuracy200: 0.3779 - val_loss: 3.3997 - val_accuracy200: 0.3000 - 72s/epoch - 42ms/step
Epoch 2/50
1691/1691 - 71s - loss: 3.2473 - accuracy200: 0.3925 - val_loss: 3.3468 - val_accuracy200: 0.3222 - 71s/epoch - 42ms/step
Epoch 3/50
1691/1691 - 69s - loss: 3.2281 - accuracy200: 0.4042 - val_loss: 3.4694 - val_accuracy200: 0.3035 - 69s/epoch - 41ms/step
Epoch 4/50
1691/1691 - 71s - loss: 3.2162 - accuracy200: 0.4112 - val_loss: 3.5343 - val_accuracy200: 0.3032 - 71s/epoch - 42ms/step
Epoch 5/50
1691/1691 - 70s - loss: 3.2083 - accuracy200: 0.4148 - val_loss: 3.5523 - val_accuracy200: 0.3096 - 70s/epoch - 41ms/step
Epoch 6/50
1691/1691 - 69s - loss: 3.2007 - accuracy200: 0.4189 - val_loss: 3.5747 - val_accuracy200: 0.3119 - 69s/epoch - 41ms/step
Epoch 7/50
1691/1691 - 71s - loss: 3.1939 - accuracy200: 0.4216 - val_loss: 3.6226 - val_accuracy200: 0.3154 - 71s/epoch - 42ms/step
Epoch 8/50
1691/1691 - 71s - loss: 3.1879 - accuracy200: 0.4249 - val_loss: 3.6096 - val_accuracy200: 0.3481 - 71s/epoch - 42ms/step
Epoch 9/50
1691/1691 - 70s - loss: 3.1820 - accuracy200: 0.4284 - val_loss: 3.6239 - val_accuracy200: 0.3421 - 70s/epoch - 42ms/step
Epoch 10/50
1691/1691 - 71s - loss: 3.1756 - accuracy200: 0.4308 - val_loss: 3.7442 - val_accuracy200: 0.3333 - 71s/epoch - 42ms/step
Epoch 11/50
1691/1691 - 70s - loss: 3.1684 - accuracy200: 0.4338 - val_loss: 3.7608 - val_accuracy200: 0.3275 - 70s/epoch - 41ms/step
Epoch 12/50
1691/1691 - 70s - loss: 3.1616 - accuracy200: 0.4376 - val_loss: 3.7721 - val_accuracy200: 0.3383 - 70s/epoch - 42ms/step
testing model: results/ATVI/W8/deepLOB_L2/h200
Evaluating performance on  test set...
4960/4960 - 69s - 69s/epoch - 14ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1075671
{'0': {'precision': 0.3433135743592327, 'recall': 0.29630595834208956, 'f1-score': 0.31808239886839956, 'support': 413991}, '1': {'precision': 0.3759618701200966, 'recall': 0.4122813050176056, 'f1-score': 0.3932848525403214, 'support': 436224}, '2': {'precision': 0.3408270335407791, 'recall': 0.35264443994135386, 'f1-score': 0.346635046878991, 'support': 419465}, 'accuracy': 0.35476419255245417, 'macro avg': {'precision': 0.3533674926733694, 'recall': 0.35374390110034976, 'f1-score': 0.3526674327625707, 'support': 1269680}, 'weighted avg': {'precision': 0.353709070331111, 'recall': 0.35476419255245417, 'f1-score': 0.3533526651152831, 'support': 1269680}}
[[122668 152586 138737]
 [109027 179847 147350]
 [125611 145932 147922]]
Evaluating performance on  train set...
1691/1691 - 24s - 24s/epoch - 14ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1016772
{'0': {'precision': 0.3810204530459644, 'recall': 0.11710512085654032, 'f1-score': 0.1791493893927017, 'support': 147944}, '1': {'precision': 0.34736421595003997, 'recall': 0.5979216514521075, 'f1-score': 0.43943656161285916, 'support': 142517}, '2': {'precision': 0.36674456911965536, 'recall': 0.36590744681598225, 'f1-score': 0.36632552972321153, 'support': 142383}, 'accuracy': 0.3572603524595466, 'macro avg': {'precision': 0.36504307937188657, 'recall': 0.3603114063748767, 'f1-score': 0.3283038269095908, 'support': 432844}, 'weighted avg': {'precision': 0.3652428770063762, 'recall': 0.3572603524595466, 'f1-score': 0.32642195713530453, 'support': 432844}}
[[17325 84259 46360]
 [13704 85214 43599]
 [14441 75843 52099]]
Evaluating performance on  val set...
591/591 - 8s - 8s/epoch - 14ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1179423
{'0': {'precision': 0.38997050147492623, 'recall': 0.012517516948831572, 'f1-score': 0.024256435661730975, 'support': 52806}, '1': {'precision': 0.3003205524536055, 'recall': 0.699322229113139, 'f1-score': 0.4201917766288037, 'support': 45148}, '2': {'precision': 0.37155818362372484, 'recall': 0.30957126739375707, 'f1-score': 0.3377441326111932, 'support': 53180}, 'accuracy': 0.32221075337118055, 'macro avg': {'precision': 0.3539497458507522, 'recall': 0.3404703378185759, 'f1-score': 0.2607307816339093, 'support': 151134}, 'weighted avg': {'precision': 0.3567107256353304, 'recall': 0.32221075337118055, 'f1-score': 0.2528414297580548, 'support': 151134}}
[[  661 37269 14876]
 [  606 31573 12969]
 [  428 36289 16463]]
training model: results/ATVI/W8/deepLOB_L2/h300
Epoch 1/50
1691/1691 - 72s - loss: 3.2845 - accuracy300: 0.3767 - val_loss: 3.7622 - val_accuracy300: 0.2762 - 72s/epoch - 43ms/step
Epoch 2/50
1691/1691 - 70s - loss: 3.2628 - accuracy300: 0.3860 - val_loss: 3.5557 - val_accuracy300: 0.2811 - 70s/epoch - 42ms/step
Epoch 3/50
1691/1691 - 71s - loss: 3.2464 - accuracy300: 0.3970 - val_loss: 3.4018 - val_accuracy300: 0.3231 - 71s/epoch - 42ms/step
Epoch 4/50
1691/1691 - 70s - loss: 3.2297 - accuracy300: 0.4063 - val_loss: 3.5248 - val_accuracy300: 0.3066 - 70s/epoch - 41ms/step
Epoch 5/50
1691/1691 - 70s - loss: 3.2194 - accuracy300: 0.4116 - val_loss: 3.4562 - val_accuracy300: 0.3531 - 70s/epoch - 41ms/step
Epoch 6/50
1691/1691 - 70s - loss: 3.2101 - accuracy300: 0.4172 - val_loss: 3.4473 - val_accuracy300: 0.3652 - 70s/epoch - 41ms/step
Epoch 7/50
1691/1691 - 69s - loss: 3.1999 - accuracy300: 0.4217 - val_loss: 3.4659 - val_accuracy300: 0.3564 - 69s/epoch - 41ms/step
Epoch 8/50
1691/1691 - 70s - loss: 3.1947 - accuracy300: 0.4241 - val_loss: 3.4873 - val_accuracy300: 0.3545 - 70s/epoch - 41ms/step
Epoch 9/50
1691/1691 - 71s - loss: 3.1870 - accuracy300: 0.4277 - val_loss: 3.5250 - val_accuracy300: 0.3548 - 71s/epoch - 42ms/step
Epoch 10/50
1691/1691 - 70s - loss: 3.1784 - accuracy300: 0.4325 - val_loss: 3.5315 - val_accuracy300: 0.3551 - 70s/epoch - 41ms/step
Epoch 11/50
1691/1691 - 70s - loss: 3.1690 - accuracy300: 0.4361 - val_loss: 3.5766 - val_accuracy300: 0.3483 - 70s/epoch - 42ms/step
Epoch 12/50
1691/1691 - 71s - loss: 3.1615 - accuracy300: 0.4396 - val_loss: 3.5859 - val_accuracy300: 0.3480 - 71s/epoch - 42ms/step
Epoch 13/50
1691/1691 - 69s - loss: 3.1545 - accuracy300: 0.4425 - val_loss: 3.6115 - val_accuracy300: 0.3269 - 69s/epoch - 41ms/step
testing model: results/ATVI/W8/deepLOB_L2/h300
Evaluating performance on  test set...
4960/4960 - 67s - 67s/epoch - 13ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1909871
{'0': {'precision': 0.37026239067055394, 'recall': 0.0026275499648280715, 'f1-score': 0.005218070135793085, 'support': 435006}, '1': {'precision': 0.3174611849127225, 'recall': 0.7238643328153967, 'f1-score': 0.4413582974764507, 'support': 393227}, '2': {'precision': 0.3511149552666432, 'recall': 0.2942640905929817, 'f1-score': 0.32018555194184983, 'support': 441447}, 'accuracy': 0.32739587927666813, 'macro avg': {'precision': 0.34627951028330656, 'recall': 0.3402519911244022, 'f1-score': 0.2555873065180312, 'support': 1269680}, 'weighted avg': {'precision': 0.34725231123850414, 'recall': 0.32739587927666813, 'f1-score': 0.24980218827368855, 'support': 1269680}}
[[  1143 301609 132254]
 [   770 284643 107814]
 [  1174 310371 129902]]
Evaluating performance on  train set...
1691/1691 - 24s - 24s/epoch - 14ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1519802
{'0': {'precision': 0.3471698113207547, 'recall': 0.0006076658366303609, 'f1-score': 0.001213208144319021, 'support': 151399}, '1': {'precision': 0.3317455280581593, 'recall': 0.681573453466652, 'f1-score': 0.4462739756250809, 'support': 136515}, '2': {'precision': 0.352262865858469, 'recall': 0.36970951493824605, 'f1-score': 0.3607753890074671, 'support': 144930}, 'accuracy': 0.33896507748750127, 'macro avg': {'precision': 0.343726068412461, 'recall': 0.3506302114138428, 'f1-score': 0.269420857592289, 'support': 432844}, 'weighted avg': {'precision': 0.34401045220882925, 'recall': 0.33896507748750127, 'f1-score': 0.2619741694724933, 'support': 432844}}
[[   92 96175 55132]
 [   76 93045 43394]
 [   97 91251 53582]]
Evaluating performance on  val set...
591/591 - 8s - 8s/epoch - 14ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1471447
{'0': {'precision': 0.4, 'recall': 0.00036789051578250314, 'f1-score': 0.0007351049362296467, 'support': 54364}, '1': {'precision': 0.28721480093268537, 'recall': 0.6319069878940429, 'f1-score': 0.3949270748278936, 'support': 41715}, '2': {'precision': 0.37849458739419284, 'recall': 0.40771955317409864, 'f1-score': 0.39256389853184215, 'support': 55055}, 'accuracy': 0.3230709171993066, 'macro avg': {'precision': 0.3552364627756261, 'recall': 0.34666481052797465, 'f1-score': 0.2627420260986551, 'support': 151134}, 'weighted avg': {'precision': 0.36103580220131976, 'recall': 0.3230709171993066, 'f1-score': 0.25227249728631107, 'support': 151134}}
[[   20 32828 21516]
 [   12 26360 15343]
 [   18 32590 22447]]
training model: results/ATVI/W8/deepLOB_L2/h500
Epoch 1/50
1691/1691 - 71s - loss: 3.2635 - accuracy500: 0.3950 - val_loss: 3.3998 - val_accuracy500: 0.2807 - 71s/epoch - 42ms/step
Epoch 2/50
1691/1691 - 70s - loss: 3.2443 - accuracy500: 0.3979 - val_loss: 3.4277 - val_accuracy500: 0.2853 - 70s/epoch - 41ms/step
Epoch 3/50
1691/1691 - 70s - loss: 3.2258 - accuracy500: 0.4132 - val_loss: 3.5191 - val_accuracy500: 0.2646 - 70s/epoch - 42ms/step
Epoch 4/50
1691/1691 - 70s - loss: 3.2041 - accuracy500: 0.4256 - val_loss: 3.5567 - val_accuracy500: 0.2732 - 70s/epoch - 42ms/step
Epoch 5/50
1691/1691 - 70s - loss: 3.1931 - accuracy500: 0.4317 - val_loss: 3.7426 - val_accuracy500: 0.2770 - 70s/epoch - 42ms/step
Epoch 6/50
1691/1691 - 71s - loss: 3.1803 - accuracy500: 0.4366 - val_loss: 3.7329 - val_accuracy500: 0.2797 - 71s/epoch - 42ms/step
Epoch 7/50
1691/1691 - 70s - loss: 3.1673 - accuracy500: 0.4427 - val_loss: 3.7682 - val_accuracy500: 0.2810 - 70s/epoch - 42ms/step
Epoch 8/50
1691/1691 - 69s - loss: 3.1576 - accuracy500: 0.4467 - val_loss: 3.7674 - val_accuracy500: 0.2876 - 69s/epoch - 41ms/step
Epoch 9/50
1691/1691 - 71s - loss: 3.1469 - accuracy500: 0.4520 - val_loss: 3.7625 - val_accuracy500: 0.2905 - 71s/epoch - 42ms/step
Epoch 10/50
1691/1691 - 70s - loss: 3.1394 - accuracy500: 0.4542 - val_loss: 3.7450 - val_accuracy500: 0.2996 - 70s/epoch - 41ms/step
Epoch 11/50
1691/1691 - 69s - loss: 3.1304 - accuracy500: 0.4578 - val_loss: 3.7748 - val_accuracy500: 0.3183 - 69s/epoch - 41ms/step
testing model: results/ATVI/W8/deepLOB_L2/h500
Evaluating performance on  test set...
4960/4960 - 73s - 73s/epoch - 15ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.155309
{'0': {'precision': 0.367, 'recall': 0.0007802965552139543, 'f1-score': 0.0015572820971964678, 'support': 470334}, '1': {'precision': 0.24982799540479467, 'recall': 0.9983824535625435, 'f1-score': 0.399650375026427, 'support': 317147}, '2': {'precision': 0.36477987421383645, 'recall': 0.0009622583207348004, 'f1-score': 0.001919453286753497, 'support': 482199}, 'accuracy': 0.25003544200113414, 'macro avg': {'precision': 0.32720262320621035, 'recall': 0.3333750028128308, 'f1-score': 0.13437570347012565, 'support': 1269680}, 'weighted avg': {'precision': 0.3368890333191687, 'recall': 0.25003544200113414, 'f1-score': 0.10113250477429611, 'support': 1269680}}
[[   367 469464    503]
 [   208 316634    305]
 [   425 481310    464]]
Evaluating performance on  train set...
1691/1691 - 25s - 25s/epoch - 15ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1206977
{'0': {'precision': 0.3228915662650602, 'recall': 0.0009058767061241322, 'f1-score': 0.0018066847335140017, 'support': 147923}, '1': {'precision': 0.3275210741741359, 'recall': 0.9968027667007799, 'f1-score': 0.4930424157793682, 'support': 141685}, '2': {'precision': 0.34761120263591433, 'recall': 0.002946186712837555, 'f1-score': 0.005842852197992386, 'support': 143236}, 'accuracy': 0.32757298241398747, 'macro avg': {'precision': 0.33267461435837015, 'recall': 0.3335516100399139, 'f1-score': 0.1668973175702915, 'support': 432844}, 'weighted avg': {'precision': 0.33258714634313236, 'recall': 0.32757298241398747, 'f1-score': 0.16394098493444986, 'support': 432844}}
[[   134 147345    444]
 [   105 141232    348]
 [   176 142638    422]]
Evaluating performance on  val set...
591/591 - 9s - 9s/epoch - 14ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1375328
{'0': {'precision': 0.379746835443038, 'recall': 0.0011038136762514486, 'f1-score': 0.0022012290195359075, 'support': 54357}, '1': {'precision': 0.2803372578201823, 'recall': 0.9965987197959232, 'f1-score': 0.43758458865928596, 'support': 42337}, '2': {'precision': 0.38675213675213677, 'recall': 0.003324761204996326, 'f1-score': 0.006592846215487725, 'support': 54440}, 'accuracy': 0.28077070679000093, 'macro avg': {'precision': 0.348945410005119, 'recall': 0.3336757648923903, 'f1-score': 0.14879288796476986, 'support': 151134}, 'weighted avg': {'precision': 0.354422721183166, 'recall': 0.28077070679000093, 'f1-score': 0.12574659232108099, 'support': 151134}}
[[   60 54109   188]
 [   45 42193    99]
 [   53 54206   181]]
training model: results/ATVI/W8/deepLOB_L2/h1000
Epoch 1/50
1691/1691 - 73s - loss: 3.2626 - accuracy1000: 0.4018 - val_loss: 3.3516 - val_accuracy1000: 0.3387 - 73s/epoch - 43ms/step
Epoch 2/50
1691/1691 - 70s - loss: 3.2139 - accuracy1000: 0.4249 - val_loss: 3.4571 - val_accuracy1000: 0.3225 - 70s/epoch - 41ms/step
Epoch 3/50
1691/1691 - 70s - loss: 3.1838 - accuracy1000: 0.4373 - val_loss: 3.5226 - val_accuracy1000: 0.3436 - 70s/epoch - 41ms/step
Epoch 4/50
1691/1691 - 70s - loss: 3.1626 - accuracy1000: 0.4444 - val_loss: 3.5521 - val_accuracy1000: 0.3428 - 70s/epoch - 41ms/step
Epoch 5/50
1691/1691 - 71s - loss: 3.1500 - accuracy1000: 0.4486 - val_loss: 3.6347 - val_accuracy1000: 0.3467 - 71s/epoch - 42ms/step
Epoch 6/50
1691/1691 - 71s - loss: 3.1308 - accuracy1000: 0.4559 - val_loss: 3.6869 - val_accuracy1000: 0.3423 - 71s/epoch - 42ms/step
Epoch 7/50
1691/1691 - 69s - loss: 3.1182 - accuracy1000: 0.4627 - val_loss: 3.6857 - val_accuracy1000: 0.3461 - 69s/epoch - 41ms/step
Epoch 8/50
1691/1691 - 70s - loss: 3.1018 - accuracy1000: 0.4683 - val_loss: 3.7354 - val_accuracy1000: 0.3424 - 70s/epoch - 42ms/step
Epoch 9/50
1691/1691 - 70s - loss: 3.0903 - accuracy1000: 0.4725 - val_loss: 3.8200 - val_accuracy1000: 0.3427 - 70s/epoch - 41ms/step
Epoch 10/50
1691/1691 - 69s - loss: 3.0769 - accuracy1000: 0.4779 - val_loss: 3.8486 - val_accuracy1000: 0.3399 - 69s/epoch - 41ms/step
Epoch 11/50
1691/1691 - 70s - loss: 3.0676 - accuracy1000: 0.4805 - val_loss: 3.9373 - val_accuracy1000: 0.3339 - 70s/epoch - 42ms/step
testing model: results/ATVI/W8/deepLOB_L2/h1000
Evaluating performance on  test set...
4960/4960 - 72s - 72s/epoch - 14ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1263053
{'0': {'precision': 0.33258891261955614, 'recall': 0.17555601847880697, 'f1-score': 0.2298083940874057, 'support': 408035}, '1': {'precision': 0.35495635128666836, 'recall': 0.7227238237116345, 'f1-score': 0.4760882076225167, 'support': 430953}, '2': {'precision': 0.3452895272562769, 'recall': 0.14177416808299204, 'f1-score': 0.20101327995891577, 'support': 430692}, 'accuracy': 0.34981570159410247, 'macro avg': {'precision': 0.34427826372083375, 'recall': 0.3466846700911445, 'f1-score': 0.3023032938896127, 'support': 1269680}, 'weighted avg': {'precision': 0.3444890511702355, 'recall': 0.34981570159410247, 'f1-score': 0.3036326641303843, 'support': 1269680}}
[[ 71633 276582  59820]
 [ 63534 311460  55959]
 [ 80213 289418  61061]]
Evaluating performance on  train set...
1691/1691 - 26s - 26s/epoch - 15ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1277364
{'0': {'precision': 0.40180188337558853, 'recall': 0.05944885054391512, 'f1-score': 0.10357342918495005, 'support': 149288}, '1': {'precision': 0.3269793613279103, 'recall': 0.6855091355606289, 'f1-score': 0.44276520675323344, 'support': 138853}, '2': {'precision': 0.3255022899742587, 'recall': 0.26915129610305244, 'f1-score': 0.2946568061886478, 'support': 144703}, 'accuracy': 0.3303892395412666, 'macro avg': {'precision': 0.35142784489258583, 'recall': 0.3380364274025321, 'f1-score': 0.2803318140422771, 'support': 432844}, 'weighted avg': {'precision': 0.3522918711821911, 'recall': 0.3303892395412666, 'f1-score': 0.2762641302071542, 'support': 432844}}
[[ 8875 98224 42189]
 [ 5152 95185 38516]
 [ 8061 97695 38947]]
Evaluating performance on  val set...
591/591 - 8s - 8s/epoch - 14ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1226312
{'0': {'precision': 0.3731105807478122, 'recall': 0.008897067192776113, 'f1-score': 0.0173797039150655, 'support': 52714}, '1': {'precision': 0.3248411257376305, 'recall': 0.6323451444729169, 'f1-score': 0.4291990283983567, 'support': 45268}, '2': {'precision': 0.35893906763605743, 'recall': 0.41704921733895245, 'f1-score': 0.38581834321071456, 'support': 53152}, 'accuracy': 0.3391758307197586, 'macro avg': {'precision': 0.3522969247071668, 'recall': 0.35276380966821513, 'f1-score': 0.2774656918413789, 'support': 151134}, 'weighted avg': {'precision': 0.35366885384111424, 'recall': 0.3391758307197586, 'f1-score': 0.2703041797878139, 'support': 151134}}
[[  469 28990 23255]
 [  308 28625 16335]
 [  480 30505 22167]]
training model: results/ATVI/W8/deepOF_L2/h10
Epoch 1/50
1691/1691 - 41s - loss: 2.9328 - accuracy10: 0.5027 - val_loss: 3.0132 - val_accuracy10: 0.5600 - 41s/epoch - 25ms/step
Epoch 2/50
1691/1691 - 39s - loss: 2.7132 - accuracy10: 0.5691 - val_loss: 2.8976 - val_accuracy10: 0.5675 - 39s/epoch - 23ms/step
Epoch 3/50
1691/1691 - 39s - loss: 2.6494 - accuracy10: 0.5813 - val_loss: 2.8672 - val_accuracy10: 0.5731 - 39s/epoch - 23ms/step
Epoch 4/50
1691/1691 - 39s - loss: 2.6207 - accuracy10: 0.5856 - val_loss: 2.8544 - val_accuracy10: 0.5762 - 39s/epoch - 23ms/step
Epoch 5/50
1691/1691 - 38s - loss: 2.6015 - accuracy10: 0.5888 - val_loss: 2.8597 - val_accuracy10: 0.5764 - 38s/epoch - 23ms/step
Epoch 6/50
1691/1691 - 39s - loss: 2.5872 - accuracy10: 0.5902 - val_loss: 2.8532 - val_accuracy10: 0.5814 - 39s/epoch - 23ms/step
Epoch 7/50
1691/1691 - 39s - loss: 2.5759 - accuracy10: 0.5927 - val_loss: 2.8408 - val_accuracy10: 0.5798 - 39s/epoch - 23ms/step
Epoch 8/50
1691/1691 - 39s - loss: 2.5660 - accuracy10: 0.5942 - val_loss: 2.8416 - val_accuracy10: 0.5823 - 39s/epoch - 23ms/step
Epoch 9/50
1691/1691 - 40s - loss: 2.5571 - accuracy10: 0.5960 - val_loss: 2.8532 - val_accuracy10: 0.5814 - 40s/epoch - 23ms/step
Epoch 10/50
1691/1691 - 40s - loss: 2.5496 - accuracy10: 0.5979 - val_loss: 2.8402 - val_accuracy10: 0.5832 - 40s/epoch - 24ms/step
Epoch 11/50
1691/1691 - 40s - loss: 2.5427 - accuracy10: 0.5987 - val_loss: 2.8334 - val_accuracy10: 0.5833 - 40s/epoch - 24ms/step
Epoch 12/50
1691/1691 - 40s - loss: 2.5349 - accuracy10: 0.6005 - val_loss: 2.8272 - val_accuracy10: 0.5853 - 40s/epoch - 23ms/step
Epoch 13/50
1691/1691 - 40s - loss: 2.5289 - accuracy10: 0.6012 - val_loss: 2.8339 - val_accuracy10: 0.5851 - 40s/epoch - 24ms/step
Epoch 14/50
1691/1691 - 39s - loss: 2.5231 - accuracy10: 0.6023 - val_loss: 2.8379 - val_accuracy10: 0.5905 - 39s/epoch - 23ms/step
Epoch 15/50
1691/1691 - 39s - loss: 2.5168 - accuracy10: 0.6034 - val_loss: 2.8192 - val_accuracy10: 0.5857 - 39s/epoch - 23ms/step
Epoch 16/50
1691/1691 - 40s - loss: 2.5130 - accuracy10: 0.6042 - val_loss: 2.8197 - val_accuracy10: 0.5889 - 40s/epoch - 24ms/step
Epoch 17/50
1691/1691 - 39s - loss: 2.5069 - accuracy10: 0.6051 - val_loss: 2.8147 - val_accuracy10: 0.5906 - 39s/epoch - 23ms/step
Epoch 18/50
1691/1691 - 40s - loss: 2.5027 - accuracy10: 0.6058 - val_loss: 2.8109 - val_accuracy10: 0.5914 - 40s/epoch - 24ms/step
Epoch 19/50
1691/1691 - 39s - loss: 2.4978 - accuracy10: 0.6070 - val_loss: 2.8073 - val_accuracy10: 0.5869 - 39s/epoch - 23ms/step
Epoch 20/50
1691/1691 - 39s - loss: 2.4927 - accuracy10: 0.6077 - val_loss: 2.8107 - val_accuracy10: 0.5904 - 39s/epoch - 23ms/step
Epoch 21/50
1691/1691 - 39s - loss: 2.4875 - accuracy10: 0.6086 - val_loss: 2.8161 - val_accuracy10: 0.5858 - 39s/epoch - 23ms/step
Epoch 22/50
1691/1691 - 39s - loss: 2.4842 - accuracy10: 0.6090 - val_loss: 2.7923 - val_accuracy10: 0.5893 - 39s/epoch - 23ms/step
Epoch 23/50
1691/1691 - 38s - loss: 2.4810 - accuracy10: 0.6091 - val_loss: 2.7930 - val_accuracy10: 0.5854 - 38s/epoch - 22ms/step
Epoch 24/50
1691/1691 - 39s - loss: 2.4752 - accuracy10: 0.6104 - val_loss: 2.7997 - val_accuracy10: 0.5844 - 39s/epoch - 23ms/step
Epoch 25/50
1691/1691 - 38s - loss: 2.4715 - accuracy10: 0.6109 - val_loss: 2.7993 - val_accuracy10: 0.5839 - 38s/epoch - 23ms/step
Epoch 26/50
1691/1691 - 37s - loss: 2.4672 - accuracy10: 0.6116 - val_loss: 2.7931 - val_accuracy10: 0.5870 - 37s/epoch - 22ms/step
Epoch 27/50
1691/1691 - 38s - loss: 2.4627 - accuracy10: 0.6123 - val_loss: 2.7976 - val_accuracy10: 0.5843 - 38s/epoch - 22ms/step
Epoch 28/50
1691/1691 - 38s - loss: 2.4582 - accuracy10: 0.6128 - val_loss: 2.8076 - val_accuracy10: 0.5880 - 38s/epoch - 22ms/step
Epoch 29/50
1691/1691 - 38s - loss: 2.4552 - accuracy10: 0.6133 - val_loss: 2.7969 - val_accuracy10: 0.5860 - 38s/epoch - 22ms/step
Epoch 30/50
1691/1691 - 38s - loss: 2.4523 - accuracy10: 0.6140 - val_loss: 2.7968 - val_accuracy10: 0.5892 - 38s/epoch - 23ms/step
Epoch 31/50
1691/1691 - 38s - loss: 2.4479 - accuracy10: 0.6145 - val_loss: 2.8051 - val_accuracy10: 0.5855 - 38s/epoch - 23ms/step
Epoch 32/50
1691/1691 - 37s - loss: 2.4428 - accuracy10: 0.6156 - val_loss: 2.8169 - val_accuracy10: 0.5845 - 37s/epoch - 22ms/step
testing model: results/ATVI/W8/deepOF_L2/h10
Evaluating performance on  test set...
4960/4960 - 38s - 38s/epoch - 8ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.8053278
{'0': {'precision': 0.4313728607173174, 'recall': 0.5438944608798134, 'f1-score': 0.4811425633205968, 'support': 249462}, '1': {'precision': 0.7844706815468108, 'recall': 0.7048951103123451, 'f1-score': 0.7425570677509318, 'support': 774528}, '2': {'precision': 0.46198216690266647, 'recall': 0.48735983067749356, 'f1-score': 0.4743318028942333, 'support': 245685}, 'accuracy': 0.6311686061393664, 'macro avg': {'precision': 0.5592752363889316, 'recall': 0.578716467289884, 'f1-score': 0.5660104779885874, 'support': 1269675}, 'weighted avg': {'precision': 0.6526928019318592, 'recall': 0.6311686061393664, 'f1-score': 0.6392929180271693, 'support': 1269675}}
[[135681  70944  42837]
 [131960 545961  96607]
 [ 46892  79056 119737]]
Evaluating performance on  train set...
1691/1691 - 14s - 14s/epoch - 8ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.8215572
{'0': {'precision': 0.48428795886301956, 'recall': 0.553573615249602, 'f1-score': 0.5166180980134468, 'support': 97996}, '1': {'precision': 0.7594875750987681, 'recall': 0.6823787880060826, 'f1-score': 0.7188713521072534, 'support': 238054}, '2': {'precision': 0.4917243314007855, 'recall': 0.5432839830149497, 'f1-score': 0.5162199174401539, 'support': 96791}, 'accuracy': 0.6221129698896362, 'macro avg': {'precision': 0.5784999551208577, 'recall': 0.5930787954235447, 'f1-score': 0.5839031225202848, 'support': 432841}, 'weighted avg': {'precision': 0.6373052178049584, 'recall': 0.6221129698896362, 'f1-score': 0.6277643523058485, 'support': 432841}}
[[ 54248  25369  18379]
 [ 39635 162443  35976]
 [ 18133  26073  52585]]
Evaluating performance on  val set...
591/591 - 5s - 5s/epoch - 8ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.8711911
{'0': {'precision': 0.4673527923063945, 'recall': 0.5322244180939834, 'f1-score': 0.49768355128912617, 'support': 36432}, '1': {'precision': 0.7441016064971249, 'recall': 0.6462071095781101, 'f1-score': 0.6917078815765908, 'support': 77698}, '2': {'precision': 0.4615585277935876, 'recall': 0.5259843796448936, 'f1-score': 0.49166992964595624, 'support': 37003}, 'accuracy': 0.5892955211634785, 'macro avg': {'precision': 0.557670975532369, 'recall': 0.5681386357723289, 'f1-score': 0.5603537875038911, 'support': 151133}, 'weighted avg': {'precision': 0.608211666246725, 'recall': 0.5892955211634785, 'f1-score': 0.5959597740400356, 'support': 151133}}
[[19390  8125  8917]
 [13701 50209 13788]
 [ 8398  9142 19463]]
training model: results/ATVI/W8/deepOF_L2/h20
Epoch 1/50
1691/1691 - 42s - loss: 2.9873 - accuracy20: 0.4900 - val_loss: 3.0515 - val_accuracy20: 0.5141 - 42s/epoch - 25ms/step
Epoch 2/50
1691/1691 - 39s - loss: 2.7855 - accuracy20: 0.5536 - val_loss: 2.9412 - val_accuracy20: 0.5394 - 39s/epoch - 23ms/step
Epoch 3/50
1691/1691 - 39s - loss: 2.7250 - accuracy20: 0.5669 - val_loss: 2.9124 - val_accuracy20: 0.5468 - 39s/epoch - 23ms/step
Epoch 4/50
1691/1691 - 38s - loss: 2.6982 - accuracy20: 0.5715 - val_loss: 2.8906 - val_accuracy20: 0.5473 - 38s/epoch - 22ms/step
Epoch 5/50
1691/1691 - 38s - loss: 2.6809 - accuracy20: 0.5749 - val_loss: 2.8838 - val_accuracy20: 0.5501 - 38s/epoch - 22ms/step
Epoch 6/50
1691/1691 - 38s - loss: 2.6694 - accuracy20: 0.5776 - val_loss: 2.8764 - val_accuracy20: 0.5513 - 38s/epoch - 23ms/step
Epoch 7/50
1691/1691 - 38s - loss: 2.6590 - accuracy20: 0.5787 - val_loss: 2.8808 - val_accuracy20: 0.5515 - 38s/epoch - 23ms/step
Epoch 8/50
1691/1691 - 38s - loss: 2.6501 - accuracy20: 0.5802 - val_loss: 2.8684 - val_accuracy20: 0.5517 - 38s/epoch - 22ms/step
Epoch 9/50
1691/1691 - 38s - loss: 2.6435 - accuracy20: 0.5825 - val_loss: 2.8647 - val_accuracy20: 0.5510 - 38s/epoch - 22ms/step
Epoch 10/50
1691/1691 - 37s - loss: 2.6364 - accuracy20: 0.5835 - val_loss: 2.8652 - val_accuracy20: 0.5528 - 37s/epoch - 22ms/step
Epoch 11/50
1691/1691 - 38s - loss: 2.6308 - accuracy20: 0.5845 - val_loss: 2.8572 - val_accuracy20: 0.5529 - 38s/epoch - 22ms/step
Epoch 12/50
1691/1691 - 38s - loss: 2.6245 - accuracy20: 0.5855 - val_loss: 2.8608 - val_accuracy20: 0.5532 - 38s/epoch - 23ms/step
Epoch 13/50
1691/1691 - 37s - loss: 2.6178 - accuracy20: 0.5868 - val_loss: 2.8521 - val_accuracy20: 0.5536 - 37s/epoch - 22ms/step
Epoch 14/50
1691/1691 - 38s - loss: 2.6120 - accuracy20: 0.5877 - val_loss: 2.8595 - val_accuracy20: 0.5524 - 38s/epoch - 22ms/step
Epoch 15/50
1691/1691 - 38s - loss: 2.6080 - accuracy20: 0.5896 - val_loss: 2.8457 - val_accuracy20: 0.5530 - 38s/epoch - 22ms/step
Epoch 16/50
1691/1691 - 37s - loss: 2.6034 - accuracy20: 0.5898 - val_loss: 2.8393 - val_accuracy20: 0.5557 - 37s/epoch - 22ms/step
Epoch 17/50
1691/1691 - 37s - loss: 2.5991 - accuracy20: 0.5909 - val_loss: 2.8404 - val_accuracy20: 0.5566 - 37s/epoch - 22ms/step
Epoch 18/50
1691/1691 - 38s - loss: 2.5934 - accuracy20: 0.5923 - val_loss: 2.8446 - val_accuracy20: 0.5532 - 38s/epoch - 22ms/step
Epoch 19/50
1691/1691 - 38s - loss: 2.5890 - accuracy20: 0.5933 - val_loss: 2.8453 - val_accuracy20: 0.5548 - 38s/epoch - 22ms/step
Epoch 20/50
1691/1691 - 37s - loss: 2.5851 - accuracy20: 0.5942 - val_loss: 2.8482 - val_accuracy20: 0.5547 - 37s/epoch - 22ms/step
Epoch 21/50
1691/1691 - 37s - loss: 2.5805 - accuracy20: 0.5944 - val_loss: 2.8455 - val_accuracy20: 0.5549 - 37s/epoch - 22ms/step
Epoch 22/50
1691/1691 - 37s - loss: 2.5758 - accuracy20: 0.5956 - val_loss: 2.8481 - val_accuracy20: 0.5564 - 37s/epoch - 22ms/step
Epoch 23/50
1691/1691 - 37s - loss: 2.5723 - accuracy20: 0.5962 - val_loss: 2.8561 - val_accuracy20: 0.5544 - 37s/epoch - 22ms/step
Epoch 24/50
1691/1691 - 38s - loss: 2.5677 - accuracy20: 0.5973 - val_loss: 2.8521 - val_accuracy20: 0.5561 - 38s/epoch - 22ms/step
Epoch 25/50
1691/1691 - 38s - loss: 2.5632 - accuracy20: 0.5973 - val_loss: 2.8477 - val_accuracy20: 0.5560 - 38s/epoch - 23ms/step
Epoch 26/50
1691/1691 - 38s - loss: 2.5595 - accuracy20: 0.5989 - val_loss: 2.8504 - val_accuracy20: 0.5529 - 38s/epoch - 22ms/step
testing model: results/ATVI/W8/deepOF_L2/h20
Evaluating performance on  test set...
4960/4960 - 38s - 38s/epoch - 8ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.868761
{'0': {'precision': 0.46635365183964855, 'recall': 0.5401676674129859, 'f1-score': 0.5005540558063869, 'support': 314432}, '1': {'precision': 0.6977202456635873, 'recall': 0.6924753280538422, 'f1-score': 0.6950878928692455, 'support': 644254}, '2': {'precision': 0.5125420951350051, 'recall': 0.43850104022971875, 'f1-score': 0.47263942826742084, 'support': 310989}, 'accuracy': 0.5925492744206194, 'macro avg': {'precision': 0.5588719975460803, 'recall': 0.5570480118988489, 'f1-score': 0.5560937923143511, 'support': 1269675}, 'weighted avg': {'precision': 0.5950660792950426, 'recall': 0.5925492744206194, 'f1-score': 0.5924264330362917, 'support': 1269675}}
[[169846  91677  52909]
 [121338 446130  76786]
 [ 73016 101604 136369]]
Evaluating performance on  train set...
1691/1691 - 13s - 13s/epoch - 8ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.8806172
{'0': {'precision': 0.5061774107014667, 'recall': 0.5533746385790995, 'f1-score': 0.5287248359229163, 'support': 121050}, '1': {'precision': 0.6633362698865108, 'recall': 0.6651078688115725, 'f1-score': 0.6642208880563324, 'support': 192456}, '2': {'precision': 0.5359700187847565, 'recall': 0.4829681149704613, 'f1-score': 0.5080905720922647, 'support': 119335}, 'accuracy': 0.5836438784680749, 'macro avg': {'precision': 0.568494566457578, 'recall': 0.567150207453711, 'f1-score': 0.5670120986905044, 'support': 432841}, 'weighted avg': {'precision': 0.5842695190944707, 'recall': 0.5836438784680749, 'f1-score': 0.583282140649497, 'support': 432841}}
[[ 66986  31575  22489]
 [ 37042 128004  27410]
 [ 28309  33391  57635]]
Evaluating performance on  val set...
591/591 - 5s - 5s/epoch - 8ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.9189224
{'0': {'precision': 0.48374275236124487, 'recall': 0.5371385672361626, 'f1-score': 0.5090442619063019, 'support': 43957}, '1': {'precision': 0.6448181307608444, 'recall': 0.6294301654358412, 'f1-score': 0.6370312347008714, 'support': 62018}, '2': {'precision': 0.5077059302158617, 'recall': 0.46979494220293194, 'f1-score': 0.48801527419948476, 'support': 45158}, 'accuracy': 0.5548887403809889, 'macro avg': {'precision': 0.5454222711126503, 'recall': 0.5454545582916452, 'f1-score': 0.5446969236022193, 'support': 151133}, 'weighted avg': {'precision': 0.5570007569211037, 'recall': 0.5548887403809889, 'f1-score': 0.5552808154843369, 'support': 151133}}
[[23611 10103 10243]
 [12654 39036 10328]
 [12544 11399 21215]]
training model: results/ATVI/W8/deepOF_L2/h30
Epoch 1/50
1691/1691 - 40s - loss: 3.0328 - accuracy30: 0.4761 - val_loss: 3.0757 - val_accuracy30: 0.4754 - 40s/epoch - 24ms/step
Epoch 2/50
1691/1691 - 37s - loss: 2.8505 - accuracy30: 0.5302 - val_loss: 2.9610 - val_accuracy30: 0.5104 - 37s/epoch - 22ms/step
Epoch 3/50
1691/1691 - 37s - loss: 2.7919 - accuracy30: 0.5450 - val_loss: 2.9375 - val_accuracy30: 0.5172 - 37s/epoch - 22ms/step
Epoch 4/50
1691/1691 - 38s - loss: 2.7671 - accuracy30: 0.5509 - val_loss: 2.9132 - val_accuracy30: 0.5243 - 38s/epoch - 22ms/step
Epoch 5/50
1691/1691 - 37s - loss: 2.7516 - accuracy30: 0.5544 - val_loss: 2.8947 - val_accuracy30: 0.5267 - 37s/epoch - 22ms/step
Epoch 6/50
1691/1691 - 37s - loss: 2.7399 - accuracy30: 0.5565 - val_loss: 2.8994 - val_accuracy30: 0.5272 - 37s/epoch - 22ms/step
Epoch 7/50
1691/1691 - 39s - loss: 2.7320 - accuracy30: 0.5579 - val_loss: 2.8914 - val_accuracy30: 0.5297 - 39s/epoch - 23ms/step
Epoch 8/50
1691/1691 - 39s - loss: 2.7225 - accuracy30: 0.5610 - val_loss: 2.8973 - val_accuracy30: 0.5287 - 39s/epoch - 23ms/step
Epoch 9/50
1691/1691 - 38s - loss: 2.7170 - accuracy30: 0.5624 - val_loss: 2.8887 - val_accuracy30: 0.5298 - 38s/epoch - 23ms/step
Epoch 10/50
1691/1691 - 38s - loss: 2.7104 - accuracy30: 0.5635 - val_loss: 2.8928 - val_accuracy30: 0.5289 - 38s/epoch - 22ms/step
Epoch 11/50
1691/1691 - 38s - loss: 2.7055 - accuracy30: 0.5645 - val_loss: 2.8883 - val_accuracy30: 0.5292 - 38s/epoch - 22ms/step
Epoch 12/50
1691/1691 - 37s - loss: 2.6994 - accuracy30: 0.5663 - val_loss: 2.8840 - val_accuracy30: 0.5294 - 37s/epoch - 22ms/step
Epoch 13/50
1691/1691 - 38s - loss: 2.6946 - accuracy30: 0.5674 - val_loss: 2.8836 - val_accuracy30: 0.5300 - 38s/epoch - 23ms/step
Epoch 14/50
1691/1691 - 38s - loss: 2.6891 - accuracy30: 0.5684 - val_loss: 2.8872 - val_accuracy30: 0.5291 - 38s/epoch - 22ms/step
Epoch 15/50
1691/1691 - 37s - loss: 2.6848 - accuracy30: 0.5696 - val_loss: 2.8833 - val_accuracy30: 0.5307 - 37s/epoch - 22ms/step
Epoch 16/50
1691/1691 - 37s - loss: 2.6787 - accuracy30: 0.5698 - val_loss: 2.8843 - val_accuracy30: 0.5313 - 37s/epoch - 22ms/step
Epoch 17/50
1691/1691 - 37s - loss: 2.6741 - accuracy30: 0.5715 - val_loss: 2.8802 - val_accuracy30: 0.5304 - 37s/epoch - 22ms/step
Epoch 18/50
1691/1691 - 37s - loss: 2.6707 - accuracy30: 0.5719 - val_loss: 2.8774 - val_accuracy30: 0.5285 - 37s/epoch - 22ms/step
Epoch 19/50
1691/1691 - 38s - loss: 2.6663 - accuracy30: 0.5725 - val_loss: 2.8797 - val_accuracy30: 0.5293 - 38s/epoch - 22ms/step
Epoch 20/50
1691/1691 - 38s - loss: 2.6616 - accuracy30: 0.5739 - val_loss: 2.8774 - val_accuracy30: 0.5304 - 38s/epoch - 22ms/step
Epoch 21/50
1691/1691 - 37s - loss: 2.6575 - accuracy30: 0.5748 - val_loss: 2.8872 - val_accuracy30: 0.5294 - 37s/epoch - 22ms/step
Epoch 22/50
1691/1691 - 37s - loss: 2.6522 - accuracy30: 0.5763 - val_loss: 2.8861 - val_accuracy30: 0.5284 - 37s/epoch - 22ms/step
Epoch 23/50
1691/1691 - 38s - loss: 2.6484 - accuracy30: 0.5768 - val_loss: 2.8854 - val_accuracy30: 0.5287 - 38s/epoch - 22ms/step
Epoch 24/50
1691/1691 - 37s - loss: 2.6445 - accuracy30: 0.5779 - val_loss: 2.8800 - val_accuracy30: 0.5297 - 37s/epoch - 22ms/step
Epoch 25/50
1691/1691 - 39s - loss: 2.6414 - accuracy30: 0.5781 - val_loss: 2.8761 - val_accuracy30: 0.5323 - 39s/epoch - 23ms/step
Epoch 26/50
1691/1691 - 37s - loss: 2.6372 - accuracy30: 0.5796 - val_loss: 2.8792 - val_accuracy30: 0.5291 - 37s/epoch - 22ms/step
Epoch 27/50
1691/1691 - 38s - loss: 2.6325 - accuracy30: 0.5805 - val_loss: 2.8840 - val_accuracy30: 0.5299 - 38s/epoch - 22ms/step
Epoch 28/50
1691/1691 - 37s - loss: 2.6277 - accuracy30: 0.5810 - val_loss: 2.8826 - val_accuracy30: 0.5293 - 37s/epoch - 22ms/step
Epoch 29/50
1691/1691 - 37s - loss: 2.6246 - accuracy30: 0.5820 - val_loss: 2.8893 - val_accuracy30: 0.5283 - 37s/epoch - 22ms/step
Epoch 30/50
1691/1691 - 37s - loss: 2.6204 - accuracy30: 0.5825 - val_loss: 2.8899 - val_accuracy30: 0.5290 - 37s/epoch - 22ms/step
Epoch 31/50
1691/1691 - 38s - loss: 2.6152 - accuracy30: 0.5837 - val_loss: 2.8952 - val_accuracy30: 0.5270 - 38s/epoch - 22ms/step
Epoch 32/50
1691/1691 - 37s - loss: 2.6105 - accuracy30: 0.5849 - val_loss: 2.9000 - val_accuracy30: 0.5255 - 37s/epoch - 22ms/step
Epoch 33/50
1691/1691 - 37s - loss: 2.6074 - accuracy30: 0.5855 - val_loss: 2.9017 - val_accuracy30: 0.5270 - 37s/epoch - 22ms/step
Epoch 34/50
1691/1691 - 37s - loss: 2.6042 - accuracy30: 0.5863 - val_loss: 2.9089 - val_accuracy30: 0.5256 - 37s/epoch - 22ms/step
Epoch 35/50
1691/1691 - 37s - loss: 2.5997 - accuracy30: 0.5874 - val_loss: 2.9126 - val_accuracy30: 0.5232 - 37s/epoch - 22ms/step
testing model: results/ATVI/W8/deepOF_L2/h30
Evaluating performance on  test set...
4960/4960 - 38s - 38s/epoch - 8ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.9094875
{'0': {'precision': 0.49450974305428175, 'recall': 0.4895870003743874, 'f1-score': 0.4920360592076353, 'support': 357918}, '1': {'precision': 0.6250869311571156, 'recall': 0.6809632125756941, 'f1-score': 0.6518298042726796, 'support': 557011}, '2': {'precision': 0.5148872999306361, 'recall': 0.4477908137089636, 'f1-score': 0.4790008201862306, 'support': 354746}, 'accuracy': 0.5618666194104791, 'macro avg': {'precision': 0.5448279913806778, 'recall': 0.5394470088863484, 'f1-score': 0.5409555612221818, 'support': 1269675}, 'weighted avg': {'precision': 0.5574878964510224, 'recall': 0.5618666194104791, 'f1-score': 0.5584961177505996, 'support': 1269675}}
[[175232 112804  69882]
 [ 97923 379304  79784]
 [ 81200 114694 158852]]
Evaluating performance on  train set...
1691/1691 - 14s - 14s/epoch - 8ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.90696037
{'0': {'precision': 0.5380498710768008, 'recall': 0.5064599862147854, 'f1-score': 0.521777230508897, 'support': 136378}, '1': {'precision': 0.5929347223761499, 'recall': 0.6574198661825152, 'f1-score': 0.6235144324760575, 'support': 162759}, '2': {'precision': 0.541649866946214, 'recall': 0.5023783880811344, 'f1-score': 0.5212755224784061, 'support': 133704}, 'accuracy': 0.5619638620186166, 'macro avg': {'precision': 0.5575448201330548, 'recall': 0.5554194134928117, 'f1-score': 0.5555223951544536, 'support': 432841}, 'weighted avg': {'precision': 0.5597999764511872, 'recall': 0.5619638620186166, 'f1-score': 0.5598779762433915, 'support': 432841}}
[[ 69070  37452  29856]
 [ 28774 107001  26984]
 [ 30527  36007  67170]]
Evaluating performance on  val set...
591/591 - 5s - 5s/epoch - 8ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.9498341
{'0': {'precision': 0.5073095772074092, 'recall': 0.4998670022302703, 'f1-score': 0.5035607911036906, 'support': 48873}, '1': {'precision': 0.5693036940176528, 'recall': 0.6034187376080387, 'f1-score': 0.5858650045322443, 'support': 51949}, '2': {'precision': 0.5125534801210477, 'recall': 0.4881437459004989, 'f1-score': 0.5000509030195672, 'support': 50311}, 'accuracy': 0.5315582963350162, 'macro avg': {'precision': 0.5297222504487032, 'recall': 0.5304764952462693, 'f1-score': 0.5298255662185006, 'support': 151133}, 'weighted avg': {'precision': 0.5303644915786148, 'recall': 0.5315582963350162, 'f1-score': 0.5306828333049279, 'support': 151133}}
[[24430 11455 12988]
 [10234 31347 10368]
 [13492 12260 24559]]
training model: results/ATVI/W8/deepOF_L2/h50
Epoch 1/50
1691/1691 - 41s - loss: 3.1152 - accuracy50: 0.4489 - val_loss: 3.1605 - val_accuracy50: 0.4238 - 41s/epoch - 24ms/step
Epoch 2/50
1691/1691 - 38s - loss: 2.9903 - accuracy50: 0.4874 - val_loss: 3.0903 - val_accuracy50: 0.4554 - 38s/epoch - 22ms/step
Epoch 3/50
1691/1691 - 37s - loss: 2.9458 - accuracy50: 0.4997 - val_loss: 3.0276 - val_accuracy50: 0.4770 - 37s/epoch - 22ms/step
Epoch 4/50
1691/1691 - 37s - loss: 2.9216 - accuracy50: 0.5068 - val_loss: 3.0096 - val_accuracy50: 0.4843 - 37s/epoch - 22ms/step
Epoch 5/50
1691/1691 - 38s - loss: 2.9076 - accuracy50: 0.5108 - val_loss: 3.0043 - val_accuracy50: 0.4869 - 38s/epoch - 22ms/step
Epoch 6/50
1691/1691 - 38s - loss: 2.8972 - accuracy50: 0.5132 - val_loss: 3.0017 - val_accuracy50: 0.4863 - 38s/epoch - 22ms/step
Epoch 7/50
1691/1691 - 37s - loss: 2.8891 - accuracy50: 0.5159 - val_loss: 3.0018 - val_accuracy50: 0.4882 - 37s/epoch - 22ms/step
Epoch 8/50
1691/1691 - 37s - loss: 2.8812 - accuracy50: 0.5182 - val_loss: 3.0044 - val_accuracy50: 0.4885 - 37s/epoch - 22ms/step
Epoch 9/50
1691/1691 - 38s - loss: 2.8764 - accuracy50: 0.5190 - val_loss: 2.9991 - val_accuracy50: 0.4887 - 38s/epoch - 22ms/step
Epoch 10/50
1691/1691 - 38s - loss: 2.8708 - accuracy50: 0.5206 - val_loss: 3.0027 - val_accuracy50: 0.4869 - 38s/epoch - 23ms/step
Epoch 11/50
1691/1691 - 38s - loss: 2.8658 - accuracy50: 0.5222 - val_loss: 3.0019 - val_accuracy50: 0.4878 - 38s/epoch - 22ms/step
Epoch 12/50
1691/1691 - 38s - loss: 2.8610 - accuracy50: 0.5239 - val_loss: 2.9955 - val_accuracy50: 0.4891 - 38s/epoch - 22ms/step
Epoch 13/50
1691/1691 - 37s - loss: 2.8559 - accuracy50: 0.5247 - val_loss: 3.0057 - val_accuracy50: 0.4870 - 37s/epoch - 22ms/step
Epoch 14/50
1691/1691 - 38s - loss: 2.8508 - accuracy50: 0.5269 - val_loss: 3.0099 - val_accuracy50: 0.4869 - 38s/epoch - 22ms/step
Epoch 15/50
1691/1691 - 37s - loss: 2.8470 - accuracy50: 0.5279 - val_loss: 3.0110 - val_accuracy50: 0.4874 - 37s/epoch - 22ms/step
Epoch 16/50
1691/1691 - 38s - loss: 2.8423 - accuracy50: 0.5287 - val_loss: 3.0156 - val_accuracy50: 0.4867 - 38s/epoch - 22ms/step
Epoch 17/50
1691/1691 - 38s - loss: 2.8389 - accuracy50: 0.5296 - val_loss: 3.0188 - val_accuracy50: 0.4863 - 38s/epoch - 23ms/step
Epoch 18/50
1691/1691 - 38s - loss: 2.8335 - accuracy50: 0.5306 - val_loss: 3.0111 - val_accuracy50: 0.4862 - 38s/epoch - 22ms/step
Epoch 19/50
1691/1691 - 38s - loss: 2.8297 - accuracy50: 0.5319 - val_loss: 3.0233 - val_accuracy50: 0.4849 - 38s/epoch - 22ms/step
Epoch 20/50
1691/1691 - 37s - loss: 2.8252 - accuracy50: 0.5326 - val_loss: 3.0313 - val_accuracy50: 0.4838 - 37s/epoch - 22ms/step
Epoch 21/50
1691/1691 - 37s - loss: 2.8210 - accuracy50: 0.5336 - val_loss: 3.0412 - val_accuracy50: 0.4790 - 37s/epoch - 22ms/step
Epoch 22/50
1691/1691 - 38s - loss: 2.8156 - accuracy50: 0.5357 - val_loss: 3.0355 - val_accuracy50: 0.4815 - 38s/epoch - 22ms/step
testing model: results/ATVI/W8/deepOF_L2/h50
Evaluating performance on  test set...
4960/4960 - 41s - 41s/epoch - 8ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.9747248
{'0': {'precision': 0.5098831920761201, 'recall': 0.36053272349527055, 'f1-score': 0.4223947945230057, 'support': 391798}, '1': {'precision': 0.5219459867340887, 'recall': 0.6716755061986447, 'f1-score': 0.5874196081818157, 'support': 486074}, '2': {'precision': 0.48711886382331954, 'recall': 0.4564385673412404, 'f1-score': 0.47127992210074987, 'support': 391803}, 'accuracy': 0.5092437040975053, 'macro avg': {'precision': 0.5063160142111761, 'recall': 0.4962155990117185, 'f1-score': 0.49369810826852384, 'support': 1269675}, 'weighted avg': {'precision': 0.5074764964635778, 'recall': 0.5092437040975053, 'f1-score': 0.5006570355805483, 'support': 1269675}}
[[141256 159574  90968]
 [ 62266 326484  97324]
 [ 73514 139455 178834]]
Evaluating performance on  train set...
1691/1691 - 14s - 14s/epoch - 8ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.97930115
{'0': {'precision': 0.5334698676375773, 'recall': 0.38442459978545906, 'f1-score': 0.4468464461713796, 'support': 146359}, '1': {'precision': 0.4891529848927215, 'recall': 0.628963057892684, 'f1-score': 0.5503170429234374, 'support': 143576}, '2': {'precision': 0.5017371812832726, 'recall': 0.5012245811932319, 'f1-score': 0.5014807502467916, 'support': 142906}, 'accuracy': 0.5041019681592086, 'macro avg': {'precision': 0.5081200112711906, 'recall': 0.5048707462904584, 'f1-score': 0.4995480797805362, 'support': 432841}, 'weighted avg': {'precision': 0.5082928810925789, 'recall': 0.5041019681592086, 'f1-score': 0.49920623708183925, 'support': 432841}}
[[56264 52191 37904]
 [20044 90304 33228]
 [29160 42118 71628]]
Evaluating performance on  val set...
591/591 - 5s - 5s/epoch - 8ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.9992519
{'0': {'precision': 0.5067615322998633, 'recall': 0.40895091068101447, 'f1-score': 0.45263246496359577, 'support': 52598}, '1': {'precision': 0.4714231947954191, 'recall': 0.584247701123895, 'f1-score': 0.5218064055386386, 'support': 45022}, '2': {'precision': 0.49151068254868596, 'recall': 0.4857884999906565, 'f1-score': 0.4886328392996438, 'support': 53513}, 'accuracy': 0.48837778645299174, 'macro avg': {'precision': 0.48989846988132274, 'recall': 0.4929957039318553, 'f1-score': 0.4876905699339594, 'support': 151133}, 'weighted avg': {'precision': 0.49083435985003543, 'recall': 0.48837778645299174, 'f1-score': 0.4859861149567442, 'support': 151133}}
[[21510 15527 15561]
 [ 7385 26304 11333]
 [13551 13966 25996]]
training model: results/ATVI/W8/deepOF_L2/h100
Epoch 1/50
1691/1691 - 42s - loss: 3.2396 - accuracy100: 0.4004 - val_loss: 3.3662 - val_accuracy100: 0.3106 - 42s/epoch - 25ms/step
Epoch 2/50
1691/1691 - 38s - loss: 3.1866 - accuracy100: 0.4263 - val_loss: 3.3868 - val_accuracy100: 0.3075 - 38s/epoch - 22ms/step
Epoch 3/50
1691/1691 - 38s - loss: 3.1695 - accuracy100: 0.4317 - val_loss: 3.3935 - val_accuracy100: 0.3071 - 38s/epoch - 23ms/step
Epoch 4/50
1691/1691 - 38s - loss: 3.1607 - accuracy100: 0.4358 - val_loss: 3.4022 - val_accuracy100: 0.3095 - 38s/epoch - 22ms/step
Epoch 5/50
1691/1691 - 38s - loss: 3.1533 - accuracy100: 0.4390 - val_loss: 3.3933 - val_accuracy100: 0.3127 - 38s/epoch - 23ms/step
Epoch 6/50
1691/1691 - 38s - loss: 3.1475 - accuracy100: 0.4408 - val_loss: 3.3857 - val_accuracy100: 0.3149 - 38s/epoch - 22ms/step
Epoch 7/50
1691/1691 - 37s - loss: 3.1421 - accuracy100: 0.4428 - val_loss: 3.3779 - val_accuracy100: 0.3182 - 37s/epoch - 22ms/step
Epoch 8/50
1691/1691 - 37s - loss: 3.1370 - accuracy100: 0.4444 - val_loss: 3.3551 - val_accuracy100: 0.3253 - 37s/epoch - 22ms/step
Epoch 9/50
1691/1691 - 39s - loss: 3.1332 - accuracy100: 0.4458 - val_loss: 3.3501 - val_accuracy100: 0.3268 - 39s/epoch - 23ms/step
Epoch 10/50
1691/1691 - 39s - loss: 3.1280 - accuracy100: 0.4483 - val_loss: 3.3570 - val_accuracy100: 0.3269 - 39s/epoch - 23ms/step
Epoch 11/50
1691/1691 - 38s - loss: 3.1242 - accuracy100: 0.4496 - val_loss: 3.3549 - val_accuracy100: 0.3296 - 38s/epoch - 23ms/step
Epoch 12/50
1691/1691 - 37s - loss: 3.1208 - accuracy100: 0.4511 - val_loss: 3.3403 - val_accuracy100: 0.3328 - 37s/epoch - 22ms/step
Epoch 13/50
1691/1691 - 37s - loss: 3.1161 - accuracy100: 0.4520 - val_loss: 3.3495 - val_accuracy100: 0.3347 - 37s/epoch - 22ms/step
Epoch 14/50
1691/1691 - 37s - loss: 3.1125 - accuracy100: 0.4539 - val_loss: 3.3565 - val_accuracy100: 0.3336 - 37s/epoch - 22ms/step
Epoch 15/50
1691/1691 - 39s - loss: 3.1085 - accuracy100: 0.4562 - val_loss: 3.3634 - val_accuracy100: 0.3322 - 39s/epoch - 23ms/step
Epoch 16/50
1691/1691 - 38s - loss: 3.1045 - accuracy100: 0.4564 - val_loss: 3.3596 - val_accuracy100: 0.3381 - 38s/epoch - 22ms/step
Epoch 17/50
1691/1691 - 37s - loss: 3.1009 - accuracy100: 0.4582 - val_loss: 3.3582 - val_accuracy100: 0.3411 - 37s/epoch - 22ms/step
Epoch 18/50
1691/1691 - 37s - loss: 3.0969 - accuracy100: 0.4596 - val_loss: 3.3634 - val_accuracy100: 0.3449 - 37s/epoch - 22ms/step
Epoch 19/50
1691/1691 - 38s - loss: 3.0923 - accuracy100: 0.4613 - val_loss: 3.3721 - val_accuracy100: 0.3455 - 38s/epoch - 22ms/step
Epoch 20/50
1691/1691 - 38s - loss: 3.0885 - accuracy100: 0.4625 - val_loss: 3.3606 - val_accuracy100: 0.3489 - 38s/epoch - 22ms/step
Epoch 21/50
1691/1691 - 39s - loss: 3.0838 - accuracy100: 0.4638 - val_loss: 3.3698 - val_accuracy100: 0.3514 - 39s/epoch - 23ms/step
Epoch 22/50
1691/1691 - 39s - loss: 3.0813 - accuracy100: 0.4651 - val_loss: 3.3741 - val_accuracy100: 0.3541 - 39s/epoch - 23ms/step
testing model: results/ATVI/W8/deepOF_L2/h100
Evaluating performance on  test set...
4960/4960 - 38s - 38s/epoch - 8ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.095836
{'0': {'precision': 0.5028032653713495, 'recall': 0.08815254621144376, 'f1-score': 0.15000576089504444, 'support': 428303}, '1': {'precision': 0.3239659345993155, 'recall': 0.7591082808726102, 'f1-score': 0.4541244176287926, 'support': 412372}, '2': {'precision': 0.4673820212416512, 'recall': 0.24875291375291375, 'f1-score': 0.3246947856844027, 'support': 429000}, 'accuracy': 0.3603331561226298, 'macro avg': {'precision': 0.43138374040410543, 'recall': 0.36533791361232254, 'f1-score': 0.3096083214027466, 'support': 1269675}, 'weighted avg': {'precision': 0.4327513060142181, 'recall': 0.3603331561226298, 'f1-score': 0.3078033156624013, 'support': 1269675}}
[[ 37756 343521  47026]
 [ 24753 313035  74584]
 [ 12582 309703 106715]]
Evaluating performance on  train set...
1691/1691 - 13s - 13s/epoch - 8ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0855829
{'0': {'precision': 0.532465030249316, 'recall': 0.09386973180076628, 'f1-score': 0.15960266812971036, 'support': 147204}, '1': {'precision': 0.33713897362533013, 'recall': 0.7561720876168468, 'f1-score': 0.4663541613008465, 'support': 143671}, '2': {'precision': 0.4608441918983095, 'recall': 0.27478410323598607, 'f1-score': 0.3442843589347572, 'support': 141966}, 'accuracy': 0.37304229497667735, 'macro avg': {'precision': 0.4434827319243186, 'recall': 0.3749419742178664, 'f1-score': 0.32341372945510466, 'support': 432841}, 'weighted avg': {'precision': 0.44414064827403255, 'recall': 0.37304229497667735, 'f1-score': 0.3219944348343885, 'support': 432841}}
[[ 13818 115157  18229]
 [  7621 108640  27410]
 [  4512  98444  39010]]
Evaluating performance on  val set...
591/591 - 5s - 5s/epoch - 8ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.1143248
{'0': {'precision': 0.5178488641631896, 'recall': 0.08377709442736068, 'f1-score': 0.14422207876049065, 'support': 53332}, '1': {'precision': 0.28771277552663815, 'recall': 0.7750623096095265, 'f1-score': 0.41964726388984336, 'support': 43332}, '2': {'precision': 0.4753239698921394, 'recall': 0.22491692522352164, 'f1-score': 0.3053475069476465, 'support': 54469}, 'accuracy': 0.3328459039389147, 'macro avg': {'precision': 0.4269618698606557, 'recall': 0.3612521097534696, 'f1-score': 0.2897389498659935, 'support': 151133}, 'weighted avg': {'precision': 0.43653938536736814, 'recall': 0.3328459039389147, 'f1-score': 0.2812607471515853, 'support': 151133}}
[[ 4468 42702  6162]
 [ 2386 33585  7361]
 [ 1774 40444 12251]]
training model: results/ATVI/W8/deepOF_L2/h200
Epoch 1/50
1691/1691 - 41s - loss: 3.2786 - accuracy200: 0.3772 - val_loss: 3.2841 - val_accuracy200: 0.3657 - 41s/epoch - 25ms/step
Epoch 2/50
1691/1691 - 39s - loss: 3.2483 - accuracy200: 0.3918 - val_loss: 3.2756 - val_accuracy200: 0.3722 - 39s/epoch - 23ms/step
Epoch 3/50
1691/1691 - 38s - loss: 3.2357 - accuracy200: 0.3988 - val_loss: 3.2745 - val_accuracy200: 0.3691 - 38s/epoch - 23ms/step
Epoch 4/50
1691/1691 - 37s - loss: 3.2296 - accuracy200: 0.4024 - val_loss: 3.2713 - val_accuracy200: 0.3728 - 37s/epoch - 22ms/step
Epoch 5/50
1691/1691 - 37s - loss: 3.2253 - accuracy200: 0.4042 - val_loss: 3.2690 - val_accuracy200: 0.3765 - 37s/epoch - 22ms/step
Epoch 6/50
1691/1691 - 38s - loss: 3.2207 - accuracy200: 0.4073 - val_loss: 3.2659 - val_accuracy200: 0.3792 - 38s/epoch - 22ms/step
Epoch 7/50
1691/1691 - 38s - loss: 3.2179 - accuracy200: 0.4074 - val_loss: 3.2680 - val_accuracy200: 0.3774 - 38s/epoch - 22ms/step
Epoch 8/50
1691/1691 - 39s - loss: 3.2143 - accuracy200: 0.4095 - val_loss: 3.2681 - val_accuracy200: 0.3789 - 39s/epoch - 23ms/step
Epoch 9/50
1691/1691 - 37s - loss: 3.2119 - accuracy200: 0.4110 - val_loss: 3.2687 - val_accuracy200: 0.3822 - 37s/epoch - 22ms/step
Epoch 10/50
1691/1691 - 37s - loss: 3.2090 - accuracy200: 0.4121 - val_loss: 3.2655 - val_accuracy200: 0.3820 - 37s/epoch - 22ms/step
Epoch 11/50
1691/1691 - 37s - loss: 3.2065 - accuracy200: 0.4138 - val_loss: 3.2691 - val_accuracy200: 0.3827 - 37s/epoch - 22ms/step
Epoch 12/50
1691/1691 - 37s - loss: 3.2033 - accuracy200: 0.4155 - val_loss: 3.2682 - val_accuracy200: 0.3841 - 37s/epoch - 22ms/step
Epoch 13/50
1691/1691 - 37s - loss: 3.2007 - accuracy200: 0.4168 - val_loss: 3.2667 - val_accuracy200: 0.3869 - 37s/epoch - 22ms/step
Epoch 14/50
1691/1691 - 38s - loss: 3.1979 - accuracy200: 0.4182 - val_loss: 3.2693 - val_accuracy200: 0.3849 - 38s/epoch - 23ms/step
Epoch 15/50
1691/1691 - 38s - loss: 3.1955 - accuracy200: 0.4196 - val_loss: 3.2666 - val_accuracy200: 0.3870 - 38s/epoch - 22ms/step
Epoch 16/50
1691/1691 - 37s - loss: 3.1924 - accuracy200: 0.4210 - val_loss: 3.2717 - val_accuracy200: 0.3870 - 37s/epoch - 22ms/step
Epoch 17/50
1691/1691 - 38s - loss: 3.1889 - accuracy200: 0.4224 - val_loss: 3.2702 - val_accuracy200: 0.3887 - 38s/epoch - 22ms/step
Epoch 18/50
1691/1691 - 38s - loss: 3.1861 - accuracy200: 0.4242 - val_loss: 3.2688 - val_accuracy200: 0.3898 - 38s/epoch - 22ms/step
Epoch 19/50
1691/1691 - 38s - loss: 3.1832 - accuracy200: 0.4270 - val_loss: 3.2678 - val_accuracy200: 0.3910 - 38s/epoch - 22ms/step
Epoch 20/50
1691/1691 - 38s - loss: 3.1795 - accuracy200: 0.4273 - val_loss: 3.2804 - val_accuracy200: 0.3887 - 38s/epoch - 23ms/step
testing model: results/ATVI/W8/deepOF_L2/h200
Evaluating performance on  test set...
4960/4960 - 38s - 38s/epoch - 8ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0843705
{'0': {'precision': 0.392918581581657, 'recall': 0.30233895103493086, 'f1-score': 0.3417283128179856, 'support': 413989}, '1': {'precision': 0.3640346762639012, 'recall': 0.3914085030099353, 'f1-score': 0.37722563811383863, 'support': 436222}, '2': {'precision': 0.3896689269216489, 'recall': 0.4478548814677779, 'f1-score': 0.4167407047538553, 'support': 419464}, 'accuracy': 0.3810148266288617, 'macro avg': {'precision': 0.38220739492240235, 'recall': 0.38053411183754804, 'f1-score': 0.37856488522855986, 'support': 1269675}, 'weighted avg': {'precision': 0.3819213515126805, 'recall': 0.3810148266288617, 'f1-score': 0.37870605295321325, 'support': 1269675}}
[[125165 151533 137291]
 [108532 170741 156949]
 [ 84855 146750 187859]]
Evaluating performance on  train set...
1691/1691 - 13s - 13s/epoch - 8ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0818624
{'0': {'precision': 0.42961907102482183, 'recall': 0.2955741319373994, 'f1-score': 0.3502081471895121, 'support': 147858}, '1': {'precision': 0.3650698666327148, 'recall': 0.40226853443135824, 'f1-score': 0.3827675508269814, 'support': 142559}, '2': {'precision': 0.3935160977067304, 'recall': 0.4808459248441274, 'f1-score': 0.43281983220363085, 'support': 142424}, 'accuracy': 0.3916773133783537, 'macro avg': {'precision': 0.39606834512142236, 'recall': 0.3928961970709617, 'f1-score': 0.3885985100733748, 'support': 432841}, 'weighted avg': {'precision': 0.3964798815746768, 'recall': 0.3916773133783537, 'f1-score': 0.3881147287046755, 'support': 432841}}
[[43703 52411 51744]
 [31409 57347 53803]
 [26613 47327 68484]]
Evaluating performance on  val set...
591/591 - 5s - 5s/epoch - 8ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0900198
{'0': {'precision': 0.41417373220284753, 'recall': 0.29386504228069843, 'f1-score': 0.3437980678787611, 'support': 52861}, '1': {'precision': 0.33294701666956406, 'recall': 0.3827807510381737, 'f1-score': 0.3561290055990579, 'support': 45031}, '2': {'precision': 0.40481117434040353, 'recall': 0.4703142315133074, 'f1-score': 0.43511125398576855, 'support': 53241}, 'accuracy': 0.38251738534932805, 'macro avg': {'precision': 0.383977307737605, 'recall': 0.38232000827739315, 'f1-score': 0.3783461091545292, 'support': 151133}, 'weighted avg': {'precision': 0.38667350280004553, 'recall': 0.38251738534932805, 'f1-score': 0.3796398747508927, 'support': 151133}}
[[15534 17599 19728]
 [10706 17237 17088]
 [11266 16935 25040]]
training model: results/ATVI/W8/deepOF_L2/h300
Epoch 1/50
1691/1691 - 41s - loss: 3.2873 - accuracy300: 0.3716 - val_loss: 3.6800 - val_accuracy300: 0.2791 - 41s/epoch - 24ms/step
Epoch 2/50
1691/1691 - 38s - loss: 3.2645 - accuracy300: 0.3825 - val_loss: 3.6616 - val_accuracy300: 0.2776 - 38s/epoch - 22ms/step
Epoch 3/50
1691/1691 - 39s - loss: 3.2548 - accuracy300: 0.3882 - val_loss: 3.6553 - val_accuracy300: 0.2775 - 39s/epoch - 23ms/step
Epoch 4/50
1691/1691 - 39s - loss: 3.2493 - accuracy300: 0.3909 - val_loss: 3.6976 - val_accuracy300: 0.2773 - 39s/epoch - 23ms/step
Epoch 5/50
1691/1691 - 38s - loss: 3.2462 - accuracy300: 0.3935 - val_loss: 3.7196 - val_accuracy300: 0.2777 - 38s/epoch - 22ms/step
Epoch 6/50
1691/1691 - 38s - loss: 3.2438 - accuracy300: 0.3940 - val_loss: 3.7152 - val_accuracy300: 0.2773 - 38s/epoch - 22ms/step
Epoch 7/50
1691/1691 - 38s - loss: 3.2411 - accuracy300: 0.3961 - val_loss: 3.7612 - val_accuracy300: 0.2774 - 38s/epoch - 22ms/step
Epoch 8/50
1691/1691 - 38s - loss: 3.2393 - accuracy300: 0.3967 - val_loss: 3.7789 - val_accuracy300: 0.2778 - 38s/epoch - 22ms/step
Epoch 9/50
1691/1691 - 38s - loss: 3.2371 - accuracy300: 0.3975 - val_loss: 3.7488 - val_accuracy300: 0.2778 - 38s/epoch - 22ms/step
Epoch 10/50
1691/1691 - 37s - loss: 3.2360 - accuracy300: 0.3996 - val_loss: 3.6931 - val_accuracy300: 0.2784 - 37s/epoch - 22ms/step
Epoch 11/50
1691/1691 - 37s - loss: 3.2339 - accuracy300: 0.3995 - val_loss: 3.7794 - val_accuracy300: 0.2779 - 37s/epoch - 22ms/step
Epoch 12/50
1691/1691 - 37s - loss: 3.2320 - accuracy300: 0.4013 - val_loss: 3.7173 - val_accuracy300: 0.2782 - 37s/epoch - 22ms/step
Epoch 13/50
1691/1691 - 38s - loss: 3.2293 - accuracy300: 0.4029 - val_loss: 3.7347 - val_accuracy300: 0.2785 - 38s/epoch - 22ms/step
testing model: results/ATVI/W8/deepOF_L2/h300
Evaluating performance on  test set...
4960/4960 - 39s - 39s/epoch - 8ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.2101499
{'0': {'precision': 0.3819226750261233, 'recall': 0.0033608886355067998, 'f1-score': 0.006663142159186203, 'support': 435004}, '1': {'precision': 0.30985873111399703, 'recall': 0.9951071394058378, 'f1-score': 0.47256812228498146, 'support': 393226}, '2': {'precision': 0.374792151646159, 'recall': 0.002552979419859779, 'f1-score': 0.005071413785965639, 'support': 441445}, 'accuracy': 0.3102297832122394, 'macro avg': {'precision': 0.3555245192620931, 'recall': 0.3336736691537348, 'f1-score': 0.1614342260767111, 'support': 1269675}, 'weighted avg': {'precision': 0.3571248722007876, 'recall': 0.3102297832122394, 'f1-score': 0.1504033049435441, 'support': 1269675}}
[[  1462 432510   1032]
 [  1076 391302    848]
 [  1290 439028   1127]]
Evaluating performance on  train set...
1691/1691 - 13s - 13s/epoch - 8ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.2041788
{'0': {'precision': 0.4256, 'recall': 0.003515403015845745, 'f1-score': 0.006973208200073402, 'support': 151334}, '1': {'precision': 0.3158588189366107, 'recall': 0.995044068987731, 'f1-score': 0.479506830468564, 'support': 136604}, '2': {'precision': 0.396, 'recall': 0.003416078342063311, 'f1-score': 0.00677372342681984, 'support': 144903}, 'accuracy': 0.3164071795416793, 'macro avg': {'precision': 0.37915293964553687, 'recall': 0.3339918501152133, 'f1-score': 0.16441792069848576, 'support': 432841}, 'weighted avg': {'precision': 0.3810565923792265, 'recall': 0.3164071795416793, 'f1-score': 0.15603736107437627, 'support': 432841}}
[[   532 150412    390]
 [   312 135927    365]
 [   406 144002    495]]
Evaluating performance on  val set...
591/591 - 5s - 5s/epoch - 8ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.236145
{'0': {'precision': 0.40482573726541554, 'recall': 0.0027800279843876573, 'f1-score': 0.005522134250031999, 'support': 54316}, '1': {'precision': 0.2768145831947309, 'recall': 0.9950972185683878, 'f1-score': 0.43313918687507486, 'support': 41813}, '2': {'precision': 0.42444444444444446, 'recall': 0.00347247472911061, 'f1-score': 0.006888592346809969, 'support': 55004}, 'accuracy': 0.2775700872741228, 'macro avg': {'precision': 0.3686949216348636, 'recall': 0.3337832404272954, 'f1-score': 0.1485166378239723, 'support': 151133}, 'weighted avg': {'precision': 0.376549827864542, 'recall': 0.2775700872741228, 'f1-score': 0.12432552254091546, 'support': 151133}}
[[  151 54019   146]
 [   92 41608   113]
 [  130 54683   191]]
training model: results/ATVI/W8/deepOF_L2/h500
Epoch 1/50
1691/1691 - 40s - loss: 3.2668 - accuracy500: 0.3913 - val_loss: 3.3972 - val_accuracy500: 0.3055 - 40s/epoch - 23ms/step
Epoch 2/50
1691/1691 - 37s - loss: 3.2443 - accuracy500: 0.3956 - val_loss: 3.3483 - val_accuracy500: 0.3156 - 37s/epoch - 22ms/step
Epoch 3/50
1691/1691 - 37s - loss: 3.2361 - accuracy500: 0.3985 - val_loss: 3.3517 - val_accuracy500: 0.3169 - 37s/epoch - 22ms/step
Epoch 4/50
1691/1691 - 38s - loss: 3.2318 - accuracy500: 0.4005 - val_loss: 3.3445 - val_accuracy500: 0.3169 - 38s/epoch - 22ms/step
Epoch 5/50
1691/1691 - 38s - loss: 3.2306 - accuracy500: 0.4013 - val_loss: 3.3382 - val_accuracy500: 0.3154 - 38s/epoch - 23ms/step
Epoch 6/50
1691/1691 - 38s - loss: 3.2288 - accuracy500: 0.4012 - val_loss: 3.3397 - val_accuracy500: 0.3148 - 38s/epoch - 22ms/step
Epoch 7/50
1691/1691 - 37s - loss: 3.2266 - accuracy500: 0.4026 - val_loss: 3.3378 - val_accuracy500: 0.3168 - 37s/epoch - 22ms/step
Epoch 8/50
1691/1691 - 37s - loss: 3.2245 - accuracy500: 0.4040 - val_loss: 3.3399 - val_accuracy500: 0.3186 - 37s/epoch - 22ms/step
Epoch 9/50
1691/1691 - 38s - loss: 3.2232 - accuracy500: 0.4046 - val_loss: 3.3373 - val_accuracy500: 0.3197 - 38s/epoch - 22ms/step
Epoch 10/50
1691/1691 - 38s - loss: 3.2213 - accuracy500: 0.4053 - val_loss: 3.3381 - val_accuracy500: 0.3192 - 38s/epoch - 23ms/step
Epoch 11/50
1691/1691 - 38s - loss: 3.2194 - accuracy500: 0.4064 - val_loss: 3.3430 - val_accuracy500: 0.3193 - 38s/epoch - 23ms/step
Epoch 12/50
1691/1691 - 38s - loss: 3.2172 - accuracy500: 0.4074 - val_loss: 3.3428 - val_accuracy500: 0.3197 - 38s/epoch - 23ms/step
Epoch 13/50
1691/1691 - 38s - loss: 3.2162 - accuracy500: 0.4079 - val_loss: 3.3462 - val_accuracy500: 0.3189 - 38s/epoch - 22ms/step
Epoch 14/50
1691/1691 - 38s - loss: 3.2143 - accuracy500: 0.4091 - val_loss: 3.3489 - val_accuracy500: 0.3187 - 38s/epoch - 22ms/step
Epoch 15/50
1691/1691 - 38s - loss: 3.2133 - accuracy500: 0.4105 - val_loss: 3.3523 - val_accuracy500: 0.3175 - 38s/epoch - 22ms/step
Epoch 16/50
1691/1691 - 39s - loss: 3.2111 - accuracy500: 0.4117 - val_loss: 3.3578 - val_accuracy500: 0.3173 - 39s/epoch - 23ms/step
Epoch 17/50
1691/1691 - 38s - loss: 3.2088 - accuracy500: 0.4128 - val_loss: 3.3677 - val_accuracy500: 0.3153 - 38s/epoch - 23ms/step
Epoch 18/50
1691/1691 - 37s - loss: 3.2075 - accuracy500: 0.4138 - val_loss: 3.3644 - val_accuracy500: 0.3151 - 37s/epoch - 22ms/step
Epoch 19/50
1691/1691 - 38s - loss: 3.2059 - accuracy500: 0.4151 - val_loss: 3.3606 - val_accuracy500: 0.3160 - 38s/epoch - 22ms/step
testing model: results/ATVI/W8/deepOF_L2/h500
Evaluating performance on  test set...
4960/4960 - 38s - 38s/epoch - 8ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1390958
{'0': {'precision': 0.43865546218487395, 'recall': 0.010543615998911408, 'f1-score': 0.020592271773140356, 'support': 470332}, '1': {'precision': 0.25534675926328326, 'recall': 0.9263239212347665, 'f1-score': 0.40033795408321443, 'support': 317145}, '2': {'precision': 0.38809567958464675, 'recall': 0.08681081215600231, 'f1-score': 0.14188435713099393, 'support': 482198}, 'accuracy': 0.2682560497765176, 'macro avg': {'precision': 0.360699300344268, 'recall': 0.3412261164632267, 'f1-score': 0.1876048609957829, 'support': 1269675}, 'weighted avg': {'precision': 0.37366618174828015, 'recall': 0.2682560497765176, 'f1-score': 0.16151120409173741, 'support': 1269675}}
[[  4959 420289  45084]
 [  2450 293779  20916]
 [  3896 436442  41860]]
Evaluating performance on  train set...
1691/1691 - 14s - 14s/epoch - 8ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.104995
{'0': {'precision': 0.4137599230214097, 'recall': 0.01162924349066618, 'f1-score': 0.02262264895436012, 'support': 147903}, '1': {'precision': 0.34103552669029935, 'recall': 0.9309355973385696, 'f1-score': 0.4991970426930885, 'support': 141578}, '2': {'precision': 0.3992277443502156, 'recall': 0.11755719866071429, 'f1-score': 0.18163104745276817, 'support': 143360}, 'accuracy': 0.3474093258263427, 'macro avg': {'precision': 0.3846743980206416, 'recall': 0.3533740131633167, 'f1-score': 0.23448357970007228, 'support': 432841}, 'weighted avg': {'precision': 0.3851593336177526, 'recall': 0.3474093258263427, 'f1-score': 0.2311701144797458, 'support': 432841}}
[[  1720 129630  16553]
 [   970 131800   8808]
 [  1467 125040  16853]]
Evaluating performance on  val set...
591/591 - 5s - 5s/epoch - 9ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1155756
{'0': {'precision': 0.42329670329670327, 'recall': 0.017709042093455193, 'f1-score': 0.03399583436297525, 'support': 54379}, '1': {'precision': 0.3014862339301462, 'recall': 0.8803212851405623, 'f1-score': 0.44915055053003955, 'support': 42330}, '2': {'precision': 0.407688957516728, 'recall': 0.18919961781566955, 'f1-score': 0.2584555916717913, 'support': 54424}, 'accuracy': 0.32106819820952404, 'macro avg': {'precision': 0.3774906315811925, 'recall': 0.36240998168322897, 'f1-score': 0.24720065885493536, 'support': 151133}, 'weighted avg': {'precision': 0.3835590343255604, 'recall': 0.32106819820952404, 'f1-score': 0.2311036597030852, 'support': 151133}}
[[  963 43031 10385]
 [  491 37264  4575]
 [  821 43306 10297]]
training model: results/ATVI/W8/deepOF_L2/h1000
Epoch 1/50
1691/1691 - 40s - loss: 3.2805 - accuracy1000: 0.3817 - val_loss: 3.2869 - val_accuracy1000: 0.3455 - 40s/epoch - 24ms/step
Epoch 2/50
1691/1691 - 37s - loss: 3.2445 - accuracy1000: 0.3938 - val_loss: 3.2742 - val_accuracy1000: 0.3538 - 37s/epoch - 22ms/step
Epoch 3/50
1691/1691 - 37s - loss: 3.2317 - accuracy1000: 0.3979 - val_loss: 3.2632 - val_accuracy1000: 0.3621 - 37s/epoch - 22ms/step
Epoch 4/50
1691/1691 - 37s - loss: 3.2265 - accuracy1000: 0.4003 - val_loss: 3.2555 - val_accuracy1000: 0.3686 - 37s/epoch - 22ms/step
Epoch 5/50
1691/1691 - 37s - loss: 3.2229 - accuracy1000: 0.4016 - val_loss: 3.2509 - val_accuracy1000: 0.3737 - 37s/epoch - 22ms/step
Epoch 6/50
1691/1691 - 38s - loss: 3.2203 - accuracy1000: 0.4015 - val_loss: 3.2470 - val_accuracy1000: 0.3760 - 38s/epoch - 23ms/step
Epoch 7/50
1691/1691 - 38s - loss: 3.2180 - accuracy1000: 0.4037 - val_loss: 3.2436 - val_accuracy1000: 0.3797 - 38s/epoch - 22ms/step
Epoch 8/50
1691/1691 - 38s - loss: 3.2158 - accuracy1000: 0.4047 - val_loss: 3.2404 - val_accuracy1000: 0.3837 - 38s/epoch - 22ms/step
Epoch 9/50
1691/1691 - 38s - loss: 3.2137 - accuracy1000: 0.4065 - val_loss: 3.2372 - val_accuracy1000: 0.3860 - 38s/epoch - 22ms/step
Epoch 10/50
1691/1691 - 38s - loss: 3.2116 - accuracy1000: 0.4071 - val_loss: 3.2333 - val_accuracy1000: 0.3900 - 38s/epoch - 22ms/step
Epoch 11/50
1691/1691 - 38s - loss: 3.2089 - accuracy1000: 0.4089 - val_loss: 3.2335 - val_accuracy1000: 0.3906 - 38s/epoch - 22ms/step
Epoch 12/50
1691/1691 - 38s - loss: 3.2068 - accuracy1000: 0.4100 - val_loss: 3.2328 - val_accuracy1000: 0.3902 - 38s/epoch - 23ms/step
Epoch 13/50
1691/1691 - 38s - loss: 3.2046 - accuracy1000: 0.4113 - val_loss: 3.2301 - val_accuracy1000: 0.3920 - 38s/epoch - 22ms/step
Epoch 14/50
1691/1691 - 37s - loss: 3.2024 - accuracy1000: 0.4120 - val_loss: 3.2304 - val_accuracy1000: 0.3924 - 37s/epoch - 22ms/step
Epoch 15/50
1691/1691 - 37s - loss: 3.2005 - accuracy1000: 0.4129 - val_loss: 3.2299 - val_accuracy1000: 0.3930 - 37s/epoch - 22ms/step
Epoch 16/50
1691/1691 - 38s - loss: 3.1987 - accuracy1000: 0.4139 - val_loss: 3.2294 - val_accuracy1000: 0.3928 - 38s/epoch - 22ms/step
Epoch 17/50
1691/1691 - 37s - loss: 3.1963 - accuracy1000: 0.4154 - val_loss: 3.2284 - val_accuracy1000: 0.3930 - 37s/epoch - 22ms/step
Epoch 18/50
1691/1691 - 39s - loss: 3.1937 - accuracy1000: 0.4160 - val_loss: 3.2273 - val_accuracy1000: 0.3944 - 39s/epoch - 23ms/step
Epoch 19/50
1691/1691 - 38s - loss: 3.1916 - accuracy1000: 0.4170 - val_loss: 3.2261 - val_accuracy1000: 0.3959 - 38s/epoch - 22ms/step
Epoch 20/50
1691/1691 - 37s - loss: 3.1884 - accuracy1000: 0.4185 - val_loss: 3.2280 - val_accuracy1000: 0.3944 - 37s/epoch - 22ms/step
Epoch 21/50
1691/1691 - 38s - loss: 3.1860 - accuracy1000: 0.4196 - val_loss: 3.2293 - val_accuracy1000: 0.3943 - 38s/epoch - 23ms/step
Epoch 22/50
1691/1691 - 37s - loss: 3.1838 - accuracy1000: 0.4213 - val_loss: 3.2304 - val_accuracy1000: 0.3928 - 37s/epoch - 22ms/step
Epoch 23/50
1691/1691 - 37s - loss: 3.1798 - accuracy1000: 0.4227 - val_loss: 3.2299 - val_accuracy1000: 0.3923 - 37s/epoch - 22ms/step
Epoch 24/50
1691/1691 - 39s - loss: 3.1777 - accuracy1000: 0.4239 - val_loss: 3.2288 - val_accuracy1000: 0.3962 - 39s/epoch - 23ms/step
Epoch 25/50
1691/1691 - 38s - loss: 3.1735 - accuracy1000: 0.4257 - val_loss: 3.2344 - val_accuracy1000: 0.3919 - 38s/epoch - 22ms/step
Epoch 26/50
1691/1691 - 38s - loss: 3.1698 - accuracy1000: 0.4267 - val_loss: 3.2327 - val_accuracy1000: 0.3930 - 38s/epoch - 22ms/step
Epoch 27/50
1691/1691 - 38s - loss: 3.1669 - accuracy1000: 0.4281 - val_loss: 3.2385 - val_accuracy1000: 0.3896 - 38s/epoch - 22ms/step
Epoch 28/50
1691/1691 - 37s - loss: 3.1642 - accuracy1000: 0.4296 - val_loss: 3.2427 - val_accuracy1000: 0.3896 - 37s/epoch - 22ms/step
Epoch 29/50
1691/1691 - 38s - loss: 3.1599 - accuracy1000: 0.4305 - val_loss: 3.2472 - val_accuracy1000: 0.3890 - 38s/epoch - 22ms/step
testing model: results/ATVI/W8/deepOF_L2/h1000
Evaluating performance on  test set...
4960/4960 - 39s - 39s/epoch - 8ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0832802
{'0': {'precision': 0.3745728901266023, 'recall': 0.09295862324186152, 'f1-score': 0.14895158582584092, 'support': 408031}, '1': {'precision': 0.4107252785909017, 'recall': 0.6068875260179184, 'f1-score': 0.48989959062646043, 'support': 430953}, '2': {'precision': 0.3756755079123537, 'recall': 0.46372689468783884, 'f1-score': 0.4150830070412583, 'support': 430691}, 'accuracy': 0.39316596766889167, 'macro avg': {'precision': 0.3869912255432859, 'recall': 0.38785768131587295, 'f1-score': 0.3513113944978532, 'support': 1269675}, 'weighted avg': {'precision': 0.38721775422380694, 'recall': 0.39316596766889167, 'f1-score': 0.35495152553287673, 'support': 1269675}}
[[ 37930 179332 190769]
 [ 28268 261540 141145]
 [ 35064 195904 199723]]
Evaluating performance on  train set...
1691/1691 - 13s - 13s/epoch - 8ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0778358
{'0': {'precision': 0.4074187302557831, 'recall': 0.10713831105751516, 'f1-score': 0.1696610915726433, 'support': 149265}, '1': {'precision': 0.41598552047660003, 'recall': 0.5676993317202442, 'f1-score': 0.48014300810358956, 'support': 138864}, '2': {'precision': 0.377077616620933, 'recall': 0.5317734534800155, 'f1-score': 0.44126012064496895, 'support': 144712}, 'accuracy': 0.39686397545519025, 'macro avg': {'precision': 0.4001606224511054, 'recall': 0.4022036987525916, 'f1-score': 0.3636880734404006, 'support': 432841}, 'weighted avg': {'precision': 0.4000231635717054, 'recall': 0.39686397545519025, 'f1-score': 0.36007373629037503, 'support': 432841}}
[[15992 55928 77345]
 [10250 78833 49781]
 [13010 54748 76954]]
Evaluating performance on  val set...
591/591 - 5s - 5s/epoch - 8ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0771886
{'0': {'precision': 0.40106829454406717, 'recall': 0.09961526069404697, 'f1-score': 0.1595919110949171, 'support': 52763}, '1': {'precision': 0.40831850378589624, 'recall': 0.5177188868734239, 'f1-score': 0.45655651359681637, 'support': 45206}, '2': {'precision': 0.38695328955519764, 'recall': 0.5874463922955383, 'f1-score': 0.46657304629726465, 'support': 53164}, 'accuracy': 0.3962800976623239, 'macro avg': {'precision': 0.3987800292950537, 'recall': 0.4015935132876698, 'f1-score': 0.3609071569963327, 'support': 151133}, 'weighted avg': {'precision': 0.3982717036854053, 'recall': 0.3962800976623239, 'f1-score': 0.3564048301304584, 'support': 151133}}
[[ 5256 16422 31085]
 [ 3408 23404 18394]
 [ 4441 17492 31231]]
training model: results/ATVI/W8/deepVOL_L2/h10
Epoch 1/50
1691/1691 - 41s - loss: 2.9604 - accuracy10: 0.4971 - val_loss: 3.0401 - val_accuracy10: 0.5355 - 41s/epoch - 24ms/step
Epoch 2/50
1691/1691 - 36s - loss: 2.7566 - accuracy10: 0.5534 - val_loss: 3.0291 - val_accuracy10: 0.5500 - 36s/epoch - 21ms/step
Epoch 3/50
1691/1691 - 39s - loss: 2.6963 - accuracy10: 0.5700 - val_loss: 2.9673 - val_accuracy10: 0.5645 - 39s/epoch - 23ms/step
Epoch 4/50
1691/1691 - 38s - loss: 2.6653 - accuracy10: 0.5782 - val_loss: 2.9767 - val_accuracy10: 0.5663 - 38s/epoch - 23ms/step
Epoch 5/50
1691/1691 - 36s - loss: 2.6443 - accuracy10: 0.5834 - val_loss: 2.9508 - val_accuracy10: 0.5672 - 36s/epoch - 21ms/step
Epoch 6/50
1691/1691 - 39s - loss: 2.6297 - accuracy10: 0.5858 - val_loss: 2.9317 - val_accuracy10: 0.5656 - 39s/epoch - 23ms/step
Epoch 7/50
1691/1691 - 39s - loss: 2.6177 - accuracy10: 0.5885 - val_loss: 2.9320 - val_accuracy10: 0.5701 - 39s/epoch - 23ms/step
Epoch 8/50
1691/1691 - 36s - loss: 2.6097 - accuracy10: 0.5906 - val_loss: 2.9199 - val_accuracy10: 0.5695 - 36s/epoch - 21ms/step
Epoch 9/50
1691/1691 - 39s - loss: 2.6005 - accuracy10: 0.5924 - val_loss: 2.9241 - val_accuracy10: 0.5683 - 39s/epoch - 23ms/step
Epoch 10/50
1691/1691 - 39s - loss: 2.5924 - accuracy10: 0.5938 - val_loss: 2.9104 - val_accuracy10: 0.5671 - 39s/epoch - 23ms/step
Epoch 11/50
1691/1691 - 40s - loss: 2.5870 - accuracy10: 0.5946 - val_loss: 2.9184 - val_accuracy10: 0.5722 - 40s/epoch - 23ms/step
Epoch 12/50
1691/1691 - 41s - loss: 2.5794 - accuracy10: 0.5959 - val_loss: 2.9024 - val_accuracy10: 0.5721 - 41s/epoch - 24ms/step
Epoch 13/50
1691/1691 - 36s - loss: 2.5736 - accuracy10: 0.5967 - val_loss: 2.9019 - val_accuracy10: 0.5712 - 36s/epoch - 21ms/step
Epoch 14/50
1691/1691 - 35s - loss: 2.5675 - accuracy10: 0.5973 - val_loss: 2.9134 - val_accuracy10: 0.5706 - 35s/epoch - 21ms/step
Epoch 15/50
1691/1691 - 40s - loss: 2.5624 - accuracy10: 0.5973 - val_loss: 2.9133 - val_accuracy10: 0.5686 - 40s/epoch - 23ms/step
Epoch 16/50
1691/1691 - 36s - loss: 2.5575 - accuracy10: 0.5989 - val_loss: 2.9337 - val_accuracy10: 0.5716 - 36s/epoch - 21ms/step
Epoch 17/50
1691/1691 - 41s - loss: 2.5518 - accuracy10: 0.5993 - val_loss: 2.9413 - val_accuracy10: 0.5714 - 41s/epoch - 24ms/step
Epoch 18/50
1691/1691 - 43s - loss: 2.5459 - accuracy10: 0.6001 - val_loss: 2.9308 - val_accuracy10: 0.5686 - 43s/epoch - 26ms/step
Epoch 19/50
1691/1691 - 38s - loss: 2.5417 - accuracy10: 0.6007 - val_loss: 2.9010 - val_accuracy10: 0.5739 - 38s/epoch - 22ms/step
Epoch 20/50
1691/1691 - 36s - loss: 2.5378 - accuracy10: 0.6011 - val_loss: 2.9070 - val_accuracy10: 0.5692 - 36s/epoch - 21ms/step
Epoch 21/50
1691/1691 - 38s - loss: 2.5330 - accuracy10: 0.6021 - val_loss: 2.9020 - val_accuracy10: 0.5753 - 38s/epoch - 23ms/step
Epoch 22/50
1691/1691 - 37s - loss: 2.5294 - accuracy10: 0.6026 - val_loss: 2.9117 - val_accuracy10: 0.5738 - 37s/epoch - 22ms/step
Epoch 23/50
1691/1691 - 36s - loss: 2.5246 - accuracy10: 0.6032 - val_loss: 2.8848 - val_accuracy10: 0.5748 - 36s/epoch - 21ms/step
Epoch 24/50
1691/1691 - 36s - loss: 2.5215 - accuracy10: 0.6041 - val_loss: 2.8888 - val_accuracy10: 0.5758 - 36s/epoch - 21ms/step
Epoch 25/50
1691/1691 - 37s - loss: 2.5176 - accuracy10: 0.6045 - val_loss: 2.8965 - val_accuracy10: 0.5725 - 37s/epoch - 22ms/step
Epoch 26/50
1691/1691 - 36s - loss: 2.5141 - accuracy10: 0.6050 - val_loss: 2.8850 - val_accuracy10: 0.5804 - 36s/epoch - 22ms/step
Epoch 27/50
1691/1691 - 39s - loss: 2.5097 - accuracy10: 0.6053 - val_loss: 2.8805 - val_accuracy10: 0.5743 - 39s/epoch - 23ms/step
Epoch 28/50
1691/1691 - 39s - loss: 2.5067 - accuracy10: 0.6057 - val_loss: 2.8897 - val_accuracy10: 0.5721 - 39s/epoch - 23ms/step
Epoch 29/50
1691/1691 - 37s - loss: 2.5039 - accuracy10: 0.6058 - val_loss: 2.8827 - val_accuracy10: 0.5755 - 37s/epoch - 22ms/step
Epoch 30/50
1691/1691 - 38s - loss: 2.4990 - accuracy10: 0.6071 - val_loss: 2.8865 - val_accuracy10: 0.5736 - 38s/epoch - 22ms/step
Epoch 31/50
1691/1691 - 39s - loss: 2.4975 - accuracy10: 0.6068 - val_loss: 2.8834 - val_accuracy10: 0.5740 - 39s/epoch - 23ms/step
Epoch 32/50
1691/1691 - 37s - loss: 2.4931 - accuracy10: 0.6078 - val_loss: 2.8731 - val_accuracy10: 0.5742 - 37s/epoch - 22ms/step
Epoch 33/50
1691/1691 - 38s - loss: 2.4888 - accuracy10: 0.6080 - val_loss: 2.9012 - val_accuracy10: 0.5731 - 38s/epoch - 22ms/step
Epoch 34/50
1691/1691 - 37s - loss: 2.4869 - accuracy10: 0.6080 - val_loss: 2.8835 - val_accuracy10: 0.5700 - 37s/epoch - 22ms/step
Epoch 35/50
1691/1691 - 38s - loss: 2.4837 - accuracy10: 0.6088 - val_loss: 2.9106 - val_accuracy10: 0.5699 - 38s/epoch - 22ms/step
Epoch 36/50
1691/1691 - 36s - loss: 2.4798 - accuracy10: 0.6100 - val_loss: 2.9017 - val_accuracy10: 0.5721 - 36s/epoch - 21ms/step
Epoch 37/50
1691/1691 - 38s - loss: 2.4778 - accuracy10: 0.6102 - val_loss: 2.8792 - val_accuracy10: 0.5759 - 38s/epoch - 23ms/step
Epoch 38/50
1691/1691 - 37s - loss: 2.4747 - accuracy10: 0.6105 - val_loss: 2.8853 - val_accuracy10: 0.5731 - 37s/epoch - 22ms/step
Epoch 39/50
1691/1691 - 40s - loss: 2.4716 - accuracy10: 0.6109 - val_loss: 2.8717 - val_accuracy10: 0.5757 - 40s/epoch - 24ms/step
Epoch 40/50
1691/1691 - 37s - loss: 2.4678 - accuracy10: 0.6124 - val_loss: 2.8808 - val_accuracy10: 0.5757 - 37s/epoch - 22ms/step
Epoch 41/50
1691/1691 - 36s - loss: 2.4661 - accuracy10: 0.6120 - val_loss: 2.8827 - val_accuracy10: 0.5750 - 36s/epoch - 21ms/step
Epoch 42/50
1691/1691 - 38s - loss: 2.4635 - accuracy10: 0.6123 - val_loss: 2.8711 - val_accuracy10: 0.5726 - 38s/epoch - 23ms/step
Epoch 43/50
1691/1691 - 39s - loss: 2.4601 - accuracy10: 0.6130 - val_loss: 2.8749 - val_accuracy10: 0.5755 - 39s/epoch - 23ms/step
Epoch 44/50
1691/1691 - 38s - loss: 2.4577 - accuracy10: 0.6127 - val_loss: 2.8869 - val_accuracy10: 0.5707 - 38s/epoch - 23ms/step
Epoch 45/50
1691/1691 - 38s - loss: 2.4538 - accuracy10: 0.6145 - val_loss: 2.8840 - val_accuracy10: 0.5727 - 38s/epoch - 22ms/step
Epoch 46/50
1691/1691 - 43s - loss: 2.4493 - accuracy10: 0.6148 - val_loss: 2.8960 - val_accuracy10: 0.5732 - 43s/epoch - 25ms/step
Epoch 47/50
1691/1691 - 40s - loss: 2.4483 - accuracy10: 0.6143 - val_loss: 2.8922 - val_accuracy10: 0.5733 - 40s/epoch - 24ms/step
Epoch 48/50
1691/1691 - 37s - loss: 2.4439 - accuracy10: 0.6153 - val_loss: 2.8777 - val_accuracy10: 0.5770 - 37s/epoch - 22ms/step
Epoch 49/50
1691/1691 - 38s - loss: 2.4423 - accuracy10: 0.6155 - val_loss: 2.8755 - val_accuracy10: 0.5692 - 38s/epoch - 23ms/step
Epoch 50/50
1691/1691 - 40s - loss: 2.4389 - accuracy10: 0.6162 - val_loss: 2.8925 - val_accuracy10: 0.5757 - 40s/epoch - 24ms/step
testing model: results/ATVI/W8/deepVOL_L2/h10
Evaluating performance on  test set...
4960/4960 - 50s - 50s/epoch - 10ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.81934476
{'0': {'precision': 0.41407955389694767, 'recall': 0.5786623374020403, 'f1-score': 0.48272817865049056, 'support': 249465}, '1': {'precision': 0.800035451700911, 'recall': 0.6701350110841556, 'f1-score': 0.7293463987538809, 'support': 774529}, '2': {'precision': 0.4587224697107139, 'recall': 0.5083968968520794, 'f1-score': 0.4822839624153196, 'support': 245686}, 'accuracy': 0.6208658874677084, 'macro avg': {'precision': 0.5576124917695242, 'recall': 0.5857314151127585, 'f1-score': 0.564786179939897, 'support': 1269680}, 'weighted avg': {'precision': 0.6581585147255241, 'recall': 0.6208658874677084, 'f1-score': 0.6330840365741441, 'support': 1269680}}
[[144356  60610  44499]
 [152604 519039 102886]
 [ 51659  69121 124906]]
Evaluating performance on  train set...
1691/1691 - 13s - 13s/epoch - 7ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.8467218
{'0': {'precision': 0.4457907640487954, 'recall': 0.6088691209249779, 'f1-score': 0.5147218254719417, 'support': 98251}, '1': {'precision': 0.7663135160958034, 'recall': 0.6469098149921864, 'f1-score': 0.7015674366795218, 'support': 238044}, '2': {'precision': 0.4990071444655981, 'recall': 0.5049456752529804, 'f1-score': 0.5019588462112671, 'support': 96549}, 'accuracy': 0.606608847529364, 'macro avg': {'precision': 0.5703704748700656, 'recall': 0.5869082037233816, 'f1-score': 0.5727493694542435, 'support': 432844}, 'weighted avg': {'precision': 0.6339336199071182, 'recall': 0.606608847529364, 'f1-score': 0.6146313166273195, 'support': 432844}}
[[ 59822  20879  17550]
 [ 52655 153993  31396]
 [ 21716  26081  48752]]
Evaluating performance on  val set...
591/591 - 5s - 5s/epoch - 9ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.90930897
{'0': {'precision': 0.4382245916899382, 'recall': 0.5692066719793355, 'f1-score': 0.49520075544771036, 'support': 36391}, '1': {'precision': 0.7396374280049098, 'recall': 0.605487922705314, 'f1-score': 0.6658733025904754, 'support': 77625}, '2': {'precision': 0.46185515873015875, 'recall': 0.5016972897246619, 'f1-score': 0.4809525039386348, 'support': 37118}, 'accuracy': 0.571261264837826, 'macro avg': {'precision': 0.5465723928083356, 'recall': 0.5587972948031038, 'f1-score': 0.5473421873256069, 'support': 151134}, 'weighted avg': {'precision': 0.5988389524978872, 'recall': 0.571261264837826, 'f1-score': 0.5793617640390483, 'support': 151134}}
[[20714  7162  8515]
 [17441 47001 13183]
 [ 9113  9383 18622]]
training model: results/ATVI/W8/deepVOL_L2/h20
Epoch 1/50
1691/1691 - 42s - loss: 3.0346 - accuracy20: 0.4773 - val_loss: 3.1268 - val_accuracy20: 0.4852 - 42s/epoch - 25ms/step
Epoch 2/50
1691/1691 - 38s - loss: 2.8389 - accuracy20: 0.5335 - val_loss: 3.0208 - val_accuracy20: 0.5218 - 38s/epoch - 23ms/step
Epoch 3/50
1691/1691 - 37s - loss: 2.7821 - accuracy20: 0.5517 - val_loss: 3.0131 - val_accuracy20: 0.5311 - 37s/epoch - 22ms/step
Epoch 4/50
1691/1691 - 38s - loss: 2.7554 - accuracy20: 0.5589 - val_loss: 3.0030 - val_accuracy20: 0.5302 - 38s/epoch - 23ms/step
Epoch 5/50
1691/1691 - 37s - loss: 2.7382 - accuracy20: 0.5632 - val_loss: 2.9766 - val_accuracy20: 0.5349 - 37s/epoch - 22ms/step
Epoch 6/50
1691/1691 - 37s - loss: 2.7246 - accuracy20: 0.5673 - val_loss: 3.0016 - val_accuracy20: 0.5339 - 37s/epoch - 22ms/step
Epoch 7/50
1691/1691 - 37s - loss: 2.7132 - accuracy20: 0.5705 - val_loss: 2.9743 - val_accuracy20: 0.5308 - 37s/epoch - 22ms/step
Epoch 8/50
1691/1691 - 36s - loss: 2.7018 - accuracy20: 0.5733 - val_loss: 2.9625 - val_accuracy20: 0.5367 - 36s/epoch - 22ms/step
Epoch 9/50
1691/1691 - 40s - loss: 2.6941 - accuracy20: 0.5749 - val_loss: 2.9696 - val_accuracy20: 0.5365 - 40s/epoch - 23ms/step
Epoch 10/50
1691/1691 - 38s - loss: 2.6838 - accuracy20: 0.5760 - val_loss: 2.9748 - val_accuracy20: 0.5384 - 38s/epoch - 22ms/step
Epoch 11/50
1691/1691 - 39s - loss: 2.6764 - accuracy20: 0.5776 - val_loss: 2.9635 - val_accuracy20: 0.5409 - 39s/epoch - 23ms/step
Epoch 12/50
1691/1691 - 36s - loss: 2.6679 - accuracy20: 0.5786 - val_loss: 2.9460 - val_accuracy20: 0.5441 - 36s/epoch - 21ms/step
Epoch 13/50
1691/1691 - 38s - loss: 2.6618 - accuracy20: 0.5804 - val_loss: 2.9421 - val_accuracy20: 0.5456 - 38s/epoch - 22ms/step
Epoch 14/50
1691/1691 - 36s - loss: 2.6535 - accuracy20: 0.5816 - val_loss: 2.9408 - val_accuracy20: 0.5486 - 36s/epoch - 22ms/step
Epoch 15/50
1691/1691 - 38s - loss: 2.6496 - accuracy20: 0.5824 - val_loss: 2.9304 - val_accuracy20: 0.5458 - 38s/epoch - 23ms/step
Epoch 16/50
1691/1691 - 41s - loss: 2.6429 - accuracy20: 0.5835 - val_loss: 2.9273 - val_accuracy20: 0.5520 - 41s/epoch - 24ms/step
Epoch 17/50
1691/1691 - 36s - loss: 2.6362 - accuracy20: 0.5845 - val_loss: 2.9279 - val_accuracy20: 0.5501 - 36s/epoch - 21ms/step
Epoch 18/50
1691/1691 - 37s - loss: 2.6326 - accuracy20: 0.5861 - val_loss: 2.9311 - val_accuracy20: 0.5509 - 37s/epoch - 22ms/step
Epoch 19/50
1691/1691 - 38s - loss: 2.6270 - accuracy20: 0.5864 - val_loss: 2.9379 - val_accuracy20: 0.5492 - 38s/epoch - 22ms/step
Epoch 20/50
1691/1691 - 38s - loss: 2.6236 - accuracy20: 0.5873 - val_loss: 2.9373 - val_accuracy20: 0.5515 - 38s/epoch - 23ms/step
Epoch 21/50
1691/1691 - 42s - loss: 2.6197 - accuracy20: 0.5871 - val_loss: 2.9162 - val_accuracy20: 0.5532 - 42s/epoch - 25ms/step
Epoch 22/50
1691/1691 - 38s - loss: 2.6159 - accuracy20: 0.5888 - val_loss: 2.9287 - val_accuracy20: 0.5519 - 38s/epoch - 22ms/step
Epoch 23/50
1691/1691 - 40s - loss: 2.6125 - accuracy20: 0.5888 - val_loss: 2.9075 - val_accuracy20: 0.5540 - 40s/epoch - 24ms/step
Epoch 24/50
1691/1691 - 37s - loss: 2.6094 - accuracy20: 0.5898 - val_loss: 2.9153 - val_accuracy20: 0.5539 - 37s/epoch - 22ms/step
Epoch 25/50
1691/1691 - 37s - loss: 2.6050 - accuracy20: 0.5905 - val_loss: 2.9102 - val_accuracy20: 0.5550 - 37s/epoch - 22ms/step
Epoch 26/50
1691/1691 - 38s - loss: 2.6026 - accuracy20: 0.5914 - val_loss: 2.9251 - val_accuracy20: 0.5536 - 38s/epoch - 23ms/step
Epoch 27/50
1691/1691 - 36s - loss: 2.5994 - accuracy20: 0.5920 - val_loss: 2.9087 - val_accuracy20: 0.5533 - 36s/epoch - 21ms/step
Epoch 28/50
1691/1691 - 38s - loss: 2.5961 - accuracy20: 0.5916 - val_loss: 2.9132 - val_accuracy20: 0.5525 - 38s/epoch - 22ms/step
Epoch 29/50
1691/1691 - 40s - loss: 2.5941 - accuracy20: 0.5919 - val_loss: 2.9098 - val_accuracy20: 0.5541 - 40s/epoch - 24ms/step
Epoch 30/50
1691/1691 - 36s - loss: 2.5899 - accuracy20: 0.5929 - val_loss: 2.9096 - val_accuracy20: 0.5536 - 36s/epoch - 21ms/step
Epoch 31/50
1691/1691 - 37s - loss: 2.5875 - accuracy20: 0.5934 - val_loss: 2.9034 - val_accuracy20: 0.5550 - 37s/epoch - 22ms/step
Epoch 32/50
1691/1691 - 39s - loss: 2.5841 - accuracy20: 0.5944 - val_loss: 2.8980 - val_accuracy20: 0.5524 - 39s/epoch - 23ms/step
Epoch 33/50
1691/1691 - 41s - loss: 2.5816 - accuracy20: 0.5950 - val_loss: 2.9065 - val_accuracy20: 0.5537 - 41s/epoch - 24ms/step
Epoch 34/50
1691/1691 - 38s - loss: 2.5780 - accuracy20: 0.5949 - val_loss: 2.9113 - val_accuracy20: 0.5525 - 38s/epoch - 22ms/step
Epoch 35/50
1691/1691 - 35s - loss: 2.5765 - accuracy20: 0.5953 - val_loss: 2.9083 - val_accuracy20: 0.5538 - 35s/epoch - 21ms/step
Epoch 36/50
1691/1691 - 39s - loss: 2.5748 - accuracy20: 0.5960 - val_loss: 2.9094 - val_accuracy20: 0.5528 - 39s/epoch - 23ms/step
Epoch 37/50
1691/1691 - 41s - loss: 2.5714 - accuracy20: 0.5961 - val_loss: 2.9010 - val_accuracy20: 0.5524 - 41s/epoch - 24ms/step
Epoch 38/50
1691/1691 - 40s - loss: 2.5700 - accuracy20: 0.5961 - val_loss: 2.9026 - val_accuracy20: 0.5536 - 40s/epoch - 24ms/step
Epoch 39/50
1691/1691 - 38s - loss: 2.5702 - accuracy20: 0.5967 - val_loss: 2.9013 - val_accuracy20: 0.5534 - 38s/epoch - 22ms/step
Epoch 40/50
1691/1691 - 37s - loss: 2.5641 - accuracy20: 0.5976 - val_loss: 2.9032 - val_accuracy20: 0.5520 - 37s/epoch - 22ms/step
Epoch 41/50
1691/1691 - 39s - loss: 2.5599 - accuracy20: 0.5983 - val_loss: 2.8980 - val_accuracy20: 0.5528 - 39s/epoch - 23ms/step
Epoch 42/50
1691/1691 - 39s - loss: 2.5591 - accuracy20: 0.5982 - val_loss: 2.9042 - val_accuracy20: 0.5516 - 39s/epoch - 23ms/step
Epoch 43/50
1691/1691 - 38s - loss: 2.5553 - accuracy20: 0.5986 - val_loss: 2.9023 - val_accuracy20: 0.5531 - 38s/epoch - 22ms/step
Epoch 44/50
1691/1691 - 37s - loss: 2.5538 - accuracy20: 0.5991 - val_loss: 2.8894 - val_accuracy20: 0.5530 - 37s/epoch - 22ms/step
Epoch 45/50
1691/1691 - 38s - loss: 2.5509 - accuracy20: 0.5998 - val_loss: 2.8999 - val_accuracy20: 0.5539 - 38s/epoch - 22ms/step
Epoch 46/50
1691/1691 - 36s - loss: 2.5494 - accuracy20: 0.6005 - val_loss: 2.9002 - val_accuracy20: 0.5515 - 36s/epoch - 22ms/step
Epoch 47/50
1691/1691 - 40s - loss: 2.5467 - accuracy20: 0.6012 - val_loss: 2.8955 - val_accuracy20: 0.5525 - 40s/epoch - 24ms/step
Epoch 48/50
1691/1691 - 38s - loss: 2.5440 - accuracy20: 0.6011 - val_loss: 2.9071 - val_accuracy20: 0.5523 - 38s/epoch - 22ms/step
Epoch 49/50
1691/1691 - 36s - loss: 2.5411 - accuracy20: 0.6023 - val_loss: 2.9042 - val_accuracy20: 0.5505 - 36s/epoch - 21ms/step
Epoch 50/50
1691/1691 - 36s - loss: 2.5387 - accuracy20: 0.6021 - val_loss: 2.8894 - val_accuracy20: 0.5522 - 36s/epoch - 21ms/step
testing model: results/ATVI/W8/deepVOL_L2/h20
Evaluating performance on  test set...
4960/4960 - 52s - 52s/epoch - 11ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.8712961
{'0': {'precision': 0.4867196278003117, 'recall': 0.4697838020061444, 'f1-score': 0.47810178224935956, 'support': 314434}, '1': {'precision': 0.70392403615147, 'recall': 0.6971913295201434, 'f1-score': 0.7005415066736955, 'support': 644255}, '2': {'precision': 0.498216974403677, 'recall': 0.5256164969404259, 'f1-score': 0.511550106793306, 'support': 310991}, 'accuracy': 0.5988493163631782, 'macro avg': {'precision': 0.5629535461184862, 'recall': 0.5641972094889045, 'f1-score': 0.5633977985721205, 'support': 1269680}, 'weighted avg': {'precision': 0.5997485779450747, 'recall': 0.5988493163631782, 'f1-score': 0.5991638077654322, 'support': 1269680}}
[[147716  96589  70129]
 [100583 449169  94503]
 [ 55194  92335 163462]]
Evaluating performance on  train set...
1691/1691 - 12s - 12s/epoch - 7ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.8834935
{'0': {'precision': 0.5210011557104169, 'recall': 0.497959789301877, 'f1-score': 0.5092199597904382, 'support': 121311}, '1': {'precision': 0.661314335946829, 'recall': 0.6764942848380574, 'f1-score': 0.6688181878915263, 'support': 192383}, '2': {'precision': 0.5226271659214481, 'recall': 0.526789760805707, 'f1-score': 0.5247002077333656, 'support': 119150}, 'accuracy': 0.5852478029035865, 'macro avg': {'precision': 0.568314219192898, 'recall': 0.5670812783152138, 'f1-score': 0.5675794518051099, 'support': 432844}, 'weighted avg': {'precision': 0.5838127221640723, 'recall': 0.5852478029035865, 'f1-score': 0.5844166991680695, 'support': 432844}}
[[ 60408  33124  27779]
 [ 32684 130146  29553]
 [ 22854  33529  62767]]
Evaluating performance on  val set...
591/591 - 5s - 5s/epoch - 9ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.9409665
{'0': {'precision': 0.5008331053691776, 'recall': 0.45802724646910326, 'f1-score': 0.47847469707769075, 'support': 43969}, '1': {'precision': 0.6325379118569535, 'recall': 0.6322210551830008, 'f1-score': 0.6323794438293505, 'support': 61885}, '2': {'precision': 0.4933053455338401, 'recall': 0.5345848056537102, 'f1-score': 0.5131161962500927, 'support': 45280}, 'accuracy': 0.5522913441052312, 'macro avg': {'precision': 0.5422254542533237, 'recall': 0.5416110357686047, 'f1-score': 0.5413234457190447, 'support': 151134}, 'weighted avg': {'precision': 0.5525070833235223, 'recall': 0.5522913441052312, 'f1-score': 0.5518728889819137, 'support': 151134}}
[[20139 10929 12901]
 [10798 39125 11962]
 [ 9274 11800 24206]]
training model: results/ATVI/W8/deepVOL_L2/h30
Epoch 1/50
1691/1691 - 40s - loss: 3.0642 - accuracy30: 0.4682 - val_loss: 3.1268 - val_accuracy30: 0.4652 - 40s/epoch - 24ms/step
Epoch 2/50
1691/1691 - 37s - loss: 2.8854 - accuracy30: 0.5202 - val_loss: 3.0347 - val_accuracy30: 0.4927 - 37s/epoch - 22ms/step
Epoch 3/50
1691/1691 - 38s - loss: 2.8354 - accuracy30: 0.5339 - val_loss: 3.0391 - val_accuracy30: 0.4970 - 38s/epoch - 22ms/step
Epoch 4/50
1691/1691 - 37s - loss: 2.8127 - accuracy30: 0.5397 - val_loss: 3.0470 - val_accuracy30: 0.5005 - 37s/epoch - 22ms/step
Epoch 5/50
1691/1691 - 41s - loss: 2.7972 - accuracy30: 0.5438 - val_loss: 3.0191 - val_accuracy30: 0.5030 - 41s/epoch - 24ms/step
Epoch 6/50
1691/1691 - 40s - loss: 2.7843 - accuracy30: 0.5471 - val_loss: 3.0222 - val_accuracy30: 0.5052 - 40s/epoch - 23ms/step
Epoch 7/50
1691/1691 - 41s - loss: 2.7738 - accuracy30: 0.5496 - val_loss: 3.0033 - val_accuracy30: 0.5074 - 41s/epoch - 24ms/step
Epoch 8/50
1691/1691 - 39s - loss: 2.7644 - accuracy30: 0.5514 - val_loss: 3.0057 - val_accuracy30: 0.5089 - 39s/epoch - 23ms/step
Epoch 9/50
1691/1691 - 37s - loss: 2.7575 - accuracy30: 0.5537 - val_loss: 3.0081 - val_accuracy30: 0.5086 - 37s/epoch - 22ms/step
Epoch 10/50
1691/1691 - 38s - loss: 2.7488 - accuracy30: 0.5556 - val_loss: 3.0066 - val_accuracy30: 0.5076 - 38s/epoch - 23ms/step
Epoch 11/50
1691/1691 - 40s - loss: 2.7420 - accuracy30: 0.5564 - val_loss: 3.0006 - val_accuracy30: 0.5113 - 40s/epoch - 24ms/step
Epoch 12/50
1691/1691 - 41s - loss: 2.7336 - accuracy30: 0.5576 - val_loss: 2.9870 - val_accuracy30: 0.5116 - 41s/epoch - 24ms/step
Epoch 13/50
1691/1691 - 35s - loss: 2.7279 - accuracy30: 0.5582 - val_loss: 2.9902 - val_accuracy30: 0.5131 - 35s/epoch - 21ms/step
Epoch 14/50
1691/1691 - 37s - loss: 2.7212 - accuracy30: 0.5608 - val_loss: 2.9914 - val_accuracy30: 0.5111 - 37s/epoch - 22ms/step
Epoch 15/50
1691/1691 - 42s - loss: 2.7155 - accuracy30: 0.5617 - val_loss: 2.9878 - val_accuracy30: 0.5150 - 42s/epoch - 25ms/step
Epoch 16/50
1691/1691 - 36s - loss: 2.7107 - accuracy30: 0.5626 - val_loss: 2.9846 - val_accuracy30: 0.5135 - 36s/epoch - 21ms/step
Epoch 17/50
1691/1691 - 36s - loss: 2.7059 - accuracy30: 0.5645 - val_loss: 2.9727 - val_accuracy30: 0.5149 - 36s/epoch - 21ms/step
Epoch 18/50
1691/1691 - 37s - loss: 2.7022 - accuracy30: 0.5653 - val_loss: 2.9808 - val_accuracy30: 0.5145 - 37s/epoch - 22ms/step
Epoch 19/50
1691/1691 - 41s - loss: 2.6979 - accuracy30: 0.5660 - val_loss: 2.9840 - val_accuracy30: 0.5137 - 41s/epoch - 24ms/step
Epoch 20/50
1691/1691 - 37s - loss: 2.6943 - accuracy30: 0.5666 - val_loss: 2.9858 - val_accuracy30: 0.5146 - 37s/epoch - 22ms/step
Epoch 21/50
1691/1691 - 42s - loss: 2.6911 - accuracy30: 0.5674 - val_loss: 2.9711 - val_accuracy30: 0.5166 - 42s/epoch - 25ms/step
Epoch 22/50
1691/1691 - 36s - loss: 2.6873 - accuracy30: 0.5680 - val_loss: 2.9736 - val_accuracy30: 0.5171 - 36s/epoch - 21ms/step
Epoch 23/50
1691/1691 - 36s - loss: 2.6845 - accuracy30: 0.5691 - val_loss: 2.9750 - val_accuracy30: 0.5165 - 36s/epoch - 21ms/step
Epoch 24/50
1691/1691 - 38s - loss: 2.6807 - accuracy30: 0.5692 - val_loss: 2.9585 - val_accuracy30: 0.5178 - 38s/epoch - 23ms/step
Epoch 25/50
1691/1691 - 35s - loss: 2.6771 - accuracy30: 0.5704 - val_loss: 2.9638 - val_accuracy30: 0.5176 - 35s/epoch - 21ms/step
Epoch 26/50
1691/1691 - 39s - loss: 2.6750 - accuracy30: 0.5712 - val_loss: 2.9640 - val_accuracy30: 0.5203 - 39s/epoch - 23ms/step
Epoch 27/50
1691/1691 - 40s - loss: 2.6716 - accuracy30: 0.5718 - val_loss: 2.9731 - val_accuracy30: 0.5178 - 40s/epoch - 24ms/step
Epoch 28/50
1691/1691 - 37s - loss: 2.6681 - accuracy30: 0.5727 - val_loss: 2.9645 - val_accuracy30: 0.5193 - 37s/epoch - 22ms/step
Epoch 29/50
1691/1691 - 40s - loss: 2.6652 - accuracy30: 0.5733 - val_loss: 2.9664 - val_accuracy30: 0.5174 - 40s/epoch - 24ms/step
Epoch 30/50
1691/1691 - 37s - loss: 2.6623 - accuracy30: 0.5736 - val_loss: 2.9594 - val_accuracy30: 0.5173 - 37s/epoch - 22ms/step
Epoch 31/50
1691/1691 - 36s - loss: 2.6593 - accuracy30: 0.5750 - val_loss: 2.9553 - val_accuracy30: 0.5197 - 36s/epoch - 21ms/step
Epoch 32/50
1691/1691 - 36s - loss: 2.6573 - accuracy30: 0.5749 - val_loss: 2.9623 - val_accuracy30: 0.5188 - 36s/epoch - 21ms/step
Epoch 33/50
1691/1691 - 37s - loss: 2.6539 - accuracy30: 0.5759 - val_loss: 2.9748 - val_accuracy30: 0.5166 - 37s/epoch - 22ms/step
Epoch 34/50
1691/1691 - 40s - loss: 2.6520 - accuracy30: 0.5762 - val_loss: 2.9578 - val_accuracy30: 0.5186 - 40s/epoch - 24ms/step
Epoch 35/50
1691/1691 - 37s - loss: 2.6497 - accuracy30: 0.5759 - val_loss: 2.9702 - val_accuracy30: 0.5170 - 37s/epoch - 22ms/step
Epoch 36/50
1691/1691 - 40s - loss: 2.6457 - accuracy30: 0.5775 - val_loss: 2.9803 - val_accuracy30: 0.5155 - 40s/epoch - 23ms/step
Epoch 37/50
1691/1691 - 39s - loss: 2.6448 - accuracy30: 0.5782 - val_loss: 2.9681 - val_accuracy30: 0.5170 - 39s/epoch - 23ms/step
Epoch 38/50
1691/1691 - 36s - loss: 2.6421 - accuracy30: 0.5787 - val_loss: 2.9724 - val_accuracy30: 0.5171 - 36s/epoch - 21ms/step
Epoch 39/50
1691/1691 - 36s - loss: 2.6399 - accuracy30: 0.5788 - val_loss: 2.9894 - val_accuracy30: 0.5145 - 36s/epoch - 22ms/step
Epoch 40/50
1691/1691 - 40s - loss: 2.6375 - accuracy30: 0.5789 - val_loss: 2.9799 - val_accuracy30: 0.5164 - 40s/epoch - 24ms/step
Epoch 41/50
1691/1691 - 37s - loss: 2.6354 - accuracy30: 0.5797 - val_loss: 2.9800 - val_accuracy30: 0.5185 - 37s/epoch - 22ms/step
testing model: results/ATVI/W8/deepVOL_L2/h30
Evaluating performance on  test set...
4960/4960 - 48s - 48s/epoch - 10ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.91613644
{'0': {'precision': 0.5143134383901338, 'recall': 0.4131610048027358, 'f1-score': 0.45822126646918104, 'support': 357921}, '1': {'precision': 0.6094518112107009, 'recall': 0.7266983955433555, 'f1-score': 0.6629309356524017, 'support': 557011}, '2': {'precision': 0.5211708765220892, 'recall': 0.4671597866654639, 'f1-score': 0.4926895108304644, 'support': 354748}, 'accuracy': 0.5657976813055258, 'macro avg': {'precision': 0.5483120420409747, 'recall': 0.5356730623371851, 'f1-score': 0.5379472376506823, 'support': 1269680}, 'weighted avg': {'precision': 0.557966786198709, 'recall': 0.5657976813055258, 'f1-score': 0.557658194114014, 'support': 1269680}}
[[147879 129147  80895]
 [ 80867 404779  71365]
 [ 58781 130243 165724]]
Evaluating performance on  train set...
1691/1691 - 12s - 12s/epoch - 7ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.92805135
{'0': {'precision': 0.5393150758539162, 'recall': 0.44074681265278043, 'f1-score': 0.4850742661984083, 'support': 136634}, '1': {'precision': 0.5566142851654051, 'recall': 0.7126491910937298, 'f1-score': 0.6250407854536826, 'support': 162627}, '2': {'precision': 0.5402776056512579, 'recall': 0.45689196978657465, 'f1-score': 0.495098337450162, 'support': 133583}, 'accuracy': 0.5478879226695992, 'macro avg': {'precision': 0.5454023222235265, 'recall': 0.5367626578443616, 'f1-score': 0.535071129700751, 'support': 432844}, 'weighted avg': {'precision': 0.5461117419290329, 'recall': 0.5478879226695992, 'f1-score': 0.5407557141033128, 'support': 432844}}
[[ 60221  44882  31531]
 [ 26329 115896  20402]
 [ 25112  47438  61033]]
Evaluating performance on  val set...
591/591 - 5s - 5s/epoch - 9ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.9766474
{'0': {'precision': 0.5165453084916172, 'recall': 0.4083329919292064, 'f1-score': 0.45610863869853213, 'support': 48818}, '1': {'precision': 0.529213569186002, 'recall': 0.6654406100754892, 'f1-score': 0.5895600692696825, 'support': 51928}, '2': {'precision': 0.5086776159837454, 'recall': 0.4769786457092959, 'f1-score': 0.49231840714490555, 'support': 50388}, 'accuracy': 0.5195588021226196, 'macro avg': {'precision': 0.5181454978871215, 'recall': 0.5169174159046638, 'f1-score': 0.5126623717043735, 'support': 151134}, 'weighted avg': {'precision': 0.5182749004514102, 'recall': 0.5195588021226196, 'f1-score': 0.5140334186896298, 'support': 151134}}
[[19934 14593 14291]
 [ 8450 34555  8923]
 [10207 16147 24034]]
training model: results/ATVI/W8/deepVOL_L2/h50
Epoch 1/50
1691/1691 - 39s - loss: 3.1530 - accuracy50: 0.4365 - val_loss: 3.1815 - val_accuracy50: 0.4349 - 39s/epoch - 23ms/step
Epoch 2/50
1691/1691 - 41s - loss: 3.0246 - accuracy50: 0.4772 - val_loss: 3.1565 - val_accuracy50: 0.4414 - 41s/epoch - 24ms/step
Epoch 3/50
1691/1691 - 38s - loss: 2.9728 - accuracy50: 0.4919 - val_loss: 3.0934 - val_accuracy50: 0.4580 - 38s/epoch - 22ms/step
Epoch 4/50
1691/1691 - 38s - loss: 2.9475 - accuracy50: 0.4998 - val_loss: 3.0778 - val_accuracy50: 0.4623 - 38s/epoch - 23ms/step
Epoch 5/50
1691/1691 - 36s - loss: 2.9329 - accuracy50: 0.5037 - val_loss: 3.0715 - val_accuracy50: 0.4641 - 36s/epoch - 21ms/step
Epoch 6/50
1691/1691 - 37s - loss: 2.9229 - accuracy50: 0.5066 - val_loss: 3.0734 - val_accuracy50: 0.4645 - 37s/epoch - 22ms/step
Epoch 7/50
1691/1691 - 37s - loss: 2.9159 - accuracy50: 0.5082 - val_loss: 3.0677 - val_accuracy50: 0.4656 - 37s/epoch - 22ms/step
Epoch 8/50
1691/1691 - 37s - loss: 2.9094 - accuracy50: 0.5105 - val_loss: 3.0971 - val_accuracy50: 0.4616 - 37s/epoch - 22ms/step
Epoch 9/50
1691/1691 - 40s - loss: 2.9029 - accuracy50: 0.5125 - val_loss: 3.0880 - val_accuracy50: 0.4611 - 40s/epoch - 24ms/step
Epoch 10/50
1691/1691 - 37s - loss: 2.8982 - accuracy50: 0.5138 - val_loss: 3.0801 - val_accuracy50: 0.4632 - 37s/epoch - 22ms/step
Epoch 11/50
1691/1691 - 39s - loss: 2.8943 - accuracy50: 0.5147 - val_loss: 3.1079 - val_accuracy50: 0.4592 - 39s/epoch - 23ms/step
Epoch 12/50
1691/1691 - 37s - loss: 2.8895 - accuracy50: 0.5155 - val_loss: 3.0834 - val_accuracy50: 0.4647 - 37s/epoch - 22ms/step
Epoch 13/50
1691/1691 - 39s - loss: 2.8859 - accuracy50: 0.5168 - val_loss: 3.0695 - val_accuracy50: 0.4685 - 39s/epoch - 23ms/step
Epoch 14/50
1691/1691 - 41s - loss: 2.8812 - accuracy50: 0.5178 - val_loss: 3.0686 - val_accuracy50: 0.4685 - 41s/epoch - 24ms/step
Epoch 15/50
1691/1691 - 38s - loss: 2.8779 - accuracy50: 0.5185 - val_loss: 3.0691 - val_accuracy50: 0.4674 - 38s/epoch - 23ms/step
Epoch 16/50
1691/1691 - 39s - loss: 2.8744 - accuracy50: 0.5192 - val_loss: 3.0532 - val_accuracy50: 0.4725 - 39s/epoch - 23ms/step
Epoch 17/50
1691/1691 - 38s - loss: 2.8711 - accuracy50: 0.5208 - val_loss: 3.0624 - val_accuracy50: 0.4697 - 38s/epoch - 22ms/step
Epoch 18/50
1691/1691 - 36s - loss: 2.8661 - accuracy50: 0.5215 - val_loss: 3.0539 - val_accuracy50: 0.4728 - 36s/epoch - 21ms/step
Epoch 19/50
1691/1691 - 37s - loss: 2.8628 - accuracy50: 0.5223 - val_loss: 3.0544 - val_accuracy50: 0.4725 - 37s/epoch - 22ms/step
Epoch 20/50
1691/1691 - 37s - loss: 2.8604 - accuracy50: 0.5229 - val_loss: 3.0443 - val_accuracy50: 0.4760 - 37s/epoch - 22ms/step
Epoch 21/50
1691/1691 - 37s - loss: 2.8571 - accuracy50: 0.5239 - val_loss: 3.0459 - val_accuracy50: 0.4756 - 37s/epoch - 22ms/step
Epoch 22/50
1691/1691 - 37s - loss: 2.8543 - accuracy50: 0.5247 - val_loss: 3.0502 - val_accuracy50: 0.4747 - 37s/epoch - 22ms/step
Epoch 23/50
1691/1691 - 37s - loss: 2.8516 - accuracy50: 0.5252 - val_loss: 3.0523 - val_accuracy50: 0.4740 - 37s/epoch - 22ms/step
Epoch 24/50
1691/1691 - 40s - loss: 2.8487 - accuracy50: 0.5260 - val_loss: 3.0581 - val_accuracy50: 0.4734 - 40s/epoch - 24ms/step
Epoch 25/50
1691/1691 - 37s - loss: 2.8458 - accuracy50: 0.5267 - val_loss: 3.0491 - val_accuracy50: 0.4753 - 37s/epoch - 22ms/step
Epoch 26/50
1691/1691 - 42s - loss: 2.8430 - accuracy50: 0.5272 - val_loss: 3.0677 - val_accuracy50: 0.4720 - 42s/epoch - 25ms/step
Epoch 27/50
1691/1691 - 40s - loss: 2.8409 - accuracy50: 0.5277 - val_loss: 3.0530 - val_accuracy50: 0.4728 - 40s/epoch - 24ms/step
Epoch 28/50
1691/1691 - 42s - loss: 2.8370 - accuracy50: 0.5295 - val_loss: 3.0732 - val_accuracy50: 0.4706 - 42s/epoch - 25ms/step
Epoch 29/50
1691/1691 - 42s - loss: 2.8353 - accuracy50: 0.5298 - val_loss: 3.0761 - val_accuracy50: 0.4706 - 42s/epoch - 25ms/step
Epoch 30/50
1691/1691 - 41s - loss: 2.8308 - accuracy50: 0.5308 - val_loss: 3.0694 - val_accuracy50: 0.4704 - 41s/epoch - 24ms/step
testing model: results/ATVI/W8/deepVOL_L2/h50
Evaluating performance on  test set...
4960/4960 - 38s - 38s/epoch - 8ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.9745064
{'0': {'precision': 0.5258827428883386, 'recall': 0.27536427931526464, 'f1-score': 0.3614598706439492, 'support': 391801}, '1': {'precision': 0.5340371555079337, 'recall': 0.6972518587704752, 'f1-score': 0.6048269659071441, 'support': 486074}, '2': {'precision': 0.48044866874159675, 'recall': 0.5271550899044167, 'f1-score': 0.5027193656071139, 'support': 391805}, 'accuracy': 0.5145753260664104, 'macro avg': {'precision': 0.5134561890459564, 'recall': 0.4999237426633855, 'f1-score': 0.48966873405273575, 'support': 1269680}, 'weighted avg': {'precision': 0.5149842098237812, 'recall': 0.5145753260664104, 'f1-score': 0.49821920676565307, 'support': 1269680}}
[[107888 153966 129947]
 [ 53753 338916  93405]
 [ 43515 141748 206542]]
Evaluating performance on  train set...
1691/1691 - 16s - 16s/epoch - 9ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.9872534
{'0': {'precision': 0.5364896831159098, 'recall': 0.31290467994426685, 'f1-score': 0.3952701828252936, 'support': 146412}, '1': {'precision': 0.48232645518311673, 'recall': 0.658372065474158, 'f1-score': 0.5567645767590964, 'support': 143507}, '2': {'precision': 0.489628143886411, 'recall': 0.5192233688997726, 'f1-score': 0.5039916601299199, 'support': 142925}, 'accuracy': 0.49556884235428933, 'macro avg': {'precision': 0.5028147607284792, 'recall': 0.49683337143939915, 'f1-score': 0.48534213990477, 'support': 432844}, 'weighted avg': {'precision': 0.5030584981039253, 'recall': 0.49556884235428933, 'f1-score': 0.4847125526722175, 'support': 432844}}
[[45813 52221 48378]
 [20050 94481 28976]
 [19531 49184 74210]]
Evaluating performance on  val set...
591/591 - 5s - 5s/epoch - 8ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.015876
{'0': {'precision': 0.5220466786355475, 'recall': 0.27642786523690016, 'f1-score': 0.36145986127340085, 'support': 52596}, '1': {'precision': 0.4505481590920538, 'recall': 0.5975107429920068, 'f1-score': 0.513725640338451, 'support': 44913}, '2': {'precision': 0.47598123067748466, 'recall': 0.5655944055944055, 'f1-score': 0.5169328311148228, 'support': 53625}, 'accuracy': 0.47444651765982504, 'macro avg': {'precision': 0.482858689468362, 'recall': 0.47984433794110415, 'f1-score': 0.4640394442422249, 'support': 151134}, 'weighted avg': {'precision': 0.48445439195612355, 'recall': 0.47444651765982504, 'f1-score': 0.4618737386464265, 'support': 151134}}
[[14539 16502 21555]
 [ 6241 26836 11836]
 [ 7070 16225 30330]]
training model: results/ATVI/W8/deepVOL_L2/h100
Epoch 1/50
1691/1691 - 38s - loss: 3.2510 - accuracy100: 0.3980 - val_loss: 3.3192 - val_accuracy100: 0.3280 - 38s/epoch - 23ms/step
Epoch 2/50
1691/1691 - 37s - loss: 3.2002 - accuracy100: 0.4187 - val_loss: 3.3436 - val_accuracy100: 0.3120 - 37s/epoch - 22ms/step
Epoch 3/50
1691/1691 - 40s - loss: 3.1859 - accuracy100: 0.4247 - val_loss: 3.3362 - val_accuracy100: 0.3132 - 40s/epoch - 24ms/step
Epoch 4/50
1691/1691 - 41s - loss: 3.1789 - accuracy100: 0.4275 - val_loss: 3.3503 - val_accuracy100: 0.3133 - 41s/epoch - 24ms/step
Epoch 5/50
1691/1691 - 37s - loss: 3.1715 - accuracy100: 0.4305 - val_loss: 3.3540 - val_accuracy100: 0.3145 - 37s/epoch - 22ms/step
Epoch 6/50
1691/1691 - 35s - loss: 3.1657 - accuracy100: 0.4330 - val_loss: 3.3609 - val_accuracy100: 0.3289 - 35s/epoch - 21ms/step
Epoch 7/50
1691/1691 - 37s - loss: 3.1602 - accuracy100: 0.4349 - val_loss: 3.3550 - val_accuracy100: 0.3356 - 37s/epoch - 22ms/step
Epoch 8/50
1691/1691 - 35s - loss: 3.1559 - accuracy100: 0.4354 - val_loss: 3.3580 - val_accuracy100: 0.3367 - 35s/epoch - 21ms/step
Epoch 9/50
1691/1691 - 38s - loss: 3.1532 - accuracy100: 0.4361 - val_loss: 3.3645 - val_accuracy100: 0.3329 - 38s/epoch - 23ms/step
Epoch 10/50
1691/1691 - 38s - loss: 3.1489 - accuracy100: 0.4380 - val_loss: 3.3425 - val_accuracy100: 0.3457 - 38s/epoch - 22ms/step
Epoch 11/50
1691/1691 - 37s - loss: 3.1478 - accuracy100: 0.4382 - val_loss: 3.3413 - val_accuracy100: 0.3473 - 37s/epoch - 22ms/step
testing model: results/ATVI/W8/deepVOL_L2/h100
Evaluating performance on  test set...
4960/4960 - 41s - 41s/epoch - 8ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0932877
{'0': {'precision': 0.45212627184972604, 'recall': 0.012138517788683792, 'f1-score': 0.023642296017553233, 'support': 428306}, '1': {'precision': 0.33232604660449777, 'recall': 0.8717977942246321, 'f1-score': 0.48121481291110163, 'support': 412372}, '2': {'precision': 0.4246670861749349, 'recall': 0.1746145705614426, 'f1-score': 0.24747315406863904, 'support': 429002}, 'accuracy': 0.34623999747967993, 'macro avg': {'precision': 0.4030398015430529, 'recall': 0.35285029419158614, 'f1-score': 0.2507767543324313, 'support': 1269680}, 'weighted avg': {'precision': 0.4039390876319058, 'recall': 0.34623999747967993, 'f1-score': 0.2478830336065979, 'support': 1269680}}
[[  5199 371036  52071]
 [  3451 359505  49416]
 [  2849 351243  74910]]
Evaluating performance on  train set...
1691/1691 - 13s - 13s/epoch - 7ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0920188
{'0': {'precision': 0.4281694544317649, 'recall': 0.018587133550488598, 'f1-score': 0.035627646220985056, 'support': 147360}, '1': {'precision': 0.34128997647374393, 'recall': 0.8517624908475995, 'f1-score': 0.48731804916387894, 'support': 143405}, '2': {'precision': 0.4193934265999504, 'recall': 0.2023451741636695, 'f1-score': 0.2729836488975825, 'support': 142079}, 'accuracy': 0.3549431203851734, 'macro avg': {'precision': 0.3962842858351531, 'recall': 0.3575649328539192, 'f1-score': 0.2653097814274821, 'support': 432844}, 'weighted avg': {'precision': 0.3965048343957095, 'recall': 0.3549431203851734, 'f1-score': 0.2631876117936024, 'support': 432844}}
[[  2739 123858  20763]
 [  2221 122147  19037]
 [  1437 111893  28749]]
Evaluating performance on  val set...
591/591 - 5s - 5s/epoch - 9ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.1072986
{'0': {'precision': 0.4137648504711184, 'recall': 0.018902884093503772, 'f1-score': 0.036154066437571596, 'support': 53431}, '1': {'precision': 0.2998560812005016, 'recall': 0.8243978064187704, 'f1-score': 0.4397595566362615, 'support': 43217}, '2': {'precision': 0.43345829428303656, 'recall': 0.23767573321587196, 'f1-score': 0.30701026528531805, 'support': 54486}, 'accuracy': 0.32810618391625973, 'macro avg': {'precision': 0.3823597419848855, 'recall': 0.3603254745760487, 'f1-score': 0.2609746294530504, 'support': 151134}, 'weighted avg': {'precision': 0.38829223476563807, 'recall': 0.32810618391625973, 'f1-score': 0.2492132676784247, 'support': 151134}}
[[ 1010 42231 10190]
 [  853 35628  6736]
 [  578 40958 12950]]
training model: results/ATVI/W8/deepVOL_L2/h200
Epoch 1/50
1691/1691 - 40s - loss: 3.2898 - accuracy200: 0.3707 - val_loss: 3.2970 - val_accuracy200: 0.3538 - 40s/epoch - 24ms/step
Epoch 2/50
1691/1691 - 36s - loss: 3.2603 - accuracy200: 0.3844 - val_loss: 3.2921 - val_accuracy200: 0.3677 - 36s/epoch - 21ms/step
Epoch 3/50
1691/1691 - 36s - loss: 3.2473 - accuracy200: 0.3935 - val_loss: 3.2991 - val_accuracy200: 0.3544 - 36s/epoch - 21ms/step
Epoch 4/50
1691/1691 - 36s - loss: 3.2405 - accuracy200: 0.3963 - val_loss: 3.3159 - val_accuracy200: 0.3396 - 36s/epoch - 21ms/step
Epoch 5/50
1691/1691 - 38s - loss: 3.2354 - accuracy200: 0.4000 - val_loss: 3.3315 - val_accuracy200: 0.3383 - 38s/epoch - 22ms/step
Epoch 6/50
1691/1691 - 39s - loss: 3.2294 - accuracy200: 0.4042 - val_loss: 3.3505 - val_accuracy200: 0.3449 - 39s/epoch - 23ms/step
Epoch 7/50
1691/1691 - 37s - loss: 3.2252 - accuracy200: 0.4060 - val_loss: 3.3603 - val_accuracy200: 0.3504 - 37s/epoch - 22ms/step
Epoch 8/50
1691/1691 - 37s - loss: 3.2208 - accuracy200: 0.4087 - val_loss: 3.3897 - val_accuracy200: 0.3446 - 37s/epoch - 22ms/step
Epoch 9/50
1691/1691 - 36s - loss: 3.2171 - accuracy200: 0.4105 - val_loss: 3.3758 - val_accuracy200: 0.3470 - 36s/epoch - 21ms/step
Epoch 10/50
1691/1691 - 37s - loss: 3.2121 - accuracy200: 0.4141 - val_loss: 3.3862 - val_accuracy200: 0.3539 - 37s/epoch - 22ms/step
Epoch 11/50
1691/1691 - 37s - loss: 3.2094 - accuracy200: 0.4149 - val_loss: 3.3846 - val_accuracy200: 0.3517 - 37s/epoch - 22ms/step
Epoch 12/50
1691/1691 - 36s - loss: 3.2066 - accuracy200: 0.4164 - val_loss: 3.3722 - val_accuracy200: 0.3587 - 36s/epoch - 22ms/step
testing model: results/ATVI/W8/deepVOL_L2/h200
Evaluating performance on  test set...
4960/4960 - 42s - 42s/epoch - 8ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0900991
{'0': {'precision': 0.3933293593346391, 'recall': 0.1673538796737127, 'f1-score': 0.23480350292136049, 'support': 413991}, '1': {'precision': 0.37433616761948985, 'recall': 0.4731238996478873, 'f1-score': 0.4179722307729696, 'support': 436224}, '2': {'precision': 0.37557797897788786, 'recall': 0.48546362628586415, 'f1-score': 0.4235090302561415, 'support': 419465}, 'accuracy': 0.37750141768004536, 'macro avg': {'precision': 0.3810811686440056, 'recall': 0.3753138018691547, 'f1-score': 0.3587615879834905, 'support': 1269680}, 'weighted avg': {'precision': 0.3809393328523019, 'recall': 0.37750141768004536, 'f1-score': 0.360077555565983, 'support': 1269680}}
[[ 69283 178514 166194]
 [ 57474 206388 172362]
 [ 49388 166442 203635]]
Evaluating performance on  train set...
1691/1691 - 14s - 14s/epoch - 9ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0928392
{'0': {'precision': 0.3972646222639322, 'recall': 0.19456686313740335, 'f1-score': 0.2612045262747162, 'support': 147944}, '1': {'precision': 0.3581605890248628, 'recall': 0.44747644140699006, 'f1-score': 0.3978675750372769, 'support': 142517}, '2': {'precision': 0.3754696181079258, 'recall': 0.48080880442187623, 'f1-score': 0.4216598093079406, 'support': 142383}, 'accuracy': 0.3719977636284666, 'macro avg': {'precision': 0.3769649431322402, 'recall': 0.3742840363220899, 'f1-score': 0.3602439702066446, 'support': 432844}, 'weighted avg': {'precision': 0.3772199235228682, 'recall': 0.3719977636284666, 'f1-score': 0.3589832000800905, 'support': 432844}}
[[28785 60131 59028]
 [23902 63773 54842]
 [19771 54153 68459]]
Evaluating performance on  val set...
591/591 - 5s - 5s/epoch - 8ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0993291
{'0': {'precision': 0.39224870275979246, 'recall': 0.16176192099382647, 'f1-score': 0.2290602416100184, 'support': 52806}, '1': {'precision': 0.3314687871309752, 'recall': 0.40163462390360594, 'f1-score': 0.36319389502568783, 'support': 45148}, '2': {'precision': 0.3837003697154798, 'recall': 0.5386235426852201, 'f1-score': 0.4481506977908505, 'support': 53180}, 'accuracy': 0.36602617544695437, 'macro avg': {'precision': 0.3691392865354158, 'recall': 0.3673400291942175, 'f1-score': 0.34680161147551897, 'support': 151134}, 'weighted avg': {'precision': 0.3710840939880642, 'recall': 0.36602617544695437, 'f1-score': 0.346221811105349, 'support': 151134}}
[[ 8542 18479 25785]
 [ 6792 18133 20223]
 [ 6443 18093 28644]]
training model: results/ATVI/W8/deepVOL_L2/h300
Epoch 1/50
1691/1691 - 39s - loss: 3.2928 - accuracy300: 0.3686 - val_loss: 3.6601 - val_accuracy300: 0.2761 - 39s/epoch - 23ms/step
Epoch 2/50
1691/1691 - 38s - loss: 3.2760 - accuracy300: 0.3683 - val_loss: 3.5845 - val_accuracy300: 0.2772 - 38s/epoch - 22ms/step
Epoch 3/50
1691/1691 - 38s - loss: 3.2634 - accuracy300: 0.3799 - val_loss: 3.5723 - val_accuracy300: 0.2766 - 38s/epoch - 23ms/step
Epoch 4/50
1691/1691 - 37s - loss: 3.2550 - accuracy300: 0.3861 - val_loss: 3.5684 - val_accuracy300: 0.2763 - 37s/epoch - 22ms/step
Epoch 5/50
1691/1691 - 36s - loss: 3.2520 - accuracy300: 0.3887 - val_loss: 3.6099 - val_accuracy300: 0.2761 - 36s/epoch - 21ms/step
Epoch 6/50
1691/1691 - 36s - loss: 3.2465 - accuracy300: 0.3922 - val_loss: 3.6788 - val_accuracy300: 0.2764 - 36s/epoch - 21ms/step
Epoch 7/50
1691/1691 - 37s - loss: 3.2410 - accuracy300: 0.3958 - val_loss: 3.7127 - val_accuracy300: 0.2769 - 37s/epoch - 22ms/step
Epoch 8/50
1691/1691 - 36s - loss: 3.2364 - accuracy300: 0.3991 - val_loss: 3.8010 - val_accuracy300: 0.2767 - 36s/epoch - 22ms/step
Epoch 9/50
1691/1691 - 37s - loss: 3.2319 - accuracy300: 0.4011 - val_loss: 3.9334 - val_accuracy300: 0.2770 - 37s/epoch - 22ms/step
Epoch 10/50
1691/1691 - 38s - loss: 3.2281 - accuracy300: 0.4034 - val_loss: 3.9782 - val_accuracy300: 0.2769 - 38s/epoch - 22ms/step
Epoch 11/50
1691/1691 - 37s - loss: 3.2243 - accuracy300: 0.4067 - val_loss: 3.9833 - val_accuracy300: 0.2774 - 37s/epoch - 22ms/step
Epoch 12/50
1691/1691 - 39s - loss: 3.2206 - accuracy300: 0.4082 - val_loss: 4.0362 - val_accuracy300: 0.2784 - 39s/epoch - 23ms/step
Epoch 13/50
1691/1691 - 36s - loss: 3.2168 - accuracy300: 0.4101 - val_loss: 4.0027 - val_accuracy300: 0.2787 - 36s/epoch - 21ms/step
Epoch 14/50
1691/1691 - 39s - loss: 3.2123 - accuracy300: 0.4131 - val_loss: 4.0060 - val_accuracy300: 0.2806 - 39s/epoch - 23ms/step
testing model: results/ATVI/W8/deepVOL_L2/h300
Evaluating performance on  test set...
4960/4960 - 49s - 49s/epoch - 10ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1866262
{'0': {'precision': 0.5555555555555556, 'recall': 1.149409433433102e-05, 'f1-score': 2.298771306736549e-05, 'support': 435006}, '1': {'precision': 0.30977687044576235, 'recall': 0.9990539815424678, 'f1-score': 0.47291644346321876, 'support': 393227}, '2': {'precision': 0.39285714285714285, 'recall': 0.0013206568398924446, 'f1-score': 0.0026324641987126663, 'support': 441447}, 'accuracy': 0.30987571671602293, 'macro avg': {'precision': 0.41939652295282026, 'recall': 0.3334620441588982, 'f1-score': 0.15852396512499958, 'support': 1269680}, 'weighted avg': {'precision': 0.4228689406603498, 'recall': 0.30987571671602293, 'f1-score': 0.14738800920700557, 'support': 1269680}}
[[     5 434469    532]
 [     3 392855    369]
 [     1 440863    583]]
Evaluating performance on  train set...
1691/1691 - 16s - 16s/epoch - 9ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1773276
{'0': {'precision': 0.8, 'recall': 2.6420253766537427e-05, 'f1-score': 5.2838762516181874e-05, 'support': 151399}, '1': {'precision': 0.31555252229638286, 'recall': 0.9991283009193129, 'f1-score': 0.4796258527322597, 'support': 136515}, '2': {'precision': 0.41414141414141414, 'recall': 0.0016973711446905402, 'f1-score': 0.0033808856271130535, 'support': 144930}, 'accuracy': 0.3156934137934221, 'macro avg': {'precision': 0.509897978812599, 'recall': 0.3336173641059233, 'f1-score': 0.16101985904062963, 'support': 432844}, 'weighted avg': {'precision': 0.5180119575015614, 'recall': 0.3156934137934221, 'f1-score': 0.15242007461230403, 'support': 432844}}
[[     4 151166    229]
 [     0 136396    119]
 [     1 144683    246]]
Evaluating performance on  val set...
591/591 - 6s - 6s/epoch - 9ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.2048985
{'0': {'precision': 0.6666666666666666, 'recall': 3.6789051578250314e-05, 'f1-score': 7.357404307760222e-05, 'support': 54364}, '1': {'precision': 0.2761019959180428, 'recall': 0.9988253625794079, 'f1-score': 0.4326170810339368, 'support': 41715}, '2': {'precision': 0.3991031390134529, 'recall': 0.0016165652529288894, 'f1-score': 0.003220087557436955, 'support': 55055}, 'accuracy': 0.2762912382389138, 'macro avg': {'precision': 0.4472906005327208, 'recall': 0.3334929056279717, 'f1-score': 0.14530358087815046, 'support': 151134}, 'weighted avg': {'precision': 0.46139773144873736, 'recall': 0.2762912382389138, 'f1-score': 0.12060756173384701, 'support': 151134}}
[[    2 54277    85]
 [    0 41666    49]
 [    1 54965    89]]
training model: results/ATVI/W8/deepVOL_L2/h500
Epoch 1/50
1691/1691 - 38s - loss: 3.2711 - accuracy500: 0.3890 - val_loss: 3.3179 - val_accuracy500: 0.2945 - 38s/epoch - 23ms/step
Epoch 2/50
1691/1691 - 36s - loss: 3.2497 - accuracy500: 0.3908 - val_loss: 3.3405 - val_accuracy500: 0.2869 - 36s/epoch - 21ms/step
Epoch 3/50
1691/1691 - 40s - loss: 3.2398 - accuracy500: 0.3960 - val_loss: 3.3469 - val_accuracy500: 0.2917 - 40s/epoch - 24ms/step
Epoch 4/50
1691/1691 - 38s - loss: 3.2392 - accuracy500: 0.3967 - val_loss: 3.3729 - val_accuracy500: 0.2820 - 38s/epoch - 22ms/step
Epoch 5/50
1691/1691 - 39s - loss: 3.2378 - accuracy500: 0.3985 - val_loss: 3.3870 - val_accuracy500: 0.2813 - 39s/epoch - 23ms/step
Epoch 6/50
1691/1691 - 36s - loss: 3.2382 - accuracy500: 0.3978 - val_loss: 3.4173 - val_accuracy500: 0.2807 - 36s/epoch - 21ms/step
Epoch 7/50
1691/1691 - 37s - loss: 3.2347 - accuracy500: 0.3984 - val_loss: 3.4213 - val_accuracy500: 0.2810 - 37s/epoch - 22ms/step
Epoch 8/50
1691/1691 - 36s - loss: 3.2293 - accuracy500: 0.4000 - val_loss: 3.3984 - val_accuracy500: 0.2820 - 36s/epoch - 22ms/step
Epoch 9/50
1691/1691 - 36s - loss: 3.2249 - accuracy500: 0.4030 - val_loss: 3.4748 - val_accuracy500: 0.2809 - 36s/epoch - 21ms/step
Epoch 10/50
1691/1691 - 37s - loss: 3.2223 - accuracy500: 0.4038 - val_loss: 3.5076 - val_accuracy500: 0.2806 - 37s/epoch - 22ms/step
Epoch 11/50
1691/1691 - 37s - loss: 3.2207 - accuracy500: 0.4051 - val_loss: 3.4515 - val_accuracy500: 0.2836 - 37s/epoch - 22ms/step
testing model: results/ATVI/W8/deepVOL_L2/h500
Evaluating performance on  test set...
4960/4960 - 39s - 39s/epoch - 8ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1154946
{'0': {'precision': 0.4254170755642787, 'recall': 0.007373483524474097, 'f1-score': 0.014495721922898476, 'support': 470334}, '1': {'precision': 0.25215810050570475, 'recall': 0.9562284997177964, 'f1-score': 0.3990788413139671, 'support': 317147}, '2': {'precision': 0.39303313508920984, 'recall': 0.04796774775559468, 'f1-score': 0.0855005738851749, 'support': 482199}, 'accuracy': 0.2598001071136034, 'macro avg': {'precision': 0.35686943705306445, 'recall': 0.33718991033262175, 'f1-score': 0.16635837904068015, 'support': 1269680}, 'weighted avg': {'precision': 0.36984081392666984, 'recall': 0.2598001071136034, 'f1-score': 0.13752502944674463, 'support': 1269680}}
[[  3468 443523  23343]
 [  1505 303265  12377]
 [  3179 455890  23130]]
Evaluating performance on  train set...
1691/1691 - 13s - 13s/epoch - 8ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.101275
{'0': {'precision': 0.3856903297931806, 'recall': 0.009329178018293301, 'f1-score': 0.01821770153332321, 'support': 147923}, '1': {'precision': 0.33059807130850216, 'recall': 0.9494512474856195, 'f1-score': 0.4904291523953094, 'support': 141685}, '2': {'precision': 0.35714285714285715, 'recall': 0.05574715853556368, 'f1-score': 0.09644069229561457, 'support': 143236}, 'accuracy': 0.33242461487279484, 'macro avg': {'precision': 0.35781041941484665, 'recall': 0.3381758613464922, 'f1-score': 0.20169584874141575, 'support': 432844}, 'weighted avg': {'precision': 0.35820982310729976, 'recall': 0.33242461487279484, 'f1-score': 0.19867446591080812, 'support': 432844}}
[[  1380 138452   8091]
 [   880 134523   6282]
 [  1318 133933   7985]]
Evaluating performance on  val set...
591/591 - 4s - 4s/epoch - 7ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1082618
{'0': {'precision': 0.43588082901554404, 'recall': 0.012381110068620417, 'f1-score': 0.02407828124720488, 'support': 54357}, '1': {'precision': 0.2867011721939409, 'recall': 0.9537992772279567, 'f1-score': 0.44087911608000696, 'support': 42337}, '2': {'precision': 0.39505890426627016, 'recall': 0.06344599559147686, 'f1-score': 0.10933320671699667, 'support': 54440}, 'accuracy': 0.29449362817102703, 'macro avg': {'precision': 0.37254696849191843, 'recall': 0.34320879429601797, 'f1-score': 0.1914302013480695, 'support': 151134}, 'weighted avg': {'precision': 0.3793868255867545, 'recall': 0.29449362817102703, 'f1-score': 0.1715459264289099, 'support': 151134}}
[[  673 50097  3587]
 [  254 40381  1702]
 [  617 50369  3454]]
training model: results/ATVI/W8/deepVOL_L2/h1000
Epoch 1/50
1691/1691 - 41s - loss: 3.2741 - accuracy1000: 0.3875 - val_loss: 3.2778 - val_accuracy1000: 0.3553 - 41s/epoch - 24ms/step
Epoch 2/50
1691/1691 - 38s - loss: 3.2518 - accuracy1000: 0.3890 - val_loss: 3.2874 - val_accuracy1000: 0.3530 - 38s/epoch - 23ms/step
Epoch 3/50
1691/1691 - 36s - loss: 3.2418 - accuracy1000: 0.3954 - val_loss: 3.3026 - val_accuracy1000: 0.3307 - 36s/epoch - 21ms/step
Epoch 4/50
1691/1691 - 41s - loss: 3.2322 - accuracy1000: 0.3988 - val_loss: 3.2937 - val_accuracy1000: 0.3448 - 41s/epoch - 24ms/step
Epoch 5/50
1691/1691 - 40s - loss: 3.2263 - accuracy1000: 0.4016 - val_loss: 3.2852 - val_accuracy1000: 0.3482 - 40s/epoch - 23ms/step
Epoch 6/50
1691/1691 - 40s - loss: 3.2210 - accuracy1000: 0.4024 - val_loss: 3.2979 - val_accuracy1000: 0.3279 - 40s/epoch - 23ms/step
Epoch 7/50
1691/1691 - 38s - loss: 3.2159 - accuracy1000: 0.4054 - val_loss: 3.2959 - val_accuracy1000: 0.3347 - 38s/epoch - 22ms/step
Epoch 8/50
1691/1691 - 38s - loss: 3.2113 - accuracy1000: 0.4070 - val_loss: 3.2996 - val_accuracy1000: 0.3356 - 38s/epoch - 23ms/step
Epoch 9/50
1691/1691 - 36s - loss: 3.2087 - accuracy1000: 0.4087 - val_loss: 3.3128 - val_accuracy1000: 0.3298 - 36s/epoch - 21ms/step
Epoch 10/50
1691/1691 - 36s - loss: 3.2060 - accuracy1000: 0.4123 - val_loss: 3.3137 - val_accuracy1000: 0.3334 - 36s/epoch - 21ms/step
Epoch 11/50
1691/1691 - 37s - loss: 3.2032 - accuracy1000: 0.4135 - val_loss: 3.3191 - val_accuracy1000: 0.3364 - 37s/epoch - 22ms/step
testing model: results/ATVI/W8/deepVOL_L2/h1000
Evaluating performance on  test set...
4960/4960 - 47s - 47s/epoch - 9ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0954753
{'0': {'precision': 0.3706585144811917, 'recall': 0.1423333782641195, 'f1-score': 0.20568386867143243, 'support': 408035}, '1': {'precision': 0.38548856518678193, 'recall': 0.24649091664288217, 'f1-score': 0.3007041605627623, 'support': 430953}, '2': {'precision': 0.3390400653426189, 'recall': 0.6592251539383133, 'f1-score': 0.44778428607927934, 'support': 430692}, 'accuracy': 0.3530228088967299, 'macro avg': {'precision': 0.3650623816701975, 'recall': 0.34934981628177164, 'f1-score': 0.3180574384378247, 'support': 1269680}, 'weighted avg': {'precision': 0.3649667194976809, 'recall': 0.3530228088967299, 'f1-score': 0.32005913868093455, 'support': 1269680}}
[[ 58077  80215 269743]
 [ 40961 106226 283766]
 [ 57648  89121 283923]]
Evaluating performance on  train set...
1691/1691 - 13s - 13s/epoch - 8ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.096141
{'0': {'precision': 0.37685441482909837, 'recall': 0.16233052891056213, 'f1-score': 0.2269164864181578, 'support': 149288}, '1': {'precision': 0.3686172475044407, 'recall': 0.21222443879498462, 'f1-score': 0.2693663017893462, 'support': 138853}, '2': {'precision': 0.335340753163592, 'recall': 0.6688043786238018, 'f1-score': 0.44670308493672967, 'support': 144703}, 'accuracy': 0.34765412019110814, 'macro avg': {'precision': 0.3602708051657104, 'recall': 0.3477864487764495, 'f1-score': 0.3143286243814112, 'support': 432844}, 'weighted avg': {'precision': 0.3603336665259812, 'recall': 0.34765412019110814, 'f1-score': 0.3140103686925304, 'support': 432844}}
[[24234 25863 99191]
 [16758 29468 92627]
 [23314 24611 96778]]
Evaluating performance on  val set...
591/591 - 5s - 5s/epoch - 9ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0930824
{'0': {'precision': 0.3882324764489861, 'recall': 0.18450506506810335, 'f1-score': 0.25013502044595326, 'support': 52714}, '1': {'precision': 0.35374941779226826, 'recall': 0.16777856322346912, 'f1-score': 0.22760646108663732, 'support': 45268}, '2': {'precision': 0.3482487668718694, 'recall': 0.6854116496086695, 'f1-score': 0.46184173829263964, 'support': 53152}, 'accuracy': 0.3556578929956198, 'macro avg': {'precision': 0.36341022037104126, 'recall': 0.3458984259667473, 'f1-score': 0.3131944066084101, 'support': 151134}, 'weighted avg': {'precision': 0.36384224506018403, 'recall': 0.3556578929956198, 'f1-score': 0.31784190732719486, 'support': 151134}}
[[ 9726  6689 36299]
 [ 5791  7595 31882]
 [ 9535  7186 36431]]
training model: results/ATVI/W8/deepVOL_L3/h10
Epoch 1/50
1691/1691 - 59s - loss: 3.2455 - accuracy10: 0.4352 - val_loss: 3.3598 - val_accuracy10: 0.3775 - 59s/epoch - 35ms/step
Epoch 2/50
1691/1691 - 56s - loss: 2.9690 - accuracy10: 0.4891 - val_loss: 3.0573 - val_accuracy10: 0.4705 - 56s/epoch - 33ms/step
Epoch 3/50
1691/1691 - 57s - loss: 2.7717 - accuracy10: 0.5429 - val_loss: 3.0274 - val_accuracy10: 0.5495 - 57s/epoch - 34ms/step
Epoch 4/50
1691/1691 - 57s - loss: 2.6950 - accuracy10: 0.5651 - val_loss: 2.9654 - val_accuracy10: 0.5512 - 57s/epoch - 34ms/step
Epoch 5/50
1691/1691 - 57s - loss: 2.6622 - accuracy10: 0.5741 - val_loss: 2.9224 - val_accuracy10: 0.5454 - 57s/epoch - 34ms/step
Epoch 6/50
1691/1691 - 57s - loss: 2.6386 - accuracy10: 0.5804 - val_loss: 2.9128 - val_accuracy10: 0.5552 - 57s/epoch - 33ms/step
Epoch 7/50
1691/1691 - 57s - loss: 2.6220 - accuracy10: 0.5842 - val_loss: 2.9058 - val_accuracy10: 0.5516 - 57s/epoch - 34ms/step
Epoch 8/50
1691/1691 - 57s - loss: 2.6099 - accuracy10: 0.5874 - val_loss: 2.8815 - val_accuracy10: 0.5625 - 57s/epoch - 34ms/step
Epoch 9/50
1691/1691 - 57s - loss: 2.5979 - accuracy10: 0.5889 - val_loss: 2.8841 - val_accuracy10: 0.5593 - 57s/epoch - 33ms/step
Epoch 10/50
1691/1691 - 56s - loss: 2.5888 - accuracy10: 0.5904 - val_loss: 2.8726 - val_accuracy10: 0.5596 - 56s/epoch - 33ms/step
Epoch 11/50
1691/1691 - 57s - loss: 2.5816 - accuracy10: 0.5928 - val_loss: 2.8663 - val_accuracy10: 0.5629 - 57s/epoch - 34ms/step
Epoch 12/50
1691/1691 - 57s - loss: 2.5733 - accuracy10: 0.5930 - val_loss: 2.8576 - val_accuracy10: 0.5683 - 57s/epoch - 34ms/step
Epoch 13/50
1691/1691 - 56s - loss: 2.5637 - accuracy10: 0.5954 - val_loss: 2.8495 - val_accuracy10: 0.5663 - 56s/epoch - 33ms/step
Epoch 14/50
1691/1691 - 57s - loss: 2.5585 - accuracy10: 0.5964 - val_loss: 2.8554 - val_accuracy10: 0.5714 - 57s/epoch - 33ms/step
Epoch 15/50
1691/1691 - 57s - loss: 2.5500 - accuracy10: 0.5980 - val_loss: 2.8404 - val_accuracy10: 0.5688 - 57s/epoch - 34ms/step
Epoch 16/50
1691/1691 - 57s - loss: 2.5429 - accuracy10: 0.5985 - val_loss: 2.8143 - val_accuracy10: 0.5711 - 57s/epoch - 34ms/step
Epoch 17/50
1691/1691 - 56s - loss: 2.5393 - accuracy10: 0.5997 - val_loss: 2.8340 - val_accuracy10: 0.5722 - 56s/epoch - 33ms/step
Epoch 18/50
1691/1691 - 56s - loss: 2.5312 - accuracy10: 0.6013 - val_loss: 2.8297 - val_accuracy10: 0.5765 - 56s/epoch - 33ms/step
Epoch 19/50
1691/1691 - 58s - loss: 2.5287 - accuracy10: 0.6014 - val_loss: 2.8227 - val_accuracy10: 0.5802 - 58s/epoch - 34ms/step
Epoch 20/50
1691/1691 - 58s - loss: 2.5221 - accuracy10: 0.6022 - val_loss: 2.8055 - val_accuracy10: 0.5795 - 58s/epoch - 34ms/step
Epoch 21/50
1691/1691 - 57s - loss: 2.5175 - accuracy10: 0.6029 - val_loss: 2.8247 - val_accuracy10: 0.5782 - 57s/epoch - 34ms/step
Epoch 22/50
1691/1691 - 57s - loss: 2.5125 - accuracy10: 0.6043 - val_loss: 2.8353 - val_accuracy10: 0.5800 - 57s/epoch - 34ms/step
Epoch 23/50
1691/1691 - 61s - loss: 2.5092 - accuracy10: 0.6050 - val_loss: 2.8126 - val_accuracy10: 0.5764 - 61s/epoch - 36ms/step
Epoch 24/50
1691/1691 - 57s - loss: 2.5049 - accuracy10: 0.6059 - val_loss: 2.8110 - val_accuracy10: 0.5815 - 57s/epoch - 34ms/step
Epoch 25/50
1691/1691 - 61s - loss: 2.5007 - accuracy10: 0.6062 - val_loss: 2.7945 - val_accuracy10: 0.5799 - 61s/epoch - 36ms/step
Epoch 26/50
1691/1691 - 56s - loss: 2.4976 - accuracy10: 0.6064 - val_loss: 2.8145 - val_accuracy10: 0.5827 - 56s/epoch - 33ms/step
Epoch 27/50
1691/1691 - 61s - loss: 2.4941 - accuracy10: 0.6079 - val_loss: 2.8043 - val_accuracy10: 0.5785 - 61s/epoch - 36ms/step
Epoch 28/50
1691/1691 - 57s - loss: 2.4895 - accuracy10: 0.6080 - val_loss: 2.7849 - val_accuracy10: 0.5803 - 57s/epoch - 34ms/step
Epoch 29/50
1691/1691 - 61s - loss: 2.4867 - accuracy10: 0.6091 - val_loss: 2.8072 - val_accuracy10: 0.5801 - 61s/epoch - 36ms/step
Epoch 30/50
1691/1691 - 56s - loss: 2.4834 - accuracy10: 0.6096 - val_loss: 2.8111 - val_accuracy10: 0.5793 - 56s/epoch - 33ms/step
Epoch 31/50
1691/1691 - 56s - loss: 2.4806 - accuracy10: 0.6092 - val_loss: 2.7933 - val_accuracy10: 0.5840 - 56s/epoch - 33ms/step
Epoch 32/50
1691/1691 - 57s - loss: 2.4769 - accuracy10: 0.6100 - val_loss: 2.8029 - val_accuracy10: 0.5823 - 57s/epoch - 34ms/step
Epoch 33/50
1691/1691 - 56s - loss: 2.4736 - accuracy10: 0.6097 - val_loss: 2.7962 - val_accuracy10: 0.5828 - 56s/epoch - 33ms/step
Epoch 34/50
1691/1691 - 57s - loss: 2.4709 - accuracy10: 0.6105 - val_loss: 2.7943 - val_accuracy10: 0.5807 - 57s/epoch - 34ms/step
Epoch 35/50
1691/1691 - 56s - loss: 2.4685 - accuracy10: 0.6112 - val_loss: 2.7966 - val_accuracy10: 0.5817 - 56s/epoch - 33ms/step
Epoch 36/50
1691/1691 - 59s - loss: 2.4657 - accuracy10: 0.6115 - val_loss: 2.7914 - val_accuracy10: 0.5826 - 59s/epoch - 35ms/step
Epoch 37/50
1691/1691 - 56s - loss: 2.4615 - accuracy10: 0.6122 - val_loss: 2.8091 - val_accuracy10: 0.5836 - 56s/epoch - 33ms/step
Epoch 38/50
1691/1691 - 55s - loss: 2.4595 - accuracy10: 0.6124 - val_loss: 2.8095 - val_accuracy10: 0.5855 - 55s/epoch - 33ms/step
testing model: results/ATVI/W8/deepVOL_L3/h10
Evaluating performance on  test set...
4960/4960 - 69s - 69s/epoch - 14ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.8190037
{'0': {'precision': 0.4146291048145388, 'recall': 0.6111077706291463, 'f1-score': 0.4940508115623121, 'support': 249465}, '1': {'precision': 0.8110539199512304, 'recall': 0.6664760131641294, 'f1-score': 0.7316914140487076, 'support': 774529}, '2': {'precision': 0.4705317466295097, 'recall': 0.5085556360557785, 'f1-score': 0.48880534245128376, 'support': 245686}, 'accuracy': 0.6250393800012601, 'macro avg': {'precision': 0.5654049237984263, 'recall': 0.5953798066163514, 'f1-score': 0.5715158560207678, 'support': 1269680}, 'weighted avg': {'precision': 0.6672730876290744, 'recall': 0.6250393800012601, 'f1-score': 0.6380010981535582, 'support': 1269680}}
[[152450  52747  44268]
 [161997 516205  96327]
 [ 53231  67510 124945]]
Evaluating performance on  train set...
1691/1691 - 23s - 23s/epoch - 14ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.8421688
{'0': {'precision': 0.44493680805893165, 'recall': 0.6356576523394164, 'f1-score': 0.523466475565446, 'support': 98251}, '1': {'precision': 0.7815673481075442, 'recall': 0.6420997798726286, 'f1-score': 0.7050021909088813, 'support': 238044}, '2': {'precision': 0.5001650982334489, 'recall': 0.5020455934292432, 'f1-score': 0.501103581600426, 'support': 96549}, 'accuracy': 0.6093973810425927, 'macro avg': {'precision': 0.5755564181333083, 'recall': 0.5932676752137628, 'f1-score': 0.5765240826915844, 'support': 432844}, 'weighted avg': {'precision': 0.6423869666920453, 'recall': 0.6093973810425927, 'f1-score': 0.6183144410536682, 'support': 432844}}
[[ 62454  17945  17852]
 [ 54608 152848  30588]
 [ 23304  24773  48472]]
Evaluating performance on  val set...
591/591 - 8s - 8s/epoch - 13ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.8934986
{'0': {'precision': 0.4409250573592414, 'recall': 0.596740952433294, 'f1-score': 0.5071343499684734, 'support': 36391}, '1': {'precision': 0.7614138438880707, 'recall': 0.6060805152979066, 'f1-score': 0.6749250433959287, 'support': 77625}, '2': {'precision': 0.4689479722651768, 'recall': 0.5065466889379816, 'f1-score': 0.4870227425788738, 'support': 37118}, 'accuracy': 0.5793865046912012, 'macro avg': {'precision': 0.557095624504163, 'recall': 0.569789385556394, 'f1-score': 0.5563607119810919, 'support': 151134}, 'weighted avg': {'precision': 0.6124158973408398, 'recall': 0.5793865046912012, 'f1-score': 0.5883751689385202, 'support': 151134}}
[[21716  6091  8584]
 [17870 47047 12708]
 [ 9665  8651 18802]]
training model: results/ATVI/W8/deepVOL_L3/h20
Epoch 1/50
1691/1691 - 60s - loss: 3.1918 - accuracy20: 0.4344 - val_loss: 3.2827 - val_accuracy20: 0.4244 - 60s/epoch - 35ms/step
Epoch 2/50
1691/1691 - 57s - loss: 3.0501 - accuracy20: 0.4807 - val_loss: 3.2607 - val_accuracy20: 0.4521 - 57s/epoch - 34ms/step
Epoch 3/50
1691/1691 - 58s - loss: 2.8521 - accuracy20: 0.5350 - val_loss: 3.0246 - val_accuracy20: 0.5118 - 58s/epoch - 34ms/step
Epoch 4/50
1691/1691 - 56s - loss: 2.7729 - accuracy20: 0.5549 - val_loss: 3.0042 - val_accuracy20: 0.5265 - 56s/epoch - 33ms/step
Epoch 5/50
1691/1691 - 56s - loss: 2.7403 - accuracy20: 0.5627 - val_loss: 2.9708 - val_accuracy20: 0.5250 - 56s/epoch - 33ms/step
Epoch 6/50
1691/1691 - 56s - loss: 2.7198 - accuracy20: 0.5666 - val_loss: 2.9723 - val_accuracy20: 0.5327 - 56s/epoch - 33ms/step
Epoch 7/50
1691/1691 - 57s - loss: 2.7049 - accuracy20: 0.5702 - val_loss: 2.9703 - val_accuracy20: 0.5342 - 57s/epoch - 34ms/step
Epoch 8/50
1691/1691 - 56s - loss: 2.6916 - accuracy20: 0.5730 - val_loss: 2.9583 - val_accuracy20: 0.5388 - 56s/epoch - 33ms/step
Epoch 9/50
1691/1691 - 57s - loss: 2.6808 - accuracy20: 0.5754 - val_loss: 2.9531 - val_accuracy20: 0.5361 - 57s/epoch - 34ms/step
Epoch 10/50
1691/1691 - 56s - loss: 2.6685 - accuracy20: 0.5780 - val_loss: 2.9678 - val_accuracy20: 0.5358 - 56s/epoch - 33ms/step
Epoch 11/50
1691/1691 - 57s - loss: 2.6619 - accuracy20: 0.5788 - val_loss: 2.9187 - val_accuracy20: 0.5416 - 57s/epoch - 34ms/step
Epoch 12/50
1691/1691 - 57s - loss: 2.6543 - accuracy20: 0.5804 - val_loss: 2.9221 - val_accuracy20: 0.5422 - 57s/epoch - 34ms/step
Epoch 13/50
1691/1691 - 57s - loss: 2.6434 - accuracy20: 0.5820 - val_loss: 2.9192 - val_accuracy20: 0.5431 - 57s/epoch - 34ms/step
Epoch 14/50
1691/1691 - 56s - loss: 2.6386 - accuracy20: 0.5824 - val_loss: 2.9082 - val_accuracy20: 0.5471 - 56s/epoch - 33ms/step
Epoch 15/50
1691/1691 - 58s - loss: 2.6311 - accuracy20: 0.5843 - val_loss: 2.8899 - val_accuracy20: 0.5469 - 58s/epoch - 34ms/step
Epoch 16/50
1691/1691 - 56s - loss: 2.6266 - accuracy20: 0.5850 - val_loss: 2.8923 - val_accuracy20: 0.5474 - 56s/epoch - 33ms/step
Epoch 17/50
1691/1691 - 57s - loss: 2.6209 - accuracy20: 0.5862 - val_loss: 2.8804 - val_accuracy20: 0.5500 - 57s/epoch - 34ms/step
Epoch 18/50
1691/1691 - 56s - loss: 2.6164 - accuracy20: 0.5872 - val_loss: 2.8620 - val_accuracy20: 0.5494 - 56s/epoch - 33ms/step
Epoch 19/50
1691/1691 - 57s - loss: 2.6125 - accuracy20: 0.5878 - val_loss: 2.8882 - val_accuracy20: 0.5517 - 57s/epoch - 34ms/step
Epoch 20/50
1691/1691 - 56s - loss: 2.6081 - accuracy20: 0.5889 - val_loss: 2.8784 - val_accuracy20: 0.5516 - 56s/epoch - 33ms/step
Epoch 21/50
1691/1691 - 57s - loss: 2.6040 - accuracy20: 0.5896 - val_loss: 2.8709 - val_accuracy20: 0.5512 - 57s/epoch - 34ms/step
Epoch 22/50
1691/1691 - 56s - loss: 2.6009 - accuracy20: 0.5896 - val_loss: 2.8736 - val_accuracy20: 0.5527 - 56s/epoch - 33ms/step
Epoch 23/50
1691/1691 - 57s - loss: 2.5972 - accuracy20: 0.5904 - val_loss: 2.8827 - val_accuracy20: 0.5525 - 57s/epoch - 34ms/step
Epoch 24/50
1691/1691 - 57s - loss: 2.5955 - accuracy20: 0.5911 - val_loss: 2.8731 - val_accuracy20: 0.5532 - 57s/epoch - 33ms/step
Epoch 25/50
1691/1691 - 57s - loss: 2.5900 - accuracy20: 0.5923 - val_loss: 2.8638 - val_accuracy20: 0.5528 - 57s/epoch - 34ms/step
Epoch 26/50
1691/1691 - 57s - loss: 2.5880 - accuracy20: 0.5927 - val_loss: 2.8813 - val_accuracy20: 0.5516 - 57s/epoch - 33ms/step
Epoch 27/50
1691/1691 - 56s - loss: 2.5846 - accuracy20: 0.5932 - val_loss: 2.8691 - val_accuracy20: 0.5508 - 56s/epoch - 33ms/step
Epoch 28/50
1691/1691 - 56s - loss: 2.5824 - accuracy20: 0.5934 - val_loss: 2.8636 - val_accuracy20: 0.5513 - 56s/epoch - 33ms/step
testing model: results/ATVI/W8/deepVOL_L3/h20
Evaluating performance on  test set...
4960/4960 - 67s - 67s/epoch - 14ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.8630766
{'0': {'precision': 0.48169104174699534, 'recall': 0.5125272712238499, 'f1-score': 0.4966309551507942, 'support': 314434}, '1': {'precision': 0.7085811454002555, 'recall': 0.6759047271654857, 'f1-score': 0.6918573244359708, 'support': 644255}, '2': {'precision': 0.4982624808155422, 'recall': 0.5136129341363577, 'f1-score': 0.5058212719871177, 'support': 310991}, 'accuracy': 0.5956934030621889, 'macro avg': {'precision': 0.562844889320931, 'recall': 0.5673483108418979, 'f1-score': 0.5647698505246276, 'support': 1269680}, 'weighted avg': {'precision': 0.6008774919836674, 'recall': 0.5956934030621889, 'f1-score': 0.5979428371738761, 'support': 1269680}}
[[161156  90419  62859]
 [110816 435455  97984]
 [ 62591  88671 159729]]
Evaluating performance on  train set...
1691/1691 - 23s - 23s/epoch - 14ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.8831243
{'0': {'precision': 0.507873169099902, 'recall': 0.5256324653164182, 'f1-score': 0.516600233326852, 'support': 121311}, '1': {'precision': 0.6608599153504697, 'recall': 0.6655213818268766, 'f1-score': 0.6631824574034698, 'support': 192383}, '2': {'precision': 0.5233595476922264, 'recall': 0.4987662610155266, 'f1-score': 0.510767035809902, 'support': 119150}, 'accuracy': 0.5804123425529752, 'macro avg': {'precision': 0.564030877380866, 'recall': 0.5633067027196071, 'f1-score': 0.563516575513408, 'support': 432844}, 'weighted avg': {'precision': 0.5801330391990566, 'recall': 0.5804123425529752, 'f1-score': 0.5801448418472135, 'support': 432844}}
[[ 63765  32075  25471]
 [ 35696 128035  28652]
 [ 26092  33630  59428]]
Evaluating performance on  val set...
591/591 - 8s - 8s/epoch - 14ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.9313215
{'0': {'precision': 0.4949408450704225, 'recall': 0.49951101912711227, 'f1-score': 0.4972154305895137, 'support': 43969}, '1': {'precision': 0.637329567424892, 'recall': 0.612571705582936, 'f1-score': 0.6247054364484288, 'support': 61885}, '2': {'precision': 0.4970810948009645, 'recall': 0.5190150176678445, 'f1-score': 0.5078113183085201, 'support': 45280}, 'accuracy': 0.5516495295565524, 'macro avg': {'precision': 0.5431171690987596, 'recall': 0.5436992474592977, 'f1-score': 0.5432440617821542, 'support': 151134}, 'weighted avg': {'precision': 0.5538861293261511, 'recall': 0.5516495295565524, 'f1-score': 0.5525934448582789, 'support': 151134}}
[[21963 10253 11753]
 [11952 37909 12024]
 [10460 11319 23501]]
training model: results/ATVI/W8/deepVOL_L3/h30
Epoch 1/50
1691/1691 - 61s - loss: 3.2386 - accuracy30: 0.4041 - val_loss: 3.2480 - val_accuracy30: 0.3986 - 61s/epoch - 36ms/step
Epoch 2/50
1691/1691 - 57s - loss: 3.1403 - accuracy30: 0.4477 - val_loss: 3.2172 - val_accuracy30: 0.4377 - 57s/epoch - 34ms/step
Epoch 3/50
1691/1691 - 57s - loss: 3.0404 - accuracy30: 0.4801 - val_loss: 3.1410 - val_accuracy30: 0.4423 - 57s/epoch - 34ms/step
Epoch 4/50
1691/1691 - 56s - loss: 2.8948 - accuracy30: 0.5154 - val_loss: 3.0302 - val_accuracy30: 0.4930 - 56s/epoch - 33ms/step
Epoch 5/50
1691/1691 - 57s - loss: 2.8530 - accuracy30: 0.5276 - val_loss: 3.0264 - val_accuracy30: 0.4915 - 57s/epoch - 34ms/step
Epoch 6/50
1691/1691 - 56s - loss: 2.8279 - accuracy30: 0.5349 - val_loss: 3.0170 - val_accuracy30: 0.5008 - 56s/epoch - 33ms/step
Epoch 7/50
1691/1691 - 56s - loss: 2.8067 - accuracy30: 0.5403 - val_loss: 3.0300 - val_accuracy30: 0.4971 - 56s/epoch - 33ms/step
Epoch 8/50
1691/1691 - 57s - loss: 2.7882 - accuracy30: 0.5441 - val_loss: 3.0230 - val_accuracy30: 0.5021 - 57s/epoch - 34ms/step
Epoch 9/50
1691/1691 - 57s - loss: 2.7749 - accuracy30: 0.5477 - val_loss: 3.0186 - val_accuracy30: 0.5037 - 57s/epoch - 33ms/step
Epoch 10/50
1691/1691 - 57s - loss: 2.7630 - accuracy30: 0.5496 - val_loss: 3.0014 - val_accuracy30: 0.5050 - 57s/epoch - 33ms/step
Epoch 11/50
1691/1691 - 57s - loss: 2.7515 - accuracy30: 0.5536 - val_loss: 3.0011 - val_accuracy30: 0.5064 - 57s/epoch - 34ms/step
Epoch 12/50
1691/1691 - 56s - loss: 2.7437 - accuracy30: 0.5551 - val_loss: 2.9763 - val_accuracy30: 0.5092 - 56s/epoch - 33ms/step
Epoch 13/50
1691/1691 - 57s - loss: 2.7350 - accuracy30: 0.5567 - val_loss: 2.9786 - val_accuracy30: 0.5101 - 57s/epoch - 34ms/step
Epoch 14/50
1691/1691 - 56s - loss: 2.7285 - accuracy30: 0.5586 - val_loss: 2.9735 - val_accuracy30: 0.5104 - 56s/epoch - 33ms/step
Epoch 15/50
1691/1691 - 57s - loss: 2.7224 - accuracy30: 0.5595 - val_loss: 2.9617 - val_accuracy30: 0.5109 - 57s/epoch - 34ms/step
Epoch 16/50
1691/1691 - 59s - loss: 2.7158 - accuracy30: 0.5607 - val_loss: 2.9590 - val_accuracy30: 0.5125 - 59s/epoch - 35ms/step
Epoch 17/50
1691/1691 - 58s - loss: 2.7091 - accuracy30: 0.5623 - val_loss: 2.9431 - val_accuracy30: 0.5137 - 58s/epoch - 34ms/step
Epoch 18/50
1691/1691 - 57s - loss: 2.7039 - accuracy30: 0.5633 - val_loss: 2.9418 - val_accuracy30: 0.5156 - 57s/epoch - 34ms/step
Epoch 19/50
1691/1691 - 57s - loss: 2.6986 - accuracy30: 0.5650 - val_loss: 2.9394 - val_accuracy30: 0.5151 - 57s/epoch - 34ms/step
Epoch 20/50
1691/1691 - 57s - loss: 2.6940 - accuracy30: 0.5660 - val_loss: 2.9437 - val_accuracy30: 0.5152 - 57s/epoch - 34ms/step
Epoch 21/50
1691/1691 - 58s - loss: 2.6902 - accuracy30: 0.5661 - val_loss: 2.9318 - val_accuracy30: 0.5178 - 58s/epoch - 34ms/step
Epoch 22/50
1691/1691 - 57s - loss: 2.6862 - accuracy30: 0.5674 - val_loss: 2.9323 - val_accuracy30: 0.5187 - 57s/epoch - 34ms/step
Epoch 23/50
1691/1691 - 57s - loss: 2.6824 - accuracy30: 0.5680 - val_loss: 2.9200 - val_accuracy30: 0.5197 - 57s/epoch - 34ms/step
Epoch 24/50
1691/1691 - 57s - loss: 2.6788 - accuracy30: 0.5687 - val_loss: 2.9371 - val_accuracy30: 0.5185 - 57s/epoch - 34ms/step
Epoch 25/50
1691/1691 - 57s - loss: 2.6744 - accuracy30: 0.5700 - val_loss: 2.9265 - val_accuracy30: 0.5213 - 57s/epoch - 34ms/step
Epoch 26/50
1691/1691 - 57s - loss: 2.6716 - accuracy30: 0.5702 - val_loss: 2.9260 - val_accuracy30: 0.5214 - 57s/epoch - 33ms/step
Epoch 27/50
1691/1691 - 57s - loss: 2.6684 - accuracy30: 0.5712 - val_loss: 2.9258 - val_accuracy30: 0.5214 - 57s/epoch - 34ms/step
Epoch 28/50
1691/1691 - 57s - loss: 2.6661 - accuracy30: 0.5716 - val_loss: 2.9271 - val_accuracy30: 0.5222 - 57s/epoch - 34ms/step
Epoch 29/50
1691/1691 - 57s - loss: 2.6623 - accuracy30: 0.5723 - val_loss: 2.9242 - val_accuracy30: 0.5228 - 57s/epoch - 34ms/step
Epoch 30/50
1691/1691 - 57s - loss: 2.6592 - accuracy30: 0.5732 - val_loss: 2.9308 - val_accuracy30: 0.5215 - 57s/epoch - 34ms/step
Epoch 31/50
1691/1691 - 57s - loss: 2.6576 - accuracy30: 0.5733 - val_loss: 2.9247 - val_accuracy30: 0.5238 - 57s/epoch - 33ms/step
Epoch 32/50
1691/1691 - 61s - loss: 2.6549 - accuracy30: 0.5739 - val_loss: 2.9256 - val_accuracy30: 0.5224 - 61s/epoch - 36ms/step
Epoch 33/50
1691/1691 - 58s - loss: 2.6510 - accuracy30: 0.5758 - val_loss: 2.9296 - val_accuracy30: 0.5215 - 58s/epoch - 34ms/step
testing model: results/ATVI/W8/deepVOL_L3/h30
Evaluating performance on  test set...
4960/4960 - 69s - 69s/epoch - 14ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.9081609
{'0': {'precision': 0.4914687853944931, 'recall': 0.488571500414896, 'f1-score': 0.49001586029490063, 'support': 357921}, '1': {'precision': 0.6323870117060059, 'recall': 0.6698844367525956, 'f1-score': 0.6505958763785362, 'support': 557011}, '2': {'precision': 0.5188154278479449, 'recall': 0.4735981598204923, 'f1-score': 0.4951766782890102, 'support': 354748}, 'accuracy': 0.563930281645769, 'macro avg': {'precision': 0.5475570749828146, 'recall': 0.544018032329328, 'f1-score': 0.5452628049874823, 'support': 1269680}, 'weighted avg': {'precision': 0.5609305150217057, 'recall': 0.563930281645769, 'f1-score': 0.561904545003281, 'support': 1269680}}
[[174870 105982  77069]
 [105125 373133  78753]
 [ 75816 110924 168008]]
Evaluating performance on  train set...
1691/1691 - 24s - 24s/epoch - 14ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.9223892
{'0': {'precision': 0.5180751753617655, 'recall': 0.5064991144224718, 'f1-score': 0.5122217493477416, 'support': 136634}, '1': {'precision': 0.5763299442617801, 'recall': 0.6542456049733439, 'f1-score': 0.6128211035594978, 'support': 162627}, '2': {'precision': 0.538107283035325, 'recall': 0.4618402042176025, 'f1-score': 0.49706525723815936, 'support': 133583}, 'accuracy': 0.5482275369417158, 'macro avg': {'precision': 0.5441708008862901, 'recall': 0.5408616412044727, 'f1-score': 0.5407027033817996, 'support': 432844}, 'weighted avg': {'precision': 0.5461447508699389, 'recall': 0.5482275369417158, 'f1-score': 0.5453411214354243, 'support': 432844}}
[[ 69205  37452  29977]
 [ 33250 106398  22979]
 [ 31126  40763  61694]]
Evaluating performance on  val set...
591/591 - 8s - 8s/epoch - 14ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.96754164
{'0': {'precision': 0.49291984100695596, 'recall': 0.4877299356794625, 'f1-score': 0.490311155042112, 'support': 48818}, '1': {'precision': 0.5470853592178476, 'recall': 0.600215683253736, 'f1-score': 0.5724203160726912, 'support': 51928}, '2': {'precision': 0.514620903203297, 'recall': 0.46836548384536003, 'f1-score': 0.49040489573701, 'support': 50388}, 'accuracy': 0.5199227175883653, 'macro avg': {'precision': 0.5182087011427002, 'recall': 0.5187703675928529, 'f1-score': 0.5177121222839377, 'support': 151134}, 'weighted avg': {'precision': 0.5187656477189097, 'recall': 0.5199227175883653, 'f1-score': 0.5185542235781821, 'support': 151134}}
[[23810 12023 12985]
 [11486 31168  9274]
 [13008 13780 23600]]
training model: results/ATVI/W8/deepVOL_L3/h50
Epoch 1/50
1691/1691 - 61s - loss: 3.2616 - accuracy50: 0.3836 - val_loss: 3.2963 - val_accuracy50: 0.3516 - 61s/epoch - 36ms/step
Epoch 2/50
1691/1691 - 57s - loss: 3.1873 - accuracy50: 0.4179 - val_loss: 3.2653 - val_accuracy50: 0.3579 - 57s/epoch - 34ms/step
Epoch 3/50
1691/1691 - 58s - loss: 3.0743 - accuracy50: 0.4602 - val_loss: 3.1146 - val_accuracy50: 0.4554 - 58s/epoch - 34ms/step
Epoch 4/50
1691/1691 - 57s - loss: 3.0032 - accuracy50: 0.4844 - val_loss: 3.0883 - val_accuracy50: 0.4609 - 57s/epoch - 34ms/step
Epoch 5/50
1691/1691 - 58s - loss: 2.9668 - accuracy50: 0.4937 - val_loss: 3.0669 - val_accuracy50: 0.4673 - 58s/epoch - 34ms/step
Epoch 6/50
1691/1691 - 57s - loss: 2.9426 - accuracy50: 0.5010 - val_loss: 3.0641 - val_accuracy50: 0.4702 - 57s/epoch - 34ms/step
Epoch 7/50
1691/1691 - 57s - loss: 2.9264 - accuracy50: 0.5050 - val_loss: 3.0771 - val_accuracy50: 0.4618 - 57s/epoch - 34ms/step
Epoch 8/50
1691/1691 - 57s - loss: 2.9151 - accuracy50: 0.5074 - val_loss: 3.0629 - val_accuracy50: 0.4621 - 57s/epoch - 34ms/step
Epoch 9/50
1691/1691 - 57s - loss: 2.9057 - accuracy50: 0.5102 - val_loss: 3.0537 - val_accuracy50: 0.4657 - 57s/epoch - 34ms/step
Epoch 10/50
1691/1691 - 58s - loss: 2.8981 - accuracy50: 0.5113 - val_loss: 3.0640 - val_accuracy50: 0.4626 - 58s/epoch - 34ms/step
Epoch 11/50
1691/1691 - 57s - loss: 2.8929 - accuracy50: 0.5135 - val_loss: 3.0410 - val_accuracy50: 0.4705 - 57s/epoch - 34ms/step
Epoch 12/50
1691/1691 - 57s - loss: 2.8861 - accuracy50: 0.5152 - val_loss: 3.0475 - val_accuracy50: 0.4642 - 57s/epoch - 34ms/step
Epoch 13/50
1691/1691 - 58s - loss: 2.8798 - accuracy50: 0.5163 - val_loss: 3.0426 - val_accuracy50: 0.4666 - 58s/epoch - 34ms/step
Epoch 14/50
1691/1691 - 58s - loss: 2.8751 - accuracy50: 0.5176 - val_loss: 3.0473 - val_accuracy50: 0.4660 - 58s/epoch - 34ms/step
Epoch 15/50
1691/1691 - 57s - loss: 2.8718 - accuracy50: 0.5184 - val_loss: 3.0388 - val_accuracy50: 0.4681 - 57s/epoch - 34ms/step
Epoch 16/50
1691/1691 - 57s - loss: 2.8672 - accuracy50: 0.5187 - val_loss: 3.0483 - val_accuracy50: 0.4658 - 57s/epoch - 33ms/step
Epoch 17/50
1691/1691 - 57s - loss: 2.8630 - accuracy50: 0.5205 - val_loss: 3.0446 - val_accuracy50: 0.4684 - 57s/epoch - 34ms/step
Epoch 18/50
1691/1691 - 57s - loss: 2.8587 - accuracy50: 0.5216 - val_loss: 3.0533 - val_accuracy50: 0.4668 - 57s/epoch - 34ms/step
Epoch 19/50
1691/1691 - 56s - loss: 2.8560 - accuracy50: 0.5226 - val_loss: 3.0500 - val_accuracy50: 0.4718 - 56s/epoch - 33ms/step
Epoch 20/50
1691/1691 - 57s - loss: 2.8520 - accuracy50: 0.5238 - val_loss: 3.0357 - val_accuracy50: 0.4740 - 57s/epoch - 34ms/step
Epoch 21/50
1691/1691 - 57s - loss: 2.8485 - accuracy50: 0.5250 - val_loss: 3.0402 - val_accuracy50: 0.4731 - 57s/epoch - 34ms/step
Epoch 22/50
1691/1691 - 56s - loss: 2.8463 - accuracy50: 0.5243 - val_loss: 3.0292 - val_accuracy50: 0.4757 - 56s/epoch - 33ms/step
Epoch 23/50
1691/1691 - 56s - loss: 2.8433 - accuracy50: 0.5266 - val_loss: 3.0390 - val_accuracy50: 0.4747 - 56s/epoch - 33ms/step
Epoch 24/50
1691/1691 - 56s - loss: 2.8409 - accuracy50: 0.5268 - val_loss: 3.0303 - val_accuracy50: 0.4775 - 56s/epoch - 33ms/step
Epoch 25/50
1691/1691 - 58s - loss: 2.8383 - accuracy50: 0.5278 - val_loss: 3.0424 - val_accuracy50: 0.4734 - 58s/epoch - 34ms/step
Epoch 26/50
1691/1691 - 57s - loss: 2.8350 - accuracy50: 0.5282 - val_loss: 3.0316 - val_accuracy50: 0.4773 - 57s/epoch - 34ms/step
Epoch 27/50
1691/1691 - 56s - loss: 2.8318 - accuracy50: 0.5296 - val_loss: 3.0291 - val_accuracy50: 0.4779 - 56s/epoch - 33ms/step
Epoch 28/50
1691/1691 - 56s - loss: 2.8302 - accuracy50: 0.5297 - val_loss: 3.0377 - val_accuracy50: 0.4763 - 56s/epoch - 33ms/step
Epoch 29/50
1691/1691 - 57s - loss: 2.8262 - accuracy50: 0.5307 - val_loss: 3.0344 - val_accuracy50: 0.4772 - 57s/epoch - 34ms/step
Epoch 30/50
1691/1691 - 56s - loss: 2.8242 - accuracy50: 0.5312 - val_loss: 3.0398 - val_accuracy50: 0.4780 - 56s/epoch - 33ms/step
Epoch 31/50
1691/1691 - 56s - loss: 2.8222 - accuracy50: 0.5324 - val_loss: 3.0399 - val_accuracy50: 0.4770 - 56s/epoch - 33ms/step
Epoch 32/50
1691/1691 - 56s - loss: 2.8194 - accuracy50: 0.5327 - val_loss: 3.0420 - val_accuracy50: 0.4754 - 56s/epoch - 33ms/step
Epoch 33/50
1691/1691 - 58s - loss: 2.8169 - accuracy50: 0.5339 - val_loss: 3.0402 - val_accuracy50: 0.4776 - 58s/epoch - 34ms/step
Epoch 34/50
1691/1691 - 56s - loss: 2.8147 - accuracy50: 0.5346 - val_loss: 3.0424 - val_accuracy50: 0.4771 - 56s/epoch - 33ms/step
Epoch 35/50
1691/1691 - 56s - loss: 2.8124 - accuracy50: 0.5349 - val_loss: 3.0454 - val_accuracy50: 0.4785 - 56s/epoch - 33ms/step
Epoch 36/50
1691/1691 - 56s - loss: 2.8095 - accuracy50: 0.5353 - val_loss: 3.0516 - val_accuracy50: 0.4764 - 56s/epoch - 33ms/step
Epoch 37/50
1691/1691 - 58s - loss: 2.8065 - accuracy50: 0.5366 - val_loss: 3.0505 - val_accuracy50: 0.4757 - 58s/epoch - 34ms/step
testing model: results/ATVI/W8/deepVOL_L3/h50
Evaluating performance on  test set...
4960/4960 - 67s - 67s/epoch - 14ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.97088903
{'0': {'precision': 0.49654096631682976, 'recall': 0.34366681044714026, 'f1-score': 0.40619631207813267, 'support': 391801}, '1': {'precision': 0.5384213192163783, 'recall': 0.6779420417467299, 'f1-score': 0.6001799465260121, 'support': 486074}, '2': {'precision': 0.48513749883563273, 'recall': 0.4785390691798216, 'f1-score': 0.4818156938175286, 'support': 391805}, 'accuracy': 0.5132576712242455, 'macro avg': {'precision': 0.5066999281229468, 'recall': 0.5000493071245639, 'f1-score': 0.4960639841405578, 'support': 1269680}, 'weighted avg': {'precision': 0.5090551549933662, 'recall': 0.5132576712242455, 'f1-score': 0.5037944887785789, 'support': 1269680}}
[[134649 140893 116259]
 [ 73821 329530  82723]
 [ 62704 141607 187494]]
Evaluating performance on  train set...
1691/1691 - 28s - 28s/epoch - 16ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.97839135
{'0': {'precision': 0.518472721822542, 'recall': 0.3780291232959047, 'f1-score': 0.43725016195035626, 'support': 146412}, '1': {'precision': 0.4922189804984724, 'recall': 0.6477663110510289, 'f1-score': 0.5593806790145744, 'support': 143507}, '2': {'precision': 0.5019856450613911, 'recall': 0.4820010495014868, 'f1-score': 0.4917904054825814, 'support': 142925}, 'accuracy': 0.5017904834074169, 'macro avg': {'precision': 0.5042257824608019, 'recall': 0.5025988279494734, 'f1-score': 0.49614041548250404, 'support': 432844}, 'weighted avg': {'precision': 0.5043244118025791, 'recall': 0.5017904834074169, 'f1-score': 0.4957510269714217, 'support': 432844}}
[[55348 47792 43272]
 [25475 92959 25073]
 [25929 48106 68890]]
Evaluating performance on  val set...
591/591 - 10s - 10s/epoch - 17ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0101919
{'0': {'precision': 0.501689379434621, 'recall': 0.3387710092022207, 'f1-score': 0.40443980388596334, 'support': 52596}, '1': {'precision': 0.456425077812361, 'recall': 0.5942377485360586, 'f1-score': 0.5162931509764284, 'support': 44913}, '2': {'precision': 0.48531779364412714, 'recall': 0.5171655011655012, 'f1-score': 0.5007357654217336, 'support': 53625}, 'accuracy': 0.4779864226448053, 'macro avg': {'precision': 0.4811440836303697, 'recall': 0.4833914196345935, 'f1-score': 0.47382290676137506, 'support': 151134}, 'weighted avg': {'precision': 0.4824291079750169, 'recall': 0.4779864226448053, 'f1-score': 0.47184713986085797, 'support': 151134}}
[[17818 15349 19429]
 [ 8242 26689  9982]
 [ 9456 16436 27733]]
training model: results/ATVI/W8/deepVOL_L3/h100
Epoch 1/50
1691/1691 - 61s - loss: 3.2851 - accuracy100: 0.3727 - val_loss: 3.3477 - val_accuracy100: 0.2862 - 61s/epoch - 36ms/step
Epoch 2/50
1691/1691 - 57s - loss: 3.2831 - accuracy100: 0.3628 - val_loss: 3.3183 - val_accuracy100: 0.3185 - 57s/epoch - 33ms/step
Epoch 3/50
1691/1691 - 57s - loss: 3.2467 - accuracy100: 0.3915 - val_loss: 3.3351 - val_accuracy100: 0.3282 - 57s/epoch - 34ms/step
Epoch 4/50
1691/1691 - 58s - loss: 3.2198 - accuracy100: 0.4077 - val_loss: 3.3025 - val_accuracy100: 0.3395 - 58s/epoch - 34ms/step
Epoch 5/50
1691/1691 - 57s - loss: 3.1922 - accuracy100: 0.4209 - val_loss: 3.3222 - val_accuracy100: 0.3175 - 57s/epoch - 34ms/step
Epoch 6/50
1691/1691 - 56s - loss: 3.1784 - accuracy100: 0.4259 - val_loss: 3.3432 - val_accuracy100: 0.3169 - 56s/epoch - 33ms/step
Epoch 7/50
1691/1691 - 56s - loss: 3.1673 - accuracy100: 0.4304 - val_loss: 3.3250 - val_accuracy100: 0.3219 - 56s/epoch - 33ms/step
Epoch 8/50
1691/1691 - 56s - loss: 3.1589 - accuracy100: 0.4334 - val_loss: 3.3322 - val_accuracy100: 0.3319 - 56s/epoch - 33ms/step
Epoch 9/50
1691/1691 - 57s - loss: 3.1516 - accuracy100: 0.4361 - val_loss: 3.3571 - val_accuracy100: 0.3425 - 57s/epoch - 34ms/step
Epoch 10/50
1691/1691 - 56s - loss: 3.1465 - accuracy100: 0.4373 - val_loss: 3.3654 - val_accuracy100: 0.3482 - 56s/epoch - 33ms/step
Epoch 11/50
1691/1691 - 61s - loss: 3.1417 - accuracy100: 0.4397 - val_loss: 3.3373 - val_accuracy100: 0.3636 - 61s/epoch - 36ms/step
Epoch 12/50
1691/1691 - 57s - loss: 3.1381 - accuracy100: 0.4413 - val_loss: 3.3308 - val_accuracy100: 0.3691 - 57s/epoch - 34ms/step
Epoch 13/50
1691/1691 - 58s - loss: 3.1346 - accuracy100: 0.4422 - val_loss: 3.3333 - val_accuracy100: 0.3664 - 58s/epoch - 34ms/step
Epoch 14/50
1691/1691 - 57s - loss: 3.1316 - accuracy100: 0.4443 - val_loss: 3.3398 - val_accuracy100: 0.3758 - 57s/epoch - 34ms/step
testing model: results/ATVI/W8/deepVOL_L3/h100
Evaluating performance on  test set...
4960/4960 - 68s - 68s/epoch - 14ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0865779
{'0': {'precision': 0.4283833901048569, 'recall': 0.11245931647000042, 'f1-score': 0.17815051456786468, 'support': 428306}, '1': {'precision': 0.3443419644990081, 'recall': 0.803956136692113, 'f1-score': 0.4821671919381135, 'support': 412372}, '2': {'precision': 0.43129631629562204, 'recall': 0.19549093011221394, 'f1-score': 0.2690371206811099, 'support': 429002}, 'accuracy': 0.3651014428832462, 'macro avg': {'precision': 0.4013405569664957, 'recall': 0.3706354610914424, 'f1-score': 0.30978494239569604, 'support': 1269680}, 'weighted avg': {'precision': 0.4020722884113243, 'recall': 0.3651014428832462, 'f1-score': 0.3075992741579336, 'support': 1269680}}
[[ 48167 324964  55175]
 [ 25433 331529  55410]
 [ 38839 306297  83866]]
Evaluating performance on  train set...
1691/1691 - 24s - 24s/epoch - 14ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0872182
{'0': {'precision': 0.41982711237695497, 'recall': 0.11403365906623236, 'f1-score': 0.17935171250787146, 'support': 147360}, '1': {'precision': 0.3479063872165135, 'recall': 0.80390502423207, 'f1-score': 0.48564146850053713, 'support': 143405}, '2': {'precision': 0.4237547393943339, 'recall': 0.18328535533048515, 'f1-score': 0.255890965548415, 'support': 142079}, 'accuracy': 0.3653256138470211, 'macro avg': {'precision': 0.39716274632926746, 'recall': 0.36707467954292916, 'f1-score': 0.30696138218560787, 'support': 432844}, 'weighted avg': {'precision': 0.3972883726170624, 'recall': 0.3653256138470211, 'f1-score': 0.30595183400863296, 'support': 432844}}
[[ 16804 112885  17671]
 [ 10380 115284  17741]
 [ 12842 103196  26041]]
Evaluating performance on  val set...
591/591 - 8s - 8s/epoch - 14ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.1008416
{'0': {'precision': 0.41404036315272075, 'recall': 0.13400460406879902, 'f1-score': 0.2024772354504836, 'support': 53431}, '1': {'precision': 0.30407633545478896, 'recall': 0.7617141402688756, 'f1-score': 0.43464311178008386, 'support': 43217}, '2': {'precision': 0.43530607458369164, 'recall': 0.20438277722717763, 'f1-score': 0.2781635609731728, 'support': 54486}, 'accuracy': 0.33887146505749866, 'macro avg': {'precision': 0.3844742577304004, 'recall': 0.36670050718828406, 'f1-score': 0.3050946360679134, 'support': 151134}, 'weighted avg': {'precision': 0.39026257766438827, 'recall': 0.33887146505749866, 'f1-score': 0.29615144383354486, 'support': 151134}}
[[ 7160 38055  8216]
 [ 4068 32919  6230]
 [ 6065 37285 11136]]
training model: results/ATVI/W8/deepVOL_L3/h200
Epoch 1/50
1691/1691 - 60s - loss: 3.3006 - accuracy200: 0.3593 - val_loss: 3.2995 - val_accuracy200: 0.3369 - 60s/epoch - 36ms/step
Epoch 2/50
1691/1691 - 58s - loss: 3.2895 - accuracy200: 0.3555 - val_loss: 3.2961 - val_accuracy200: 0.3424 - 58s/epoch - 34ms/step
Epoch 3/50
1691/1691 - 60s - loss: 3.2785 - accuracy200: 0.3681 - val_loss: 3.2857 - val_accuracy200: 0.3641 - 60s/epoch - 36ms/step
Epoch 4/50
1691/1691 - 60s - loss: 3.2636 - accuracy200: 0.3812 - val_loss: 3.2770 - val_accuracy200: 0.3735 - 60s/epoch - 36ms/step
Epoch 5/50
1691/1691 - 58s - loss: 3.2508 - accuracy200: 0.3891 - val_loss: 3.2693 - val_accuracy200: 0.3783 - 58s/epoch - 34ms/step
Epoch 6/50
1691/1691 - 57s - loss: 3.2401 - accuracy200: 0.3952 - val_loss: 3.2772 - val_accuracy200: 0.3689 - 57s/epoch - 34ms/step
Epoch 7/50
1691/1691 - 57s - loss: 3.2349 - accuracy200: 0.3986 - val_loss: 3.2758 - val_accuracy200: 0.3699 - 57s/epoch - 34ms/step
Epoch 8/50
1691/1691 - 57s - loss: 3.2283 - accuracy200: 0.4037 - val_loss: 3.2900 - val_accuracy200: 0.3613 - 57s/epoch - 34ms/step
Epoch 9/50
1691/1691 - 57s - loss: 3.2223 - accuracy200: 0.4067 - val_loss: 3.2857 - val_accuracy200: 0.3743 - 57s/epoch - 33ms/step
Epoch 10/50
1691/1691 - 57s - loss: 3.2171 - accuracy200: 0.4099 - val_loss: 3.2965 - val_accuracy200: 0.3711 - 57s/epoch - 34ms/step
Epoch 11/50
1691/1691 - 56s - loss: 3.2109 - accuracy200: 0.4138 - val_loss: 3.2920 - val_accuracy200: 0.3743 - 56s/epoch - 33ms/step
Epoch 12/50
1691/1691 - 58s - loss: 3.2068 - accuracy200: 0.4153 - val_loss: 3.3323 - val_accuracy200: 0.3476 - 58s/epoch - 34ms/step
Epoch 13/50
1691/1691 - 58s - loss: 3.2014 - accuracy200: 0.4183 - val_loss: 3.3297 - val_accuracy200: 0.3516 - 58s/epoch - 34ms/step
Epoch 14/50
1691/1691 - 56s - loss: 3.1968 - accuracy200: 0.4211 - val_loss: 3.3260 - val_accuracy200: 0.3623 - 56s/epoch - 33ms/step
Epoch 15/50
1691/1691 - 56s - loss: 3.1916 - accuracy200: 0.4238 - val_loss: 3.3800 - val_accuracy200: 0.3502 - 56s/epoch - 33ms/step
testing model: results/ATVI/W8/deepVOL_L3/h200
Evaluating performance on  test set...
4960/4960 - 69s - 69s/epoch - 14ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0875534
{'0': {'precision': 0.3720585891510331, 'recall': 0.17480573249176914, 'f1-score': 0.23785780725655628, 'support': 413991}, '1': {'precision': 0.404649659494633, 'recall': 0.3673640148180751, 'f1-score': 0.3851064520043785, 'support': 436224}, '2': {'precision': 0.36602841223658017, 'recall': 0.5926263216239734, 'f1-score': 0.45254681146795633, 'support': 419465}, 'accuracy': 0.37899864532795663, 'macro avg': {'precision': 0.38091222029408206, 'recall': 0.37826535631127256, 'f1-score': 0.3585036902429637, 'support': 1269680}, 'weighted avg': {'precision': 0.38126371084322763, 'recall': 0.37899864532795663, 'f1-score': 0.3593749737536334, 'support': 1269680}}
[[ 72368 123882 217741]
 [ 63154 160253 212817]
 [ 58985 111894 248586]]
Evaluating performance on  train set...
1691/1691 - 23s - 23s/epoch - 14ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0883551
{'0': {'precision': 0.3876388949568206, 'recall': 0.17991942897312496, 'f1-score': 0.24576775879341306, 'support': 147944}, '1': {'precision': 0.3924405297469653, 'recall': 0.34889171116428214, 'f1-score': 0.3693870046319167, 'support': 142517}, '2': {'precision': 0.36593325613222444, 'recall': 0.6103256709017228, 'f1-score': 0.45753939630072293, 'support': 142383}, 'accuracy': 0.37713587343246063, 'macro avg': {'precision': 0.38200422694533676, 'recall': 0.37971227034637667, 'f1-score': 0.3575647199086842, 'support': 432844}, 'weighted avg': {'precision': 0.38207984969484304, 'recall': 0.37713587343246063, 'f1-score': 0.3561320589162502, 'support': 432844}}
[[26618 41337 79989]
 [22208 49723 70586]
 [19841 35642 86900]]
Evaluating performance on  val set...
591/591 - 8s - 8s/epoch - 13ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.090311
{'0': {'precision': 0.37714859269792145, 'recall': 0.1707760481763436, 'f1-score': 0.23509782707874397, 'support': 52806}, '1': {'precision': 0.37139419549843, 'recall': 0.28032249490564365, 'f1-score': 0.31949510886715055, 'support': 45148}, '2': {'precision': 0.37945805509630043, 'recall': 0.6646295599849568, 'f1-score': 0.4830993808345749, 'support': 53180}, 'accuracy': 0.37727447166091016, 'macro avg': {'precision': 0.3760002810975506, 'recall': 0.37190936768898136, 'f1-score': 0.3458974389268232, 'support': 151134}, 'weighted avg': {'precision': 0.3762422293751956, 'recall': 0.37727447166091016, 'f1-score': 0.347574775395589, 'support': 151134}}
[[ 9018 11121 32667]
 [ 7358 12656 25134]
 [ 7535 10300 35345]]
training model: results/ATVI/W8/deepVOL_L3/h300
Epoch 1/50
1691/1691 - 60s - loss: 3.2912 - accuracy300: 0.3720 - val_loss: 3.7574 - val_accuracy300: 0.2760 - 60s/epoch - 36ms/step
Epoch 2/50
1691/1691 - 56s - loss: 3.2899 - accuracy300: 0.3577 - val_loss: 3.6443 - val_accuracy300: 0.2762 - 56s/epoch - 33ms/step
Epoch 3/50
1691/1691 - 56s - loss: 3.2816 - accuracy300: 0.3661 - val_loss: 3.8390 - val_accuracy300: 0.2762 - 56s/epoch - 33ms/step
Epoch 4/50
1691/1691 - 56s - loss: 3.2732 - accuracy300: 0.3784 - val_loss: 3.7584 - val_accuracy300: 0.2763 - 56s/epoch - 33ms/step
Epoch 5/50
1691/1691 - 58s - loss: 3.2600 - accuracy300: 0.3888 - val_loss: 3.8689 - val_accuracy300: 0.2770 - 58s/epoch - 35ms/step
Epoch 6/50
1691/1691 - 57s - loss: 3.2515 - accuracy300: 0.3949 - val_loss: 3.9822 - val_accuracy300: 0.2761 - 57s/epoch - 34ms/step
Epoch 7/50
1691/1691 - 56s - loss: 3.2426 - accuracy300: 0.3993 - val_loss: 4.0556 - val_accuracy300: 0.2762 - 56s/epoch - 33ms/step
Epoch 8/50
1691/1691 - 56s - loss: 3.2360 - accuracy300: 0.4036 - val_loss: 4.1495 - val_accuracy300: 0.2764 - 56s/epoch - 33ms/step
Epoch 9/50
1691/1691 - 58s - loss: 3.2308 - accuracy300: 0.4056 - val_loss: 4.1346 - val_accuracy300: 0.2772 - 58s/epoch - 34ms/step
Epoch 10/50
1691/1691 - 57s - loss: 3.2267 - accuracy300: 0.4067 - val_loss: 4.2211 - val_accuracy300: 0.2768 - 57s/epoch - 34ms/step
Epoch 11/50
1691/1691 - 57s - loss: 3.2236 - accuracy300: 0.4089 - val_loss: 4.3304 - val_accuracy300: 0.2766 - 57s/epoch - 34ms/step
Epoch 12/50
1691/1691 - 57s - loss: 3.2183 - accuracy300: 0.4119 - val_loss: 4.3366 - val_accuracy300: 0.2770 - 57s/epoch - 34ms/step
testing model: results/ATVI/W8/deepVOL_L3/h300
Evaluating performance on  test set...
4960/4960 - 70s - 70s/epoch - 14ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.2033675
{'0': {'precision': 0.39592239394935874, 'recall': 0.00276777791570691, 'f1-score': 0.0054971270206165095, 'support': 435006}, '1': {'precision': 0.30972494824719443, 'recall': 0.9976349538561696, 'f1-score': 0.4726968204479388, 'support': 393227}, '2': {'precision': 0.4146341463414634, 'recall': 3.850971917353612e-05, 'f1-score': 7.70122857246403e-05, 'support': 441447}, 'accuracy': 0.3099347867179132, 'macro avg': {'precision': 0.3734271628460055, 'recall': 0.33348041383035, 'f1-score': 0.15942365325142666, 'support': 1269680}, 'weighted avg': {'precision': 0.3757323334436506, 'recall': 0.3099347867179132, 'f1-score': 0.1483070007352311, 'support': 1269680}}
[[  1204 433788     14]
 [   920 392297     10]
 [   917 440513     17]]
Evaluating performance on  train set...
1691/1691 - 25s - 25s/epoch - 15ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1992984
{'0': {'precision': 0.3738140417457306, 'recall': 0.0026023949960039365, 'f1-score': 0.005168806123854564, 'support': 151399}, '1': {'precision': 0.3154875362748481, 'recall': 0.9978317401018203, 'f1-score': 0.47940128948702065, 'support': 136515}, '2': {'precision': 0.23529411764705882, 'recall': 2.7599530807976266e-05, 'f1-score': 5.519258763548056e-05, 'support': 144930}, 'accuracy': 0.31562641505946715, 'macro avg': {'precision': 0.30819856522254585, 'recall': 0.33348724487621073, 'f1-score': 0.1615417627328369, 'support': 432844}, 'weighted avg': {'precision': 0.3090375044852441, 'recall': 0.31562641505946715, 'f1-score': 0.15302515034144423, 'support': 432844}}
[[   394 150997      8]
 [   291 136219      5]
 [   369 144557      4]]
Evaluating performance on  val set...
591/591 - 8s - 8s/epoch - 14ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.2334231
{'0': {'precision': 0.3667711598746082, 'recall': 0.0021521595173276432, 'f1-score': 0.0042792092606477325, 'support': 54364}, '1': {'precision': 0.27601251889770045, 'recall': 0.9978664748891286, 'f1-score': 0.43241727134375957, 'support': 41715}, '2': {'precision': 0.3333333333333333, 'recall': 1.8163654527290892e-05, 'f1-score': 3.63253296523666e-05, 'support': 55055}, 'accuracy': 0.2762052218561012, 'macro avg': {'precision': 0.3253723373685473, 'recall': 0.3333455993536612, 'f1-score': 0.1455776019780199, 'support': 151134}, 'weighted avg': {'precision': 0.32953985355980414, 'recall': 0.2762052218561012, 'f1-score': 0.12090543026304335, 'support': 151134}}
[[  117 54245     2]
 [   89 41626     0]
 [  113 54941     1]]
training model: results/ATVI/W8/deepVOL_L3/h500
Epoch 1/50
1691/1691 - 61s - loss: 3.2706 - accuracy500: 0.3925 - val_loss: 3.3673 - val_accuracy500: 0.2802 - 61s/epoch - 36ms/step
Epoch 2/50
1691/1691 - 59s - loss: 3.2774 - accuracy500: 0.3781 - val_loss: 3.3629 - val_accuracy500: 0.2802 - 59s/epoch - 35ms/step
Epoch 3/50
1691/1691 - 57s - loss: 3.2780 - accuracy500: 0.3769 - val_loss: 3.3378 - val_accuracy500: 0.2802 - 57s/epoch - 34ms/step
Epoch 4/50
1691/1691 - 57s - loss: 3.2684 - accuracy500: 0.3811 - val_loss: 3.3230 - val_accuracy500: 0.2838 - 57s/epoch - 34ms/step
Epoch 5/50
1691/1691 - 56s - loss: 3.2866 - accuracy500: 0.3643 - val_loss: 3.3487 - val_accuracy500: 0.2851 - 56s/epoch - 33ms/step
Epoch 6/50
1691/1691 - 58s - loss: 3.2897 - accuracy500: 0.3589 - val_loss: 3.3154 - val_accuracy500: 0.2822 - 58s/epoch - 34ms/step
Epoch 7/50
1691/1691 - 57s - loss: 3.2863 - accuracy500: 0.3655 - val_loss: 3.3140 - val_accuracy500: 0.2828 - 57s/epoch - 33ms/step
Epoch 8/50
1691/1691 - 57s - loss: 3.2576 - accuracy500: 0.3827 - val_loss: 3.3473 - val_accuracy500: 0.3135 - 57s/epoch - 34ms/step
Epoch 9/50
1691/1691 - 58s - loss: 3.2601 - accuracy500: 0.3862 - val_loss: 3.3304 - val_accuracy500: 0.3059 - 58s/epoch - 34ms/step
Epoch 10/50
1691/1691 - 58s - loss: 3.2429 - accuracy500: 0.3935 - val_loss: 3.3608 - val_accuracy500: 0.2806 - 58s/epoch - 34ms/step
Epoch 11/50
1691/1691 - 57s - loss: 3.2443 - accuracy500: 0.3903 - val_loss: 3.3358 - val_accuracy500: 0.2896 - 57s/epoch - 34ms/step
Epoch 12/50
1691/1691 - 58s - loss: 3.2420 - accuracy500: 0.3907 - val_loss: 3.3329 - val_accuracy500: 0.2821 - 58s/epoch - 35ms/step
Epoch 13/50
1691/1691 - 57s - loss: 3.2373 - accuracy500: 0.3942 - val_loss: 3.3504 - val_accuracy500: 0.2842 - 57s/epoch - 34ms/step
Epoch 14/50
1691/1691 - 58s - loss: 3.2405 - accuracy500: 0.3931 - val_loss: 3.3390 - val_accuracy500: 0.2955 - 58s/epoch - 34ms/step
Epoch 15/50
1691/1691 - 58s - loss: 3.2361 - accuracy500: 0.3941 - val_loss: 3.3466 - val_accuracy500: 0.2872 - 58s/epoch - 34ms/step
Epoch 16/50
1691/1691 - 58s - loss: 3.2325 - accuracy500: 0.3960 - val_loss: 3.3274 - val_accuracy500: 0.3238 - 58s/epoch - 34ms/step
Epoch 17/50
1691/1691 - 57s - loss: 3.2270 - accuracy500: 0.4005 - val_loss: 3.3457 - val_accuracy500: 0.3134 - 57s/epoch - 34ms/step
testing model: results/ATVI/W8/deepVOL_L3/h500
Evaluating performance on  test set...
4960/4960 - 71s - 71s/epoch - 14ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1103965
{'0': {'precision': 0.40314240254574385, 'recall': 0.0043097033172171265, 'f1-score': 0.008528237427476323, 'support': 470334}, '1': {'precision': 0.24992181099405764, 'recall': 0.9801385477396917, 'f1-score': 0.3982861477275057, 'support': 317147}, '2': {'precision': 0.37214316515739543, 'recall': 0.016107457709368955, 'f1-score': 0.03087840658357684, 'support': 482199}, 'accuracy': 0.2525376472812047, 'macro avg': {'precision': 0.34173579289906564, 'recall': 0.33351856958875925, 'f1-score': 0.14589759724618628, 'support': 1269680}, 'weighted avg': {'precision': 0.3530973106971939, 'recall': 0.2525376472812047, 'f1-score': 0.11437205728352345, 'support': 1269680}}
[[  2027 460295   8012]
 [  1207 310848   5092]
 [  1794 472638   7767]]
Evaluating performance on  train set...
1691/1691 - 24s - 24s/epoch - 14ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1015213
{'0': {'precision': 0.3572593800978793, 'recall': 0.004441499969578768, 'f1-score': 0.008773921288444333, 'support': 147923}, '1': {'precision': 0.32765086619420425, 'recall': 0.978600416416699, 'f1-score': 0.49093046393960965, 'support': 141685}, '2': {'precision': 0.32660878447395303, 'recall': 0.01785863888966461, 'f1-score': 0.03386554399343342, 'support': 143236}, 'accuracy': 0.32775780650765635, 'macro avg': {'precision': 0.3371730102553456, 'recall': 0.33363351842531414, 'f1-score': 0.17785664307382912, 'support': 432844}, 'weighted avg': {'precision': 0.33742463361362424, 'recall': 0.32775780650765635, 'f1-score': 0.17490392058450058, 'support': 432844}}
[[   657 144469   2797]
 [   555 138653   2477]
 [   627 140051   2558]]
Evaluating performance on  val set...
591/591 - 8s - 8s/epoch - 14ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1069416
{'0': {'precision': 0.35596026490066224, 'recall': 0.003955332339901025, 'f1-score': 0.00782372955368352, 'support': 54357}, '1': {'precision': 0.28039190495831445, 'recall': 0.9794742187684531, 'f1-score': 0.435977500919939, 'support': 42337}, '2': {'precision': 0.36594615092908606, 'recall': 0.01772593681116826, 'f1-score': 0.03381397060111779, 'support': 54440}, 'accuracy': 0.282186668783993, 'macro avg': {'precision': 0.33409944026268756, 'recall': 0.3337184959731741, 'f1-score': 0.15920506702491344, 'support': 151134}, 'weighted avg': {'precision': 0.33838840139217446, 'recall': 0.282186668783993, 'f1-score': 0.13712391972237808, 'support': 151134}}
[[  215 53162   980]
 [  177 41468   692]
 [  212 53263   965]]
training model: results/ATVI/W8/deepVOL_L3/h1000
Epoch 1/50
1691/1691 - 61s - loss: 3.2850 - accuracy1000: 0.3818 - val_loss: 3.2937 - val_accuracy1000: 0.3516 - 61s/epoch - 36ms/step
Epoch 2/50
1691/1691 - 59s - loss: 3.2904 - accuracy1000: 0.3578 - val_loss: 3.2920 - val_accuracy1000: 0.3517 - 59s/epoch - 35ms/step
Epoch 3/50
1691/1691 - 57s - loss: 3.2860 - accuracy1000: 0.3606 - val_loss: 3.2835 - val_accuracy1000: 0.3500 - 57s/epoch - 34ms/step
Epoch 4/50
1691/1691 - 56s - loss: 3.2772 - accuracy1000: 0.3707 - val_loss: 3.2710 - val_accuracy1000: 0.3774 - 56s/epoch - 33ms/step
Epoch 5/50
1691/1691 - 57s - loss: 3.2707 - accuracy1000: 0.3752 - val_loss: 3.2716 - val_accuracy1000: 0.3741 - 57s/epoch - 33ms/step
Epoch 6/50
1691/1691 - 58s - loss: 3.2594 - accuracy1000: 0.3850 - val_loss: 3.2643 - val_accuracy1000: 0.3770 - 58s/epoch - 34ms/step
Epoch 7/50
1691/1691 - 57s - loss: 3.2511 - accuracy1000: 0.3901 - val_loss: 3.2574 - val_accuracy1000: 0.3772 - 57s/epoch - 34ms/step
Epoch 8/50
1691/1691 - 56s - loss: 3.2411 - accuracy1000: 0.3968 - val_loss: 3.2460 - val_accuracy1000: 0.3866 - 56s/epoch - 33ms/step
Epoch 9/50
1691/1691 - 56s - loss: 3.2340 - accuracy1000: 0.4022 - val_loss: 3.2517 - val_accuracy1000: 0.3859 - 56s/epoch - 33ms/step
Epoch 10/50
1691/1691 - 57s - loss: 3.2280 - accuracy1000: 0.4033 - val_loss: 3.2835 - val_accuracy1000: 0.3355 - 57s/epoch - 34ms/step
Epoch 11/50
1691/1691 - 57s - loss: 3.2240 - accuracy1000: 0.4022 - val_loss: 3.2446 - val_accuracy1000: 0.3887 - 57s/epoch - 34ms/step
Epoch 12/50
1691/1691 - 56s - loss: 3.2190 - accuracy1000: 0.4044 - val_loss: 3.2593 - val_accuracy1000: 0.3824 - 56s/epoch - 33ms/step
Epoch 13/50
1691/1691 - 58s - loss: 3.2143 - accuracy1000: 0.4045 - val_loss: 3.2469 - val_accuracy1000: 0.3907 - 58s/epoch - 34ms/step
Epoch 14/50
1691/1691 - 58s - loss: 3.2083 - accuracy1000: 0.4083 - val_loss: 3.2472 - val_accuracy1000: 0.3915 - 58s/epoch - 34ms/step
Epoch 15/50
1691/1691 - 57s - loss: 3.2031 - accuracy1000: 0.4114 - val_loss: 3.2467 - val_accuracy1000: 0.3897 - 57s/epoch - 34ms/step
Epoch 16/50
1691/1691 - 57s - loss: 3.2013 - accuracy1000: 0.4137 - val_loss: 3.2569 - val_accuracy1000: 0.3756 - 57s/epoch - 34ms/step
Epoch 17/50
1691/1691 - 56s - loss: 3.1963 - accuracy1000: 0.4165 - val_loss: 3.2674 - val_accuracy1000: 0.3659 - 56s/epoch - 33ms/step
Epoch 18/50
1691/1691 - 57s - loss: 3.1932 - accuracy1000: 0.4191 - val_loss: 3.2617 - val_accuracy1000: 0.3776 - 57s/epoch - 34ms/step
Epoch 19/50
1691/1691 - 57s - loss: 3.1924 - accuracy1000: 0.4208 - val_loss: 3.2561 - val_accuracy1000: 0.3843 - 57s/epoch - 34ms/step
Epoch 20/50
1691/1691 - 56s - loss: 3.1896 - accuracy1000: 0.4218 - val_loss: 3.2610 - val_accuracy1000: 0.3805 - 56s/epoch - 33ms/step
Epoch 21/50
1691/1691 - 57s - loss: 3.1858 - accuracy1000: 0.4251 - val_loss: 3.2500 - val_accuracy1000: 0.3878 - 57s/epoch - 33ms/step
testing model: results/ATVI/W8/deepVOL_L3/h1000
Evaluating performance on  test set...
4960/4960 - 70s - 70s/epoch - 14ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0838358
{'0': {'precision': 0.32653061224489793, 'recall': 3.921232247233693e-05, 'f1-score': 7.84152282373237e-05, 'support': 408035}, '1': {'precision': 0.4160987456048228, 'recall': 0.644485593556606, 'f1-score': 0.5057016912984343, 'support': 430953}, '2': {'precision': 0.3730805894994171, 'recall': 0.5215931570588727, 'f1-score': 0.4350106019383635, 'support': 430692}, 'accuracy': 0.3956941906622141, 'macro avg': {'precision': 0.371903315783046, 'recall': 0.3887059876459837, 'f1-score': 0.3135969028216784, 'support': 1269680}, 'weighted avg': {'precision': 0.3727220609402881, 'recall': 0.3956941906622141, 'f1-score': 0.31923102143676013, 'support': 1269680}}
[[    16 183725 224294]
 [    12 277743 153198]
 [    21 206025 224646]]
Evaluating performance on  train set...
1691/1691 - 29s - 29s/epoch - 17ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0852741
{'0': {'precision': 0.4, 'recall': 4.019077219870318e-05, 'f1-score': 8.037346871797621e-05, 'support': 149288}, '1': {'precision': 0.40620564923121066, 'recall': 0.5709779406998768, 'f1-score': 0.4746998772565339, 'support': 138853}, '2': {'precision': 0.3675584468045714, 'recall': 0.6036571460163231, 'f1-score': 0.4569104627898158, 'support': 144703}, 'accuracy': 0.3849862768110451, 'macro avg': {'precision': 0.391254698678594, 'recall': 0.3915584258294662, 'f1-score': 0.3105635711716892, 'support': 432844}, 'weighted avg': {'precision': 0.3911452692902367, 'recall': 0.3849862768110451, 'f1-score': 0.30505636106351064, 'support': 432844}}
[[    6 58548 90734]
 [    4 79282 59567]
 [    5 57347 87351]]
Evaluating performance on  val set...
591/591 - 10s - 10s/epoch - 17ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0832165
{'0': {'precision': 0.4, 'recall': 3.794058504382138e-05, 'f1-score': 7.587397333029838e-05, 'support': 52714}, '1': {'precision': 0.41469694329906887, 'recall': 0.4732261199964655, 'f1-score': 0.4420324993551715, 'support': 45268}, '2': {'precision': 0.3750100530802638, 'recall': 0.7018174292594822, 'f1-score': 0.48882220358528145, 'support': 53152}, 'accuracy': 0.3885757010335199, 'macro avg': {'precision': 0.3965689987931109, 'recall': 0.3916938299469972, 'f1-score': 0.3103101923045944, 'support': 151134}, 'weighted avg': {'precision': 0.39561339983448085, 'recall': 0.3885757010335199, 'f1-score': 0.3043379025659674, 'support': 151134}}
[[    2 14389 38323]
 [    0 21422 23846]
 [    3 15846 37303]]

============================================

        Job resource usage summary 

                 Memory (GB)    NCPUs
 Requested  :        96            32
 Used       :        25 (peak)  16.08 (ave)

============================================
