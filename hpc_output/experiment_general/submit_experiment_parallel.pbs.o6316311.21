This machine has 1 visible gpus.
This machine has 1 physical gpus.
getting alphas...
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-04-17.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-04-09.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-03-27.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-03-28.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-04-05.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-04-01.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-04-03.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-03-29.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-04-02.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-04-15.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-04-04.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-03-26.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-04-11.csv
data/QRTEA_orderbooks/QRTEA_orderbooks_2019-04-10.csv
training model: results/QRTEA/W2/deepLOB_L1/h10
Epoch 1/50
528/528 - 38s - loss: 3.0106 - accuracy10: 0.4229 - val_loss: 3.3606 - val_accuracy10: 0.4104 - 38s/epoch - 72ms/step
Epoch 2/50
528/528 - 8s - loss: 2.9031 - accuracy10: 0.4455 - val_loss: 3.2301 - val_accuracy10: 0.3381 - 8s/epoch - 15ms/step
Epoch 3/50
528/528 - 8s - loss: 2.8478 - accuracy10: 0.4656 - val_loss: 3.3480 - val_accuracy10: 0.3237 - 8s/epoch - 15ms/step
Epoch 4/50
528/528 - 8s - loss: 2.8049 - accuracy10: 0.4861 - val_loss: 3.1841 - val_accuracy10: 0.3921 - 8s/epoch - 15ms/step
Epoch 5/50
528/528 - 8s - loss: 2.7592 - accuracy10: 0.5028 - val_loss: 3.1858 - val_accuracy10: 0.3791 - 8s/epoch - 15ms/step
Epoch 6/50
528/528 - 8s - loss: 2.7140 - accuracy10: 0.5233 - val_loss: 3.2131 - val_accuracy10: 0.4258 - 8s/epoch - 15ms/step
Epoch 7/50
528/528 - 8s - loss: 2.6856 - accuracy10: 0.5321 - val_loss: 3.1800 - val_accuracy10: 0.4325 - 8s/epoch - 15ms/step
Epoch 8/50
528/528 - 8s - loss: 2.6487 - accuracy10: 0.5531 - val_loss: 3.1980 - val_accuracy10: 0.4670 - 8s/epoch - 15ms/step
Epoch 9/50
528/528 - 8s - loss: 2.6255 - accuracy10: 0.5620 - val_loss: 3.2171 - val_accuracy10: 0.4991 - 8s/epoch - 15ms/step
Epoch 10/50
528/528 - 8s - loss: 2.5967 - accuracy10: 0.5723 - val_loss: 3.2182 - val_accuracy10: 0.5147 - 8s/epoch - 15ms/step
Epoch 11/50
528/528 - 8s - loss: 2.5715 - accuracy10: 0.5800 - val_loss: 3.2451 - val_accuracy10: 0.4156 - 8s/epoch - 15ms/step
Epoch 12/50
528/528 - 8s - loss: 2.5483 - accuracy10: 0.5893 - val_loss: 3.3285 - val_accuracy10: 0.3956 - 8s/epoch - 15ms/step
Epoch 13/50
528/528 - 8s - loss: 2.5254 - accuracy10: 0.5979 - val_loss: 3.2901 - val_accuracy10: 0.4174 - 8s/epoch - 15ms/step
Epoch 14/50
528/528 - 8s - loss: 2.5054 - accuracy10: 0.6017 - val_loss: 3.2696 - val_accuracy10: 0.5040 - 8s/epoch - 15ms/step
Epoch 15/50
528/528 - 8s - loss: 2.4881 - accuracy10: 0.6076 - val_loss: 3.2514 - val_accuracy10: 0.4683 - 8s/epoch - 15ms/step
Epoch 16/50
528/528 - 8s - loss: 2.4678 - accuracy10: 0.6130 - val_loss: 3.3639 - val_accuracy10: 0.5204 - 8s/epoch - 15ms/step
Epoch 17/50
528/528 - 8s - loss: 2.4608 - accuracy10: 0.6131 - val_loss: 3.2351 - val_accuracy10: 0.4639 - 8s/epoch - 15ms/step
testing model: results/QRTEA/W2/deepLOB_L1/h10
Evaluating performance on  test set...
1242/1242 - 7s - 7s/epoch - 6ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.9149755
{'0': {'precision': 0.2376475255380343, 'recall': 0.2382808615580438, 'f1-score': 0.23796377214586478, 'support': 50281}, '1': {'precision': 0.743399983576942, 'recall': 0.6664059624585941, 'f1-score': 0.7028005278888328, 'support': 217360}, '2': {'precision': 0.33059446343884413, 'recall': 0.47808923800789505, 'f1-score': 0.3908911601219293, 'support': 50158}, 'accuracy': 0.5689476681802019, 'macro avg': {'precision': 0.4372139908512735, 'recall': 0.46092535400817763, 'f1-score': 0.44388515338554235, 'support': 317799}, 'weighted avg': {'precision': 0.5982288577340632, 'recall': 0.5689476681802019, 'f1-score': 0.5800273065005827, 'support': 317799}}
[[ 11981  29601   8699]
 [ 32653 144850  39857]
 [  5781  20397  23980]]
Evaluating performance on  train set...
528/528 - 3s - 3s/epoch - 6ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.95677227
{'0': {'precision': 0.19955515245745875, 'recall': 0.5752972670111436, 'f1-score': 0.29632361193503387, 'support': 16063}, '1': {'precision': 0.8500330435666718, 'recall': 0.4885705102607307, 'f1-score': 0.6204989918731368, 'support': 102673}, '2': {'precision': 0.271821038759166, 'recall': 0.4972184448015824, 'f1-score': 0.3514889340412051, 'support': 16178}, 'accuracy': 0.4999332908371259, 'macro avg': {'precision': 0.44046974492776547, 'recall': 0.5203620740244855, 'f1-score': 0.42277051261645865, 'support': 134914}, 'weighted avg': {'precision': 0.7032510922594456, 'recall': 0.4999332908371259, 'f1-score': 0.5496444190078246, 'support': 134914}}
[[ 9241  4821  2001]
 [32962 50163 19548]
 [ 4105  4029  8044]]
Evaluating performance on  val set...
159/159 - 1s - 975ms/epoch - 6ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 1.0192436
{'0': {'precision': 0.1977067407922168, 'recall': 0.6348084789884716, 'f1-score': 0.30151020047690535, 'support': 5378}, '1': {'precision': 0.8287151867337538, 'recall': 0.3895532829208168, 'f1-score': 0.5299796057104011, 'support': 30019}, '2': {'precision': 0.2591145833333333, 'recall': 0.45940746440938823, 'f1-score': 0.33134452615512694, 'support': 5198}, 'accuracy': 0.43098903805887423, 'macro avg': {'precision': 0.42851217028643457, 'recall': 0.4945897421062255, 'f1-score': 0.3876114441141445, 'support': 40595}, 'weighted avg': {'precision': 0.6721848909153285, 'recall': 0.43098903805887423, 'f1-score': 0.4742778295095377, 'support': 40595}}
[[ 3414  1295   669]
 [12166 11694  6159]
 [ 1688  1122  2388]]
training model: results/QRTEA/W2/deepLOB_L1/h20
Epoch 1/50
528/528 - 10s - loss: 3.0023 - accuracy20: 0.4521 - val_loss: 3.2662 - val_accuracy20: 0.4729 - 10s/epoch - 19ms/step
Epoch 2/50
528/528 - 8s - loss: 2.8875 - accuracy20: 0.4665 - val_loss: 3.2511 - val_accuracy20: 0.4997 - 8s/epoch - 15ms/step
Epoch 3/50
528/528 - 8s - loss: 2.8636 - accuracy20: 0.4742 - val_loss: 3.2017 - val_accuracy20: 0.3829 - 8s/epoch - 15ms/step
Epoch 4/50
528/528 - 8s - loss: 2.8298 - accuracy20: 0.4768 - val_loss: 3.2040 - val_accuracy20: 0.4858 - 8s/epoch - 15ms/step
Epoch 5/50
528/528 - 8s - loss: 2.7917 - accuracy20: 0.4938 - val_loss: 3.2101 - val_accuracy20: 0.5484 - 8s/epoch - 15ms/step
Epoch 6/50
528/528 - 8s - loss: 2.7504 - accuracy20: 0.5132 - val_loss: 3.1688 - val_accuracy20: 0.5599 - 8s/epoch - 15ms/step
Epoch 7/50
528/528 - 8s - loss: 2.7243 - accuracy20: 0.5291 - val_loss: 3.1659 - val_accuracy20: 0.5437 - 8s/epoch - 15ms/step
Epoch 8/50
528/528 - 8s - loss: 2.7009 - accuracy20: 0.5383 - val_loss: 3.1650 - val_accuracy20: 0.5433 - 8s/epoch - 15ms/step
Epoch 9/50
528/528 - 8s - loss: 2.6730 - accuracy20: 0.5536 - val_loss: 3.2065 - val_accuracy20: 0.5209 - 8s/epoch - 15ms/step
Epoch 10/50
528/528 - 8s - loss: 2.6509 - accuracy20: 0.5561 - val_loss: 3.4240 - val_accuracy20: 0.5934 - 8s/epoch - 15ms/step
Epoch 11/50
528/528 - 8s - loss: 2.6214 - accuracy20: 0.5698 - val_loss: 3.3679 - val_accuracy20: 0.5431 - 8s/epoch - 15ms/step
Epoch 12/50
528/528 - 8s - loss: 2.6018 - accuracy20: 0.5779 - val_loss: 3.3661 - val_accuracy20: 0.5771 - 8s/epoch - 15ms/step
Epoch 13/50
528/528 - 8s - loss: 2.5788 - accuracy20: 0.5886 - val_loss: 3.2736 - val_accuracy20: 0.5144 - 8s/epoch - 15ms/step
Epoch 14/50
528/528 - 8s - loss: 2.5598 - accuracy20: 0.5949 - val_loss: 3.2622 - val_accuracy20: 0.5142 - 8s/epoch - 15ms/step
Epoch 15/50
528/528 - 8s - loss: 2.5411 - accuracy20: 0.6012 - val_loss: 3.4008 - val_accuracy20: 0.5432 - 8s/epoch - 15ms/step
Epoch 16/50
528/528 - 8s - loss: 2.5236 - accuracy20: 0.6047 - val_loss: 3.3957 - val_accuracy20: 0.4821 - 8s/epoch - 15ms/step
Epoch 17/50
528/528 - 8s - loss: 2.5142 - accuracy20: 0.6076 - val_loss: 3.3983 - val_accuracy20: 0.5174 - 8s/epoch - 15ms/step
Epoch 18/50
528/528 - 8s - loss: 2.4939 - accuracy20: 0.6129 - val_loss: 3.5702 - val_accuracy20: 0.4842 - 8s/epoch - 15ms/step
testing model: results/QRTEA/W2/deepLOB_L1/h20
Evaluating performance on  test set...
1242/1242 - 7s - 7s/epoch - 5ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.94117427
{'0': {'precision': 0.4037389202256245, 'recall': 0.1933054522446334, 'f1-score': 0.2614376356653866, 'support': 64799}, '1': {'precision': 0.6531966641898845, 'recall': 0.7553152883917517, 'f1-score': 0.7005541215107545, 'support': 187384}, '2': {'precision': 0.3964334117982738, 'recall': 0.42349426969031945, 'f1-score': 0.4095172830500107, 'support': 65616}, 'accuracy': 0.5722107369752579, 'macro avg': {'precision': 0.48445633207126093, 'recall': 0.4573716701089015, 'f1-score': 0.45716968007538394, 'support': 317799}, 'weighted avg': {'precision': 0.5493184584055114, 'recall': 0.5722107369752579, 'f1-score': 0.5509281555425352, 'support': 317799}}
[[ 12526  40470  11803]
 [ 15346 141534  30504]
 [  3153  34675  27788]]
Evaluating performance on  train set...
528/528 - 3s - 3s/epoch - 6ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.9379011
{'0': {'precision': 0.3151468452716119, 'recall': 0.49131399002032894, 'f1-score': 0.3839890226948562, 'support': 21644}, '1': {'precision': 0.7895765277964231, 'recall': 0.5790832512854174, 'f1-score': 0.6681434639099785, 'support': 91410}, '2': {'precision': 0.327629651333138, 'recall': 0.5115279048490393, 'f1-score': 0.39942846936953025, 'support': 21860}, 'accuracy': 0.5540566583156677, 'macro avg': {'precision': 0.4774510081337244, 'recall': 0.5273083820515952, 'f1-score': 0.48385365199145497, 'support': 134914}, 'weighted avg': {'precision': 0.6386158063883082, 'recall': 0.5540566583156677, 'f1-score': 0.5790174391363131, 'support': 134914}}
[[10634  6769  4241]
 [19769 52934 18707]
 [ 3340  7338 11182]]
Evaluating performance on  val set...
159/159 - 1s - 999ms/epoch - 6ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.96666116
{'0': {'precision': 0.3614892379290285, 'recall': 0.4320678626060353, 'f1-score': 0.39363993411883946, 'support': 7191}, '1': {'precision': 0.7471291638986429, 'recall': 0.595499243570348, 'f1-score': 0.6627520309803426, 'support': 26440}, '2': {'precision': 0.2907742998352554, 'recall': 0.4562033314187249, 'f1-score': 0.3551704863051985, 'support': 6964}, 'accuracy': 0.5426530360881882, 'macro avg': {'precision': 0.4664642338876423, 'recall': 0.4945901458650361, 'f1-score': 0.4705208171347935, 'support': 40595}, 'weighted avg': {'precision': 0.6005300265421969, 'recall': 0.5426530360881882, 'f1-score': 0.5623164363098468, 'support': 40595}}
[[ 3107  2528  1556]
 [ 4502 15745  6193]
 [  986  2801  3177]]
training model: results/QRTEA/W2/deepLOB_L1/h30
Epoch 1/50
528/528 - 10s - loss: 3.0423 - accuracy30: 0.4394 - val_loss: 3.3503 - val_accuracy30: 0.4642 - 10s/epoch - 20ms/step
Epoch 2/50
528/528 - 8s - loss: 2.9224 - accuracy30: 0.4703 - val_loss: 3.1712 - val_accuracy30: 0.4939 - 8s/epoch - 15ms/step
Epoch 3/50
528/528 - 8s - loss: 2.8827 - accuracy30: 0.4861 - val_loss: 3.1920 - val_accuracy30: 0.4899 - 8s/epoch - 15ms/step
Epoch 4/50
528/528 - 8s - loss: 2.8578 - accuracy30: 0.4948 - val_loss: 3.1331 - val_accuracy30: 0.4571 - 8s/epoch - 15ms/step
Epoch 5/50
528/528 - 8s - loss: 2.8264 - accuracy30: 0.5060 - val_loss: 3.2426 - val_accuracy30: 0.5220 - 8s/epoch - 15ms/step
Epoch 6/50
528/528 - 8s - loss: 2.8005 - accuracy30: 0.5115 - val_loss: 3.2225 - val_accuracy30: 0.5372 - 8s/epoch - 15ms/step
Epoch 7/50
528/528 - 8s - loss: 2.7766 - accuracy30: 0.5205 - val_loss: 3.2733 - val_accuracy30: 0.5411 - 8s/epoch - 15ms/step
Epoch 8/50
528/528 - 8s - loss: 2.7560 - accuracy30: 0.5318 - val_loss: 3.3391 - val_accuracy30: 0.5522 - 8s/epoch - 15ms/step
Epoch 9/50
528/528 - 8s - loss: 2.7310 - accuracy30: 0.5415 - val_loss: 3.1950 - val_accuracy30: 0.5054 - 8s/epoch - 15ms/step
Epoch 10/50
528/528 - 8s - loss: 2.7127 - accuracy30: 0.5499 - val_loss: 3.1958 - val_accuracy30: 0.5042 - 8s/epoch - 15ms/step
Epoch 11/50
528/528 - 8s - loss: 2.6972 - accuracy30: 0.5567 - val_loss: 3.1678 - val_accuracy30: 0.4947 - 8s/epoch - 15ms/step
Epoch 12/50
528/528 - 8s - loss: 2.6714 - accuracy30: 0.5659 - val_loss: 3.1992 - val_accuracy30: 0.4802 - 8s/epoch - 15ms/step
Epoch 13/50
528/528 - 8s - loss: 2.6538 - accuracy30: 0.5703 - val_loss: 3.2447 - val_accuracy30: 0.5038 - 8s/epoch - 15ms/step
Epoch 14/50
528/528 - 8s - loss: 2.6360 - accuracy30: 0.5802 - val_loss: 3.2829 - val_accuracy30: 0.5548 - 8s/epoch - 15ms/step
testing model: results/QRTEA/W2/deepLOB_L1/h30
Evaluating performance on  test set...
1242/1242 - 7s - 7s/epoch - 5ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.0058647
{'0': {'precision': 0.370096971642099, 'recall': 0.2183510062756979, 'f1-score': 0.2746582508910571, 'support': 73936}, '1': {'precision': 0.6080403817562707, 'recall': 0.605513898175566, 'f1-score': 0.606774510038527, 'support': 167504}, '2': {'precision': 0.37878364533854897, 'recall': 0.5326156707133409, 'f1-score': 0.4427172629252868, 'support': 76359}, 'accuracy': 0.4979247889389205, 'macro avg': {'precision': 0.45230699957897286, 'recall': 0.45216019172153493, 'f1-score': 0.441383341284957, 'support': 317799}, 'weighted avg': {'precision': 0.49759824975987615, 'recall': 0.4979247889389205, 'f1-score': 0.49008882169889334, 'support': 317799}}
[[ 16144  36867  20925]
 [ 20303 101426  45775]
 [  7174  28515  40670]]
Evaluating performance on  train set...
528/528 - 3s - 3s/epoch - 6ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.985566
{'0': {'precision': 0.3209917433580165, 'recall': 0.5306218224481815, 'f1-score': 0.40000589631333006, 'support': 25570}, '1': {'precision': 0.7442624910351422, 'recall': 0.44738638404885933, 'f1-score': 0.5588439877039064, 'support': 83505}, '2': {'precision': 0.338146952813965, 'recall': 0.555516854367429, 'f1-score': 0.42039597000937207, 'support': 25839}, 'accuracy': 0.4838712068428777, 'macro avg': {'precision': 0.4678003957357079, 'recall': 0.5111750202881566, 'f1-score': 0.4597486180088695, 'support': 134914}, 'weighted avg': {'precision': 0.5862607090836688, 'recall': 0.4838712068428777, 'f1-score': 0.5022238569089844, 'support': 134914}}
[[13568  7177  4825]
 [22876 37359 23270]
 [ 5825  5660 14354]]
Evaluating performance on  val set...
159/159 - 1s - 993ms/epoch - 6ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.0220823
{'0': {'precision': 0.3359909687433853, 'recall': 0.5582649472450176, 'f1-score': 0.41950403030436506, 'support': 8530}, '1': {'precision': 0.71996400179991, 'recall': 0.4012036108324975, 'f1-score': 0.5152702485105469, 'support': 23928}, '2': {'precision': 0.3238080684596577, 'recall': 0.5208307730121666, 'f1-score': 0.3993404004711425, 'support': 8137}, 'accuracy': 0.45818450548097056, 'macro avg': {'precision': 0.4599210130009843, 'recall': 0.49343311036322723, 'f1-score': 0.4447048930953515, 'support': 40595}, 'weighted avg': {'precision': 0.559875054846793, 'recall': 0.45818450548097056, 'f1-score': 0.4719100560041948, 'support': 40595}}
[[4762 1987 1781]
 [7259 9600 7069]
 [2152 1747 4238]]
training model: results/QRTEA/W2/deepLOB_L1/h50
Epoch 1/50
528/528 - 10s - loss: 3.0776 - accuracy50: 0.4577 - val_loss: 3.4369 - val_accuracy50: 0.4850 - 10s/epoch - 19ms/step
Epoch 2/50
528/528 - 8s - loss: 2.9740 - accuracy50: 0.4809 - val_loss: 3.3434 - val_accuracy50: 0.4035 - 8s/epoch - 16ms/step
Epoch 3/50
528/528 - 8s - loss: 2.9416 - accuracy50: 0.4886 - val_loss: 3.3198 - val_accuracy50: 0.4544 - 8s/epoch - 15ms/step
Epoch 4/50
528/528 - 8s - loss: 2.9198 - accuracy50: 0.4950 - val_loss: 3.2620 - val_accuracy50: 0.4115 - 8s/epoch - 15ms/step
Epoch 5/50
528/528 - 8s - loss: 2.8851 - accuracy50: 0.5079 - val_loss: 3.2679 - val_accuracy50: 0.4024 - 8s/epoch - 15ms/step
Epoch 6/50
528/528 - 8s - loss: 2.8627 - accuracy50: 0.5155 - val_loss: 3.1981 - val_accuracy50: 0.4197 - 8s/epoch - 15ms/step
Epoch 7/50
528/528 - 8s - loss: 2.8488 - accuracy50: 0.5196 - val_loss: 3.1822 - val_accuracy50: 0.4179 - 8s/epoch - 15ms/step
Epoch 8/50
528/528 - 8s - loss: 2.8320 - accuracy50: 0.5278 - val_loss: 3.2175 - val_accuracy50: 0.4114 - 8s/epoch - 15ms/step
Epoch 9/50
528/528 - 8s - loss: 2.8187 - accuracy50: 0.5323 - val_loss: 3.1988 - val_accuracy50: 0.4322 - 8s/epoch - 15ms/step
Epoch 10/50
528/528 - 8s - loss: 2.8029 - accuracy50: 0.5373 - val_loss: 3.2399 - val_accuracy50: 0.4245 - 8s/epoch - 15ms/step
Epoch 11/50
528/528 - 8s - loss: 2.7927 - accuracy50: 0.5384 - val_loss: 3.3001 - val_accuracy50: 0.4067 - 8s/epoch - 15ms/step
Epoch 12/50
528/528 - 8s - loss: 2.7756 - accuracy50: 0.5436 - val_loss: 3.3007 - val_accuracy50: 0.4110 - 8s/epoch - 15ms/step
Epoch 13/50
528/528 - 8s - loss: 2.7684 - accuracy50: 0.5475 - val_loss: 3.3298 - val_accuracy50: 0.4203 - 8s/epoch - 15ms/step
Epoch 14/50
528/528 - 8s - loss: 2.7592 - accuracy50: 0.5517 - val_loss: 3.3974 - val_accuracy50: 0.4090 - 8s/epoch - 15ms/step
Epoch 15/50
528/528 - 8s - loss: 2.7507 - accuracy50: 0.5526 - val_loss: 3.5211 - val_accuracy50: 0.4108 - 8s/epoch - 15ms/step
Epoch 16/50
528/528 - 8s - loss: 2.7377 - accuracy50: 0.5581 - val_loss: 3.5035 - val_accuracy50: 0.4136 - 8s/epoch - 15ms/step
Epoch 17/50
528/528 - 8s - loss: 2.7286 - accuracy50: 0.5604 - val_loss: 3.5242 - val_accuracy50: 0.4074 - 8s/epoch - 15ms/step
testing model: results/QRTEA/W2/deepLOB_L1/h50
Evaluating performance on  test set...
1242/1242 - 7s - 7s/epoch - 5ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0726964
{'0': {'precision': 0.4221759619343917, 'recall': 0.2137851143932812, 'f1-score': 0.2838379255454133, 'support': 86325}, '1': {'precision': 0.48391788856304985, 'recall': 0.5875257240107382, 'f1-score': 0.5307124042800218, 'support': 140433}, '2': {'precision': 0.40834097601004005, 'recall': 0.46460385979943103, 'f1-score': 0.43465929526373653, 'support': 91041}, 'accuracy': 0.4507912233833335, 'macro avg': {'precision': 0.43814494216916056, 'recall': 0.4219715660678168, 'f1-score': 0.41640320836305716, 'support': 317799}, 'weighted avg': {'precision': 0.44549590009877693, 'recall': 0.4507912233833335, 'f1-score': 0.4361362398656696, 'support': 317799}}
[[18455 47075 20795]
 [17433 82508 40492]
 [ 7826 40917 42298]]
Evaluating performance on  train set...
528/528 - 3s - 3s/epoch - 6ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0256127
{'0': {'precision': 0.4043323114037292, 'recall': 0.5070111863872696, 'f1-score': 0.4498874582337234, 'support': 31735}, '1': {'precision': 0.6568710925146569, 'recall': 0.37985510304564957, 'f1-score': 0.4813533941814034, 'support': 71085}, '2': {'precision': 0.3488049173347157, 'recall': 0.5870256122639745, 'f1-score': 0.4375950851847121, 'support': 32094}, 'accuracy': 0.4590479861244941, 'macro avg': {'precision': 0.47000277375103394, 'recall': 0.4912973005656312, 'f1-score': 0.456278645866613, 'support': 134914}, 'weighted avg': {'precision': 0.5241836468471923, 'recall': 0.4590479861244941, 'f1-score': 0.46354241351046166, 'support': 134914}}
[[16090  7304  8341]
 [17251 27002 26832]
 [ 6453  6801 18840]]
Evaluating performance on  val set...
159/159 - 1s - 953ms/epoch - 6ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0724616
{'0': {'precision': 0.4225614296351452, 'recall': 0.427777254310751, 'f1-score': 0.4251533455073278, 'support': 10613}, '1': {'precision': 0.6768661320172733, 'recall': 0.2742040285899935, 'f1-score': 0.3902959590210586, 'support': 20007}, '2': {'precision': 0.3197369631196542, 'recall': 0.6970426065162907, 'f1-score': 0.43838466630938494, 'support': 9975}, 'accuracy': 0.4182534794925483, 'macro avg': {'precision': 0.47305484159069094, 'recall': 0.46634129647234507, 'f1-score': 0.41794465694592375, 'support': 40595}, 'weighted avg': {'precision': 0.5226279434192865, 'recall': 0.4182534794925483, 'f1-score': 0.4112252926330756, 'support': 40595}}
[[ 4540  1496  4577]
 [ 4305  5486 10216]
 [ 1899  1123  6953]]
training model: results/QRTEA/W2/deepLOB_L1/h100
Epoch 1/50
528/528 - 10s - loss: 3.1556 - accuracy100: 0.4467 - val_loss: 3.3409 - val_accuracy100: 0.3937 - 10s/epoch - 19ms/step
Epoch 2/50
528/528 - 8s - loss: 3.0972 - accuracy100: 0.4705 - val_loss: 3.4036 - val_accuracy100: 0.3969 - 8s/epoch - 15ms/step
Epoch 3/50
528/528 - 8s - loss: 3.0641 - accuracy100: 0.4765 - val_loss: 3.3166 - val_accuracy100: 0.4077 - 8s/epoch - 15ms/step
Epoch 4/50
528/528 - 8s - loss: 3.0473 - accuracy100: 0.4861 - val_loss: 3.3518 - val_accuracy100: 0.4169 - 8s/epoch - 15ms/step
Epoch 5/50
528/528 - 8s - loss: 3.0288 - accuracy100: 0.4929 - val_loss: 3.2691 - val_accuracy100: 0.4231 - 8s/epoch - 15ms/step
Epoch 6/50
528/528 - 8s - loss: 3.0094 - accuracy100: 0.4981 - val_loss: 3.2806 - val_accuracy100: 0.4180 - 8s/epoch - 15ms/step
Epoch 7/50
528/528 - 8s - loss: 2.9962 - accuracy100: 0.5018 - val_loss: 3.2534 - val_accuracy100: 0.4286 - 8s/epoch - 15ms/step
Epoch 8/50
528/528 - 8s - loss: 2.9839 - accuracy100: 0.5054 - val_loss: 3.2675 - val_accuracy100: 0.4298 - 8s/epoch - 15ms/step
Epoch 9/50
528/528 - 8s - loss: 2.9778 - accuracy100: 0.5076 - val_loss: 3.2675 - val_accuracy100: 0.4201 - 8s/epoch - 15ms/step
Epoch 10/50
528/528 - 8s - loss: 2.9665 - accuracy100: 0.5115 - val_loss: 3.2571 - val_accuracy100: 0.4239 - 8s/epoch - 15ms/step
Epoch 11/50
528/528 - 8s - loss: 2.9555 - accuracy100: 0.5147 - val_loss: 3.2476 - val_accuracy100: 0.4292 - 8s/epoch - 15ms/step
Epoch 12/50
528/528 - 8s - loss: 2.9496 - accuracy100: 0.5162 - val_loss: 3.2672 - val_accuracy100: 0.4174 - 8s/epoch - 15ms/step
Epoch 13/50
528/528 - 8s - loss: 2.9403 - accuracy100: 0.5182 - val_loss: 3.2942 - val_accuracy100: 0.4123 - 8s/epoch - 15ms/step
Epoch 14/50
528/528 - 8s - loss: 2.9343 - accuracy100: 0.5208 - val_loss: 3.3204 - val_accuracy100: 0.4100 - 8s/epoch - 15ms/step
Epoch 15/50
528/528 - 8s - loss: 2.9274 - accuracy100: 0.5228 - val_loss: 3.3513 - val_accuracy100: 0.4032 - 8s/epoch - 15ms/step
Epoch 16/50
528/528 - 8s - loss: 2.9219 - accuracy100: 0.5240 - val_loss: 3.3928 - val_accuracy100: 0.3951 - 8s/epoch - 15ms/step
Epoch 17/50
528/528 - 8s - loss: 2.9168 - accuracy100: 0.5245 - val_loss: 3.4058 - val_accuracy100: 0.3927 - 8s/epoch - 15ms/step
Epoch 18/50
528/528 - 8s - loss: 2.9126 - accuracy100: 0.5267 - val_loss: 3.3487 - val_accuracy100: 0.4129 - 8s/epoch - 15ms/step
Epoch 19/50
528/528 - 8s - loss: 2.9093 - accuracy100: 0.5273 - val_loss: 3.3561 - val_accuracy100: 0.4050 - 8s/epoch - 15ms/step
Epoch 20/50
528/528 - 8s - loss: 2.8988 - accuracy100: 0.5293 - val_loss: 3.3468 - val_accuracy100: 0.4102 - 8s/epoch - 15ms/step
Epoch 21/50
528/528 - 8s - loss: 2.8953 - accuracy100: 0.5301 - val_loss: 3.3463 - val_accuracy100: 0.4137 - 8s/epoch - 15ms/step
testing model: results/QRTEA/W2/deepLOB_L1/h100
Evaluating performance on  test set...
1242/1242 - 7s - 7s/epoch - 5ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.1829561
{'0': {'precision': 0.40967065048809415, 'recall': 0.21414877483475292, 'f1-score': 0.28126879134095006, 'support': 104843}, '1': {'precision': 0.32967877335229423, 'recall': 0.5793254939895005, 'f1-score': 0.4202209496522766, 'support': 99243}, '2': {'precision': 0.4599774266365689, 'recall': 0.35839349942398846, 'f1-score': 0.40288068487937007, 'support': 113713}, 'accuracy': 0.37979981057209117, 'macro avg': {'precision': 0.3997756168256524, 'recall': 0.383955922749414, 'f1-score': 0.36812347529086553, 'support': 317799}, 'weighted avg': {'precision': 0.4026910834459805, 'recall': 0.37979981057209117, 'f1-score': 0.3681755540973632, 'support': 317799}}
[[22452 59263 23128]
 [17031 57494 24718]
 [15322 57637 40754]]
Evaluating performance on  train set...
528/528 - 3s - 3s/epoch - 6ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0753645
{'0': {'precision': 0.4213267176254973, 'recall': 0.45431759573904035, 'f1-score': 0.4372006725807387, 'support': 41493}, '1': {'precision': 0.4807311045327395, 'recall': 0.34627046694966646, 'f1-score': 0.40256993404594044, 'support': 51119}, '2': {'precision': 0.41155742160409364, 'recall': 0.5190534726490473, 'f1-score': 0.4590969441627549, 'support': 42302}, 'accuracy': 0.4336762678447011, 'macro avg': {'precision': 0.43787174792077677, 'recall': 0.4398805117792513, 'f1-score': 0.4329558502631447, 'support': 134914}, 'weighted avg': {'precision': 0.4407719352753624, 'recall': 0.4336762678447011, 'f1-score': 0.43094459357709264, 'support': 134914}}
[[18851  9972 12670]
 [14694 17701 18724]
 [11197  9148 21957]]
Evaluating performance on  val set...
159/159 - 1s - 964ms/epoch - 6ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0802833
{'0': {'precision': 0.44228384991843395, 'recall': 0.4918722786647315, 'f1-score': 0.4657618965813434, 'support': 13780}, '1': {'precision': 0.47954911433172304, 'recall': 0.3114845547730284, 'f1-score': 0.37766317213391953, 'support': 14341}, '2': {'precision': 0.39680350987151364, 'recall': 0.5075356742023409, 'f1-score': 0.4453902704984347, 'support': 12474}, 'accuracy': 0.43295972410395367, 'macro avg': {'precision': 0.43954549137389026, 'recall': 0.43696416921336695, 'f1-score': 0.42960511307123256, 'support': 40595}, 'weighted avg': {'precision': 0.4414733903841488, 'recall': 0.43295972410395367, 'f1-score': 0.42837947335043547, 'support': 40595}}
[[6778 2689 4313]
 [4563 4467 5311]
 [3984 2159 6331]]
training model: results/QRTEA/W2/deepLOB_L1/h200
Epoch 1/50
528/528 - 10s - loss: 3.2506 - accuracy200: 0.4067 - val_loss: 3.3463 - val_accuracy200: 0.3563 - 10s/epoch - 19ms/step
Epoch 2/50
528/528 - 8s - loss: 3.2033 - accuracy200: 0.4266 - val_loss: 3.4277 - val_accuracy200: 0.3655 - 8s/epoch - 16ms/step
Epoch 3/50
528/528 - 8s - loss: 3.1875 - accuracy200: 0.4313 - val_loss: 3.4633 - val_accuracy200: 0.3566 - 8s/epoch - 16ms/step
Epoch 4/50
528/528 - 8s - loss: 3.1883 - accuracy200: 0.4300 - val_loss: 3.3979 - val_accuracy200: 0.3693 - 8s/epoch - 16ms/step
Epoch 5/50
528/528 - 8s - loss: 3.1730 - accuracy200: 0.4393 - val_loss: 3.4049 - val_accuracy200: 0.3620 - 8s/epoch - 15ms/step
Epoch 6/50
528/528 - 8s - loss: 3.1633 - accuracy200: 0.4416 - val_loss: 3.5359 - val_accuracy200: 0.3596 - 8s/epoch - 15ms/step
Epoch 7/50
528/528 - 8s - loss: 3.1517 - accuracy200: 0.4453 - val_loss: 3.4705 - val_accuracy200: 0.3699 - 8s/epoch - 15ms/step
Epoch 8/50
528/528 - 8s - loss: 3.1479 - accuracy200: 0.4472 - val_loss: 3.4618 - val_accuracy200: 0.3775 - 8s/epoch - 15ms/step
Epoch 9/50
528/528 - 8s - loss: 3.1386 - accuracy200: 0.4516 - val_loss: 3.4552 - val_accuracy200: 0.3784 - 8s/epoch - 15ms/step
Epoch 10/50
528/528 - 8s - loss: 3.1295 - accuracy200: 0.4553 - val_loss: 3.4922 - val_accuracy200: 0.3742 - 8s/epoch - 15ms/step
Epoch 11/50
528/528 - 8s - loss: 3.1249 - accuracy200: 0.4556 - val_loss: 3.3983 - val_accuracy200: 0.3920 - 8s/epoch - 15ms/step
testing model: results/QRTEA/W2/deepLOB_L1/h200
Evaluating performance on  test set...
1242/1242 - 7s - 7s/epoch - 5ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1071024
{'0': {'precision': 0.3864652187598363, 'recall': 0.12282175939819538, 'f1-score': 0.18640310924880063, 'support': 99966}, '1': {'precision': 0.35365230552690186, 'recall': 0.682658131268958, 'f1-score': 0.4659291529600041, 'support': 107474}, '2': {'precision': 0.418093189599216, 'recall': 0.29766489366521987, 'f1-score': 0.34774784311649815, 'support': 110359}, 'accuracy': 0.3728646093914707, 'macro avg': {'precision': 0.3860702379619847, 'recall': 0.36771492811079104, 'f1-score': 0.33336003510843426, 'support': 317799}, 'weighted avg': {'precision': 0.38635161298092163, 'recall': 0.3728646093914707, 'f1-score': 0.3369625053032977, 'support': 317799}}
[[12278 64803 22885]
 [11270 73368 22836]
 [ 8222 69287 32850]]
Evaluating performance on  train set...
528/528 - 3s - 3s/epoch - 6ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.10407
{'0': {'precision': 0.4134733549324098, 'recall': 0.16559654578402203, 'f1-score': 0.23648184533793387, 'support': 44699}, '1': {'precision': 0.34776079974417085, 'recall': 0.5598030438675022, 'f1-score': 0.4290112604306922, 'support': 44680}, '2': {'precision': 0.4045776131650735, 'recall': 0.40061491160645657, 'f1-score': 0.40258651129943496, 'support': 45535}, 'accuracy': 0.375468817172421, 'macro avg': {'precision': 0.3886039226138847, 'recall': 0.37533816708599366, 'f1-score': 0.35602653902268705, 'support': 134914}, 'weighted avg': {'precision': 0.3887086561821973, 'recall': 0.375468817172421, 'f1-score': 0.35630477128262006, 'support': 134914}}
[[ 7402 24418 12879]
 [ 5700 25012 13968]
 [ 4800 22493 18242]]
Evaluating performance on  val set...
159/159 - 1s - 972ms/epoch - 6ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1139414
{'0': {'precision': 0.4241978937056086, 'recall': 0.1169796028637039, 'f1-score': 0.18338715654613794, 'support': 14806}, '1': {'precision': 0.34133186103796825, 'recall': 0.6111322332902441, 'f1-score': 0.43801945663133235, 'support': 13151}, '2': {'precision': 0.3631806262532778, 'recall': 0.3726064250672575, 'f1-score': 0.36783315107014525, 'support': 12638}, 'accuracy': 0.35664490700825224, 'macro avg': {'precision': 0.3762367936656182, 'recall': 0.36690608707373523, 'f1-score': 0.3297465880825385, 'support': 40595}, 'weighted avg': {'precision': 0.37835709011712, 'recall': 0.35664490700825224, 'f1-score': 0.32329842288964816, 'support': 40595}}
[[1732 8560 4514]
 [1371 8037 3743]
 [ 980 6949 4709]]
training model: results/QRTEA/W2/deepLOB_L1/h300
Epoch 1/50
528/528 - 11s - loss: 3.2831 - accuracy300: 0.3878 - val_loss: 3.3646 - val_accuracy300: 0.3495 - 11s/epoch - 20ms/step
Epoch 2/50
528/528 - 8s - loss: 3.2552 - accuracy300: 0.3942 - val_loss: 3.3780 - val_accuracy300: 0.3385 - 8s/epoch - 16ms/step
Epoch 3/50
528/528 - 8s - loss: 3.2379 - accuracy300: 0.4035 - val_loss: 3.3788 - val_accuracy300: 0.3442 - 8s/epoch - 16ms/step
Epoch 4/50
528/528 - 8s - loss: 3.2208 - accuracy300: 0.4107 - val_loss: 3.3696 - val_accuracy300: 0.3393 - 8s/epoch - 16ms/step
Epoch 5/50
528/528 - 8s - loss: 3.2064 - accuracy300: 0.4161 - val_loss: 3.4363 - val_accuracy300: 0.3418 - 8s/epoch - 15ms/step
Epoch 6/50
528/528 - 8s - loss: 3.1966 - accuracy300: 0.4222 - val_loss: 3.5260 - val_accuracy300: 0.3326 - 8s/epoch - 15ms/step
Epoch 7/50
528/528 - 8s - loss: 3.1881 - accuracy300: 0.4264 - val_loss: 3.5493 - val_accuracy300: 0.3357 - 8s/epoch - 15ms/step
Epoch 8/50
528/528 - 8s - loss: 3.1838 - accuracy300: 0.4292 - val_loss: 3.4314 - val_accuracy300: 0.3410 - 8s/epoch - 15ms/step
Epoch 9/50
528/528 - 8s - loss: 3.1783 - accuracy300: 0.4326 - val_loss: 3.4836 - val_accuracy300: 0.3330 - 8s/epoch - 15ms/step
Epoch 10/50
528/528 - 8s - loss: 3.1717 - accuracy300: 0.4342 - val_loss: 3.5789 - val_accuracy300: 0.3294 - 8s/epoch - 15ms/step
Epoch 11/50
528/528 - 8s - loss: 3.1632 - accuracy300: 0.4372 - val_loss: 3.5425 - val_accuracy300: 0.3285 - 8s/epoch - 15ms/step
testing model: results/QRTEA/W2/deepLOB_L1/h300
Evaluating performance on  test set...
1242/1242 - 8s - 8s/epoch - 6ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1132936
{'0': {'precision': 0.33382551860150544, 'recall': 0.32794368254483486, 'f1-score': 0.3308584615542058, 'support': 98584}, '1': {'precision': 0.3638156156196852, 'recall': 0.4886468088204512, 'f1-score': 0.4170913215051424, 'support': 109881}, '2': {'precision': 0.4004279736673527, 'recall': 0.26870872738580864, 'f1-score': 0.3216039145498432, 'support': 109334}, 'accuracy': 0.36312889593736924, 'macro avg': {'precision': 0.36602303596284774, 'recall': 0.3617664062503649, 'f1-score': 0.3565178992030638, 'support': 317799}, 'weighted avg': {'precision': 0.36710836301770544, 'recall': 0.36312889593736924, 'f1-score': 0.35749012572587996, 'support': 317799}}
[[32330 43896 22358]
 [34556 53693 21632]
 [29961 49994 29379]]
Evaluating performance on  train set...
528/528 - 3s - 3s/epoch - 5ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1179984
{'0': {'precision': 0.37593574934311635, 'recall': 0.3376224398931434, 'f1-score': 0.3557505101921138, 'support': 44920}, '1': {'precision': 0.3477551781179376, 'recall': 0.3361711711711712, 'f1-score': 0.3418650725484133, 'support': 44400}, '2': {'precision': 0.3744361193394126, 'recall': 0.42417861999385886, 'f1-score': 0.39775823949817474, 'support': 45594}, 'accuracy': 0.36639637102153966, 'macro avg': {'precision': 0.3660423489334888, 'recall': 0.36599074368605783, 'f1-score': 0.3651246074129006, 'support': 134914}, 'weighted avg': {'precision': 0.3661547666964911, 'recall': 0.36639637102153966, 'f1-score': 0.3653772870914737, 'support': 134914}}
[[15166 13633 16121]
 [13284 14926 16190]
 [11892 14362 19340]]
Evaluating performance on  val set...
159/159 - 1s - 951ms/epoch - 6ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1200958
{'0': {'precision': 0.4014758675708018, 'recall': 0.27184334908845376, 'f1-score': 0.32418069087688217, 'support': 14810}, '1': {'precision': 0.3524049314117034, 'recall': 0.2969493013387958, 'f1-score': 0.32230912772461984, 'support': 13669}, '2': {'precision': 0.32642133445325217, 'recall': 0.5132056784417299, 'f1-score': 0.3990373816781646, 'support': 12116}, 'accuracy': 0.35233403128464097, 'macro avg': {'precision': 0.3601007111452524, 'recall': 0.3606661096229932, 'f1-score': 0.34850906675988885, 'support': 40595}, 'weighted avg': {'precision': 0.3625520752414276, 'recall': 0.35233403128464097, 'f1-score': 0.34589226296753534, 'support': 40595}}
[[4026 4025 6759]
 [3538 4059 6072]
 [2464 3434 6218]]
training model: results/QRTEA/W2/deepLOB_L1/h500
Epoch 1/50
528/528 - 10s - loss: 3.2316 - accuracy500: 0.4187 - val_loss: 3.4596 - val_accuracy500: 0.3770 - 10s/epoch - 20ms/step
Epoch 2/50
528/528 - 9s - loss: 3.2168 - accuracy500: 0.4236 - val_loss: 3.3241 - val_accuracy500: 0.3891 - 9s/epoch - 17ms/step
Epoch 3/50
528/528 - 8s - loss: 3.2132 - accuracy500: 0.4180 - val_loss: 3.3154 - val_accuracy500: 0.3930 - 8s/epoch - 15ms/step
Epoch 4/50
528/528 - 8s - loss: 3.1935 - accuracy500: 0.4283 - val_loss: 3.3092 - val_accuracy500: 0.3855 - 8s/epoch - 16ms/step
Epoch 5/50
528/528 - 8s - loss: 3.2161 - accuracy500: 0.4235 - val_loss: 3.2551 - val_accuracy500: 0.3940 - 8s/epoch - 15ms/step
Epoch 6/50
528/528 - 8s - loss: 3.1747 - accuracy500: 0.4407 - val_loss: 3.3113 - val_accuracy500: 0.3735 - 8s/epoch - 15ms/step
Epoch 7/50
528/528 - 8s - loss: 3.1738 - accuracy500: 0.4376 - val_loss: 3.2915 - val_accuracy500: 0.3738 - 8s/epoch - 15ms/step
Epoch 8/50
528/528 - 8s - loss: 3.1697 - accuracy500: 0.4398 - val_loss: 3.3184 - val_accuracy500: 0.3678 - 8s/epoch - 15ms/step
Epoch 9/50
528/528 - 8s - loss: 3.1822 - accuracy500: 0.4335 - val_loss: 3.3223 - val_accuracy500: 0.3843 - 8s/epoch - 15ms/step
Epoch 10/50
528/528 - 8s - loss: 3.1669 - accuracy500: 0.4395 - val_loss: 3.2468 - val_accuracy500: 0.4092 - 8s/epoch - 15ms/step
Epoch 11/50
528/528 - 8s - loss: 3.1673 - accuracy500: 0.4411 - val_loss: 3.2963 - val_accuracy500: 0.3653 - 8s/epoch - 15ms/step
Epoch 12/50
528/528 - 8s - loss: 3.1671 - accuracy500: 0.4413 - val_loss: 3.2574 - val_accuracy500: 0.3875 - 8s/epoch - 15ms/step
Epoch 13/50
528/528 - 8s - loss: 3.1597 - accuracy500: 0.4462 - val_loss: 3.3694 - val_accuracy500: 0.3435 - 8s/epoch - 15ms/step
Epoch 14/50
528/528 - 8s - loss: 3.1539 - accuracy500: 0.4467 - val_loss: 3.3534 - val_accuracy500: 0.3429 - 8s/epoch - 15ms/step
Epoch 15/50
528/528 - 8s - loss: 3.1616 - accuracy500: 0.4468 - val_loss: 3.3178 - val_accuracy500: 0.3798 - 8s/epoch - 15ms/step
Epoch 16/50
528/528 - 8s - loss: 3.1577 - accuracy500: 0.4454 - val_loss: 3.2401 - val_accuracy500: 0.3939 - 8s/epoch - 15ms/step
Epoch 17/50
528/528 - 8s - loss: 3.1470 - accuracy500: 0.4500 - val_loss: 3.2905 - val_accuracy500: 0.3746 - 8s/epoch - 15ms/step
Epoch 18/50
528/528 - 8s - loss: 3.1416 - accuracy500: 0.4543 - val_loss: 3.3257 - val_accuracy500: 0.3635 - 8s/epoch - 15ms/step
Epoch 19/50
528/528 - 8s - loss: 3.1293 - accuracy500: 0.4549 - val_loss: 3.3798 - val_accuracy500: 0.3666 - 8s/epoch - 15ms/step
Epoch 20/50
528/528 - 8s - loss: 3.1247 - accuracy500: 0.4577 - val_loss: 3.3896 - val_accuracy500: 0.3680 - 8s/epoch - 15ms/step
Epoch 21/50
528/528 - 8s - loss: 3.1255 - accuracy500: 0.4554 - val_loss: 3.3658 - val_accuracy500: 0.3646 - 8s/epoch - 15ms/step
Epoch 22/50
528/528 - 8s - loss: 3.1146 - accuracy500: 0.4619 - val_loss: 3.3823 - val_accuracy500: 0.3741 - 8s/epoch - 15ms/step
Epoch 23/50
528/528 - 8s - loss: 3.1144 - accuracy500: 0.4606 - val_loss: 3.3586 - val_accuracy500: 0.3726 - 8s/epoch - 15ms/step
Epoch 24/50
528/528 - 8s - loss: 3.0987 - accuracy500: 0.4647 - val_loss: 3.4061 - val_accuracy500: 0.3792 - 8s/epoch - 15ms/step
Epoch 25/50
528/528 - 8s - loss: 3.1129 - accuracy500: 0.4615 - val_loss: 3.3661 - val_accuracy500: 0.3805 - 8s/epoch - 15ms/step
Epoch 26/50
528/528 - 8s - loss: 3.0944 - accuracy500: 0.4655 - val_loss: 3.4206 - val_accuracy500: 0.3608 - 8s/epoch - 15ms/step
testing model: results/QRTEA/W2/deepLOB_L1/h500
Evaluating performance on  test set...
1242/1242 - 8s - 8s/epoch - 6ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0883045
{'0': {'precision': 0.2537827269636178, 'recall': 0.21764698735161536, 'f1-score': 0.23432992994826243, 'support': 82303}, '1': {'precision': 0.48776271226442924, 'recall': 0.5824203696005974, 'f1-score': 0.530905307640189, 'support': 141937}, '2': {'precision': 0.3746542652412746, 'recall': 0.3112795134620934, 'f1-score': 0.3400392312542325, 'support': 93559}, 'accuracy': 0.4081290375363044, 'macro avg': {'precision': 0.37206656815644057, 'recall': 0.3704489568047687, 'f1-score': 0.3684248229475613, 'support': 317799}, 'weighted avg': {'precision': 0.39386824461269965, 'recall': 0.4081290375363044, 'f1-score': 0.39790840535046396, 'support': 317799}}
[[17913 40184 24206]
 [34866 82667 24404]
 [17805 46631 29123]]
Evaluating performance on  train set...
528/528 - 3s - 3s/epoch - 6ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1075886
{'0': {'precision': 0.3401318567113767, 'recall': 0.2286182056319581, 'f1-score': 0.2734429054450986, 'support': 45810}, '1': {'precision': 0.36825879965659875, 'recall': 0.4283217973448315, 'f1-score': 0.39602589254802395, 'support': 44065}, '2': {'precision': 0.3571523141230542, 'recall': 0.4192588645396212, 'f1-score': 0.38572158104381576, 'support': 45039}, 'accuracy': 0.35748699171323955, 'macro avg': {'precision': 0.3551809901636765, 'recall': 0.35873295583880355, 'f1-score': 0.3517301263456461, 'support': 134914}, 'weighted avg': {'precision': 0.3550005739849417, 'recall': 0.35748699171323955, 'f1-score': 0.350962944855249, 'support': 134914}}
[[10473 16438 18899]
 [10102 18874 15089]
 [10216 15940 18883]]
Evaluating performance on  val set...
159/159 - 1s - 957ms/epoch - 6ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0806346
{'0': {'precision': 0.39323467230443976, 'recall': 0.20251143209697323, 'f1-score': 0.2673438098888463, 'support': 13777}, '1': {'precision': 0.49937741252645995, 'recall': 0.5008429597252576, 'f1-score': 0.5001091124481716, 'support': 16015}, '2': {'precision': 0.29240738616813855, 'recall': 0.4719985189299269, 'f1-score': 0.361106193123473, 'support': 10803}, 'accuracy': 0.3919201872151743, 'macro avg': {'precision': 0.39500649033301277, 'recall': 0.39178430358405253, 'f1-score': 0.3761863718201636, 'support': 40595}, 'weighted avg': {'precision': 0.4082768896347807, 'recall': 0.3919201872151743, 'f1-score': 0.38412300305478464, 'support': 40595}}
[[2790 4330 6657]
 [2312 8021 5682]
 [1993 3711 5099]]
training model: results/QRTEA/W2/deepLOB_L1/h1000
Epoch 1/50
528/528 - 10s - loss: 3.2577 - accuracy1000: 0.4116 - val_loss: 3.4649 - val_accuracy1000: 0.3402 - 10s/epoch - 19ms/step
Epoch 2/50
528/528 - 8s - loss: 3.2182 - accuracy1000: 0.4177 - val_loss: 3.5987 - val_accuracy1000: 0.2964 - 8s/epoch - 15ms/step
Epoch 3/50
528/528 - 8s - loss: 3.1745 - accuracy1000: 0.4384 - val_loss: 3.4937 - val_accuracy1000: 0.2996 - 8s/epoch - 15ms/step
Epoch 4/50
528/528 - 8s - loss: 3.1576 - accuracy1000: 0.4458 - val_loss: 3.4361 - val_accuracy1000: 0.3244 - 8s/epoch - 15ms/step
Epoch 5/50
528/528 - 8s - loss: 3.1548 - accuracy1000: 0.4463 - val_loss: 3.4736 - val_accuracy1000: 0.3088 - 8s/epoch - 15ms/step
Epoch 6/50
528/528 - 8s - loss: 3.1438 - accuracy1000: 0.4499 - val_loss: 3.4757 - val_accuracy1000: 0.3112 - 8s/epoch - 15ms/step
Epoch 7/50
528/528 - 8s - loss: 3.1413 - accuracy1000: 0.4534 - val_loss: 3.4371 - val_accuracy1000: 0.3201 - 8s/epoch - 15ms/step
Epoch 8/50
528/528 - 8s - loss: 3.1308 - accuracy1000: 0.4538 - val_loss: 3.4263 - val_accuracy1000: 0.3362 - 8s/epoch - 15ms/step
Epoch 9/50
528/528 - 8s - loss: 3.1198 - accuracy1000: 0.4599 - val_loss: 3.4109 - val_accuracy1000: 0.3447 - 8s/epoch - 15ms/step
Epoch 10/50
528/528 - 8s - loss: 3.1105 - accuracy1000: 0.4633 - val_loss: 3.4251 - val_accuracy1000: 0.3493 - 8s/epoch - 15ms/step
Epoch 11/50
528/528 - 8s - loss: 3.1065 - accuracy1000: 0.4634 - val_loss: 3.4261 - val_accuracy1000: 0.3592 - 8s/epoch - 15ms/step
Epoch 12/50
528/528 - 8s - loss: 3.0965 - accuracy1000: 0.4694 - val_loss: 3.4055 - val_accuracy1000: 0.3577 - 8s/epoch - 15ms/step
Epoch 13/50
528/528 - 8s - loss: 3.0855 - accuracy1000: 0.4740 - val_loss: 3.4333 - val_accuracy1000: 0.3495 - 8s/epoch - 15ms/step
Epoch 14/50
528/528 - 8s - loss: 3.0887 - accuracy1000: 0.4716 - val_loss: 3.4820 - val_accuracy1000: 0.3430 - 8s/epoch - 15ms/step
Epoch 15/50
528/528 - 8s - loss: 3.0793 - accuracy1000: 0.4755 - val_loss: 3.4424 - val_accuracy1000: 0.3499 - 8s/epoch - 15ms/step
Epoch 16/50
528/528 - 8s - loss: 3.0735 - accuracy1000: 0.4761 - val_loss: 3.5085 - val_accuracy1000: 0.3261 - 8s/epoch - 15ms/step
Epoch 17/50
528/528 - 8s - loss: 3.0694 - accuracy1000: 0.4774 - val_loss: 3.4967 - val_accuracy1000: 0.3226 - 8s/epoch - 15ms/step
Epoch 18/50
528/528 - 8s - loss: 3.0565 - accuracy1000: 0.4814 - val_loss: 3.4855 - val_accuracy1000: 0.3313 - 8s/epoch - 15ms/step
Epoch 19/50
528/528 - 8s - loss: 3.0535 - accuracy1000: 0.4830 - val_loss: 3.5038 - val_accuracy1000: 0.3291 - 8s/epoch - 15ms/step
Epoch 20/50
528/528 - 8s - loss: 3.0438 - accuracy1000: 0.4865 - val_loss: 3.4984 - val_accuracy1000: 0.3290 - 8s/epoch - 15ms/step
Epoch 21/50
528/528 - 8s - loss: 3.0388 - accuracy1000: 0.4881 - val_loss: 3.5464 - val_accuracy1000: 0.3240 - 8s/epoch - 15ms/step
Epoch 22/50
528/528 - 8s - loss: 3.0347 - accuracy1000: 0.4892 - val_loss: 3.5254 - val_accuracy1000: 0.3253 - 8s/epoch - 15ms/step
testing model: results/QRTEA/W2/deepLOB_L1/h1000
Evaluating performance on  test set...
1242/1242 - 8s - 8s/epoch - 7ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1466819
{'0': {'precision': 0.2954649634813434, 'recall': 0.21912856252478893, 'f1-score': 0.25163477366924547, 'support': 88245}, '1': {'precision': 0.42235888678635714, 'recall': 0.5892579744206824, 'f1-score': 0.4920407155122876, 'support': 124241}, '2': {'precision': 0.38484123669590087, 'recall': 0.2887487774538756, 'f1-score': 0.32994086692345254, 'support': 105313}, 'accuracy': 0.386898637188915, 'macro avg': {'precision': 0.3675550289878671, 'recall': 0.365711771466449, 'f1-score': 0.35787211870166186, 'support': 317799}, 'weighted avg': {'precision': 0.37469086219840325, 'recall': 0.386898637188915, 'f1-score': 0.37156883330883433, 'support': 317799}}
[[19337 47278 21630]
 [24053 73210 26978]
 [22056 52848 30409]]
Evaluating performance on  train set...
528/528 - 3s - 3s/epoch - 6ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1276706
{'0': {'precision': 0.38956243944591373, 'recall': 0.31931745009658724, 'f1-score': 0.3509595536630533, 'support': 46590}, '1': {'precision': 0.36150004540088987, 'recall': 0.44642296479031174, 'f1-score': 0.39949826902814717, 'support': 44590}, '2': {'precision': 0.3273883821411426, 'recall': 0.3118626240453652, 'f1-score': 0.3194369627842706, 'support': 43734}, 'accuracy': 0.3589101205212209, 'macro avg': {'precision': 0.3594836223293154, 'recall': 0.3592010129774214, 'f1-score': 0.35663159515849036, 'support': 134914}, 'weighted avg': {'precision': 0.3601331558086746, 'recall': 0.3589101205212209, 'f1-score': 0.35678350320599805, 'support': 134914}}
[[14877 17893 13820]
 [10483 19906 14201]
 [12829 17266 13639]]
Evaluating performance on  val set...
159/159 - 1s - 966ms/epoch - 6ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1365079
{'0': {'precision': 0.36670480549199086, 'recall': 0.31342553785973737, 'f1-score': 0.33797830671889123, 'support': 14316}, '1': {'precision': 0.40367393800229623, 'recall': 0.44636282848800307, 'f1-score': 0.4239464640983903, 'support': 15754}, '2': {'precision': 0.262364018648871, 'recall': 0.27268408551068885, 'f1-score': 0.2674245247856876, 'support': 10525}, 'accuracy': 0.35445251878310136, 'macro avg': {'precision': 0.34424758738105266, 'recall': 0.3441574839528098, 'f1-score': 0.34311643186765645, 'support': 40595}, 'weighted avg': {'precision': 0.353999421381719, 'recall': 0.35445251878310136, 'f1-score': 0.35304823642722133, 'support': 40595}}
[[4487 5848 3981]
 [4634 7032 4088]
 [3115 4540 2870]]
training model: results/QRTEA/W2/deepOF_L1/h10
Epoch 1/50
528/528 - 9s - loss: 3.1251 - accuracy10: 0.3993 - val_loss: 3.2733 - val_accuracy10: 0.5426 - 9s/epoch - 18ms/step
Epoch 2/50
528/528 - 7s - loss: 3.0455 - accuracy10: 0.4172 - val_loss: 3.2438 - val_accuracy10: 0.5655 - 7s/epoch - 14ms/step
Epoch 3/50
528/528 - 7s - loss: 3.0130 - accuracy10: 0.4352 - val_loss: 3.2012 - val_accuracy10: 0.5256 - 7s/epoch - 14ms/step
Epoch 4/50
528/528 - 7s - loss: 2.9881 - accuracy10: 0.4463 - val_loss: 3.1771 - val_accuracy10: 0.5233 - 7s/epoch - 13ms/step
Epoch 5/50
528/528 - 7s - loss: 2.9713 - accuracy10: 0.4510 - val_loss: 3.1664 - val_accuracy10: 0.5181 - 7s/epoch - 13ms/step
Epoch 6/50
528/528 - 7s - loss: 2.9561 - accuracy10: 0.4636 - val_loss: 3.1572 - val_accuracy10: 0.5196 - 7s/epoch - 14ms/step
Epoch 7/50
528/528 - 7s - loss: 2.9338 - accuracy10: 0.4759 - val_loss: 3.1387 - val_accuracy10: 0.5372 - 7s/epoch - 13ms/step
Epoch 8/50
528/528 - 7s - loss: 2.9210 - accuracy10: 0.4799 - val_loss: 3.1339 - val_accuracy10: 0.5253 - 7s/epoch - 14ms/step
Epoch 9/50
528/528 - 7s - loss: 2.9068 - accuracy10: 0.4894 - val_loss: 3.1192 - val_accuracy10: 0.5361 - 7s/epoch - 14ms/step
Epoch 10/50
528/528 - 7s - loss: 2.8918 - accuracy10: 0.4936 - val_loss: 3.1135 - val_accuracy10: 0.5342 - 7s/epoch - 13ms/step
Epoch 11/50
528/528 - 7s - loss: 2.8805 - accuracy10: 0.4987 - val_loss: 3.1049 - val_accuracy10: 0.5260 - 7s/epoch - 14ms/step
Epoch 12/50
528/528 - 7s - loss: 2.8680 - accuracy10: 0.4993 - val_loss: 3.1010 - val_accuracy10: 0.5341 - 7s/epoch - 14ms/step
Epoch 13/50
528/528 - 7s - loss: 2.8561 - accuracy10: 0.5059 - val_loss: 3.0861 - val_accuracy10: 0.5361 - 7s/epoch - 13ms/step
Epoch 14/50
528/528 - 7s - loss: 2.8436 - accuracy10: 0.5087 - val_loss: 3.0838 - val_accuracy10: 0.5296 - 7s/epoch - 13ms/step
Epoch 15/50
528/528 - 7s - loss: 2.8322 - accuracy10: 0.5137 - val_loss: 3.0849 - val_accuracy10: 0.5537 - 7s/epoch - 13ms/step
Epoch 16/50
528/528 - 7s - loss: 2.8174 - accuracy10: 0.5190 - val_loss: 3.0680 - val_accuracy10: 0.5333 - 7s/epoch - 13ms/step
Epoch 17/50
528/528 - 7s - loss: 2.8062 - accuracy10: 0.5205 - val_loss: 3.0681 - val_accuracy10: 0.5289 - 7s/epoch - 14ms/step
Epoch 18/50
528/528 - 7s - loss: 2.7918 - accuracy10: 0.5249 - val_loss: 3.0615 - val_accuracy10: 0.5357 - 7s/epoch - 14ms/step
Epoch 19/50
528/528 - 7s - loss: 2.7807 - accuracy10: 0.5224 - val_loss: 3.0509 - val_accuracy10: 0.5272 - 7s/epoch - 14ms/step
Epoch 20/50
528/528 - 7s - loss: 2.7638 - accuracy10: 0.5288 - val_loss: 3.0547 - val_accuracy10: 0.5415 - 7s/epoch - 13ms/step
Epoch 21/50
528/528 - 7s - loss: 2.7546 - accuracy10: 0.5320 - val_loss: 3.0495 - val_accuracy10: 0.5397 - 7s/epoch - 13ms/step
Epoch 22/50
528/528 - 7s - loss: 2.7398 - accuracy10: 0.5329 - val_loss: 3.0511 - val_accuracy10: 0.5325 - 7s/epoch - 14ms/step
Epoch 23/50
528/528 - 7s - loss: 2.7289 - accuracy10: 0.5331 - val_loss: 3.0689 - val_accuracy10: 0.5371 - 7s/epoch - 14ms/step
Epoch 24/50
528/528 - 7s - loss: 2.7175 - accuracy10: 0.5369 - val_loss: 3.0424 - val_accuracy10: 0.5313 - 7s/epoch - 13ms/step
Epoch 25/50
528/528 - 7s - loss: 2.7085 - accuracy10: 0.5396 - val_loss: 3.0614 - val_accuracy10: 0.5425 - 7s/epoch - 13ms/step
Epoch 26/50
528/528 - 7s - loss: 2.6960 - accuracy10: 0.5382 - val_loss: 3.0735 - val_accuracy10: 0.5602 - 7s/epoch - 13ms/step
Epoch 27/50
528/528 - 7s - loss: 2.6887 - accuracy10: 0.5394 - val_loss: 3.0684 - val_accuracy10: 0.5603 - 7s/epoch - 13ms/step
Epoch 28/50
528/528 - 7s - loss: 2.6739 - accuracy10: 0.5408 - val_loss: 3.0591 - val_accuracy10: 0.5581 - 7s/epoch - 13ms/step
Epoch 29/50
528/528 - 7s - loss: 2.6623 - accuracy10: 0.5465 - val_loss: 3.0810 - val_accuracy10: 0.5652 - 7s/epoch - 13ms/step
Epoch 30/50
528/528 - 7s - loss: 2.6512 - accuracy10: 0.5466 - val_loss: 3.0746 - val_accuracy10: 0.5627 - 7s/epoch - 13ms/step
Epoch 31/50
528/528 - 7s - loss: 2.6399 - accuracy10: 0.5474 - val_loss: 3.0701 - val_accuracy10: 0.5690 - 7s/epoch - 13ms/step
Epoch 32/50
528/528 - 7s - loss: 2.6251 - accuracy10: 0.5514 - val_loss: 3.0839 - val_accuracy10: 0.5762 - 7s/epoch - 13ms/step
Epoch 33/50
528/528 - 7s - loss: 2.6197 - accuracy10: 0.5517 - val_loss: 3.0947 - val_accuracy10: 0.5829 - 7s/epoch - 13ms/step
Epoch 34/50
528/528 - 7s - loss: 2.6047 - accuracy10: 0.5538 - val_loss: 3.1054 - val_accuracy10: 0.5816 - 7s/epoch - 13ms/step
testing model: results/QRTEA/W2/deepOF_L1/h10
Evaluating performance on  test set...
1242/1242 - 8s - 8s/epoch - 7ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.98574764
{'0': {'precision': 0.2950109378307812, 'recall': 0.41574843868093403, 'f1-score': 0.34512478020027576, 'support': 50278}, '1': {'precision': 0.7999725077954869, 'recall': 0.5087113945132247, 'f1-score': 0.621930367287249, 'support': 217359}, '2': {'precision': 0.2606008204713111, 'recall': 0.5648663197559662, 'f1-score': 0.3566577498033045, 'support': 50157}, 'accuracy': 0.5028666368779776, 'macro avg': {'precision': 0.4518614220325264, 'recall': 0.49644205098337496, 'f1-score': 0.44123763243027647, 'support': 317794}, 'weighted avg': {'precision': 0.6349545290551578, 'recall': 0.5028666368779776, 'f1-score': 0.5362694989804181, 'support': 317794}}
[[ 20903  15322  14053]
 [ 40453 110573  66333]
 [  9499  12326  28332]]
Evaluating performance on  train set...
528/528 - 3s - 3s/epoch - 6ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.94351953
{'0': {'precision': 0.27828915270775734, 'recall': 0.5306704707560628, 'f1-score': 0.3651105231714602, 'support': 16123}, '1': {'precision': 0.878597980196717, 'recall': 0.5203951406275877, 'f1-score': 0.6536388387530974, 'support': 102647}, '2': {'precision': 0.2359695642148951, 'recall': 0.6339589915133494, 'f1-score': 0.34392485675398654, 'support': 16143}, 'accuracy': 0.5352115807965133, 'macro avg': {'precision': 0.46428556570645646, 'recall': 0.5616748676323333, 'f1-score': 0.4542247395595147, 'support': 134913}, 'weighted avg': {'precision': 0.7299634546521139, 'recall': 0.5352115807965133, 'f1-score': 0.5820989957169602, 'support': 134913}}
[[ 8556  3828  3739]
 [19833 53417 29397]
 [ 2356  3553 10234]]
Evaluating performance on  val set...
159/159 - 1s - 950ms/epoch - 6ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.95213205
{'0': {'precision': 0.2866694525699958, 'recall': 0.505526897568165, 'f1-score': 0.36586666666666673, 'support': 5428}, '1': {'precision': 0.8491374748650651, 'recall': 0.5350962019407116, 'f1-score': 0.6564935463415632, 'support': 29989}, '2': {'precision': 0.24034971956450016, 'recall': 0.562874251497006, 'f1-score': 0.3368591410901104, 'support': 5177}, 'accuracy': 0.5346849288072129, 'macro avg': {'precision': 0.458718882333187, 'recall': 0.534499117001961, 'f1-score': 0.4530731180327801, 'support': 40594}, 'weighted avg': {'precision': 0.69628802336463, 'recall': 0.5346849288072129, 'f1-score': 0.5768692171583808, 'support': 40594}}
[[ 2744  1497  1187]
 [ 5919 16047  8023]
 [  909  1354  2914]]
training model: results/QRTEA/W2/deepOF_L1/h20
Epoch 1/50
528/528 - 10s - loss: 3.1342 - accuracy20: 0.4003 - val_loss: 3.2706 - val_accuracy20: 0.4994 - 10s/epoch - 18ms/step
Epoch 2/50
528/528 - 7s - loss: 3.0571 - accuracy20: 0.4120 - val_loss: 3.2377 - val_accuracy20: 0.5197 - 7s/epoch - 14ms/step
Epoch 3/50
528/528 - 7s - loss: 3.0265 - accuracy20: 0.4278 - val_loss: 3.2050 - val_accuracy20: 0.5152 - 7s/epoch - 14ms/step
Epoch 4/50
528/528 - 7s - loss: 3.0005 - accuracy20: 0.4352 - val_loss: 3.1905 - val_accuracy20: 0.5218 - 7s/epoch - 14ms/step
Epoch 5/50
528/528 - 7s - loss: 2.9804 - accuracy20: 0.4450 - val_loss: 3.1732 - val_accuracy20: 0.5204 - 7s/epoch - 13ms/step
Epoch 6/50
528/528 - 7s - loss: 2.9615 - accuracy20: 0.4549 - val_loss: 3.1674 - val_accuracy20: 0.5388 - 7s/epoch - 14ms/step
Epoch 7/50
528/528 - 7s - loss: 2.9414 - accuracy20: 0.4649 - val_loss: 3.1496 - val_accuracy20: 0.5243 - 7s/epoch - 14ms/step
Epoch 8/50
528/528 - 7s - loss: 2.9347 - accuracy20: 0.4727 - val_loss: 3.1419 - val_accuracy20: 0.5188 - 7s/epoch - 14ms/step
Epoch 9/50
528/528 - 7s - loss: 2.9092 - accuracy20: 0.4824 - val_loss: 3.1333 - val_accuracy20: 0.5284 - 7s/epoch - 14ms/step
Epoch 10/50
528/528 - 7s - loss: 2.8942 - accuracy20: 0.4908 - val_loss: 3.1300 - val_accuracy20: 0.5383 - 7s/epoch - 14ms/step
Epoch 11/50
528/528 - 7s - loss: 2.8779 - accuracy20: 0.4956 - val_loss: 3.1132 - val_accuracy20: 0.5353 - 7s/epoch - 14ms/step
Epoch 12/50
528/528 - 7s - loss: 2.8675 - accuracy20: 0.5014 - val_loss: 3.1090 - val_accuracy20: 0.5523 - 7s/epoch - 14ms/step
Epoch 13/50
528/528 - 7s - loss: 2.8548 - accuracy20: 0.5073 - val_loss: 3.1080 - val_accuracy20: 0.5544 - 7s/epoch - 14ms/step
Epoch 14/50
528/528 - 7s - loss: 2.8434 - accuracy20: 0.5088 - val_loss: 3.0998 - val_accuracy20: 0.5606 - 7s/epoch - 14ms/step
Epoch 15/50
528/528 - 7s - loss: 2.8340 - accuracy20: 0.5094 - val_loss: 3.1038 - val_accuracy20: 0.5634 - 7s/epoch - 13ms/step
Epoch 16/50
528/528 - 7s - loss: 2.8225 - accuracy20: 0.5128 - val_loss: 3.0971 - val_accuracy20: 0.5744 - 7s/epoch - 13ms/step
Epoch 17/50
528/528 - 7s - loss: 2.8140 - accuracy20: 0.5156 - val_loss: 3.1018 - val_accuracy20: 0.5749 - 7s/epoch - 13ms/step
Epoch 18/50
528/528 - 7s - loss: 2.7996 - accuracy20: 0.5207 - val_loss: 3.1002 - val_accuracy20: 0.5930 - 7s/epoch - 13ms/step
Epoch 19/50
528/528 - 7s - loss: 2.7931 - accuracy20: 0.5187 - val_loss: 3.0990 - val_accuracy20: 0.5903 - 7s/epoch - 13ms/step
Epoch 20/50
528/528 - 7s - loss: 2.7824 - accuracy20: 0.5220 - val_loss: 3.0870 - val_accuracy20: 0.5829 - 7s/epoch - 14ms/step
Epoch 21/50
528/528 - 7s - loss: 2.7708 - accuracy20: 0.5237 - val_loss: 3.0828 - val_accuracy20: 0.5842 - 7s/epoch - 14ms/step
Epoch 22/50
528/528 - 7s - loss: 2.7638 - accuracy20: 0.5246 - val_loss: 3.0948 - val_accuracy20: 0.5891 - 7s/epoch - 14ms/step
Epoch 23/50
528/528 - 7s - loss: 2.7530 - accuracy20: 0.5256 - val_loss: 3.0841 - val_accuracy20: 0.5803 - 7s/epoch - 13ms/step
Epoch 24/50
528/528 - 7s - loss: 2.7454 - accuracy20: 0.5276 - val_loss: 3.0731 - val_accuracy20: 0.5734 - 7s/epoch - 14ms/step
Epoch 25/50
528/528 - 7s - loss: 2.7312 - accuracy20: 0.5306 - val_loss: 3.0872 - val_accuracy20: 0.5805 - 7s/epoch - 13ms/step
Epoch 26/50
528/528 - 7s - loss: 2.7250 - accuracy20: 0.5299 - val_loss: 3.0824 - val_accuracy20: 0.5771 - 7s/epoch - 13ms/step
Epoch 27/50
528/528 - 7s - loss: 2.7079 - accuracy20: 0.5322 - val_loss: 3.0685 - val_accuracy20: 0.5696 - 7s/epoch - 14ms/step
Epoch 28/50
528/528 - 7s - loss: 2.6974 - accuracy20: 0.5356 - val_loss: 3.0722 - val_accuracy20: 0.5691 - 7s/epoch - 14ms/step
Epoch 29/50
528/528 - 7s - loss: 2.6887 - accuracy20: 0.5371 - val_loss: 3.0898 - val_accuracy20: 0.5802 - 7s/epoch - 14ms/step
Epoch 30/50
528/528 - 7s - loss: 2.6774 - accuracy20: 0.5419 - val_loss: 3.0903 - val_accuracy20: 0.5815 - 7s/epoch - 13ms/step
Epoch 31/50
528/528 - 7s - loss: 2.6644 - accuracy20: 0.5417 - val_loss: 3.0696 - val_accuracy20: 0.5812 - 7s/epoch - 13ms/step
Epoch 32/50
528/528 - 7s - loss: 2.6521 - accuracy20: 0.5469 - val_loss: 3.1009 - val_accuracy20: 0.5863 - 7s/epoch - 14ms/step
Epoch 33/50
528/528 - 7s - loss: 2.6445 - accuracy20: 0.5452 - val_loss: 3.1024 - val_accuracy20: 0.5823 - 7s/epoch - 13ms/step
Epoch 34/50
528/528 - 7s - loss: 2.6360 - accuracy20: 0.5495 - val_loss: 3.1128 - val_accuracy20: 0.5895 - 7s/epoch - 13ms/step
Epoch 35/50
528/528 - 7s - loss: 2.6241 - accuracy20: 0.5520 - val_loss: 3.0887 - val_accuracy20: 0.5771 - 7s/epoch - 13ms/step
Epoch 36/50
528/528 - 7s - loss: 2.6136 - accuracy20: 0.5565 - val_loss: 3.1154 - val_accuracy20: 0.5700 - 7s/epoch - 13ms/step
Epoch 37/50
528/528 - 7s - loss: 2.6018 - accuracy20: 0.5604 - val_loss: 3.1204 - val_accuracy20: 0.5847 - 7s/epoch - 13ms/step
testing model: results/QRTEA/W2/deepOF_L1/h20
Evaluating performance on  test set...
1242/1242 - 6s - 6s/epoch - 5ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.9844245
{'0': {'precision': 0.3730496453900709, 'recall': 0.33281891416401743, 'f1-score': 0.3517878115620514, 'support': 64798}, '1': {'precision': 0.6799180397654712, 'recall': 0.6392789100398649, 'f1-score': 0.6589725111809136, 'support': 187383}, '2': {'precision': 0.3561294017971146, 'recall': 0.4548488866535595, 'f1-score': 0.39948063769124714, 'support': 65613}, 'accuracy': 0.5387137579689988, 'macro avg': {'precision': 0.4696990289842189, 'recall': 0.4756489036191473, 'f1-score': 0.47008032014473744, 'support': 317794}, 'weighted avg': {'precision': 0.5504970874449272, 'recall': 0.5387137579689988, 'f1-score': 0.5427620274676259, 'support': 317794}}
[[ 21566  29519  13713]
 [ 27349 119790  40244]
 [  8895  26874  29844]]
Evaluating performance on  train set...
528/528 - 3s - 3s/epoch - 5ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.92080265
{'0': {'precision': 0.3699344993881811, 'recall': 0.47412361623616234, 'f1-score': 0.41559859297295115, 'support': 21680}, '1': {'precision': 0.7869694327902795, 'recall': 0.63223497740181, 'f1-score': 0.7011669326601574, 'support': 91379}, '2': {'precision': 0.340352958623758, 'recall': 0.5250755010524389, 'f1-score': 0.4130000539869351, 'support': 21854}, 'accuracy': 0.5894687687620911, 'macro avg': {'precision': 0.4990856302674062, 'recall': 0.5438113648968037, 'f1-score': 0.5099218598733479, 'support': 134913}, 'weighted avg': {'precision': 0.6476079644173824, 'recall': 0.5894687687620911, 'f1-score': 0.6085982360116267, 'support': 134913}}
[[10279  7795  3606]
 [14972 57773 18634]
 [ 2535  7844 11475]]
Evaluating performance on  val set...
159/159 - 1s - 941ms/epoch - 6ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.94877666
{'0': {'precision': 0.3624272651704073, 'recall': 0.4198651809052139, 'f1-score': 0.38903760356915235, 'support': 7269}, '1': {'precision': 0.7427793872355368, 'recall': 0.6411305599757521, 'f1-score': 0.6882218968602569, 'support': 26394}, '2': {'precision': 0.33468214247683953, 'recall': 0.4534699177607849, 'f1-score': 0.3851243720132337, 'support': 6931}, 'accuracy': 0.5694683943439918, 'macro avg': {'precision': 0.47996293162759457, 'recall': 0.504821886213917, 'f1-score': 0.48746129081421435, 'support': 40594}, 'weighted avg': {'precision': 0.6049929759749082, 'recall': 0.5694683943439918, 'f1-score': 0.5828974752056341, 'support': 40594}}
[[ 3052  3089  1128]
 [ 4352 16922  5120]
 [ 1017  2771  3143]]
training model: results/QRTEA/W2/deepOF_L1/h30
Epoch 1/50
528/528 - 9s - loss: 3.1428 - accuracy30: 0.4004 - val_loss: 3.3092 - val_accuracy30: 0.5202 - 9s/epoch - 17ms/step
Epoch 2/50
528/528 - 7s - loss: 3.0653 - accuracy30: 0.4151 - val_loss: 3.2286 - val_accuracy30: 0.5040 - 7s/epoch - 14ms/step
Epoch 3/50
528/528 - 8s - loss: 3.0362 - accuracy30: 0.4185 - val_loss: 3.2217 - val_accuracy30: 0.4905 - 8s/epoch - 14ms/step
Epoch 4/50
528/528 - 7s - loss: 3.0112 - accuracy30: 0.4301 - val_loss: 3.2067 - val_accuracy30: 0.5022 - 7s/epoch - 14ms/step
Epoch 5/50
528/528 - 7s - loss: 2.9963 - accuracy30: 0.4396 - val_loss: 3.2050 - val_accuracy30: 0.5095 - 7s/epoch - 14ms/step
Epoch 6/50
528/528 - 7s - loss: 2.9802 - accuracy30: 0.4442 - val_loss: 3.1962 - val_accuracy30: 0.5096 - 7s/epoch - 14ms/step
Epoch 7/50
528/528 - 7s - loss: 2.9635 - accuracy30: 0.4502 - val_loss: 3.1935 - val_accuracy30: 0.5029 - 7s/epoch - 13ms/step
Epoch 8/50
528/528 - 7s - loss: 2.9493 - accuracy30: 0.4546 - val_loss: 3.1928 - val_accuracy30: 0.5263 - 7s/epoch - 14ms/step
Epoch 9/50
528/528 - 7s - loss: 2.9346 - accuracy30: 0.4590 - val_loss: 3.1641 - val_accuracy30: 0.5279 - 7s/epoch - 14ms/step
Epoch 10/50
528/528 - 7s - loss: 2.9225 - accuracy30: 0.4651 - val_loss: 3.1659 - val_accuracy30: 0.5192 - 7s/epoch - 13ms/step
Epoch 11/50
528/528 - 7s - loss: 2.9116 - accuracy30: 0.4688 - val_loss: 3.1648 - val_accuracy30: 0.5188 - 7s/epoch - 13ms/step
Epoch 12/50
528/528 - 7s - loss: 2.9005 - accuracy30: 0.4721 - val_loss: 3.1552 - val_accuracy30: 0.5302 - 7s/epoch - 14ms/step
Epoch 13/50
528/528 - 7s - loss: 2.8859 - accuracy30: 0.4771 - val_loss: 3.1524 - val_accuracy30: 0.5319 - 7s/epoch - 14ms/step
Epoch 14/50
528/528 - 7s - loss: 2.8778 - accuracy30: 0.4804 - val_loss: 3.1425 - val_accuracy30: 0.5140 - 7s/epoch - 14ms/step
Epoch 15/50
528/528 - 7s - loss: 2.8650 - accuracy30: 0.4847 - val_loss: 3.1456 - val_accuracy30: 0.5440 - 7s/epoch - 13ms/step
Epoch 16/50
528/528 - 7s - loss: 2.8514 - accuracy30: 0.4896 - val_loss: 3.1537 - val_accuracy30: 0.5364 - 7s/epoch - 13ms/step
Epoch 17/50
528/528 - 7s - loss: 2.8487 - accuracy30: 0.4900 - val_loss: 3.1504 - val_accuracy30: 0.5494 - 7s/epoch - 13ms/step
Epoch 18/50
528/528 - 7s - loss: 2.8359 - accuracy30: 0.4947 - val_loss: 3.1363 - val_accuracy30: 0.5413 - 7s/epoch - 14ms/step
Epoch 19/50
528/528 - 7s - loss: 2.8262 - accuracy30: 0.4966 - val_loss: 3.1359 - val_accuracy30: 0.5431 - 7s/epoch - 14ms/step
Epoch 20/50
528/528 - 7s - loss: 2.8210 - accuracy30: 0.5003 - val_loss: 3.1330 - val_accuracy30: 0.5443 - 7s/epoch - 13ms/step
Epoch 21/50
528/528 - 7s - loss: 2.8094 - accuracy30: 0.5044 - val_loss: 3.1257 - val_accuracy30: 0.5417 - 7s/epoch - 14ms/step
Epoch 22/50
528/528 - 7s - loss: 2.7977 - accuracy30: 0.5065 - val_loss: 3.1369 - val_accuracy30: 0.5613 - 7s/epoch - 13ms/step
Epoch 23/50
528/528 - 7s - loss: 2.7888 - accuracy30: 0.5125 - val_loss: 3.1268 - val_accuracy30: 0.5476 - 7s/epoch - 13ms/step
Epoch 24/50
528/528 - 7s - loss: 2.7811 - accuracy30: 0.5127 - val_loss: 3.1266 - val_accuracy30: 0.5495 - 7s/epoch - 13ms/step
Epoch 25/50
528/528 - 7s - loss: 2.7689 - accuracy30: 0.5155 - val_loss: 3.1092 - val_accuracy30: 0.5491 - 7s/epoch - 13ms/step
Epoch 26/50
528/528 - 7s - loss: 2.7597 - accuracy30: 0.5204 - val_loss: 3.1076 - val_accuracy30: 0.5433 - 7s/epoch - 13ms/step
Epoch 27/50
528/528 - 7s - loss: 2.7522 - accuracy30: 0.5221 - val_loss: 3.1071 - val_accuracy30: 0.5344 - 7s/epoch - 13ms/step
Epoch 28/50
528/528 - 7s - loss: 2.7392 - accuracy30: 0.5218 - val_loss: 3.1018 - val_accuracy30: 0.5444 - 7s/epoch - 13ms/step
Epoch 29/50
528/528 - 7s - loss: 2.7278 - accuracy30: 0.5263 - val_loss: 3.1028 - val_accuracy30: 0.5444 - 7s/epoch - 13ms/step
Epoch 30/50
528/528 - 7s - loss: 2.7244 - accuracy30: 0.5281 - val_loss: 3.0984 - val_accuracy30: 0.5463 - 7s/epoch - 14ms/step
Epoch 31/50
528/528 - 7s - loss: 2.7094 - accuracy30: 0.5318 - val_loss: 3.0892 - val_accuracy30: 0.5350 - 7s/epoch - 14ms/step
Epoch 32/50
528/528 - 7s - loss: 2.6993 - accuracy30: 0.5331 - val_loss: 3.1005 - val_accuracy30: 0.5485 - 7s/epoch - 13ms/step
Epoch 33/50
528/528 - 7s - loss: 2.6918 - accuracy30: 0.5335 - val_loss: 3.0773 - val_accuracy30: 0.5349 - 7s/epoch - 14ms/step
Epoch 34/50
528/528 - 7s - loss: 2.6783 - accuracy30: 0.5404 - val_loss: 3.0907 - val_accuracy30: 0.5428 - 7s/epoch - 14ms/step
Epoch 35/50
528/528 - 7s - loss: 2.6713 - accuracy30: 0.5400 - val_loss: 3.0997 - val_accuracy30: 0.5490 - 7s/epoch - 13ms/step
Epoch 36/50
528/528 - 7s - loss: 2.6606 - accuracy30: 0.5425 - val_loss: 3.1249 - val_accuracy30: 0.5434 - 7s/epoch - 13ms/step
Epoch 37/50
528/528 - 7s - loss: 2.6501 - accuracy30: 0.5472 - val_loss: 3.0940 - val_accuracy30: 0.5412 - 7s/epoch - 14ms/step
Epoch 38/50
528/528 - 7s - loss: 2.6328 - accuracy30: 0.5517 - val_loss: 3.1065 - val_accuracy30: 0.5457 - 7s/epoch - 13ms/step
Epoch 39/50
528/528 - 7s - loss: 2.6317 - accuracy30: 0.5511 - val_loss: 3.1113 - val_accuracy30: 0.5457 - 7s/epoch - 14ms/step
Epoch 40/50
528/528 - 7s - loss: 2.6212 - accuracy30: 0.5516 - val_loss: 3.1241 - val_accuracy30: 0.5562 - 7s/epoch - 13ms/step
Epoch 41/50
528/528 - 7s - loss: 2.6058 - accuracy30: 0.5580 - val_loss: 3.1217 - val_accuracy30: 0.5479 - 7s/epoch - 13ms/step
Epoch 42/50
528/528 - 7s - loss: 2.5968 - accuracy30: 0.5586 - val_loss: 3.1301 - val_accuracy30: 0.5415 - 7s/epoch - 13ms/step
Epoch 43/50
528/528 - 7s - loss: 2.5866 - accuracy30: 0.5614 - val_loss: 3.1643 - val_accuracy30: 0.5453 - 7s/epoch - 13ms/step
testing model: results/QRTEA/W2/deepOF_L1/h30
Evaluating performance on  test set...
1242/1242 - 7s - 7s/epoch - 6ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.0022637
{'0': {'precision': 0.39093877185920656, 'recall': 0.3546812021532718, 'f1-score': 0.37192843111530305, 'support': 73934}, '1': {'precision': 0.6494416038282051, 'recall': 0.55581956251791, 'f1-score': 0.5989944058598538, 'support': 167504}, '2': {'precision': 0.3694672131147541, 'recall': 0.5194876630520194, 'f1-score': 0.4318186766530949, 'support': 76356}, 'accuracy': 0.5002957890960811, 'macro avg': {'precision': 0.46994919626738857, 'recall': 0.476662809241067, 'f1-score': 0.4675805045427506, 'support': 317794}, 'weighted avg': {'precision': 0.5220324238055735, 'recall': 0.5002957890960811, 'f1-score': 0.5060009391610649, 'support': 317794}}
[[26223 26221 21490]
 [28198 93102 46204]
 [12656 24034 39666]]
Evaluating performance on  train set...
528/528 - 3s - 3s/epoch - 5ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.91271514
{'0': {'precision': 0.41625024985008996, 'recall': 0.4887732749178532, 'f1-score': 0.4496059875499262, 'support': 25564}, '1': {'precision': 0.7569858760501643, 'recall': 0.5955813675008981, 'f1-score': 0.6666532630986368, 'support': 83510}, '2': {'precision': 0.3771784338240923, 'recall': 0.5720809628855605, 'f1-score': 0.4546209441796094, 'support': 25839}, 'accuracy': 0.5708419499974058, 'macro avg': {'precision': 0.5168048532414489, 'recall': 0.552145201768104, 'f1-score': 0.5236267316093909, 'support': 134913}, 'weighted avg': {'precision': 0.6196795375367656, 'recall': 0.5708419499974058, 'f1-score': 0.5849168875034312, 'support': 134913}}
[[12495  8021  5048]
 [14412 49737 19361]
 [ 3111  7946 14782]]
Evaluating performance on  val set...
159/159 - 1s - 975ms/epoch - 6ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.95618755
{'0': {'precision': 0.3954008304056212, 'recall': 0.43256464011180995, 'f1-score': 0.4131486734523611, 'support': 8586}, '1': {'precision': 0.706007496707527, 'recall': 0.5837905759162304, 'f1-score': 0.6391086044432217, 'support': 23875}, '2': {'precision': 0.35352124967274634, 'recall': 0.49809418418787654, 'f1-score': 0.4135361371988567, 'support': 8133}, 'accuracy': 0.5346356604424299, 'macro avg': {'precision': 0.4849765255952982, 'recall': 0.5048164667386389, 'f1-score': 0.4885978050314798, 'support': 40594}, 'weighted avg': {'precision': 0.56969081236989, 'recall': 0.5346356604424299, 'f1-score': 0.5461226251461347, 'support': 40594}}
[[ 3714  3043  1829]
 [ 4358 13938  5579]
 [ 1321  2761  4051]]
training model: results/QRTEA/W2/deepOF_L1/h50
Epoch 1/50
528/528 - 9s - loss: 3.1798 - accuracy50: 0.4066 - val_loss: 3.2860 - val_accuracy50: 0.4599 - 9s/epoch - 17ms/step
Epoch 2/50
528/528 - 7s - loss: 3.1171 - accuracy50: 0.4168 - val_loss: 3.2634 - val_accuracy50: 0.4654 - 7s/epoch - 14ms/step
Epoch 3/50
528/528 - 7s - loss: 3.0921 - accuracy50: 0.4209 - val_loss: 3.2310 - val_accuracy50: 0.4550 - 7s/epoch - 13ms/step
Epoch 4/50
528/528 - 7s - loss: 3.0765 - accuracy50: 0.4243 - val_loss: 3.2326 - val_accuracy50: 0.4517 - 7s/epoch - 14ms/step
Epoch 5/50
528/528 - 7s - loss: 3.0611 - accuracy50: 0.4281 - val_loss: 3.2232 - val_accuracy50: 0.4411 - 7s/epoch - 14ms/step
Epoch 6/50
528/528 - 7s - loss: 3.0488 - accuracy50: 0.4283 - val_loss: 3.2322 - val_accuracy50: 0.4588 - 7s/epoch - 13ms/step
Epoch 7/50
528/528 - 7s - loss: 3.0333 - accuracy50: 0.4367 - val_loss: 3.2135 - val_accuracy50: 0.4531 - 7s/epoch - 13ms/step
Epoch 8/50
528/528 - 7s - loss: 3.0203 - accuracy50: 0.4455 - val_loss: 3.2106 - val_accuracy50: 0.4577 - 7s/epoch - 13ms/step
Epoch 9/50
528/528 - 7s - loss: 3.0058 - accuracy50: 0.4473 - val_loss: 3.1998 - val_accuracy50: 0.4628 - 7s/epoch - 13ms/step
Epoch 10/50
528/528 - 7s - loss: 2.9960 - accuracy50: 0.4558 - val_loss: 3.1902 - val_accuracy50: 0.4612 - 7s/epoch - 14ms/step
Epoch 11/50
528/528 - 7s - loss: 2.9831 - accuracy50: 0.4575 - val_loss: 3.1845 - val_accuracy50: 0.4596 - 7s/epoch - 13ms/step
Epoch 12/50
528/528 - 7s - loss: 2.9714 - accuracy50: 0.4620 - val_loss: 3.1861 - val_accuracy50: 0.4738 - 7s/epoch - 13ms/step
Epoch 13/50
528/528 - 7s - loss: 2.9598 - accuracy50: 0.4689 - val_loss: 3.1815 - val_accuracy50: 0.4783 - 7s/epoch - 13ms/step
Epoch 14/50
528/528 - 7s - loss: 2.9530 - accuracy50: 0.4684 - val_loss: 3.1764 - val_accuracy50: 0.4703 - 7s/epoch - 13ms/step
Epoch 15/50
528/528 - 7s - loss: 2.9424 - accuracy50: 0.4725 - val_loss: 3.1813 - val_accuracy50: 0.4739 - 7s/epoch - 14ms/step
Epoch 16/50
528/528 - 7s - loss: 2.9340 - accuracy50: 0.4749 - val_loss: 3.1793 - val_accuracy50: 0.4743 - 7s/epoch - 13ms/step
Epoch 17/50
528/528 - 7s - loss: 2.9251 - accuracy50: 0.4768 - val_loss: 3.1766 - val_accuracy50: 0.4749 - 7s/epoch - 13ms/step
Epoch 18/50
528/528 - 7s - loss: 2.9122 - accuracy50: 0.4811 - val_loss: 3.1852 - val_accuracy50: 0.4782 - 7s/epoch - 13ms/step
Epoch 19/50
528/528 - 7s - loss: 2.9113 - accuracy50: 0.4830 - val_loss: 3.1849 - val_accuracy50: 0.4933 - 7s/epoch - 13ms/step
Epoch 20/50
528/528 - 7s - loss: 2.8991 - accuracy50: 0.4820 - val_loss: 3.1706 - val_accuracy50: 0.4827 - 7s/epoch - 14ms/step
Epoch 21/50
528/528 - 7s - loss: 2.8895 - accuracy50: 0.4874 - val_loss: 3.1928 - val_accuracy50: 0.4823 - 7s/epoch - 13ms/step
Epoch 22/50
528/528 - 7s - loss: 2.8778 - accuracy50: 0.4916 - val_loss: 3.1766 - val_accuracy50: 0.4889 - 7s/epoch - 13ms/step
Epoch 23/50
528/528 - 7s - loss: 2.8702 - accuracy50: 0.4923 - val_loss: 3.1810 - val_accuracy50: 0.4933 - 7s/epoch - 13ms/step
Epoch 24/50
528/528 - 7s - loss: 2.8631 - accuracy50: 0.4946 - val_loss: 3.1869 - val_accuracy50: 0.4933 - 7s/epoch - 13ms/step
Epoch 25/50
528/528 - 7s - loss: 2.8522 - accuracy50: 0.4974 - val_loss: 3.1991 - val_accuracy50: 0.4923 - 7s/epoch - 14ms/step
Epoch 26/50
528/528 - 7s - loss: 2.8401 - accuracy50: 0.5024 - val_loss: 3.2096 - val_accuracy50: 0.4907 - 7s/epoch - 13ms/step
Epoch 27/50
528/528 - 7s - loss: 2.8285 - accuracy50: 0.5030 - val_loss: 3.1949 - val_accuracy50: 0.4993 - 7s/epoch - 13ms/step
Epoch 28/50
528/528 - 7s - loss: 2.8226 - accuracy50: 0.5043 - val_loss: 3.2122 - val_accuracy50: 0.4936 - 7s/epoch - 13ms/step
Epoch 29/50
528/528 - 7s - loss: 2.8087 - accuracy50: 0.5079 - val_loss: 3.2207 - val_accuracy50: 0.4933 - 7s/epoch - 13ms/step
Epoch 30/50
528/528 - 7s - loss: 2.7993 - accuracy50: 0.5112 - val_loss: 3.1997 - val_accuracy50: 0.4945 - 7s/epoch - 14ms/step
testing model: results/QRTEA/W2/deepOF_L1/h50
Evaluating performance on  test set...
1242/1242 - 8s - 8s/epoch - 6ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.04798
{'0': {'precision': 0.4260076072787014, 'recall': 0.27635740185118685, 'f1-score': 0.33523980832197414, 'support': 86323}, '1': {'precision': 0.4919478311950456, 'recall': 0.5605591278403225, 'f1-score': 0.52401714749777, 'support': 140433}, '2': {'precision': 0.39731370853639364, 'recall': 0.4441771567916694, 'f1-score': 0.41944049705934217, 'support': 91038}, 'accuracy': 0.45002108283982706, 'macro avg': {'precision': 0.4384230490033802, 'recall': 0.42703122882772626, 'f1-score': 0.42623248429302873, 'support': 317794}, 'weighted avg': {'precision': 0.4469266564474766, 'recall': 0.45002108283982706, 'f1-score': 0.4427812671718802, 'support': 317794}}
[[23856 41989 20478]
 [20851 78721 40861]
 [11292 39309 40437]]
Evaluating performance on  train set...
528/528 - 3s - 3s/epoch - 6ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.97910714
{'0': {'precision': 0.46326685180509974, 'recall': 0.4047964200176478, 'f1-score': 0.4320624295733195, 'support': 31732}, '1': {'precision': 0.6064793203248996, 'recall': 0.5483244703300414, 'f1-score': 0.5759375831190708, 'support': 71082}, '2': {'precision': 0.39317334575955265, 'recall': 0.5257173120657964, 'f1-score': 0.44988602887268553, 'support': 32099}, 'accuracy': 0.5091874022518216, 'macro avg': {'precision': 0.48763983929651733, 'recall': 0.4929460674711619, 'f1-score': 0.4859620138550253, 'support': 134913}, 'weighted avg': {'precision': 0.5220447104011461, 'recall': 0.5091874022518216, 'f1-score': 0.5121070018402578, 'support': 134913}}
[[12845 13172  5715]
 [11776 38976 20330]
 [ 3106 12118 16875]]
Evaluating performance on  val set...
159/159 - 1s - 947ms/epoch - 6ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0143385
{'0': {'precision': 0.43616399953276486, 'recall': 0.3505115929785037, 'f1-score': 0.38867492453419383, 'support': 10653}, '1': {'precision': 0.5523278949462793, 'recall': 0.5552277613880694, 'f1-score': 0.55377403186794, 'support': 19999}, '2': {'precision': 0.39274038058512867, 'recall': 0.4712331522832428, 'f1-score': 0.4284211970188834, 'support': 9942}, 'accuracy': 0.4809331428289895, 'macro avg': {'precision': 0.4604107583547243, 'recall': 0.4589908355499386, 'f1-score': 0.45695671780700575, 'support': 40594}, 'weighted avg': {'precision': 0.4827581790863313, 'recall': 0.4809331428289895, 'f1-score': 0.47974686838329406, 'support': 40594}}
[[ 3734  5012  1907]
 [ 3558 11104  5337]
 [ 1269  3988  4685]]
training model: results/QRTEA/W2/deepOF_L1/h100
Epoch 1/50
528/528 - 10s - loss: 3.2437 - accuracy100: 0.4054 - val_loss: 3.2821 - val_accuracy100: 0.4018 - 10s/epoch - 18ms/step
Epoch 2/50
528/528 - 7s - loss: 3.2014 - accuracy100: 0.4214 - val_loss: 3.2563 - val_accuracy100: 0.4104 - 7s/epoch - 14ms/step
Epoch 3/50
528/528 - 7s - loss: 3.1871 - accuracy100: 0.4251 - val_loss: 3.2369 - val_accuracy100: 0.4135 - 7s/epoch - 13ms/step
Epoch 4/50
528/528 - 7s - loss: 3.1743 - accuracy100: 0.4283 - val_loss: 3.2318 - val_accuracy100: 0.4129 - 7s/epoch - 13ms/step
Epoch 5/50
528/528 - 7s - loss: 3.1639 - accuracy100: 0.4311 - val_loss: 3.2319 - val_accuracy100: 0.4164 - 7s/epoch - 14ms/step
Epoch 6/50
528/528 - 7s - loss: 3.1545 - accuracy100: 0.4335 - val_loss: 3.2343 - val_accuracy100: 0.4162 - 7s/epoch - 14ms/step
Epoch 7/50
528/528 - 7s - loss: 3.1427 - accuracy100: 0.4380 - val_loss: 3.2289 - val_accuracy100: 0.4175 - 7s/epoch - 14ms/step
Epoch 8/50
528/528 - 7s - loss: 3.1339 - accuracy100: 0.4402 - val_loss: 3.2401 - val_accuracy100: 0.4174 - 7s/epoch - 14ms/step
Epoch 9/50
528/528 - 7s - loss: 3.1287 - accuracy100: 0.4442 - val_loss: 3.2328 - val_accuracy100: 0.4210 - 7s/epoch - 13ms/step
Epoch 10/50
528/528 - 7s - loss: 3.1191 - accuracy100: 0.4481 - val_loss: 3.2367 - val_accuracy100: 0.4200 - 7s/epoch - 14ms/step
Epoch 11/50
528/528 - 7s - loss: 3.1081 - accuracy100: 0.4534 - val_loss: 3.2318 - val_accuracy100: 0.4225 - 7s/epoch - 14ms/step
Epoch 12/50
528/528 - 7s - loss: 3.0996 - accuracy100: 0.4566 - val_loss: 3.2309 - val_accuracy100: 0.4219 - 7s/epoch - 14ms/step
Epoch 13/50
528/528 - 7s - loss: 3.0922 - accuracy100: 0.4592 - val_loss: 3.2341 - val_accuracy100: 0.4234 - 7s/epoch - 14ms/step
Epoch 14/50
528/528 - 7s - loss: 3.0853 - accuracy100: 0.4628 - val_loss: 3.2452 - val_accuracy100: 0.4207 - 7s/epoch - 13ms/step
Epoch 15/50
528/528 - 7s - loss: 3.0762 - accuracy100: 0.4666 - val_loss: 3.2483 - val_accuracy100: 0.4191 - 7s/epoch - 13ms/step
Epoch 16/50
528/528 - 7s - loss: 3.0703 - accuracy100: 0.4692 - val_loss: 3.2365 - val_accuracy100: 0.4235 - 7s/epoch - 13ms/step
Epoch 17/50
528/528 - 7s - loss: 3.0654 - accuracy100: 0.4688 - val_loss: 3.2330 - val_accuracy100: 0.4261 - 7s/epoch - 13ms/step
testing model: results/QRTEA/W2/deepOF_L1/h100
Evaluating performance on  test set...
1242/1242 - 7s - 7s/epoch - 5ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.081599
{'0': {'precision': 0.46487160866245836, 'recall': 0.23812476154139642, 'f1-score': 0.31493033435724066, 'support': 104840}, '1': {'precision': 0.32586697497432326, 'recall': 0.5850488195641003, 'f1-score': 0.418585538173167, 'support': 99243}, '2': {'precision': 0.45942454081988965, 'recall': 0.3471168136767771, 'f1-score': 0.3954514715090795, 'support': 113711}, 'accuracy': 0.3854635392738692, 'macro avg': {'precision': 0.4167210414855571, 'recall': 0.39009679826075794, 'f1-score': 0.3763224480131624, 'support': 317794}, 'weighted avg': {'precision': 0.4195132054435244, 'recall': 0.3854635392738692, 'f1-score': 0.37611208234171084, 'support': 317794}}
[[24965 58700 21175]
 [15913 58062 25268]
 [12825 61415 39471]]
Evaluating performance on  train set...
528/528 - 3s - 3s/epoch - 6ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0492564
{'0': {'precision': 0.485969343621328, 'recall': 0.3383766593586624, 'f1-score': 0.3989603454152937, 'support': 41507}, '1': {'precision': 0.4101640597436199, 'recall': 0.545965090795241, 'f1-score': 0.4684205224632328, 'support': 51104}, '2': {'precision': 0.4456144045488049, 'recall': 0.40017020471845305, 'f1-score': 0.42167144102627974, 'support': 42302}, 'accuracy': 0.43638492954718966, 'macro avg': {'precision': 0.44724926930458425, 'recall': 0.4281706516241188, 'f1-score': 0.4296841029682687, 'support': 134913}, 'weighted avg': {'precision': 0.44460158914301773, 'recall': 0.43638492954718966, 'f1-score': 0.4323923916554174, 'support': 134913}}
[[14045 19661  7801]
 [ 9944 27901 13259]
 [ 4912 20462 16928]]
Evaluating performance on  val set...
159/159 - 1s - 955ms/epoch - 6ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0665456
{'0': {'precision': 0.4755528255528256, 'recall': 0.2804869212375915, 'f1-score': 0.3528553848958571, 'support': 13801}, '1': {'precision': 0.3806586228794339, 'recall': 0.5849306475221301, 'f1-score': 0.46118759102025114, 'support': 14347}, '2': {'precision': 0.45618754803996925, 'recall': 0.38148802828217904, 'f1-score': 0.41550713223068175, 'support': 12446}, 'accuracy': 0.4190520766615756, 'macro avg': {'precision': 0.43746633215740954, 'recall': 0.4156351990139669, 'f1-score': 0.40985003604893006, 'support': 40594}, 'weighted avg': {'precision': 0.43607735209171905, 'recall': 0.4190520766615756, 'f1-score': 0.41035170968759743, 'support': 40594}}
[[3871 7505 2425]
 [2720 8392 3235]
 [1549 6149 4748]]
training model: results/QRTEA/W2/deepOF_L1/h200
Epoch 1/50
528/528 - 9s - loss: 3.2835 - accuracy200: 0.3861 - val_loss: 3.3502 - val_accuracy200: 0.3461 - 9s/epoch - 17ms/step
Epoch 2/50
528/528 - 7s - loss: 3.2607 - accuracy200: 0.3984 - val_loss: 3.3299 - val_accuracy200: 0.3535 - 7s/epoch - 13ms/step
Epoch 3/50
528/528 - 7s - loss: 3.2443 - accuracy200: 0.4031 - val_loss: 3.3256 - val_accuracy200: 0.3563 - 7s/epoch - 14ms/step
Epoch 4/50
528/528 - 7s - loss: 3.2391 - accuracy200: 0.4062 - val_loss: 3.3145 - val_accuracy200: 0.3603 - 7s/epoch - 14ms/step
Epoch 5/50
528/528 - 7s - loss: 3.2315 - accuracy200: 0.4091 - val_loss: 3.3078 - val_accuracy200: 0.3643 - 7s/epoch - 14ms/step
Epoch 6/50
528/528 - 7s - loss: 3.2274 - accuracy200: 0.4096 - val_loss: 3.3032 - val_accuracy200: 0.3644 - 7s/epoch - 14ms/step
Epoch 7/50
528/528 - 7s - loss: 3.2218 - accuracy200: 0.4106 - val_loss: 3.2967 - val_accuracy200: 0.3681 - 7s/epoch - 14ms/step
Epoch 8/50
528/528 - 7s - loss: 3.2179 - accuracy200: 0.4142 - val_loss: 3.2904 - val_accuracy200: 0.3694 - 7s/epoch - 14ms/step
Epoch 9/50
528/528 - 7s - loss: 3.2151 - accuracy200: 0.4147 - val_loss: 3.2876 - val_accuracy200: 0.3731 - 7s/epoch - 13ms/step
Epoch 10/50
528/528 - 7s - loss: 3.2109 - accuracy200: 0.4180 - val_loss: 3.2906 - val_accuracy200: 0.3729 - 7s/epoch - 13ms/step
Epoch 11/50
528/528 - 7s - loss: 3.2081 - accuracy200: 0.4186 - val_loss: 3.2848 - val_accuracy200: 0.3720 - 7s/epoch - 14ms/step
Epoch 12/50
528/528 - 7s - loss: 3.2047 - accuracy200: 0.4203 - val_loss: 3.2843 - val_accuracy200: 0.3727 - 7s/epoch - 14ms/step
Epoch 13/50
528/528 - 7s - loss: 3.2004 - accuracy200: 0.4219 - val_loss: 3.2882 - val_accuracy200: 0.3698 - 7s/epoch - 13ms/step
Epoch 14/50
528/528 - 7s - loss: 3.1978 - accuracy200: 0.4232 - val_loss: 3.2853 - val_accuracy200: 0.3711 - 7s/epoch - 13ms/step
Epoch 15/50
528/528 - 7s - loss: 3.1949 - accuracy200: 0.4254 - val_loss: 3.2774 - val_accuracy200: 0.3695 - 7s/epoch - 13ms/step
Epoch 16/50
528/528 - 7s - loss: 3.1908 - accuracy200: 0.4263 - val_loss: 3.2813 - val_accuracy200: 0.3670 - 7s/epoch - 14ms/step
Epoch 17/50
528/528 - 7s - loss: 3.1874 - accuracy200: 0.4293 - val_loss: 3.2796 - val_accuracy200: 0.3700 - 7s/epoch - 13ms/step
Epoch 18/50
528/528 - 7s - loss: 3.1837 - accuracy200: 0.4310 - val_loss: 3.2836 - val_accuracy200: 0.3701 - 7s/epoch - 14ms/step
Epoch 19/50
528/528 - 7s - loss: 3.1800 - accuracy200: 0.4313 - val_loss: 3.2845 - val_accuracy200: 0.3715 - 7s/epoch - 13ms/step
Epoch 20/50
528/528 - 7s - loss: 3.1744 - accuracy200: 0.4337 - val_loss: 3.2911 - val_accuracy200: 0.3694 - 7s/epoch - 13ms/step
Epoch 21/50
528/528 - 7s - loss: 3.1709 - accuracy200: 0.4353 - val_loss: 3.2918 - val_accuracy200: 0.3695 - 7s/epoch - 13ms/step
Epoch 22/50
528/528 - 7s - loss: 3.1678 - accuracy200: 0.4391 - val_loss: 3.2910 - val_accuracy200: 0.3662 - 7s/epoch - 13ms/step
Epoch 23/50
528/528 - 7s - loss: 3.1634 - accuracy200: 0.4388 - val_loss: 3.2969 - val_accuracy200: 0.3672 - 7s/epoch - 14ms/step
Epoch 24/50
528/528 - 7s - loss: 3.1595 - accuracy200: 0.4401 - val_loss: 3.3099 - val_accuracy200: 0.3650 - 7s/epoch - 13ms/step
Epoch 25/50
528/528 - 7s - loss: 3.1555 - accuracy200: 0.4432 - val_loss: 3.3092 - val_accuracy200: 0.3654 - 7s/epoch - 13ms/step
testing model: results/QRTEA/W2/deepOF_L1/h200
Evaluating performance on  test set...
1242/1242 - 8s - 8s/epoch - 6ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0953072
{'0': {'precision': 0.4415251425296371, 'recall': 0.1464212474366028, 'f1-score': 0.21991345893806905, 'support': 99965}, '1': {'precision': 0.34359771902540176, 'recall': 0.7092265892511538, 'f1-score': 0.4629236548266511, 'support': 107472}, '2': {'precision': 0.43091644376512545, 'recall': 0.24524950841360313, 'f1-score': 0.31259203649698264, 'support': 110357}, 'accuracy': 0.3710705677262629, 'macro avg': {'precision': 0.40534643510672147, 'recall': 0.36696578170045324, 'f1-score': 0.3318097167539009, 'support': 317794}, 'weighted avg': {'precision': 0.40472394355041663, 'recall': 0.3710705677262629, 'f1-score': 0.33427849275307725, 'support': 317794}}
[[14637 70249 15079]
 [10586 76222 20664]
 [ 7928 75364 27065]]
Evaluating performance on  train set...
528/528 - 3s - 3s/epoch - 6ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0753897
{'0': {'precision': 0.511322367015595, 'recall': 0.21434168401728346, 'f1-score': 0.30206180688110296, 'support': 44667}, '1': {'precision': 0.34707460710178767, 'recall': 0.667739340305712, 'f1-score': 0.456744548643753, 'support': 44748}, '2': {'precision': 0.46145923317163934, 'recall': 0.30526616554573827, 'f1-score': 0.3674533044076406, 'support': 45498}, 'accuracy': 0.3953881390229259, 'macro avg': {'precision': 0.4399520690963407, 'recall': 0.39578239662291126, 'f1-score': 0.37541988664416553, 'support': 134913}, 'weighted avg': {'precision': 0.44002878059875344, 'recall': 0.3953881390229259, 'f1-score': 0.37541964254451177, 'support': 134913}}
[[ 9574 28230  6863]
 [ 5522 29880  9346]
 [ 3628 27981 13889]]
Evaluating performance on  val set...
159/159 - 1s - 977ms/epoch - 6ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0919621
{'0': {'precision': 0.4743301288607077, 'recall': 0.15629844308148547, 'f1-score': 0.23512115989049984, 'support': 14837}, '1': {'precision': 0.3304593589009731, 'recall': 0.7035034272658035, 'f1-score': 0.4496859938659267, 'support': 13130}, '2': {'precision': 0.44963240036115054, 'recall': 0.2760750772154906, 'f1-score': 0.34210009813542686, 'support': 12627}, 'accuracy': 0.3705473715327388, 'macro avg': {'precision': 0.4181406293742771, 'recall': 0.37862564918759317, 'f1-score': 0.34230241729728444, 'support': 40594}, 'weighted avg': {'precision': 0.4201132143576968, 'recall': 0.3705473715327388, 'f1-score': 0.3377978934796029, 'support': 40594}}
[[ 2319 10544  1974]
 [ 1600  9237  2293]
 [  970  8171  3486]]
training model: results/QRTEA/W2/deepOF_L1/h300
Epoch 1/50
528/528 - 9s - loss: 3.3022 - accuracy300: 0.3667 - val_loss: 3.3094 - val_accuracy300: 0.3491 - 9s/epoch - 18ms/step
Epoch 2/50
528/528 - 7s - loss: 3.2777 - accuracy300: 0.3766 - val_loss: 3.3083 - val_accuracy300: 0.3459 - 7s/epoch - 14ms/step
Epoch 3/50
528/528 - 7s - loss: 3.2657 - accuracy300: 0.3823 - val_loss: 3.3114 - val_accuracy300: 0.3448 - 7s/epoch - 14ms/step
Epoch 4/50
528/528 - 7s - loss: 3.2596 - accuracy300: 0.3856 - val_loss: 3.3075 - val_accuracy300: 0.3506 - 7s/epoch - 14ms/step
Epoch 5/50
528/528 - 7s - loss: 3.2549 - accuracy300: 0.3896 - val_loss: 3.3084 - val_accuracy300: 0.3482 - 7s/epoch - 14ms/step
Epoch 6/50
528/528 - 7s - loss: 3.2511 - accuracy300: 0.3914 - val_loss: 3.3001 - val_accuracy300: 0.3485 - 7s/epoch - 14ms/step
Epoch 7/50
528/528 - 7s - loss: 3.2478 - accuracy300: 0.3935 - val_loss: 3.3000 - val_accuracy300: 0.3527 - 7s/epoch - 14ms/step
Epoch 8/50
528/528 - 7s - loss: 3.2445 - accuracy300: 0.3935 - val_loss: 3.2994 - val_accuracy300: 0.3516 - 7s/epoch - 14ms/step
Epoch 9/50
528/528 - 7s - loss: 3.2422 - accuracy300: 0.3950 - val_loss: 3.2966 - val_accuracy300: 0.3524 - 7s/epoch - 14ms/step
Epoch 10/50
528/528 - 7s - loss: 3.2392 - accuracy300: 0.3972 - val_loss: 3.2970 - val_accuracy300: 0.3493 - 7s/epoch - 13ms/step
Epoch 11/50
528/528 - 7s - loss: 3.2379 - accuracy300: 0.3982 - val_loss: 3.2990 - val_accuracy300: 0.3523 - 7s/epoch - 14ms/step
Epoch 12/50
528/528 - 7s - loss: 3.2360 - accuracy300: 0.3983 - val_loss: 3.2953 - val_accuracy300: 0.3557 - 7s/epoch - 14ms/step
Epoch 13/50
528/528 - 7s - loss: 3.2331 - accuracy300: 0.4013 - val_loss: 3.2932 - val_accuracy300: 0.3570 - 7s/epoch - 14ms/step
Epoch 14/50
528/528 - 7s - loss: 3.2313 - accuracy300: 0.4017 - val_loss: 3.2918 - val_accuracy300: 0.3560 - 7s/epoch - 13ms/step
Epoch 15/50
528/528 - 7s - loss: 3.2292 - accuracy300: 0.4031 - val_loss: 3.2938 - val_accuracy300: 0.3537 - 7s/epoch - 13ms/step
Epoch 16/50
528/528 - 7s - loss: 3.2270 - accuracy300: 0.4035 - val_loss: 3.2927 - val_accuracy300: 0.3559 - 7s/epoch - 14ms/step
Epoch 17/50
528/528 - 7s - loss: 3.2240 - accuracy300: 0.4062 - val_loss: 3.2939 - val_accuracy300: 0.3579 - 7s/epoch - 13ms/step
Epoch 18/50
528/528 - 7s - loss: 3.2225 - accuracy300: 0.4070 - val_loss: 3.2948 - val_accuracy300: 0.3547 - 7s/epoch - 13ms/step
Epoch 19/50
528/528 - 7s - loss: 3.2208 - accuracy300: 0.4078 - val_loss: 3.2954 - val_accuracy300: 0.3569 - 7s/epoch - 13ms/step
Epoch 20/50
528/528 - 7s - loss: 3.2186 - accuracy300: 0.4097 - val_loss: 3.2945 - val_accuracy300: 0.3561 - 7s/epoch - 14ms/step
Epoch 21/50
528/528 - 7s - loss: 3.2163 - accuracy300: 0.4102 - val_loss: 3.2966 - val_accuracy300: 0.3565 - 7s/epoch - 14ms/step
Epoch 22/50
528/528 - 7s - loss: 3.2137 - accuracy300: 0.4109 - val_loss: 3.2992 - val_accuracy300: 0.3553 - 7s/epoch - 14ms/step
Epoch 23/50
528/528 - 7s - loss: 3.2103 - accuracy300: 0.4132 - val_loss: 3.2974 - val_accuracy300: 0.3536 - 7s/epoch - 14ms/step
Epoch 24/50
528/528 - 7s - loss: 3.2084 - accuracy300: 0.4143 - val_loss: 3.3010 - val_accuracy300: 0.3527 - 7s/epoch - 14ms/step
testing model: results/QRTEA/W2/deepOF_L1/h300
Evaluating performance on  test set...
1242/1242 - 7s - 7s/epoch - 5ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0963575
{'0': {'precision': 0.3737018198696501, 'recall': 0.19601140179142026, 'f1-score': 0.2571462791440434, 'support': 98581}, '1': {'precision': 0.3497348464558192, 'recall': 0.41593556607207866, 'f1-score': 0.37997331216042635, 'support': 109880}, '2': {'precision': 0.3756646579227224, 'recall': 0.4652575160290123, 'f1-score': 0.41568842163756786, 'support': 109333}, 'accuracy': 0.3646827819279156, 'macro avg': {'precision': 0.3663671080827306, 'recall': 0.35906816129750374, 'f1-score': 0.35093600431401256, 'support': 317794}, 'weighted avg': {'precision': 0.3660903229066641, 'recall': 0.3646827819279156, 'f1-score': 0.35415919459582873, 'support': 317794}}
[[19323 40954 38304]
 [17941 45703 46236]
 [14443 44022 50868]]
Evaluating performance on  train set...
528/528 - 3s - 3s/epoch - 5ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0829198
{'0': {'precision': 0.4388876259756005, 'recall': 0.25783475783475784, 'f1-score': 0.32483665629118647, 'support': 44928}, '1': {'precision': 0.33602232679419014, 'recall': 0.37138354159630754, 'f1-score': 0.3528191307323751, 'support': 44415}, '2': {'precision': 0.40388692579505303, 'recall': 0.5267281105990783, 'f1-score': 0.4572, 'support': 45570}, 'accuracy': 0.3860413748119158, 'macro avg': {'precision': 0.3929322928549479, 'recall': 0.3853154700100479, 'f1-score': 0.3782852623411872, 'support': 134913}, 'weighted avg': {'precision': 0.3932008191417899, 'recall': 0.3860413748119158, 'f1-score': 0.37875762146960534, 'support': 134913}}
[[11584 16833 16511]
 [ 9004 16495 18916]
 [ 5806 15761 24003]]
Evaluating performance on  val set...
159/159 - 1s - 935ms/epoch - 6ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0966537
{'0': {'precision': 0.42302766393442626, 'recall': 0.22261912785603558, 'f1-score': 0.2917200264959152, 'support': 14837}, '1': {'precision': 0.3319769207409657, 'recall': 0.40017570832418187, 'f1-score': 0.36290001327844906, 'support': 13659}, '2': {'precision': 0.34746645426138106, 'recall': 0.46875516614316415, 'f1-score': 0.3990991942010627, 'support': 12098}, 'accuracy': 0.355717593733064, 'macro avg': {'precision': 0.36749034631225763, 'recall': 0.36385000077446056, 'f1-score': 0.35123974465847563, 'support': 40594}, 'weighted avg': {'precision': 0.3698719853636035, 'recall': 0.355717593733064, 'f1-score': 0.3476721526810535, 'support': 40594}}
[[3303 6275 5259]
 [2802 5466 5391]
 [1703 4724 5671]]
training model: results/QRTEA/W2/deepOF_L1/h500
Epoch 1/50
528/528 - 10s - loss: 3.2875 - accuracy500: 0.3824 - val_loss: 3.5107 - val_accuracy500: 0.3938 - 10s/epoch - 19ms/step
Epoch 2/50
528/528 - 7s - loss: 3.2816 - accuracy500: 0.3829 - val_loss: 3.4780 - val_accuracy500: 0.3930 - 7s/epoch - 14ms/step
Epoch 3/50
528/528 - 7s - loss: 3.2774 - accuracy500: 0.3822 - val_loss: 3.4466 - val_accuracy500: 0.3934 - 7s/epoch - 14ms/step
Epoch 4/50
528/528 - 7s - loss: 3.2763 - accuracy500: 0.3824 - val_loss: 3.3621 - val_accuracy500: 0.3937 - 7s/epoch - 14ms/step
Epoch 5/50
528/528 - 7s - loss: 3.2734 - accuracy500: 0.3796 - val_loss: 3.3255 - val_accuracy500: 0.3935 - 7s/epoch - 14ms/step
Epoch 6/50
528/528 - 7s - loss: 3.2685 - accuracy500: 0.3819 - val_loss: 3.2961 - val_accuracy500: 0.3933 - 7s/epoch - 13ms/step
Epoch 7/50
528/528 - 7s - loss: 3.2717 - accuracy500: 0.3792 - val_loss: 3.2744 - val_accuracy500: 0.3935 - 7s/epoch - 13ms/step
Epoch 8/50
528/528 - 7s - loss: 3.2737 - accuracy500: 0.3766 - val_loss: 3.2663 - val_accuracy500: 0.3929 - 7s/epoch - 13ms/step
Epoch 9/50
528/528 - 7s - loss: 3.2709 - accuracy500: 0.3769 - val_loss: 3.2639 - val_accuracy500: 0.3928 - 7s/epoch - 13ms/step
Epoch 10/50
528/528 - 7s - loss: 3.2688 - accuracy500: 0.3775 - val_loss: 3.2664 - val_accuracy500: 0.3935 - 7s/epoch - 14ms/step
Epoch 11/50
528/528 - 7s - loss: 3.2659 - accuracy500: 0.3795 - val_loss: 3.2699 - val_accuracy500: 0.3926 - 7s/epoch - 13ms/step
Epoch 12/50
528/528 - 7s - loss: 3.2651 - accuracy500: 0.3798 - val_loss: 3.2652 - val_accuracy500: 0.3924 - 7s/epoch - 14ms/step
Epoch 13/50
528/528 - 7s - loss: 3.2653 - accuracy500: 0.3781 - val_loss: 3.2637 - val_accuracy500: 0.3941 - 7s/epoch - 13ms/step
Epoch 14/50
528/528 - 7s - loss: 3.2618 - accuracy500: 0.3803 - val_loss: 3.2654 - val_accuracy500: 0.3922 - 7s/epoch - 13ms/step
Epoch 15/50
528/528 - 7s - loss: 3.2609 - accuracy500: 0.3799 - val_loss: 3.2657 - val_accuracy500: 0.3933 - 7s/epoch - 13ms/step
Epoch 16/50
528/528 - 7s - loss: 3.2601 - accuracy500: 0.3805 - val_loss: 3.2679 - val_accuracy500: 0.3932 - 7s/epoch - 13ms/step
Epoch 17/50
528/528 - 7s - loss: 3.2599 - accuracy500: 0.3804 - val_loss: 3.2724 - val_accuracy500: 0.3933 - 7s/epoch - 14ms/step
Epoch 18/50
528/528 - 7s - loss: 3.2605 - accuracy500: 0.3796 - val_loss: 3.2765 - val_accuracy500: 0.3936 - 7s/epoch - 14ms/step
Epoch 19/50
528/528 - 7s - loss: 3.2601 - accuracy500: 0.3805 - val_loss: 3.2792 - val_accuracy500: 0.3930 - 7s/epoch - 14ms/step
Epoch 20/50
528/528 - 7s - loss: 3.2588 - accuracy500: 0.3807 - val_loss: 3.2716 - val_accuracy500: 0.3931 - 7s/epoch - 14ms/step
Epoch 21/50
528/528 - 7s - loss: 3.2576 - accuracy500: 0.3815 - val_loss: 3.2713 - val_accuracy500: 0.3933 - 7s/epoch - 13ms/step
Epoch 22/50
528/528 - 7s - loss: 3.2561 - accuracy500: 0.3820 - val_loss: 3.2712 - val_accuracy500: 0.3916 - 7s/epoch - 14ms/step
Epoch 23/50
528/528 - 7s - loss: 3.2547 - accuracy500: 0.3832 - val_loss: 3.2703 - val_accuracy500: 0.3916 - 7s/epoch - 13ms/step
testing model: results/QRTEA/W2/deepOF_L1/h500
Evaluating performance on  test set...
1242/1242 - 9s - 9s/epoch - 7ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0756583
{'0': {'precision': 0.2991046446558478, 'recall': 0.012989380057838586, 'f1-score': 0.024897521893050122, 'support': 82298}, '1': {'precision': 0.4467306930756823, 'recall': 0.9775816031056032, 'f1-score': 0.6132302701651574, 'support': 141937}, '2': {'precision': 0.3478861563967947, 'recall': 0.01345674921707158, 'f1-score': 0.02591121447241145, 'support': 93559}, 'accuracy': 0.44394481960011833, 'macro avg': {'precision': 0.36457383137610827, 'recall': 0.33467591079350445, 'f1-score': 0.22134633551020633, 'support': 317794}, 'weighted avg': {'precision': 0.37940052151802045, 'recall': 0.44394481960011833, 'f1-score': 0.2879642423331168, 'support': 317794}}
[[  1069  80439    790]
 [  1612 138755   1570]
 [   893  91407   1259]]
Evaluating performance on  train set...
528/528 - 3s - 3s/epoch - 6ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1060983
{'0': {'precision': 0.45427728613569324, 'recall': 0.01345183761710305, 'f1-score': 0.026129928524464992, 'support': 45793}, '1': {'precision': 0.3270362317738821, 'recall': 0.9757530393757938, 'f1-score': 0.4898821385868018, 'support': 44088}, '2': {'precision': 0.4258064516129032, 'recall': 0.01905311778290993, 'f1-score': 0.0364741641337386, 'support': 45032}, 'accuracy': 0.3297903093104445, 'macro avg': {'precision': 0.4023733231741595, 'recall': 0.33608599825860225, 'f1-score': 0.18416207708166846, 'support': 134913}, 'weighted avg': {'precision': 0.4031932377123848, 'recall': 0.3297903093104445, 'f1-score': 0.18113151514091497, 'support': 134913}}
[[  616 44644   533]
 [  445 43019   624]
 [  295 43879   858]]
Evaluating performance on  val set...
159/159 - 1s - 959ms/epoch - 6ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0886854
{'0': {'precision': 0.3936651583710407, 'recall': 0.012625163256421419, 'f1-score': 0.02446569178852643, 'support': 13782}, '1': {'precision': 0.39380731633578553, 'recall': 0.9768153980752406, 'f1-score': 0.561317197543721, 'support': 16002}, '2': {'precision': 0.34130434782608693, 'recall': 0.01452358926919519, 'f1-score': 0.02786157941437445, 'support': 10810}, 'accuracy': 0.39321081933290636, 'macro avg': {'precision': 0.3762589408443044, 'recall': 0.3346547168669524, 'f1-score': 0.20454815624887393, 'support': 40594}, 'weighted avg': {'precision': 0.3797777476640618, 'recall': 0.39321081933290636, 'f1-score': 0.23699481777586548, 'support': 40594}}
[[  174 13487   121]
 [  189 15631   182]
 [   79 10574   157]]
training model: results/QRTEA/W2/deepOF_L1/h1000
Epoch 1/50
528/528 - 9s - loss: 3.3301 - accuracy1000: 0.3560 - val_loss: 3.3382 - val_accuracy1000: 0.3807 - 9s/epoch - 18ms/step
Epoch 2/50
528/528 - 7s - loss: 3.3149 - accuracy1000: 0.3556 - val_loss: 3.3480 - val_accuracy1000: 0.3829 - 7s/epoch - 14ms/step
Epoch 3/50
528/528 - 7s - loss: 3.3075 - accuracy1000: 0.3588 - val_loss: 3.3318 - val_accuracy1000: 0.3829 - 7s/epoch - 14ms/step
Epoch 4/50
528/528 - 7s - loss: 3.3013 - accuracy1000: 0.3588 - val_loss: 3.3143 - val_accuracy1000: 0.3834 - 7s/epoch - 13ms/step
Epoch 5/50
528/528 - 7s - loss: 3.2972 - accuracy1000: 0.3609 - val_loss: 3.3240 - val_accuracy1000: 0.3818 - 7s/epoch - 13ms/step
Epoch 6/50
528/528 - 7s - loss: 3.2946 - accuracy1000: 0.3604 - val_loss: 3.3014 - val_accuracy1000: 0.3818 - 7s/epoch - 14ms/step
Epoch 7/50
528/528 - 7s - loss: 3.2920 - accuracy1000: 0.3597 - val_loss: 3.2980 - val_accuracy1000: 0.3826 - 7s/epoch - 13ms/step
Epoch 8/50
528/528 - 7s - loss: 3.2903 - accuracy1000: 0.3650 - val_loss: 3.3002 - val_accuracy1000: 0.3827 - 7s/epoch - 13ms/step
Epoch 9/50
528/528 - 7s - loss: 3.2889 - accuracy1000: 0.3645 - val_loss: 3.2920 - val_accuracy1000: 0.3850 - 7s/epoch - 14ms/step
Epoch 10/50
528/528 - 7s - loss: 3.2879 - accuracy1000: 0.3643 - val_loss: 3.2885 - val_accuracy1000: 0.3832 - 7s/epoch - 14ms/step
Epoch 11/50
528/528 - 7s - loss: 3.2869 - accuracy1000: 0.3645 - val_loss: 3.2887 - val_accuracy1000: 0.3831 - 7s/epoch - 14ms/step
Epoch 12/50
528/528 - 7s - loss: 3.2860 - accuracy1000: 0.3658 - val_loss: 3.2910 - val_accuracy1000: 0.3847 - 7s/epoch - 14ms/step
Epoch 13/50
528/528 - 7s - loss: 3.2840 - accuracy1000: 0.3685 - val_loss: 3.2902 - val_accuracy1000: 0.3845 - 7s/epoch - 13ms/step
Epoch 14/50
528/528 - 7s - loss: 3.2829 - accuracy1000: 0.3681 - val_loss: 3.2875 - val_accuracy1000: 0.3849 - 7s/epoch - 14ms/step
Epoch 15/50
528/528 - 7s - loss: 3.2820 - accuracy1000: 0.3704 - val_loss: 3.2904 - val_accuracy1000: 0.3828 - 7s/epoch - 13ms/step
Epoch 16/50
528/528 - 7s - loss: 3.2806 - accuracy1000: 0.3714 - val_loss: 3.2900 - val_accuracy1000: 0.3834 - 7s/epoch - 13ms/step
Epoch 17/50
528/528 - 7s - loss: 3.2795 - accuracy1000: 0.3732 - val_loss: 3.2896 - val_accuracy1000: 0.3825 - 7s/epoch - 13ms/step
Epoch 18/50
528/528 - 7s - loss: 3.2782 - accuracy1000: 0.3752 - val_loss: 3.2882 - val_accuracy1000: 0.3834 - 7s/epoch - 13ms/step
Epoch 19/50
528/528 - 7s - loss: 3.2774 - accuracy1000: 0.3755 - val_loss: 3.2892 - val_accuracy1000: 0.3814 - 7s/epoch - 14ms/step
Epoch 20/50
528/528 - 7s - loss: 3.2757 - accuracy1000: 0.3769 - val_loss: 3.2889 - val_accuracy1000: 0.3831 - 7s/epoch - 13ms/step
Epoch 21/50
528/528 - 7s - loss: 3.2742 - accuracy1000: 0.3762 - val_loss: 3.2899 - val_accuracy1000: 0.3821 - 7s/epoch - 13ms/step
Epoch 22/50
528/528 - 7s - loss: 3.2734 - accuracy1000: 0.3773 - val_loss: 3.2893 - val_accuracy1000: 0.3811 - 7s/epoch - 13ms/step
Epoch 23/50
528/528 - 7s - loss: 3.2721 - accuracy1000: 0.3786 - val_loss: 3.2925 - val_accuracy1000: 0.3794 - 7s/epoch - 14ms/step
Epoch 24/50
528/528 - 7s - loss: 3.2713 - accuracy1000: 0.3793 - val_loss: 3.2927 - val_accuracy1000: 0.3793 - 7s/epoch - 14ms/step
testing model: results/QRTEA/W2/deepOF_L1/h1000
Evaluating performance on  test set...
1242/1242 - 8s - 8s/epoch - 6ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0908387
{'0': {'precision': 0.29379147350240886, 'recall': 0.03662696478961027, 'f1-score': 0.06513371354869915, 'support': 88241}, '1': {'precision': 0.38967094514160583, 'recall': 0.9195112724462939, 'f1-score': 0.547375028149511, 'support': 124241}, '2': {'precision': 0.35704845814977976, 'recall': 0.04617707383773929, 'f1-score': 0.08177782262132983, 'support': 105312}, 'accuracy': 0.38495377508700607, 'macro avg': {'precision': 0.3468369589312648, 'recall': 0.33410510369121454, 'f1-score': 0.23142885477317998, 'support': 317794}, 'weighted avg': {'precision': 0.35223776576440685, 'recall': 0.38495377508700607, 'f1-score': 0.259180698645889, 'support': 317794}}
[[  3232  81690   3319]
 [  4562 114241   5438]
 [  3207  97242   4863]]
Evaluating performance on  train set...
528/528 - 3s - 3s/epoch - 6ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1025656
{'0': {'precision': 0.46388028895768835, 'recall': 0.05789417194375872, 'f1-score': 0.1029408958186225, 'support': 46585}, '1': {'precision': 0.33477695259110446, 'recall': 0.9115774370011658, 'f1-score': 0.4897084151320623, 'support': 44604}, '2': {'precision': 0.37671680837148463, 'recall': 0.06586771567102735, 'f1-score': 0.11212988378204755, 'support': 43724}, 'accuracy': 0.3427171584650849, 'macro avg': {'precision': 0.3917913499734258, 'recall': 0.3451131082053173, 'f1-score': 0.23492639824424413, 'support': 134913}, 'weighted avg': {'precision': 0.392948197606623, 'recall': 0.3427171584650849, 'f1-score': 0.23378935179521085, 'support': 134913}}
[[ 2697 41457  2431]
 [ 1610 40660  2334]
 [ 1507 39337  2880]]
Evaluating performance on  val set...
159/159 - 1s - 939ms/epoch - 6ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0999011
{'0': {'precision': 0.38759065269943593, 'recall': 0.03360346513902473, 'f1-score': 0.06184506589521054, 'support': 14314}, '1': {'precision': 0.3872207542637521, 'recall': 0.9210259014728288, 'f1-score': 0.5452188128300043, 'support': 15752}, '2': {'precision': 0.2985153764581124, 'recall': 0.05347644376899696, 'f1-score': 0.09070404382149186, 'support': 10528}, 'accuracy': 0.38311080455239693, 'macro avg': {'precision': 0.3577755944737668, 'recall': 0.33603527012695017, 'f1-score': 0.23258930751556892, 'support': 40594}, 'weighted avg': {'precision': 0.36434556356243175, 'recall': 0.38311080455239693, 'f1-score': 0.25689681199869285, 'support': 40594}}
[[  481 13245   588]
 [  509 14508   735]
 [  251  9714   563]]
training model: results/QRTEA/W2/deepLOB_L2/h10
Epoch 1/50
528/528 - 24s - loss: 3.1844 - accuracy10: 0.4109 - val_loss: 3.6105 - val_accuracy10: 0.3861 - 24s/epoch - 46ms/step
Epoch 2/50
528/528 - 22s - loss: 2.9226 - accuracy10: 0.4383 - val_loss: 3.3499 - val_accuracy10: 0.3463 - 22s/epoch - 41ms/step
Epoch 3/50
528/528 - 21s - loss: 2.8047 - accuracy10: 0.4909 - val_loss: 3.2648 - val_accuracy10: 0.4622 - 21s/epoch - 41ms/step
Epoch 4/50
528/528 - 21s - loss: 2.7417 - accuracy10: 0.5096 - val_loss: 3.2533 - val_accuracy10: 0.4217 - 21s/epoch - 41ms/step
Epoch 5/50
528/528 - 21s - loss: 2.6855 - accuracy10: 0.5271 - val_loss: 3.1561 - val_accuracy10: 0.4390 - 21s/epoch - 40ms/step
Epoch 6/50
528/528 - 21s - loss: 2.6455 - accuracy10: 0.5407 - val_loss: 3.2870 - val_accuracy10: 0.4597 - 21s/epoch - 40ms/step
Epoch 7/50
528/528 - 21s - loss: 2.6168 - accuracy10: 0.5478 - val_loss: 3.2733 - val_accuracy10: 0.4563 - 21s/epoch - 40ms/step
Epoch 8/50
528/528 - 21s - loss: 2.5802 - accuracy10: 0.5583 - val_loss: 3.2195 - val_accuracy10: 0.4954 - 21s/epoch - 40ms/step
Epoch 9/50
528/528 - 21s - loss: 2.5458 - accuracy10: 0.5683 - val_loss: 3.1709 - val_accuracy10: 0.4723 - 21s/epoch - 40ms/step
Epoch 10/50
528/528 - 21s - loss: 2.5158 - accuracy10: 0.5769 - val_loss: 3.2016 - val_accuracy10: 0.4834 - 21s/epoch - 40ms/step
Epoch 11/50
528/528 - 21s - loss: 2.4835 - accuracy10: 0.5900 - val_loss: 3.2023 - val_accuracy10: 0.5138 - 21s/epoch - 40ms/step
Epoch 12/50
528/528 - 21s - loss: 2.4609 - accuracy10: 0.5993 - val_loss: 3.1282 - val_accuracy10: 0.5424 - 21s/epoch - 40ms/step
Epoch 13/50
528/528 - 21s - loss: 2.4272 - accuracy10: 0.6112 - val_loss: 3.0721 - val_accuracy10: 0.4881 - 21s/epoch - 40ms/step
Epoch 14/50
528/528 - 21s - loss: 2.3920 - accuracy10: 0.6241 - val_loss: 3.1576 - val_accuracy10: 0.3862 - 21s/epoch - 40ms/step
Epoch 15/50
528/528 - 21s - loss: 2.3607 - accuracy10: 0.6333 - val_loss: 3.0040 - val_accuracy10: 0.4920 - 21s/epoch - 40ms/step
Epoch 16/50
528/528 - 21s - loss: 2.3355 - accuracy10: 0.6396 - val_loss: 3.0010 - val_accuracy10: 0.5012 - 21s/epoch - 40ms/step
Epoch 17/50
528/528 - 21s - loss: 2.3147 - accuracy10: 0.6468 - val_loss: 3.1754 - val_accuracy10: 0.4093 - 21s/epoch - 40ms/step
Epoch 18/50
528/528 - 21s - loss: 2.2934 - accuracy10: 0.6509 - val_loss: 3.0827 - val_accuracy10: 0.4685 - 21s/epoch - 40ms/step
Epoch 19/50
528/528 - 21s - loss: 2.2719 - accuracy10: 0.6547 - val_loss: 3.0744 - val_accuracy10: 0.4774 - 21s/epoch - 40ms/step
Epoch 20/50
528/528 - 21s - loss: 2.2558 - accuracy10: 0.6590 - val_loss: 3.1373 - val_accuracy10: 0.4399 - 21s/epoch - 40ms/step
Epoch 21/50
528/528 - 21s - loss: 2.2426 - accuracy10: 0.6597 - val_loss: 3.1166 - val_accuracy10: 0.4476 - 21s/epoch - 40ms/step
Epoch 22/50
528/528 - 21s - loss: 2.2207 - accuracy10: 0.6637 - val_loss: 3.2146 - val_accuracy10: 0.4206 - 21s/epoch - 40ms/step
Epoch 23/50
528/528 - 21s - loss: 2.2076 - accuracy10: 0.6644 - val_loss: 3.1699 - val_accuracy10: 0.4928 - 21s/epoch - 40ms/step
Epoch 24/50
528/528 - 21s - loss: 2.1924 - accuracy10: 0.6663 - val_loss: 3.1763 - val_accuracy10: 0.5008 - 21s/epoch - 40ms/step
Epoch 25/50
528/528 - 21s - loss: 2.1770 - accuracy10: 0.6671 - val_loss: 3.2712 - val_accuracy10: 0.4987 - 21s/epoch - 40ms/step
Epoch 26/50
528/528 - 21s - loss: 2.1612 - accuracy10: 0.6697 - val_loss: 3.2167 - val_accuracy10: 0.5005 - 21s/epoch - 40ms/step
testing model: results/QRTEA/W2/deepLOB_L2/h10
Evaluating performance on  test set...
1242/1242 - 17s - 17s/epoch - 13ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.9536499
{'0': {'precision': 0.3114023793582943, 'recall': 0.48101668622342436, 'f1-score': 0.3780568820389374, 'support': 50281}, '1': {'precision': 0.8228515043193327, 'recall': 0.6100064409274936, 'f1-score': 0.7006203500169089, 'support': 217360}, '2': {'precision': 0.3305778846762453, 'recall': 0.5206347940507995, 'f1-score': 0.40438859337375044, 'support': 50158}, 'accuracy': 0.5754926856283374, 'macro avg': {'precision': 0.4882772561179574, 'recall': 0.5372193070672391, 'f1-score': 0.494355275143199, 'support': 317799}, 'weighted avg': {'precision': 0.6642366764997866, 'recall': 0.5754926856283374, 'f1-score': 0.6028314765997241, 'support': 317799}}
[[ 24186  15853  10242]
 [ 42130 132591  42639]
 [ 11352  12692  26114]]
Evaluating performance on  train set...
528/528 - 8s - 8s/epoch - 14ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.9245019
{'0': {'precision': 0.27044607059747106, 'recall': 0.6005104899458382, 'f1-score': 0.372936400541272, 'support': 16063}, '1': {'precision': 0.8938537324744221, 'recall': 0.5743671656618585, 'f1-score': 0.6993501257056117, 'support': 102673}, '2': {'precision': 0.28071651839384465, 'recall': 0.5773272345160094, 'f1-score': 0.37775530839231547, 'support': 16178}, 'accuracy': 0.57783476881569, 'macro avg': {'precision': 0.48167210715524594, 'recall': 0.5840682967079021, 'f1-score': 0.4833472782130664, 'support': 134914}, 'weighted avg': {'precision': 0.7461067890725139, 'recall': 0.57783476881569, 'f1-score': 0.6219234344666796, 'support': 134914}}
[[ 9646  3669  2748]
 [22517 58972 21184]
 [ 3504  3334  9340]]
Evaluating performance on  val set...
159/159 - 2s - 2s/epoch - 14ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 1.0632879
{'0': {'precision': 0.27297297297297296, 'recall': 0.6009669021941242, 'f1-score': 0.3754210709722383, 'support': 5378}, '1': {'precision': 0.8780472440944882, 'recall': 0.46433925180718877, 'f1-score': 0.6074432387675949, 'support': 30019}, '2': {'precision': 0.2437111801242236, 'recall': 0.603886110042324, 'f1-score': 0.34727292842128554, 'support': 5198}, 'accuracy': 0.5003079196945437, 'macro avg': {'precision': 0.4649104657305616, 'recall': 0.556397421347879, 'f1-score': 0.4433790793870396, 'support': 40595}, 'weighted avg': {'precision': 0.7166636182635006, 'recall': 0.5003079196945437, 'f1-score': 0.5433914961494511, 'support': 40595}}
[[ 3232  1053  1093]
 [ 7432 13939  8648]
 [ 1176   883  3139]]
training model: results/QRTEA/W2/deepLOB_L2/h20
Epoch 1/50
528/528 - 24s - loss: 3.1604 - accuracy20: 0.4176 - val_loss: 3.4818 - val_accuracy20: 0.4322 - 24s/epoch - 45ms/step
Epoch 2/50
528/528 - 21s - loss: 2.9299 - accuracy20: 0.4537 - val_loss: 3.4133 - val_accuracy20: 0.5011 - 21s/epoch - 40ms/step
Epoch 3/50
528/528 - 21s - loss: 2.8345 - accuracy20: 0.4840 - val_loss: 3.2374 - val_accuracy20: 0.5253 - 21s/epoch - 40ms/step
Epoch 4/50
528/528 - 21s - loss: 2.7777 - accuracy20: 0.5108 - val_loss: 3.3160 - val_accuracy20: 0.5273 - 21s/epoch - 40ms/step
Epoch 5/50
528/528 - 21s - loss: 2.7400 - accuracy20: 0.5237 - val_loss: 3.3818 - val_accuracy20: 0.5743 - 21s/epoch - 40ms/step
Epoch 6/50
528/528 - 21s - loss: 2.6956 - accuracy20: 0.5395 - val_loss: 3.6577 - val_accuracy20: 0.5853 - 21s/epoch - 40ms/step
Epoch 7/50
528/528 - 21s - loss: 2.6596 - accuracy20: 0.5480 - val_loss: 3.3471 - val_accuracy20: 0.5846 - 21s/epoch - 39ms/step
Epoch 8/50
528/528 - 21s - loss: 2.6301 - accuracy20: 0.5600 - val_loss: 3.6226 - val_accuracy20: 0.6198 - 21s/epoch - 39ms/step
Epoch 9/50
528/528 - 21s - loss: 2.5944 - accuracy20: 0.5708 - val_loss: 3.3648 - val_accuracy20: 0.6065 - 21s/epoch - 39ms/step
Epoch 10/50
528/528 - 21s - loss: 2.5667 - accuracy20: 0.5790 - val_loss: 3.2657 - val_accuracy20: 0.5603 - 21s/epoch - 40ms/step
Epoch 11/50
528/528 - 21s - loss: 2.5373 - accuracy20: 0.5889 - val_loss: 3.1866 - val_accuracy20: 0.5231 - 21s/epoch - 40ms/step
Epoch 12/50
528/528 - 21s - loss: 2.5043 - accuracy20: 0.5985 - val_loss: 3.1956 - val_accuracy20: 0.5690 - 21s/epoch - 40ms/step
Epoch 13/50
528/528 - 21s - loss: 2.4739 - accuracy20: 0.6068 - val_loss: 3.1322 - val_accuracy20: 0.5309 - 21s/epoch - 40ms/step
Epoch 14/50
528/528 - 21s - loss: 2.4448 - accuracy20: 0.6146 - val_loss: 3.1340 - val_accuracy20: 0.5169 - 21s/epoch - 40ms/step
Epoch 15/50
528/528 - 21s - loss: 2.4152 - accuracy20: 0.6213 - val_loss: 3.1848 - val_accuracy20: 0.5313 - 21s/epoch - 40ms/step
Epoch 16/50
528/528 - 21s - loss: 2.3921 - accuracy20: 0.6263 - val_loss: 3.1493 - val_accuracy20: 0.4971 - 21s/epoch - 40ms/step
Epoch 17/50
528/528 - 21s - loss: 2.3682 - accuracy20: 0.6317 - val_loss: 3.2012 - val_accuracy20: 0.4769 - 21s/epoch - 40ms/step
Epoch 18/50
528/528 - 21s - loss: 2.3481 - accuracy20: 0.6343 - val_loss: 3.2262 - val_accuracy20: 0.5163 - 21s/epoch - 40ms/step
Epoch 19/50
528/528 - 21s - loss: 2.3306 - accuracy20: 0.6393 - val_loss: 3.2895 - val_accuracy20: 0.5070 - 21s/epoch - 40ms/step
Epoch 20/50
528/528 - 21s - loss: 2.3112 - accuracy20: 0.6429 - val_loss: 3.2676 - val_accuracy20: 0.5266 - 21s/epoch - 40ms/step
Epoch 21/50
528/528 - 21s - loss: 2.2911 - accuracy20: 0.6446 - val_loss: 3.4096 - val_accuracy20: 0.5283 - 21s/epoch - 40ms/step
Epoch 22/50
528/528 - 21s - loss: 2.2747 - accuracy20: 0.6468 - val_loss: 3.2909 - val_accuracy20: 0.5038 - 21s/epoch - 40ms/step
Epoch 23/50
528/528 - 21s - loss: 2.2602 - accuracy20: 0.6497 - val_loss: 3.3523 - val_accuracy20: 0.5179 - 21s/epoch - 40ms/step
testing model: results/QRTEA/W2/deepLOB_L2/h20
Evaluating performance on  test set...
1242/1242 - 17s - 17s/epoch - 13ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.9238538
{'0': {'precision': 0.49391938055112733, 'recall': 0.1673482615472461, 'f1-score': 0.24999423657698783, 'support': 64799}, '1': {'precision': 0.7027396916906881, 'recall': 0.7480841480595996, 'f1-score': 0.724703315678322, 'support': 187384}, '2': {'precision': 0.3863379302472787, 'recall': 0.5674073396732504, 'f1-score': 0.4596845386918542, 'support': 65616}, 'accuracy': 0.5923681320583136, 'macro avg': {'precision': 0.5276656674963647, 'recall': 0.49427991642669866, 'f1-score': 0.47812736364905467, 'support': 317799}, 'weighted avg': {'precision': 0.5948338602676718, 'recall': 0.5923681320583136, 'f1-score': 0.5731919966136572, 'support': 317799}}
[[ 10844  34018  19937]
 [  8004 140179  39201]
 [  3107  25278  37231]]
Evaluating performance on  train set...
528/528 - 7s - 7s/epoch - 14ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.84568536
{'0': {'precision': 0.39084434351775393, 'recall': 0.349889114766217, 'f1-score': 0.36923451974646515, 'support': 21644}, '1': {'precision': 0.7950436131526079, 'recall': 0.6840280056886555, 'f1-score': 0.7353695253328315, 'support': 91410}, '2': {'precision': 0.34484441071234956, 'recall': 0.5819762122598353, 'f1-score': 0.4330746187363834, 'support': 21860}, 'accuracy': 0.6138873652845517, 'macro avg': {'precision': 0.5102441224609038, 'recall': 0.5386311109049026, 'f1-score': 0.5125595546052267, 'support': 134914}, 'weighted avg': {'precision': 0.6572532907448457, 'recall': 0.6138873652845517, 'f1-score': 0.6276505879422741, 'support': 134914}}
[[ 7573  9051  5020]
 [ 9733 62527 19150]
 [ 2070  7068 12722]]
Evaluating performance on  val set...
159/159 - 2s - 2s/epoch - 15ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.99323404
{'0': {'precision': 0.42764578833693306, 'recall': 0.2753441802252816, 'f1-score': 0.3349970391675831, 'support': 7191}, '1': {'precision': 0.7695936139332366, 'recall': 0.561535552193646, 'f1-score': 0.6493046444502755, 'support': 26440}, '2': {'precision': 0.28387212859113536, 'recall': 0.6796381390005743, 'f1-score': 0.40047383339679316, 'support': 6964}, 'accuracy': 0.5310998891489099, 'macro avg': {'precision': 0.493703843620435, 'recall': 0.505505957139834, 'f1-score': 0.46159183900488393, 'support': 40595}, 'weighted avg': {'precision': 0.6256963054522559, 'recall': 0.53109988914891, 'f1-score': 0.5509416993150545, 'support': 40595}}
[[ 1980  2837  2374]
 [ 2027 14847  9566]
 [  623  1608  4733]]
training model: results/QRTEA/W2/deepLOB_L2/h30
Epoch 1/50
528/528 - 24s - loss: 3.1819 - accuracy30: 0.4208 - val_loss: 3.4384 - val_accuracy30: 0.4237 - 24s/epoch - 45ms/step
Epoch 2/50
528/528 - 22s - loss: 2.9490 - accuracy30: 0.4554 - val_loss: 3.2447 - val_accuracy30: 0.4279 - 22s/epoch - 42ms/step
Epoch 3/50
528/528 - 22s - loss: 2.8662 - accuracy30: 0.4922 - val_loss: 3.2318 - val_accuracy30: 0.4598 - 22s/epoch - 41ms/step
Epoch 4/50
528/528 - 21s - loss: 2.8129 - accuracy30: 0.5128 - val_loss: 3.2445 - val_accuracy30: 0.5084 - 21s/epoch - 40ms/step
Epoch 5/50
528/528 - 21s - loss: 2.7894 - accuracy30: 0.5234 - val_loss: 3.2195 - val_accuracy30: 0.4891 - 21s/epoch - 40ms/step
Epoch 6/50
528/528 - 21s - loss: 2.7531 - accuracy30: 0.5344 - val_loss: 3.2289 - val_accuracy30: 0.5192 - 21s/epoch - 40ms/step
Epoch 7/50
528/528 - 21s - loss: 2.7255 - accuracy30: 0.5433 - val_loss: 3.2372 - val_accuracy30: 0.5173 - 21s/epoch - 40ms/step
Epoch 8/50
528/528 - 21s - loss: 2.6975 - accuracy30: 0.5545 - val_loss: 3.3281 - val_accuracy30: 0.5304 - 21s/epoch - 40ms/step
Epoch 9/50
528/528 - 21s - loss: 2.6684 - accuracy30: 0.5606 - val_loss: 3.2443 - val_accuracy30: 0.5105 - 21s/epoch - 40ms/step
Epoch 10/50
528/528 - 21s - loss: 2.6427 - accuracy30: 0.5671 - val_loss: 3.3117 - val_accuracy30: 0.4787 - 21s/epoch - 40ms/step
Epoch 11/50
528/528 - 21s - loss: 2.6177 - accuracy30: 0.5706 - val_loss: 3.3232 - val_accuracy30: 0.4802 - 21s/epoch - 39ms/step
Epoch 12/50
528/528 - 21s - loss: 2.5898 - accuracy30: 0.5782 - val_loss: 3.2859 - val_accuracy30: 0.4597 - 21s/epoch - 39ms/step
Epoch 13/50
528/528 - 21s - loss: 2.5664 - accuracy30: 0.5840 - val_loss: 3.3418 - val_accuracy30: 0.4342 - 21s/epoch - 40ms/step
Epoch 14/50
528/528 - 21s - loss: 2.5390 - accuracy30: 0.5888 - val_loss: 3.2741 - val_accuracy30: 0.4649 - 21s/epoch - 39ms/step
Epoch 15/50
528/528 - 21s - loss: 2.5212 - accuracy30: 0.5926 - val_loss: 3.2887 - val_accuracy30: 0.4827 - 21s/epoch - 40ms/step
testing model: results/QRTEA/W2/deepLOB_L2/h30
Evaluating performance on  test set...
1242/1242 - 17s - 17s/epoch - 13ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.97192633
{'0': {'precision': 0.4909495962127541, 'recall': 0.09537978792469162, 'f1-score': 0.15972819932049828, 'support': 73936}, '1': {'precision': 0.5888338547097671, 'recall': 0.8090911261820614, 'f1-score': 0.681610605938682, 'support': 167504}, '2': {'precision': 0.44019106107130673, 'recall': 0.42241255123822996, 'f1-score': 0.4311185960410068, 'support': 76359}, 'accuracy': 0.5501370363028203, 'macro avg': {'precision': 0.5066581706646093, 'recall': 0.4422944884483277, 'f1-score': 0.4241524671000623, 'support': 317799}, 'weighted avg': {'precision': 0.5303459878012043, 'recall': 0.5501370363028203, 'f1-score': 0.5000077154339962, 'support': 317799}}
[[  7052  53064  13820]
 [  4778 135526  27200]
 [  2534  41570  32255]]
Evaluating performance on  train set...
528/528 - 8s - 8s/epoch - 14ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.8971544
{'0': {'precision': 0.407780293101394, 'recall': 0.2676965193586234, 'f1-score': 0.3232127679667579, 'support': 25570}, '1': {'precision': 0.7026163729677349, 'recall': 0.7033231543021375, 'f1-score': 0.7029695859815432, 'support': 83505}, '2': {'precision': 0.36581835027070847, 'recall': 0.4889895119780177, 'f1-score': 0.41852992811951373, 'support': 25839}, 'accuracy': 0.5797100375053738, 'macro avg': {'precision': 0.4920716721132791, 'recall': 0.48666972854625956, 'f1-score': 0.4815707606892716, 'support': 134914}, 'weighted avg': {'precision': 0.5822324048795394, 'recall': 0.5797100375053738, 'f1-score': 0.5765185271134121, 'support': 134914}}
[[ 6845 13925  4800]
 [ 7670 58731 17104]
 [ 2271 10933 12635]]
Evaluating performance on  val set...
159/159 - 2s - 2s/epoch - 15ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.9832965
{'0': {'precision': 0.3991827754203992, 'recall': 0.2977725674091442, 'f1-score': 0.3410998455650306, 'support': 8530}, '1': {'precision': 0.6785772029102668, 'recall': 0.5262036108324974, 'f1-score': 0.592754748958407, 'support': 23928}, '2': {'precision': 0.30586209096128086, 'recall': 0.5892835197247143, 'f1-score': 0.4027042915931805, 'support': 8137}, 'accuracy': 0.4908486266781623, 'macro avg': {'precision': 0.4612073564306489, 'recall': 0.4710865659887853, 'f1-score': 0.44551962870553935, 'support': 40595}, 'weighted avg': {'precision': 0.5451613306989731, 'recall': 0.4908486266781623, 'f1-score': 0.5017815528129125, 'support': 40595}}
[[ 2540  3518  2472]
 [ 2927 12591  8410]
 [  896  2446  4795]]
training model: results/QRTEA/W2/deepLOB_L2/h50
Epoch 1/50
528/528 - 23s - loss: 3.1950 - accuracy50: 0.4220 - val_loss: 3.5995 - val_accuracy50: 0.4526 - 23s/epoch - 44ms/step
Epoch 2/50
528/528 - 21s - loss: 3.0403 - accuracy50: 0.4539 - val_loss: 3.4757 - val_accuracy50: 0.4284 - 21s/epoch - 40ms/step
Epoch 3/50
528/528 - 21s - loss: 2.9599 - accuracy50: 0.4835 - val_loss: 3.3239 - val_accuracy50: 0.4497 - 21s/epoch - 39ms/step
Epoch 4/50
528/528 - 21s - loss: 2.9019 - accuracy50: 0.5091 - val_loss: 3.3298 - val_accuracy50: 0.4499 - 21s/epoch - 39ms/step
Epoch 5/50
528/528 - 21s - loss: 2.8560 - accuracy50: 0.5229 - val_loss: 3.2925 - val_accuracy50: 0.4336 - 21s/epoch - 40ms/step
Epoch 6/50
528/528 - 21s - loss: 2.8304 - accuracy50: 0.5296 - val_loss: 3.2195 - val_accuracy50: 0.4514 - 21s/epoch - 39ms/step
Epoch 7/50
528/528 - 21s - loss: 2.8017 - accuracy50: 0.5400 - val_loss: 3.2225 - val_accuracy50: 0.4627 - 21s/epoch - 39ms/step
Epoch 8/50
528/528 - 21s - loss: 2.7781 - accuracy50: 0.5461 - val_loss: 3.2102 - val_accuracy50: 0.4830 - 21s/epoch - 39ms/step
Epoch 9/50
528/528 - 21s - loss: 2.7612 - accuracy50: 0.5508 - val_loss: 3.2190 - val_accuracy50: 0.4727 - 21s/epoch - 39ms/step
Epoch 10/50
528/528 - 21s - loss: 2.7353 - accuracy50: 0.5550 - val_loss: 3.3541 - val_accuracy50: 0.4825 - 21s/epoch - 40ms/step
Epoch 11/50
528/528 - 21s - loss: 2.7125 - accuracy50: 0.5627 - val_loss: 3.4694 - val_accuracy50: 0.4770 - 21s/epoch - 39ms/step
Epoch 12/50
528/528 - 21s - loss: 2.6838 - accuracy50: 0.5689 - val_loss: 3.6053 - val_accuracy50: 0.4671 - 21s/epoch - 39ms/step
Epoch 13/50
528/528 - 21s - loss: 2.6661 - accuracy50: 0.5719 - val_loss: 3.3746 - val_accuracy50: 0.4553 - 21s/epoch - 39ms/step
Epoch 14/50
528/528 - 21s - loss: 2.6481 - accuracy50: 0.5743 - val_loss: 3.5912 - val_accuracy50: 0.4403 - 21s/epoch - 39ms/step
Epoch 15/50
528/528 - 21s - loss: 2.6317 - accuracy50: 0.5785 - val_loss: 3.5953 - val_accuracy50: 0.4328 - 21s/epoch - 39ms/step
Epoch 16/50
528/528 - 21s - loss: 2.6121 - accuracy50: 0.5820 - val_loss: 3.6740 - val_accuracy50: 0.4487 - 21s/epoch - 40ms/step
Epoch 17/50
528/528 - 21s - loss: 2.5881 - accuracy50: 0.5866 - val_loss: 3.5261 - val_accuracy50: 0.4456 - 21s/epoch - 39ms/step
Epoch 18/50
528/528 - 21s - loss: 2.5583 - accuracy50: 0.5904 - val_loss: 3.7410 - val_accuracy50: 0.4622 - 21s/epoch - 40ms/step
testing model: results/QRTEA/W2/deepLOB_L2/h50
Evaluating performance on  test set...
1242/1242 - 17s - 17s/epoch - 13ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0600334
{'0': {'precision': 0.4092293633871459, 'recall': 0.2178858963220388, 'f1-score': 0.28436656663164184, 'support': 86325}, '1': {'precision': 0.5053778643542374, 'recall': 0.6872387544238178, 'f1-score': 0.5824424187012109, 'support': 140433}, '2': {'precision': 0.4368793975441764, 'recall': 0.3880669149064707, 'f1-score': 0.4110290268163574, 'support': 91041}, 'accuracy': 0.4740417685392339, 'macro avg': {'precision': 0.45049554176185325, 'recall': 0.43106385521744245, 'f1-score': 0.4259460040497367, 'support': 317799}, 'weighted avg': {'precision': 0.459637669253438, 'recall': 0.4740417685392339, 'f1-score': 0.4523694966954951, 'support': 317799}}
[[18809 46638 20878]
 [19261 96511 24661]
 [ 7892 47819 35330]]
Evaluating performance on  train set...
528/528 - 8s - 8s/epoch - 14ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.9636743
{'0': {'precision': 0.4095843177319456, 'recall': 0.40425397825744447, 'f1-score': 0.40690169211982813, 'support': 31735}, '1': {'precision': 0.6325512499825324, 'recall': 0.636786945206443, 'f1-score': 0.634662030481051, 'support': 71085}, '2': {'precision': 0.41275639224501265, 'recall': 0.4119461581604038, 'f1-score': 0.41235087719298247, 'support': 32094}, 'accuracy': 0.5286034066145842, 'macro avg': {'precision': 0.4849639866531636, 'recall': 0.48432902720809706, 'f1-score': 0.4846381999312872, 'support': 134914}, 'weighted avg': {'precision': 0.527818221837193, 'recall': 0.5286034066145842, 'f1-score': 0.5282028899061613, 'support': 134914}}
[[12829 12655  6251]
 [13260 45266 12559]
 [ 5233 13640 13221]]
Evaluating performance on  val set...
159/159 - 2s - 2s/epoch - 15ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0222136
{'0': {'precision': 0.4190073492399074, 'recall': 0.39216055780646375, 'f1-score': 0.4051396865569941, 'support': 10613}, '1': {'precision': 0.6126271040386052, 'recall': 0.5330134452941471, 'f1-score': 0.5700539904848452, 'support': 20007}, '2': {'precision': 0.36491889852885706, 'recall': 0.4849122807017544, 'f1-score': 0.4164442531209643, 'support': 9975}, 'accuracy': 0.4843699963049637, 'macro avg': {'precision': 0.46551778393578996, 'recall': 0.47002876126745513, 'f1-score': 0.4638793100542678, 'support': 40595}, 'weighted avg': {'precision': 0.5011410636977179, 'recall': 0.4843699963049637, 'f1-score': 0.4891944600552111, 'support': 40595}}
[[ 4162  3361  3090]
 [ 4015 10664  5328]
 [ 1756  3382  4837]]
training model: results/QRTEA/W2/deepLOB_L2/h100
Epoch 1/50
528/528 - 23s - loss: 3.2555 - accuracy100: 0.4058 - val_loss: 3.4878 - val_accuracy100: 0.3709 - 23s/epoch - 44ms/step
Epoch 2/50
528/528 - 21s - loss: 3.1474 - accuracy100: 0.4479 - val_loss: 3.5501 - val_accuracy100: 0.3921 - 21s/epoch - 40ms/step
Epoch 3/50
528/528 - 21s - loss: 3.0669 - accuracy100: 0.4787 - val_loss: 3.6298 - val_accuracy100: 0.3868 - 21s/epoch - 40ms/step
Epoch 4/50
528/528 - 21s - loss: 3.0299 - accuracy100: 0.4900 - val_loss: 3.6954 - val_accuracy100: 0.3986 - 21s/epoch - 40ms/step
Epoch 5/50
528/528 - 21s - loss: 2.9916 - accuracy100: 0.4993 - val_loss: 3.7773 - val_accuracy100: 0.4008 - 21s/epoch - 40ms/step
Epoch 6/50
528/528 - 21s - loss: 2.9634 - accuracy100: 0.5097 - val_loss: 3.6513 - val_accuracy100: 0.4042 - 21s/epoch - 40ms/step
Epoch 7/50
528/528 - 21s - loss: 2.9369 - accuracy100: 0.5180 - val_loss: 3.7702 - val_accuracy100: 0.4024 - 21s/epoch - 39ms/step
Epoch 8/50
528/528 - 21s - loss: 2.9137 - accuracy100: 0.5251 - val_loss: 3.8254 - val_accuracy100: 0.4002 - 21s/epoch - 39ms/step
Epoch 9/50
528/528 - 21s - loss: 2.8889 - accuracy100: 0.5313 - val_loss: 3.8071 - val_accuracy100: 0.4101 - 21s/epoch - 40ms/step
Epoch 10/50
528/528 - 21s - loss: 2.8590 - accuracy100: 0.5398 - val_loss: 3.8822 - val_accuracy100: 0.4058 - 21s/epoch - 39ms/step
Epoch 11/50
528/528 - 21s - loss: 2.8351 - accuracy100: 0.5455 - val_loss: 3.8825 - val_accuracy100: 0.4087 - 21s/epoch - 39ms/step
testing model: results/QRTEA/W2/deepLOB_L2/h100
Evaluating performance on  test set...
1242/1242 - 16s - 16s/epoch - 13ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.1275221
{'0': {'precision': 0.423515922239016, 'recall': 0.07750636666253351, 'f1-score': 0.13103281464161898, 'support': 104843}, '1': {'precision': 0.33621305915098787, 'recall': 0.6682083371119374, 'f1-score': 0.4473428582992674, 'support': 99243}, '2': {'precision': 0.4412504562448827, 'recall': 0.39335871887998736, 'f1-score': 0.4159305201688642, 'support': 113713}, 'accuracy': 0.37498859341911084, 'macro avg': {'precision': 0.40032647921162884, 'recall': 0.3796911408848194, 'f1-score': 0.3314353977032502, 'support': 317799}, 'weighted avg': {'precision': 0.40259845246712855, 'recall': 0.37498859341911084, 'f1-score': 0.33175128905889417, 'support': 317799}}
[[ 8126 66493 30224]
 [ 6511 66315 26417]
 [ 4550 64433 44730]]
Evaluating performance on  train set...
528/528 - 7s - 7s/epoch - 14ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.1076329
{'0': {'precision': 0.40579271369462105, 'recall': 0.09690791217795773, 'f1-score': 0.15645305630131123, 'support': 41493}, '1': {'precision': 0.4101138160794379, 'recall': 0.6188892583970735, 'f1-score': 0.49332221018080313, 'support': 51119}, '2': {'precision': 0.39500240269101394, 'recall': 0.4469292232045766, 'f1-score': 0.41936449841956414, 'support': 42302}, 'accuracy': 0.40443541811820866, 'macro avg': {'precision': 0.403636310821691, 'recall': 0.3875754645932026, 'f1-score': 0.3563799216338928, 'support': 134914}, 'weighted avg': {'precision': 0.40404670287835937, 'recall': 0.40443541811820866, 'f1-score': 0.36652831981475004, 'support': 134914}}
[[ 4021 23979 13493]
 [ 4018 31637 15464]
 [ 1870 21526 18906]]
Evaluating performance on  val set...
159/159 - 2s - 2s/epoch - 14ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.1412817
{'0': {'precision': 0.3972962823882839, 'recall': 0.07677793904208999, 'f1-score': 0.1286869792616919, 'support': 13780}, '1': {'precision': 0.3809168349872662, 'recall': 0.6049090021616345, 'f1-score': 0.46746598410346224, 'support': 14341}, '2': {'precision': 0.351167700224304, 'recall': 0.4267275933942601, 'f1-score': 0.38527793862188764, 'support': 12474}, 'accuracy': 0.3708831136839512, 'macro avg': {'precision': 0.3764602725332847, 'recall': 0.3694715115326615, 'f1-score': 0.3271436339956806, 'support': 40595}, 'weighted avg': {'precision': 0.3773355584298782, 'recall': 0.3708831136839512, 'f1-score': 0.3272125448607782, 'support': 40595}}
[[1058 7621 5101]
 [ 932 8675 4734]
 [ 673 6478 5323]]
training model: results/QRTEA/W2/deepLOB_L2/h200
Epoch 1/50
528/528 - 24s - loss: 3.2962 - accuracy200: 0.3818 - val_loss: 3.3892 - val_accuracy200: 0.3561 - 24s/epoch - 45ms/step
Epoch 2/50
528/528 - 21s - loss: 3.2410 - accuracy200: 0.4067 - val_loss: 3.5055 - val_accuracy200: 0.3452 - 21s/epoch - 40ms/step
Epoch 3/50
528/528 - 21s - loss: 3.2210 - accuracy200: 0.4159 - val_loss: 3.4619 - val_accuracy200: 0.3510 - 21s/epoch - 40ms/step
Epoch 4/50
528/528 - 21s - loss: 3.1963 - accuracy200: 0.4253 - val_loss: 3.5190 - val_accuracy200: 0.3621 - 21s/epoch - 40ms/step
Epoch 5/50
528/528 - 21s - loss: 3.1622 - accuracy200: 0.4403 - val_loss: 3.5190 - val_accuracy200: 0.3616 - 21s/epoch - 40ms/step
Epoch 6/50
528/528 - 21s - loss: 3.1316 - accuracy200: 0.4544 - val_loss: 3.5861 - val_accuracy200: 0.3592 - 21s/epoch - 40ms/step
Epoch 7/50
528/528 - 21s - loss: 3.1111 - accuracy200: 0.4635 - val_loss: 3.5631 - val_accuracy200: 0.3632 - 21s/epoch - 40ms/step
Epoch 8/50
528/528 - 21s - loss: 3.0759 - accuracy200: 0.4755 - val_loss: 3.5205 - val_accuracy200: 0.3676 - 21s/epoch - 40ms/step
Epoch 9/50
528/528 - 21s - loss: 3.0531 - accuracy200: 0.4814 - val_loss: 3.4220 - val_accuracy200: 0.3789 - 21s/epoch - 39ms/step
Epoch 10/50
528/528 - 21s - loss: 3.0186 - accuracy200: 0.4917 - val_loss: 3.5509 - val_accuracy200: 0.3714 - 21s/epoch - 40ms/step
Epoch 11/50
528/528 - 21s - loss: 2.9910 - accuracy200: 0.5002 - val_loss: 3.6076 - val_accuracy200: 0.3686 - 21s/epoch - 39ms/step
testing model: results/QRTEA/W2/deepLOB_L2/h200
Evaluating performance on  test set...
1242/1242 - 17s - 17s/epoch - 13ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1475066
{'0': {'precision': 0.3360067053429093, 'recall': 0.20451953664245845, 'f1-score': 0.25427048808243113, 'support': 99966}, '1': {'precision': 0.351432434299474, 'recall': 0.6626905111934049, 'f1-score': 0.4592952769107746, 'support': 107474}, '2': {'precision': 0.40033155277214955, 'recall': 0.19693908063683072, 'f1-score': 0.2640040328213351, 'support': 110359}, 'accuracy': 0.3568324632865428, 'macro avg': {'precision': 0.3625902308048443, 'recall': 0.3547163761575647, 'f1-score': 0.3258565992715136, 'support': 317799}, 'weighted avg': {'precision': 0.36356088465537206, 'recall': 0.3568324632865428, 'f1-score': 0.3269863192158774, 'support': 317799}}
[[20445 61246 18275]
 [21971 71222 14281]
 [18431 70194 21734]]
Evaluating performance on  train set...
528/528 - 8s - 8s/epoch - 14ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1235739
{'0': {'precision': 0.36623326714917054, 'recall': 0.25584464976845117, 'f1-score': 0.30124464932499173, 'support': 44699}, '1': {'precision': 0.35982283183311903, 'recall': 0.5636526410026858, 'f1-score': 0.4392430452603122, 'support': 44680}, '2': {'precision': 0.39486022909371477, 'recall': 0.29221477983968375, 'f1-score': 0.3358701551121376, 'support': 45535}, 'accuracy': 0.37005796285040843, 'macro avg': {'precision': 0.3736387760253348, 'recall': 0.37057069020360683, 'f1-score': 0.3587859498991472, 'support': 134914}, 'weighted avg': {'precision': 0.37377222131422116, 'recall': 0.37005796285040843, 'f1-score': 0.35863262045035904, 'support': 134914}}
[[11436 22459 10804]
 [ 9908 25184  9588]
 [ 9882 22347 13306]]
Evaluating performance on  val set...
159/159 - 2s - 2s/epoch - 15ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1317376
{'0': {'precision': 0.36922133660331086, 'recall': 0.20336350128326355, 'f1-score': 0.2622708070206002, 'support': 14806}, '1': {'precision': 0.3552578968412635, 'recall': 0.5404912173979165, 'f1-score': 0.42872221719593473, 'support': 13151}, '2': {'precision': 0.3421010296010296, 'recall': 0.33652476657699004, 'f1-score': 0.3392899880335062, 'support': 12638}, 'accuracy': 0.354033747998522, 'macro avg': {'precision': 0.3555267543485347, 'recall': 0.3601264950860567, 'f1-score': 0.34342767075001374, 'support': 40595}, 'weighted avg': {'precision': 0.35625472405975833, 'recall': 0.354033747998522, 'f1-score': 0.3401713096651853, 'support': 40595}}
[[3011 6981 4814]
 [2678 7108 3365]
 [2466 5919 4253]]
training model: results/QRTEA/W2/deepLOB_L2/h300
Epoch 1/50
528/528 - 23s - loss: 3.3119 - accuracy300: 0.3735 - val_loss: 3.4334 - val_accuracy300: 0.3389 - 23s/epoch - 43ms/step
Epoch 2/50
528/528 - 21s - loss: 3.2477 - accuracy300: 0.3990 - val_loss: 3.5443 - val_accuracy300: 0.3360 - 21s/epoch - 39ms/step
Epoch 3/50
528/528 - 21s - loss: 3.2222 - accuracy300: 0.4121 - val_loss: 3.5538 - val_accuracy300: 0.3303 - 21s/epoch - 39ms/step
Epoch 4/50
528/528 - 21s - loss: 3.1988 - accuracy300: 0.4233 - val_loss: 3.4862 - val_accuracy300: 0.3330 - 21s/epoch - 40ms/step
Epoch 5/50
528/528 - 21s - loss: 3.1715 - accuracy300: 0.4370 - val_loss: 3.4869 - val_accuracy300: 0.3403 - 21s/epoch - 39ms/step
Epoch 6/50
528/528 - 21s - loss: 3.1540 - accuracy300: 0.4442 - val_loss: 3.5105 - val_accuracy300: 0.3316 - 21s/epoch - 39ms/step
Epoch 7/50
528/528 - 21s - loss: 3.1255 - accuracy300: 0.4547 - val_loss: 3.5338 - val_accuracy300: 0.3387 - 21s/epoch - 39ms/step
Epoch 8/50
528/528 - 21s - loss: 3.1021 - accuracy300: 0.4640 - val_loss: 3.5759 - val_accuracy300: 0.3392 - 21s/epoch - 39ms/step
Epoch 9/50
528/528 - 21s - loss: 3.0791 - accuracy300: 0.4711 - val_loss: 3.9731 - val_accuracy300: 0.3281 - 21s/epoch - 39ms/step
Epoch 10/50
528/528 - 21s - loss: 3.0439 - accuracy300: 0.4826 - val_loss: 3.8392 - val_accuracy300: 0.3385 - 21s/epoch - 39ms/step
Epoch 11/50
528/528 - 21s - loss: 3.0009 - accuracy300: 0.4959 - val_loss: 4.1964 - val_accuracy300: 0.3346 - 21s/epoch - 39ms/step
testing model: results/QRTEA/W2/deepLOB_L2/h300
Evaluating performance on  test set...
1242/1242 - 17s - 17s/epoch - 13ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.117128
{'0': {'precision': 0.3246019920006274, 'recall': 0.2099225026373448, 'f1-score': 0.2549602991271352, 'support': 98584}, '1': {'precision': 0.35508833487914715, 'recall': 0.5783802477225362, 'f1-score': 0.4400278336489429, 'support': 109881}, '2': {'precision': 0.3786268084086004, 'recall': 0.25995573197724403, 'f1-score': 0.30826464208242943, 'support': 109334}, 'accuracy': 0.3545322672506836, 'macro avg': {'precision': 0.3527723784294583, 'recall': 0.349419494112375, 'f1-score': 0.33441759161950246, 'support': 317799}, 'weighted avg': {'precision': 0.35372926779124964, 'recall': 0.3545322672506836, 'f1-score': 0.3372871245528442, 'support': 317799}}
[[20695 54570 23319]
 [23003 63553 23325]
 [20057 60855 28422]]
Evaluating performance on  train set...
528/528 - 7s - 7s/epoch - 14ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1244112
{'0': {'precision': 0.3716236023284057, 'recall': 0.19755120213713268, 'f1-score': 0.25796886582653816, 'support': 44920}, '1': {'precision': 0.3436857628027527, 'recall': 0.5196621621621622, 'f1-score': 0.41373930819301735, 'support': 44400}, '2': {'precision': 0.3734311291314549, 'recall': 0.35956485502478397, 'f1-score': 0.36636683613609705, 'support': 45594}, 'accuracy': 0.35830973805535377, 'macro avg': {'precision': 0.36291349808753776, 'recall': 0.3589260731080263, 'f1-score': 0.3460250033852175, 'support': 134914}, 'weighted avg': {'precision': 0.36304015140499696, 'recall': 0.35830973805535377, 'f1-score': 0.34586563487471483, 'support': 134914}}
[[ 8874 22041 14005]
 [ 7825 23073 13502]
 [ 7180 22020 16394]]
Evaluating performance on  val set...
159/159 - 2s - 2s/epoch - 14ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1437426
{'0': {'precision': 0.37175702967220753, 'recall': 0.16158001350438891, 'f1-score': 0.22525533016425844, 'support': 14810}, '1': {'precision': 0.3471007450599287, 'recall': 0.4703343331626308, 'f1-score': 0.39942841166785753, 'support': 13669}, '2': {'precision': 0.30640828856485036, 'recall': 0.395427533839551, 'f1-score': 0.34527241279907755, 'support': 12116}, 'accuracy': 0.33533686414583075, 'macro avg': {'precision': 0.34175535443232885, 'recall': 0.3424472935021902, 'f1-score': 0.3233187182103978, 'support': 40595}, 'weighted avg': {'precision': 0.3439508441414284, 'recall': 0.33533686414583075, 'f1-score': 0.3197226001304159, 'support': 40595}}
[[2393 6592 5825]
 [2220 6429 5020]
 [1824 5501 4791]]
training model: results/QRTEA/W2/deepLOB_L2/h500
Epoch 1/50
528/528 - 24s - loss: 3.2532 - accuracy500: 0.4058 - val_loss: 3.5319 - val_accuracy500: 0.3667 - 24s/epoch - 45ms/step
Epoch 2/50
528/528 - 22s - loss: 3.2326 - accuracy500: 0.4081 - val_loss: 3.4627 - val_accuracy500: 0.3847 - 22s/epoch - 41ms/step
Epoch 3/50
528/528 - 21s - loss: 3.2137 - accuracy500: 0.4160 - val_loss: 3.4274 - val_accuracy500: 0.3671 - 21s/epoch - 41ms/step
Epoch 4/50
528/528 - 22s - loss: 3.1745 - accuracy500: 0.4324 - val_loss: 3.3437 - val_accuracy500: 0.3784 - 22s/epoch - 41ms/step
Epoch 5/50
528/528 - 21s - loss: 3.1664 - accuracy500: 0.4342 - val_loss: 3.3925 - val_accuracy500: 0.3690 - 21s/epoch - 40ms/step
Epoch 6/50
528/528 - 21s - loss: 3.1428 - accuracy500: 0.4462 - val_loss: 3.3962 - val_accuracy500: 0.3776 - 21s/epoch - 40ms/step
Epoch 7/50
528/528 - 21s - loss: 3.1218 - accuracy500: 0.4585 - val_loss: 3.3758 - val_accuracy500: 0.3737 - 21s/epoch - 40ms/step
Epoch 8/50
528/528 - 21s - loss: 3.0985 - accuracy500: 0.4657 - val_loss: 3.4943 - val_accuracy500: 0.3664 - 21s/epoch - 40ms/step
Epoch 9/50
528/528 - 21s - loss: 3.0757 - accuracy500: 0.4756 - val_loss: 3.7571 - val_accuracy500: 0.3571 - 21s/epoch - 40ms/step
Epoch 10/50
528/528 - 21s - loss: 3.0582 - accuracy500: 0.4809 - val_loss: 3.8072 - val_accuracy500: 0.3547 - 21s/epoch - 40ms/step
Epoch 11/50
528/528 - 21s - loss: 3.0398 - accuracy500: 0.4889 - val_loss: 3.8339 - val_accuracy500: 0.3566 - 21s/epoch - 40ms/step
Epoch 12/50
528/528 - 21s - loss: 3.0100 - accuracy500: 0.4975 - val_loss: 3.9714 - val_accuracy500: 0.3566 - 21s/epoch - 40ms/step
Epoch 13/50
528/528 - 21s - loss: 2.9806 - accuracy500: 0.5058 - val_loss: 4.0360 - val_accuracy500: 0.3500 - 21s/epoch - 40ms/step
Epoch 14/50
528/528 - 21s - loss: 2.9764 - accuracy500: 0.5081 - val_loss: 3.8950 - val_accuracy500: 0.3602 - 21s/epoch - 40ms/step
testing model: results/QRTEA/W2/deepLOB_L2/h500
Evaluating performance on  test set...
1242/1242 - 16s - 16s/epoch - 13ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0882132
{'0': {'precision': 0.2902869757174393, 'recall': 0.015977546383485412, 'f1-score': 0.030288024138288436, 'support': 82303}, '1': {'precision': 0.5207336447264529, 'recall': 0.7713140336910037, 'f1-score': 0.6217249946759423, 'support': 141937}, '2': {'precision': 0.3817394764682474, 'recall': 0.42038713539050226, 'f1-score': 0.40013225494684374, 'support': 93559}, 'accuracy': 0.4723866343191766, 'macro avg': {'precision': 0.39758669897071314, 'recall': 0.40255957182166374, 'f1-score': 0.35071509125369155, 'support': 317799}, 'weighted avg': {'precision': 0.42013355603039565, 'recall': 0.4723866343191766, 'f1-score': 0.4033195493395024, 'support': 317799}}
[[  1315  48312  32676]
 [  1435 109478  31024]
 [  1780  52448  39331]]
Evaluating performance on  train set...
528/528 - 7s - 7s/epoch - 14ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1527253
{'0': {'precision': 0.4100979653353429, 'recall': 0.05939751146037983, 'f1-score': 0.10376584993803033, 'support': 45810}, '1': {'precision': 0.38593880495026955, 'recall': 0.5767842959264723, 'f1-score': 0.4624454148471616, 'support': 44065}, '2': {'precision': 0.37226066897347176, 'recall': 0.5159528408712449, 'f1-score': 0.4324837385890958, 'support': 45039}, 'accuracy': 0.3807981380731429, 'macro avg': {'precision': 0.389432479753028, 'recall': 0.38404488275269905, 'f1-score': 0.33289833445809586, 'support': 134914}, 'weighted avg': {'precision': 0.38957580015448273, 'recall': 0.3807981380731429, 'f1-score': 0.33065364523485796, 'support': 134914}}
[[ 2721 20718 22371]
 [ 1834 25416 16815]
 [ 2080 19721 23238]]
Evaluating performance on  val set...
159/159 - 2s - 2s/epoch - 14ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1169791
{'0': {'precision': 0.38478676002546147, 'recall': 0.0877549539086884, 'f1-score': 0.14291624800520125, 'support': 13777}, '1': {'precision': 0.4846189429860067, 'recall': 0.5233218857321261, 'f1-score': 0.503227355969858, 'support': 16015}, '2': {'precision': 0.285629247482514, 'recall': 0.5330000925668795, 'f1-score': 0.37193979717072534, 'support': 10803}, 'accuracy': 0.3780761177484912, 'macro avg': {'precision': 0.3850116501646607, 'recall': 0.3813589774025647, 'f1-score': 0.3393611337152615, 'support': 40595}, 'weighted avg': {'precision': 0.3977837744881212, 'recall': 0.3780761177484912, 'f1-score': 0.346008347911326, 'support': 40595}}
[[1209 4906 7662]
 [ 895 8381 6739]
 [1038 4007 5758]]
training model: results/QRTEA/W2/deepLOB_L2/h1000
Epoch 1/50
528/528 - 24s - loss: 3.2686 - accuracy1000: 0.4028 - val_loss: 3.4207 - val_accuracy1000: 0.3302 - 24s/epoch - 45ms/step
Epoch 2/50
528/528 - 21s - loss: 3.2149 - accuracy1000: 0.4201 - val_loss: 3.4435 - val_accuracy1000: 0.3157 - 21s/epoch - 39ms/step
Epoch 3/50
528/528 - 21s - loss: 3.2077 - accuracy1000: 0.4208 - val_loss: 3.4746 - val_accuracy1000: 0.3104 - 21s/epoch - 39ms/step
Epoch 4/50
528/528 - 21s - loss: 3.1863 - accuracy1000: 0.4307 - val_loss: 3.4435 - val_accuracy1000: 0.3223 - 21s/epoch - 40ms/step
Epoch 5/50
528/528 - 21s - loss: 3.1634 - accuracy1000: 0.4428 - val_loss: 3.4720 - val_accuracy1000: 0.3125 - 21s/epoch - 39ms/step
Epoch 6/50
528/528 - 21s - loss: 3.1465 - accuracy1000: 0.4538 - val_loss: 3.4830 - val_accuracy1000: 0.3114 - 21s/epoch - 39ms/step
Epoch 7/50
528/528 - 21s - loss: 3.1150 - accuracy1000: 0.4649 - val_loss: 3.4711 - val_accuracy1000: 0.3081 - 21s/epoch - 39ms/step
Epoch 8/50
528/528 - 21s - loss: 3.1032 - accuracy1000: 0.4719 - val_loss: 3.4710 - val_accuracy1000: 0.3102 - 21s/epoch - 39ms/step
Epoch 9/50
528/528 - 21s - loss: 3.0763 - accuracy1000: 0.4814 - val_loss: 3.4953 - val_accuracy1000: 0.3070 - 21s/epoch - 39ms/step
Epoch 10/50
528/528 - 21s - loss: 3.0558 - accuracy1000: 0.4888 - val_loss: 3.4668 - val_accuracy1000: 0.3245 - 21s/epoch - 39ms/step
Epoch 11/50
528/528 - 21s - loss: 3.0375 - accuracy1000: 0.4949 - val_loss: 3.5080 - val_accuracy1000: 0.3118 - 21s/epoch - 40ms/step
testing model: results/QRTEA/W2/deepLOB_L2/h1000
Evaluating performance on  test set...
1242/1242 - 17s - 17s/epoch - 13ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1095428
{'0': {'precision': 0.323808060633994, 'recall': 0.14330556972066405, 'f1-score': 0.19868184353372767, 'support': 88245}, '1': {'precision': 0.42623423008237804, 'recall': 0.5955360951698715, 'f1-score': 0.4968589569252361, 'support': 124241}, '2': {'precision': 0.3662022728353383, 'recall': 0.36565286336919467, 'f1-score': 0.3659273618792406, 'support': 105313}, 'accuracy': 0.3937834920814729, 'macro avg': {'precision': 0.3720815211839034, 'recall': 0.3681648427532434, 'f1-score': 0.3538227207794014, 'support': 317799}, 'weighted avg': {'precision': 0.3778994561009302, 'recall': 0.3937834920814729, 'f1-score': 0.37067404621024774, 'support': 317799}}
[[12646 45309 30290]
 [13894 73990 36357]
 [12514 54291 38508]]
Evaluating performance on  train set...
528/528 - 7s - 7s/epoch - 14ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1147759
{'0': {'precision': 0.37577780095248026, 'recall': 0.23202403949345354, 'f1-score': 0.28690101782183475, 'support': 46590}, '1': {'precision': 0.40656038727985977, 'recall': 0.436958959407939, 'f1-score': 0.4212119246816698, 'support': 44590}, '2': {'precision': 0.3541212235714408, 'recall': 0.47144098413133945, 'f1-score': 0.404445011132144, 'support': 43734}, 'accuracy': 0.37736632224972944, 'macro avg': {'precision': 0.3788198039345936, 'recall': 0.38014132767757736, 'f1-score': 0.3708526512118828, 'support': 134914}, 'weighted avg': {'precision': 0.3789314156192715, 'recall': 0.37736632224972944, 'f1-score': 0.36939499428323314, 'support': 134914}}
[[10810 14379 21401]
 [ 8902 19484 16204]
 [ 9055 14061 20618]]
Evaluating performance on  val set...
159/159 - 2s - 2s/epoch - 14ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1444576
{'0': {'precision': 0.34665532879818595, 'recall': 0.25628667225481977, 'f1-score': 0.29469879518072284, 'support': 14316}, '1': {'precision': 0.436162223056703, 'recall': 0.2949092294020566, 'f1-score': 0.3518897220328713, 'support': 15754}, '2': {'precision': 0.2653546154243504, 'recall': 0.4880760095011876, 'f1-score': 0.34379601124347475, 'support': 10525}, 'accuracy': 0.3313708584801084, 'macro avg': {'precision': 0.34939072242641317, 'recall': 0.3464239703860213, 'f1-score': 0.3301281761523563, 'support': 40595}, 'weighted avg': {'precision': 0.3603122226001088, 'recall': 0.3313708584801084, 'f1-score': 0.32962265429364834, 'support': 40595}}
[[3669 3396 7251]
 [4137 4646 6971]
 [2778 2610 5137]]
training model: results/QRTEA/W2/deepOF_L2/h10
Epoch 1/50
528/528 - 14s - loss: 2.9843 - accuracy10: 0.4769 - val_loss: 3.1024 - val_accuracy10: 0.6364 - 14s/epoch - 27ms/step
Epoch 2/50
528/528 - 12s - loss: 2.7086 - accuracy10: 0.5620 - val_loss: 3.0283 - val_accuracy10: 0.6782 - 12s/epoch - 23ms/step
Epoch 3/50
528/528 - 12s - loss: 2.5648 - accuracy10: 0.6005 - val_loss: 3.0355 - val_accuracy10: 0.6933 - 12s/epoch - 22ms/step
Epoch 4/50
528/528 - 12s - loss: 2.4624 - accuracy10: 0.6206 - val_loss: 2.9352 - val_accuracy10: 0.7016 - 12s/epoch - 23ms/step
Epoch 5/50
528/528 - 12s - loss: 2.4075 - accuracy10: 0.6318 - val_loss: 2.8790 - val_accuracy10: 0.6809 - 12s/epoch - 23ms/step
Epoch 6/50
528/528 - 12s - loss: 2.3642 - accuracy10: 0.6402 - val_loss: 2.9225 - val_accuracy10: 0.6864 - 12s/epoch - 22ms/step
Epoch 7/50
528/528 - 12s - loss: 2.3330 - accuracy10: 0.6433 - val_loss: 2.8934 - val_accuracy10: 0.6818 - 12s/epoch - 22ms/step
Epoch 8/50
528/528 - 12s - loss: 2.3100 - accuracy10: 0.6477 - val_loss: 2.8994 - val_accuracy10: 0.6983 - 12s/epoch - 22ms/step
Epoch 9/50
528/528 - 12s - loss: 2.2886 - accuracy10: 0.6489 - val_loss: 2.8706 - val_accuracy10: 0.6761 - 12s/epoch - 22ms/step
Epoch 10/50
528/528 - 12s - loss: 2.2724 - accuracy10: 0.6494 - val_loss: 2.8562 - val_accuracy10: 0.6849 - 12s/epoch - 22ms/step
Epoch 11/50
528/528 - 12s - loss: 2.2571 - accuracy10: 0.6524 - val_loss: 2.8946 - val_accuracy10: 0.6919 - 12s/epoch - 22ms/step
Epoch 12/50
528/528 - 12s - loss: 2.2438 - accuracy10: 0.6525 - val_loss: 2.9376 - val_accuracy10: 0.6932 - 12s/epoch - 22ms/step
Epoch 13/50
528/528 - 11s - loss: 2.2272 - accuracy10: 0.6548 - val_loss: 2.9400 - val_accuracy10: 0.6977 - 11s/epoch - 22ms/step
Epoch 14/50
528/528 - 12s - loss: 2.2185 - accuracy10: 0.6548 - val_loss: 2.8681 - val_accuracy10: 0.6894 - 12s/epoch - 22ms/step
Epoch 15/50
528/528 - 11s - loss: 2.2007 - accuracy10: 0.6557 - val_loss: 2.9119 - val_accuracy10: 0.6893 - 11s/epoch - 22ms/step
Epoch 16/50
528/528 - 11s - loss: 2.1933 - accuracy10: 0.6569 - val_loss: 2.8878 - val_accuracy10: 0.6802 - 11s/epoch - 22ms/step
Epoch 17/50
528/528 - 11s - loss: 2.1753 - accuracy10: 0.6590 - val_loss: 2.9100 - val_accuracy10: 0.6925 - 11s/epoch - 22ms/step
Epoch 18/50
528/528 - 11s - loss: 2.1621 - accuracy10: 0.6587 - val_loss: 2.9620 - val_accuracy10: 0.6835 - 11s/epoch - 22ms/step
Epoch 19/50
528/528 - 11s - loss: 2.1526 - accuracy10: 0.6605 - val_loss: 2.9065 - val_accuracy10: 0.6897 - 11s/epoch - 22ms/step
Epoch 20/50
528/528 - 11s - loss: 2.1353 - accuracy10: 0.6610 - val_loss: 2.9531 - val_accuracy10: 0.6792 - 11s/epoch - 22ms/step
testing model: results/QRTEA/W2/deepOF_L2/h10
Evaluating performance on  test set...
1242/1242 - 10s - 10s/epoch - 8ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.85116756
{'0': {'precision': 0.3920993023466522, 'recall': 0.430367158598194, 'f1-score': 0.41034296388306796, 'support': 50278}, '1': {'precision': 0.8494893766874047, 'recall': 0.665884550444196, 'f1-score': 0.746564054686271, 'support': 217359}, '2': {'precision': 0.3395027594357523, 'recall': 0.624279761548737, 'f1-score': 0.43981852148385375, 'support': 50157}, 'accuracy': 0.6220570558286186, 'macro avg': {'precision': 0.5270304794899364, 'recall': 0.5735104901970424, 'f1-score': 0.5322418466843976, 'support': 317794}, 'weighted avg': {'precision': 0.6966354621415182, 'recall': 0.6220570558286186, 'f1-score': 0.6449574802631003, 'support': 317794}}
[[ 21638  14227  14413]
 [ 26119 144736  46504]
 [  7428  11417  31312]]
Evaluating performance on  train set...
528/528 - 4s - 4s/epoch - 8ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.70390934
{'0': {'precision': 0.43064246329223715, 'recall': 0.4311232400917943, 'f1-score': 0.43088271757996527, 'support': 16123}, '1': {'precision': 0.8909867258641779, 'recall': 0.7663838202772609, 'f1-score': 0.8240013826405291, 'support': 102647}, '2': {'precision': 0.3256561679790026, 'recall': 0.6148795143405811, 'f1-score': 0.4257984256697338, 'support': 16143}, 'accuracy': 0.70818972226546, 'macro avg': {'precision': 0.5490951190451393, 'recall': 0.6041288582365455, 'f1-score': 0.5602275086300761, 'support': 134913}, 'weighted avg': {'precision': 0.7683279625026948, 'recall': 0.70818972226546, 'f1-score': 0.7293741593844232, 'support': 134913}}
[[ 6951  5255  3917]
 [ 7343 78667 16637]
 [ 1847  4370  9926]]
Evaluating performance on  val set...
159/159 - 1s - 1s/epoch - 9ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.7570003
{'0': {'precision': 0.41009174311926605, 'recall': 0.41175386882829773, 'f1-score': 0.41092112520683954, 'support': 5428}, '1': {'precision': 0.8714047277102822, 'recall': 0.7486078228683851, 'f1-score': 0.8053522743578706, 'support': 29989}, '2': {'precision': 0.3265110329389191, 'recall': 0.59165539887966, 'f1-score': 0.42079956037917293, 'support': 5177}, 'accuracy': 0.6835492929989654, 'macro avg': {'precision': 0.5360025012561558, 'recall': 0.5840056968587809, 'f1-score': 0.545690986647961, 'support': 40594}, 'weighted avg': {'precision': 0.7402296393181212, 'recall': 0.6835492929989654, 'f1-score': 0.7035687182200296, 'support': 40594}}
[[ 2235  1822  1371]
 [ 2592 22450  4947]
 [  623  1491  3063]]
training model: results/QRTEA/W2/deepOF_L2/h20
Epoch 1/50
528/528 - 14s - loss: 2.9983 - accuracy20: 0.4692 - val_loss: 3.1522 - val_accuracy20: 0.6216 - 14s/epoch - 26ms/step
Epoch 2/50
528/528 - 12s - loss: 2.7416 - accuracy20: 0.5478 - val_loss: 3.0854 - val_accuracy20: 0.6425 - 12s/epoch - 23ms/step
Epoch 3/50
528/528 - 12s - loss: 2.6140 - accuracy20: 0.5780 - val_loss: 2.9956 - val_accuracy20: 0.6626 - 12s/epoch - 23ms/step
Epoch 4/50
528/528 - 12s - loss: 2.5191 - accuracy20: 0.5997 - val_loss: 3.0504 - val_accuracy20: 0.6087 - 12s/epoch - 23ms/step
Epoch 5/50
528/528 - 12s - loss: 2.4723 - accuracy20: 0.6102 - val_loss: 2.8220 - val_accuracy20: 0.6409 - 12s/epoch - 23ms/step
Epoch 6/50
528/528 - 12s - loss: 2.4293 - accuracy20: 0.6169 - val_loss: 2.8187 - val_accuracy20: 0.6393 - 12s/epoch - 23ms/step
Epoch 7/50
528/528 - 12s - loss: 2.3991 - accuracy20: 0.6245 - val_loss: 2.8036 - val_accuracy20: 0.6325 - 12s/epoch - 22ms/step
Epoch 8/50
528/528 - 12s - loss: 2.3714 - accuracy20: 0.6291 - val_loss: 2.7873 - val_accuracy20: 0.6431 - 12s/epoch - 22ms/step
Epoch 9/50
528/528 - 12s - loss: 2.3510 - accuracy20: 0.6324 - val_loss: 2.8256 - val_accuracy20: 0.6386 - 12s/epoch - 22ms/step
Epoch 10/50
528/528 - 12s - loss: 2.3347 - accuracy20: 0.6342 - val_loss: 2.8244 - val_accuracy20: 0.6328 - 12s/epoch - 22ms/step
Epoch 11/50
528/528 - 12s - loss: 2.3195 - accuracy20: 0.6387 - val_loss: 2.7941 - val_accuracy20: 0.6506 - 12s/epoch - 22ms/step
Epoch 12/50
528/528 - 12s - loss: 2.3063 - accuracy20: 0.6387 - val_loss: 2.8038 - val_accuracy20: 0.6485 - 12s/epoch - 22ms/step
Epoch 13/50
528/528 - 12s - loss: 2.2912 - accuracy20: 0.6400 - val_loss: 2.7685 - val_accuracy20: 0.6419 - 12s/epoch - 22ms/step
Epoch 14/50
528/528 - 12s - loss: 2.2779 - accuracy20: 0.6421 - val_loss: 2.7806 - val_accuracy20: 0.6455 - 12s/epoch - 22ms/step
Epoch 15/50
528/528 - 11s - loss: 2.2639 - accuracy20: 0.6444 - val_loss: 2.8276 - val_accuracy20: 0.6451 - 11s/epoch - 22ms/step
Epoch 16/50
528/528 - 12s - loss: 2.2493 - accuracy20: 0.6449 - val_loss: 2.7877 - val_accuracy20: 0.6408 - 12s/epoch - 22ms/step
Epoch 17/50
528/528 - 11s - loss: 2.2391 - accuracy20: 0.6470 - val_loss: 2.8032 - val_accuracy20: 0.6359 - 11s/epoch - 22ms/step
Epoch 18/50
528/528 - 12s - loss: 2.2273 - accuracy20: 0.6483 - val_loss: 2.8121 - val_accuracy20: 0.6373 - 12s/epoch - 22ms/step
Epoch 19/50
528/528 - 12s - loss: 2.2155 - accuracy20: 0.6484 - val_loss: 2.7675 - val_accuracy20: 0.6284 - 12s/epoch - 22ms/step
Epoch 20/50
528/528 - 11s - loss: 2.1999 - accuracy20: 0.6509 - val_loss: 2.7926 - val_accuracy20: 0.6205 - 11s/epoch - 22ms/step
Epoch 21/50
528/528 - 11s - loss: 2.1839 - accuracy20: 0.6521 - val_loss: 2.8432 - val_accuracy20: 0.6097 - 11s/epoch - 22ms/step
Epoch 22/50
528/528 - 11s - loss: 2.1730 - accuracy20: 0.6531 - val_loss: 2.8368 - val_accuracy20: 0.5969 - 11s/epoch - 22ms/step
Epoch 23/50
528/528 - 11s - loss: 2.1628 - accuracy20: 0.6540 - val_loss: 2.8345 - val_accuracy20: 0.5972 - 11s/epoch - 22ms/step
Epoch 24/50
528/528 - 11s - loss: 2.1477 - accuracy20: 0.6557 - val_loss: 2.8312 - val_accuracy20: 0.6040 - 11s/epoch - 22ms/step
Epoch 25/50
528/528 - 12s - loss: 2.1358 - accuracy20: 0.6563 - val_loss: 2.8585 - val_accuracy20: 0.6081 - 12s/epoch - 22ms/step
Epoch 26/50
528/528 - 11s - loss: 2.1238 - accuracy20: 0.6569 - val_loss: 2.9223 - val_accuracy20: 0.5830 - 11s/epoch - 22ms/step
Epoch 27/50
528/528 - 11s - loss: 2.1125 - accuracy20: 0.6590 - val_loss: 2.9197 - val_accuracy20: 0.5891 - 11s/epoch - 22ms/step
Epoch 28/50
528/528 - 11s - loss: 2.0984 - accuracy20: 0.6600 - val_loss: 2.8835 - val_accuracy20: 0.5937 - 11s/epoch - 22ms/step
Epoch 29/50
528/528 - 11s - loss: 2.0878 - accuracy20: 0.6608 - val_loss: 2.9353 - val_accuracy20: 0.5955 - 11s/epoch - 22ms/step
testing model: results/QRTEA/W2/deepOF_L2/h20
Evaluating performance on  test set...
1242/1242 - 10s - 10s/epoch - 8ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.9135335
{'0': {'precision': 0.42982977163871655, 'recall': 0.5248927436031976, 'f1-score': 0.47262848527378465, 'support': 64798}, '1': {'precision': 0.7826715255089218, 'recall': 0.5983093450312995, 'f1-score': 0.6781841773357893, 'support': 187383}, '2': {'precision': 0.406011255384035, 'recall': 0.5904622559553747, 'f1-score': 0.48116546816200306, 'support': 65613}, 'accuracy': 0.5817196045236852, 'macro avg': {'precision': 0.5395041841772245, 'recall': 0.5712214481966239, 'f1-score': 0.5439927102571923, 'support': 317794}, 'weighted avg': {'precision': 0.6329605483633943, 'recall': 0.5817196045236852, 'f1-score': 0.5955942407754596, 'support': 317794}}
[[ 34012  17677  13109]
 [ 31700 112113  43570]
 [ 13417  13454  38742]]
Evaluating performance on  train set...
528/528 - 5s - 5s/epoch - 9ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.7648964
{'0': {'precision': 0.4823724595603484, 'recall': 0.5364391143911439, 'f1-score': 0.5079711727451409, 'support': 21680}, '1': {'precision': 0.8499100731585282, 'recall': 0.6877947887370184, 'f1-score': 0.7603067840898092, 'support': 91379}, '2': {'precision': 0.39016117653443316, 'recall': 0.6579573533449254, 'f1-score': 0.4898480615929685, 'support': 21854}, 'accuracy': 0.6586392712340545, 'macro avg': {'precision': 0.5741479030844365, 'recall': 0.6273970854910292, 'f1-score': 0.5860420061426396, 'support': 134913}, 'weighted avg': {'precision': 0.7163753667208127, 'recall': 0.6586392712340545, 'f1-score': 0.6759469301439451, 'support': 134913}}
[[11630  6418  3632]
 [ 9686 62850 18843]
 [ 2794  4681 14379]]
Evaluating performance on  val set...
159/159 - 1s - 1s/epoch - 9ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.84252733
{'0': {'precision': 0.45265311033569966, 'recall': 0.5175402393726785, 'f1-score': 0.48292682926829267, 'support': 7269}, '1': {'precision': 0.8167587476979742, 'recall': 0.6721224520724407, 'f1-score': 0.7374153053165398, 'support': 26394}, '2': {'precision': 0.3773549181103853, 'recall': 0.5750973885442217, 'f1-score': 0.4556990968332, 'support': 6931}, 'accuracy': 0.627876040794206, 'macro avg': {'precision': 0.5489222587146864, 'recall': 0.5882533599964469, 'f1-score': 0.5586804104726775, 'support': 40594}, 'weighted avg': {'precision': 0.6765362561756322, 'recall': 0.627876040794206, 'f1-score': 0.643745014795952, 'support': 40594}}
[[ 3762  2214  1293]
 [ 3370 17740  5284]
 [ 1179  1766  3986]]
training model: results/QRTEA/W2/deepOF_L2/h30
Epoch 1/50
528/528 - 14s - loss: 3.0257 - accuracy30: 0.4546 - val_loss: 3.1952 - val_accuracy30: 0.5789 - 14s/epoch - 27ms/step
Epoch 2/50
528/528 - 12s - loss: 2.8136 - accuracy30: 0.5207 - val_loss: 3.1204 - val_accuracy30: 0.6099 - 12s/epoch - 23ms/step
Epoch 3/50
528/528 - 12s - loss: 2.6886 - accuracy30: 0.5551 - val_loss: 3.1178 - val_accuracy30: 0.6335 - 12s/epoch - 22ms/step
Epoch 4/50
528/528 - 12s - loss: 2.6041 - accuracy30: 0.5745 - val_loss: 3.0913 - val_accuracy30: 0.6377 - 12s/epoch - 22ms/step
Epoch 5/50
528/528 - 11s - loss: 2.5501 - accuracy30: 0.5868 - val_loss: 3.0283 - val_accuracy30: 0.6364 - 11s/epoch - 22ms/step
Epoch 6/50
528/528 - 12s - loss: 2.5130 - accuracy30: 0.5931 - val_loss: 2.9808 - val_accuracy30: 0.6363 - 12s/epoch - 22ms/step
Epoch 7/50
528/528 - 12s - loss: 2.4862 - accuracy30: 0.5995 - val_loss: 2.9763 - val_accuracy30: 0.6271 - 12s/epoch - 22ms/step
Epoch 8/50
528/528 - 11s - loss: 2.4632 - accuracy30: 0.6054 - val_loss: 2.9454 - val_accuracy30: 0.6190 - 11s/epoch - 22ms/step
Epoch 9/50
528/528 - 12s - loss: 2.4448 - accuracy30: 0.6094 - val_loss: 2.9144 - val_accuracy30: 0.6131 - 12s/epoch - 22ms/step
Epoch 10/50
528/528 - 11s - loss: 2.4273 - accuracy30: 0.6116 - val_loss: 2.9121 - val_accuracy30: 0.6192 - 11s/epoch - 22ms/step
Epoch 11/50
528/528 - 11s - loss: 2.4136 - accuracy30: 0.6149 - val_loss: 2.9123 - val_accuracy30: 0.6273 - 11s/epoch - 21ms/step
Epoch 12/50
528/528 - 11s - loss: 2.4001 - accuracy30: 0.6166 - val_loss: 2.9058 - val_accuracy30: 0.6127 - 11s/epoch - 22ms/step
Epoch 13/50
528/528 - 11s - loss: 2.3882 - accuracy30: 0.6182 - val_loss: 2.9337 - val_accuracy30: 0.6282 - 11s/epoch - 22ms/step
Epoch 14/50
528/528 - 11s - loss: 2.3755 - accuracy30: 0.6190 - val_loss: 2.8874 - val_accuracy30: 0.6284 - 11s/epoch - 22ms/step
Epoch 15/50
528/528 - 11s - loss: 2.3597 - accuracy30: 0.6215 - val_loss: 2.8944 - val_accuracy30: 0.6303 - 11s/epoch - 22ms/step
Epoch 16/50
528/528 - 11s - loss: 2.3463 - accuracy30: 0.6246 - val_loss: 2.9143 - val_accuracy30: 0.6379 - 11s/epoch - 22ms/step
Epoch 17/50
528/528 - 11s - loss: 2.3338 - accuracy30: 0.6269 - val_loss: 2.9013 - val_accuracy30: 0.6467 - 11s/epoch - 22ms/step
Epoch 18/50
528/528 - 11s - loss: 2.3213 - accuracy30: 0.6267 - val_loss: 2.9480 - val_accuracy30: 0.6439 - 11s/epoch - 21ms/step
Epoch 19/50
528/528 - 11s - loss: 2.3106 - accuracy30: 0.6263 - val_loss: 2.9815 - val_accuracy30: 0.6445 - 11s/epoch - 22ms/step
Epoch 20/50
528/528 - 11s - loss: 2.2948 - accuracy30: 0.6299 - val_loss: 3.0036 - val_accuracy30: 0.6422 - 11s/epoch - 22ms/step
Epoch 21/50
528/528 - 11s - loss: 2.2791 - accuracy30: 0.6316 - val_loss: 3.0215 - val_accuracy30: 0.6333 - 11s/epoch - 22ms/step
Epoch 22/50
528/528 - 11s - loss: 2.2700 - accuracy30: 0.6334 - val_loss: 2.9867 - val_accuracy30: 0.6245 - 11s/epoch - 22ms/step
Epoch 23/50
528/528 - 11s - loss: 2.2575 - accuracy30: 0.6336 - val_loss: 3.0173 - val_accuracy30: 0.6138 - 11s/epoch - 22ms/step
Epoch 24/50
528/528 - 12s - loss: 2.2421 - accuracy30: 0.6357 - val_loss: 3.0201 - val_accuracy30: 0.6167 - 12s/epoch - 22ms/step
testing model: results/QRTEA/W2/deepOF_L2/h30
Evaluating performance on  test set...
1242/1242 - 9s - 9s/epoch - 8ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.9391491
{'0': {'precision': 0.4568345323741007, 'recall': 0.479251765087781, 'f1-score': 0.46777472672545806, 'support': 73934}, '1': {'precision': 0.698886282225922, 'recall': 0.6616021109943643, 'f1-score': 0.6797333104345052, 'support': 167504}, '2': {'precision': 0.46914184952978055, 'recall': 0.5017549373985017, 'f1-score': 0.48490064548791295, 'support': 76356}, 'accuracy': 0.5807724500777233, 'macro avg': {'precision': 0.5416208880432677, 'recall': 0.5475362711602157, 'f1-score': 0.5441362275492921, 'support': 317794}, 'weighted avg': {'precision': 0.5873731008049665, 'recall': 0.5807724500777233, 'f1-score': 0.5836094412217238, 'support': 317794}}
[[ 35433  26066  12435]
 [ 25766 110821  30917]
 [ 16363  21681  38312]]
Evaluating performance on  train set...
528/528 - 4s - 4s/epoch - 8ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.80656606
{'0': {'precision': 0.5180469877936738, 'recall': 0.4631904240337975, 'f1-score': 0.48908531422316764, 'support': 25564}, '1': {'precision': 0.7737554276481874, 'recall': 0.7340438270865765, 'f1-score': 0.7533766760480292, 'support': 83510}, '2': {'precision': 0.4441703216374269, 'recall': 0.564379426448392, 'f1-score': 0.4971110088459375, 'support': 25839}, 'accuracy': 0.6502264422257307, 'macro avg': {'precision': 0.5786575790264293, 'recall': 0.5872045591895887, 'f1-score': 0.5798576663723781, 'support': 134913}, 'weighted avg': {'precision': 0.6621792258688717, 'recall': 0.6502264422257307, 'f1-score': 0.6542165287788587, 'support': 134913}}
[[11841 10044  3679]
 [ 7640 61300 14570]
 [ 3376  7880 14583]]
Evaluating performance on  val set...
159/159 - 1s - 1s/epoch - 9ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.8651352
{'0': {'precision': 0.5019642630845267, 'recall': 0.46133240158397393, 'f1-score': 0.4807914062025854, 'support': 8586}, '1': {'precision': 0.742333630232854, 'recall': 0.7330680628272251, 'f1-score': 0.7376717525077973, 'support': 23875}, '2': {'precision': 0.44521148367302216, 'recall': 0.4995696544940366, 'f1-score': 0.470826814995075, 'support': 8133}, 'accuracy': 0.6288121397250825, 'macro avg': {'precision': 0.5631697923301343, 'recall': 0.5646567063017452, 'f1-score': 0.5630966579018192, 'support': 40594}, 'weighted avg': {'precision': 0.6319649598799287, 'recall': 0.6288121397250825, 'f1-score': 0.6298768929185102, 'support': 40594}}
[[ 3961  3355  1270]
 [ 2580 17502  3793]
 [ 1350  2720  4063]]
training model: results/QRTEA/W2/deepOF_L2/h50
Epoch 1/50
528/528 - 14s - loss: 3.0990 - accuracy50: 0.4336 - val_loss: 3.2056 - val_accuracy50: 0.5082 - 14s/epoch - 26ms/step
Epoch 2/50
528/528 - 12s - loss: 2.9175 - accuracy50: 0.4896 - val_loss: 3.1808 - val_accuracy50: 0.5383 - 12s/epoch - 22ms/step
Epoch 3/50
528/528 - 12s - loss: 2.8218 - accuracy50: 0.5215 - val_loss: 3.1840 - val_accuracy50: 0.5588 - 12s/epoch - 22ms/step
Epoch 4/50
528/528 - 11s - loss: 2.7520 - accuracy50: 0.5432 - val_loss: 3.1761 - val_accuracy50: 0.5666 - 11s/epoch - 22ms/step
Epoch 5/50
528/528 - 11s - loss: 2.7076 - accuracy50: 0.5521 - val_loss: 3.1358 - val_accuracy50: 0.5660 - 11s/epoch - 22ms/step
Epoch 6/50
528/528 - 12s - loss: 2.6720 - accuracy50: 0.5620 - val_loss: 3.1058 - val_accuracy50: 0.5706 - 12s/epoch - 22ms/step
Epoch 7/50
528/528 - 11s - loss: 2.6494 - accuracy50: 0.5681 - val_loss: 3.0539 - val_accuracy50: 0.5744 - 11s/epoch - 21ms/step
Epoch 8/50
528/528 - 11s - loss: 2.6290 - accuracy50: 0.5729 - val_loss: 3.0352 - val_accuracy50: 0.5724 - 11s/epoch - 22ms/step
Epoch 9/50
528/528 - 11s - loss: 2.6144 - accuracy50: 0.5761 - val_loss: 3.0245 - val_accuracy50: 0.5782 - 11s/epoch - 22ms/step
Epoch 10/50
528/528 - 11s - loss: 2.5952 - accuracy50: 0.5792 - val_loss: 3.0114 - val_accuracy50: 0.5756 - 11s/epoch - 22ms/step
Epoch 11/50
528/528 - 12s - loss: 2.5803 - accuracy50: 0.5833 - val_loss: 2.9894 - val_accuracy50: 0.5753 - 12s/epoch - 22ms/step
Epoch 12/50
528/528 - 11s - loss: 2.5664 - accuracy50: 0.5857 - val_loss: 2.9998 - val_accuracy50: 0.5736 - 11s/epoch - 21ms/step
Epoch 13/50
528/528 - 12s - loss: 2.5559 - accuracy50: 0.5876 - val_loss: 2.9669 - val_accuracy50: 0.5688 - 12s/epoch - 22ms/step
Epoch 14/50
528/528 - 12s - loss: 2.5408 - accuracy50: 0.5910 - val_loss: 2.9656 - val_accuracy50: 0.5623 - 12s/epoch - 22ms/step
Epoch 15/50
528/528 - 11s - loss: 2.5311 - accuracy50: 0.5919 - val_loss: 2.9750 - val_accuracy50: 0.5637 - 11s/epoch - 22ms/step
Epoch 16/50
528/528 - 11s - loss: 2.5160 - accuracy50: 0.5951 - val_loss: 2.9667 - val_accuracy50: 0.5677 - 11s/epoch - 22ms/step
Epoch 17/50
528/528 - 11s - loss: 2.4991 - accuracy50: 0.5975 - val_loss: 2.9777 - val_accuracy50: 0.5690 - 11s/epoch - 22ms/step
Epoch 18/50
528/528 - 11s - loss: 2.4855 - accuracy50: 0.5994 - val_loss: 3.0094 - val_accuracy50: 0.5618 - 11s/epoch - 22ms/step
Epoch 19/50
528/528 - 11s - loss: 2.4705 - accuracy50: 0.6033 - val_loss: 3.0534 - val_accuracy50: 0.5591 - 11s/epoch - 22ms/step
Epoch 20/50
528/528 - 11s - loss: 2.4605 - accuracy50: 0.6051 - val_loss: 3.0404 - val_accuracy50: 0.5627 - 11s/epoch - 22ms/step
Epoch 21/50
528/528 - 11s - loss: 2.4461 - accuracy50: 0.6064 - val_loss: 3.1187 - val_accuracy50: 0.5476 - 11s/epoch - 22ms/step
Epoch 22/50
528/528 - 11s - loss: 2.4291 - accuracy50: 0.6107 - val_loss: 3.0980 - val_accuracy50: 0.5368 - 11s/epoch - 22ms/step
Epoch 23/50
528/528 - 11s - loss: 2.4100 - accuracy50: 0.6128 - val_loss: 3.1079 - val_accuracy50: 0.5428 - 11s/epoch - 21ms/step
Epoch 24/50
528/528 - 11s - loss: 2.3915 - accuracy50: 0.6161 - val_loss: 3.2131 - val_accuracy50: 0.5380 - 11s/epoch - 22ms/step
testing model: results/QRTEA/W2/deepOF_L2/h50
Evaluating performance on  test set...
1242/1242 - 10s - 10s/epoch - 8ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.99526125
{'0': {'precision': 0.4339945768517197, 'recall': 0.5284223208183219, 'f1-score': 0.4765760494807447, 'support': 86323}, '1': {'precision': 0.5883918448262986, 'recall': 0.6171341493808435, 'f1-score': 0.602420358257509, 'support': 140433}, '2': {'precision': 0.5248639060492997, 'recall': 0.37702937235000766, 'f1-score': 0.4388304332817674, 'support': 91038}, 'accuracy': 0.524254705878651, 'macro avg': {'precision': 0.5157501092424394, 'recall': 0.5075286141830576, 'f1-score': 0.505942280340007, 'support': 317794}, 'weighted avg': {'precision': 0.5282538565264879, 'recall': 0.524254705878651, 'f1-score': 0.5213736492054873, 'support': 317794}}
[[45615 29005 11703]
 [34398 86666 19369]
 [25092 31622 34324]]
Evaluating performance on  train set...
528/528 - 4s - 4s/epoch - 8ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.87666243
{'0': {'precision': 0.4832719148071845, 'recall': 0.5248644901046262, 'f1-score': 0.5032102122516807, 'support': 31732}, '1': {'precision': 0.6719300852322613, 'recall': 0.6998255535859993, 'f1-score': 0.6855941839230955, 'support': 71082}, '2': {'precision': 0.5253435287882803, 'recall': 0.432349917442911, 'f1-score': 0.4743318066853511, 'support': 32099}, 'accuracy': 0.5950353190574666, 'macro avg': {'precision': 0.5601818429425753, 'recall': 0.5523466537111789, 'f1-score': 0.5543787342867091, 'support': 134913}, 'weighted avg': {'precision': 0.5926806212130498, 'recall': 0.5950353190574666, 'f1-score': 0.5924325224373106, 'support': 134913}}
[[16655 11632  3445]
 [12243 49745  9094]
 [ 5565 12656 13878]]
Evaluating performance on  val set...
159/159 - 1s - 1s/epoch - 9ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.9290421
{'0': {'precision': 0.462468249102216, 'recall': 0.4956350323852436, 'f1-score': 0.47847757136384234, 'support': 10653}, '1': {'precision': 0.6342143155743416, 'recall': 0.6827341367068354, 'f1-score': 0.6575804276632633, 'support': 19999}, '2': {'precision': 0.5092834728033473, 'recall': 0.39177227921947294, 'f1-score': 0.44286526435474705, 'support': 9942}, 'accuracy': 0.5623737498152437, 'macro avg': {'precision': 0.5353220124933017, 'recall': 0.5233804827705173, 'f1-score': 0.5263077544606175, 'support': 40594}, 'weighted avg': {'precision': 0.55854615562566, 'recall': 0.5623737498152437, 'f1-score': 0.5579922894711413, 'support': 40594}}
[[ 5280  4033  1340]
 [ 3932 13654  2413]
 [ 2205  3842  3895]]
training model: results/QRTEA/W2/deepOF_L2/h100
Epoch 1/50
528/528 - 14s - loss: 3.1945 - accuracy100: 0.4197 - val_loss: 3.2533 - val_accuracy100: 0.4220 - 14s/epoch - 26ms/step
Epoch 2/50
528/528 - 12s - loss: 3.0870 - accuracy100: 0.4578 - val_loss: 3.2536 - val_accuracy100: 0.4319 - 12s/epoch - 22ms/step
Epoch 3/50
528/528 - 12s - loss: 3.0233 - accuracy100: 0.4803 - val_loss: 3.3161 - val_accuracy100: 0.4370 - 12s/epoch - 22ms/step
Epoch 4/50
528/528 - 12s - loss: 2.9799 - accuracy100: 0.4955 - val_loss: 3.3136 - val_accuracy100: 0.4418 - 12s/epoch - 22ms/step
Epoch 5/50
528/528 - 12s - loss: 2.9485 - accuracy100: 0.5044 - val_loss: 3.3005 - val_accuracy100: 0.4451 - 12s/epoch - 22ms/step
Epoch 6/50
528/528 - 12s - loss: 2.9212 - accuracy100: 0.5112 - val_loss: 3.2959 - val_accuracy100: 0.4485 - 12s/epoch - 22ms/step
Epoch 7/50
528/528 - 12s - loss: 2.9019 - accuracy100: 0.5152 - val_loss: 3.2680 - val_accuracy100: 0.4521 - 12s/epoch - 22ms/step
Epoch 8/50
528/528 - 12s - loss: 2.8863 - accuracy100: 0.5174 - val_loss: 3.2608 - val_accuracy100: 0.4568 - 12s/epoch - 22ms/step
Epoch 9/50
528/528 - 12s - loss: 2.8729 - accuracy100: 0.5217 - val_loss: 3.2210 - val_accuracy100: 0.4613 - 12s/epoch - 22ms/step
Epoch 10/50
528/528 - 12s - loss: 2.8583 - accuracy100: 0.5242 - val_loss: 3.2138 - val_accuracy100: 0.4626 - 12s/epoch - 22ms/step
Epoch 11/50
528/528 - 12s - loss: 2.8459 - accuracy100: 0.5277 - val_loss: 3.1946 - val_accuracy100: 0.4666 - 12s/epoch - 22ms/step
Epoch 12/50
528/528 - 12s - loss: 2.8334 - accuracy100: 0.5304 - val_loss: 3.1770 - val_accuracy100: 0.4695 - 12s/epoch - 22ms/step
Epoch 13/50
528/528 - 12s - loss: 2.8228 - accuracy100: 0.5331 - val_loss: 3.1640 - val_accuracy100: 0.4756 - 12s/epoch - 23ms/step
Epoch 14/50
528/528 - 12s - loss: 2.8084 - accuracy100: 0.5379 - val_loss: 3.1709 - val_accuracy100: 0.4771 - 12s/epoch - 22ms/step
Epoch 15/50
528/528 - 12s - loss: 2.7971 - accuracy100: 0.5378 - val_loss: 3.1505 - val_accuracy100: 0.4770 - 12s/epoch - 23ms/step
Epoch 16/50
528/528 - 12s - loss: 2.8039 - accuracy100: 0.5381 - val_loss: 3.1787 - val_accuracy100: 0.4709 - 12s/epoch - 22ms/step
Epoch 17/50
528/528 - 12s - loss: 2.7774 - accuracy100: 0.5448 - val_loss: 3.1762 - val_accuracy100: 0.4698 - 12s/epoch - 22ms/step
Epoch 18/50
528/528 - 12s - loss: 2.7607 - accuracy100: 0.5488 - val_loss: 3.1549 - val_accuracy100: 0.4762 - 12s/epoch - 22ms/step
Epoch 19/50
528/528 - 11s - loss: 2.7460 - accuracy100: 0.5528 - val_loss: 3.1770 - val_accuracy100: 0.4775 - 11s/epoch - 22ms/step
Epoch 20/50
528/528 - 11s - loss: 2.7331 - accuracy100: 0.5582 - val_loss: 3.2217 - val_accuracy100: 0.4705 - 11s/epoch - 22ms/step
Epoch 21/50
528/528 - 11s - loss: 2.7123 - accuracy100: 0.5614 - val_loss: 3.2425 - val_accuracy100: 0.4720 - 11s/epoch - 22ms/step
Epoch 22/50
528/528 - 11s - loss: 2.6922 - accuracy100: 0.5669 - val_loss: 3.2527 - val_accuracy100: 0.4750 - 11s/epoch - 22ms/step
Epoch 23/50
528/528 - 11s - loss: 2.6808 - accuracy100: 0.5689 - val_loss: 3.3463 - val_accuracy100: 0.4628 - 11s/epoch - 22ms/step
Epoch 24/50
528/528 - 11s - loss: 2.6571 - accuracy100: 0.5773 - val_loss: 3.3129 - val_accuracy100: 0.4629 - 11s/epoch - 22ms/step
Epoch 25/50
528/528 - 11s - loss: 2.6382 - accuracy100: 0.5795 - val_loss: 3.3821 - val_accuracy100: 0.4588 - 11s/epoch - 22ms/step
testing model: results/QRTEA/W2/deepOF_L2/h100
Evaluating performance on  test set...
1242/1242 - 10s - 10s/epoch - 8ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0729064
{'0': {'precision': 0.48568543363365724, 'recall': 0.3532430370087753, 'f1-score': 0.4090098348344203, 'support': 104840}, '1': {'precision': 0.4106471830368286, 'recall': 0.6133329302822366, 'f1-score': 0.4919303349900998, 'support': 99243}, '2': {'precision': 0.49004457970765997, 'recall': 0.4021510671790768, 'f1-score': 0.44176846498282835, 'support': 113711}, 'accuracy': 0.4519657388119348, 'macro avg': {'precision': 0.4621257321260486, 'recall': 0.45624234482336296, 'f1-score': 0.4475695449357828, 'support': 317794}, 'weighted avg': {'precision': 0.4638117096339589, 'recall': 0.4519657388119348, 'f1-score': 0.44662632787631446, 'support': 317794}}
[[37034 43153 24653]
 [15440 60869 22934]
 [23777 44205 45729]]
Evaluating performance on  train set...
528/528 - 4s - 4s/epoch - 8ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 0.98851496
{'0': {'precision': 0.5816976694462263, 'recall': 0.32772785313320646, 'f1-score': 0.4192504468963817, 'support': 41507}, '1': {'precision': 0.4905469369887001, 'recall': 0.701667188478397, 'f1-score': 0.5774142123315245, 'support': 51104}, '2': {'precision': 0.5055945875618006, 'recall': 0.4593163443808803, 'f1-score': 0.4813456869642768, 'support': 42302}, 'accuracy': 0.5106327781607406, 'macro avg': {'precision': 0.525946397998909, 'recall': 0.4962371286641613, 'f1-score': 0.4926701153973943, 'support': 134913}, 'weighted avg': {'precision': 0.5233083400162648, 'recall': 0.5106327781607406, 'f1-score': 0.49863163265423777, 'support': 134913}}
[[13603 19571  8333]
 [ 4579 35858 10667]
 [ 5203 17669 19430]]
Evaluating performance on  val set...
159/159 - 1s - 1s/epoch - 9ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0329767
{'0': {'precision': 0.5290314401622718, 'recall': 0.30236939352220854, 'f1-score': 0.38480335654018166, 'support': 13801}, '1': {'precision': 0.4568799780280143, 'recall': 0.6956855091656793, 'f1-score': 0.5515431160721688, 'support': 14347}, '2': {'precision': 0.47117863720073666, 'recall': 0.4111361079865017, 'f1-score': 0.43911439114391143, 'support': 12446}, 'accuracy': 0.47472532886633495, 'macro avg': {'precision': 0.48569668513034087, 'recall': 0.46973033689146315, 'f1-score': 0.45848695458542066, 'support': 40594}, 'weighted avg': {'precision': 0.4857936953502439, 'recall': 0.47472532886633495, 'f1-score': 0.46038522742463356, 'support': 40594}}
[[4173 6653 2975]
 [1598 9981 2768]
 [2117 5212 5117]]
training model: results/QRTEA/W2/deepOF_L2/h200
Epoch 1/50
528/528 - 14s - loss: 3.2699 - accuracy200: 0.3894 - val_loss: 3.3393 - val_accuracy200: 0.3587 - 14s/epoch - 26ms/step
Epoch 2/50
528/528 - 12s - loss: 3.2309 - accuracy200: 0.4065 - val_loss: 3.3298 - val_accuracy200: 0.3623 - 12s/epoch - 23ms/step
Epoch 3/50
528/528 - 12s - loss: 3.2000 - accuracy200: 0.4218 - val_loss: 3.3116 - val_accuracy200: 0.3649 - 12s/epoch - 23ms/step
Epoch 4/50
528/528 - 12s - loss: 3.1818 - accuracy200: 0.4311 - val_loss: 3.3277 - val_accuracy200: 0.3632 - 12s/epoch - 23ms/step
Epoch 5/50
528/528 - 12s - loss: 3.1687 - accuracy200: 0.4369 - val_loss: 3.3285 - val_accuracy200: 0.3701 - 12s/epoch - 23ms/step
Epoch 6/50
528/528 - 12s - loss: 3.1574 - accuracy200: 0.4410 - val_loss: 3.3184 - val_accuracy200: 0.3717 - 12s/epoch - 23ms/step
Epoch 7/50
528/528 - 12s - loss: 3.1485 - accuracy200: 0.4430 - val_loss: 3.3261 - val_accuracy200: 0.3712 - 12s/epoch - 23ms/step
Epoch 8/50
528/528 - 12s - loss: 3.1390 - accuracy200: 0.4456 - val_loss: 3.3329 - val_accuracy200: 0.3698 - 12s/epoch - 23ms/step
Epoch 9/50
528/528 - 12s - loss: 3.1320 - accuracy200: 0.4490 - val_loss: 3.3199 - val_accuracy200: 0.3741 - 12s/epoch - 22ms/step
Epoch 10/50
528/528 - 11s - loss: 3.1224 - accuracy200: 0.4520 - val_loss: 3.3273 - val_accuracy200: 0.3704 - 11s/epoch - 22ms/step
Epoch 11/50
528/528 - 11s - loss: 3.1160 - accuracy200: 0.4551 - val_loss: 3.3301 - val_accuracy200: 0.3714 - 11s/epoch - 22ms/step
Epoch 12/50
528/528 - 11s - loss: 3.1080 - accuracy200: 0.4571 - val_loss: 3.3341 - val_accuracy200: 0.3704 - 11s/epoch - 22ms/step
Epoch 13/50
528/528 - 12s - loss: 3.1010 - accuracy200: 0.4597 - val_loss: 3.3548 - val_accuracy200: 0.3669 - 12s/epoch - 22ms/step
testing model: results/QRTEA/W2/deepOF_L2/h200
Evaluating performance on  test set...
1242/1242 - 9s - 9s/epoch - 8ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1084012
{'0': {'precision': 0.4024733912476419, 'recall': 0.1728705046766368, 'f1-score': 0.24185805657023693, 'support': 99965}, '1': {'precision': 0.34578223549648696, 'recall': 0.7519167783236564, 'f1-score': 0.47371722346954925, 'support': 107472}, '2': {'precision': 0.42811323047017374, 'recall': 0.15965457560462862, 'f1-score': 0.23257563757326155, 'support': 110357}, 'accuracy': 0.36410379050579933, 'macro avg': {'precision': 0.3921229524047676, 'recall': 0.36148061953497396, 'f1-score': 0.31605030587101596, 'support': 317794}, 'weighted avg': {'precision': 0.3922051792807477, 'recall': 0.36410379050579933, 'f1-score': 0.3170450911641993, 'support': 317794}}
[[17281 72359 10325]
 [13451 80810 13211]
 [12205 80533 17619]]
Evaluating performance on  train set...
528/528 - 4s - 4s/epoch - 8ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0889575
{'0': {'precision': 0.4904183691085918, 'recall': 0.1907896209729778, 'f1-score': 0.2747082715492231, 'support': 44667}, '1': {'precision': 0.3516733870967742, 'recall': 0.7796102619111469, 'f1-score': 0.4847028093478201, 'support': 44748}, '2': {'precision': 0.475021815008726, 'recall': 0.19143698624115346, 'f1-score': 0.27289532224206536, 'support': 45498}, 'accuracy': 0.3863082134412547, 'macro avg': {'precision': 0.439037857071364, 'recall': 0.3872789563750927, 'f1-score': 0.34410213437970283, 'support': 134913}, 'weighted avg': {'precision': 0.4392070486761612, 'recall': 0.3863082134412547, 'f1-score': 0.34374794904386446, 'support': 134913}}
[[ 8522 31603  4542]
 [ 4778 34886  5084]
 [ 4077 32711  8710]]
Evaluating performance on  val set...
159/159 - 1s - 1s/epoch - 8ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1041429
{'0': {'precision': 0.46460798074994986, 'recall': 0.1561636449416998, 'f1-score': 0.23375706214689262, 'support': 14837}, '1': {'precision': 0.3359479687551067, 'recall': 0.7828636709824829, 'f1-score': 0.47014430443433114, 'support': 13130}, '2': {'precision': 0.4538922155688623, 'recall': 0.18009028272748873, 'f1-score': 0.2578669841809832, 'support': 12627}, 'accuracy': 0.36631029216140315, 'macro avg': {'precision': 0.41814938835797294, 'recall': 0.37303919955055714, 'f1-score': 0.320589450254069, 'support': 40594}, 'weighted avg': {'precision': 0.41966010854139973, 'recall': 0.36631029216140315, 'f1-score': 0.3177152943181132, 'support': 40594}}
[[ 2317 11161  1359]
 [ 1474 10279  1377]
 [ 1196  9157  2274]]
training model: results/QRTEA/W2/deepOF_L2/h300
Epoch 1/50
528/528 - 14s - loss: 3.2949 - accuracy300: 0.3687 - val_loss: 3.3196 - val_accuracy300: 0.3549 - 14s/epoch - 26ms/step
Epoch 2/50
528/528 - 12s - loss: 3.2602 - accuracy300: 0.3872 - val_loss: 3.3115 - val_accuracy300: 0.3510 - 12s/epoch - 23ms/step
Epoch 3/50
528/528 - 12s - loss: 3.2436 - accuracy300: 0.3956 - val_loss: 3.3033 - val_accuracy300: 0.3548 - 12s/epoch - 22ms/step
Epoch 4/50
528/528 - 12s - loss: 3.2344 - accuracy300: 0.4011 - val_loss: 3.2923 - val_accuracy300: 0.3643 - 12s/epoch - 22ms/step
Epoch 5/50
528/528 - 12s - loss: 3.2270 - accuracy300: 0.4043 - val_loss: 3.2922 - val_accuracy300: 0.3613 - 12s/epoch - 22ms/step
Epoch 6/50
528/528 - 12s - loss: 3.2196 - accuracy300: 0.4089 - val_loss: 3.2914 - val_accuracy300: 0.3620 - 12s/epoch - 22ms/step
Epoch 7/50
528/528 - 11s - loss: 3.2140 - accuracy300: 0.4120 - val_loss: 3.2934 - val_accuracy300: 0.3640 - 11s/epoch - 22ms/step
Epoch 8/50
528/528 - 11s - loss: 3.2075 - accuracy300: 0.4148 - val_loss: 3.2995 - val_accuracy300: 0.3646 - 11s/epoch - 22ms/step
Epoch 9/50
528/528 - 12s - loss: 3.2019 - accuracy300: 0.4185 - val_loss: 3.2933 - val_accuracy300: 0.3679 - 12s/epoch - 22ms/step
Epoch 10/50
528/528 - 11s - loss: 3.1965 - accuracy300: 0.4206 - val_loss: 3.3046 - val_accuracy300: 0.3643 - 11s/epoch - 22ms/step
Epoch 11/50
528/528 - 11s - loss: 3.1925 - accuracy300: 0.4229 - val_loss: 3.3036 - val_accuracy300: 0.3657 - 11s/epoch - 22ms/step
Epoch 12/50
528/528 - 11s - loss: 3.1852 - accuracy300: 0.4263 - val_loss: 3.2986 - val_accuracy300: 0.3688 - 11s/epoch - 22ms/step
Epoch 13/50
528/528 - 11s - loss: 3.1781 - accuracy300: 0.4296 - val_loss: 3.2955 - val_accuracy300: 0.3721 - 11s/epoch - 22ms/step
Epoch 14/50
528/528 - 11s - loss: 3.1707 - accuracy300: 0.4355 - val_loss: 3.2925 - val_accuracy300: 0.3767 - 11s/epoch - 22ms/step
Epoch 15/50
528/528 - 11s - loss: 3.1649 - accuracy300: 0.4369 - val_loss: 3.2996 - val_accuracy300: 0.3752 - 11s/epoch - 22ms/step
Epoch 16/50
528/528 - 11s - loss: 3.1561 - accuracy300: 0.4401 - val_loss: 3.2856 - val_accuracy300: 0.3788 - 11s/epoch - 22ms/step
Epoch 17/50
528/528 - 11s - loss: 3.1505 - accuracy300: 0.4418 - val_loss: 3.2862 - val_accuracy300: 0.3810 - 11s/epoch - 22ms/step
Epoch 18/50
528/528 - 12s - loss: 3.1436 - accuracy300: 0.4454 - val_loss: 3.2785 - val_accuracy300: 0.3859 - 12s/epoch - 22ms/step
Epoch 19/50
528/528 - 11s - loss: 3.1320 - accuracy300: 0.4516 - val_loss: 3.2902 - val_accuracy300: 0.3862 - 11s/epoch - 21ms/step
Epoch 20/50
528/528 - 11s - loss: 3.1242 - accuracy300: 0.4534 - val_loss: 3.2942 - val_accuracy300: 0.3832 - 11s/epoch - 22ms/step
Epoch 21/50
528/528 - 11s - loss: 3.1116 - accuracy300: 0.4576 - val_loss: 3.3063 - val_accuracy300: 0.3828 - 11s/epoch - 22ms/step
Epoch 22/50
528/528 - 11s - loss: 3.1095 - accuracy300: 0.4593 - val_loss: 3.2859 - val_accuracy300: 0.3932 - 11s/epoch - 22ms/step
Epoch 23/50
528/528 - 11s - loss: 3.0865 - accuracy300: 0.4663 - val_loss: 3.2758 - val_accuracy300: 0.3936 - 11s/epoch - 22ms/step
Epoch 24/50
528/528 - 11s - loss: 3.0753 - accuracy300: 0.4698 - val_loss: 3.3000 - val_accuracy300: 0.3921 - 11s/epoch - 22ms/step
Epoch 25/50
528/528 - 11s - loss: 3.0552 - accuracy300: 0.4760 - val_loss: 3.3397 - val_accuracy300: 0.3816 - 11s/epoch - 21ms/step
Epoch 26/50
528/528 - 11s - loss: 3.0402 - accuracy300: 0.4816 - val_loss: 3.3391 - val_accuracy300: 0.3811 - 11s/epoch - 21ms/step
Epoch 27/50
528/528 - 11s - loss: 3.0249 - accuracy300: 0.4859 - val_loss: 3.3051 - val_accuracy300: 0.3941 - 11s/epoch - 22ms/step
Epoch 28/50
528/528 - 11s - loss: 3.0004 - accuracy300: 0.4936 - val_loss: 3.3223 - val_accuracy300: 0.3882 - 11s/epoch - 22ms/step
Epoch 29/50
528/528 - 12s - loss: 2.9807 - accuracy300: 0.4991 - val_loss: 3.3478 - val_accuracy300: 0.3866 - 12s/epoch - 22ms/step
Epoch 30/50
528/528 - 12s - loss: 2.9541 - accuracy300: 0.5058 - val_loss: 3.4531 - val_accuracy300: 0.3697 - 12s/epoch - 23ms/step
Epoch 31/50
528/528 - 12s - loss: 2.9308 - accuracy300: 0.5116 - val_loss: 3.4021 - val_accuracy300: 0.3791 - 12s/epoch - 23ms/step
Epoch 32/50
528/528 - 12s - loss: 2.9092 - accuracy300: 0.5155 - val_loss: 3.4004 - val_accuracy300: 0.3899 - 12s/epoch - 23ms/step
Epoch 33/50
528/528 - 12s - loss: 2.8750 - accuracy300: 0.5240 - val_loss: 3.4111 - val_accuracy300: 0.3826 - 12s/epoch - 22ms/step
testing model: results/QRTEA/W2/deepOF_L2/h300
Evaluating performance on  test set...
1242/1242 - 9s - 9s/epoch - 8ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1092826
{'0': {'precision': 0.3573363391702492, 'recall': 0.414836530365892, 'f1-score': 0.383945546297383, 'support': 98581}, '1': {'precision': 0.36722316865417376, 'recall': 0.29426647251547144, 'f1-score': 0.32672156823119286, 'support': 109880}, '2': {'precision': 0.39336513443191673, 'recall': 0.41483358180970065, 'f1-score': 0.40381422141893675, 'support': 109333}, 'accuracy': 0.3731473847838537, 'macro avg': {'precision': 0.37264154741877986, 'recall': 0.3746455282303547, 'f1-score': 0.3714937786491708, 'support': 317794}, 'weighted avg': {'precision': 0.37315004583569134, 'recall': 0.3731473847838537, 'f1-score': 0.37099543127680945, 'support': 317794}}
[[40895 26214 31472]
 [39073 32334 38473]
 [34476 29502 45355]]
Evaluating performance on  train set...
528/528 - 4s - 4s/epoch - 8ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0594023
{'0': {'precision': 0.472163565448538, 'recall': 0.4230324074074074, 'f1-score': 0.44624975053122173, 'support': 44928}, '1': {'precision': 0.3781044095286366, 'recall': 0.3191264212540808, 'f1-score': 0.34612097384679247, 'support': 44415}, '2': {'precision': 0.44283140643310653, 'recall': 0.5555848145709897, 'f1-score': 0.4928413614552816, 'support': 45570}, 'accuracy': 0.43359794830742776, 'macro avg': {'precision': 0.4310331271367604, 'recall': 0.43258121441082603, 'f1-score': 0.4284040286110986, 'support': 134913}, 'weighted avg': {'precision': 0.4312905295178595, 'recall': 0.43359794830742776, 'f1-score': 0.4290235387752789, 'support': 134913}}
[[19006 11854 14068]
 [12454 14174 17787]
 [ 8793 11459 25318]]
Evaluating performance on  val set...
159/159 - 1s - 1s/epoch - 8ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0931897
{'0': {'precision': 0.45258554549639407, 'recall': 0.39758711329783647, 'f1-score': 0.42330738043127264, 'support': 14837}, '1': {'precision': 0.3645505421476041, 'recall': 0.30522000146423606, 'f1-score': 0.3322574217971707, 'support': 13659}, '2': {'precision': 0.36467377821880426, 'recall': 0.4860307488841131, 'f1-score': 0.41669619445822403, 'support': 12098}, 'accuracy': 0.39286594077942555, 'macro avg': {'precision': 0.3939366219542675, 'recall': 0.39627928788206185, 'f1-score': 0.3907536655622225, 'support': 40594}, 'weighted avg': {'precision': 0.3967638311724692, 'recall': 0.39286594077942555, 'f1-score': 0.39070075105537616, 'support': 40594}}
[[5899 3956 4982]
 [4228 4169 5262]
 [2907 3311 5880]]
training model: results/QRTEA/W2/deepOF_L2/h500
Epoch 1/50
528/528 - 14s - loss: 3.2856 - accuracy500: 0.3805 - val_loss: 3.4911 - val_accuracy500: 0.3951 - 14s/epoch - 27ms/step
Epoch 2/50
528/528 - 12s - loss: 3.2740 - accuracy500: 0.3866 - val_loss: 3.4372 - val_accuracy500: 0.3949 - 12s/epoch - 23ms/step
Epoch 3/50
528/528 - 12s - loss: 3.2698 - accuracy500: 0.3867 - val_loss: 3.3728 - val_accuracy500: 0.3954 - 12s/epoch - 22ms/step
Epoch 4/50
528/528 - 12s - loss: 3.2648 - accuracy500: 0.3884 - val_loss: 3.3416 - val_accuracy500: 0.3940 - 12s/epoch - 22ms/step
Epoch 5/50
528/528 - 12s - loss: 3.2582 - accuracy500: 0.3915 - val_loss: 3.3239 - val_accuracy500: 0.3945 - 12s/epoch - 22ms/step
Epoch 6/50
528/528 - 12s - loss: 3.2526 - accuracy500: 0.3942 - val_loss: 3.3125 - val_accuracy500: 0.3954 - 12s/epoch - 22ms/step
Epoch 7/50
528/528 - 12s - loss: 3.2487 - accuracy500: 0.3958 - val_loss: 3.3095 - val_accuracy500: 0.3952 - 12s/epoch - 22ms/step
Epoch 8/50
528/528 - 11s - loss: 3.2413 - accuracy500: 0.3994 - val_loss: 3.3527 - val_accuracy500: 0.3944 - 11s/epoch - 22ms/step
Epoch 9/50
528/528 - 11s - loss: 3.2342 - accuracy500: 0.4032 - val_loss: 3.4064 - val_accuracy500: 0.3957 - 11s/epoch - 22ms/step
Epoch 10/50
528/528 - 11s - loss: 3.2291 - accuracy500: 0.4057 - val_loss: 3.3571 - val_accuracy500: 0.3952 - 11s/epoch - 22ms/step
Epoch 11/50
528/528 - 11s - loss: 3.2202 - accuracy500: 0.4106 - val_loss: 3.3744 - val_accuracy500: 0.3945 - 11s/epoch - 22ms/step
Epoch 12/50
528/528 - 11s - loss: 3.2086 - accuracy500: 0.4173 - val_loss: 3.3972 - val_accuracy500: 0.3963 - 11s/epoch - 22ms/step
Epoch 13/50
528/528 - 11s - loss: 3.1991 - accuracy500: 0.4213 - val_loss: 3.4077 - val_accuracy500: 0.3946 - 11s/epoch - 22ms/step
Epoch 14/50
528/528 - 12s - loss: 3.1929 - accuracy500: 0.4246 - val_loss: 3.4049 - val_accuracy500: 0.3964 - 12s/epoch - 22ms/step
Epoch 15/50
528/528 - 12s - loss: 3.1877 - accuracy500: 0.4267 - val_loss: 3.4551 - val_accuracy500: 0.3954 - 12s/epoch - 22ms/step
Epoch 16/50
528/528 - 12s - loss: 3.1823 - accuracy500: 0.4309 - val_loss: 3.4387 - val_accuracy500: 0.3951 - 12s/epoch - 22ms/step
Epoch 17/50
528/528 - 11s - loss: 3.1757 - accuracy500: 0.4336 - val_loss: 3.4684 - val_accuracy500: 0.3943 - 11s/epoch - 22ms/step
testing model: results/QRTEA/W2/deepOF_L2/h500
Evaluating performance on  test set...
1242/1242 - 10s - 10s/epoch - 8ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0716548
{'0': {'precision': 0.32417974322396576, 'recall': 0.022090451772825585, 'f1-score': 0.0413623643437308, 'support': 82298}, '1': {'precision': 0.448619536551688, 'recall': 0.9659778634182771, 'f1-score': 0.612692404800261, 'support': 141937}, '2': {'precision': 0.3485679463741621, 'recall': 0.024455156639126112, 'f1-score': 0.045703784345255336, 'support': 93559}, 'accuracy': 0.444357036319125, 'macro avg': {'precision': 0.373789075383272, 'recall': 0.33750782394340956, 'f1-score': 0.23325285116308236, 'support': 317794}, 'weighted avg': {'precision': 0.3869384700850334, 'recall': 0.444357036319125, 'f1-score': 0.2978148173988582, 'support': 317794}}
[[  1818  78812   1668]
 [  2221 137108   2608]
 [  1569  89702   2288]]
Evaluating performance on  train set...
528/528 - 4s - 4s/epoch - 8ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1418333
{'0': {'precision': 0.4380378657487091, 'recall': 0.022230471906186534, 'f1-score': 0.042313527443523076, 'support': 45793}, '1': {'precision': 0.3279154502106812, 'recall': 0.9655461803665396, 'f1-score': 0.4895661424340875, 'support': 44088}, '2': {'precision': 0.42568542568542567, 'recall': 0.026203588559246756, 'f1-score': 0.049368253702619026, 'support': 45032}, 'accuracy': 0.33182124776707955, 'macro avg': {'precision': 0.39721291388160535, 'recall': 0.33799341361065766, 'f1-score': 0.19374930786007652, 'support': 134913}, 'weighted avg': {'precision': 0.3979280754603725, 'recall': 0.33182124776707955, 'f1-score': 0.19082524775664053, 'support': 134913}}
[[ 1018 43999   776]
 [  703 42569   816]
 [  603 43249  1180]]
Evaluating performance on  val set...
159/159 - 1s - 1s/epoch - 9ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.106224
{'0': {'precision': 0.44315992292870904, 'recall': 0.016688434189522566, 'f1-score': 0.032165582826375785, 'support': 13782}, '1': {'precision': 0.39621682090918336, 'recall': 0.973878265216848, 'f1-score': 0.5632703220443128, 'support': 16002}, '2': {'precision': 0.35262449528936746, 'recall': 0.0242368177613321, 'f1-score': 0.04535618454081192, 'support': 10810}, 'accuracy': 0.3960191161255358, 'macro avg': {'precision': 0.3973337463757533, 'recall': 0.33826783905590085, 'f1-score': 0.21359736313716685, 'support': 40594}, 'weighted avg': {'precision': 0.40054595309824803, 'recall': 0.3960191161255358, 'f1-score': 0.24503764375898854, 'support': 40594}}
[[  230 13316   236]
 [  173 15584   245]
 [  116 10432   262]]
training model: results/QRTEA/W2/deepOF_L2/h1000
Epoch 1/50
528/528 - 14s - loss: 3.3278 - accuracy1000: 0.3580 - val_loss: 3.3244 - val_accuracy1000: 0.3834 - 14s/epoch - 27ms/step
Epoch 2/50
528/528 - 12s - loss: 3.3096 - accuracy1000: 0.3602 - val_loss: 3.3307 - val_accuracy1000: 0.3834 - 12s/epoch - 23ms/step
Epoch 3/50
528/528 - 12s - loss: 3.2995 - accuracy1000: 0.3651 - val_loss: 3.3403 - val_accuracy1000: 0.3850 - 12s/epoch - 23ms/step
Epoch 4/50
528/528 - 12s - loss: 3.2953 - accuracy1000: 0.3651 - val_loss: 3.3181 - val_accuracy1000: 0.3835 - 12s/epoch - 23ms/step
Epoch 5/50
528/528 - 12s - loss: 3.2947 - accuracy1000: 0.3631 - val_loss: 3.3140 - val_accuracy1000: 0.3780 - 12s/epoch - 23ms/step
Epoch 6/50
528/528 - 12s - loss: 3.2892 - accuracy1000: 0.3644 - val_loss: 3.3087 - val_accuracy1000: 0.3790 - 12s/epoch - 23ms/step
Epoch 7/50
528/528 - 12s - loss: 3.2860 - accuracy1000: 0.3655 - val_loss: 3.3050 - val_accuracy1000: 0.3778 - 12s/epoch - 23ms/step
Epoch 8/50
528/528 - 12s - loss: 3.2818 - accuracy1000: 0.3699 - val_loss: 3.3057 - val_accuracy1000: 0.3773 - 12s/epoch - 22ms/step
Epoch 9/50
528/528 - 12s - loss: 3.2806 - accuracy1000: 0.3713 - val_loss: 3.3025 - val_accuracy1000: 0.3786 - 12s/epoch - 23ms/step
Epoch 10/50
528/528 - 12s - loss: 3.2774 - accuracy1000: 0.3730 - val_loss: 3.3049 - val_accuracy1000: 0.3725 - 12s/epoch - 23ms/step
Epoch 11/50
528/528 - 12s - loss: 3.2751 - accuracy1000: 0.3753 - val_loss: 3.3040 - val_accuracy1000: 0.3731 - 12s/epoch - 23ms/step
Epoch 12/50
528/528 - 12s - loss: 3.2714 - accuracy1000: 0.3783 - val_loss: 3.3052 - val_accuracy1000: 0.3728 - 12s/epoch - 23ms/step
Epoch 13/50
528/528 - 12s - loss: 3.2686 - accuracy1000: 0.3811 - val_loss: 3.3079 - val_accuracy1000: 0.3668 - 12s/epoch - 22ms/step
Epoch 14/50
528/528 - 12s - loss: 3.2657 - accuracy1000: 0.3833 - val_loss: 3.3097 - val_accuracy1000: 0.3681 - 12s/epoch - 22ms/step
Epoch 15/50
528/528 - 12s - loss: 3.2631 - accuracy1000: 0.3869 - val_loss: 3.3107 - val_accuracy1000: 0.3664 - 12s/epoch - 22ms/step
Epoch 16/50
528/528 - 12s - loss: 3.2590 - accuracy1000: 0.3900 - val_loss: 3.3238 - val_accuracy1000: 0.3503 - 12s/epoch - 22ms/step
Epoch 17/50
528/528 - 12s - loss: 3.2559 - accuracy1000: 0.3914 - val_loss: 3.3209 - val_accuracy1000: 0.3470 - 12s/epoch - 22ms/step
Epoch 18/50
528/528 - 12s - loss: 3.2528 - accuracy1000: 0.3929 - val_loss: 3.3235 - val_accuracy1000: 0.3385 - 12s/epoch - 22ms/step
Epoch 19/50
528/528 - 12s - loss: 3.2502 - accuracy1000: 0.3934 - val_loss: 3.3376 - val_accuracy1000: 0.3253 - 12s/epoch - 22ms/step
testing model: results/QRTEA/W2/deepOF_L2/h1000
Evaluating performance on  test set...
1242/1242 - 9s - 9s/epoch - 8ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0897815
{'0': {'precision': 0.30976805295871446, 'recall': 0.0694688410149477, 'f1-score': 0.11348699435342036, 'support': 88241}, '1': {'precision': 0.4040710953903667, 'recall': 0.7760320667090574, 'f1-score': 0.5314317210968721, 'support': 124241}, '2': {'precision': 0.37335847531820326, 'recall': 0.2105742935278031, 'f1-score': 0.26927653787308453, 'support': 105312}, 'accuracy': 0.3924586367269363, 'macro avg': {'precision': 0.3623992078890948, 'recall': 0.35202506708393605, 'f1-score': 0.3047317511077923, 'support': 317794}, 'weighted avg': {'precision': 0.3677085391046876, 'recall': 0.3924586367269363, 'f1-score': 0.3285079802829095, 'support': 317794}}
[[ 6130 65732 16379]
 [ 6985 96415 20841]
 [ 6674 76462 22176]]
Evaluating performance on  train set...
528/528 - 4s - 4s/epoch - 8ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1051136
{'0': {'precision': 0.4304662929030494, 'recall': 0.06757539980680477, 'f1-score': 0.11681323982337008, 'support': 46585}, '1': {'precision': 0.3413871325836189, 'recall': 0.7928885301766657, 'f1-score': 0.4772771746098152, 'support': 44604}, '2': {'precision': 0.3753384711518434, 'recall': 0.20606531881804044, 'f1-score': 0.2660603286627589, 'support': 43724}, 'accuracy': 0.35225663946395086, 'macro avg': {'precision': 0.3823972988795039, 'recall': 0.3555097496005036, 'f1-score': 0.28671691436531477, 'support': 134913}, 'weighted avg': {'precision': 0.3831491644933512, 'recall': 0.35225663946395086, 'f1-score': 0.28435686467514887, 'support': 134913}}
[[ 3148 35545  7892]
 [ 2135 35366  7103]
 [ 2030 32684  9010]]
Evaluating performance on  val set...
159/159 - 1s - 1s/epoch - 9ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1055168
{'0': {'precision': 0.4137371552190373, 'recall': 0.05344418052256532, 'f1-score': 0.09466064468229908, 'support': 14314}, '1': {'precision': 0.3989529798576308, 'recall': 0.7934230573895379, 'f1-score': 0.5309373606066399, 'support': 15752}, '2': {'precision': 0.29401455918037206, 'recall': 0.20716185410334345, 'f1-score': 0.24306252089602137, 'support': 10528}, 'accuracy': 0.38045031285411635, 'macro avg': {'precision': 0.36890156475234676, 'recall': 0.35134303067181555, 'f1-score': 0.2895535087283201, 'support': 40594}, 'weighted avg': {'precision': 0.3769504423701448, 'recall': 0.38045031285411635, 'f1-score': 0.3024402619168235, 'support': 40594}}
[[  765 10937  2612]
 [  629 12498  2625]
 [  455  7892  2181]]
training model: results/QRTEA/W2/deepVOL_L2/h10
Epoch 1/50
528/528 - 14s - loss: 2.8413 - accuracy10: 0.5394 - val_loss: 3.0795 - val_accuracy10: 0.5298 - 14s/epoch - 27ms/step
Epoch 2/50
528/528 - 11s - loss: 2.5342 - accuracy10: 0.6165 - val_loss: 2.9932 - val_accuracy10: 0.5640 - 11s/epoch - 22ms/step
Epoch 3/50
528/528 - 11s - loss: 2.4645 - accuracy10: 0.6308 - val_loss: 2.8558 - val_accuracy10: 0.5888 - 11s/epoch - 21ms/step
Epoch 4/50
528/528 - 11s - loss: 2.4269 - accuracy10: 0.6406 - val_loss: 2.8373 - val_accuracy10: 0.5666 - 11s/epoch - 21ms/step
Epoch 5/50
528/528 - 11s - loss: 2.3989 - accuracy10: 0.6467 - val_loss: 2.7939 - val_accuracy10: 0.5391 - 11s/epoch - 20ms/step
Epoch 6/50
528/528 - 11s - loss: 2.3829 - accuracy10: 0.6487 - val_loss: 2.8371 - val_accuracy10: 0.5410 - 11s/epoch - 21ms/step
Epoch 7/50
528/528 - 11s - loss: 2.3661 - accuracy10: 0.6529 - val_loss: 2.8164 - val_accuracy10: 0.5647 - 11s/epoch - 21ms/step
Epoch 8/50
528/528 - 11s - loss: 2.3520 - accuracy10: 0.6535 - val_loss: 2.8433 - val_accuracy10: 0.5639 - 11s/epoch - 20ms/step
Epoch 9/50
528/528 - 11s - loss: 2.3412 - accuracy10: 0.6535 - val_loss: 2.8339 - val_accuracy10: 0.5621 - 11s/epoch - 20ms/step
Epoch 10/50
528/528 - 11s - loss: 2.3308 - accuracy10: 0.6539 - val_loss: 2.8250 - val_accuracy10: 0.5583 - 11s/epoch - 20ms/step
Epoch 11/50
528/528 - 11s - loss: 2.3217 - accuracy10: 0.6553 - val_loss: 2.8084 - val_accuracy10: 0.5774 - 11s/epoch - 20ms/step
Epoch 12/50
528/528 - 11s - loss: 2.3102 - accuracy10: 0.6599 - val_loss: 2.7829 - val_accuracy10: 0.5950 - 11s/epoch - 21ms/step
Epoch 13/50
528/528 - 11s - loss: 2.3050 - accuracy10: 0.6588 - val_loss: 2.7917 - val_accuracy10: 0.5855 - 11s/epoch - 20ms/step
Epoch 14/50
528/528 - 11s - loss: 2.2951 - accuracy10: 0.6606 - val_loss: 2.7982 - val_accuracy10: 0.5845 - 11s/epoch - 20ms/step
Epoch 15/50
528/528 - 11s - loss: 2.2839 - accuracy10: 0.6614 - val_loss: 2.7904 - val_accuracy10: 0.5721 - 11s/epoch - 21ms/step
Epoch 16/50
528/528 - 12s - loss: 2.2767 - accuracy10: 0.6626 - val_loss: 2.7744 - val_accuracy10: 0.5631 - 12s/epoch - 23ms/step
Epoch 17/50
528/528 - 12s - loss: 2.2727 - accuracy10: 0.6627 - val_loss: 2.7612 - val_accuracy10: 0.5900 - 12s/epoch - 22ms/step
Epoch 18/50
528/528 - 11s - loss: 2.2594 - accuracy10: 0.6636 - val_loss: 2.7644 - val_accuracy10: 0.6002 - 11s/epoch - 20ms/step
Epoch 19/50
528/528 - 11s - loss: 2.2519 - accuracy10: 0.6630 - val_loss: 2.8078 - val_accuracy10: 0.5782 - 11s/epoch - 20ms/step
Epoch 20/50
528/528 - 11s - loss: 2.2442 - accuracy10: 0.6676 - val_loss: 2.7673 - val_accuracy10: 0.5993 - 11s/epoch - 21ms/step
Epoch 21/50
528/528 - 11s - loss: 2.2340 - accuracy10: 0.6673 - val_loss: 2.8149 - val_accuracy10: 0.5846 - 11s/epoch - 20ms/step
Epoch 22/50
528/528 - 11s - loss: 2.2244 - accuracy10: 0.6695 - val_loss: 2.7791 - val_accuracy10: 0.5931 - 11s/epoch - 20ms/step
Epoch 23/50
528/528 - 11s - loss: 2.2154 - accuracy10: 0.6692 - val_loss: 2.7314 - val_accuracy10: 0.5846 - 11s/epoch - 20ms/step
Epoch 24/50
528/528 - 11s - loss: 2.2114 - accuracy10: 0.6692 - val_loss: 2.7707 - val_accuracy10: 0.6163 - 11s/epoch - 20ms/step
Epoch 25/50
528/528 - 11s - loss: 2.2074 - accuracy10: 0.6664 - val_loss: 2.7463 - val_accuracy10: 0.5864 - 11s/epoch - 22ms/step
Epoch 26/50
528/528 - 11s - loss: 2.2025 - accuracy10: 0.6671 - val_loss: 2.7443 - val_accuracy10: 0.5966 - 11s/epoch - 20ms/step
Epoch 27/50
528/528 - 11s - loss: 2.1881 - accuracy10: 0.6706 - val_loss: 2.7353 - val_accuracy10: 0.6187 - 11s/epoch - 20ms/step
Epoch 28/50
528/528 - 11s - loss: 2.1792 - accuracy10: 0.6732 - val_loss: 2.7422 - val_accuracy10: 0.5997 - 11s/epoch - 20ms/step
Epoch 29/50
528/528 - 11s - loss: 2.1719 - accuracy10: 0.6720 - val_loss: 2.7538 - val_accuracy10: 0.6362 - 11s/epoch - 21ms/step
Epoch 30/50
528/528 - 11s - loss: 2.1593 - accuracy10: 0.6751 - val_loss: 2.8147 - val_accuracy10: 0.6269 - 11s/epoch - 20ms/step
Epoch 31/50
528/528 - 11s - loss: 2.1607 - accuracy10: 0.6720 - val_loss: 2.8335 - val_accuracy10: 0.6233 - 11s/epoch - 20ms/step
Epoch 32/50
528/528 - 11s - loss: 2.2377 - accuracy10: 0.6605 - val_loss: 2.8112 - val_accuracy10: 0.6466 - 11s/epoch - 20ms/step
Epoch 33/50
528/528 - 11s - loss: 2.1720 - accuracy10: 0.6673 - val_loss: 2.7888 - val_accuracy10: 0.6212 - 11s/epoch - 21ms/step
testing model: results/QRTEA/W2/deepVOL_L2/h10
Evaluating performance on  test set...
1242/1242 - 10s - 10s/epoch - 8ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 1.0541645
{'0': {'precision': 0.30988499682212284, 'recall': 0.5139317038245063, 'f1-score': 0.3866387371885988, 'support': 50281}, '1': {'precision': 0.8834837439135659, 'recall': 0.4499401913875598, 'f1-score': 0.5962317524088802, 'support': 217360}, '2': {'precision': 0.28940370050035163, 'recall': 0.7138043781649986, 'f1-score': 0.41183406088421876, 'support': 50158}, 'accuracy': 0.5017102004726258, 'macro avg': {'precision': 0.49425748041201345, 'recall': 0.5592254244590216, 'f1-score': 0.4649015168272326, 'support': 317799}, 'weighted avg': {'precision': 0.6989677906851893, 'recall': 0.5017102004726258, 'f1-score': 0.5339673468890864, 'support': 317799}}
[[25841  8028 16412]
 [48063 97799 71498]
 [ 9485  4870 35803]]
Evaluating performance on  train set...
528/528 - 4s - 4s/epoch - 8ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.8017427
{'0': {'precision': 0.3681214421252372, 'recall': 0.5072526925231899, 'f1-score': 0.4266303636411236, 'support': 16063}, '1': {'precision': 0.918827634333566, 'recall': 0.6412007051513056, 'f1-score': 0.7553105442196383, 'support': 102673}, '2': {'precision': 0.287089715536105, 'recall': 0.7298800840647793, 'f1-score': 0.41208906260905975, 'support': 16178}, 'accuracy': 0.6358865647745972, 'macro avg': {'precision': 0.524679597331636, 'recall': 0.6261111605797582, 'f1-score': 0.5313433234899406, 'support': 134914}, 'weighted avg': {'precision': 0.7775061286651571, 'recall': 0.6358865647745972, 'f1-score': 0.6750206790453152, 'support': 134914}}
[[ 8148  3460  4455]
 [11972 65834 24867]
 [ 2014  2356 11808]]
Evaluating performance on  val set...
159/159 - 1s - 1s/epoch - 8ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.8999257
{'0': {'precision': 0.34445277361319343, 'recall': 0.5126441056154705, 'f1-score': 0.4120460319832611, 'support': 5378}, '1': {'precision': 0.9063611634233103, 'recall': 0.5771677937306373, 'f1-score': 0.7052406634781725, 'support': 30019}, '2': {'precision': 0.26827458256029685, 'recall': 0.6954597922277799, 'f1-score': 0.38719006051518234, 'support': 5198}, 'accuracy': 0.5837664737036581, 'macro avg': {'precision': 0.5063628398656002, 'recall': 0.5950905638579626, 'f1-score': 0.5014922519922053, 'support': 40595}, 'weighted avg': {'precision': 0.7502158901698369, 'recall': 0.5837664737036581, 'f1-score': 0.6256735305213734, 'support': 40595}}
[[ 2757  1063  1558]
 [ 4391 17326  8302]
 [  856   727  3615]]
training model: results/QRTEA/W2/deepVOL_L2/h20
Epoch 1/50
528/528 - 13s - loss: 2.8877 - accuracy20: 0.5234 - val_loss: 3.0828 - val_accuracy20: 0.5785 - 13s/epoch - 25ms/step
Epoch 2/50
528/528 - 11s - loss: 2.6300 - accuracy20: 0.5983 - val_loss: 3.0009 - val_accuracy20: 0.5794 - 11s/epoch - 20ms/step
Epoch 3/50
528/528 - 11s - loss: 2.5502 - accuracy20: 0.6156 - val_loss: 2.8822 - val_accuracy20: 0.5739 - 11s/epoch - 20ms/step
Epoch 4/50
528/528 - 11s - loss: 2.5073 - accuracy20: 0.6220 - val_loss: 2.9272 - val_accuracy20: 0.5658 - 11s/epoch - 20ms/step
Epoch 5/50
528/528 - 11s - loss: 2.4876 - accuracy20: 0.6255 - val_loss: 2.9056 - val_accuracy20: 0.5643 - 11s/epoch - 20ms/step
Epoch 6/50
528/528 - 11s - loss: 2.4610 - accuracy20: 0.6298 - val_loss: 2.9350 - val_accuracy20: 0.5650 - 11s/epoch - 20ms/step
Epoch 7/50
528/528 - 11s - loss: 2.4417 - accuracy20: 0.6354 - val_loss: 2.9852 - val_accuracy20: 0.5429 - 11s/epoch - 20ms/step
Epoch 8/50
528/528 - 11s - loss: 2.4332 - accuracy20: 0.6354 - val_loss: 2.9320 - val_accuracy20: 0.5618 - 11s/epoch - 20ms/step
Epoch 9/50
528/528 - 11s - loss: 2.4244 - accuracy20: 0.6374 - val_loss: 2.9613 - val_accuracy20: 0.5414 - 11s/epoch - 20ms/step
Epoch 10/50
528/528 - 11s - loss: 2.4081 - accuracy20: 0.6434 - val_loss: 2.9433 - val_accuracy20: 0.5418 - 11s/epoch - 21ms/step
Epoch 11/50
528/528 - 11s - loss: 2.3962 - accuracy20: 0.6440 - val_loss: 2.9489 - val_accuracy20: 0.5239 - 11s/epoch - 20ms/step
Epoch 12/50
528/528 - 11s - loss: 2.3891 - accuracy20: 0.6447 - val_loss: 2.9838 - val_accuracy20: 0.5226 - 11s/epoch - 21ms/step
Epoch 13/50
528/528 - 11s - loss: 2.3799 - accuracy20: 0.6472 - val_loss: 2.9093 - val_accuracy20: 0.5476 - 11s/epoch - 20ms/step
testing model: results/QRTEA/W2/deepVOL_L2/h20
Evaluating performance on  test set...
1242/1242 - 10s - 10s/epoch - 8ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 1.0244663
{'0': {'precision': 0.41191239588104567, 'recall': 0.3747125727248877, 'f1-score': 0.3924328867195707, 'support': 64799}, '1': {'precision': 0.7973770954152051, 'recall': 0.4828160355206421, 'f1-score': 0.6014505760422276, 'support': 187384}, '2': {'precision': 0.32936928261916226, 'recall': 0.7298067544501341, 'f1-score': 0.45389230637991335, 'support': 65616}, 'accuracy': 0.5117700181561301, 'macro avg': {'precision': 0.5128862579718044, 'recall': 0.5291117875652213, 'f1-score': 0.48259192304723725, 'support': 317799}, 'weighted avg': {'precision': 0.6221514725858722, 'recall': 0.5117700181561301, 'f1-score': 0.5283656365912499, 'support': 317799}}
[[24281 14640 25878]
 [25287 90472 71625]
 [ 9379  8350 47887]]
Evaluating performance on  train set...
528/528 - 4s - 4s/epoch - 8ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.8334693
{'0': {'precision': 0.4717613541142953, 'recall': 0.39017741637405284, 'f1-score': 0.4271083575673284, 'support': 21644}, '1': {'precision': 0.8524347131942068, 'recall': 0.6541953834372607, 'f1-score': 0.7402730840172812, 'support': 91410}, '2': {'precision': 0.33168306267471886, 'recall': 0.7110247026532479, 'f1-score': 0.4523508097961322, 'support': 21860}, 'accuracy': 0.621047482099708, 'macro avg': {'precision': 0.551959709994407, 'recall': 0.5851325008215205, 'f1-score': 0.5399107504602473, 'support': 134914}, 'weighted avg': {'precision': 0.706987055691786, 'recall': 0.621047482099708, 'f1-score': 0.6433808544950885, 'support': 134914}}
[[ 8445  6143  7056]
 [ 7348 59800 24262]
 [ 2108  4209 15543]]
Evaluating performance on  val set...
159/159 - 1s - 1s/epoch - 8ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.91455996
{'0': {'precision': 0.47543698252069916, 'recall': 0.35933806146572106, 'f1-score': 0.4093141137335657, 'support': 7191}, '1': {'precision': 0.83057129242336, 'recall': 0.5933055975794251, 'f1-score': 0.6921702296644384, 'support': 26440}, '2': {'precision': 0.3096540281447797, 'recall': 0.7235784032165422, 'f1-score': 0.4337048672375952, 'support': 6964}, 'accuracy': 0.5742086463850228, 'macro avg': {'precision': 0.538554101029613, 'recall': 0.5587406874205628, 'f1-score': 0.5117297368785331, 'support': 40595}, 'weighted avg': {'precision': 0.6783003563241836, 'recall': 0.5742086463850228, 'f1-score': 0.597725812529337, 'support': 40595}}
[[ 2584  2008  2599]
 [ 2118 15687  8635]
 [  733  1192  5039]]
training model: results/QRTEA/W2/deepVOL_L2/h30
Epoch 1/50
528/528 - 13s - loss: 2.9445 - accuracy30: 0.5038 - val_loss: 3.1309 - val_accuracy30: 0.5523 - 13s/epoch - 25ms/step
Epoch 2/50
528/528 - 11s - loss: 2.6902 - accuracy30: 0.5838 - val_loss: 2.9535 - val_accuracy30: 0.5662 - 11s/epoch - 21ms/step
Epoch 3/50
528/528 - 11s - loss: 2.6226 - accuracy30: 0.6010 - val_loss: 2.9580 - val_accuracy30: 0.5814 - 11s/epoch - 21ms/step
Epoch 4/50
528/528 - 11s - loss: 2.5745 - accuracy30: 0.6054 - val_loss: 2.9708 - val_accuracy30: 0.5662 - 11s/epoch - 21ms/step
Epoch 5/50
528/528 - 11s - loss: 2.5480 - accuracy30: 0.6110 - val_loss: 2.9783 - val_accuracy30: 0.5687 - 11s/epoch - 21ms/step
Epoch 6/50
528/528 - 11s - loss: 2.5276 - accuracy30: 0.6133 - val_loss: 2.9542 - val_accuracy30: 0.5536 - 11s/epoch - 21ms/step
Epoch 7/50
528/528 - 11s - loss: 2.5121 - accuracy30: 0.6172 - val_loss: 2.9565 - val_accuracy30: 0.5429 - 11s/epoch - 21ms/step
Epoch 8/50
528/528 - 11s - loss: 2.5033 - accuracy30: 0.6192 - val_loss: 2.9624 - val_accuracy30: 0.5468 - 11s/epoch - 21ms/step
Epoch 9/50
528/528 - 11s - loss: 2.4909 - accuracy30: 0.6196 - val_loss: 2.9541 - val_accuracy30: 0.5567 - 11s/epoch - 21ms/step
Epoch 10/50
528/528 - 11s - loss: 2.4824 - accuracy30: 0.6226 - val_loss: 2.9650 - val_accuracy30: 0.5668 - 11s/epoch - 21ms/step
Epoch 11/50
528/528 - 11s - loss: 2.4680 - accuracy30: 0.6251 - val_loss: 2.9509 - val_accuracy30: 0.5820 - 11s/epoch - 21ms/step
Epoch 12/50
528/528 - 11s - loss: 2.4546 - accuracy30: 0.6257 - val_loss: 2.9474 - val_accuracy30: 0.5747 - 11s/epoch - 20ms/step
Epoch 13/50
528/528 - 11s - loss: 2.4520 - accuracy30: 0.6267 - val_loss: 2.9632 - val_accuracy30: 0.5679 - 11s/epoch - 20ms/step
Epoch 14/50
528/528 - 11s - loss: 2.4419 - accuracy30: 0.6268 - val_loss: 2.9614 - val_accuracy30: 0.5779 - 11s/epoch - 20ms/step
Epoch 15/50
528/528 - 11s - loss: 2.4326 - accuracy30: 0.6274 - val_loss: 3.0648 - val_accuracy30: 0.5799 - 11s/epoch - 22ms/step
Epoch 16/50
528/528 - 11s - loss: 2.4240 - accuracy30: 0.6315 - val_loss: 3.0097 - val_accuracy30: 0.5749 - 11s/epoch - 20ms/step
Epoch 17/50
528/528 - 11s - loss: 2.4158 - accuracy30: 0.6315 - val_loss: 3.0628 - val_accuracy30: 0.5770 - 11s/epoch - 20ms/step
Epoch 18/50
528/528 - 11s - loss: 2.4092 - accuracy30: 0.6337 - val_loss: 3.0320 - val_accuracy30: 0.5865 - 11s/epoch - 20ms/step
Epoch 19/50
528/528 - 11s - loss: 2.3960 - accuracy30: 0.6335 - val_loss: 3.0375 - val_accuracy30: 0.5932 - 11s/epoch - 21ms/step
Epoch 20/50
528/528 - 11s - loss: 2.3840 - accuracy30: 0.6356 - val_loss: 3.1119 - val_accuracy30: 0.5847 - 11s/epoch - 21ms/step
Epoch 21/50
528/528 - 11s - loss: 2.3845 - accuracy30: 0.6370 - val_loss: 3.0991 - val_accuracy30: 0.5951 - 11s/epoch - 21ms/step
Epoch 22/50
528/528 - 11s - loss: 2.3649 - accuracy30: 0.6378 - val_loss: 3.2064 - val_accuracy30: 0.5675 - 11s/epoch - 20ms/step
testing model: results/QRTEA/W2/deepVOL_L2/h30
Evaluating performance on  test set...
1242/1242 - 12s - 12s/epoch - 10ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.0150155
{'0': {'precision': 0.4345197829560011, 'recall': 0.40832611988747025, 'f1-score': 0.4210159327824844, 'support': 73936}, '1': {'precision': 0.7234157718361206, 'recall': 0.5425661476740854, 'f1-score': 0.6200734820030498, 'support': 167504}, '2': {'precision': 0.39914908183974374, 'recall': 0.6413389384355479, 'f1-score': 0.49205727204220046, 'support': 76359}, 'accuracy': 0.5350677629570892, 'macro avg': {'precision': 0.5190282122106219, 'recall': 0.5307437353323678, 'f1-score': 0.5110488956092449, 'support': 317799}, 'weighted avg': {'precision': 0.5782910420060272, 'recall': 0.5350677629570892, 'f1-score': 0.5430036714134249, 'support': 317799}}
[[30190 21279 22467]
 [25370 90882 51252]
 [13919 13468 48972]]
Evaluating performance on  train set...
528/528 - 4s - 4s/epoch - 8ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.841293
{'0': {'precision': 0.5232486999082289, 'recall': 0.4013687915526007, 'f1-score': 0.45427584985835695, 'support': 25570}, '1': {'precision': 0.7901513881906039, 'recall': 0.6775402670498772, 'f1-score': 0.7295256883868763, 'support': 83505}, '2': {'precision': 0.38843372391065545, 'recall': 0.6568752660706684, 'f1-score': 0.48818580570935494, 'support': 25839}, 'accuracy': 0.6212401974591221, 'macro avg': {'precision': 0.5672779373364961, 'recall': 0.5785947748910488, 'f1-score': 0.5573291146515293, 'support': 134914}, 'weighted avg': {'precision': 0.662628043936413, 'recall': 0.6212401974591221, 'f1-score': 0.631136198788475, 'support': 134914}}
[[10263  8895  6412]
 [ 6616 56578 20311]
 [ 2735  6131 16973]]
Evaluating performance on  val set...
159/159 - 1s - 1s/epoch - 8ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.92391557
{'0': {'precision': 0.5039865072063784, 'recall': 0.3853458382180539, 'f1-score': 0.4367525910178049, 'support': 8530}, '1': {'precision': 0.7642454602379462, 'recall': 0.6120862587763289, 'f1-score': 0.6797549429128376, 'support': 23928}, '2': {'precision': 0.3570997384130391, 'recall': 0.6542951947892344, 'f1-score': 0.4620324568254795, 'support': 8137}, 'accuracy': 0.5729030668801577, 'macro avg': {'precision': 0.5417772352857879, 'recall': 0.5505757639278724, 'f1-score': 0.5261799969187073, 'support': 40595}, 'weighted avg': {'precision': 0.6279490294497077, 'recall': 0.5729030668801577, 'f1-score': 0.5850531833129493, 'support': 40595}}
[[ 3287  2833  2410]
 [ 2107 14646  7175]
 [ 1128  1685  5324]]
training model: results/QRTEA/W2/deepVOL_L2/h50
Epoch 1/50
528/528 - 14s - loss: 3.0641 - accuracy50: 0.4651 - val_loss: 3.2300 - val_accuracy50: 0.5148 - 14s/epoch - 26ms/step
Epoch 2/50
528/528 - 11s - loss: 2.8361 - accuracy50: 0.5475 - val_loss: 3.2044 - val_accuracy50: 0.4974 - 11s/epoch - 21ms/step
Epoch 3/50
528/528 - 11s - loss: 2.7610 - accuracy50: 0.5632 - val_loss: 3.2412 - val_accuracy50: 0.5118 - 11s/epoch - 21ms/step
Epoch 4/50
528/528 - 11s - loss: 2.7223 - accuracy50: 0.5721 - val_loss: 3.1070 - val_accuracy50: 0.5379 - 11s/epoch - 21ms/step
Epoch 5/50
528/528 - 11s - loss: 2.6973 - accuracy50: 0.5775 - val_loss: 3.1402 - val_accuracy50: 0.5408 - 11s/epoch - 20ms/step
Epoch 6/50
528/528 - 11s - loss: 2.6762 - accuracy50: 0.5815 - val_loss: 3.0811 - val_accuracy50: 0.5370 - 11s/epoch - 20ms/step
Epoch 7/50
528/528 - 11s - loss: 2.6610 - accuracy50: 0.5840 - val_loss: 3.0917 - val_accuracy50: 0.5331 - 11s/epoch - 21ms/step
Epoch 8/50
528/528 - 11s - loss: 2.6515 - accuracy50: 0.5860 - val_loss: 3.0855 - val_accuracy50: 0.5481 - 11s/epoch - 21ms/step
Epoch 9/50
528/528 - 11s - loss: 2.6399 - accuracy50: 0.5871 - val_loss: 3.0778 - val_accuracy50: 0.5475 - 11s/epoch - 21ms/step
Epoch 10/50
528/528 - 11s - loss: 2.6305 - accuracy50: 0.5896 - val_loss: 3.1528 - val_accuracy50: 0.5451 - 11s/epoch - 20ms/step
Epoch 11/50
528/528 - 11s - loss: 2.6228 - accuracy50: 0.5904 - val_loss: 3.1147 - val_accuracy50: 0.5419 - 11s/epoch - 21ms/step
Epoch 12/50
528/528 - 11s - loss: 2.6124 - accuracy50: 0.5941 - val_loss: 3.2016 - val_accuracy50: 0.5427 - 11s/epoch - 20ms/step
Epoch 13/50
528/528 - 11s - loss: 2.5999 - accuracy50: 0.5966 - val_loss: 3.2315 - val_accuracy50: 0.5340 - 11s/epoch - 20ms/step
Epoch 14/50
528/528 - 11s - loss: 2.5931 - accuracy50: 0.5979 - val_loss: 3.1994 - val_accuracy50: 0.5448 - 11s/epoch - 20ms/step
Epoch 15/50
528/528 - 11s - loss: 2.5817 - accuracy50: 0.6003 - val_loss: 3.1930 - val_accuracy50: 0.5426 - 11s/epoch - 21ms/step
Epoch 16/50
528/528 - 11s - loss: 2.5710 - accuracy50: 0.6019 - val_loss: 3.1875 - val_accuracy50: 0.5458 - 11s/epoch - 20ms/step
Epoch 17/50
528/528 - 11s - loss: 2.5586 - accuracy50: 0.6039 - val_loss: 3.2114 - val_accuracy50: 0.5438 - 11s/epoch - 20ms/step
Epoch 18/50
528/528 - 11s - loss: 2.5527 - accuracy50: 0.6049 - val_loss: 3.1728 - val_accuracy50: 0.5430 - 11s/epoch - 20ms/step
Epoch 19/50
528/528 - 11s - loss: 2.5405 - accuracy50: 0.6069 - val_loss: 3.1963 - val_accuracy50: 0.5454 - 11s/epoch - 20ms/step
testing model: results/QRTEA/W2/deepVOL_L2/h50
Evaluating performance on  test set...
1242/1242 - 12s - 12s/epoch - 10ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0278156
{'0': {'precision': 0.45176051694579983, 'recall': 0.3968375325803649, 'f1-score': 0.4225216613733774, 'support': 86325}, '1': {'precision': 0.6210451362791249, 'recall': 0.5589640611537174, 'f1-score': 0.5883715352211912, 'support': 140433}, '2': {'precision': 0.4475747140360289, 'recall': 0.5681835656462473, 'f1-score': 0.500718728069114, 'support': 91041}, 'accuracy': 0.5175661345693348, 'macro avg': {'precision': 0.5067934557536512, 'recall': 0.5079950531267765, 'f1-score': 0.503870641554561, 'support': 317799}, 'weighted avg': {'precision': 0.5253670017494915, 'recall': 0.5175661345693348, 'f1-score': 0.5182108689640765, 'support': 317799}}
[[34257 27404 24664]
 [22754 78497 39182]
 [18819 20494 51728]]
Evaluating performance on  train set...
528/528 - 4s - 4s/epoch - 7ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.90008557
{'0': {'precision': 0.5510682024566267, 'recall': 0.3633212541358122, 'f1-score': 0.437920164077633, 'support': 31735}, '1': {'precision': 0.6867772186321648, 'recall': 0.6892312020820145, 'f1-score': 0.6880020221311016, 'support': 71085}, '2': {'precision': 0.4410813092000375, 'recall': 0.5861843335202842, 'f1-score': 0.5033847965108501, 'support': 32094}, 'accuracy': 0.5880560949938479, 'macro avg': {'precision': 0.5596422434296097, 'recall': 0.5462455965793702, 'f1-score': 0.543102327573195, 'support': 134914}, 'weighted avg': {'precision': 0.5964078711541759, 'recall': 0.5880560949938479, 'f1-score': 0.5852591414487174, 'support': 134914}}
[[11530 12871  7334]
 [ 5586 48994 16505]
 [ 3807  9474 18813]]
Evaluating performance on  val set...
159/159 - 1s - 1s/epoch - 8ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.96326035
{'0': {'precision': 0.5268574651064429, 'recall': 0.3521153302553472, 'f1-score': 0.42211679656613577, 'support': 10613}, '1': {'precision': 0.6529514244722279, 'recall': 0.6369270755235668, 'f1-score': 0.6448397135844951, 'support': 20007}, '2': {'precision': 0.41534391534391535, 'recall': 0.5823558897243107, 'f1-score': 0.48487124911314217, 'support': 9975}, 'accuracy': 0.5490577657346964, 'macro avg': {'precision': 0.531717601640862, 'recall': 0.5237994318344082, 'f1-score': 0.517275919754591, 'support': 40595}, 'weighted avg': {'precision': 0.5616010095367926, 'recall': 0.5490577657346964, 'f1-score': 0.5473044567445494, 'support': 40595}}
[[ 3737  4188  2688]
 [ 1775 12743  5489]
 [ 1581  2585  5809]]
training model: results/QRTEA/W2/deepVOL_L2/h100
Epoch 1/50
528/528 - 14s - loss: 3.1465 - accuracy100: 0.4484 - val_loss: 3.1907 - val_accuracy100: 0.4505 - 14s/epoch - 26ms/step
Epoch 2/50
528/528 - 11s - loss: 3.0207 - accuracy100: 0.4959 - val_loss: 3.2130 - val_accuracy100: 0.4486 - 11s/epoch - 21ms/step
Epoch 3/50
528/528 - 11s - loss: 2.9817 - accuracy100: 0.5081 - val_loss: 3.1659 - val_accuracy100: 0.4650 - 11s/epoch - 21ms/step
Epoch 4/50
528/528 - 11s - loss: 2.9474 - accuracy100: 0.5123 - val_loss: 3.2750 - val_accuracy100: 0.4606 - 11s/epoch - 20ms/step
Epoch 5/50
528/528 - 11s - loss: 2.9219 - accuracy100: 0.5173 - val_loss: 3.2447 - val_accuracy100: 0.4614 - 11s/epoch - 20ms/step
Epoch 6/50
528/528 - 11s - loss: 2.8957 - accuracy100: 0.5238 - val_loss: 3.3043 - val_accuracy100: 0.4577 - 11s/epoch - 21ms/step
Epoch 7/50
528/528 - 11s - loss: 2.8873 - accuracy100: 0.5265 - val_loss: 3.2851 - val_accuracy100: 0.4629 - 11s/epoch - 21ms/step
Epoch 8/50
528/528 - 11s - loss: 2.8696 - accuracy100: 0.5308 - val_loss: 3.3423 - val_accuracy100: 0.4557 - 11s/epoch - 20ms/step
Epoch 9/50
528/528 - 11s - loss: 2.8577 - accuracy100: 0.5335 - val_loss: 3.3496 - val_accuracy100: 0.4470 - 11s/epoch - 20ms/step
Epoch 10/50
528/528 - 11s - loss: 2.8408 - accuracy100: 0.5387 - val_loss: 3.3786 - val_accuracy100: 0.4435 - 11s/epoch - 21ms/step
Epoch 11/50
528/528 - 11s - loss: 2.8299 - accuracy100: 0.5410 - val_loss: 3.3447 - val_accuracy100: 0.4519 - 11s/epoch - 21ms/step
Epoch 12/50
528/528 - 11s - loss: 2.8225 - accuracy100: 0.5427 - val_loss: 3.3425 - val_accuracy100: 0.4436 - 11s/epoch - 21ms/step
Epoch 13/50
528/528 - 11s - loss: 2.8077 - accuracy100: 0.5463 - val_loss: 3.3755 - val_accuracy100: 0.4480 - 11s/epoch - 20ms/step
testing model: results/QRTEA/W2/deepVOL_L2/h100
Evaluating performance on  test set...
1242/1242 - 9s - 9s/epoch - 7ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0473515
{'0': {'precision': 0.44018205461638493, 'recall': 0.3616073557605181, 'f1-score': 0.39704457744893207, 'support': 104843}, '1': {'precision': 0.44810131346204507, 'recall': 0.47989278840825045, 'f1-score': 0.4634524904270485, 'support': 99243}, '2': {'precision': 0.4683260625104676, 'recall': 0.5164053362412389, 'f1-score': 0.49119196988707653, 'support': 113713}, 'accuracy': 0.4539347197442409, 'macro avg': {'precision': 0.45220314352963253, 'recall': 0.45263516013666916, 'f1-score': 0.45056301258768566, 'support': 317799}, 'weighted avg': {'precision': 0.4527254250337861, 'recall': 0.4539347197442409, 'f1-score': 0.45146986810121836, 'support': 317799}}
[[37912 31905 35026]
 [19978 47626 31639]
 [28238 26753 58722]]
Evaluating performance on  train set...
528/528 - 4s - 4s/epoch - 8ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0094622
{'0': {'precision': 0.5319539827654083, 'recall': 0.2930855807003591, 'f1-score': 0.37794076514280384, 'support': 41493}, '1': {'precision': 0.5076831701262507, 'recall': 0.6521254328136309, 'f1-score': 0.5709099004983645, 'support': 51119}, '2': {'precision': 0.47296831213623625, 'recall': 0.5186752399413739, 'f1-score': 0.49476841203265226, 'support': 42302}, 'accuracy': 0.4998591695450435, 'macro avg': {'precision': 0.5042018216759651, 'recall': 0.4879620844851213, 'f1-score': 0.4812063592246069, 'support': 134914}, 'weighted avg': {'precision': 0.5042629239408509, 'recall': 0.4998591695450435, 'f1-score': 0.48768795482641913, 'support': 134914}}
[[12161 18012 11320]
 [ 4654 33336 13129]
 [ 6046 14315 21941]]
Evaluating performance on  val set...
159/159 - 1s - 1s/epoch - 8ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0398018
{'0': {'precision': 0.5056833201163098, 'recall': 0.2776487663280116, 'f1-score': 0.3584746556731941, 'support': 13780}, '1': {'precision': 0.47955432385046093, 'recall': 0.5912418938707203, 'f1-score': 0.5295734182749361, 'support': 14341}, '2': {'precision': 0.42663539223351576, 'recall': 0.5249318582651916, 'f1-score': 0.47070663503702104, 'support': 12474}, 'accuracy': 0.4644168000985343, 'macro avg': {'precision': 0.4706243454000955, 'recall': 0.46460750615464114, 'f1-score': 0.45291823632838374, 'support': 40595}, 'weighted avg': {'precision': 0.47216294105833445, 'recall': 0.4644168000985343, 'f1-score': 0.45340528912696815, 'support': 40595}}
[[3826 5512 4442]
 [1504 8479 4358]
 [2236 3690 6548]]
training model: results/QRTEA/W2/deepVOL_L2/h200
Epoch 1/50
528/528 - 13s - loss: 3.2488 - accuracy200: 0.4051 - val_loss: 3.4148 - val_accuracy200: 0.3597 - 13s/epoch - 25ms/step
Epoch 2/50
528/528 - 11s - loss: 3.2171 - accuracy200: 0.4197 - val_loss: 3.4175 - val_accuracy200: 0.3503 - 11s/epoch - 21ms/step
Epoch 3/50
528/528 - 11s - loss: 3.1997 - accuracy200: 0.4281 - val_loss: 3.4310 - val_accuracy200: 0.3682 - 11s/epoch - 21ms/step
Epoch 4/50
528/528 - 11s - loss: 3.1721 - accuracy200: 0.4385 - val_loss: 3.4470 - val_accuracy200: 0.3757 - 11s/epoch - 21ms/step
Epoch 5/50
528/528 - 11s - loss: 3.1516 - accuracy200: 0.4473 - val_loss: 3.4742 - val_accuracy200: 0.3799 - 11s/epoch - 21ms/step
Epoch 6/50
528/528 - 11s - loss: 3.1431 - accuracy200: 0.4526 - val_loss: 3.4448 - val_accuracy200: 0.3868 - 11s/epoch - 21ms/step
Epoch 7/50
528/528 - 11s - loss: 3.1347 - accuracy200: 0.4539 - val_loss: 3.4009 - val_accuracy200: 0.3875 - 11s/epoch - 21ms/step
Epoch 8/50
528/528 - 11s - loss: 3.1200 - accuracy200: 0.4582 - val_loss: 3.4549 - val_accuracy200: 0.3813 - 11s/epoch - 21ms/step
Epoch 9/50
528/528 - 11s - loss: 3.1098 - accuracy200: 0.4635 - val_loss: 3.4433 - val_accuracy200: 0.3905 - 11s/epoch - 20ms/step
Epoch 10/50
528/528 - 11s - loss: 3.0927 - accuracy200: 0.4677 - val_loss: 3.4898 - val_accuracy200: 0.3857 - 11s/epoch - 21ms/step
Epoch 11/50
528/528 - 11s - loss: 3.0827 - accuracy200: 0.4726 - val_loss: 3.4777 - val_accuracy200: 0.3929 - 11s/epoch - 21ms/step
Epoch 12/50
528/528 - 11s - loss: 3.0688 - accuracy200: 0.4762 - val_loss: 3.5102 - val_accuracy200: 0.3930 - 11s/epoch - 20ms/step
Epoch 13/50
528/528 - 11s - loss: 3.0568 - accuracy200: 0.4788 - val_loss: 3.5517 - val_accuracy200: 0.3887 - 11s/epoch - 21ms/step
Epoch 14/50
528/528 - 11s - loss: 3.0448 - accuracy200: 0.4834 - val_loss: 3.5989 - val_accuracy200: 0.3873 - 11s/epoch - 20ms/step
Epoch 15/50
528/528 - 11s - loss: 3.0318 - accuracy200: 0.4867 - val_loss: 3.6733 - val_accuracy200: 0.3775 - 11s/epoch - 20ms/step
Epoch 16/50
528/528 - 11s - loss: 3.0188 - accuracy200: 0.4908 - val_loss: 3.6947 - val_accuracy200: 0.3841 - 11s/epoch - 20ms/step
Epoch 17/50
528/528 - 11s - loss: 3.0075 - accuracy200: 0.4920 - val_loss: 3.7471 - val_accuracy200: 0.3735 - 11s/epoch - 21ms/step
testing model: results/QRTEA/W2/deepVOL_L2/h200
Evaluating performance on  test set...
1242/1242 - 9s - 9s/epoch - 7ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1112872
{'0': {'precision': 0.37957626597206556, 'recall': 0.18513294520136847, 'f1-score': 0.2488787880825427, 'support': 99966}, '1': {'precision': 0.35624284077892326, 'recall': 0.41669613115730314, 'f1-score': 0.38410539226197116, 'support': 107474}, '2': {'precision': 0.4039628828577409, 'recall': 0.5246513650902962, 'f1-score': 0.45646441114908415, 'support': 110359}, 'accuracy': 0.3813448122870116, 'macro avg': {'precision': 0.3799273298695766, 'recall': 0.37549348048298925, 'f1-score': 0.363149530497866, 'support': 317799}, 'weighted avg': {'precision': 0.38015382006656706, 'recall': 0.3813448122870116, 'f1-score': 0.3666962948512246, 'support': 317799}}
[[18507 42500 38959]
 [16219 44784 46471]
 [14031 38428 57900]]
Evaluating performance on  train set...
528/528 - 4s - 4s/epoch - 8ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0996952
{'0': {'precision': 0.4917950555356503, 'recall': 0.15353811047227006, 'f1-score': 0.2340164353667269, 'support': 44699}, '1': {'precision': 0.3790602671399501, 'recall': 0.5544986571172784, 'f1-score': 0.45029489544615997, 'support': 44680}, '2': {'precision': 0.44075539568345323, 'recall': 0.5381794224223125, 'f1-score': 0.48461956790428634, 'support': 45535}, 'accuracy': 0.41614658226722206, 'macro avg': {'precision': 0.4372035727863512, 'recall': 0.4154053966706203, 'f1-score': 0.3896436329057244, 'support': 134914}, 'weighted avg': {'precision': 0.4372337701472572, 'recall': 0.41614658226722206, 'f1-score': 0.39022361354280083, 'support': 134914}}
[[ 6863 22994 14842]
 [ 3653 24775 16252]
 [ 3439 17590 24506]]
Evaluating performance on  val set...
159/159 - 1s - 1s/epoch - 8ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1339387
{'0': {'precision': 0.46112860256720756, 'recall': 0.1285965149263812, 'f1-score': 0.20110905730129391, 'support': 14806}, '1': {'precision': 0.3737215670932767, 'recall': 0.5084784427039769, 'f1-score': 0.430807885581755, 'support': 13151}, '2': {'precision': 0.38001399881548487, 'recall': 0.5584744421585693, 'f1-score': 0.452276440998366, 'support': 12638}, 'accuracy': 0.3854908239931026, 'macro avg': {'precision': 0.404954722825323, 'recall': 0.3985164665963092, 'f1-score': 0.3613977946271383, 'support': 40595}, 'weighted avg': {'precision': 0.4075600279710273, 'recall': 0.3854908239931026, 'f1-score': 0.3537146167514711, 'support': 40595}}
[[1904 6742 6160]
 [1109 6687 5355]
 [1116 4464 7058]]
training model: results/QRTEA/W2/deepVOL_L2/h300
Epoch 1/50
528/528 - 13s - loss: 3.3017 - accuracy300: 0.3777 - val_loss: 3.3993 - val_accuracy300: 0.3430 - 13s/epoch - 25ms/step
Epoch 2/50
528/528 - 11s - loss: 3.2526 - accuracy300: 0.3946 - val_loss: 3.3947 - val_accuracy300: 0.3583 - 11s/epoch - 21ms/step
Epoch 3/50
528/528 - 11s - loss: 3.2373 - accuracy300: 0.4015 - val_loss: 3.3892 - val_accuracy300: 0.3565 - 11s/epoch - 21ms/step
Epoch 4/50
528/528 - 11s - loss: 3.2249 - accuracy300: 0.4078 - val_loss: 3.4357 - val_accuracy300: 0.3604 - 11s/epoch - 21ms/step
Epoch 5/50
528/528 - 11s - loss: 3.2139 - accuracy300: 0.4150 - val_loss: 3.4142 - val_accuracy300: 0.3668 - 11s/epoch - 21ms/step
Epoch 6/50
528/528 - 11s - loss: 3.2000 - accuracy300: 0.4208 - val_loss: 3.4286 - val_accuracy300: 0.3660 - 11s/epoch - 21ms/step
Epoch 7/50
528/528 - 11s - loss: 3.1904 - accuracy300: 0.4260 - val_loss: 3.4793 - val_accuracy300: 0.3569 - 11s/epoch - 21ms/step
Epoch 8/50
528/528 - 11s - loss: 3.1748 - accuracy300: 0.4324 - val_loss: 3.5138 - val_accuracy300: 0.3543 - 11s/epoch - 21ms/step
Epoch 9/50
528/528 - 11s - loss: 3.1638 - accuracy300: 0.4388 - val_loss: 3.5484 - val_accuracy300: 0.3567 - 11s/epoch - 21ms/step
Epoch 10/50
528/528 - 11s - loss: 3.1523 - accuracy300: 0.4425 - val_loss: 3.6354 - val_accuracy300: 0.3525 - 11s/epoch - 21ms/step
Epoch 11/50
528/528 - 11s - loss: 3.1484 - accuracy300: 0.4448 - val_loss: 3.6370 - val_accuracy300: 0.3546 - 11s/epoch - 21ms/step
Epoch 12/50
528/528 - 11s - loss: 3.1317 - accuracy300: 0.4527 - val_loss: 3.7157 - val_accuracy300: 0.3527 - 11s/epoch - 21ms/step
Epoch 13/50
528/528 - 11s - loss: 3.1190 - accuracy300: 0.4562 - val_loss: 3.7580 - val_accuracy300: 0.3536 - 11s/epoch - 21ms/step
testing model: results/QRTEA/W2/deepVOL_L2/h300
Evaluating performance on  test set...
1242/1242 - 12s - 12s/epoch - 10ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1052091
{'0': {'precision': 0.3462839302749111, 'recall': 0.24302117990749006, 'f1-score': 0.28560529296060083, 'support': 98584}, '1': {'precision': 0.36563362645493613, 'recall': 0.3507794796188604, 'f1-score': 0.3580525597079397, 'support': 109881}, '2': {'precision': 0.3799896645157686, 'recall': 0.4976768434338815, 'f1-score': 0.4309428582742644, 'support': 109334}, 'accuracy': 0.36788976680228697, 'macro avg': {'precision': 0.3639690737485386, 'recall': 0.3638258343200773, 'f1-score': 0.35820023698093495, 'support': 317799}, 'weighted avg': {'precision': 0.3645701637540827, 'recall': 0.36788976680228697, 'f1-score': 0.36065560930353596, 'support': 317799}}
[[23958 33872 40754]
 [23308 38544 48029]
 [21920 33001 54413]]
Evaluating performance on  train set...
528/528 - 4s - 4s/epoch - 8ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.099092
{'0': {'precision': 0.430559771061874, 'recall': 0.22105966162065896, 'f1-score': 0.2921318564935352, 'support': 44920}, '1': {'precision': 0.3561716875499867, 'recall': 0.45135135135135135, 'f1-score': 0.3981522872895247, 'support': 44400}, '2': {'precision': 0.40247544345698555, 'recall': 0.4906785980611484, 'f1-score': 0.4422217829610595, 'support': 45594}, 'accuracy': 0.38796566701750745, 'macro avg': {'precision': 0.3964023006896154, 'recall': 0.38769653701105294, 'f1-score': 0.3775019755813731, 'support': 134914}, 'weighted avg': {'precision': 0.39658770188636155, 'recall': 0.38796566701750745, 'f1-score': 0.377745708537817, 'support': 134914}}
[[ 9930 18886 16104]
 [ 7250 20040 17110]
 [ 5883 17339 22372]]
Evaluating performance on  val set...
159/159 - 1s - 1s/epoch - 8ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1284027
{'0': {'precision': 0.42568542568542567, 'recall': 0.19918973666441595, 'f1-score': 0.27138914443422263, 'support': 14810}, '1': {'precision': 0.36534005724410523, 'recall': 0.3922013314799912, 'f1-score': 0.37829446424161167, 'support': 13669}, '2': {'precision': 0.33115686377757886, 'recall': 0.5190656982502476, 'f1-score': 0.40434628861671007, 'support': 12116}, 'accuracy': 0.3596502032269984, 'macro avg': {'precision': 0.3740607822357032, 'recall': 0.3701522554648849, 'f1-score': 0.35134329909751477, 'support': 40595}, 'weighted avg': {'precision': 0.37715312128094525, 'recall': 0.3596502032269984, 'f1-score': 0.347068355552888, 'support': 40595}}
[[2950 5242 6618]
 [2224 5361 6084]
 [1756 4071 6289]]
training model: results/QRTEA/W2/deepVOL_L2/h500
Epoch 1/50
528/528 - 14s - loss: 3.2744 - accuracy500: 0.3972 - val_loss: 3.5009 - val_accuracy500: 0.3936 - 14s/epoch - 27ms/step
Epoch 2/50
528/528 - 11s - loss: 3.2646 - accuracy500: 0.3901 - val_loss: 3.4116 - val_accuracy500: 0.3907 - 11s/epoch - 22ms/step
Epoch 3/50
528/528 - 11s - loss: 3.2427 - accuracy500: 0.4032 - val_loss: 3.4797 - val_accuracy500: 0.3939 - 11s/epoch - 22ms/step
Epoch 4/50
528/528 - 11s - loss: 3.2331 - accuracy500: 0.4069 - val_loss: 3.5593 - val_accuracy500: 0.3940 - 11s/epoch - 21ms/step
Epoch 5/50
528/528 - 11s - loss: 3.2112 - accuracy500: 0.4182 - val_loss: 3.5614 - val_accuracy500: 0.3892 - 11s/epoch - 21ms/step
Epoch 6/50
528/528 - 11s - loss: 3.1963 - accuracy500: 0.4230 - val_loss: 3.5919 - val_accuracy500: 0.3811 - 11s/epoch - 21ms/step
Epoch 7/50
528/528 - 11s - loss: 3.1728 - accuracy500: 0.4346 - val_loss: 3.6140 - val_accuracy500: 0.3733 - 11s/epoch - 21ms/step
Epoch 8/50
528/528 - 12s - loss: 3.1578 - accuracy500: 0.4394 - val_loss: 3.6357 - val_accuracy500: 0.3786 - 12s/epoch - 23ms/step
Epoch 9/50
528/528 - 12s - loss: 3.1417 - accuracy500: 0.4459 - val_loss: 3.6822 - val_accuracy500: 0.3751 - 12s/epoch - 22ms/step
Epoch 10/50
528/528 - 12s - loss: 3.1348 - accuracy500: 0.4496 - val_loss: 3.7236 - val_accuracy500: 0.3688 - 12s/epoch - 22ms/step
Epoch 11/50
528/528 - 11s - loss: 3.1175 - accuracy500: 0.4562 - val_loss: 3.7593 - val_accuracy500: 0.3593 - 11s/epoch - 21ms/step
Epoch 12/50
528/528 - 11s - loss: 3.0988 - accuracy500: 0.4611 - val_loss: 3.7734 - val_accuracy500: 0.3578 - 11s/epoch - 21ms/step
testing model: results/QRTEA/W2/deepVOL_L2/h500
Evaluating performance on  test set...
1242/1242 - 12s - 12s/epoch - 10ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0861291
{'0': {'precision': 0.2939244663382594, 'recall': 0.002174890344215885, 'f1-score': 0.004317830953299884, 'support': 82303}, '1': {'precision': 0.4474580776499496, 'recall': 0.9725089300182476, 'f1-score': 0.61291139015683, 'support': 141937}, '2': {'precision': 0.3248305182121108, 'recall': 0.03021622719353563, 'f1-score': 0.055289354794547343, 'support': 93559}, 'accuracy': 0.4438056759146505, 'macro avg': {'precision': 0.3554043540667733, 'recall': 0.33496668251866635, 'f1-score': 0.22417285863489242, 'support': 317799}, 'weighted avg': {'precision': 0.3715950678694569, 'recall': 0.4438056759146505, 'f1-score': 0.2911368228687393, 'support': 317799}}
[[   179  79891   2233]
 [   259 138035   3643]
 [   171  90561   2827]]
Evaluating performance on  train set...
528/528 - 4s - 4s/epoch - 8ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1829364
{'0': {'precision': 0.42105263157894735, 'recall': 0.0013970748744815543, 'f1-score': 0.0027849092728775946, 'support': 45810}, '1': {'precision': 0.32832668210656546, 'recall': 0.9876772949052536, 'f1-score': 0.4928264882064522, 'support': 44065}, '2': {'precision': 0.3791383219954649, 'recall': 0.018561690978929374, 'f1-score': 0.035390737448141564, 'support': 45039}, 'accuracy': 0.3292616036882755, 'macro avg': {'precision': 0.37617254522699256, 'recall': 0.33587868691955486, 'f1-score': 0.17700071164249045, 'support': 134914}, 'weighted avg': {'precision': 0.37677444285997835, 'recall': 0.3292616036882755, 'f1-score': 0.17372503461860656, 'support': 134914}}
[[   64 44887   859]
 [   33 43522   510]
 [   55 44148   836]]
Evaluating performance on  val set...
159/159 - 1s - 1s/epoch - 8ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1433299
{'0': {'precision': 0.2, 'recall': 0.0010887711403063077, 'f1-score': 0.002165752237943979, 'support': 13777}, '1': {'precision': 0.3942515995768049, 'recall': 0.9772713081486106, 'f1-score': 0.5618437348554198, 'support': 16015}, '2': {'precision': 0.2591240875912409, 'recall': 0.0197167453485143, 'f1-score': 0.03664516129032258, 'support': 10803}, 'accuracy': 0.39115654637270597, 'macro avg': {'precision': 0.2844585623893486, 'recall': 0.3326922748791437, 'f1-score': 0.20021821612789548, 'support': 40595}, 'weighted avg': {'precision': 0.2923674562254146, 'recall': 0.39115654637270597, 'f1-score': 0.2321380135413489, 'support': 40595}}
[[   15 13478   284]
 [   39 15651   325]
 [   21 10569   213]]
training model: results/QRTEA/W2/deepVOL_L2/h1000
Epoch 1/50
528/528 - 13s - loss: 3.3189 - accuracy1000: 0.3784 - val_loss: 3.3370 - val_accuracy1000: 0.3290 - 13s/epoch - 25ms/step
Epoch 2/50
528/528 - 11s - loss: 3.2899 - accuracy1000: 0.3705 - val_loss: 3.4141 - val_accuracy1000: 0.3378 - 11s/epoch - 21ms/step
Epoch 3/50
528/528 - 11s - loss: 3.2814 - accuracy1000: 0.3753 - val_loss: 3.4621 - val_accuracy1000: 0.3093 - 11s/epoch - 21ms/step
Epoch 4/50
528/528 - 11s - loss: 3.2873 - accuracy1000: 0.3686 - val_loss: 3.4166 - val_accuracy1000: 0.3085 - 11s/epoch - 20ms/step
Epoch 5/50
528/528 - 11s - loss: 3.2655 - accuracy1000: 0.3869 - val_loss: 3.4597 - val_accuracy1000: 0.2984 - 11s/epoch - 20ms/step
Epoch 6/50
528/528 - 11s - loss: 3.2569 - accuracy1000: 0.3930 - val_loss: 3.4783 - val_accuracy1000: 0.2974 - 11s/epoch - 21ms/step
Epoch 7/50
528/528 - 11s - loss: 3.2373 - accuracy1000: 0.4033 - val_loss: 3.4412 - val_accuracy1000: 0.3053 - 11s/epoch - 21ms/step
Epoch 8/50
528/528 - 11s - loss: 3.2291 - accuracy1000: 0.4106 - val_loss: 3.4592 - val_accuracy1000: 0.2992 - 11s/epoch - 21ms/step
Epoch 9/50
528/528 - 11s - loss: 3.2152 - accuracy1000: 0.4149 - val_loss: 3.5077 - val_accuracy1000: 0.2981 - 11s/epoch - 21ms/step
Epoch 10/50
528/528 - 11s - loss: 3.1866 - accuracy1000: 0.4269 - val_loss: 3.6113 - val_accuracy1000: 0.2935 - 11s/epoch - 20ms/step
Epoch 11/50
528/528 - 11s - loss: 3.1702 - accuracy1000: 0.4304 - val_loss: 3.6825 - val_accuracy1000: 0.2901 - 11s/epoch - 21ms/step
testing model: results/QRTEA/W2/deepVOL_L2/h1000
Evaluating performance on  test set...
1242/1242 - 13s - 13s/epoch - 10ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0991037
{'0': {'precision': 0.2801184317996188, 'recall': 0.09327440648195365, 'f1-score': 0.13994848209200111, 'support': 88245}, '1': {'precision': 0.38626724459358686, 'recall': 0.5336563614265822, 'f1-score': 0.4481545444406517, 'support': 124241}, '2': {'precision': 0.34103813577466235, 'recall': 0.3781299554660868, 'f1-score': 0.35862752161383277, 'support': 105313}, 'accuracy': 0.3598343607122741, 'macro avg': {'precision': 0.3358079373892893, 'recall': 0.3350202411248742, 'f1-score': 0.31557684938216185, 'support': 317799}, 'weighted avg': {'precision': 0.34180418737172297, 'recall': 0.3598343607122741, 'f1-score': 0.33290558731077574, 'support': 317799}}
[[ 8231 48510 31504]
 [12498 66302 45441]
 [ 8655 56836 39822]]
Evaluating performance on  train set...
528/528 - 4s - 4s/epoch - 8ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1110048
{'0': {'precision': 0.3379938565829891, 'recall': 0.06849109250912212, 'f1-score': 0.11390123324588174, 'support': 46590}, '1': {'precision': 0.3407117654055054, 'recall': 0.5782013904462884, 'f1-score': 0.42876743083792745, 'support': 44590}, '2': {'precision': 0.34042809525721857, 'recall': 0.3876617734485755, 'f1-score': 0.3625128292849812, 'support': 43734}, 'accuracy': 0.3404168581466712, 'macro avg': {'precision': 0.33971123908190437, 'recall': 0.34478475213466203, 'f1-score': 0.30172716445626346, 'support': 134914}, 'weighted avg': {'precision': 0.3396812318633511, 'recall': 0.3404168581466712, 'f1-score': 0.29855711248601463, 'support': 134914}}
[[ 3191 25984 17415]
 [ 3375 25782 15433]
 [ 2875 23905 16954]]
Evaluating performance on  val set...
159/159 - 1s - 1s/epoch - 8ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1152403
{'0': {'precision': 0.35774134790528234, 'recall': 0.06859457949147807, 'f1-score': 0.11511634722466445, 'support': 14316}, '1': {'precision': 0.38851921274601686, 'recall': 0.5262790402437476, 'f1-score': 0.44702647328408907, 'support': 15754}, '2': {'precision': 0.2543912780133253, 'recall': 0.3990498812351544, 'f1-score': 0.31070834103939343, 'support': 10525}, 'accuracy': 0.33188816356694173, 'macro avg': {'precision': 0.33355061288820814, 'recall': 0.33130783365679334, 'f1-score': 0.29095038718271565, 'support': 40595}, 'weighted avg': {'precision': 0.34289013462995493, 'recall': 0.33188816356694173, 'f1-score': 0.29463396911997664, 'support': 40595}}
[[ 982 7453 5881]
 [1034 8291 6429]
 [ 729 5596 4200]]
training model: results/QRTEA/W2/deepVOL_L3/h10
Epoch 1/50
528/528 - 21s - loss: 3.1695 - accuracy10: 0.3784 - val_loss: 3.4381 - val_accuracy10: 0.4855 - 21s/epoch - 39ms/step
Epoch 2/50
528/528 - 18s - loss: 2.8513 - accuracy10: 0.4358 - val_loss: 3.1153 - val_accuracy10: 0.5596 - 18s/epoch - 33ms/step
Epoch 3/50
528/528 - 19s - loss: 2.5529 - accuracy10: 0.6072 - val_loss: 2.9633 - val_accuracy10: 0.5714 - 19s/epoch - 36ms/step
Epoch 4/50
528/528 - 18s - loss: 2.4550 - accuracy10: 0.6305 - val_loss: 2.9059 - val_accuracy10: 0.5941 - 18s/epoch - 33ms/step
Epoch 5/50
528/528 - 18s - loss: 2.4045 - accuracy10: 0.6406 - val_loss: 2.8889 - val_accuracy10: 0.5853 - 18s/epoch - 33ms/step
Epoch 6/50
528/528 - 17s - loss: 2.3705 - accuracy10: 0.6497 - val_loss: 2.9010 - val_accuracy10: 0.5595 - 17s/epoch - 33ms/step
Epoch 7/50
528/528 - 17s - loss: 2.3469 - accuracy10: 0.6526 - val_loss: 2.9388 - val_accuracy10: 0.5801 - 17s/epoch - 33ms/step
Epoch 8/50
528/528 - 17s - loss: 2.3274 - accuracy10: 0.6582 - val_loss: 2.8576 - val_accuracy10: 0.5778 - 17s/epoch - 33ms/step
Epoch 9/50
528/528 - 18s - loss: 2.3161 - accuracy10: 0.6597 - val_loss: 2.8381 - val_accuracy10: 0.5526 - 18s/epoch - 33ms/step
Epoch 10/50
528/528 - 18s - loss: 2.3031 - accuracy10: 0.6609 - val_loss: 2.8669 - val_accuracy10: 0.5713 - 18s/epoch - 33ms/step
Epoch 11/50
528/528 - 17s - loss: 2.2933 - accuracy10: 0.6608 - val_loss: 2.9154 - val_accuracy10: 0.5661 - 17s/epoch - 33ms/step
Epoch 12/50
528/528 - 19s - loss: 2.2784 - accuracy10: 0.6621 - val_loss: 2.9051 - val_accuracy10: 0.5829 - 19s/epoch - 36ms/step
Epoch 13/50
528/528 - 19s - loss: 2.2678 - accuracy10: 0.6651 - val_loss: 2.8455 - val_accuracy10: 0.5712 - 19s/epoch - 36ms/step
Epoch 14/50
528/528 - 17s - loss: 2.2589 - accuracy10: 0.6659 - val_loss: 2.8852 - val_accuracy10: 0.6043 - 17s/epoch - 33ms/step
Epoch 15/50
528/528 - 17s - loss: 2.2479 - accuracy10: 0.6696 - val_loss: 2.8728 - val_accuracy10: 0.6129 - 17s/epoch - 33ms/step
Epoch 16/50
528/528 - 19s - loss: 2.2389 - accuracy10: 0.6672 - val_loss: 2.8796 - val_accuracy10: 0.5979 - 19s/epoch - 36ms/step
Epoch 17/50
528/528 - 18s - loss: 2.2236 - accuracy10: 0.6709 - val_loss: 2.8878 - val_accuracy10: 0.5916 - 18s/epoch - 34ms/step
Epoch 18/50
528/528 - 18s - loss: 2.2126 - accuracy10: 0.6717 - val_loss: 2.9024 - val_accuracy10: 0.6076 - 18s/epoch - 34ms/step
Epoch 19/50
528/528 - 17s - loss: 2.2086 - accuracy10: 0.6716 - val_loss: 2.8543 - val_accuracy10: 0.6064 - 17s/epoch - 33ms/step
testing model: results/QRTEA/W2/deepVOL_L3/h10
Evaluating performance on  test set...
1242/1242 - 17s - 17s/epoch - 13ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 1.0456996
{'0': {'precision': 0.38028169014084506, 'recall': 0.41025437043813767, 'f1-score': 0.39469983257593877, 'support': 50281}, '1': {'precision': 0.8824948758529435, 'recall': 0.4694608023555392, 'f1-score': 0.6128851103189594, 'support': 217360}, '2': {'precision': 0.25898084177223746, 'recall': 0.763786434865824, 'f1-score': 0.3868055976252499, 'support': 50158}, 'accuracy': 0.5065465907696374, 'macro avg': {'precision': 0.5072524692553421, 'recall': 0.5478338692198337, 'f1-score': 0.4647968468400494, 'support': 317799}, 'weighted avg': {'precision': 0.7046277393540556, 'recall': 0.5065465907696374, 'f1-score': 0.5426826548427374, 'support': 317799}}
[[ 20628   9420  20233]
 [ 25935 102042  89383]
 [  7681   4167  38310]]
Evaluating performance on  train set...
528/528 - 9s - 9s/epoch - 17ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.84877205
{'0': {'precision': 0.4324908854971266, 'recall': 0.4357218452343896, 'f1-score': 0.4341003535322211, 'support': 16063}, '1': {'precision': 0.9161007086138571, 'recall': 0.6056509501037274, 'f1-score': 0.7292086870866363, 'support': 102673}, '2': {'precision': 0.2475222213482262, 'recall': 0.7780318951662751, 'f1-score': 0.3755631806653737, 'support': 16178}, 'accuracy': 0.606089805357487, 'macro avg': {'precision': 0.5320379384864032, 'recall': 0.6064682301681308, 'f1-score': 0.5129574070947437, 'support': 134914}, 'weighted avg': {'precision': 0.7783500870645188, 'recall': 0.606089805357487, 'f1-score': 0.6516659401162125, 'support': 134914}}
[[ 6999  3888  5176]
 [ 7400 62184 33089]
 [ 1784  1807 12587]]
Evaluating performance on  val set...
159/159 - 3s - 3s/epoch - 17ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.9342926
{'0': {'precision': 0.43160287987874196, 'recall': 0.4235775381182596, 'f1-score': 0.4275525525525526, 'support': 5378}, '1': {'precision': 0.902370834265265, 'recall': 0.5375928578566908, 'f1-score': 0.6737782602342233, 'support': 30019}, '2': {'precision': 0.22910571903860494, 'recall': 0.7683724509426703, 'f1-score': 0.3529671689275772, 'support': 5198}, 'accuracy': 0.5520384283778791, 'macro avg': {'precision': 0.5210264777275373, 'recall': 0.5765142823058735, 'f1-score': 0.4847659939047843, 'support': 40595}, 'weighted avg': {'precision': 0.753795341528748, 'recall': 0.5520384283778791, 'f1-score': 0.6000800730554089, 'support': 40595}}
[[ 2278  1197  1903]
 [ 2345 16138 11536]
 [  655   549  3994]]
training model: results/QRTEA/W2/deepVOL_L3/h20
Epoch 1/50
528/528 - 20s - loss: 3.1742 - accuracy20: 0.4048 - val_loss: 3.5196 - val_accuracy20: 0.5146 - 20s/epoch - 38ms/step
Epoch 2/50
528/528 - 17s - loss: 2.8446 - accuracy20: 0.4877 - val_loss: 3.2494 - val_accuracy20: 0.3937 - 17s/epoch - 32ms/step
Epoch 3/50
528/528 - 17s - loss: 2.5991 - accuracy20: 0.6002 - val_loss: 3.0364 - val_accuracy20: 0.5183 - 17s/epoch - 32ms/step
Epoch 4/50
528/528 - 17s - loss: 2.5177 - accuracy20: 0.6228 - val_loss: 3.0846 - val_accuracy20: 0.4997 - 17s/epoch - 32ms/step
Epoch 5/50
528/528 - 17s - loss: 2.4622 - accuracy20: 0.6321 - val_loss: 3.0399 - val_accuracy20: 0.5333 - 17s/epoch - 33ms/step
Epoch 6/50
528/528 - 19s - loss: 2.4253 - accuracy20: 0.6357 - val_loss: 3.0129 - val_accuracy20: 0.5364 - 19s/epoch - 36ms/step
Epoch 7/50
528/528 - 19s - loss: 2.4043 - accuracy20: 0.6383 - val_loss: 2.9692 - val_accuracy20: 0.5451 - 19s/epoch - 36ms/step
Epoch 8/50
528/528 - 17s - loss: 2.3923 - accuracy20: 0.6393 - val_loss: 2.9354 - val_accuracy20: 0.5349 - 17s/epoch - 32ms/step
Epoch 9/50
528/528 - 17s - loss: 2.3725 - accuracy20: 0.6432 - val_loss: 2.9108 - val_accuracy20: 0.5364 - 17s/epoch - 32ms/step
Epoch 10/50
528/528 - 17s - loss: 2.3610 - accuracy20: 0.6452 - val_loss: 2.9475 - val_accuracy20: 0.5431 - 17s/epoch - 32ms/step
Epoch 11/50
528/528 - 17s - loss: 2.3461 - accuracy20: 0.6476 - val_loss: 2.9542 - val_accuracy20: 0.5494 - 17s/epoch - 32ms/step
Epoch 12/50
528/528 - 17s - loss: 2.3353 - accuracy20: 0.6491 - val_loss: 2.9488 - val_accuracy20: 0.5819 - 17s/epoch - 32ms/step
Epoch 13/50
528/528 - 19s - loss: 2.3240 - accuracy20: 0.6505 - val_loss: 2.9255 - val_accuracy20: 0.5971 - 19s/epoch - 35ms/step
Epoch 14/50
528/528 - 18s - loss: 2.3166 - accuracy20: 0.6512 - val_loss: 2.8795 - val_accuracy20: 0.5912 - 18s/epoch - 34ms/step
Epoch 15/50
528/528 - 17s - loss: 2.3077 - accuracy20: 0.6526 - val_loss: 2.9069 - val_accuracy20: 0.5790 - 17s/epoch - 32ms/step
Epoch 16/50
528/528 - 19s - loss: 2.3038 - accuracy20: 0.6541 - val_loss: 2.9170 - val_accuracy20: 0.5945 - 19s/epoch - 35ms/step
Epoch 17/50
528/528 - 18s - loss: 2.2926 - accuracy20: 0.6534 - val_loss: 2.9214 - val_accuracy20: 0.5773 - 18s/epoch - 35ms/step
Epoch 18/50
528/528 - 19s - loss: 2.2830 - accuracy20: 0.6548 - val_loss: 2.9473 - val_accuracy20: 0.5581 - 19s/epoch - 35ms/step
Epoch 19/50
528/528 - 19s - loss: 2.2791 - accuracy20: 0.6551 - val_loss: 2.9777 - val_accuracy20: 0.5842 - 19s/epoch - 36ms/step
Epoch 20/50
528/528 - 19s - loss: 2.2685 - accuracy20: 0.6550 - val_loss: 2.9519 - val_accuracy20: 0.6299 - 19s/epoch - 35ms/step
Epoch 21/50
528/528 - 19s - loss: 2.2745 - accuracy20: 0.6549 - val_loss: 2.9691 - val_accuracy20: 0.6064 - 19s/epoch - 35ms/step
Epoch 22/50
528/528 - 19s - loss: 2.2560 - accuracy20: 0.6560 - val_loss: 2.9046 - val_accuracy20: 0.5832 - 19s/epoch - 35ms/step
Epoch 23/50
528/528 - 19s - loss: 2.2485 - accuracy20: 0.6564 - val_loss: 2.9997 - val_accuracy20: 0.5860 - 19s/epoch - 35ms/step
Epoch 24/50
528/528 - 19s - loss: 2.2431 - accuracy20: 0.6564 - val_loss: 3.0138 - val_accuracy20: 0.5763 - 19s/epoch - 36ms/step
testing model: results/QRTEA/W2/deepVOL_L3/h20
Evaluating performance on  test set...
1242/1242 - 17s - 17s/epoch - 14ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 1.0364882
{'0': {'precision': 0.4122597231771845, 'recall': 0.42563928455686045, 'f1-score': 0.4188426815286141, 'support': 64799}, '1': {'precision': 0.8115703196149009, 'recall': 0.4993489305383597, 'f1-score': 0.6182787705787319, 'support': 187384}, '2': {'precision': 0.3418754885621156, 'recall': 0.7065197512801755, 'f1-score': 0.46078382649663546, 'support': 65616}, 'accuracy': 0.5270941695851781, 'macro avg': {'precision': 0.5219018437847337, 'recall': 0.5438359887917986, 'f1-score': 0.4993017595346605, 'support': 317799}, 'weighted avg': {'precision': 0.6331732089476957, 'recall': 0.5270941695851781, 'f1-score': 0.5450958864751022, 'support': 317799}}
[[27581 14046 23172]
 [27743 93570 66071]
 [11578  7679 46359]]
Evaluating performance on  train set...
528/528 - 7s - 7s/epoch - 14ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.8125436
{'0': {'precision': 0.5237730061349694, 'recall': 0.4102291628164849, 'f1-score': 0.46009949217535495, 'support': 21644}, '1': {'precision': 0.8518307352143621, 'recall': 0.670123618860081, 'f1-score': 0.7501301118655899, 'support': 91410}, '2': {'precision': 0.34272871381728953, 'recall': 0.722003659652333, 'f1-score': 0.46481424216989886, 'support': 21860}, 'accuracy': 0.6368353173132514, 'macro avg': {'precision': 0.5727774850555404, 'recall': 0.6007854804429663, 'f1-score': 0.5583479487369479, 'support': 134914}, 'weighted avg': {'precision': 0.7167116839970357, 'recall': 0.6368353173132514, 'f1-score': 0.6573715572002233, 'support': 134914}}
[[ 8879  6817  5948]
 [ 5834 61256 24320]
 [ 2239  3838 15783]]
Evaluating performance on  val set...
159/159 - 2s - 2s/epoch - 14ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.9046044
{'0': {'precision': 0.49087078651685395, 'recall': 0.38881935753024616, 'f1-score': 0.4339256615193606, 'support': 7191}, '1': {'precision': 0.8312731767614339, 'recall': 0.6104387291981845, 'f1-score': 0.7039427773900907, 'support': 26440}, '2': {'precision': 0.31957630950074273, 'recall': 0.710511200459506, 'f1-score': 0.440860694079387, 'support': 6964}, 'accuracy': 0.5883483187584678, 'macro avg': {'precision': 0.5472400909263435, 'recall': 0.5699230957293122, 'f1-score': 0.5262430443296128, 'support': 40595}, 'weighted avg': {'precision': 0.6831935962255988, 'recall': 0.5883483187584678, 'f1-score': 0.6109806710124048, 'support': 40595}}
[[ 2796  2159  2236]
 [ 2001 16140  8299]
 [  899  1117  4948]]
training model: results/QRTEA/W2/deepVOL_L3/h30
Epoch 1/50
528/528 - 20s - loss: 3.2047 - accuracy30: 0.4080 - val_loss: 3.3722 - val_accuracy30: 0.4916 - 20s/epoch - 39ms/step
Epoch 2/50
528/528 - 17s - loss: 2.8858 - accuracy30: 0.4887 - val_loss: 3.1036 - val_accuracy30: 0.5052 - 17s/epoch - 32ms/step
Epoch 3/50
528/528 - 17s - loss: 2.6672 - accuracy30: 0.5854 - val_loss: 3.0863 - val_accuracy30: 0.5680 - 17s/epoch - 33ms/step
Epoch 4/50
528/528 - 17s - loss: 2.5853 - accuracy30: 0.6069 - val_loss: 3.0913 - val_accuracy30: 0.5723 - 17s/epoch - 33ms/step
Epoch 5/50
528/528 - 17s - loss: 2.5390 - accuracy30: 0.6141 - val_loss: 2.9733 - val_accuracy30: 0.5700 - 17s/epoch - 33ms/step
Epoch 6/50
528/528 - 17s - loss: 2.5209 - accuracy30: 0.6172 - val_loss: 3.0615 - val_accuracy30: 0.5805 - 17s/epoch - 32ms/step
Epoch 7/50
528/528 - 17s - loss: 2.4941 - accuracy30: 0.6194 - val_loss: 2.9722 - val_accuracy30: 0.5553 - 17s/epoch - 32ms/step
Epoch 8/50
528/528 - 17s - loss: 2.4762 - accuracy30: 0.6240 - val_loss: 3.0462 - val_accuracy30: 0.5552 - 17s/epoch - 32ms/step
Epoch 9/50
528/528 - 17s - loss: 2.4605 - accuracy30: 0.6238 - val_loss: 2.9711 - val_accuracy30: 0.5733 - 17s/epoch - 33ms/step
Epoch 10/50
528/528 - 17s - loss: 2.4532 - accuracy30: 0.6256 - val_loss: 2.9647 - val_accuracy30: 0.5615 - 17s/epoch - 33ms/step
Epoch 11/50
528/528 - 17s - loss: 2.4390 - accuracy30: 0.6271 - val_loss: 2.9746 - val_accuracy30: 0.5722 - 17s/epoch - 33ms/step
Epoch 12/50
528/528 - 18s - loss: 2.4273 - accuracy30: 0.6282 - val_loss: 2.9484 - val_accuracy30: 0.5452 - 18s/epoch - 33ms/step
Epoch 13/50
528/528 - 17s - loss: 2.4164 - accuracy30: 0.6297 - val_loss: 2.9337 - val_accuracy30: 0.5828 - 17s/epoch - 33ms/step
Epoch 14/50
528/528 - 17s - loss: 2.4022 - accuracy30: 0.6310 - val_loss: 2.9637 - val_accuracy30: 0.5901 - 17s/epoch - 32ms/step
Epoch 15/50
528/528 - 17s - loss: 2.3951 - accuracy30: 0.6332 - val_loss: 3.0041 - val_accuracy30: 0.5622 - 17s/epoch - 31ms/step
Epoch 16/50
528/528 - 17s - loss: 2.3865 - accuracy30: 0.6331 - val_loss: 2.9752 - val_accuracy30: 0.5433 - 17s/epoch - 32ms/step
Epoch 17/50
528/528 - 17s - loss: 2.3728 - accuracy30: 0.6352 - val_loss: 2.9972 - val_accuracy30: 0.5603 - 17s/epoch - 33ms/step
Epoch 18/50
528/528 - 17s - loss: 2.3649 - accuracy30: 0.6358 - val_loss: 3.0034 - val_accuracy30: 0.5592 - 17s/epoch - 32ms/step
Epoch 19/50
528/528 - 17s - loss: 2.3529 - accuracy30: 0.6371 - val_loss: 3.0145 - val_accuracy30: 0.5534 - 17s/epoch - 32ms/step
Epoch 20/50
528/528 - 17s - loss: 2.3452 - accuracy30: 0.6362 - val_loss: 3.0874 - val_accuracy30: 0.5566 - 17s/epoch - 32ms/step
Epoch 21/50
528/528 - 17s - loss: 2.3392 - accuracy30: 0.6376 - val_loss: 3.0533 - val_accuracy30: 0.5322 - 17s/epoch - 32ms/step
Epoch 22/50
528/528 - 17s - loss: 2.3277 - accuracy30: 0.6401 - val_loss: 3.0624 - val_accuracy30: 0.5854 - 17s/epoch - 33ms/step
Epoch 23/50
528/528 - 17s - loss: 2.3176 - accuracy30: 0.6404 - val_loss: 3.0240 - val_accuracy30: 0.5739 - 17s/epoch - 32ms/step
testing model: results/QRTEA/W2/deepVOL_L3/h30
Evaluating performance on  test set...
1242/1242 - 17s - 17s/epoch - 14ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.99871993
{'0': {'precision': 0.41556509228631505, 'recall': 0.4570845055182861, 'f1-score': 0.4353370819082952, 'support': 73936}, '1': {'precision': 0.7349986288734326, 'recall': 0.528041121406056, 'f1-score': 0.6145641895060849, 'support': 167504}, '2': {'precision': 0.40836253734813194, 'recall': 0.6210924710905067, 'f1-score': 0.49274790125509094, 'support': 76359}, 'accuracy': 0.5338909184736265, 'macro avg': {'precision': 0.5196420861692932, 'recall': 0.5354060326716162, 'f1-score': 0.5142163908898237, 'support': 317799}, 'weighted avg': {'precision': 0.5822000257504348, 'recall': 0.5338909184736265, 'f1-score': 0.5435976182396309, 'support': 317799}}
[[33795 18840 21301]
 [31645 88449 47410]
 [15883 13050 47426]]
Evaluating performance on  train set...
528/528 - 7s - 7s/epoch - 14ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.81654435
{'0': {'precision': 0.5421958326461048, 'recall': 0.3856863511928041, 'f1-score': 0.45074156173587154, 'support': 25570}, '1': {'precision': 0.7849284855848598, 'recall': 0.7117418118675528, 'f1-score': 0.7465457468723308, 'support': 83505}, '2': {'precision': 0.4070623811149588, 'recall': 0.6460002322071288, 'f1-score': 0.49942404069115115, 'support': 25839}, 'accuracy': 0.6373541663578279, 'macro avg': {'precision': 0.5780622331153078, 'recall': 0.5811427984224952, 'f1-score': 0.5655704497664512, 'support': 134914}, 'weighted avg': {'precision': 0.6665541418618828, 'recall': 0.6373541663578279, 'f1-score': 0.6431532836738876, 'support': 134914}}
[[ 9862  9711  5997]
 [ 5754 59434 18317]
 [ 2573  6574 16692]]
Evaluating performance on  val set...
159/159 - 2s - 2s/epoch - 14ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.9085078
{'0': {'precision': 0.5013546056592414, 'recall': 0.39050410316529893, 'f1-score': 0.439040463951496, 'support': 8530}, '1': {'precision': 0.767532401004047, 'recall': 0.6261701771982614, 'f1-score': 0.6896821560910492, 'support': 23928}, '2': {'precision': 0.37262647262647264, 'recall': 0.6608086518372864, 'f1-score': 0.4765365356493995, 'support': 8137}, 'accuracy': 0.5835940386747136, 'macro avg': {'precision': 0.5471711597632537, 'recall': 0.5591609774002823, 'f1-score': 0.5350863852306482, 'support': 40595}, 'weighted avg': {'precision': 0.6324456628959175, 'recall': 0.5835940386747136, 'f1-score': 0.5942925872405974, 'support': 40595}}
[[ 3331  2874  2325]
 [ 2217 14983  6728]
 [ 1096  1664  5377]]
training model: results/QRTEA/W2/deepVOL_L3/h50
Epoch 1/50
528/528 - 20s - loss: 3.2248 - accuracy50: 0.4137 - val_loss: 3.6685 - val_accuracy50: 0.4317 - 20s/epoch - 38ms/step
Epoch 2/50
528/528 - 20s - loss: 3.0602 - accuracy50: 0.4249 - val_loss: 3.4565 - val_accuracy50: 0.3880 - 20s/epoch - 37ms/step
Epoch 3/50
528/528 - 19s - loss: 2.9050 - accuracy50: 0.5080 - val_loss: 3.3186 - val_accuracy50: 0.4620 - 19s/epoch - 35ms/step
Epoch 4/50
528/528 - 19s - loss: 2.7968 - accuracy50: 0.5522 - val_loss: 3.4545 - val_accuracy50: 0.5011 - 19s/epoch - 36ms/step
Epoch 5/50
528/528 - 19s - loss: 2.7323 - accuracy50: 0.5677 - val_loss: 3.2618 - val_accuracy50: 0.5482 - 19s/epoch - 36ms/step
Epoch 6/50
528/528 - 19s - loss: 2.6986 - accuracy50: 0.5758 - val_loss: 3.2988 - val_accuracy50: 0.5552 - 19s/epoch - 36ms/step
Epoch 7/50
528/528 - 19s - loss: 2.6705 - accuracy50: 0.5840 - val_loss: 3.3216 - val_accuracy50: 0.5509 - 19s/epoch - 36ms/step
Epoch 8/50
528/528 - 19s - loss: 2.6544 - accuracy50: 0.5847 - val_loss: 3.3267 - val_accuracy50: 0.5232 - 19s/epoch - 36ms/step
Epoch 9/50
528/528 - 19s - loss: 2.6354 - accuracy50: 0.5862 - val_loss: 3.3112 - val_accuracy50: 0.5433 - 19s/epoch - 36ms/step
Epoch 10/50
528/528 - 19s - loss: 2.6190 - accuracy50: 0.5886 - val_loss: 3.2770 - val_accuracy50: 0.5489 - 19s/epoch - 36ms/step
Epoch 11/50
528/528 - 19s - loss: 2.6051 - accuracy50: 0.5915 - val_loss: 3.3072 - val_accuracy50: 0.5378 - 19s/epoch - 36ms/step
Epoch 12/50
528/528 - 19s - loss: 2.5947 - accuracy50: 0.5913 - val_loss: 3.1886 - val_accuracy50: 0.5438 - 19s/epoch - 36ms/step
Epoch 13/50
528/528 - 19s - loss: 2.5822 - accuracy50: 0.5943 - val_loss: 3.2158 - val_accuracy50: 0.5457 - 19s/epoch - 36ms/step
Epoch 14/50
528/528 - 19s - loss: 2.5725 - accuracy50: 0.5968 - val_loss: 3.2324 - val_accuracy50: 0.5479 - 19s/epoch - 36ms/step
Epoch 15/50
528/528 - 19s - loss: 2.5642 - accuracy50: 0.5984 - val_loss: 3.1603 - val_accuracy50: 0.5468 - 19s/epoch - 36ms/step
Epoch 16/50
528/528 - 19s - loss: 2.5500 - accuracy50: 0.6001 - val_loss: 3.2057 - val_accuracy50: 0.5462 - 19s/epoch - 35ms/step
Epoch 17/50
528/528 - 19s - loss: 2.5395 - accuracy50: 0.6028 - val_loss: 3.1823 - val_accuracy50: 0.5479 - 19s/epoch - 36ms/step
Epoch 18/50
528/528 - 19s - loss: 2.5308 - accuracy50: 0.6058 - val_loss: 3.2288 - val_accuracy50: 0.5499 - 19s/epoch - 35ms/step
Epoch 19/50
528/528 - 19s - loss: 2.5212 - accuracy50: 0.6059 - val_loss: 3.2010 - val_accuracy50: 0.5502 - 19s/epoch - 36ms/step
Epoch 20/50
528/528 - 19s - loss: 2.5110 - accuracy50: 0.6076 - val_loss: 3.2194 - val_accuracy50: 0.5382 - 19s/epoch - 36ms/step
Epoch 21/50
528/528 - 19s - loss: 2.5035 - accuracy50: 0.6102 - val_loss: 3.2832 - val_accuracy50: 0.5403 - 19s/epoch - 36ms/step
Epoch 22/50
528/528 - 19s - loss: 2.4922 - accuracy50: 0.6114 - val_loss: 3.2976 - val_accuracy50: 0.5436 - 19s/epoch - 36ms/step
Epoch 23/50
528/528 - 19s - loss: 2.4804 - accuracy50: 0.6134 - val_loss: 3.3194 - val_accuracy50: 0.5419 - 19s/epoch - 36ms/step
Epoch 24/50
528/528 - 19s - loss: 2.4767 - accuracy50: 0.6141 - val_loss: 3.4195 - val_accuracy50: 0.5446 - 19s/epoch - 36ms/step
Epoch 25/50
528/528 - 19s - loss: 2.4652 - accuracy50: 0.6157 - val_loss: 3.4521 - val_accuracy50: 0.5432 - 19s/epoch - 36ms/step
testing model: results/QRTEA/W2/deepVOL_L3/h50
Evaluating performance on  test set...
1242/1242 - 16s - 16s/epoch - 13ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0051621
{'0': {'precision': 0.46594891888491474, 'recall': 0.3003069794381697, 'f1-score': 0.365224496696299, 'support': 86325}, '1': {'precision': 0.6209490133796802, 'recall': 0.5902316407112288, 'f1-score': 0.6052008075379947, 'support': 140433}, '2': {'precision': 0.44325282103888836, 'recall': 0.6264869674102876, 'f1-score': 0.5191769412471497, 'support': 91041}, 'accuracy': 0.5218644489126775, 'macro avg': {'precision': 0.5100502511011611, 'recall': 0.5056751958532287, 'f1-score': 0.49653408182714776, 'support': 317799}, 'weighted avg': {'precision': 0.5279404696015102, 'recall': 0.5218644489126775, 'f1-score': 0.5153715322904509, 'support': 317799}}
[[25924 28708 31693]
 [17598 82888 39947]
 [12115 21890 57036]]
Evaluating performance on  train set...
528/528 - 7s - 7s/epoch - 14ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.90711886
{'0': {'precision': 0.6466183771465777, 'recall': 0.2503544981881204, 'f1-score': 0.3609558856935169, 'support': 31735}, '1': {'precision': 0.6755868972978609, 'recall': 0.7291130336920588, 'f1-score': 0.7013301579139659, 'support': 71085}, '2': {'precision': 0.4434981485515138, 'recall': 0.6344176481585343, 'f1-score': 0.5220501512742936, 'support': 32094}, 'accuracy': 0.5939709741020206, 'macro avg': {'precision': 0.5885678076653175, 'recall': 0.5379617266795712, 'f1-score': 0.5281120649605922, 'support': 134914}, 'weighted avg': {'precision': 0.6135624054788782, 'recall': 0.5939709741020206, 'f1-score': 0.578617985255757, 'support': 134914}}
[[ 7945 14966  8824]
 [ 2531 51829 16725]
 [ 1811  9922 20361]]
Evaluating performance on  val set...
159/159 - 2s - 2s/epoch - 14ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.96340203
{'0': {'precision': 0.5332057416267942, 'recall': 0.2625082446056723, 'f1-score': 0.35181209748705644, 'support': 10613}, '1': {'precision': 0.6499550134959512, 'recall': 0.6499225271155096, 'f1-score': 0.6499387698997825, 'support': 20007}, '2': {'precision': 0.4125227805259047, 'recall': 0.6353884711779448, 'f1-score': 0.5002565215675441, 'support': 9975}, 'accuracy': 0.5450671264934105, 'macro avg': {'precision': 0.5318945118828834, 'recall': 0.5159397476330422, 'f1-score': 0.500669129651461, 'support': 40595}, 'weighted avg': {'precision': 0.5610907064082908, 'recall': 0.5450671264934105, 'f1-score': 0.5352177746680954, 'support': 40595}}
[[ 2786  4399  3428]
 [ 1406 13003  5598]
 [ 1033  2604  6338]]
training model: results/QRTEA/W2/deepVOL_L3/h100
Epoch 1/50
528/528 - 21s - loss: 3.2493 - accuracy100: 0.4097 - val_loss: 3.5437 - val_accuracy100: 0.3795 - 21s/epoch - 39ms/step
Epoch 2/50
528/528 - 18s - loss: 3.1552 - accuracy100: 0.4382 - val_loss: 3.5663 - val_accuracy100: 0.3963 - 18s/epoch - 34ms/step
Epoch 3/50
528/528 - 18s - loss: 3.0794 - accuracy100: 0.4698 - val_loss: 3.3289 - val_accuracy100: 0.4467 - 18s/epoch - 34ms/step
Epoch 4/50
528/528 - 19s - loss: 2.9909 - accuracy100: 0.5021 - val_loss: 3.2372 - val_accuracy100: 0.4628 - 19s/epoch - 36ms/step
Epoch 5/50
528/528 - 19s - loss: 2.9497 - accuracy100: 0.5145 - val_loss: 3.2926 - val_accuracy100: 0.4629 - 19s/epoch - 35ms/step
Epoch 6/50
528/528 - 19s - loss: 2.9234 - accuracy100: 0.5199 - val_loss: 3.3605 - val_accuracy100: 0.4650 - 19s/epoch - 35ms/step
Epoch 7/50
528/528 - 17s - loss: 2.9044 - accuracy100: 0.5249 - val_loss: 3.4117 - val_accuracy100: 0.4659 - 17s/epoch - 32ms/step
Epoch 8/50
528/528 - 17s - loss: 2.8789 - accuracy100: 0.5324 - val_loss: 3.3067 - val_accuracy100: 0.4735 - 17s/epoch - 32ms/step
Epoch 9/50
528/528 - 17s - loss: 2.8618 - accuracy100: 0.5347 - val_loss: 3.3882 - val_accuracy100: 0.4609 - 17s/epoch - 33ms/step
Epoch 10/50
528/528 - 17s - loss: 2.8454 - accuracy100: 0.5384 - val_loss: 3.3614 - val_accuracy100: 0.4654 - 17s/epoch - 33ms/step
Epoch 11/50
528/528 - 17s - loss: 2.8285 - accuracy100: 0.5407 - val_loss: 3.3505 - val_accuracy100: 0.4667 - 17s/epoch - 32ms/step
Epoch 12/50
528/528 - 17s - loss: 2.8163 - accuracy100: 0.5445 - val_loss: 3.3509 - val_accuracy100: 0.4696 - 17s/epoch - 32ms/step
Epoch 13/50
528/528 - 17s - loss: 2.8006 - accuracy100: 0.5487 - val_loss: 3.3494 - val_accuracy100: 0.4715 - 17s/epoch - 32ms/step
Epoch 14/50
528/528 - 17s - loss: 2.7922 - accuracy100: 0.5502 - val_loss: 3.3628 - val_accuracy100: 0.4719 - 17s/epoch - 32ms/step
testing model: results/QRTEA/W2/deepVOL_L3/h100
Evaluating performance on  test set...
1242/1242 - 17s - 17s/epoch - 14ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0559185
{'0': {'precision': 0.47706242864868115, 'recall': 0.30291960359776043, 'f1-score': 0.3705510019543214, 'support': 104843}, '1': {'precision': 0.4599874125708043, 'recall': 0.3903146821438288, 'f1-score': 0.42229659751218285, 'support': 99243}, '2': {'precision': 0.4463284954734876, 'recall': 0.6555451003843008, 'f1-score': 0.5310744525859459, 'support': 113713}, 'accuracy': 0.4563859546442877, 'macro avg': {'precision': 0.46112611223099104, 'recall': 0.44959312870862994, 'f1-score': 0.44130735068415006, 'support': 317799}, 'weighted avg': {'precision': 0.46073316529741976, 'recall': 0.4563859546442877, 'f1-score': 0.4441478077391815, 'support': 317799}}
[[31759 23656 49428]
 [17463 38736 43044]
 [17350 21819 74544]]
Evaluating performance on  train set...
528/528 - 7s - 7s/epoch - 14ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0254285
{'0': {'precision': 0.5667825094662586, 'recall': 0.26334562456317934, 'f1-score': 0.35960639768314356, 'support': 41493}, '1': {'precision': 0.5176120038310099, 'recall': 0.5709031866820556, 'f1-score': 0.5429530888084763, 'support': 51119}, '2': {'precision': 0.4457327055170202, 'recall': 0.6243440026476289, 'f1-score': 0.5201319482054059, 'support': 42302}, 'accuracy': 0.493069659190299, 'macro avg': {'precision': 0.5100424062714296, 'recall': 0.4861976046309546, 'f1-score': 0.4742304782323419, 'support': 134914}, 'weighted avg': {'precision': 0.5101968631713674, 'recall': 0.493069659190299, 'f1-score': 0.47940902262813534, 'support': 134914}}
[[10927 15169 15397]
 [ 4490 29184 17445]
 [ 3862 12029 26411]]
Evaluating performance on  val set...
159/159 - 2s - 2s/epoch - 14ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.061787
{'0': {'precision': 0.5373183619550859, 'recall': 0.23613933236574747, 'f1-score': 0.32809034079451505, 'support': 13780}, '1': {'precision': 0.4981675218231492, 'recall': 0.5213025590962973, 'f1-score': 0.5094725364590431, 'support': 14341}, '2': {'precision': 0.4158304321114069, 'recall': 0.6511143177809845, 'f1-score': 0.5075298381553458, 'support': 12474}, 'accuracy': 0.46439216652297083, 'macro avg': {'precision': 0.4837721052965473, 'recall': 0.4695187364143431, 'f1-score': 0.44836423846963464, 'support': 40595}, 'weighted avg': {'precision': 0.48615682395281573, 'recall': 0.46439216652297083, 'f1-score': 0.4473052775626885, 'support': 40595}}
[[3254 4536 5990]
 [1445 7476 5420]
 [1357 2995 8122]]
training model: results/QRTEA/W2/deepVOL_L3/h200
Epoch 1/50
528/528 - 20s - loss: 3.2992 - accuracy200: 0.3778 - val_loss: 3.5452 - val_accuracy200: 0.3252 - 20s/epoch - 39ms/step
Epoch 2/50
528/528 - 20s - loss: 3.2561 - accuracy200: 0.3961 - val_loss: 3.3941 - val_accuracy200: 0.3260 - 20s/epoch - 37ms/step
Epoch 3/50
528/528 - 19s - loss: 3.2333 - accuracy200: 0.4033 - val_loss: 3.3879 - val_accuracy200: 0.3425 - 19s/epoch - 36ms/step
Epoch 4/50
528/528 - 19s - loss: 3.2162 - accuracy200: 0.4133 - val_loss: 3.4703 - val_accuracy200: 0.3529 - 19s/epoch - 35ms/step
Epoch 5/50
528/528 - 18s - loss: 3.1932 - accuracy200: 0.4270 - val_loss: 3.4839 - val_accuracy200: 0.3580 - 18s/epoch - 35ms/step
Epoch 6/50
528/528 - 19s - loss: 3.1776 - accuracy200: 0.4371 - val_loss: 3.4735 - val_accuracy200: 0.3456 - 19s/epoch - 36ms/step
Epoch 7/50
528/528 - 19s - loss: 3.1608 - accuracy200: 0.4451 - val_loss: 3.4189 - val_accuracy200: 0.3572 - 19s/epoch - 35ms/step
Epoch 8/50
528/528 - 19s - loss: 3.1527 - accuracy200: 0.4489 - val_loss: 3.4989 - val_accuracy200: 0.3455 - 19s/epoch - 35ms/step
Epoch 9/50
528/528 - 17s - loss: 3.1377 - accuracy200: 0.4558 - val_loss: 3.5532 - val_accuracy200: 0.3507 - 17s/epoch - 33ms/step
Epoch 10/50
528/528 - 19s - loss: 3.1197 - accuracy200: 0.4633 - val_loss: 3.5941 - val_accuracy200: 0.3513 - 19s/epoch - 35ms/step
Epoch 11/50
528/528 - 19s - loss: 3.1071 - accuracy200: 0.4671 - val_loss: 3.5966 - val_accuracy200: 0.3548 - 19s/epoch - 35ms/step
Epoch 12/50
528/528 - 18s - loss: 3.0976 - accuracy200: 0.4710 - val_loss: 3.5428 - val_accuracy200: 0.3695 - 18s/epoch - 34ms/step
Epoch 13/50
528/528 - 19s - loss: 3.0898 - accuracy200: 0.4723 - val_loss: 3.6457 - val_accuracy200: 0.3737 - 19s/epoch - 35ms/step
testing model: results/QRTEA/W2/deepVOL_L3/h200
Evaluating performance on  test set...
1242/1242 - 17s - 17s/epoch - 14ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1012352
{'0': {'precision': 0.4437476670399403, 'recall': 0.05946021647360102, 'f1-score': 0.1048685173913427, 'support': 99966}, '1': {'precision': 0.33689342639858316, 'recall': 0.7522377505257085, 'f1-score': 0.4653690181868418, 'support': 107474}, '2': {'precision': 0.39964922628009125, 'recall': 0.23332034541813537, 'f1-score': 0.2946312103805753, 'support': 110359}, 'accuracy': 0.35412005701717125, 'macro avg': {'precision': 0.3934301065728716, 'recall': 0.3483394374724816, 'f1-score': 0.28828958198625326, 'support': 317799}, 'weighted avg': {'precision': 0.39229781199789987, 'recall': 0.35412005701717125, 'f1-score': 0.29268047355890203, 'support': 317799}}
[[ 5944 77237 16785]
 [ 4733 80846 21895]
 [ 2718 81892 25749]]
Evaluating performance on  train set...
528/528 - 7s - 7s/epoch - 14ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0953492
{'0': {'precision': 0.51252067091897, 'recall': 0.09707152285286025, 'f1-score': 0.1632276873883194, 'support': 44699}, '1': {'precision': 0.3290752048003563, 'recall': 0.6284467323187108, 'f1-score': 0.4319613559269886, 'support': 44680}, '2': {'precision': 0.42221735852727316, 'recall': 0.3812891182606786, 'f1-score': 0.4007108567208272, 'support': 45535}, 'accuracy': 0.3689757919860059, 'macro avg': {'precision': 0.42127107808219977, 'recall': 0.3689357911440832, 'f1-score': 0.3319666333453784, 'support': 134914}, 'weighted avg': {'precision': 0.42128992573362545, 'recall': 0.3689757919860059, 'f1-score': 0.33237852737426216, 'support': 134914}}
[[ 4339 30361  9999]
 [ 2841 28079 13760]
 [ 1286 26887 17362]]
Evaluating performance on  val set...
159/159 - 2s - 2s/epoch - 14ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1283644
{'0': {'precision': 0.39185140802875973, 'recall': 0.04417128191273808, 'f1-score': 0.07939301972685887, 'support': 14806}, '1': {'precision': 0.32446560922338785, 'recall': 0.6890730742909285, 'f1-score': 0.44118792599805257, 'support': 13151}, '2': {'precision': 0.38446849140674727, 'recall': 0.33454660547554993, 'f1-score': 0.357774486989634, 'support': 12638}, 'accuracy': 0.343490577657347, 'macro avg': {'precision': 0.3669285028862983, 'recall': 0.35593032055973883, 'f1-score': 0.2927851442381818, 'support': 40595}, 'weighted avg': {'precision': 0.3677229207678055, 'recall': 0.343490577657347, 'f1-score': 0.28326418109253, 'support': 40595}}
[[  654 10731  3421]
 [  741  9062  3348]
 [  274  8136  4228]]
training model: results/QRTEA/W2/deepVOL_L3/h300
Epoch 1/50
528/528 - 20s - loss: 3.3172 - accuracy300: 0.3648 - val_loss: 3.3332 - val_accuracy300: 0.3412 - 20s/epoch - 38ms/step
Epoch 2/50
528/528 - 17s - loss: 3.2697 - accuracy300: 0.3808 - val_loss: 3.3350 - val_accuracy300: 0.3474 - 17s/epoch - 32ms/step
Epoch 3/50
528/528 - 17s - loss: 3.2515 - accuracy300: 0.3923 - val_loss: 3.3400 - val_accuracy300: 0.3582 - 17s/epoch - 32ms/step
Epoch 4/50
528/528 - 17s - loss: 3.2398 - accuracy300: 0.3989 - val_loss: 3.4029 - val_accuracy300: 0.3537 - 17s/epoch - 32ms/step
Epoch 5/50
528/528 - 17s - loss: 3.2311 - accuracy300: 0.4061 - val_loss: 3.4346 - val_accuracy300: 0.3415 - 17s/epoch - 32ms/step
Epoch 6/50
528/528 - 17s - loss: 3.2253 - accuracy300: 0.4071 - val_loss: 3.4251 - val_accuracy300: 0.3494 - 17s/epoch - 33ms/step
Epoch 7/50
528/528 - 18s - loss: 3.2168 - accuracy300: 0.4153 - val_loss: 3.5356 - val_accuracy300: 0.3407 - 18s/epoch - 33ms/step
Epoch 8/50
528/528 - 18s - loss: 3.2068 - accuracy300: 0.4175 - val_loss: 3.5200 - val_accuracy300: 0.3465 - 18s/epoch - 34ms/step
Epoch 9/50
528/528 - 18s - loss: 3.1890 - accuracy300: 0.4276 - val_loss: 3.6143 - val_accuracy300: 0.3334 - 18s/epoch - 33ms/step
Epoch 10/50
528/528 - 17s - loss: 3.1768 - accuracy300: 0.4330 - val_loss: 3.6248 - val_accuracy300: 0.3408 - 17s/epoch - 33ms/step
Epoch 11/50
528/528 - 17s - loss: 3.1617 - accuracy300: 0.4378 - val_loss: 3.7044 - val_accuracy300: 0.3459 - 17s/epoch - 32ms/step
testing model: results/QRTEA/W2/deepVOL_L3/h300
Evaluating performance on  test set...
1242/1242 - 17s - 17s/epoch - 14ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.106722
{'0': {'precision': 0.30852660927111736, 'recall': 0.10214639292380102, 'f1-score': 0.15347919190995482, 'support': 98584}, '1': {'precision': 0.34508118961436085, 'recall': 0.6819468333924882, 'f1-score': 0.45826797175768363, 'support': 109881}, '2': {'precision': 0.36142558884935455, 'recall': 0.22483399491466516, 'f1-score': 0.2772176737262332, 'support': 109334}, 'accuracy': 0.3448248735836173, 'macro avg': {'precision': 0.3383444625782776, 'recall': 0.33630907374365143, 'f1-score': 0.2963216124646239, 'support': 317799}, 'weighted avg': {'precision': 0.3393646889249329, 'recall': 0.3448248735836173, 'f1-score': 0.30143220337112764, 'support': 317799}}
[[10070 68415 20099]
 [11615 74933 23333]
 [10954 73798 24582]]
Evaluating performance on  train set...
528/528 - 7s - 7s/epoch - 14ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1045903
{'0': {'precision': 0.3838903170522708, 'recall': 0.08975957257346394, 'f1-score': 0.14549916099814156, 'support': 44920}, '1': {'precision': 0.3327551465547685, 'recall': 0.721554054054054, 'f1-score': 0.45546567338176547, 'support': 44400}, '2': {'precision': 0.3655849002950272, 'recall': 0.2255779269202088, 'f1-score': 0.2790022651131879, 'support': 45594}, 'accuracy': 0.34358183731858816, 'macro avg': {'precision': 0.3607434546340222, 'recall': 0.34563051784924226, 'f1-score': 0.2933223664976983, 'support': 134914}, 'weighted avg': {'precision': 0.36087551694465514, 'recall': 0.34358183731858816, 'f1-score': 0.29262587637871235, 'support': 134914}}
[[ 4032 32167  8721]
 [ 3236 32037  9127]
 [ 3235 32074 10285]]
Evaluating performance on  val set...
159/159 - 2s - 2s/epoch - 14ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1110965
{'0': {'precision': 0.38318009734991887, 'recall': 0.09567859554355165, 'f1-score': 0.1531229738491463, 'support': 14810}, '1': {'precision': 0.33948473006223767, 'recall': 0.6863706196503037, 'f1-score': 0.45427914296090066, 'support': 13669}, '2': {'precision': 0.31357304826692584, 'recall': 0.23968306371739848, 'f1-score': 0.27169387659634187, 'support': 12116}, 'accuracy': 0.3375538859465451, 'macro avg': {'precision': 0.3454126252263608, 'recall': 0.34057742630375126, 'f1-score': 0.29303199780212963, 'support': 40595}, 'weighted avg': {'precision': 0.34769220519214433, 'recall': 0.3375538859465451, 'f1-score': 0.28991589744253443, 'support': 40595}}
[[1417 9999 3394]
 [1324 9382 2963]
 [ 957 8255 2904]]
training model: results/QRTEA/W2/deepVOL_L3/h500
Epoch 1/50
528/528 - 20s - loss: 3.2665 - accuracy500: 0.4020 - val_loss: 3.5409 - val_accuracy500: 0.3853 - 20s/epoch - 38ms/step
Epoch 2/50
528/528 - 20s - loss: 3.2776 - accuracy500: 0.3759 - val_loss: 3.4095 - val_accuracy500: 0.3918 - 20s/epoch - 37ms/step
Epoch 3/50
528/528 - 17s - loss: 3.2769 - accuracy500: 0.3764 - val_loss: 3.3751 - val_accuracy500: 0.3736 - 17s/epoch - 32ms/step
Epoch 4/50
528/528 - 17s - loss: 3.2667 - accuracy500: 0.3866 - val_loss: 3.3987 - val_accuracy500: 0.3660 - 17s/epoch - 32ms/step
Epoch 5/50
528/528 - 17s - loss: 3.2490 - accuracy500: 0.3912 - val_loss: 3.5292 - val_accuracy500: 0.3919 - 17s/epoch - 32ms/step
Epoch 6/50
528/528 - 17s - loss: 3.2300 - accuracy500: 0.3999 - val_loss: 3.5983 - val_accuracy500: 0.3931 - 17s/epoch - 32ms/step
Epoch 7/50
528/528 - 17s - loss: 3.2204 - accuracy500: 0.4107 - val_loss: 3.5837 - val_accuracy500: 0.3891 - 17s/epoch - 32ms/step
Epoch 8/50
528/528 - 17s - loss: 3.2140 - accuracy500: 0.4172 - val_loss: 3.5947 - val_accuracy500: 0.3857 - 17s/epoch - 33ms/step
Epoch 9/50
528/528 - 17s - loss: 3.2004 - accuracy500: 0.4192 - val_loss: 3.6100 - val_accuracy500: 0.3844 - 17s/epoch - 32ms/step
Epoch 10/50
528/528 - 17s - loss: 3.1850 - accuracy500: 0.4272 - val_loss: 3.6480 - val_accuracy500: 0.3847 - 17s/epoch - 33ms/step
Epoch 11/50
528/528 - 19s - loss: 3.1812 - accuracy500: 0.4285 - val_loss: 3.6713 - val_accuracy500: 0.3818 - 19s/epoch - 35ms/step
Epoch 12/50
528/528 - 19s - loss: 3.1681 - accuracy500: 0.4360 - val_loss: 3.7601 - val_accuracy500: 0.3878 - 19s/epoch - 35ms/step
Epoch 13/50
528/528 - 18s - loss: 3.1646 - accuracy500: 0.4362 - val_loss: 3.6694 - val_accuracy500: 0.3780 - 18s/epoch - 33ms/step
testing model: results/QRTEA/W2/deepVOL_L3/h500
Evaluating performance on  test set...
1242/1242 - 17s - 17s/epoch - 14ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1002321
{'0': {'precision': 0.2623680721008204, 'recall': 0.29570003523565364, 'f1-score': 0.2780386377397722, 'support': 82303}, '1': {'precision': 0.44928578664775604, 'recall': 0.6249110520864891, 'f1-score': 0.5227415376727164, 'support': 141937}, '2': {'precision': 0.3112961622013034, 'recall': 0.09189922936328948, 'f1-score': 0.14190577575322458, 'support': 93559}, 'accuracy': 0.3827356284947404, 'macro avg': {'precision': 0.34098334031662664, 'recall': 0.33750343889514406, 'f1-score': 0.31422865038857106, 'support': 317799}, 'weighted avg': {'precision': 0.36025448090437073, 'recall': 0.3827356284947404, 'f1-score': 0.3472520118321479, 'support': 317799}}
[[24337 51192  6774]
 [40991 88698 12248]
 [27431 57530  8598]]
Evaluating performance on  train set...
528/528 - 8s - 8s/epoch - 14ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1508697
{'0': {'precision': 0.386873216469629, 'recall': 0.14501200611220258, 'f1-score': 0.21095250948698815, 'support': 45810}, '1': {'precision': 0.3396936691019705, 'recall': 0.8641779189833201, 'f1-score': 0.4876861800904166, 'support': 44065}, '2': {'precision': 0.37167671038638783, 'recall': 0.046559648304802505, 'f1-score': 0.08275290542806969, 'support': 45039}, 'accuracy': 0.3470358895296263, 'macro avg': {'precision': 0.3660811986526625, 'recall': 0.35191652446677507, 'f1-score': 0.2604638650018248, 'support': 134914}, 'weighted avg': {'precision': 0.3663905223664302, 'recall': 0.3470358895296263, 'f1-score': 0.25854050797439826, 'support': 134914}}
[[ 6643 37195  1972]
 [ 4412 38080  1573]
 [ 6116 36826  2097]]
Evaluating performance on  val set...
159/159 - 2s - 2s/epoch - 14ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1272625
{'0': {'precision': 0.3443476413089673, 'recall': 0.23524715104884952, 'f1-score': 0.27952908706714386, 'support': 13777}, '1': {'precision': 0.3958634807468323, 'recall': 0.7003434280362161, 'f1-score': 0.5058176242446109, 'support': 16015}, '2': {'precision': 0.2635087719298246, 'recall': 0.06951772655743775, 'f1-score': 0.11001245147586611, 'support': 10803}, 'accuracy': 0.3746274171696022, 'macro avg': {'precision': 0.3345732979952081, 'recall': 0.3350361018808345, 'f1-score': 0.29845305426254026, 'support': 40595}, 'weighted avg': {'precision': 0.34315842743273944, 'recall': 0.3746274171696022, 'f1-score': 0.3236902573739442, 'support': 40595}}
[[ 3241  9492  1044]
 [ 3744 11216  1055]
 [ 2427  7625   751]]
training model: results/QRTEA/W2/deepVOL_L3/h1000
Epoch 1/50
528/528 - 21s - loss: 3.3025 - accuracy1000: 0.3847 - val_loss: 3.3628 - val_accuracy1000: 0.3865 - 21s/epoch - 39ms/step
Epoch 2/50
528/528 - 18s - loss: 3.2946 - accuracy1000: 0.3771 - val_loss: 3.3210 - val_accuracy1000: 0.3756 - 18s/epoch - 33ms/step
Epoch 3/50
528/528 - 18s - loss: 3.2957 - accuracy1000: 0.3613 - val_loss: 3.3182 - val_accuracy1000: 0.3776 - 18s/epoch - 34ms/step
Epoch 4/50
528/528 - 17s - loss: 3.2807 - accuracy1000: 0.3790 - val_loss: 3.3393 - val_accuracy1000: 0.3645 - 17s/epoch - 33ms/step
Epoch 5/50
528/528 - 17s - loss: 3.2617 - accuracy1000: 0.3901 - val_loss: 3.4111 - val_accuracy1000: 0.3292 - 17s/epoch - 32ms/step
Epoch 6/50
528/528 - 17s - loss: 3.2743 - accuracy1000: 0.3774 - val_loss: 3.3806 - val_accuracy1000: 0.3388 - 17s/epoch - 33ms/step
Epoch 7/50
528/528 - 17s - loss: 3.2549 - accuracy1000: 0.3903 - val_loss: 3.4164 - val_accuracy1000: 0.3319 - 17s/epoch - 33ms/step
Epoch 8/50
528/528 - 17s - loss: 3.2399 - accuracy1000: 0.4042 - val_loss: 3.4019 - val_accuracy1000: 0.3543 - 17s/epoch - 32ms/step
Epoch 9/50
528/528 - 17s - loss: 3.2263 - accuracy1000: 0.4140 - val_loss: 3.3946 - val_accuracy1000: 0.3365 - 17s/epoch - 33ms/step
Epoch 10/50
528/528 - 17s - loss: 3.2087 - accuracy1000: 0.4263 - val_loss: 3.4570 - val_accuracy1000: 0.3308 - 17s/epoch - 33ms/step
Epoch 11/50
528/528 - 17s - loss: 3.1884 - accuracy1000: 0.4335 - val_loss: 3.4824 - val_accuracy1000: 0.3317 - 17s/epoch - 32ms/step
Epoch 12/50
528/528 - 17s - loss: 3.1994 - accuracy1000: 0.4285 - val_loss: 3.4633 - val_accuracy1000: 0.3340 - 17s/epoch - 33ms/step
Epoch 13/50
528/528 - 18s - loss: 3.1957 - accuracy1000: 0.4317 - val_loss: 3.5210 - val_accuracy1000: 0.3195 - 18s/epoch - 33ms/step
testing model: results/QRTEA/W2/deepVOL_L3/h1000
Evaluating performance on  test set...
1242/1242 - 17s - 17s/epoch - 14ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0953212
{'0': {'precision': 0.24810594394825994, 'recall': 0.04564564564564565, 'f1-score': 0.07710566615620215, 'support': 88245}, '1': {'precision': 0.387092562612374, 'recall': 0.8352395746975636, 'f1-score': 0.5290133794182795, 'support': 124241}, '2': {'precision': 0.36026996356686375, 'recall': 0.11455375879521047, 'f1-score': 0.1738341054330363, 'support': 105313}, 'accuracy': 0.3771660703778174, 'macro avg': {'precision': 0.3318228233758325, 'recall': 0.3318129930461399, 'f1-score': 0.25998438366917265, 'support': 317799}, 'weighted avg': {'precision': 0.33961084449087403, 'recall': 0.3771660703778174, 'f1-score': 0.2858295083613538, 'support': 317799}}
[[  4028  76280   7937]
 [  6985 103771  13485]
 [  5222  88027  12064]]
Evaluating performance on  train set...
528/528 - 7s - 7s/epoch - 14ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1097591
{'0': {'precision': 0.378718056137411, 'recall': 0.03880661086069972, 'f1-score': 0.07039950159644888, 'support': 46590}, '1': {'precision': 0.331992117609228, 'recall': 0.903005158107199, 'f1-score': 0.4854919124872643, 'support': 44590}, '2': {'precision': 0.35260246133002143, 'recall': 0.07140897242420086, 'f1-score': 0.11876556825312316, 'support': 43734}, 'accuracy': 0.33499859169545043, 'macro avg': {'precision': 0.35443754502555347, 'recall': 0.33774024713069983, 'f1-score': 0.22488566077894545, 'support': 134914}, 'weighted avg': {'precision': 0.3548091288038648, 'recall': 0.33499859169545043, 'f1-score': 0.2232688269502628, 'support': 134914}}
[[ 1808 41619  3163]
 [ 1754 40265  2571]
 [ 1212 39399  3123]]
Evaluating performance on  val set...
159/159 - 2s - 2s/epoch - 14ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1099048
{'0': {'precision': 0.3588290840415486, 'recall': 0.05308745459625594, 'f1-score': 0.09249117682852623, 'support': 14316}, '1': {'precision': 0.38890632579108053, 'recall': 0.8651770978799035, 'f1-score': 0.5366036101651541, 'support': 15754}, '2': {'precision': 0.26034985422740525, 'recall': 0.08484560570071259, 'f1-score': 0.1279828018631315, 'support': 10525}, 'accuracy': 0.37647493533686416, 'macro avg': {'precision': 0.3360284213533448, 'recall': 0.334370052725624, 'f1-score': 0.25235919628560394, 'support': 40595}, 'weighted avg': {'precision': 0.34496882964392, 'recall': 0.37647493533686416, 'f1-score': 0.27404300903137035, 'support': 40595}}
[[  760 12345  1211]
 [  798 13630  1326]
 [  560  9072   893]]

============================================

        Job resource usage summary 

                 Memory (GB)    NCPUs
 Requested  :        96            32
 Used       :        15 (peak)  13.35 (ave)

============================================
