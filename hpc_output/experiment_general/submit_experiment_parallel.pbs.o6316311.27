This machine has 1 visible gpus.
This machine has 1 physical gpus.
getting alphas...
data/WBA_orderbooks/WBA_orderbooks_2019-04-17.csv
data/WBA_orderbooks/WBA_orderbooks_2019-04-09.csv
data/WBA_orderbooks/WBA_orderbooks_2019-03-27.csv
data/WBA_orderbooks/WBA_orderbooks_2019-03-28.csv
data/WBA_orderbooks/WBA_orderbooks_2019-04-05.csv
data/WBA_orderbooks/WBA_orderbooks_2019-04-01.csv
data/WBA_orderbooks/WBA_orderbooks_2019-04-03.csv
data/WBA_orderbooks/WBA_orderbooks_2019-03-29.csv
data/WBA_orderbooks/WBA_orderbooks_2019-04-02.csv
data/WBA_orderbooks/WBA_orderbooks_2019-04-15.csv
data/WBA_orderbooks/WBA_orderbooks_2019-04-04.csv
data/WBA_orderbooks/WBA_orderbooks_2019-03-26.csv
data/WBA_orderbooks/WBA_orderbooks_2019-04-11.csv
data/WBA_orderbooks/WBA_orderbooks_2019-04-10.csv
training model: results/WBA/W2/deepLOB_L1/h10
Epoch 1/50
1542/1542 - 46s - loss: 3.0022 - accuracy10: 0.4491 - val_loss: 3.3192 - val_accuracy10: 0.5671 - 46s/epoch - 30ms/step
Epoch 2/50
1542/1542 - 37s - loss: 2.9465 - accuracy10: 0.4550 - val_loss: 3.2630 - val_accuracy10: 0.5772 - 37s/epoch - 24ms/step
Epoch 3/50
1542/1542 - 36s - loss: 2.8914 - accuracy10: 0.4782 - val_loss: 3.5214 - val_accuracy10: 0.5840 - 36s/epoch - 24ms/step
Epoch 4/50
1542/1542 - 37s - loss: 2.8365 - accuracy10: 0.5064 - val_loss: 3.1682 - val_accuracy10: 0.5991 - 37s/epoch - 24ms/step
Epoch 5/50
1542/1542 - 36s - loss: 2.7905 - accuracy10: 0.5293 - val_loss: 3.2145 - val_accuracy10: 0.6172 - 36s/epoch - 23ms/step
Epoch 6/50
1542/1542 - 36s - loss: 2.7341 - accuracy10: 0.5496 - val_loss: 3.1032 - val_accuracy10: 0.5889 - 36s/epoch - 24ms/step
Epoch 7/50
1542/1542 - 37s - loss: 2.7039 - accuracy10: 0.5594 - val_loss: 3.1003 - val_accuracy10: 0.5876 - 37s/epoch - 24ms/step
Epoch 8/50
1542/1542 - 36s - loss: 2.6759 - accuracy10: 0.5677 - val_loss: 3.1116 - val_accuracy10: 0.5859 - 36s/epoch - 23ms/step
Epoch 9/50
1542/1542 - 36s - loss: 2.6538 - accuracy10: 0.5728 - val_loss: 3.1782 - val_accuracy10: 0.5999 - 36s/epoch - 24ms/step
Epoch 10/50
1542/1542 - 36s - loss: 2.6435 - accuracy10: 0.5738 - val_loss: 3.2295 - val_accuracy10: 0.5935 - 36s/epoch - 23ms/step
Epoch 11/50
1542/1542 - 36s - loss: 2.6283 - accuracy10: 0.5783 - val_loss: 3.2354 - val_accuracy10: 0.5883 - 36s/epoch - 24ms/step
Epoch 12/50
1542/1542 - 36s - loss: 2.6128 - accuracy10: 0.5823 - val_loss: 3.2808 - val_accuracy10: 0.5763 - 36s/epoch - 23ms/step
Epoch 13/50
1542/1542 - 35s - loss: 2.6017 - accuracy10: 0.5832 - val_loss: 3.2744 - val_accuracy10: 0.5710 - 35s/epoch - 23ms/step
Epoch 14/50
1542/1542 - 35s - loss: 2.5922 - accuracy10: 0.5849 - val_loss: 3.3006 - val_accuracy10: 0.5798 - 35s/epoch - 23ms/step
Epoch 15/50
1542/1542 - 36s - loss: 2.5842 - accuracy10: 0.5876 - val_loss: 3.2856 - val_accuracy10: 0.5639 - 36s/epoch - 23ms/step
Epoch 16/50
1542/1542 - 36s - loss: 2.5755 - accuracy10: 0.5886 - val_loss: 3.2624 - val_accuracy10: 0.5574 - 36s/epoch - 23ms/step
Epoch 17/50
1542/1542 - 37s - loss: 2.5667 - accuracy10: 0.5911 - val_loss: 3.3129 - val_accuracy10: 0.5644 - 37s/epoch - 24ms/step
testing model: results/WBA/W2/deepLOB_L1/h10
Evaluating performance on  test set...
4353/4353 - 60s - 60s/epoch - 14ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.8534759
{'0': {'precision': 0.341430410516055, 'recall': 0.4434028779284043, 'f1-score': 0.3857920627580742, 'support': 187218}, '1': {'precision': 0.7424238346240638, 'recall': 0.7080394427009523, 'f1-score': 0.7248240839086565, 'support': 740213}, '2': {'precision': 0.3885815620006779, 'recall': 0.3435942993840209, 'f1-score': 0.3647058489381705, 'support': 186857}, 'accuracy': 0.6024618411039157, 'macro avg': {'precision': 0.4908119357135989, 'recall': 0.4983455400044592, 'f1-score': 0.491773998534967, 'support': 1114288}, 'weighted avg': {'precision': 0.6157141398142469, 'recall': 0.6024618411039157, 'f1-score': 0.6074724567102573, 'support': 1114288}}
[[ 83013  88481  15724]
 [130816 524100  85297]
 [ 29304  93350  64203]]
Evaluating performance on  train set...
1542/1542 - 22s - 22s/epoch - 14ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.8859889
{'0': {'precision': 0.3514397753903984, 'recall': 0.40470273881095525, 'f1-score': 0.37619532550110535, 'support': 74850}, '1': {'precision': 0.68969562910542, 'recall': 0.7458442093694189, 'f1-score': 0.7166718434539524, 'support': 247486}, '2': {'precision': 0.4197618755370075, 'recall': 0.23673972337214616, 'f1-score': 0.3027389741683044, 'support': 72227}, 'accuracy': 0.5879339927970945, 'macro avg': {'precision': 0.486965760010942, 'recall': 0.46242889051750674, 'f1-score': 0.4652020477077874, 'support': 394563}, 'weighted avg': {'precision': 0.5761143863899219, 'recall': 0.5879339927970945, 'f1-score': 0.5763094761801201, 'support': 394563}}
[[ 30292  39718   4840]
 [ 44104 184586  18796]
 [ 11798  43330  17099]]
Evaluating performance on  val set...
482/482 - 7s - 7s/epoch - 15ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.86432874
{'0': {'precision': 0.33474108245078293, 'recall': 0.4652128764278297, 'f1-score': 0.389337061457369, 'support': 22149}, '1': {'precision': 0.7141001311817823, 'recall': 0.70791510422585, 'f1-score': 0.7109941668780116, 'support': 79203}, '2': {'precision': 0.42880593819142104, 'recall': 0.2736132616813918, 'f1-score': 0.3340654452445161, 'support': 21958}, 'accuracy': 0.5869840240045414, 'macro avg': {'precision': 0.4925490506079955, 'recall': 0.48224708077835715, 'f1-score': 0.47813222452663223, 'support': 123310}, 'weighted avg': {'precision': 0.5951567084259209, 'recall': 0.5869840240045414, 'f1-score': 0.5860976937810195, 'support': 123310}}
[[10304 10291  1554]
 [16685 56069  6449]
 [ 3793 12157  6008]]
training model: results/WBA/W2/deepLOB_L1/h20
Epoch 1/50
1542/1542 - 39s - loss: 3.0573 - accuracy20: 0.4553 - val_loss: 3.2616 - val_accuracy20: 0.4992 - 39s/epoch - 25ms/step
Epoch 2/50
1542/1542 - 37s - loss: 3.0063 - accuracy20: 0.4641 - val_loss: 3.3618 - val_accuracy20: 0.4543 - 37s/epoch - 24ms/step
Epoch 3/50
1542/1542 - 37s - loss: 2.9552 - accuracy20: 0.4904 - val_loss: 3.3354 - val_accuracy20: 0.4733 - 37s/epoch - 24ms/step
Epoch 4/50
1542/1542 - 37s - loss: 2.8838 - accuracy20: 0.5194 - val_loss: 3.5495 - val_accuracy20: 0.4612 - 37s/epoch - 24ms/step
Epoch 5/50
1542/1542 - 36s - loss: 2.8319 - accuracy20: 0.5371 - val_loss: 3.5309 - val_accuracy20: 0.4661 - 36s/epoch - 24ms/step
Epoch 6/50
1542/1542 - 37s - loss: 2.7830 - accuracy20: 0.5509 - val_loss: 3.4812 - val_accuracy20: 0.4938 - 37s/epoch - 24ms/step
Epoch 7/50
1542/1542 - 36s - loss: 2.7610 - accuracy20: 0.5562 - val_loss: 3.3725 - val_accuracy20: 0.5191 - 36s/epoch - 24ms/step
Epoch 8/50
1542/1542 - 37s - loss: 2.7407 - accuracy20: 0.5611 - val_loss: 3.5065 - val_accuracy20: 0.4920 - 37s/epoch - 24ms/step
Epoch 9/50
1542/1542 - 37s - loss: 2.7255 - accuracy20: 0.5641 - val_loss: 3.3982 - val_accuracy20: 0.5324 - 37s/epoch - 24ms/step
Epoch 10/50
1542/1542 - 36s - loss: 2.7105 - accuracy20: 0.5682 - val_loss: 3.3896 - val_accuracy20: 0.5150 - 36s/epoch - 23ms/step
Epoch 11/50
1542/1542 - 36s - loss: 2.7006 - accuracy20: 0.5706 - val_loss: 3.3618 - val_accuracy20: 0.5409 - 36s/epoch - 24ms/step
testing model: results/WBA/W2/deepLOB_L1/h20
Evaluating performance on  test set...
4353/4353 - 59s - 59s/epoch - 14ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.9609994
{'0': {'precision': 0.38996272161559237, 'recall': 0.22103494316173014, 'f1-score': 0.2821463746147373, 'support': 240419}, '1': {'precision': 0.5785980162493022, 'recall': 0.7524202598094224, 'f1-score': 0.6541591164332123, 'support': 630924}, '2': {'precision': 0.378838463979689, 'recall': 0.2456770050834551, 'f1-score': 0.298061149327707, 'support': 242945}, 'accuracy': 0.5272846876211535, 'macro avg': {'precision': 0.44913306728152785, 'recall': 0.4063774026848692, 'f1-score': 0.4114555467918855, 'support': 1114288}, 'weighted avg': {'precision': 0.4943450283981514, 'recall': 0.5272846876211535, 'f1-score': 0.49625456034564525, 'support': 1114288}}
[[ 53141 173133  14145]
 [ 72485 474720  83719]
 [ 10646 172613  59686]]
Evaluating performance on  train set...
1542/1542 - 22s - 22s/epoch - 14ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.99256873
{'0': {'precision': 0.37427057842794526, 'recall': 0.2925885827806216, 'f1-score': 0.3284270637303774, 'support': 95137}, '1': {'precision': 0.545125046605673, 'recall': 0.7350694679441936, 'f1-score': 0.6260060848837161, 'support': 206858}, '2': {'precision': 0.396262090029816, 'recall': 0.17659450350012965, 'f1-score': 0.2443114309413321, 'support': 92568}, 'accuracy': 0.4973553019416418, 'macro avg': {'precision': 0.43855257168781137, 'recall': 0.40141751807498166, 'f1-score': 0.3995815265184752, 'support': 394563}, 'weighted avg': {'precision': 0.46900405273818313, 'recall': 0.4973553019416418, 'f1-score': 0.46470488314507413, 'support': 394563}}
[[ 27836  61913   5388]
 [ 35285 152055  19518]
 [ 11253  64968  16347]]
Evaluating performance on  val set...
482/482 - 7s - 7s/epoch - 14ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.98361665
{'0': {'precision': 0.3761855934375801, 'recall': 0.20408163265306123, 'f1-score': 0.2646110848152906, 'support': 28763}, '1': {'precision': 0.5442244942353709, 'recall': 0.7561049323017408, 'f1-score': 0.6329024260669381, 'support': 66176}, '2': {'precision': 0.3700367880248636, 'recall': 0.20563251207218639, 'f1-score': 0.2643587013163559, 'support': 28371}, 'accuracy': 0.5006893196010056, 'macro avg': {'precision': 0.4301489585659382, 'recall': 0.38860635900899615, 'f1-score': 0.38729073739952824, 'support': 123310}, 'weighted avg': {'precision': 0.46495126159774897, 'recall': 0.5006893196010056, 'f1-score': 0.4622016081014859, 'support': 123310}}
[[ 5870 20940  1953]
 [ 8161 50036  7979]
 [ 1573 20964  5834]]
training model: results/WBA/W2/deepLOB_L1/h30
Epoch 1/50
1542/1542 - 38s - loss: 3.0827 - accuracy30: 0.4592 - val_loss: 3.4198 - val_accuracy30: 0.4079 - 38s/epoch - 25ms/step
Epoch 2/50
1542/1542 - 36s - loss: 3.0293 - accuracy30: 0.4757 - val_loss: 3.4415 - val_accuracy30: 0.4520 - 36s/epoch - 23ms/step
Epoch 3/50
1542/1542 - 35s - loss: 2.9802 - accuracy30: 0.4955 - val_loss: 3.6772 - val_accuracy30: 0.4816 - 35s/epoch - 23ms/step
Epoch 4/50
1542/1542 - 40s - loss: 2.9323 - accuracy30: 0.5103 - val_loss: 3.6651 - val_accuracy30: 0.4855 - 40s/epoch - 26ms/step
Epoch 5/50
1542/1542 - 35s - loss: 2.8967 - accuracy30: 0.5214 - val_loss: 3.5266 - val_accuracy30: 0.4732 - 35s/epoch - 23ms/step
Epoch 6/50
1542/1542 - 36s - loss: 2.8688 - accuracy30: 0.5297 - val_loss: 3.5099 - val_accuracy30: 0.4780 - 36s/epoch - 23ms/step
Epoch 7/50
1542/1542 - 36s - loss: 2.8490 - accuracy30: 0.5358 - val_loss: 3.5276 - val_accuracy30: 0.4793 - 36s/epoch - 23ms/step
Epoch 8/50
1542/1542 - 36s - loss: 2.8343 - accuracy30: 0.5397 - val_loss: 3.4499 - val_accuracy30: 0.5031 - 36s/epoch - 24ms/step
Epoch 9/50
1542/1542 - 35s - loss: 2.8217 - accuracy30: 0.5433 - val_loss: 3.4593 - val_accuracy30: 0.5092 - 35s/epoch - 23ms/step
Epoch 10/50
1542/1542 - 36s - loss: 2.8105 - accuracy30: 0.5460 - val_loss: 3.4343 - val_accuracy30: 0.5118 - 36s/epoch - 23ms/step
Epoch 11/50
1542/1542 - 35s - loss: 2.7982 - accuracy30: 0.5490 - val_loss: 3.4387 - val_accuracy30: 0.5154 - 35s/epoch - 23ms/step
testing model: results/WBA/W2/deepLOB_L1/h30
Evaluating performance on  test set...
4353/4353 - 58s - 58s/epoch - 13ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.0152987
{'0': {'precision': 0.38381864266671045, 'recall': 0.5048696798073011, 'f1-score': 0.43609978960397966, 'support': 277739}, '1': {'precision': 0.5346657588624889, 'recall': 0.6331303336896625, 'f1-score': 0.5797469480844781, 'support': 555666}, '2': {'precision': 0.42373235410528165, 'recall': 0.13721371531918983, 'f1-score': 0.20729939570620617, 'support': 280883}, 'accuracy': 0.4761533822494723, 'macro avg': {'precision': 0.4474055852114936, 'recall': 0.42507124293871784, 'f1-score': 0.40771537779822126, 'support': 1114288}, 'weighted avg': {'precision': 0.46910332371689106, 'recall': 0.4761533822494723, 'f1-score': 0.4500582105194309, 'support': 1114288}}
[[140222 129367   8150]
 [159592 351809  44265]
 [ 65520 176822  38541]]
Evaluating performance on  train set...
1542/1542 - 21s - 21s/epoch - 14ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.082624
{'0': {'precision': 0.354516896465609, 'recall': 0.49670362049279954, 'f1-score': 0.4137349194296802, 'support': 108604}, '1': {'precision': 0.49396306165579346, 'recall': 0.5985247863723662, 'f1-score': 0.5412401364225575, 'support': 179635}, '2': {'precision': 0.438826239844792, 'recall': 0.10211241112072533, 'f1-score': 0.16567352077213596, 'support': 106324}, 'accuracy': 0.43672873533504153, 'macro avg': {'precision': 0.42910206598873146, 'recall': 0.39911360599529705, 'f1-score': 0.37354952554145787, 'support': 394563}, 'weighted avg': {'precision': 0.4407224416114717, 'recall': 0.43672873533504153, 'f1-score': 0.4049391618539592, 'support': 394563}}
[[ 53944  51447   3213]
 [ 61448 107516  10671]
 [ 36770  58697  10857]]
Evaluating performance on  val set...
482/482 - 7s - 7s/epoch - 14ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.0881268
{'0': {'precision': 0.3241634523133554, 'recall': 0.4999698012925047, 'f1-score': 0.39331488234525525, 'support': 33114}, '1': {'precision': 0.4662114792574755, 'recall': 0.5325278972198527, 'f1-score': 0.4971679790666114, 'support': 57443}, '2': {'precision': 0.487090442397705, 'recall': 0.09849479436998138, 'f1-score': 0.16385615603413248, 'support': 32753}, 'accuracy': 0.40849890519828075, 'macro avg': {'precision': 0.4258217913228453, 'recall': 0.37699749762744633, 'f1-score': 0.3514463391486664, 'support': 123310}, 'weighted avg': {'precision': 0.43361128718468617, 'recall': 0.40849890519828075, 'f1-score': 0.3807463296901313, 'support': 123310}}
[[16556 15726   832]
 [24288 30590  2565]
 [10229 19298  3226]]
training model: results/WBA/W2/deepLOB_L1/h50
Epoch 1/50
1542/1542 - 38s - loss: 3.1525 - accuracy50: 0.4410 - val_loss: 3.6577 - val_accuracy50: 0.3693 - 38s/epoch - 25ms/step
Epoch 2/50
1542/1542 - 36s - loss: 3.1312 - accuracy50: 0.4494 - val_loss: 3.5341 - val_accuracy50: 0.3717 - 36s/epoch - 23ms/step
Epoch 3/50
1542/1542 - 36s - loss: 3.1135 - accuracy50: 0.4556 - val_loss: 3.5449 - val_accuracy50: 0.3716 - 36s/epoch - 23ms/step
Epoch 4/50
1542/1542 - 36s - loss: 3.1066 - accuracy50: 0.4593 - val_loss: 3.5399 - val_accuracy50: 0.3726 - 36s/epoch - 23ms/step
Epoch 5/50
1542/1542 - 35s - loss: 3.0916 - accuracy50: 0.4654 - val_loss: 3.4319 - val_accuracy50: 0.3789 - 35s/epoch - 23ms/step
Epoch 6/50
1542/1542 - 35s - loss: 3.0710 - accuracy50: 0.4740 - val_loss: 3.5151 - val_accuracy50: 0.3787 - 35s/epoch - 23ms/step
Epoch 7/50
1542/1542 - 36s - loss: 3.0471 - accuracy50: 0.4821 - val_loss: 3.5321 - val_accuracy50: 0.3828 - 36s/epoch - 23ms/step
Epoch 8/50
1542/1542 - 36s - loss: 3.0307 - accuracy50: 0.4864 - val_loss: 3.6378 - val_accuracy50: 0.3848 - 36s/epoch - 23ms/step
Epoch 9/50
1542/1542 - 35s - loss: 3.0136 - accuracy50: 0.4920 - val_loss: 3.5249 - val_accuracy50: 0.4075 - 35s/epoch - 23ms/step
Epoch 10/50
1542/1542 - 36s - loss: 2.9985 - accuracy50: 0.4964 - val_loss: 3.6449 - val_accuracy50: 0.3939 - 36s/epoch - 23ms/step
Epoch 11/50
1542/1542 - 36s - loss: 2.9842 - accuracy50: 0.5003 - val_loss: 3.5202 - val_accuracy50: 0.4056 - 36s/epoch - 23ms/step
Epoch 12/50
1542/1542 - 35s - loss: 2.9715 - accuracy50: 0.5035 - val_loss: 3.5917 - val_accuracy50: 0.3945 - 35s/epoch - 23ms/step
Epoch 13/50
1542/1542 - 35s - loss: 2.9620 - accuracy50: 0.5057 - val_loss: 3.5060 - val_accuracy50: 0.4077 - 35s/epoch - 23ms/step
Epoch 14/50
1542/1542 - 36s - loss: 2.9511 - accuracy50: 0.5079 - val_loss: 3.4275 - val_accuracy50: 0.4226 - 36s/epoch - 24ms/step
Epoch 15/50
1542/1542 - 36s - loss: 2.9409 - accuracy50: 0.5121 - val_loss: 3.4441 - val_accuracy50: 0.4200 - 36s/epoch - 23ms/step
Epoch 16/50
1542/1542 - 36s - loss: 2.9320 - accuracy50: 0.5139 - val_loss: 3.4728 - val_accuracy50: 0.4230 - 36s/epoch - 23ms/step
Epoch 17/50
1542/1542 - 36s - loss: 2.9250 - accuracy50: 0.5156 - val_loss: 3.4160 - val_accuracy50: 0.4218 - 36s/epoch - 23ms/step
Epoch 18/50
1542/1542 - 36s - loss: 2.9167 - accuracy50: 0.5178 - val_loss: 3.4157 - val_accuracy50: 0.4255 - 36s/epoch - 23ms/step
Epoch 19/50
1542/1542 - 35s - loss: 2.9103 - accuracy50: 0.5189 - val_loss: 3.4577 - val_accuracy50: 0.4217 - 35s/epoch - 23ms/step
Epoch 20/50
1542/1542 - 36s - loss: 2.9034 - accuracy50: 0.5205 - val_loss: 3.4585 - val_accuracy50: 0.4160 - 36s/epoch - 23ms/step
Epoch 21/50
1542/1542 - 36s - loss: 2.8988 - accuracy50: 0.5212 - val_loss: 3.4098 - val_accuracy50: 0.4279 - 36s/epoch - 23ms/step
Epoch 22/50
1542/1542 - 36s - loss: 2.8927 - accuracy50: 0.5222 - val_loss: 3.4315 - val_accuracy50: 0.4242 - 36s/epoch - 23ms/step
Epoch 23/50
1542/1542 - 36s - loss: 2.8880 - accuracy50: 0.5240 - val_loss: 3.4412 - val_accuracy50: 0.4267 - 36s/epoch - 23ms/step
Epoch 24/50
1542/1542 - 35s - loss: 2.8835 - accuracy50: 0.5247 - val_loss: 3.4640 - val_accuracy50: 0.4186 - 35s/epoch - 23ms/step
Epoch 25/50
1542/1542 - 35s - loss: 2.8800 - accuracy50: 0.5261 - val_loss: 3.4283 - val_accuracy50: 0.4204 - 35s/epoch - 23ms/step
Epoch 26/50
1542/1542 - 35s - loss: 2.8757 - accuracy50: 0.5268 - val_loss: 3.4749 - val_accuracy50: 0.4149 - 35s/epoch - 23ms/step
Epoch 27/50
1542/1542 - 36s - loss: 2.8712 - accuracy50: 0.5277 - val_loss: 3.4172 - val_accuracy50: 0.4285 - 36s/epoch - 23ms/step
Epoch 28/50
1542/1542 - 35s - loss: 2.8674 - accuracy50: 0.5284 - val_loss: 3.4281 - val_accuracy50: 0.4339 - 35s/epoch - 23ms/step
Epoch 29/50
1542/1542 - 35s - loss: 2.8636 - accuracy50: 0.5299 - val_loss: 3.3773 - val_accuracy50: 0.4370 - 35s/epoch - 23ms/step
Epoch 30/50
1542/1542 - 35s - loss: 2.8609 - accuracy50: 0.5293 - val_loss: 3.3902 - val_accuracy50: 0.4324 - 35s/epoch - 22ms/step
Epoch 31/50
1542/1542 - 35s - loss: 2.8579 - accuracy50: 0.5308 - val_loss: 3.3486 - val_accuracy50: 0.4404 - 35s/epoch - 22ms/step
Epoch 32/50
1542/1542 - 34s - loss: 2.8537 - accuracy50: 0.5313 - val_loss: 3.3630 - val_accuracy50: 0.4361 - 34s/epoch - 22ms/step
Epoch 33/50
1542/1542 - 35s - loss: 2.8492 - accuracy50: 0.5319 - val_loss: 3.4188 - val_accuracy50: 0.4294 - 35s/epoch - 23ms/step
Epoch 34/50
1542/1542 - 35s - loss: 2.8480 - accuracy50: 0.5319 - val_loss: 3.4092 - val_accuracy50: 0.4381 - 35s/epoch - 23ms/step
Epoch 35/50
1542/1542 - 35s - loss: 2.8449 - accuracy50: 0.5329 - val_loss: 3.4148 - val_accuracy50: 0.4304 - 35s/epoch - 22ms/step
Epoch 36/50
1542/1542 - 35s - loss: 2.8413 - accuracy50: 0.5341 - val_loss: 3.3661 - val_accuracy50: 0.4362 - 35s/epoch - 22ms/step
Epoch 37/50
1542/1542 - 35s - loss: 2.8385 - accuracy50: 0.5349 - val_loss: 3.4045 - val_accuracy50: 0.4307 - 35s/epoch - 23ms/step
Epoch 38/50
1542/1542 - 35s - loss: 2.8362 - accuracy50: 0.5351 - val_loss: 3.4350 - val_accuracy50: 0.4289 - 35s/epoch - 23ms/step
Epoch 39/50
1542/1542 - 35s - loss: 2.8357 - accuracy50: 0.5353 - val_loss: 3.4450 - val_accuracy50: 0.4284 - 35s/epoch - 22ms/step
Epoch 40/50
1542/1542 - 35s - loss: 2.8314 - accuracy50: 0.5371 - val_loss: 3.4296 - val_accuracy50: 0.4306 - 35s/epoch - 23ms/step
Epoch 41/50
1542/1542 - 35s - loss: 2.8285 - accuracy50: 0.5374 - val_loss: 3.4814 - val_accuracy50: 0.4247 - 35s/epoch - 22ms/step
testing model: results/WBA/W2/deepLOB_L1/h50
Evaluating performance on  test set...
4353/4353 - 62s - 62s/epoch - 14ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0650537
{'0': {'precision': 0.43892363246241806, 'recall': 0.40211977921213976, 'f1-score': 0.41971644204514535, 'support': 333714}, '1': {'precision': 0.47404126350734255, 'recall': 0.5718221920293903, 'f1-score': 0.5183608108231295, 'support': 447494}, '2': {'precision': 0.42727817321967426, 'recall': 0.34476402065569833, 'f1-score': 0.38161163238551304, 'support': 333080}, 'accuracy': 0.45312701922662724, 'macro avg': {'precision': 0.44674768972981166, 'recall': 0.4395686639657428, 'f1-score': 0.43989629508459593, 'support': 1114288}, 'weighted avg': {'precision': 0.4495457154627235, 'recall': 0.45312701922662724, 'f1-score': 0.44794147288143266, 'support': 1114288}}
[[134193 136700  62821]
 [100505 255887  91102]
 [ 71034 147212 114834]]
Evaluating performance on  train set...
1542/1542 - 20s - 20s/epoch - 13ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.1302123
{'0': {'precision': 0.44848958333333333, 'recall': 0.27091608397108674, 'f1-score': 0.3377872795296633, 'support': 127139}, '1': {'precision': 0.4073861097620204, 'recall': 0.7347189035029326, 'f1-score': 0.5241449295647914, 'support': 142709}, '2': {'precision': 0.480857123931907, 'recall': 0.23283486348875437, 'f1-score': 0.3137496420911601, 'support': 124715}, 'accuracy': 0.42663148850753874, 'macro avg': {'precision': 0.4455776056757536, 'recall': 0.41282328365425797, 'f1-score': 0.39189395039520497, 'support': 394563}, 'weighted avg': {'precision': 0.4438537766709312, 'recall': 0.42663148850753874, 'f1-score': 0.39759283637538934, 'support': 394563}}
[[ 34444  76630  16065]
 [ 22573 104851  15285]
 [ 19783  75894  29038]]
Evaluating performance on  val set...
482/482 - 7s - 7s/epoch - 15ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.104085
{'0': {'precision': 0.44258816266687245, 'recall': 0.29527903624382207, 'f1-score': 0.35422907080875765, 'support': 38848}, '1': {'precision': 0.4370179948586118, 'recall': 0.6887263489838823, 'f1-score': 0.534732081374491, 'support': 45664}, '2': {'precision': 0.447634404373304, 'recall': 0.2933656374039899, 'f1-score': 0.354441416893733, 'support': 38798}, 'accuracy': 0.44037790933419835, 'macro avg': {'precision': 0.44241352063292944, 'recall': 0.42579034087723144, 'f1-score': 0.41446752302566053, 'support': 123310}, 'weighted avg': {'precision': 0.44211316423146346, 'recall': 0.44037790933419835, 'f1-score': 0.4211395247693328, 'support': 123310}}
[[11471 19865  7512]
 [ 7681 31450  6533]
 [ 6766 20650 11382]]
training model: results/WBA/W2/deepLOB_L1/h100
Epoch 1/50
1542/1542 - 38s - loss: 3.2407 - accuracy100: 0.4038 - val_loss: 3.4311 - val_accuracy100: 0.3324 - 38s/epoch - 25ms/step
Epoch 2/50
1542/1542 - 35s - loss: 3.2263 - accuracy100: 0.4067 - val_loss: 3.3783 - val_accuracy100: 0.3325 - 35s/epoch - 23ms/step
Epoch 3/50
1542/1542 - 35s - loss: 3.2109 - accuracy100: 0.4157 - val_loss: 3.4101 - val_accuracy100: 0.3419 - 35s/epoch - 23ms/step
Epoch 4/50
1542/1542 - 35s - loss: 3.1979 - accuracy100: 0.4227 - val_loss: 3.4973 - val_accuracy100: 0.3446 - 35s/epoch - 23ms/step
Epoch 5/50
1542/1542 - 35s - loss: 3.1868 - accuracy100: 0.4281 - val_loss: 3.4422 - val_accuracy100: 0.3535 - 35s/epoch - 22ms/step
Epoch 6/50
1542/1542 - 35s - loss: 3.1760 - accuracy100: 0.4331 - val_loss: 3.4126 - val_accuracy100: 0.3501 - 35s/epoch - 23ms/step
Epoch 7/50
1542/1542 - 35s - loss: 3.1678 - accuracy100: 0.4364 - val_loss: 3.4394 - val_accuracy100: 0.3590 - 35s/epoch - 23ms/step
Epoch 8/50
1542/1542 - 36s - loss: 3.1590 - accuracy100: 0.4388 - val_loss: 3.4529 - val_accuracy100: 0.3461 - 36s/epoch - 23ms/step
Epoch 9/50
1542/1542 - 36s - loss: 3.1514 - accuracy100: 0.4422 - val_loss: 3.4856 - val_accuracy100: 0.3425 - 36s/epoch - 23ms/step
Epoch 10/50
1542/1542 - 36s - loss: 3.1458 - accuracy100: 0.4441 - val_loss: 3.5004 - val_accuracy100: 0.3426 - 36s/epoch - 23ms/step
Epoch 11/50
1542/1542 - 35s - loss: 3.1398 - accuracy100: 0.4473 - val_loss: 3.5516 - val_accuracy100: 0.3386 - 35s/epoch - 23ms/step
Epoch 12/50
1542/1542 - 36s - loss: 3.1357 - accuracy100: 0.4488 - val_loss: 3.6078 - val_accuracy100: 0.3398 - 36s/epoch - 23ms/step
testing model: results/WBA/W2/deepLOB_L1/h100
Evaluating performance on  test set...
4353/4353 - 60s - 60s/epoch - 14ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.1031309
{'0': {'precision': 0.41681390435951604, 'recall': 0.11566995144777305, 'f1-score': 0.18108659466089286, 'support': 375266}, '1': {'precision': 0.35053061979607725, 'recall': 0.830460452338526, 'f1-score': 0.49297886147131836, 'support': 383297}, '2': {'precision': 0.4080776805573247, 'recall': 0.11707920444163328, 'f1-score': 0.18195480838124528, 'support': 355725}, 'accuracy': 0.36199618052065535, 'macro avg': {'precision': 0.39180740157097266, 'recall': 0.3544032027426441, 'f1-score': 0.28534008817115214, 'support': 1114288}, 'weighted avg': {'precision': 0.3912245797546141, 'recall': 0.36199618052065535, 'f1-score': 0.28864964435478535, 'support': 1114288}}
[[ 43407 308541  23318]
 [ 27891 318313  37093]
 [ 32842 281235  41648]]
Evaluating performance on  train set...
1542/1542 - 22s - 22s/epoch - 14ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.1296256
{'0': {'precision': 0.3925034807502777, 'recall': 0.1858931614432837, 'f1-score': 0.2522964609111432, 'support': 134970}, '1': {'precision': 0.3305602405452696, 'recall': 0.8158842513915091, 'f1-score': 0.4704962103162115, 'support': 128278}, '2': {'precision': 0.4285612434051048, 'recall': 0.04577542550356014, 'f1-score': 0.0827158200370164, 'support': 131315}, 'accuracy': 0.34407939923408937, 'macro avg': {'precision': 0.38387498823355076, 'recall': 0.3491842794461176, 'f1-score': 0.268502830421457, 'support': 394563}, 'weighted avg': {'precision': 0.3843652877012604, 'recall': 0.34407939923408937, 'f1-score': 0.2667979362086176, 'support': 394563}}
[[ 25090 106080   3800]
 [ 19403 104660   4215]
 [ 19430 105874   6011]]
Evaluating performance on  val set...
482/482 - 7s - 7s/epoch - 14ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.127752
{'0': {'precision': 0.35485406846640954, 'recall': 0.18040326289545663, 'f1-score': 0.23920020540471149, 'support': 41313}, '1': {'precision': 0.3240688298715876, 'recall': 0.7717775161859918, 'f1-score': 0.45646734597671973, 'support': 40776}, '2': {'precision': 0.4107348980377068, 'recall': 0.05179398850100677, 'f1-score': 0.09198819448932549, 'support': 41221}, 'accuracy': 0.33296569621279704, 'macro avg': {'precision': 0.363219265458568, 'recall': 0.3346582558608184, 'f1-score': 0.26255191529025224, 'support': 123310}, 'weighted avg': {'precision': 0.3633543100268344, 'recall': 0.33296569621279704, 'f1-score': 0.261834692648415, 'support': 123310}}
[[ 7453 32376  1484]
 [ 7727 31470  1579]
 [ 5823 33263  2135]]
training model: results/WBA/W2/deepLOB_L1/h200
Epoch 1/50
1542/1542 - 39s - loss: 3.2766 - accuracy200: 0.3810 - val_loss: 3.3269 - val_accuracy200: 0.3455 - 39s/epoch - 25ms/step
Epoch 2/50
1542/1542 - 37s - loss: 3.2554 - accuracy200: 0.3860 - val_loss: 3.3454 - val_accuracy200: 0.3371 - 37s/epoch - 24ms/step
Epoch 3/50
1542/1542 - 37s - loss: 3.2468 - accuracy200: 0.3921 - val_loss: 3.3704 - val_accuracy200: 0.3366 - 37s/epoch - 24ms/step
Epoch 4/50
1542/1542 - 36s - loss: 3.2399 - accuracy200: 0.3947 - val_loss: 3.3625 - val_accuracy200: 0.3374 - 36s/epoch - 23ms/step
Epoch 5/50
1542/1542 - 34s - loss: 3.2324 - accuracy200: 0.4004 - val_loss: 3.3770 - val_accuracy200: 0.3346 - 34s/epoch - 22ms/step
Epoch 6/50
1542/1542 - 34s - loss: 3.2263 - accuracy200: 0.4025 - val_loss: 3.3701 - val_accuracy200: 0.3341 - 34s/epoch - 22ms/step
Epoch 7/50
1542/1542 - 36s - loss: 3.2248 - accuracy200: 0.4044 - val_loss: 3.3828 - val_accuracy200: 0.3368 - 36s/epoch - 23ms/step
Epoch 8/50
1542/1542 - 36s - loss: 3.2188 - accuracy200: 0.4069 - val_loss: 3.3726 - val_accuracy200: 0.3378 - 36s/epoch - 23ms/step
Epoch 9/50
1542/1542 - 35s - loss: 3.2146 - accuracy200: 0.4087 - val_loss: 3.3794 - val_accuracy200: 0.3390 - 35s/epoch - 23ms/step
Epoch 10/50
1542/1542 - 36s - loss: 3.2104 - accuracy200: 0.4119 - val_loss: 3.4019 - val_accuracy200: 0.3337 - 36s/epoch - 23ms/step
Epoch 11/50
1542/1542 - 33s - loss: 3.2068 - accuracy200: 0.4132 - val_loss: 3.4213 - val_accuracy200: 0.3373 - 33s/epoch - 22ms/step
testing model: results/WBA/W2/deepLOB_L1/h200
Evaluating performance on  test set...
4353/4353 - 56s - 56s/epoch - 13ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0985501
{'0': {'precision': 0.378652862675027, 'recall': 0.3027371395408076, 'f1-score': 0.33646600082889216, 'support': 380799}, '1': {'precision': 0.3560777370424898, 'recall': 0.5806050082634254, 'f1-score': 0.44143124978875603, 'support': 382408}, '2': {'precision': 0.35146030263503975, 'recall': 0.1864982724784309, 'f1-score': 0.24368693917503137, 'support': 351081}, 'accuracy': 0.36147387389974583, 'macro avg': {'precision': 0.3620636341175189, 'recall': 0.3566134734275546, 'f1-score': 0.3405280632642265, 'support': 1114288}, 'weighted avg': {'precision': 0.36233778092391233, 'recall': 0.36147387389974583, 'f1-score': 0.3432565120609476, 'support': 1114288}}
[[115282 205448  60069]
 [ 99628 222028  60752]
 [ 89543 196062  65476]]
Evaluating performance on  train set...
1542/1542 - 22s - 22s/epoch - 14ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1039767
{'0': {'precision': 0.3607016273353341, 'recall': 0.387643308288682, 'f1-score': 0.37368749481490565, 'support': 133628}, '1': {'precision': 0.33761853004010345, 'recall': 0.4787596710880971, 'f1-score': 0.3959883695372306, 'support': 131707}, '2': {'precision': 0.36351597675541775, 'recall': 0.18055684526573187, 'f1-score': 0.24127394462683868, 'support': 129228}, 'accuracy': 0.35023304263197513, 'macro avg': {'precision': 0.3539453780436184, 'recall': 0.3489866082141703, 'f1-score': 0.33698326965965825, 'support': 394563}, 'weighted avg': {'precision': 0.3539181409247878, 'recall': 0.35023304263197513, 'f1-score': 0.33776330284391426, 'support': 394563}}
[[51800 61559 20269]
 [48066 63056 20585]
 [43743 62152 23333]]
Evaluating performance on  val set...
482/482 - 7s - 7s/epoch - 14ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1082455
{'0': {'precision': 0.3449066022873744, 'recall': 0.40976155173671036, 'f1-score': 0.3745473127596703, 'support': 41141}, '1': {'precision': 0.3390998916718642, 'recall': 0.5030803321401612, 'f1-score': 0.4051258419695469, 'support': 41067}, '2': {'precision': 0.3647738209817132, 'recall': 0.11987251228650674, 'f1-score': 0.1804464465564284, 'support': 41102}, 'accuracy': 0.34421377017273536, 'macro avg': {'precision': 0.3495934383136506, 'recall': 0.3442381320544594, 'f1-score': 0.3200398670952152, 'support': 123310}, 'weighted avg': {'precision': 0.3495949344415189, 'recall': 0.34421377017273536, 'f1-score': 0.3200329559060197, 'support': 123310}}
[[16858 20037  4246]
 [16073 20660  4334]
 [15946 20229  4927]]
training model: results/WBA/W2/deepLOB_L1/h300
Epoch 1/50
1542/1542 - 37s - loss: 3.2621 - accuracy300: 0.3913 - val_loss: 3.3723 - val_accuracy300: 0.3248 - 37s/epoch - 24ms/step
Epoch 2/50
1542/1542 - 35s - loss: 3.2378 - accuracy300: 0.4009 - val_loss: 3.3638 - val_accuracy300: 0.3243 - 35s/epoch - 23ms/step
Epoch 3/50
1542/1542 - 34s - loss: 3.2365 - accuracy300: 0.4053 - val_loss: 3.4273 - val_accuracy300: 0.3100 - 34s/epoch - 22ms/step
Epoch 4/50
1542/1542 - 35s - loss: 3.2284 - accuracy300: 0.4096 - val_loss: 3.3970 - val_accuracy300: 0.3175 - 35s/epoch - 22ms/step
Epoch 5/50
1542/1542 - 35s - loss: 3.2217 - accuracy300: 0.4130 - val_loss: 3.4562 - val_accuracy300: 0.3191 - 35s/epoch - 23ms/step
Epoch 6/50
1542/1542 - 35s - loss: 3.2151 - accuracy300: 0.4159 - val_loss: 3.4619 - val_accuracy300: 0.3132 - 35s/epoch - 23ms/step
Epoch 7/50
1542/1542 - 35s - loss: 3.2096 - accuracy300: 0.4190 - val_loss: 3.4898 - val_accuracy300: 0.3117 - 35s/epoch - 23ms/step
Epoch 8/50
1542/1542 - 35s - loss: 3.2051 - accuracy300: 0.4201 - val_loss: 3.5484 - val_accuracy300: 0.3103 - 35s/epoch - 23ms/step
Epoch 9/50
1542/1542 - 34s - loss: 3.2025 - accuracy300: 0.4211 - val_loss: 3.5852 - val_accuracy300: 0.3116 - 34s/epoch - 22ms/step
Epoch 10/50
1542/1542 - 35s - loss: 3.1997 - accuracy300: 0.4226 - val_loss: 3.5519 - val_accuracy300: 0.3117 - 35s/epoch - 22ms/step
Epoch 11/50
1542/1542 - 36s - loss: 3.1972 - accuracy300: 0.4228 - val_loss: 3.5393 - val_accuracy300: 0.3189 - 36s/epoch - 23ms/step
Epoch 12/50
1542/1542 - 34s - loss: 3.1949 - accuracy300: 0.4242 - val_loss: 3.5659 - val_accuracy300: 0.3103 - 34s/epoch - 22ms/step
testing model: results/WBA/W2/deepLOB_L1/h300
Evaluating performance on  test set...
4353/4353 - 57s - 57s/epoch - 13ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1125624
{'0': {'precision': 0.37368338924865413, 'recall': 0.25904591919519715, 'f1-score': 0.3059796844055453, 'support': 406758}, '1': {'precision': 0.3009810060530161, 'recall': 0.20437039929425715, 'f1-score': 0.24344093134468234, 'support': 345735}, '2': {'precision': 0.33105739220657515, 'recall': 0.5467875454331873, 'f1-score': 0.4124146557565018, 'support': 361795}, 'accuracy': 0.3355075169076576, 'macro avg': {'precision': 0.3352405958360818, 'recall': 0.3367346213075472, 'f1-score': 0.32061175716890983, 'support': 1114288}, 'weighted avg': {'precision': 0.3372855898880015, 'recall': 0.3355075169076576, 'f1-score': 0.32113358058895736, 'support': 1114288}}
[[105369  86715 214674]
 [ 90021  70658 185056]
 [ 86584  77386 197825]]
Evaluating performance on  train set...
1542/1542 - 21s - 21s/epoch - 14ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.101905
{'0': {'precision': 0.3687317511715052, 'recall': 0.3431890883241514, 'f1-score': 0.35550220333587734, 'support': 135048}, '1': {'precision': 0.3952865899048132, 'recall': 0.38225496427559486, 'f1-score': 0.38866157182289257, 'support': 130583}, '2': {'precision': 0.3509874326750449, 'recall': 0.38817361089566593, 'f1-score': 0.36864512897570756, 'support': 128932}, 'accuracy': 0.37081784151073466, 'macro avg': {'precision': 0.3716685912504544, 'recall': 0.3712058878318041, 'f1-score': 0.3709363013781592, 'support': 394563}, 'weighted avg': {'precision': 0.37172189478336426, 'recall': 0.37081784151073466, 'f1-score': 0.3707712313586126, 'support': 394563}}
[[46347 38783 49918]
 [38041 49916 42626]
 [41305 37579 50048]]
Evaluating performance on  val set...
482/482 - 7s - 7s/epoch - 14ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1199417
{'0': {'precision': 0.34584348355663824, 'recall': 0.4202104289513239, 'f1-score': 0.37941726085458666, 'support': 43245}, '1': {'precision': 0.2852905018974825, 'recall': 0.2864003434121214, 'f1-score': 0.2858443453695894, 'support': 37273}, '2': {'precision': 0.3378013673983447, 'recall': 0.26325014021312393, 'f1-score': 0.2959022852639874, 'support': 42792}, 'accuracy': 0.32529397453572295, 'macro avg': {'precision': 0.3229784509508218, 'recall': 0.3232869708588564, 'f1-score': 0.32038796382938783, 'support': 123310}, 'weighted avg': {'precision': 0.3247492534047657, 'recall': 0.32529397453572295, 'f1-score': 0.32215089061417446, 'support': 123310}}
[[18172 13303 11770]
 [16285 10675 10313]
 [18087 13440 11265]]
training model: results/WBA/W2/deepLOB_L1/h500
Epoch 1/50
1542/1542 - 37s - loss: 3.2411 - accuracy500: 0.4092 - val_loss: 3.4237 - val_accuracy500: 0.2975 - 37s/epoch - 24ms/step
Epoch 2/50
1542/1542 - 35s - loss: 3.2340 - accuracy500: 0.4043 - val_loss: 3.4031 - val_accuracy500: 0.2938 - 35s/epoch - 23ms/step
Epoch 3/50
1542/1542 - 35s - loss: 3.2117 - accuracy500: 0.4257 - val_loss: 3.4420 - val_accuracy500: 0.2962 - 35s/epoch - 23ms/step
Epoch 4/50
1542/1542 - 35s - loss: 3.1971 - accuracy500: 0.4326 - val_loss: 3.3909 - val_accuracy500: 0.2978 - 35s/epoch - 22ms/step
Epoch 5/50
1542/1542 - 35s - loss: 3.1964 - accuracy500: 0.4336 - val_loss: 3.4046 - val_accuracy500: 0.2956 - 35s/epoch - 23ms/step
Epoch 6/50
1542/1542 - 35s - loss: 3.1864 - accuracy500: 0.4374 - val_loss: 3.4217 - val_accuracy500: 0.2994 - 35s/epoch - 23ms/step
Epoch 7/50
1542/1542 - 35s - loss: 3.1794 - accuracy500: 0.4393 - val_loss: 3.4718 - val_accuracy500: 0.2980 - 35s/epoch - 23ms/step
Epoch 8/50
1542/1542 - 35s - loss: 3.1752 - accuracy500: 0.4439 - val_loss: 3.5129 - val_accuracy500: 0.2968 - 35s/epoch - 22ms/step
Epoch 9/50
1542/1542 - 36s - loss: 3.1706 - accuracy500: 0.4446 - val_loss: 3.4381 - val_accuracy500: 0.2961 - 36s/epoch - 23ms/step
Epoch 10/50
1542/1542 - 35s - loss: 3.1647 - accuracy500: 0.4449 - val_loss: 3.4560 - val_accuracy500: 0.2964 - 35s/epoch - 23ms/step
Epoch 11/50
1542/1542 - 35s - loss: 3.1626 - accuracy500: 0.4467 - val_loss: 3.5192 - val_accuracy500: 0.2999 - 35s/epoch - 23ms/step
Epoch 12/50
1542/1542 - 36s - loss: 3.1501 - accuracy500: 0.4527 - val_loss: 3.4984 - val_accuracy500: 0.3006 - 36s/epoch - 23ms/step
Epoch 13/50
1542/1542 - 36s - loss: 3.1471 - accuracy500: 0.4531 - val_loss: 3.5393 - val_accuracy500: 0.2972 - 36s/epoch - 23ms/step
Epoch 14/50
1542/1542 - 35s - loss: 3.1439 - accuracy500: 0.4554 - val_loss: 3.5107 - val_accuracy500: 0.2997 - 35s/epoch - 23ms/step
testing model: results/WBA/W2/deepLOB_L1/h500
Evaluating performance on  test set...
4353/4353 - 61s - 61s/epoch - 14ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1064256
{'0': {'precision': 0.3970243245841746, 'recall': 0.18477609135329598, 'f1-score': 0.2521847728508003, 'support': 446968}, '1': {'precision': 0.2505703444352564, 'recall': 0.3025892718027168, 'f1-score': 0.2741338876965375, 'support': 282396}, '2': {'precision': 0.34425365239205585, 'recall': 0.5055231682098285, 'f1-score': 0.4095856530936569, 'support': 384924}, 'accuracy': 0.3254338196229341, 'macro avg': {'precision': 0.3306161071371623, 'recall': 0.33096284378861374, 'f1-score': 0.31196810454699825, 'support': 1114288}, 'weighted avg': {'precision': 0.3416789233943448, 'recall': 0.3254338196229341, 'f1-score': 0.312120551269466, 'support': 1114288}}
[[ 82589 137356 227023]
 [ 53311  85450 143635]
 [ 72120 118216 194588]]
Evaluating performance on  train set...
1542/1542 - 21s - 21s/epoch - 13ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1127365
{'0': {'precision': 0.37188190716766656, 'recall': 0.19951578635308068, 'f1-score': 0.25970112228444375, 'support': 141673}, '1': {'precision': 0.3381587778550889, 'recall': 0.45620156004685125, 'f1-score': 0.38840952812040286, 'support': 120381}, '2': {'precision': 0.34780214150315075, 'recall': 0.40985895297677893, 'f1-score': 0.37628914193465696, 'support': 132509}, 'accuracy': 0.3484716002260729, 'macro avg': {'precision': 0.3526142755086354, 'recall': 0.3551920997922369, 'f1-score': 0.3414665974465012, 'support': 394563}, 'weighted avg': {'precision': 0.3535061098977331, 'recall': 0.3484716002260729, 'f1-score': 0.33812461485411877, 'support': 394563}}
[[28266 55527 57880]
 [21501 54918 43962]
 [26241 51958 54310]]
Evaluating performance on  val set...
482/482 - 6s - 6s/epoch - 13ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1340162
{'0': {'precision': 0.3504351214443434, 'recall': 0.3006664140682461, 'f1-score': 0.3236486648592884, 'support': 44867}, '1': {'precision': 0.24642534308488784, 'recall': 0.35285638642113315, 'f1-score': 0.290189911697109, 'support': 33994}, '2': {'precision': 0.31567005174465257, 'recall': 0.25665369299646784, 'f1-score': 0.28311907480021836, 'support': 44449}, 'accuracy': 0.29918903576352285, 'macro avg': {'precision': 0.30417683875796125, 'recall': 0.3033921644952824, 'f1-score': 0.2989858837855386, 'support': 123310}, 'weighted avg': {'precision': 0.3092301827643265, 'recall': 0.29918903576352285, 'f1-score': 0.29981526445761186, 'support': 123310}}
[[13490 18416 12961]
 [10229 11995 11770]
 [14776 18265 11408]]
training model: results/WBA/W2/deepLOB_L1/h1000
Epoch 1/50
1542/1542 - 37s - loss: 3.2889 - accuracy1000: 0.3813 - val_loss: 3.5278 - val_accuracy1000: 0.3290 - 37s/epoch - 24ms/step
Epoch 2/50
1542/1542 - 35s - loss: 3.2400 - accuracy1000: 0.4022 - val_loss: 3.4967 - val_accuracy1000: 0.3285 - 35s/epoch - 23ms/step
Epoch 3/50
1542/1542 - 34s - loss: 3.1995 - accuracy1000: 0.4257 - val_loss: 3.5184 - val_accuracy1000: 0.3260 - 34s/epoch - 22ms/step
Epoch 4/50
1542/1542 - 35s - loss: 3.1810 - accuracy1000: 0.4346 - val_loss: 3.4979 - val_accuracy1000: 0.3209 - 35s/epoch - 23ms/step
Epoch 5/50
1542/1542 - 35s - loss: 3.1740 - accuracy1000: 0.4361 - val_loss: 3.4721 - val_accuracy1000: 0.3161 - 35s/epoch - 23ms/step
Epoch 6/50
1542/1542 - 34s - loss: 3.1612 - accuracy1000: 0.4430 - val_loss: 3.4748 - val_accuracy1000: 0.3145 - 34s/epoch - 22ms/step
Epoch 7/50
1542/1542 - 35s - loss: 3.1555 - accuracy1000: 0.4421 - val_loss: 3.5166 - val_accuracy1000: 0.3047 - 35s/epoch - 23ms/step
Epoch 8/50
1542/1542 - 35s - loss: 3.1428 - accuracy1000: 0.4481 - val_loss: 3.4814 - val_accuracy1000: 0.3033 - 35s/epoch - 23ms/step
Epoch 9/50
1542/1542 - 34s - loss: 3.1313 - accuracy1000: 0.4519 - val_loss: 3.4894 - val_accuracy1000: 0.3050 - 34s/epoch - 22ms/step
Epoch 10/50
1542/1542 - 35s - loss: 3.1271 - accuracy1000: 0.4535 - val_loss: 3.5461 - val_accuracy1000: 0.3106 - 35s/epoch - 22ms/step
Epoch 11/50
1542/1542 - 36s - loss: 3.1178 - accuracy1000: 0.4585 - val_loss: 3.5375 - val_accuracy1000: 0.3139 - 36s/epoch - 23ms/step
Epoch 12/50
1542/1542 - 35s - loss: 3.1165 - accuracy1000: 0.4584 - val_loss: 3.5222 - val_accuracy1000: 0.3137 - 35s/epoch - 23ms/step
Epoch 13/50
1542/1542 - 35s - loss: 3.1079 - accuracy1000: 0.4626 - val_loss: 3.5457 - val_accuracy1000: 0.3138 - 35s/epoch - 22ms/step
Epoch 14/50
1542/1542 - 35s - loss: 3.0998 - accuracy1000: 0.4657 - val_loss: 3.5351 - val_accuracy1000: 0.3137 - 35s/epoch - 22ms/step
Epoch 15/50
1542/1542 - 35s - loss: 3.1000 - accuracy1000: 0.4659 - val_loss: 3.5196 - val_accuracy1000: 0.3211 - 35s/epoch - 22ms/step
testing model: results/WBA/W2/deepLOB_L1/h1000
Evaluating performance on  test set...
4353/4353 - 57s - 57s/epoch - 13ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.113882
{'0': {'precision': 0.3408045403655792, 'recall': 0.07817525802030599, 'f1-score': 0.12717788771778876, 'support': 393283}, '1': {'precision': 0.34525792002670813, 'recall': 0.6746555660831611, 'f1-score': 0.45676457984441504, 'support': 386286}, '2': {'precision': 0.29688242809603044, 'recall': 0.23881225744579782, 'f1-score': 0.2646998925437979, 'support': 334719}, 'accuracy': 0.333208290854788, 'macro avg': {'precision': 0.32764829616277263, 'recall': 0.33054769384975496, 'f1-score': 0.28288078670200056, 'support': 1114288}, 'weighted avg': {'precision': 0.3291546910618334, 'recall': 0.333208290854788, 'f1-score': 0.2827444494039802, 'support': 1114288}}
[[ 30745 266622  95916]
 [ 32279 260610  93397]
 [ 27189 227595  79935]]
Evaluating performance on  train set...
1542/1542 - 21s - 21s/epoch - 13ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1394979
{'0': {'precision': 0.3389714828333185, 'recall': 0.08345692722450739, 'f1-score': 0.1339375747484933, 'support': 136873}, '1': {'precision': 0.3274918066645623, 'recall': 0.6423548475861436, 'f1-score': 0.4338128066611776, 'support': 130828}, '2': {'precision': 0.32144878324844367, 'recall': 0.2641610568964702, 'f1-score': 0.29000281245267506, 'support': 126862}, 'accuracy': 0.3268755559948601, 'macro avg': {'precision': 0.3293040242487748, 'recall': 0.3299909439023737, 'f1-score': 0.28591773128744863, 'support': 394563}, 'weighted avg': {'precision': 0.329531094888827, 'recall': 0.3268755559948601, 'f1-score': 0.2835482200099612, 'support': 394563}}
[[11423 89529 35921]
 [11970 84038 34820]
 [10306 83044 33512]]
Evaluating performance on  val set...
482/482 - 7s - 7s/epoch - 14ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1545682
{'0': {'precision': 0.3060882070949185, 'recall': 0.12242061114439784, 'f1-score': 0.17489257528289934, 'support': 41725}, '1': {'precision': 0.3161317414200109, 'recall': 0.7013193010725616, 'f1-score': 0.43581318939216146, 'support': 39718}, '2': {'precision': 0.3252836304700162, 'recall': 0.1438125492631428, 'f1-score': 0.1994468092154297, 'support': 41867}, 'accuracy': 0.3161462979482605, 'macro avg': {'precision': 0.31583452632831516, 'recall': 0.3225174871600341, 'f1-score': 0.2700508579634968, 'support': 123310}, 'weighted avg': {'precision': 0.3158405701374068, 'recall': 0.3161462979482605, 'f1-score': 0.2672715961509954, 'support': 123310}}
[[ 5108 29827  6790]
 [ 6164 27855  5699]
 [ 5416 30430  6021]]
training model: results/WBA/W2/deepOF_L1/h10
Epoch 1/50
1542/1542 - 35s - loss: 3.1624 - accuracy10: 0.4162 - val_loss: 3.3180 - val_accuracy10: 0.6151 - 35s/epoch - 22ms/step
Epoch 2/50
1542/1542 - 33s - loss: 3.1211 - accuracy10: 0.4271 - val_loss: 3.2216 - val_accuracy10: 0.6178 - 33s/epoch - 21ms/step
Epoch 3/50
1542/1542 - 32s - loss: 3.1036 - accuracy10: 0.4328 - val_loss: 3.1783 - val_accuracy10: 0.6249 - 32s/epoch - 21ms/step
Epoch 4/50
1542/1542 - 33s - loss: 3.0904 - accuracy10: 0.4440 - val_loss: 3.1591 - val_accuracy10: 0.6261 - 33s/epoch - 21ms/step
Epoch 5/50
1542/1542 - 32s - loss: 3.0814 - accuracy10: 0.4506 - val_loss: 3.1517 - val_accuracy10: 0.6272 - 32s/epoch - 21ms/step
Epoch 6/50
1542/1542 - 32s - loss: 3.0709 - accuracy10: 0.4560 - val_loss: 3.1710 - val_accuracy10: 0.6346 - 32s/epoch - 21ms/step
Epoch 7/50
1542/1542 - 32s - loss: 3.0620 - accuracy10: 0.4610 - val_loss: 3.1907 - val_accuracy10: 0.6336 - 32s/epoch - 21ms/step
Epoch 8/50
1542/1542 - 32s - loss: 3.0526 - accuracy10: 0.4637 - val_loss: 3.1946 - val_accuracy10: 0.6370 - 32s/epoch - 21ms/step
Epoch 9/50
1542/1542 - 32s - loss: 3.0450 - accuracy10: 0.4672 - val_loss: 3.2315 - val_accuracy10: 0.6381 - 32s/epoch - 21ms/step
Epoch 10/50
1542/1542 - 33s - loss: 3.0371 - accuracy10: 0.4709 - val_loss: 3.1699 - val_accuracy10: 0.6379 - 33s/epoch - 21ms/step
Epoch 11/50
1542/1542 - 32s - loss: 3.0286 - accuracy10: 0.4748 - val_loss: 3.1943 - val_accuracy10: 0.6385 - 32s/epoch - 21ms/step
Epoch 12/50
1542/1542 - 32s - loss: 3.0172 - accuracy10: 0.4782 - val_loss: 3.1918 - val_accuracy10: 0.6385 - 32s/epoch - 21ms/step
Epoch 13/50
1542/1542 - 32s - loss: 3.0107 - accuracy10: 0.4810 - val_loss: 3.2167 - val_accuracy10: 0.6420 - 32s/epoch - 21ms/step
Epoch 14/50
1542/1542 - 32s - loss: 3.0043 - accuracy10: 0.4833 - val_loss: 3.2221 - val_accuracy10: 0.6405 - 32s/epoch - 21ms/step
Epoch 15/50
1542/1542 - 32s - loss: 2.9966 - accuracy10: 0.4864 - val_loss: 3.2064 - val_accuracy10: 0.6407 - 32s/epoch - 21ms/step
testing model: results/WBA/W2/deepOF_L1/h10
Evaluating performance on  test set...
4353/4353 - 59s - 59s/epoch - 14ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.8932809
{'0': {'precision': 0.3858390661021152, 'recall': 0.22438667428705728, 'f1-score': 0.2837544833735233, 'support': 187217}, '1': {'precision': 0.697680957270965, 'recall': 0.8581892755048554, 'f1-score': 0.769655852578001, 'support': 740212}, '2': {'precision': 0.3749591679750477, 'recall': 0.19043745384096675, 'f1-score': 0.2525882415573814, 'support': 186854}, 'accuracy': 0.6397252762538781, 'macro avg': {'precision': 0.48615973044937594, 'recall': 0.42433780121095976, 'f1-score': 0.43533285916963527, 'support': 1114283}, 'weighted avg': {'precision': 0.5911694511669879, 'recall': 0.6397252762538781, 'f1-score': 0.6013097968381204, 'support': 1114283}}
[[ 42009 133599  11609]
 [ 57262 635242  47708]
 [  9606 141664  35584]]
Evaluating performance on  train set...
1542/1542 - 21s - 21s/epoch - 13ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.9180538
{'0': {'precision': 0.40092111198157776, 'recall': 0.22563664056863425, 'f1-score': 0.28876026981507924, 'support': 74846}, '1': {'precision': 0.6635846462007949, 'recall': 0.8543186622635942, 'f1-score': 0.7469681949826564, 'support': 247403}, '2': {'precision': 0.3984672070744289, 'recall': 0.18693734183341862, 'f1-score': 0.2544852124475235, 'support': 72313}, 'accuracy': 0.612747806428394, 'macro avg': {'precision': 0.4876576550856005, 'recall': 0.4222975482218823, 'f1-score': 0.43007122574841966, 'support': 394562}, 'weighted avg': {'precision': 0.565169815939096, 'recall': 0.612747806428394, 'f1-score': 0.5697895708800932, 'support': 394562}}
[[ 16888  53580   4378]
 [ 20013 211361  16029]
 [  5222  53573  13518]]
Evaluating performance on  val set...
482/482 - 6s - 6s/epoch - 13ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.90711355
{'0': {'precision': 0.4057147927943917, 'recall': 0.20668143393155824, 'f1-score': 0.2738544474393531, 'support': 22121}, '1': {'precision': 0.6765542863918422, 'recall': 0.8638766575404686, 'f1-score': 0.7588259089120762, 'support': 79259}, '2': {'precision': 0.3803986710963455, 'recall': 0.18797026768206485, 'f1-score': 0.25160994964138567, 'support': 21929}, 'accuracy': 0.6257775182671176, 'macro avg': {'precision': 0.4875559167608598, 'recall': 0.41950945305136395, 'f1-score': 0.42809676866427165, 'support': 123309}, 'weighted avg': {'precision': 0.575299415087362, 'recall': 0.6257775182671176, 'f1-score': 0.5816223595354282, 'support': 123309}}
[[ 4572 16232  1317]
 [ 5392 68470  5397]
 [ 1305 16502  4122]]
training model: results/WBA/W2/deepOF_L1/h20
Epoch 1/50
1542/1542 - 36s - loss: 3.1878 - accuracy20: 0.4164 - val_loss: 3.3494 - val_accuracy20: 0.5345 - 36s/epoch - 23ms/step
Epoch 2/50
1542/1542 - 33s - loss: 3.1486 - accuracy20: 0.4253 - val_loss: 3.2636 - val_accuracy20: 0.5457 - 33s/epoch - 21ms/step
Epoch 3/50
1542/1542 - 33s - loss: 3.1320 - accuracy20: 0.4354 - val_loss: 3.2312 - val_accuracy20: 0.5516 - 33s/epoch - 21ms/step
Epoch 4/50
1542/1542 - 32s - loss: 3.1196 - accuracy20: 0.4420 - val_loss: 3.2228 - val_accuracy20: 0.5541 - 32s/epoch - 21ms/step
Epoch 5/50
1542/1542 - 32s - loss: 3.1121 - accuracy20: 0.4457 - val_loss: 3.2174 - val_accuracy20: 0.5538 - 32s/epoch - 21ms/step
Epoch 6/50
1542/1542 - 33s - loss: 3.1017 - accuracy20: 0.4509 - val_loss: 3.2338 - val_accuracy20: 0.5546 - 33s/epoch - 22ms/step
Epoch 7/50
1542/1542 - 33s - loss: 3.0945 - accuracy20: 0.4520 - val_loss: 3.2354 - val_accuracy20: 0.5561 - 33s/epoch - 22ms/step
Epoch 8/50
1542/1542 - 33s - loss: 3.0880 - accuracy20: 0.4550 - val_loss: 3.2254 - val_accuracy20: 0.5567 - 33s/epoch - 21ms/step
Epoch 9/50
1542/1542 - 33s - loss: 3.0810 - accuracy20: 0.4577 - val_loss: 3.2313 - val_accuracy20: 0.5571 - 33s/epoch - 21ms/step
Epoch 10/50
1542/1542 - 33s - loss: 3.0722 - accuracy20: 0.4615 - val_loss: 3.2391 - val_accuracy20: 0.5571 - 33s/epoch - 21ms/step
Epoch 11/50
1542/1542 - 33s - loss: 3.0653 - accuracy20: 0.4644 - val_loss: 3.2464 - val_accuracy20: 0.5572 - 33s/epoch - 21ms/step
Epoch 12/50
1542/1542 - 33s - loss: 3.0600 - accuracy20: 0.4687 - val_loss: 3.2556 - val_accuracy20: 0.5590 - 33s/epoch - 21ms/step
Epoch 13/50
1542/1542 - 34s - loss: 3.0518 - accuracy20: 0.4721 - val_loss: 3.2792 - val_accuracy20: 0.5594 - 34s/epoch - 22ms/step
Epoch 14/50
1542/1542 - 33s - loss: 3.0440 - accuracy20: 0.4739 - val_loss: 3.2635 - val_accuracy20: 0.5597 - 33s/epoch - 21ms/step
Epoch 15/50
1542/1542 - 34s - loss: 3.0346 - accuracy20: 0.4773 - val_loss: 3.2865 - val_accuracy20: 0.5598 - 34s/epoch - 22ms/step
testing model: results/WBA/W2/deepOF_L1/h20
Evaluating performance on  test set...
4353/4353 - 61s - 61s/epoch - 14ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.95507056
{'0': {'precision': 0.4882101306398238, 'recall': 0.17611410127361513, 'f1-score': 0.2588515795748063, 'support': 240418}, '1': {'precision': 0.5923863782153247, 'recall': 0.9001700682967653, 'f1-score': 0.7145438121047878, 'support': 630923}, '2': {'precision': 0.46826100222296485, 'recall': 0.13266129364210388, 'f1-score': 0.20674922779365493, 'support': 242942}, 'accuracy': 0.5766111481553609, 'macro avg': {'precision': 0.5162858370260378, 'recall': 0.4029818210708281, 'f1-score': 0.3933815398244163, 'support': 1114283}, 'weighted avg': {'precision': 0.5428467978897318, 'recall': 0.5766111481553609, 'f1-score': 0.505511414534235, 'support': 1114283}}
[[ 42341 188812   9265]
 [ 35652 567938  27333]
 [  8734 201979  32229]]
Evaluating performance on  train set...
1542/1542 - 22s - 22s/epoch - 14ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.9815002
{'0': {'precision': 0.5015512836111449, 'recall': 0.1731546725193485, 'f1-score': 0.2574334715033996, 'support': 95227}, '1': {'precision': 0.5524752123492683, 'recall': 0.9022904306705929, 'f1-score': 0.6853242646707776, 'support': 206817}, '2': {'precision': 0.5050800685704729, 'recall': 0.13056918653667393, 'f1-score': 0.2074977455232533, 'support': 92518}, 'accuracy': 0.5453591577496059, 'macro avg': {'precision': 0.519702188176962, 'recall': 0.4020047632422051, 'f1-score': 0.38341849389914356, 'support': 394562}, 'weighted avg': {'precision': 0.529071445960027, 'recall': 0.5453591577496059, 'f1-score': 0.4700113088883136, 'support': 394562}}
[[ 16489  75336   3402]
 [ 11773 186609   8435]
 [  4614  75824  12080]]
Evaluating performance on  val set...
482/482 - 7s - 7s/epoch - 14ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.9759423
{'0': {'precision': 0.5143232275005968, 'recall': 0.1499199777329344, 'f1-score': 0.2321659482758621, 'support': 28742}, '1': {'precision': 0.5623121236656708, 'recall': 0.9128280279796347, 'f1-score': 0.6959261008281405, 'support': 66191}, '2': {'precision': 0.48315508021390374, 'recall': 0.12736115026783196, 'f1-score': 0.20158411423471662, 'support': 28376}, 'accuracy': 0.5542498925463673, 'macro avg': {'precision': 0.5199301437933904, 'recall': 0.39670305199346706, 'f1-score': 0.37655872111290645, 'support': 123309}, 'weighted avg': {'precision': 0.5329107245904703, 'recall': 0.5542498925463673, 'f1-score': 0.4740700926192297, 'support': 123309}}
[[ 4309 23388  1045]
 [ 2949 60421  2821]
 [ 1120 23642  3614]]
training model: results/WBA/W2/deepOF_L1/h30
Epoch 1/50
1542/1542 - 35s - loss: 3.2087 - accuracy30: 0.4167 - val_loss: 3.3709 - val_accuracy30: 0.4767 - 35s/epoch - 22ms/step
Epoch 2/50
1542/1542 - 32s - loss: 3.1829 - accuracy30: 0.4183 - val_loss: 3.2634 - val_accuracy30: 0.4857 - 32s/epoch - 21ms/step
Epoch 3/50
1542/1542 - 33s - loss: 3.1663 - accuracy30: 0.4257 - val_loss: 3.2464 - val_accuracy30: 0.4876 - 33s/epoch - 21ms/step
Epoch 4/50
1542/1542 - 32s - loss: 3.1545 - accuracy30: 0.4324 - val_loss: 3.2365 - val_accuracy30: 0.4893 - 32s/epoch - 21ms/step
Epoch 5/50
1542/1542 - 33s - loss: 3.1468 - accuracy30: 0.4347 - val_loss: 3.2393 - val_accuracy30: 0.4901 - 33s/epoch - 21ms/step
Epoch 6/50
1542/1542 - 32s - loss: 3.1402 - accuracy30: 0.4380 - val_loss: 3.2410 - val_accuracy30: 0.4917 - 32s/epoch - 21ms/step
Epoch 7/50
1542/1542 - 32s - loss: 3.1334 - accuracy30: 0.4412 - val_loss: 3.2400 - val_accuracy30: 0.4932 - 32s/epoch - 21ms/step
Epoch 8/50
1542/1542 - 33s - loss: 3.1268 - accuracy30: 0.4440 - val_loss: 3.2474 - val_accuracy30: 0.4930 - 33s/epoch - 21ms/step
Epoch 9/50
1542/1542 - 33s - loss: 3.1186 - accuracy30: 0.4471 - val_loss: 3.2543 - val_accuracy30: 0.4933 - 33s/epoch - 21ms/step
Epoch 10/50
1542/1542 - 33s - loss: 3.1108 - accuracy30: 0.4507 - val_loss: 3.2511 - val_accuracy30: 0.4948 - 33s/epoch - 22ms/step
Epoch 11/50
1542/1542 - 33s - loss: 3.1046 - accuracy30: 0.4519 - val_loss: 3.2638 - val_accuracy30: 0.4951 - 33s/epoch - 21ms/step
Epoch 12/50
1542/1542 - 33s - loss: 3.0969 - accuracy30: 0.4566 - val_loss: 3.2628 - val_accuracy30: 0.4960 - 33s/epoch - 21ms/step
Epoch 13/50
1542/1542 - 33s - loss: 3.0911 - accuracy30: 0.4590 - val_loss: 3.2373 - val_accuracy30: 0.4979 - 33s/epoch - 21ms/step
Epoch 14/50
1542/1542 - 33s - loss: 3.0839 - accuracy30: 0.4619 - val_loss: 3.2842 - val_accuracy30: 0.4973 - 33s/epoch - 21ms/step
testing model: results/WBA/W2/deepOF_L1/h30
Evaluating performance on  test set...
4353/4353 - 58s - 58s/epoch - 13ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.0030752
{'0': {'precision': 0.525483327719771, 'recall': 0.1404350158603283, 'f1-score': 0.2216375631460215, 'support': 277737}, '1': {'precision': 0.5213646379584237, 'recall': 0.8788660814230131, 'f1-score': 0.6544774229170827, 'support': 555666}, '2': {'precision': 0.4566411918351553, 'recall': 0.16805397322700086, 'f1-score': 0.2456890045543266, 'support': 280880}, 'accuracy': 0.515634717571748, 'macro avg': {'precision': 0.50116305250445, 'recall': 0.3957850235034474, 'f1-score': 0.37393466353914356, 'support': 1114283}, 'weighted avg': {'precision': 0.5060762336582089, 'recall': 0.515634717571748, 'f1-score': 0.4435470442942677, 'support': 1114283}}
[[ 39004 222738  15995]
 [ 27138 488356  40172]
 [  8083 225594  47203]]
Evaluating performance on  train set...
1542/1542 - 21s - 21s/epoch - 13ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.0279955
{'0': {'precision': 0.5276608538785328, 'recall': 0.14531487188923134, 'f1-score': 0.22787439857461284, 'support': 108695}, '1': {'precision': 0.4813681197669908, 'recall': 0.8778717383069278, 'f1-score': 0.6217879288269146, 'support': 179508}, '2': {'precision': 0.4849029764620629, 'recall': 0.1698680882670954, 'f1-score': 0.25159798911000014, 'support': 106359}, 'accuracy': 0.4852139841140302, 'macro avg': {'precision': 0.4979773167025288, 'recall': 0.3976848994877515, 'f1-score': 0.36708677217050917, 'support': 394562}, 'weighted avg': {'precision': 0.4950738302953367, 'recall': 0.4852139841140302, 'f1-score': 0.41348235715725246, 'support': 394562}}
[[ 15795  86481   6419]
 [  9150 157585  12773]
 [  4989  83303  18067]]
Evaluating performance on  val set...
482/482 - 6s - 6s/epoch - 13ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 1.0252376
{'0': {'precision': 0.543309162821358, 'recall': 0.12448646689221847, 'f1-score': 0.2025608886922756, 'support': 33104}, '1': {'precision': 0.488347966417552, 'recall': 0.8850934921132352, 'f1-score': 0.6294168626965457, 'support': 57438}, '2': {'precision': 0.4580106694200654, 'recall': 0.16245002594073304, 'f1-score': 0.23983419315596202, 'support': 32767}, 'accuracy': 0.488869425589373, 'macro avg': {'precision': 0.49655593288632516, 'recall': 0.39067666164872894, 'f1-score': 0.35727064818159443, 'support': 123309}, 'weighted avg': {'precision': 0.49504150245332357, 'recall': 0.488869425589373, 'f1-score': 0.4112973783420082, 'support': 123309}}
[[ 4121 26972  2011]
 [ 2312 50838  4288]
 [ 1152 26292  5323]]
training model: results/WBA/W2/deepOF_L1/h50
Epoch 1/50
1542/1542 - 34s - loss: 3.2455 - accuracy50: 0.4043 - val_loss: 3.4215 - val_accuracy50: 0.3860 - 34s/epoch - 22ms/step
Epoch 2/50
1542/1542 - 31s - loss: 3.2219 - accuracy50: 0.4105 - val_loss: 3.3244 - val_accuracy50: 0.3984 - 31s/epoch - 20ms/step
Epoch 3/50
1542/1542 - 32s - loss: 3.2105 - accuracy50: 0.4126 - val_loss: 3.2965 - val_accuracy50: 0.4002 - 32s/epoch - 21ms/step
Epoch 4/50
1542/1542 - 32s - loss: 3.2017 - accuracy50: 0.4165 - val_loss: 3.3020 - val_accuracy50: 0.4011 - 32s/epoch - 21ms/step
Epoch 5/50
1542/1542 - 33s - loss: 3.1940 - accuracy50: 0.4208 - val_loss: 3.2972 - val_accuracy50: 0.4030 - 33s/epoch - 21ms/step
Epoch 6/50
1542/1542 - 32s - loss: 3.1880 - accuracy50: 0.4246 - val_loss: 3.2988 - val_accuracy50: 0.4040 - 32s/epoch - 21ms/step
Epoch 7/50
1542/1542 - 32s - loss: 3.1819 - accuracy50: 0.4269 - val_loss: 3.2961 - val_accuracy50: 0.4047 - 32s/epoch - 21ms/step
Epoch 8/50
1542/1542 - 31s - loss: 3.1760 - accuracy50: 0.4296 - val_loss: 3.3035 - val_accuracy50: 0.4036 - 31s/epoch - 20ms/step
Epoch 9/50
1542/1542 - 31s - loss: 3.1693 - accuracy50: 0.4331 - val_loss: 3.3218 - val_accuracy50: 0.4033 - 31s/epoch - 20ms/step
Epoch 10/50
1542/1542 - 32s - loss: 3.1634 - accuracy50: 0.4359 - val_loss: 3.3211 - val_accuracy50: 0.4043 - 32s/epoch - 21ms/step
Epoch 11/50
1542/1542 - 32s - loss: 3.1580 - accuracy50: 0.4383 - val_loss: 3.3398 - val_accuracy50: 0.4033 - 32s/epoch - 21ms/step
Epoch 12/50
1542/1542 - 32s - loss: 3.1526 - accuracy50: 0.4409 - val_loss: 3.3386 - val_accuracy50: 0.4054 - 32s/epoch - 21ms/step
Epoch 13/50
1542/1542 - 33s - loss: 3.1476 - accuracy50: 0.4439 - val_loss: 3.3344 - val_accuracy50: 0.4065 - 33s/epoch - 21ms/step
Epoch 14/50
1542/1542 - 32s - loss: 3.1415 - accuracy50: 0.4458 - val_loss: 3.3477 - val_accuracy50: 0.4077 - 32s/epoch - 21ms/step
Epoch 15/50
1542/1542 - 32s - loss: 3.1357 - accuracy50: 0.4483 - val_loss: 3.3591 - val_accuracy50: 0.4072 - 32s/epoch - 21ms/step
Epoch 16/50
1542/1542 - 32s - loss: 3.1296 - accuracy50: 0.4495 - val_loss: 3.3593 - val_accuracy50: 0.4077 - 32s/epoch - 21ms/step
Epoch 17/50
1542/1542 - 32s - loss: 3.1239 - accuracy50: 0.4527 - val_loss: 3.3526 - val_accuracy50: 0.4088 - 32s/epoch - 21ms/step
testing model: results/WBA/W2/deepOF_L1/h50
Evaluating performance on  test set...
4353/4353 - 60s - 60s/epoch - 14ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0609514
{'0': {'precision': 0.6107641693426056, 'recall': 0.09290290488262404, 'f1-score': 0.16127446517979063, 'support': 333714}, '1': {'precision': 0.41659430445441586, 'recall': 0.9220032492128368, 'f1-score': 0.5738861560866302, 'support': 447493}, '2': {'precision': 0.5140837367024913, 'recall': 0.11287814192556654, 'f1-score': 0.18511114940547993, 'support': 333076}, 'accuracy': 0.43183823140082006, 'macro avg': {'precision': 0.5138140701665043, 'recall': 0.37592809867367577, 'f1-score': 0.30675725689063355, 'support': 1114283}, 'weighted avg': {'precision': 0.5038868436269217, 'recall': 0.43183823140082006, 'f1-score': 0.3341033343576656, 'support': 1114283}}
[[ 31003 288953  13758]
 [ 13124 412590  21779]
 [  6634 288845  37597]]
Evaluating performance on  train set...
1542/1542 - 23s - 23s/epoch - 15ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0858794
{'0': {'precision': 0.5807118039252512, 'recall': 0.09729772253471267, 'f1-score': 0.16667003564377783, 'support': 127115}, '1': {'precision': 0.3784784299320743, 'recall': 0.9246279068137045, 'f1-score': 0.5371038549565472, 'support': 142639}, '2': {'precision': 0.5504738858640855, 'recall': 0.10935997692455612, 'f1-score': 0.18246960288229516, 'support': 124808}, 'accuracy': 0.40020326336545337, 'macro avg': {'precision': 0.5032213732404703, 'recall': 0.37709520209099107, 'f1-score': 0.2954144978275401, 'support': 394562}, 'weighted avg': {'precision': 0.49803709041915906, 'recall': 0.40020326336545337, 'f1-score': 0.3055841275757403, 'support': 394562}}
[[ 12368 109705   5042]
 [  4647 131888   6104]
 [  4283 106876  13649]]
Evaluating performance on  val set...
482/482 - 8s - 8s/epoch - 17ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0845376
{'0': {'precision': 0.5938526966943747, 'recall': 0.0790957542676176, 'f1-score': 0.1395982913750795, 'support': 38839}, '1': {'precision': 0.38702978198570753, 'recall': 0.9334018634355452, 'f1-score': 0.5471761010321173, 'support': 45722}, '2': {'precision': 0.5247839349262837, 'recall': 0.1065603385981212, 'f1-score': 0.17714947657456667, 'support': 38748}, 'accuracy': 0.40449602218816144, 'macro avg': {'precision': 0.5018888045354554, 'recall': 0.3730193187670947, 'f1-score': 0.2879746229939212, 'support': 123309}, 'weighted avg': {'precision': 0.4954605786227038, 'recall': 0.40449602218816144, 'f1-score': 0.30252480880080523, 'support': 123309}}
[[ 3072 34000  1767]
 [ 1073 42677  1972]
 [ 1028 33591  4129]]
training model: results/WBA/W2/deepOF_L1/h100
Epoch 1/50
1542/1542 - 46s - loss: 3.2765 - accuracy100: 0.3873 - val_loss: 3.3463 - val_accuracy100: 0.3461 - 46s/epoch - 30ms/step
Epoch 2/50
1542/1542 - 37s - loss: 3.2576 - accuracy100: 0.3946 - val_loss: 3.2884 - val_accuracy100: 0.3611 - 37s/epoch - 24ms/step
Epoch 3/50
1542/1542 - 35s - loss: 3.2514 - accuracy100: 0.3933 - val_loss: 3.2694 - val_accuracy100: 0.3712 - 35s/epoch - 23ms/step
Epoch 4/50
1542/1542 - 36s - loss: 3.2470 - accuracy100: 0.3954 - val_loss: 3.2648 - val_accuracy100: 0.3736 - 36s/epoch - 23ms/step
Epoch 5/50
1542/1542 - 36s - loss: 3.2434 - accuracy100: 0.3977 - val_loss: 3.2636 - val_accuracy100: 0.3745 - 36s/epoch - 23ms/step
Epoch 6/50
1542/1542 - 33s - loss: 3.2396 - accuracy100: 0.4005 - val_loss: 3.2681 - val_accuracy100: 0.3714 - 33s/epoch - 21ms/step
Epoch 7/50
1542/1542 - 36s - loss: 3.2361 - accuracy100: 0.4027 - val_loss: 3.2622 - val_accuracy100: 0.3755 - 36s/epoch - 23ms/step
Epoch 8/50
1542/1542 - 36s - loss: 3.2323 - accuracy100: 0.4056 - val_loss: 3.2600 - val_accuracy100: 0.3757 - 36s/epoch - 23ms/step
Epoch 9/50
1542/1542 - 36s - loss: 3.2294 - accuracy100: 0.4074 - val_loss: 3.2599 - val_accuracy100: 0.3782 - 36s/epoch - 23ms/step
Epoch 10/50
1542/1542 - 32s - loss: 3.2266 - accuracy100: 0.4079 - val_loss: 3.2617 - val_accuracy100: 0.3765 - 32s/epoch - 21ms/step
Epoch 11/50
1542/1542 - 37s - loss: 3.2230 - accuracy100: 0.4105 - val_loss: 3.2592 - val_accuracy100: 0.3789 - 37s/epoch - 24ms/step
Epoch 12/50
1542/1542 - 36s - loss: 3.2202 - accuracy100: 0.4120 - val_loss: 3.2587 - val_accuracy100: 0.3800 - 36s/epoch - 23ms/step
Epoch 13/50
1542/1542 - 32s - loss: 3.2175 - accuracy100: 0.4137 - val_loss: 3.2624 - val_accuracy100: 0.3771 - 32s/epoch - 21ms/step
Epoch 14/50
1542/1542 - 36s - loss: 3.2155 - accuracy100: 0.4142 - val_loss: 3.2570 - val_accuracy100: 0.3824 - 36s/epoch - 24ms/step
Epoch 15/50
1542/1542 - 32s - loss: 3.2120 - accuracy100: 0.4162 - val_loss: 3.2580 - val_accuracy100: 0.3811 - 32s/epoch - 21ms/step
Epoch 16/50
1542/1542 - 33s - loss: 3.2086 - accuracy100: 0.4181 - val_loss: 3.2606 - val_accuracy100: 0.3804 - 33s/epoch - 21ms/step
Epoch 17/50
1542/1542 - 33s - loss: 3.2064 - accuracy100: 0.4193 - val_loss: 3.2643 - val_accuracy100: 0.3794 - 33s/epoch - 21ms/step
Epoch 18/50
1542/1542 - 33s - loss: 3.2038 - accuracy100: 0.4206 - val_loss: 3.2654 - val_accuracy100: 0.3774 - 33s/epoch - 21ms/step
Epoch 19/50
1542/1542 - 32s - loss: 3.2020 - accuracy100: 0.4211 - val_loss: 3.2643 - val_accuracy100: 0.3791 - 32s/epoch - 21ms/step
Epoch 20/50
1542/1542 - 33s - loss: 3.1989 - accuracy100: 0.4227 - val_loss: 3.2688 - val_accuracy100: 0.3789 - 33s/epoch - 21ms/step
Epoch 21/50
1542/1542 - 33s - loss: 3.1972 - accuracy100: 0.4234 - val_loss: 3.2710 - val_accuracy100: 0.3786 - 33s/epoch - 21ms/step
Epoch 22/50
1542/1542 - 33s - loss: 3.1986 - accuracy100: 0.4222 - val_loss: 3.2703 - val_accuracy100: 0.3795 - 33s/epoch - 21ms/step
Epoch 23/50
1542/1542 - 33s - loss: 3.1931 - accuracy100: 0.4257 - val_loss: 3.2872 - val_accuracy100: 0.3754 - 33s/epoch - 21ms/step
Epoch 24/50
1542/1542 - 32s - loss: 3.1907 - accuracy100: 0.4266 - val_loss: 3.2782 - val_accuracy100: 0.3758 - 32s/epoch - 21ms/step
testing model: results/WBA/W2/deepOF_L1/h100
Evaluating performance on  test set...
4353/4353 - 61s - 61s/epoch - 14ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.075175
{'0': {'precision': 0.5028991049062376, 'recall': 0.171726188890014, 'f1-score': 0.25602641192350556, 'support': 375266}, '1': {'precision': 0.36671427100035203, 'recall': 0.6223581191608596, 'f1-score': 0.46149828109553315, 'support': 383297}, '2': {'precision': 0.42782870882108454, 'recall': 0.40367704936466886, 'f1-score': 0.4154021282719976, 'support': 355720}, 'accuracy': 0.40078418139736494, 'macro avg': {'precision': 0.43248069490922475, 'recall': 0.3992537858051808, 'f1-score': 0.3776422737636787, 'support': 1114283}, 'weighted avg': {'precision': 0.43208829690052014, 'recall': 0.40078418139736494, 'f1-score': 0.37758429341098787, 'support': 1114283}}
[[ 64443 224630  86193]
 [ 38899 238548 105850]
 [ 24801 187323 143596]]
Evaluating performance on  train set...
1542/1542 - 23s - 23s/epoch - 15ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0852648
{'0': {'precision': 0.479231850117096, 'recall': 0.18948530283276047, 'f1-score': 0.2715868490765368, 'support': 134992}, '1': {'precision': 0.34261565135156435, 'recall': 0.6777905100441991, 'f1-score': 0.45515530161256135, 'support': 128283}, '2': {'precision': 0.4467834383973824, 'recall': 0.2974551935835231, 'f1-score': 0.3571382845437003, 'support': 131287}, 'accuracy': 0.3841728296186658, 'macro avg': {'precision': 0.42287697995534757, 'recall': 0.38824366882016087, 'f1-score': 0.3612934784109328, 'support': 394562}, 'weighted avg': {'precision': 0.42401723123417084, 'recall': 0.3841728296186658, 'f1-score': 0.35973650136149155, 'support': 394562}}
[[25579 87019 22394]
 [15373 86949 25961]
 [12423 79812 39052]]
Evaluating performance on  val set...
482/482 - 9s - 9s/epoch - 19ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0871396
{'0': {'precision': 0.4721665168383929, 'recall': 0.16542701393095094, 'f1-score': 0.24501220037318786, 'support': 41275}, '1': {'precision': 0.3446605172436742, 'recall': 0.633709405056166, 'f1-score': 0.4464867661005259, 'support': 40861}, '2': {'precision': 0.4197929950473027, 'recall': 0.3437932625749885, 'f1-score': 0.37801100251028147, 'support': 41173}, 'accuracy': 0.3801587880852168, 'macro avg': {'precision': 0.41220667637645664, 'recall': 0.38097656052070183, 'f1-score': 0.3565033229946651, 'support': 123309}, 'weighted avg': {'precision': 0.4124271818170696, 'recall': 0.3801587880852168, 'f1-score': 0.3561834199157623, 'support': 123309}}
[[ 6828 25660  8787]
 [ 4190 25894 10777]
 [ 3443 23575 14155]]
training model: results/WBA/W2/deepOF_L1/h200
Epoch 1/50
1542/1542 - 47s - loss: 3.2949 - accuracy200: 0.3668 - val_loss: 3.2955 - val_accuracy200: 0.3451 - 47s/epoch - 30ms/step
Epoch 2/50
1542/1542 - 37s - loss: 3.2772 - accuracy200: 0.3729 - val_loss: 3.2798 - val_accuracy200: 0.3627 - 37s/epoch - 24ms/step
Epoch 3/50
1542/1542 - 37s - loss: 3.2729 - accuracy200: 0.3745 - val_loss: 3.2736 - val_accuracy200: 0.3737 - 37s/epoch - 24ms/step
Epoch 4/50
1542/1542 - 37s - loss: 3.2700 - accuracy200: 0.3763 - val_loss: 3.2716 - val_accuracy200: 0.3771 - 37s/epoch - 24ms/step
Epoch 5/50
1542/1542 - 36s - loss: 3.2673 - accuracy200: 0.3781 - val_loss: 3.2703 - val_accuracy200: 0.3764 - 36s/epoch - 23ms/step
Epoch 6/50
1542/1542 - 37s - loss: 3.2661 - accuracy200: 0.3790 - val_loss: 3.2689 - val_accuracy200: 0.3776 - 37s/epoch - 24ms/step
Epoch 7/50
1542/1542 - 35s - loss: 3.2646 - accuracy200: 0.3801 - val_loss: 3.2692 - val_accuracy200: 0.3758 - 35s/epoch - 23ms/step
Epoch 8/50
1542/1542 - 35s - loss: 3.2632 - accuracy200: 0.3810 - val_loss: 3.2687 - val_accuracy200: 0.3788 - 35s/epoch - 23ms/step
Epoch 9/50
1542/1542 - 36s - loss: 3.2615 - accuracy200: 0.3825 - val_loss: 3.2677 - val_accuracy200: 0.3780 - 36s/epoch - 23ms/step
Epoch 10/50
1542/1542 - 56s - loss: 3.2599 - accuracy200: 0.3831 - val_loss: 3.2675 - val_accuracy200: 0.3797 - 56s/epoch - 37ms/step
Epoch 11/50
1542/1542 - 56s - loss: 3.2580 - accuracy200: 0.3845 - val_loss: 3.2670 - val_accuracy200: 0.3769 - 56s/epoch - 36ms/step
Epoch 12/50
1542/1542 - 54s - loss: 3.2565 - accuracy200: 0.3862 - val_loss: 3.2659 - val_accuracy200: 0.3788 - 54s/epoch - 35ms/step
Epoch 13/50
1542/1542 - 53s - loss: 3.2550 - accuracy200: 0.3868 - val_loss: 3.2666 - val_accuracy200: 0.3774 - 53s/epoch - 34ms/step
Epoch 14/50
1542/1542 - 54s - loss: 3.2537 - accuracy200: 0.3878 - val_loss: 3.2669 - val_accuracy200: 0.3777 - 54s/epoch - 35ms/step
Epoch 15/50
1542/1542 - 56s - loss: 3.2521 - accuracy200: 0.3884 - val_loss: 3.2657 - val_accuracy200: 0.3790 - 56s/epoch - 36ms/step
Epoch 16/50
1542/1542 - 56s - loss: 3.2502 - accuracy200: 0.3900 - val_loss: 3.2664 - val_accuracy200: 0.3778 - 56s/epoch - 37ms/step
Epoch 17/50
1542/1542 - 56s - loss: 3.2481 - accuracy200: 0.3916 - val_loss: 3.2678 - val_accuracy200: 0.3760 - 56s/epoch - 36ms/step
Epoch 18/50
1542/1542 - 56s - loss: 3.2458 - accuracy200: 0.3931 - val_loss: 3.2685 - val_accuracy200: 0.3776 - 56s/epoch - 36ms/step
Epoch 19/50
1542/1542 - 55s - loss: 3.2442 - accuracy200: 0.3935 - val_loss: 3.2701 - val_accuracy200: 0.3761 - 55s/epoch - 36ms/step
Epoch 20/50
1542/1542 - 56s - loss: 3.2418 - accuracy200: 0.3964 - val_loss: 3.2771 - val_accuracy200: 0.3749 - 56s/epoch - 36ms/step
Epoch 21/50
1542/1542 - 56s - loss: 3.2399 - accuracy200: 0.3970 - val_loss: 3.2796 - val_accuracy200: 0.3736 - 56s/epoch - 36ms/step
Epoch 22/50
1542/1542 - 55s - loss: 3.2391 - accuracy200: 0.3980 - val_loss: 3.2812 - val_accuracy200: 0.3749 - 55s/epoch - 36ms/step
Epoch 23/50
1542/1542 - 55s - loss: 3.2351 - accuracy200: 0.3998 - val_loss: 3.2892 - val_accuracy200: 0.3701 - 55s/epoch - 35ms/step
Epoch 24/50
1542/1542 - 57s - loss: 3.2340 - accuracy200: 0.4005 - val_loss: 3.2939 - val_accuracy200: 0.3703 - 57s/epoch - 37ms/step
Epoch 25/50
1542/1542 - 57s - loss: 3.2310 - accuracy200: 0.4022 - val_loss: 3.2892 - val_accuracy200: 0.3725 - 57s/epoch - 37ms/step
testing model: results/WBA/W2/deepOF_L1/h200
Evaluating performance on  test set...
4353/4353 - 71s - 71s/epoch - 16ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0838662
{'0': {'precision': 0.39885223033547046, 'recall': 0.461025370339733, 'f1-score': 0.42769109709765557, 'support': 380799}, '1': {'precision': 0.39232702027537325, 'recall': 0.1412758101294952, 'f1-score': 0.20774371673793338, 'support': 382408}, '2': {'precision': 0.37183853726830235, 'recall': 0.5681447891624606, 'f1-score': 0.4494933504000578, 'support': 351076}, 'accuracy': 0.3850413225365549, 'macro avg': {'precision': 0.38767259595971537, 'recall': 0.39014865654389624, 'f1-score': 0.36164272141188225, 'support': 1114283}, 'weighted avg': {'precision': 0.38810168326985894, 'recall': 0.3850413225365549, 'f1-score': 0.35907711846906076, 'support': 1114283}}
[[175558  46733 158508]
 [149932  54025 178451]
 [114668  36946 199462]]
Evaluating performance on  train set...
1542/1542 - 26s - 26s/epoch - 17ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0856522
{'0': {'precision': 0.3911139450667116, 'recall': 0.48650873228476077, 'f1-score': 0.43362678404695215, 'support': 133642}, '1': {'precision': 0.3707527104839965, 'recall': 0.1628450993050545, 'f1-score': 0.22629501414277875, 'support': 131665}, '2': {'precision': 0.3860920976227763, 'recall': 0.5092723685737496, 'f1-score': 0.4392089355058249, 'support': 129255}, 'accuracy': 0.38595962104814957, 'macro avg': {'precision': 0.38265291772449483, 'recall': 0.38620873338785494, 'f1-score': 0.36637691123185195, 'support': 394562}, 'weighted avg': {'precision': 0.3826743060677734, 'recall': 0.38595962104814957, 'f1-score': 0.3662690139180082, 'support': 394562}}
[[65018 19033 49591]
 [55148 21441 55076]
 [46072 17357 65826]]
Evaluating performance on  val set...
482/482 - 8s - 8s/epoch - 17ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0883578
{'0': {'precision': 0.3789530969705521, 'recall': 0.45714494127945143, 'f1-score': 0.414392770553229, 'support': 41127}, '1': {'precision': 0.3672494025908691, 'recall': 0.14215471496032325, 'f1-score': 0.20496981608872666, 'support': 41082}, '2': {'precision': 0.3809391978406063, 'recall': 0.535669099756691, 'f1-score': 0.4452444030982668, 'support': 41100}, 'accuracy': 0.3783746522962639, 'macro avg': {'precision': 0.37571389913400915, 'recall': 0.37832291866548856, 'f1-score': 0.35486899658007415, 'support': 123309}, 'weighted avg': {'precision': 0.3757158439983691, 'recall': 0.3783746522962639, 'f1-score': 0.35490391152664025, 'support': 123309}}
[[18801  5224 17102]
 [16566  5840 18676]
 [14246  4838 22016]]
training model: results/WBA/W2/deepOF_L1/h300
Epoch 1/50
1542/1542 - 62s - loss: 3.2887 - accuracy300: 0.3741 - val_loss: 3.2978 - val_accuracy300: 0.3539 - 62s/epoch - 40ms/step
Epoch 2/50
1542/1542 - 57s - loss: 3.2738 - accuracy300: 0.3797 - val_loss: 3.2849 - val_accuracy300: 0.3738 - 57s/epoch - 37ms/step
Epoch 3/50
1542/1542 - 56s - loss: 3.2716 - accuracy300: 0.3814 - val_loss: 3.2790 - val_accuracy300: 0.3806 - 56s/epoch - 37ms/step
Epoch 4/50
1542/1542 - 58s - loss: 3.2691 - accuracy300: 0.3826 - val_loss: 3.2767 - val_accuracy300: 0.3820 - 58s/epoch - 38ms/step
Epoch 5/50
1542/1542 - 58s - loss: 3.2668 - accuracy300: 0.3837 - val_loss: 3.2767 - val_accuracy300: 0.3823 - 58s/epoch - 37ms/step
Epoch 6/50
1542/1542 - 57s - loss: 3.2643 - accuracy300: 0.3843 - val_loss: 3.2765 - val_accuracy300: 0.3806 - 57s/epoch - 37ms/step
Epoch 7/50
1542/1542 - 57s - loss: 3.2617 - accuracy300: 0.3866 - val_loss: 3.2762 - val_accuracy300: 0.3806 - 57s/epoch - 37ms/step
Epoch 8/50
1542/1542 - 57s - loss: 3.2600 - accuracy300: 0.3881 - val_loss: 3.2771 - val_accuracy300: 0.3798 - 57s/epoch - 37ms/step
Epoch 9/50
1542/1542 - 57s - loss: 3.2576 - accuracy300: 0.3892 - val_loss: 3.2778 - val_accuracy300: 0.3781 - 57s/epoch - 37ms/step
Epoch 10/50
1542/1542 - 59s - loss: 3.2561 - accuracy300: 0.3897 - val_loss: 3.2763 - val_accuracy300: 0.3818 - 59s/epoch - 38ms/step
Epoch 11/50
1542/1542 - 58s - loss: 3.2540 - accuracy300: 0.3916 - val_loss: 3.2768 - val_accuracy300: 0.3792 - 58s/epoch - 38ms/step
Epoch 12/50
1542/1542 - 57s - loss: 3.2525 - accuracy300: 0.3921 - val_loss: 3.2770 - val_accuracy300: 0.3800 - 57s/epoch - 37ms/step
Epoch 13/50
1542/1542 - 60s - loss: 3.2498 - accuracy300: 0.3937 - val_loss: 3.2780 - val_accuracy300: 0.3782 - 60s/epoch - 39ms/step
Epoch 14/50
1542/1542 - 59s - loss: 3.2490 - accuracy300: 0.3940 - val_loss: 3.2769 - val_accuracy300: 0.3801 - 59s/epoch - 38ms/step
Epoch 15/50
1542/1542 - 59s - loss: 3.2474 - accuracy300: 0.3954 - val_loss: 3.2767 - val_accuracy300: 0.3808 - 59s/epoch - 38ms/step
Epoch 16/50
1542/1542 - 59s - loss: 3.2457 - accuracy300: 0.3976 - val_loss: 3.2757 - val_accuracy300: 0.3802 - 59s/epoch - 38ms/step
Epoch 17/50
1542/1542 - 58s - loss: 3.2439 - accuracy300: 0.3986 - val_loss: 3.2776 - val_accuracy300: 0.3781 - 58s/epoch - 38ms/step
Epoch 18/50
1542/1542 - 57s - loss: 3.2431 - accuracy300: 0.3995 - val_loss: 3.2769 - val_accuracy300: 0.3780 - 57s/epoch - 37ms/step
Epoch 19/50
1542/1542 - 57s - loss: 3.2413 - accuracy300: 0.4012 - val_loss: 3.2755 - val_accuracy300: 0.3801 - 57s/epoch - 37ms/step
Epoch 20/50
1542/1542 - 58s - loss: 3.2393 - accuracy300: 0.4025 - val_loss: 3.2759 - val_accuracy300: 0.3809 - 58s/epoch - 38ms/step
Epoch 21/50
1542/1542 - 58s - loss: 3.2380 - accuracy300: 0.4029 - val_loss: 3.2759 - val_accuracy300: 0.3818 - 58s/epoch - 37ms/step
Epoch 22/50
1542/1542 - 57s - loss: 3.2370 - accuracy300: 0.4041 - val_loss: 3.2757 - val_accuracy300: 0.3807 - 57s/epoch - 37ms/step
Epoch 23/50
1542/1542 - 58s - loss: 3.2362 - accuracy300: 0.4041 - val_loss: 3.2753 - val_accuracy300: 0.3798 - 58s/epoch - 38ms/step
Epoch 24/50
1542/1542 - 61s - loss: 3.2346 - accuracy300: 0.4062 - val_loss: 3.2772 - val_accuracy300: 0.3783 - 61s/epoch - 39ms/step
Epoch 25/50
1542/1542 - 59s - loss: 3.2341 - accuracy300: 0.4064 - val_loss: 3.2762 - val_accuracy300: 0.3788 - 59s/epoch - 38ms/step
Epoch 26/50
1542/1542 - 57s - loss: 3.2357 - accuracy300: 0.4050 - val_loss: 3.2750 - val_accuracy300: 0.3811 - 57s/epoch - 37ms/step
Epoch 27/50
1542/1542 - 58s - loss: 3.2310 - accuracy300: 0.4083 - val_loss: 3.2772 - val_accuracy300: 0.3795 - 58s/epoch - 37ms/step
Epoch 28/50
1542/1542 - 59s - loss: 3.2305 - accuracy300: 0.4087 - val_loss: 3.2823 - val_accuracy300: 0.3754 - 59s/epoch - 38ms/step
Epoch 29/50
1542/1542 - 61s - loss: 3.2281 - accuracy300: 0.4102 - val_loss: 3.2807 - val_accuracy300: 0.3778 - 61s/epoch - 39ms/step
Epoch 30/50
1542/1542 - 61s - loss: 3.2271 - accuracy300: 0.4113 - val_loss: 3.2877 - val_accuracy300: 0.3737 - 61s/epoch - 39ms/step
Epoch 31/50
1542/1542 - 60s - loss: 3.2257 - accuracy300: 0.4124 - val_loss: 3.2825 - val_accuracy300: 0.3756 - 60s/epoch - 39ms/step
Epoch 32/50
1542/1542 - 58s - loss: 3.2251 - accuracy300: 0.4120 - val_loss: 3.2919 - val_accuracy300: 0.3727 - 58s/epoch - 38ms/step
Epoch 33/50
1542/1542 - 56s - loss: 3.2273 - accuracy300: 0.4119 - val_loss: 3.2856 - val_accuracy300: 0.3735 - 56s/epoch - 37ms/step
Epoch 34/50
1542/1542 - 54s - loss: 3.2278 - accuracy300: 0.4122 - val_loss: 3.2896 - val_accuracy300: 0.3733 - 54s/epoch - 35ms/step
Epoch 35/50
1542/1542 - 56s - loss: 3.2223 - accuracy300: 0.4152 - val_loss: 3.2943 - val_accuracy300: 0.3698 - 56s/epoch - 36ms/step
Epoch 36/50
1542/1542 - 58s - loss: 3.2212 - accuracy300: 0.4154 - val_loss: 3.2852 - val_accuracy300: 0.3742 - 58s/epoch - 38ms/step
testing model: results/WBA/W2/deepOF_L1/h300
Evaluating performance on  test set...
4353/4353 - 79s - 79s/epoch - 18ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0886822
{'0': {'precision': 0.4107852893317332, 'recall': 0.4729224747884492, 'f1-score': 0.43966931948564875, 'support': 406758}, '1': {'precision': 0.346611628110505, 'recall': 0.06873183218360883, 'f1-score': 0.11471591361669156, 'support': 345735}, '2': {'precision': 0.37204449301138304, 'recall': 0.5938057989441389, 'f1-score': 0.4574667093967499, 'support': 361790}, 'accuracy': 0.3867608139045467, 'macro avg': {'precision': 0.37648047015120706, 'recall': 0.37848670197206563, 'f1-score': 0.3372839808330301, 'support': 1114283}, 'weighted avg': {'precision': 0.3782952365686014, 'recall': 0.3867608139045467, 'f1-score': 0.3446226858367762, 'support': 1114283}}
[[192365  25641 188752]
 [148118  23763 173854]
 [127803  19154 214833]]
Evaluating performance on  train set...
1542/1542 - 29s - 29s/epoch - 19ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0902369
{'0': {'precision': 0.386987750653627, 'recall': 0.4944155594068939, 'f1-score': 0.43415485973133194, 'support': 135018}, '1': {'precision': 0.3745033849283285, 'recall': 0.09026144641995358, 'f1-score': 0.1454637482562374, 'support': 130543}, '2': {'precision': 0.37091290661070303, 'recall': 0.5480267594824846, 'f1-score': 0.4424016195193381, 'support': 129001}, 'accuracy': 0.37822699601076637, 'macro avg': {'precision': 0.37746801406421954, 'recall': 0.3775679217697774, 'f1-score': 0.34067340916896915, 'support': 394562}, 'weighted avg': {'precision': 0.37760160218707706, 'recall': 0.37822699601076637, 'f1-score': 0.34133607965144414, 'support': 394562}}
[[66755 10321 57942]
 [56798 11783 61962]
 [48946  9359 70696]]
Evaluating performance on  val set...
482/482 - 9s - 9s/epoch - 19ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0918304
{'0': {'precision': 0.3871671415937899, 'recall': 0.4559361258967832, 'f1-score': 0.4187470109995218, 'support': 43210}, '1': {'precision': 0.33369022127052106, 'recall': 0.07524545308224691, 'f1-score': 0.12280010506960863, 'support': 37278}, '2': {'precision': 0.38173638664125714, 'recall': 0.5707012914224329, 'f1-score': 0.4574733945469351, 'support': 42821}, 'accuracy': 0.3807021385300343, 'macro avg': {'precision': 0.3675312498351893, 'recall': 0.367294290133821, 'f1-score': 0.3330068368720218, 'support': 123309}, 'weighted avg': {'precision': 0.3691144204328591, 'recall': 0.3807021385300343, 'f1-score': 0.34272655596889534, 'support': 123309}}
[[19701  2915 20594]
 [15487  2805 18986]
 [15697  2686 24438]]
training model: results/WBA/W2/deepOF_L1/h500
Epoch 1/50
1542/1542 - 67s - loss: 3.2646 - accuracy500: 0.3927 - val_loss: 3.2805 - val_accuracy500: 0.3721 - 67s/epoch - 43ms/step
Epoch 2/50
1542/1542 - 58s - loss: 3.2547 - accuracy500: 0.3964 - val_loss: 3.2816 - val_accuracy500: 0.3746 - 58s/epoch - 38ms/step
Epoch 3/50
1542/1542 - 62s - loss: 3.2540 - accuracy500: 0.3962 - val_loss: 3.2802 - val_accuracy500: 0.3715 - 62s/epoch - 40ms/step
Epoch 4/50
1542/1542 - 59s - loss: 3.2498 - accuracy500: 0.3981 - val_loss: 3.2748 - val_accuracy500: 0.3837 - 59s/epoch - 38ms/step
Epoch 5/50
1542/1542 - 59s - loss: 3.2482 - accuracy500: 0.3987 - val_loss: 3.2697 - val_accuracy500: 0.3851 - 59s/epoch - 38ms/step
Epoch 6/50
1542/1542 - 58s - loss: 3.2445 - accuracy500: 0.4006 - val_loss: 3.2692 - val_accuracy500: 0.3862 - 58s/epoch - 38ms/step
Epoch 7/50
1542/1542 - 59s - loss: 3.2417 - accuracy500: 0.4021 - val_loss: 3.2700 - val_accuracy500: 0.3871 - 59s/epoch - 38ms/step
Epoch 8/50
1542/1542 - 62s - loss: 3.2403 - accuracy500: 0.4027 - val_loss: 3.2696 - val_accuracy500: 0.3875 - 62s/epoch - 40ms/step
Epoch 9/50
1542/1542 - 61s - loss: 3.2383 - accuracy500: 0.4043 - val_loss: 3.2704 - val_accuracy500: 0.3876 - 61s/epoch - 39ms/step
Epoch 10/50
1542/1542 - 59s - loss: 3.2376 - accuracy500: 0.4053 - val_loss: 3.2719 - val_accuracy500: 0.3851 - 59s/epoch - 38ms/step
Epoch 11/50
1542/1542 - 59s - loss: 3.2371 - accuracy500: 0.4063 - val_loss: 3.2721 - val_accuracy500: 0.3846 - 59s/epoch - 38ms/step
Epoch 12/50
1542/1542 - 63s - loss: 3.2371 - accuracy500: 0.4071 - val_loss: 3.2716 - val_accuracy500: 0.3829 - 63s/epoch - 41ms/step
Epoch 13/50
1542/1542 - 61s - loss: 3.2357 - accuracy500: 0.4074 - val_loss: 3.2742 - val_accuracy500: 0.3774 - 61s/epoch - 40ms/step
Epoch 14/50
1542/1542 - 59s - loss: 3.2343 - accuracy500: 0.4080 - val_loss: 3.2762 - val_accuracy500: 0.3746 - 59s/epoch - 39ms/step
Epoch 15/50
1542/1542 - 60s - loss: 3.2338 - accuracy500: 0.4086 - val_loss: 3.2738 - val_accuracy500: 0.3799 - 60s/epoch - 39ms/step
Epoch 16/50
1542/1542 - 59s - loss: 3.2337 - accuracy500: 0.4090 - val_loss: 3.2774 - val_accuracy500: 0.3705 - 59s/epoch - 38ms/step
testing model: results/WBA/W2/deepOF_L1/h500
Evaluating performance on  test set...
4353/4353 - 78s - 78s/epoch - 18ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0876987
{'0': {'precision': 0.43270198354575995, 'recall': 0.4434980658527363, 'f1-score': 0.4380335128374541, 'support': 446967}, '1': {'precision': 0.30324631538387437, 'recall': 0.03344240003399482, 'f1-score': 0.06024130969353096, 'support': 282396}, '2': {'precision': 0.37092353696915786, 'recall': 0.602293983165333, 'f1-score': 0.4591060269857348, 'support': 384920}, 'accuracy': 0.394431217204247, 'macro avg': {'precision': 0.3689572786329307, 'recall': 0.359744816350688, 'f1-score': 0.31912694983890666, 'support': 1114283}, 'weighted avg': {'precision': 0.3785527929698385, 'recall': 0.394431217204247, 'f1-score': 0.3495678583734848, 'support': 1114283}}
[[198229  11504 237234]
 [117000   9444 155952]
 [142890  10195 231835]]
Evaluating performance on  train set...
1542/1542 - 30s - 30s/epoch - 20ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0938295
{'0': {'precision': 0.3839253311558701, 'recall': 0.47797081600813257, 'f1-score': 0.4258172041320105, 'support': 141653}, '1': {'precision': 0.33417047184170473, 'recall': 0.03647767393561786, 'f1-score': 0.06577538104332847, 'support': 120375}, '2': {'precision': 0.35960403764568194, 'recall': 0.5564157121946066, 'f1-score': 0.43686686176704065, 'support': 132534}, 'accuracy': 0.3696275870458889, 'macro avg': {'precision': 0.3592332802144189, 'recall': 0.356954734046119, 'f1-score': 0.30948648231412657, 'support': 394562}, 'weighted avg': {'precision': 0.3605763023491884, 'recall': 0.3696275870458889, 'f1-score': 0.3196853943548424, 'support': 394562}}
[[67706  4281 69666]
 [54324  4391 61660]
 [54322  4468 73744]]
Evaluating performance on  val set...
482/482 - 10s - 10s/epoch - 20ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0902616
{'0': {'precision': 0.3899617501632615, 'recall': 0.46590427784836935, 'f1-score': 0.42456375566254295, 'support': 44859}, '1': {'precision': 0.32141605327725203, 'recall': 0.026992023077149502, 'f1-score': 0.049801770488242005, 'support': 33973}, '2': {'precision': 0.3851423101658665, 'recall': 0.5789734019830474, 'f1-score': 0.4625734250660152, 'support': 44477}, 'accuracy': 0.3857625964041554, 'macro avg': {'precision': 0.36550670453546, 'recall': 0.35728990096952207, 'f1-score': 0.3123129837389334, 'support': 123309}, 'weighted avg': {'precision': 0.36933829856546624, 'recall': 0.3857625964041554, 'f1-score': 0.3350225797851269, 'support': 123309}}
[[20900   935 23024]
 [14970   917 18086]
 [17725  1001 25751]]
training model: results/WBA/W2/deepOF_L1/h1000
Epoch 1/50
1542/1542 - 66s - loss: 3.3162 - accuracy1000: 0.3586 - val_loss: 3.4159 - val_accuracy1000: 0.3226 - 66s/epoch - 43ms/step
Epoch 2/50
1542/1542 - 61s - loss: 3.3015 - accuracy1000: 0.3550 - val_loss: 3.3666 - val_accuracy1000: 0.3229 - 61s/epoch - 39ms/step
Epoch 3/50
1542/1542 - 61s - loss: 3.2977 - accuracy1000: 0.3542 - val_loss: 3.3196 - val_accuracy1000: 0.3236 - 61s/epoch - 39ms/step
Epoch 4/50
1542/1542 - 63s - loss: 3.2952 - accuracy1000: 0.3541 - val_loss: 3.3169 - val_accuracy1000: 0.3237 - 63s/epoch - 41ms/step
Epoch 5/50
1542/1542 - 63s - loss: 3.2943 - accuracy1000: 0.3530 - val_loss: 3.3156 - val_accuracy1000: 0.3246 - 63s/epoch - 41ms/step
Epoch 6/50
1542/1542 - 60s - loss: 3.2932 - accuracy1000: 0.3541 - val_loss: 3.3141 - val_accuracy1000: 0.3250 - 60s/epoch - 39ms/step
Epoch 7/50
1542/1542 - 60s - loss: 3.2923 - accuracy1000: 0.3554 - val_loss: 3.3140 - val_accuracy1000: 0.3252 - 60s/epoch - 39ms/step
Epoch 8/50
1542/1542 - 58s - loss: 3.2917 - accuracy1000: 0.3558 - val_loss: 3.3137 - val_accuracy1000: 0.3255 - 58s/epoch - 38ms/step
Epoch 9/50
1542/1542 - 61s - loss: 3.2911 - accuracy1000: 0.3566 - val_loss: 3.3137 - val_accuracy1000: 0.3266 - 61s/epoch - 40ms/step
Epoch 10/50
1542/1542 - 65s - loss: 3.2905 - accuracy1000: 0.3574 - val_loss: 3.3139 - val_accuracy1000: 0.3266 - 65s/epoch - 42ms/step
Epoch 11/50
1542/1542 - 64s - loss: 3.2901 - accuracy1000: 0.3580 - val_loss: 3.3137 - val_accuracy1000: 0.3263 - 64s/epoch - 41ms/step
Epoch 12/50
1542/1542 - 63s - loss: 3.2893 - accuracy1000: 0.3589 - val_loss: 3.3135 - val_accuracy1000: 0.3273 - 63s/epoch - 41ms/step
Epoch 13/50
1542/1542 - 63s - loss: 3.2886 - accuracy1000: 0.3599 - val_loss: 3.3150 - val_accuracy1000: 0.3267 - 63s/epoch - 41ms/step
Epoch 14/50
1542/1542 - 61s - loss: 3.2882 - accuracy1000: 0.3599 - val_loss: 3.3153 - val_accuracy1000: 0.3271 - 61s/epoch - 40ms/step
Epoch 15/50
1542/1542 - 64s - loss: 3.2878 - accuracy1000: 0.3604 - val_loss: 3.3155 - val_accuracy1000: 0.3268 - 64s/epoch - 41ms/step
Epoch 16/50
1542/1542 - 63s - loss: 3.2866 - accuracy1000: 0.3624 - val_loss: 3.3181 - val_accuracy1000: 0.3272 - 63s/epoch - 41ms/step
Epoch 17/50
1542/1542 - 64s - loss: 3.2862 - accuracy1000: 0.3621 - val_loss: 3.3170 - val_accuracy1000: 0.3266 - 64s/epoch - 42ms/step
Epoch 18/50
1542/1542 - 63s - loss: 3.2853 - accuracy1000: 0.3636 - val_loss: 3.3166 - val_accuracy1000: 0.3266 - 63s/epoch - 41ms/step
Epoch 19/50
1542/1542 - 64s - loss: 3.2849 - accuracy1000: 0.3646 - val_loss: 3.3176 - val_accuracy1000: 0.3266 - 64s/epoch - 42ms/step
Epoch 20/50
1542/1542 - 66s - loss: 3.2842 - accuracy1000: 0.3639 - val_loss: 3.3179 - val_accuracy1000: 0.3267 - 66s/epoch - 43ms/step
Epoch 21/50
1542/1542 - 65s - loss: 3.2829 - accuracy1000: 0.3656 - val_loss: 3.3194 - val_accuracy1000: 0.3278 - 65s/epoch - 42ms/step
Epoch 22/50
1542/1542 - 64s - loss: 3.2829 - accuracy1000: 0.3663 - val_loss: 3.3197 - val_accuracy1000: 0.3272 - 64s/epoch - 41ms/step
testing model: results/WBA/W2/deepOF_L1/h1000
Evaluating performance on  test set...
4353/4353 - 86s - 86s/epoch - 20ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0966398
{'0': {'precision': 0.39818193322506484, 'recall': 0.048003844579321144, 'f1-score': 0.08567849800541873, 'support': 393281}, '1': {'precision': 0.3472068510699585, 'recall': 0.9486002599110503, 'f1-score': 0.5083480502256437, 'support': 386286}, '2': {'precision': 0.37054425317336115, 'recall': 0.012733182757920148, 'f1-score': 0.024620325921818047, 'support': 334716}, 'accuracy': 0.34961674906644, 'macro avg': {'precision': 0.37197767915612817, 'recall': 0.33644576241609725, 'f1-score': 0.2062156247176268, 'support': 1114283}, 'weighted avg': {'precision': 0.37220851866022503, 'recall': 0.34961674906644, 'f1-score': 0.21386333392394868, 'support': 1114283}}
[[ 18879 371119   3283]
 [ 15898 366431   3957]
 [ 12636 317818   4262]]
Evaluating performance on  train set...
1542/1542 - 32s - 32s/epoch - 21ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.0998617
{'0': {'precision': 0.3966794656860094, 'recall': 0.05359139030752033, 'f1-score': 0.09442584963954687, 'support': 136869}, '1': {'precision': 0.33302577550436785, 'recall': 0.9434135306166122, 'f1-score': 0.4922772608901987, 'support': 130844}, '2': {'precision': 0.40672952486596414, 'recall': 0.017343455604695347, 'f1-score': 0.033268308911370205, 'support': 126849}, 'accuracy': 0.337019277071791, 'macro avg': {'precision': 0.3788115886854471, 'recall': 0.3381161255096093, 'f1-score': 0.20665713981370526, 'support': 394562}, 'weighted avg': {'precision': 0.3788017595683178, 'recall': 0.337019277071791, 'f1-score': 0.20669894529967583, 'support': 394562}}
[[  7335 127936   1598]
 [  5793 123440   1611]
 [  5363 119286   2200]]
Evaluating performance on  val set...
482/482 - 11s - 11s/epoch - 23ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1028643
{'0': {'precision': 0.3793563448390862, 'recall': 0.05454065976217875, 'f1-score': 0.09536984636022554, 'support': 41712}, '1': {'precision': 0.3236267144530981, 'recall': 0.9442224065555639, 'f1-score': 0.48203779153700554, 'support': 39783}, '2': {'precision': 0.38064516129032255, 'recall': 0.011288085330272158, 'f1-score': 0.021925953453802202, 'support': 41814}, 'accuracy': 0.3269104444931027, 'macro avg': {'precision': 0.36120940686083564, 'recall': 0.33668371721600493, 'f1-score': 0.19977786378367776, 'support': 123309}, 'weighted avg': {'precision': 0.36181341354815233, 'recall': 0.3269104444931027, 'f1-score': 0.19521517739833832, 'support': 123309}}
[[ 2275 39068   369]
 [ 1820 37564   399]
 [ 1902 39440   472]]
training model: results/WBA/W2/deepLOB_L2/h10
Epoch 1/50
1542/1542 - 129s - loss: 3.0496 - accuracy10: 0.4415 - val_loss: 3.3838 - val_accuracy10: 0.5498 - 129s/epoch - 84ms/step
Epoch 2/50
1542/1542 - 120s - loss: 2.9169 - accuracy10: 0.4648 - val_loss: 3.1875 - val_accuracy10: 0.5732 - 120s/epoch - 78ms/step
Epoch 3/50
1542/1542 - 115s - loss: 2.8498 - accuracy10: 0.4948 - val_loss: 3.1933 - val_accuracy10: 0.5456 - 115s/epoch - 75ms/step
Epoch 4/50
1542/1542 - 114s - loss: 2.7864 - accuracy10: 0.5281 - val_loss: 3.1553 - val_accuracy10: 0.5662 - 114s/epoch - 74ms/step
Epoch 5/50
1542/1542 - 121s - loss: 2.7132 - accuracy10: 0.5570 - val_loss: 3.0336 - val_accuracy10: 0.5764 - 121s/epoch - 79ms/step
Epoch 6/50
1542/1542 - 119s - loss: 2.6543 - accuracy10: 0.5782 - val_loss: 3.0444 - val_accuracy10: 0.5856 - 119s/epoch - 77ms/step
Epoch 7/50
1542/1542 - 119s - loss: 2.6097 - accuracy10: 0.5920 - val_loss: 3.0881 - val_accuracy10: 0.5606 - 119s/epoch - 77ms/step
Epoch 8/50
1542/1542 - 125s - loss: 2.5762 - accuracy10: 0.6007 - val_loss: 3.1164 - val_accuracy10: 0.5499 - 125s/epoch - 81ms/step
Epoch 9/50
1542/1542 - 126s - loss: 2.5556 - accuracy10: 0.6063 - val_loss: 3.0572 - val_accuracy10: 0.5466 - 126s/epoch - 82ms/step
Epoch 10/50
1542/1542 - 125s - loss: 2.5377 - accuracy10: 0.6105 - val_loss: 3.1056 - val_accuracy10: 0.5411 - 125s/epoch - 81ms/step
Epoch 11/50
1542/1542 - 124s - loss: 2.5207 - accuracy10: 0.6133 - val_loss: 3.0603 - val_accuracy10: 0.5443 - 124s/epoch - 80ms/step
Epoch 12/50
1542/1542 - 123s - loss: 2.5057 - accuracy10: 0.6158 - val_loss: 2.9953 - val_accuracy10: 0.5511 - 123s/epoch - 80ms/step
Epoch 13/50
1542/1542 - 126s - loss: 2.4934 - accuracy10: 0.6183 - val_loss: 2.9887 - val_accuracy10: 0.5422 - 126s/epoch - 82ms/step
Epoch 14/50
1542/1542 - 124s - loss: 2.4838 - accuracy10: 0.6190 - val_loss: 2.9721 - val_accuracy10: 0.5467 - 124s/epoch - 81ms/step
Epoch 15/50
1542/1542 - 130s - loss: 2.4737 - accuracy10: 0.6198 - val_loss: 2.9503 - val_accuracy10: 0.5467 - 130s/epoch - 84ms/step
Epoch 16/50
1542/1542 - 127s - loss: 2.4640 - accuracy10: 0.6218 - val_loss: 2.9484 - val_accuracy10: 0.5448 - 127s/epoch - 83ms/step
Epoch 17/50
1542/1542 - 127s - loss: 2.4546 - accuracy10: 0.6220 - val_loss: 2.9425 - val_accuracy10: 0.5429 - 127s/epoch - 82ms/step
Epoch 18/50
1542/1542 - 129s - loss: 2.4456 - accuracy10: 0.6233 - val_loss: 2.9400 - val_accuracy10: 0.5536 - 129s/epoch - 84ms/step
Epoch 19/50
1542/1542 - 130s - loss: 2.4371 - accuracy10: 0.6241 - val_loss: 2.9602 - val_accuracy10: 0.5505 - 130s/epoch - 85ms/step
Epoch 20/50
1542/1542 - 133s - loss: 2.4303 - accuracy10: 0.6253 - val_loss: 2.9689 - val_accuracy10: 0.5571 - 133s/epoch - 87ms/step
Epoch 21/50
1542/1542 - 134s - loss: 2.4225 - accuracy10: 0.6266 - val_loss: 2.9606 - val_accuracy10: 0.5510 - 134s/epoch - 87ms/step
Epoch 22/50
1542/1542 - 127s - loss: 2.4167 - accuracy10: 0.6267 - val_loss: 2.9971 - val_accuracy10: 0.5430 - 127s/epoch - 83ms/step
Epoch 23/50
1542/1542 - 134s - loss: 2.4098 - accuracy10: 0.6274 - val_loss: 2.9468 - val_accuracy10: 0.5615 - 134s/epoch - 87ms/step
Epoch 24/50
1542/1542 - 132s - loss: 2.4036 - accuracy10: 0.6286 - val_loss: 2.9684 - val_accuracy10: 0.5568 - 132s/epoch - 86ms/step
Epoch 25/50
1542/1542 - 136s - loss: 2.3977 - accuracy10: 0.6286 - val_loss: 2.9674 - val_accuracy10: 0.5553 - 136s/epoch - 89ms/step
Epoch 26/50
1542/1542 - 134s - loss: 2.3904 - accuracy10: 0.6293 - val_loss: 3.0373 - val_accuracy10: 0.5503 - 134s/epoch - 87ms/step
Epoch 27/50
1542/1542 - 132s - loss: 2.3846 - accuracy10: 0.6297 - val_loss: 3.0387 - val_accuracy10: 0.5495 - 132s/epoch - 85ms/step
Epoch 28/50
1542/1542 - 138s - loss: 2.3792 - accuracy10: 0.6305 - val_loss: 2.9882 - val_accuracy10: 0.5590 - 138s/epoch - 89ms/step
testing model: results/WBA/W2/deepLOB_L2/h10
Evaluating performance on  test set...
4353/4353 - 180s - 180s/epoch - 41ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.90579313
{'0': {'precision': 0.32200844887020336, 'recall': 0.6815637385294149, 'f1-score': 0.43737617483941293, 'support': 187218}, '1': {'precision': 0.8359572872588704, 'recall': 0.5903638547283012, 'f1-score': 0.6920166180903449, 'support': 740213}, '2': {'precision': 0.43674017022235423, 'recall': 0.4564131929764472, 'f1-score': 0.4463600178996208, 'support': 186857}, 'accuracy': 0.5832244446678058, 'macro avg': {'precision': 0.531568635450476, 'recall': 0.5761135954113877, 'f1-score': 0.5252509369431262, 'support': 1114288}, 'weighted avg': {'precision': 0.682660306170012, 'recall': 0.5832244446678058, 'f1-score': 0.6080383917732787, 'support': 1114288}}
[[127601  33618  25999]
 [219227 436995  83991]
 [ 49438  52135  85284]]
Evaluating performance on  train set...
1542/1542 - 65s - 65s/epoch - 42ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.93269086
{'0': {'precision': 0.35709042748408304, 'recall': 0.5979559118236473, 'f1-score': 0.44714967930145666, 'support': 74850}, '1': {'precision': 0.7833654375343974, 'recall': 0.6441495680563749, 'f1-score': 0.7069691123971706, 'support': 247486}, '2': {'precision': 0.4428417096514052, 'recall': 0.40295180472676423, 'f1-score': 0.4219560993997738, 'support': 72227}, 'accuracy': 0.5912338460524682, 'macro avg': {'precision': 0.5277658582232952, 'recall': 0.5483524282022622, 'f1-score': 0.5253582970328003, 'support': 394563}, 'weighted avg': {'precision': 0.6401647527360993, 'recall': 0.5912338460524682, 'f1-score': 0.6055071926100208, 'support': 394563}}
[[ 44757  19698  10395]
 [ 61846 159418  26222]
 [ 18735  24388  29104]]
Evaluating performance on  val set...
482/482 - 20s - 20s/epoch - 42ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 1.0098257
{'0': {'precision': 0.3215203312453551, 'recall': 0.6836426023748251, 'f1-score': 0.4373519727340997, 'support': 22149}, '1': {'precision': 0.8152568857427942, 'recall': 0.5467469666553034, 'f1-score': 0.65453446191052, 'support': 79203}, '2': {'precision': 0.42687678586890637, 'recall': 0.44903907459695785, 'f1-score': 0.43767755681818177, 'support': 21958}, 'accuracy': 0.5539372313680967, 'macro avg': {'precision': 0.5212180009523519, 'recall': 0.5598095478756955, 'f1-score': 0.5098546638209339, 'support': 123310}, 'weighted avg': {'precision': 0.6574122569325225, 'recall': 0.5539372313680967, 'f1-score': 0.5769080011629237, 'support': 123310}}
[[15142  4036  2971]
 [25632 43304 10267]
 [ 6321  5777  9860]]
training model: results/WBA/W2/deepLOB_L2/h20
Epoch 1/50
1542/1542 - 143s - loss: 3.1160 - accuracy20: 0.4407 - val_loss: 3.3434 - val_accuracy20: 0.4916 - 143s/epoch - 93ms/step
Epoch 2/50
1542/1542 - 139s - loss: 2.9929 - accuracy20: 0.4686 - val_loss: 3.1807 - val_accuracy20: 0.4500 - 139s/epoch - 90ms/step
Epoch 3/50
1542/1542 - 139s - loss: 2.9160 - accuracy20: 0.4964 - val_loss: 3.1687 - val_accuracy20: 0.5088 - 139s/epoch - 90ms/step
Epoch 4/50
1542/1542 - 139s - loss: 2.8439 - accuracy20: 0.5247 - val_loss: 3.1248 - val_accuracy20: 0.4754 - 139s/epoch - 90ms/step
Epoch 5/50
1542/1542 - 138s - loss: 2.7879 - accuracy20: 0.5489 - val_loss: 3.1865 - val_accuracy20: 0.5148 - 138s/epoch - 90ms/step
Epoch 6/50
1542/1542 - 138s - loss: 2.7332 - accuracy20: 0.5667 - val_loss: 3.0612 - val_accuracy20: 0.5462 - 138s/epoch - 89ms/step
Epoch 7/50
1542/1542 - 139s - loss: 2.6945 - accuracy20: 0.5767 - val_loss: 3.0956 - val_accuracy20: 0.5457 - 139s/epoch - 90ms/step
Epoch 8/50
1542/1542 - 136s - loss: 2.6643 - accuracy20: 0.5834 - val_loss: 3.0442 - val_accuracy20: 0.5464 - 136s/epoch - 88ms/step
Epoch 9/50
1542/1542 - 138s - loss: 2.6394 - accuracy20: 0.5895 - val_loss: 3.0738 - val_accuracy20: 0.5608 - 138s/epoch - 89ms/step
Epoch 10/50
1542/1542 - 134s - loss: 2.6218 - accuracy20: 0.5943 - val_loss: 3.0223 - val_accuracy20: 0.5648 - 134s/epoch - 87ms/step
Epoch 11/50
1542/1542 - 137s - loss: 2.6063 - accuracy20: 0.5968 - val_loss: 3.0208 - val_accuracy20: 0.5633 - 137s/epoch - 89ms/step
Epoch 12/50
1542/1542 - 138s - loss: 2.5938 - accuracy20: 0.5997 - val_loss: 3.0006 - val_accuracy20: 0.5727 - 138s/epoch - 89ms/step
Epoch 13/50
1542/1542 - 139s - loss: 2.5833 - accuracy20: 0.6003 - val_loss: 3.0095 - val_accuracy20: 0.5811 - 139s/epoch - 90ms/step
Epoch 14/50
1542/1542 - 146s - loss: 2.5713 - accuracy20: 0.6025 - val_loss: 2.9760 - val_accuracy20: 0.5836 - 146s/epoch - 94ms/step
Epoch 15/50
1542/1542 - 138s - loss: 2.5634 - accuracy20: 0.6037 - val_loss: 2.9786 - val_accuracy20: 0.5842 - 138s/epoch - 89ms/step
Epoch 16/50
1542/1542 - 135s - loss: 2.5554 - accuracy20: 0.6042 - val_loss: 2.9580 - val_accuracy20: 0.5821 - 135s/epoch - 87ms/step
Epoch 17/50
1542/1542 - 136s - loss: 2.5467 - accuracy20: 0.6055 - val_loss: 2.9333 - val_accuracy20: 0.5879 - 136s/epoch - 88ms/step
Epoch 18/50
1542/1542 - 133s - loss: 2.5393 - accuracy20: 0.6069 - val_loss: 2.9298 - val_accuracy20: 0.5970 - 133s/epoch - 86ms/step
Epoch 19/50
1542/1542 - 137s - loss: 2.5335 - accuracy20: 0.6076 - val_loss: 2.9285 - val_accuracy20: 0.5924 - 137s/epoch - 89ms/step
Epoch 20/50
1542/1542 - 137s - loss: 2.5280 - accuracy20: 0.6085 - val_loss: 2.9550 - val_accuracy20: 0.5888 - 137s/epoch - 89ms/step
Epoch 21/50
1542/1542 - 142s - loss: 2.5214 - accuracy20: 0.6094 - val_loss: 2.9633 - val_accuracy20: 0.5970 - 142s/epoch - 92ms/step
Epoch 22/50
1542/1542 - 143s - loss: 2.5161 - accuracy20: 0.6105 - val_loss: 2.9922 - val_accuracy20: 0.5931 - 143s/epoch - 93ms/step
Epoch 23/50
1542/1542 - 146s - loss: 2.5102 - accuracy20: 0.6115 - val_loss: 2.9987 - val_accuracy20: 0.5910 - 146s/epoch - 95ms/step
Epoch 24/50
1542/1542 - 147s - loss: 2.5049 - accuracy20: 0.6123 - val_loss: 2.9994 - val_accuracy20: 0.5947 - 147s/epoch - 95ms/step
Epoch 25/50
1542/1542 - 144s - loss: 2.4987 - accuracy20: 0.6135 - val_loss: 3.0321 - val_accuracy20: 0.5865 - 144s/epoch - 93ms/step
Epoch 26/50
1542/1542 - 142s - loss: 2.4943 - accuracy20: 0.6130 - val_loss: 3.0271 - val_accuracy20: 0.5876 - 142s/epoch - 92ms/step
Epoch 27/50
1542/1542 - 144s - loss: 2.4902 - accuracy20: 0.6145 - val_loss: 3.0237 - val_accuracy20: 0.5880 - 144s/epoch - 94ms/step
Epoch 28/50
1542/1542 - 149s - loss: 2.4826 - accuracy20: 0.6160 - val_loss: 3.0492 - val_accuracy20: 0.5871 - 149s/epoch - 97ms/step
Epoch 29/50
1542/1542 - 149s - loss: 2.4767 - accuracy20: 0.6161 - val_loss: 3.0905 - val_accuracy20: 0.5861 - 149s/epoch - 96ms/step
testing model: results/WBA/W2/deepLOB_L2/h20
Evaluating performance on  test set...
4353/4353 - 188s - 188s/epoch - 43ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.8259271
{'0': {'precision': 0.4740572580676672, 'recall': 0.5046398163206735, 'f1-score': 0.4888707116780968, 'support': 240419}, '1': {'precision': 0.7281921716243484, 'recall': 0.7441577749459523, 'f1-score': 0.7360884108174377, 'support': 630924}, '2': {'precision': 0.5041993988820329, 'recall': 0.4433019819300665, 'f1-score': 0.47179370360554335, 'support': 242945}, 'accuracy': 0.6268846115187456, 'macro avg': {'precision': 0.5688162761913494, 'recall': 0.564033191065564, 'f1-score': 0.5655842753670259, 'support': 1114288}, 'weighted avg': {'precision': 0.6245234738045159, 'recall': 0.6268846115187456, 'f1-score': 0.6251252579763635, 'support': 1114288}}
[[121325  80078  39016]
 [ 94529 469507  66888]
 [ 40075  95172 107698]]
Evaluating performance on  train set...
1542/1542 - 63s - 63s/epoch - 41ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.9019019
{'0': {'precision': 0.4755865431913938, 'recall': 0.4674732228260298, 'f1-score': 0.47149498279892504, 'support': 95137}, '1': {'precision': 0.6649478068854763, 'recall': 0.7686287211517079, 'f1-score': 0.7130389936542817, 'support': 206858}, '2': {'precision': 0.5251788107270291, 'recall': 0.35139573070607555, 'f1-score': 0.4210608070936216, 'support': 92568}, 'accuracy': 0.5981275487057833, 'macro avg': {'precision': 0.5552377202679665, 'recall': 0.529165891561271, 'f1-score': 0.5351982611822761, 'support': 394563}, 'weighted avg': {'precision': 0.5864979801646255, 'recall': 0.5981275487057833, 'f1-score': 0.5862972329359851, 'support': 394563}}
[[ 44474  37345  13318]
 [ 31770 158997  16091]
 [ 17270  42770  32528]]
Evaluating performance on  val set...
482/482 - 21s - 21s/epoch - 43ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.896281
{'0': {'precision': 0.45412246417271546, 'recall': 0.5089872405520982, 'f1-score': 0.4799921312765365, 'support': 28763}, '1': {'precision': 0.6881393909018544, 'recall': 0.7054219052224371, 'f1-score': 0.696673481875028, 'support': 66176}, '2': {'precision': 0.5040027545837996, 'recall': 0.4127454090444468, 'f1-score': 0.4538319930239318, 'support': 28371}, 'accuracy': 0.5922634011840078, 'macro avg': {'precision': 0.5487548698861232, 'recall': 0.5423848516063274, 'f1-score': 0.5434992020584988, 'support': 123310}, 'weighted avg': {'precision': 0.5911872428806902, 'recall': 0.5922634011840078, 'f1-score': 0.5902582554744209, 'support': 123310}}
[[14640  9805  4318]
 [12288 46682  7206]
 [ 5310 11351 11710]]
training model: results/WBA/W2/deepLOB_L2/h30
Epoch 1/50
1542/1542 - 161s - loss: 3.1413 - accuracy30: 0.4423 - val_loss: 3.6368 - val_accuracy30: 0.4218 - 161s/epoch - 104ms/step
Epoch 2/50
1542/1542 - 150s - loss: 3.0560 - accuracy30: 0.4633 - val_loss: 3.2981 - val_accuracy30: 0.4507 - 150s/epoch - 98ms/step
Epoch 3/50
1542/1542 - 150s - loss: 3.0040 - accuracy30: 0.4837 - val_loss: 3.2799 - val_accuracy30: 0.4396 - 150s/epoch - 97ms/step
Epoch 4/50
1542/1542 - 146s - loss: 2.9561 - accuracy30: 0.4997 - val_loss: 3.2943 - val_accuracy30: 0.4581 - 146s/epoch - 95ms/step
Epoch 5/50
1542/1542 - 145s - loss: 2.9125 - accuracy30: 0.5159 - val_loss: 3.3080 - val_accuracy30: 0.4630 - 145s/epoch - 94ms/step
Epoch 6/50
1542/1542 - 150s - loss: 2.8694 - accuracy30: 0.5324 - val_loss: 3.2814 - val_accuracy30: 0.4929 - 150s/epoch - 97ms/step
Epoch 7/50
1542/1542 - 147s - loss: 2.8275 - accuracy30: 0.5454 - val_loss: 3.2617 - val_accuracy30: 0.4948 - 147s/epoch - 95ms/step
Epoch 8/50
1542/1542 - 152s - loss: 2.7923 - accuracy30: 0.5545 - val_loss: 3.1446 - val_accuracy30: 0.5192 - 152s/epoch - 99ms/step
Epoch 9/50
1542/1542 - 152s - loss: 2.7608 - accuracy30: 0.5617 - val_loss: 3.1623 - val_accuracy30: 0.5120 - 152s/epoch - 99ms/step
Epoch 10/50
1542/1542 - 149s - loss: 2.7363 - accuracy30: 0.5677 - val_loss: 3.1213 - val_accuracy30: 0.5197 - 149s/epoch - 97ms/step
Epoch 11/50
1542/1542 - 147s - loss: 2.7185 - accuracy30: 0.5717 - val_loss: 3.0866 - val_accuracy30: 0.5253 - 147s/epoch - 95ms/step
Epoch 12/50
1542/1542 - 142s - loss: 2.7065 - accuracy30: 0.5742 - val_loss: 3.0922 - val_accuracy30: 0.5237 - 142s/epoch - 92ms/step
Epoch 13/50
1542/1542 - 149s - loss: 2.6919 - accuracy30: 0.5775 - val_loss: 3.0457 - val_accuracy30: 0.5306 - 149s/epoch - 97ms/step
Epoch 14/50
1542/1542 - 144s - loss: 2.6813 - accuracy30: 0.5791 - val_loss: 3.0509 - val_accuracy30: 0.5382 - 144s/epoch - 94ms/step
Epoch 15/50
1542/1542 - 149s - loss: 2.6729 - accuracy30: 0.5798 - val_loss: 3.0520 - val_accuracy30: 0.5309 - 149s/epoch - 96ms/step
Epoch 16/50
1542/1542 - 150s - loss: 2.6649 - accuracy30: 0.5821 - val_loss: 3.0547 - val_accuracy30: 0.5465 - 150s/epoch - 97ms/step
Epoch 17/50
1542/1542 - 150s - loss: 2.6556 - accuracy30: 0.5836 - val_loss: 3.0469 - val_accuracy30: 0.5418 - 150s/epoch - 97ms/step
Epoch 18/50
1542/1542 - 154s - loss: 2.6474 - accuracy30: 0.5852 - val_loss: 3.0252 - val_accuracy30: 0.5482 - 154s/epoch - 100ms/step
Epoch 19/50
1542/1542 - 152s - loss: 2.6427 - accuracy30: 0.5863 - val_loss: 3.0490 - val_accuracy30: 0.5478 - 152s/epoch - 99ms/step
Epoch 20/50
1542/1542 - 148s - loss: 2.6357 - accuracy30: 0.5870 - val_loss: 3.0751 - val_accuracy30: 0.5514 - 148s/epoch - 96ms/step
Epoch 21/50
1542/1542 - 154s - loss: 2.6283 - accuracy30: 0.5881 - val_loss: 3.0577 - val_accuracy30: 0.5538 - 154s/epoch - 100ms/step
Epoch 22/50
1542/1542 - 157s - loss: 2.6235 - accuracy30: 0.5887 - val_loss: 3.0451 - val_accuracy30: 0.5477 - 157s/epoch - 102ms/step
Epoch 23/50
1542/1542 - 150s - loss: 2.6175 - accuracy30: 0.5901 - val_loss: 3.0483 - val_accuracy30: 0.5500 - 150s/epoch - 97ms/step
Epoch 24/50
1542/1542 - 150s - loss: 2.6115 - accuracy30: 0.5904 - val_loss: 3.0833 - val_accuracy30: 0.5445 - 150s/epoch - 97ms/step
Epoch 25/50
1542/1542 - 149s - loss: 2.6070 - accuracy30: 0.5917 - val_loss: 3.0687 - val_accuracy30: 0.5463 - 149s/epoch - 97ms/step
Epoch 26/50
1542/1542 - 154s - loss: 2.6002 - accuracy30: 0.5934 - val_loss: 3.0922 - val_accuracy30: 0.5435 - 154s/epoch - 100ms/step
Epoch 27/50
1542/1542 - 155s - loss: 2.5955 - accuracy30: 0.5942 - val_loss: 3.1364 - val_accuracy30: 0.5494 - 155s/epoch - 101ms/step
Epoch 28/50
1542/1542 - 152s - loss: 2.5911 - accuracy30: 0.5946 - val_loss: 3.1048 - val_accuracy30: 0.5412 - 152s/epoch - 98ms/step
testing model: results/WBA/W2/deepLOB_L2/h30
Evaluating performance on  test set...
4353/4353 - 205s - 205s/epoch - 47ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.89933103
{'0': {'precision': 0.48757294619907554, 'recall': 0.4774050457443859, 'f1-score': 0.4824354267709201, 'support': 277739}, '1': {'precision': 0.6607722031424255, 'recall': 0.6973505667073385, 'f1-score': 0.6785688018128136, 'support': 555666}, '2': {'precision': 0.4936756344880136, 'recall': 0.44979226225866287, 'f1-score': 0.47071337821675935, 'support': 280883}, 'accuracy': 0.5801256048705541, 'macro avg': {'precision': 0.5473402612765048, 'recall': 0.5415159582367958, 'f1-score': 0.5439058689334978, 'support': 1114288}, 'weighted avg': {'precision': 0.5754811707364889, 'recall': 0.5801256048705541, 'f1-score': 0.5772871381884267, 'support': 1114288}}
[[132594  93109  52036]
 [ 90632 387494  77540]
 [ 48721 105823 126339]]
Evaluating performance on  train set...
1542/1542 - 69s - 69s/epoch - 45ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.9798977
{'0': {'precision': 0.49181383681909085, 'recall': 0.4007863430444551, 'f1-score': 0.44165859152642983, 'support': 108604}, '1': {'precision': 0.5827422653496367, 'recall': 0.7455117321234725, 'f1-score': 0.6541537935498053, 'support': 179635}, '2': {'precision': 0.5024, 'recall': 0.3602949475189045, 'f1-score': 0.4196435417967509, 'support': 106324}, 'accuracy': 0.5468201529286831, 'macro avg': {'precision': 0.5256520340562425, 'recall': 0.5021976742289441, 'f1-score': 0.5051519756243287, 'support': 394563}, 'weighted avg': {'precision': 0.5360640363388927, 'recall': 0.5468201529286831, 'f1-score': 0.5324700651517081, 'support': 394563}}
[[ 43527  46613  18464]
 [ 26237 133920  19478]
 [ 18739  49277  38308]]
Evaluating performance on  val set...
482/482 - 22s - 22s/epoch - 45ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.95945346
{'0': {'precision': 0.4684241650845031, 'recall': 0.45449054780455395, 'f1-score': 0.46135217571233694, 'support': 33114}, '1': {'precision': 0.6101277584204413, 'recall': 0.6858799157425622, 'f1-score': 0.6457899654149387, 'support': 57443}, '2': {'precision': 0.498083139141547, 'recall': 0.40460415839770403, 'f1-score': 0.4465034788321906, 'support': 32753}, 'accuracy': 0.5490308977374098, 'macro avg': {'precision': 0.5255450208821638, 'recall': 0.5149915406482733, 'f1-score': 0.5178818733198222, 'support': 123310}, 'weighted avg': {'precision': 0.542313548664802, 'recall': 0.5490308977374098, 'f1-score': 0.5433270405649128, 'support': 123310}}
[[15050 11954  6110]
 [10800 39399  7244]
 [ 6279 13222 13252]]
training model: results/WBA/W2/deepLOB_L2/h50
Epoch 1/50
1542/1542 - 171s - loss: 3.2056 - accuracy50: 0.4221 - val_loss: 3.6344 - val_accuracy50: 0.3767 - 171s/epoch - 111ms/step
Epoch 2/50
1542/1542 - 160s - loss: 3.1285 - accuracy50: 0.4505 - val_loss: 3.4544 - val_accuracy50: 0.3866 - 160s/epoch - 104ms/step
Epoch 3/50
1542/1542 - 158s - loss: 3.0735 - accuracy50: 0.4695 - val_loss: 3.3762 - val_accuracy50: 0.4150 - 158s/epoch - 102ms/step
Epoch 4/50
1542/1542 - 156s - loss: 3.0421 - accuracy50: 0.4784 - val_loss: 3.3505 - val_accuracy50: 0.4252 - 156s/epoch - 101ms/step
Epoch 5/50
1542/1542 - 155s - loss: 3.0096 - accuracy50: 0.4880 - val_loss: 3.3333 - val_accuracy50: 0.4362 - 155s/epoch - 101ms/step
Epoch 6/50
1542/1542 - 155s - loss: 2.9855 - accuracy50: 0.4960 - val_loss: 3.2289 - val_accuracy50: 0.4559 - 155s/epoch - 101ms/step
Epoch 7/50
1542/1542 - 159s - loss: 2.9644 - accuracy50: 0.5029 - val_loss: 3.2900 - val_accuracy50: 0.4473 - 159s/epoch - 103ms/step
Epoch 8/50
1542/1542 - 161s - loss: 2.9432 - accuracy50: 0.5090 - val_loss: 3.2872 - val_accuracy50: 0.4497 - 161s/epoch - 105ms/step
Epoch 9/50
1542/1542 - 155s - loss: 2.9209 - accuracy50: 0.5152 - val_loss: 3.2750 - val_accuracy50: 0.4539 - 155s/epoch - 100ms/step
Epoch 10/50
1542/1542 - 157s - loss: 2.9047 - accuracy50: 0.5191 - val_loss: 3.2666 - val_accuracy50: 0.4583 - 157s/epoch - 101ms/step
Epoch 11/50
1542/1542 - 158s - loss: 2.8880 - accuracy50: 0.5231 - val_loss: 3.2674 - val_accuracy50: 0.4655 - 158s/epoch - 102ms/step
Epoch 12/50
1542/1542 - 161s - loss: 2.8735 - accuracy50: 0.5258 - val_loss: 3.3275 - val_accuracy50: 0.4574 - 161s/epoch - 104ms/step
Epoch 13/50
1542/1542 - 159s - loss: 2.8602 - accuracy50: 0.5288 - val_loss: 3.3119 - val_accuracy50: 0.4573 - 159s/epoch - 103ms/step
Epoch 14/50
1542/1542 - 163s - loss: 2.8479 - accuracy50: 0.5321 - val_loss: 3.3222 - val_accuracy50: 0.4547 - 163s/epoch - 106ms/step
Epoch 15/50
1542/1542 - 162s - loss: 2.8388 - accuracy50: 0.5338 - val_loss: 3.3187 - val_accuracy50: 0.4552 - 162s/epoch - 105ms/step
Epoch 16/50
1542/1542 - 160s - loss: 2.8294 - accuracy50: 0.5359 - val_loss: 3.3442 - val_accuracy50: 0.4495 - 160s/epoch - 104ms/step
testing model: results/WBA/W2/deepLOB_L2/h50
Evaluating performance on  test set...
4353/4353 - 204s - 204s/epoch - 47ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0241493
{'0': {'precision': 0.46107090084176494, 'recall': 0.4777983542794129, 'f1-score': 0.4692856144275129, 'support': 333714}, '1': {'precision': 0.5051489301335047, 'recall': 0.6604535479805316, 'f1-score': 0.5724548624931846, 'support': 447494}, '2': {'precision': 0.4845251207782152, 'recall': 0.2667797526119851, 'f1-score': 0.3440986380727781, 'support': 333080}, 'accuracy': 0.48807489625662304, 'macro avg': {'precision': 0.4835816505844949, 'recall': 0.46834388495730983, 'f1-score': 0.4619463716644918, 'support': 1114288}, 'weighted avg': {'precision': 0.48578334970266146, 'recall': 0.48807489625662304, 'f1-score': 0.47329745105293164, 'support': 1114288}}
[[159448 136093  38173]
 [ 95583 295549  56362]
 [ 90790 153431  88859]]
Evaluating performance on  train set...
1542/1542 - 74s - 74s/epoch - 48ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0800501
{'0': {'precision': 0.4388924826621335, 'recall': 0.458938641958801, 'f1-score': 0.44869177384316666, 'support': 127139}, '1': {'precision': 0.45630396573086046, 'recall': 0.6658164516603718, 'f1-score': 0.5415010414796705, 'support': 142709}, '2': {'precision': 0.49156098383380475, 'recall': 0.21040772962354168, 'f1-score': 0.2946804568271401, 'support': 124715}, 'accuracy': 0.45520740667523313, 'macro avg': {'precision': 0.4622524774089329, 'recall': 0.4450542744142381, 'f1-score': 0.4282910907166591, 'support': 394563}, 'weighted avg': {'precision': 0.4618376839630156, 'recall': 0.45520740667523313, 'f1-score': 0.4335793491441555, 'support': 394563}}
[[58349 54432 14358]
 [34907 95018 12784]
 [39690 58784 26241]]
Evaluating performance on  val set...
482/482 - 20s - 20s/epoch - 42ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0661726
{'0': {'precision': 0.41671047763693364, 'recall': 0.5508906507413509, 'f1-score': 0.4744969791031539, 'support': 38848}, '1': {'precision': 0.47899756298812196, 'recall': 0.5466450595655221, 'f1-score': 0.5105904251511092, 'support': 45664}, '2': {'precision': 0.496875, 'recall': 0.25408526212691374, 'f1-score': 0.3362324772331935, 'support': 38798}, 'accuracy': 0.4559322033898305, 'macro avg': {'precision': 0.46419434687501854, 'recall': 0.4505403241445956, 'f1-score': 0.4404399604958189, 'support': 123310}, 'weighted avg': {'precision': 0.4649993479971552, 'recall': 0.4559322033898305, 'f1-score': 0.44435980431427313, 'support': 123310}}
[[21401 12607  4840]
 [15560 24962  5142]
 [14396 14544  9858]]
training model: results/WBA/W2/deepLOB_L2/h100
Epoch 1/50
1542/1542 - 165s - loss: 3.2593 - accuracy100: 0.3941 - val_loss: 3.4171 - val_accuracy100: 0.3322 - 165s/epoch - 107ms/step
Epoch 2/50
1542/1542 - 156s - loss: 3.2170 - accuracy100: 0.4134 - val_loss: 3.4286 - val_accuracy100: 0.3235 - 156s/epoch - 101ms/step
Epoch 3/50
1542/1542 - 160s - loss: 3.1853 - accuracy100: 0.4272 - val_loss: 3.3835 - val_accuracy100: 0.3471 - 160s/epoch - 104ms/step
Epoch 4/50
1542/1542 - 168s - loss: 3.1646 - accuracy100: 0.4360 - val_loss: 3.3307 - val_accuracy100: 0.3717 - 168s/epoch - 109ms/step
Epoch 5/50
1542/1542 - 164s - loss: 3.1563 - accuracy100: 0.4374 - val_loss: 3.3643 - val_accuracy100: 0.3672 - 164s/epoch - 106ms/step
Epoch 6/50
1542/1542 - 165s - loss: 3.1443 - accuracy100: 0.4423 - val_loss: 3.3788 - val_accuracy100: 0.3601 - 165s/epoch - 107ms/step
Epoch 7/50
1542/1542 - 161s - loss: 3.1320 - accuracy100: 0.4480 - val_loss: 3.3825 - val_accuracy100: 0.3657 - 161s/epoch - 105ms/step
Epoch 8/50
1542/1542 - 163s - loss: 3.1224 - accuracy100: 0.4502 - val_loss: 3.4180 - val_accuracy100: 0.3550 - 163s/epoch - 106ms/step
Epoch 9/50
1542/1542 - 166s - loss: 3.1148 - accuracy100: 0.4548 - val_loss: 3.4231 - val_accuracy100: 0.3584 - 166s/epoch - 107ms/step
Epoch 10/50
1542/1542 - 159s - loss: 3.1069 - accuracy100: 0.4567 - val_loss: 3.4335 - val_accuracy100: 0.3613 - 159s/epoch - 103ms/step
Epoch 11/50
1542/1542 - 162s - loss: 3.0983 - accuracy100: 0.4595 - val_loss: 3.4763 - val_accuracy100: 0.3644 - 162s/epoch - 105ms/step
Epoch 12/50
1542/1542 - 162s - loss: 3.0880 - accuracy100: 0.4628 - val_loss: 3.4620 - val_accuracy100: 0.3782 - 162s/epoch - 105ms/step
Epoch 13/50
1542/1542 - 164s - loss: 3.0797 - accuracy100: 0.4665 - val_loss: 3.4923 - val_accuracy100: 0.3707 - 164s/epoch - 106ms/step
Epoch 14/50
1542/1542 - 163s - loss: 3.0705 - accuracy100: 0.4694 - val_loss: 3.5965 - val_accuracy100: 0.3678 - 163s/epoch - 105ms/step
testing model: results/WBA/W2/deepLOB_L2/h100
Evaluating performance on  test set...
4353/4353 - 210s - 210s/epoch - 48ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0931851
{'0': {'precision': 0.4670410120503097, 'recall': 0.1699994137491806, 'f1-score': 0.24926737779861682, 'support': 375266}, '1': {'precision': 0.36928334400652035, 'recall': 0.8274497321920078, 'f1-score': 0.5106625866342711, 'support': 383297}, '2': {'precision': 0.4525933156070142, 'recall': 0.15120669056152927, 'f1-score': 0.22668147308399833, 'support': 355725}, 'accuracy': 0.39015227661071467, 'macro avg': {'precision': 0.42963922388794806, 'recall': 0.38288527883423923, 'f1-score': 0.32887047917229545, 'support': 1114288}, 'weighted avg': {'precision': 0.42880168101069366, 'recall': 0.39015227661071467, 'f1-score': 0.3319727721010522, 'support': 1114288}}
[[ 63795 276565  34906]
 [ 35988 317159  30150]
 [ 36811 265126  53788]]
Evaluating performance on  train set...
1542/1542 - 78s - 78s/epoch - 50ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.1211885
{'0': {'precision': 0.4164610227515869, 'recall': 0.21631473660813513, 'f1-score': 0.28473485310252344, 'support': 134970}, '1': {'precision': 0.3431160704547933, 'recall': 0.7848033177941658, 'f1-score': 0.4774785029619195, 'support': 128278}, '2': {'precision': 0.44412238325281805, 'recall': 0.10501465940676998, 'f1-score': 0.16986419486958396, 'support': 131315}, 'accuracy': 0.36409648142375234, 'macro avg': {'precision': 0.4012331588197327, 'recall': 0.36871090460302364, 'f1-score': 0.310692516978009, 'support': 394563}, 'weighted avg': {'precision': 0.40182155519758683, 'recall': 0.36409648142375234, 'f1-score': 0.309168288145356, 'support': 394563}}
[[ 29196  96569   9205]
 [ 19550 100673   8055]
 [ 21359  96166  13790]]
Evaluating performance on  val set...
482/482 - 24s - 24s/epoch - 50ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.1131607
{'0': {'precision': 0.4053360080240722, 'recall': 0.2445477210563261, 'f1-score': 0.3050514810229778, 'support': 41313}, '1': {'precision': 0.35146351613798205, 'recall': 0.7456101628408868, 'f1-score': 0.47773412947831556, 'support': 40776}, '2': {'precision': 0.4501304603989563, 'recall': 0.12973969578612843, 'f1-score': 0.20142367519114157, 'support': 41221}, 'accuracy': 0.3718595409942422, 'macro avg': {'precision': 0.4023099948536702, 'recall': 0.37329919322778043, 'f1-score': 0.32806976189747833, 'support': 123310}, 'weighted avg': {'precision': 0.4024957468303157, 'recall': 0.3718595409942422, 'f1-score': 0.3275124808544653, 'support': 123310}}
[[10103 27557  3653]
 [ 7493 30403  2880]
 [ 7329 28544  5348]]
training model: results/WBA/W2/deepLOB_L2/h200
Epoch 1/50
1542/1542 - 170s - loss: 3.2920 - accuracy200: 0.3716 - val_loss: 3.3528 - val_accuracy200: 0.3318 - 170s/epoch - 110ms/step
Epoch 2/50
1542/1542 - 166s - loss: 3.2691 - accuracy200: 0.3792 - val_loss: 3.3224 - val_accuracy200: 0.3349 - 166s/epoch - 108ms/step
Epoch 3/50
1542/1542 - 163s - loss: 3.2569 - accuracy200: 0.3865 - val_loss: 3.3098 - val_accuracy200: 0.3458 - 163s/epoch - 105ms/step
Epoch 4/50
1542/1542 - 164s - loss: 3.2391 - accuracy200: 0.3980 - val_loss: 3.3321 - val_accuracy200: 0.3428 - 164s/epoch - 106ms/step
Epoch 5/50
1542/1542 - 162s - loss: 3.2281 - accuracy200: 0.4022 - val_loss: 3.3220 - val_accuracy200: 0.3423 - 162s/epoch - 105ms/step
Epoch 6/50
1542/1542 - 162s - loss: 3.2195 - accuracy200: 0.4073 - val_loss: 3.3314 - val_accuracy200: 0.3391 - 162s/epoch - 105ms/step
Epoch 7/50
1542/1542 - 166s - loss: 3.2091 - accuracy200: 0.4131 - val_loss: 3.3583 - val_accuracy200: 0.3439 - 166s/epoch - 107ms/step
Epoch 8/50
1542/1542 - 160s - loss: 3.2012 - accuracy200: 0.4172 - val_loss: 3.3578 - val_accuracy200: 0.3462 - 160s/epoch - 104ms/step
Epoch 9/50
1542/1542 - 166s - loss: 3.1914 - accuracy200: 0.4211 - val_loss: 3.3629 - val_accuracy200: 0.3405 - 166s/epoch - 108ms/step
Epoch 10/50
1542/1542 - 162s - loss: 3.1881 - accuracy200: 0.4229 - val_loss: 3.3575 - val_accuracy200: 0.3399 - 162s/epoch - 105ms/step
Epoch 11/50
1542/1542 - 163s - loss: 3.1839 - accuracy200: 0.4257 - val_loss: 3.3805 - val_accuracy200: 0.3408 - 163s/epoch - 106ms/step
Epoch 12/50
1542/1542 - 165s - loss: 3.1756 - accuracy200: 0.4290 - val_loss: 3.3784 - val_accuracy200: 0.3379 - 165s/epoch - 107ms/step
Epoch 13/50
1542/1542 - 155s - loss: 3.1672 - accuracy200: 0.4314 - val_loss: 3.3783 - val_accuracy200: 0.3413 - 155s/epoch - 101ms/step
testing model: results/WBA/W2/deepLOB_L2/h200
Evaluating performance on  test set...
4353/4353 - 214s - 214s/epoch - 49ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0961728
{'0': {'precision': 0.38202044407457725, 'recall': 0.200110819618749, 'f1-score': 0.26264325227911145, 'support': 380799}, '1': {'precision': 0.35528984495870813, 'recall': 0.6257374322712914, 'f1-score': 0.4532354205772105, 'support': 382408}, '2': {'precision': 0.36449678641134764, 'recall': 0.25054047356592923, 'f1-score': 0.2969615124915598, 'support': 351081}, 'accuracy': 0.36206887267923554, 'macro avg': {'precision': 0.3672690251482111, 'recall': 0.35879624181865655, 'f1-score': 0.33761339511596056, 'support': 1114288}, 'weighted avg': {'precision': 0.3673256630101077, 'recall': 0.36206887267923554, 'f1-score': 0.33886453349921436, 'support': 1114288}}
[[ 76202 226811  77786]
 [ 67548 239287  75573]
 [ 55721 207400  87960]]
Evaluating performance on  train set...
1542/1542 - 77s - 77s/epoch - 50ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1001381
{'0': {'precision': 0.366663215177349, 'recall': 0.2384979195976891, 'f1-score': 0.28900869202482915, 'support': 133628}, '1': {'precision': 0.3411334644068365, 'recall': 0.6178487096357824, 'f1-score': 0.4395678595543551, 'support': 131707}, '2': {'precision': 0.3729323743505883, 'recall': 0.1994149874640171, 'f1-score': 0.25987122407716473, 'support': 129228}, 'accuracy': 0.3523264979230186, 'macro avg': {'precision': 0.3602430179782579, 'recall': 0.35192053889916286, 'f1-score': 0.32948259188544965, 'support': 394563}, 'weighted avg': {'precision': 0.3601945498866539, 'recall': 0.3523264979230186, 'f1-score': 0.3297228988051672, 'support': 394563}}
[[31870 80030 21728]
 [28729 81375 21603]
 [26320 77138 25770]]
Evaluating performance on  val set...
482/482 - 26s - 26s/epoch - 54ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.1020596
{'0': {'precision': 0.34953442058237794, 'recall': 0.31569480566831143, 'f1-score': 0.33175391767455525, 'support': 41141}, '1': {'precision': 0.34014982220910456, 'recall': 0.5893296320646748, 'f1-score': 0.4313390008733001, 'support': 41067}, '2': {'precision': 0.37037530831277915, 'recall': 0.1351759038489611, 'f1-score': 0.19806427463771992, 'support': 41102}, 'accuracy': 0.3466547725245317, 'macro avg': {'precision': 0.35335318370142055, 'recall': 0.34673344719398247, 'f1-score': 0.32038573106185847, 'support': 123310}, 'weighted avg': {'precision': 0.35335572352698696, 'recall': 0.3466547725245317, 'f1-score': 0.3203578338502332, 'support': 123310}}
[[12988 23201  4952]
 [12372 24202  4493]
 [11798 23748  5556]]
training model: results/WBA/W2/deepLOB_L2/h300
Epoch 1/50
1542/1542 - 173s - loss: 3.2677 - accuracy300: 0.3866 - val_loss: 3.3917 - val_accuracy300: 0.3203 - 173s/epoch - 112ms/step
Epoch 2/50
1542/1542 - 164s - loss: 3.2469 - accuracy300: 0.3923 - val_loss: 3.3742 - val_accuracy300: 0.3283 - 164s/epoch - 106ms/step
Epoch 3/50
1542/1542 - 162s - loss: 3.2325 - accuracy300: 0.4046 - val_loss: 3.3752 - val_accuracy300: 0.3209 - 162s/epoch - 105ms/step
Epoch 4/50
1542/1542 - 165s - loss: 3.2223 - accuracy300: 0.4107 - val_loss: 3.4351 - val_accuracy300: 0.3107 - 165s/epoch - 107ms/step
Epoch 5/50
1542/1542 - 169s - loss: 3.2143 - accuracy300: 0.4160 - val_loss: 3.3673 - val_accuracy300: 0.3102 - 169s/epoch - 109ms/step
Epoch 6/50
1542/1542 - 162s - loss: 3.2039 - accuracy300: 0.4193 - val_loss: 3.4419 - val_accuracy300: 0.3117 - 162s/epoch - 105ms/step
Epoch 7/50
1542/1542 - 159s - loss: 3.1947 - accuracy300: 0.4248 - val_loss: 3.3941 - val_accuracy300: 0.3155 - 159s/epoch - 103ms/step
Epoch 8/50
1542/1542 - 163s - loss: 3.1871 - accuracy300: 0.4278 - val_loss: 3.4156 - val_accuracy300: 0.3135 - 163s/epoch - 106ms/step
Epoch 9/50
1542/1542 - 158s - loss: 3.1792 - accuracy300: 0.4311 - val_loss: 3.3820 - val_accuracy300: 0.3124 - 158s/epoch - 103ms/step
Epoch 10/50
1542/1542 - 155s - loss: 3.1731 - accuracy300: 0.4347 - val_loss: 3.4661 - val_accuracy300: 0.3134 - 155s/epoch - 100ms/step
Epoch 11/50
1542/1542 - 161s - loss: 3.1605 - accuracy300: 0.4401 - val_loss: 3.4596 - val_accuracy300: 0.3120 - 161s/epoch - 105ms/step
Epoch 12/50
1542/1542 - 164s - loss: 3.1510 - accuracy300: 0.4430 - val_loss: 3.5491 - val_accuracy300: 0.3123 - 164s/epoch - 107ms/step
Epoch 13/50
1542/1542 - 164s - loss: 3.1380 - accuracy300: 0.4474 - val_loss: 3.5347 - val_accuracy300: 0.3125 - 164s/epoch - 106ms/step
Epoch 14/50
1542/1542 - 161s - loss: 3.1299 - accuracy300: 0.4512 - val_loss: 3.5201 - val_accuracy300: 0.3114 - 161s/epoch - 105ms/step
Epoch 15/50
1542/1542 - 164s - loss: 3.1158 - accuracy300: 0.4560 - val_loss: 3.5546 - val_accuracy300: 0.3126 - 164s/epoch - 107ms/step
testing model: results/WBA/W2/deepLOB_L2/h300
Evaluating performance on  test set...
4353/4353 - 218s - 218s/epoch - 50ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1138333
{'0': {'precision': 0.3546602823412862, 'recall': 0.03168468720959391, 'f1-score': 0.05817236406475331, 'support': 406758}, '1': {'precision': 0.3123139849778236, 'recall': 0.916311625956296, 'f1-score': 0.46584888486304704, 'support': 345735}, '2': {'precision': 0.3240697052624957, 'recall': 0.05695214140604486, 'f1-score': 0.09687876871575098, 'support': 361795}, 'accuracy': 0.31436576540355815, 'macro avg': {'precision': 0.3303479908605352, 'recall': 0.3349828181906449, 'f1-score': 0.20696667254785042, 'support': 1114288}, 'weighted avg': {'precision': 0.3315889444527172, 'recall': 0.31436576540355815, 'f1-score': 0.1972314094721397, 'support': 1114288}}
[[ 12888 369984  23886]
 [  9843 316801  19091]
 [ 13608 327582  20605]]
Evaluating performance on  train set...
1542/1542 - 75s - 75s/epoch - 49ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.110183
{'0': {'precision': 0.3616035112279839, 'recall': 0.1415348616788105, 'f1-score': 0.20344106393056136, 'support': 135048}, '1': {'precision': 0.3411547848520606, 'recall': 0.7129182205953302, 'f1-score': 0.46147745157572523, 'support': 130583}, '2': {'precision': 0.3491034843509343, 'recall': 0.18634629106815995, 'f1-score': 0.24298876381767245, 'support': 128932}, 'accuracy': 0.3452807282994097, 'macro avg': {'precision': 0.35062059347699287, 'recall': 0.34693312444743357, 'f1-score': 0.302635759774653, 'support': 394563}, 'weighted avg': {'precision': 0.35075122781149787, 'recall': 0.3452807282994097, 'f1-score': 0.30176282661412124, 'support': 394563}}
[[19114 92350 23584]
 [16276 93095 21212]
 [17469 87437 24026]]
Evaluating performance on  val set...
482/482 - 22s - 22s/epoch - 46ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.1222228
{'0': {'precision': 0.3317701354771475, 'recall': 0.20612787605503527, 'f1-score': 0.25427524139603214, 'support': 43245}, '1': {'precision': 0.30162557276892865, 'recall': 0.7417433530974163, 'f1-score': 0.42885839932367975, 'support': 37273}, '2': {'precision': 0.3822668339606859, 'recall': 0.04271826509627968, 'f1-score': 0.07684869886913019, 'support': 42792}, 'accuracy': 0.3113210607412213, 'macro avg': {'precision': 0.33855418073558735, 'recall': 0.3301964980829104, 'f1-score': 0.25332744652961403, 'support': 123310}, 'weighted avg': {'precision': 0.340182076403951, 'recall': 0.3113210607412213, 'f1-score': 0.24547466916041474, 'support': 123310}}
[[ 8914 32760  1571]
 [ 8243 27647  1383]
 [ 9711 31253  1828]]
training model: results/WBA/W2/deepLOB_L2/h500
Epoch 1/50
1542/1542 - 176s - loss: 3.2411 - accuracy500: 0.4096 - val_loss: 3.4380 - val_accuracy500: 0.2966 - 176s/epoch - 114ms/step
Epoch 2/50
1542/1542 - 164s - loss: 3.2183 - accuracy500: 0.4178 - val_loss: 3.3971 - val_accuracy500: 0.3368 - 164s/epoch - 106ms/step
Epoch 3/50
1542/1542 - 161s - loss: 3.2028 - accuracy500: 0.4264 - val_loss: 3.4113 - val_accuracy500: 0.3371 - 161s/epoch - 105ms/step
Epoch 4/50
1542/1542 - 160s - loss: 3.1920 - accuracy500: 0.4348 - val_loss: 3.4369 - val_accuracy500: 0.3268 - 160s/epoch - 104ms/step
Epoch 5/50
1542/1542 - 159s - loss: 3.1848 - accuracy500: 0.4370 - val_loss: 3.4724 - val_accuracy500: 0.3140 - 159s/epoch - 103ms/step
Epoch 6/50
1542/1542 - 163s - loss: 3.1770 - accuracy500: 0.4405 - val_loss: 3.4111 - val_accuracy500: 0.3302 - 163s/epoch - 106ms/step
Epoch 7/50
1542/1542 - 157s - loss: 3.1630 - accuracy500: 0.4476 - val_loss: 3.4582 - val_accuracy500: 0.3212 - 157s/epoch - 102ms/step
Epoch 8/50
1542/1542 - 160s - loss: 3.1471 - accuracy500: 0.4529 - val_loss: 3.4838 - val_accuracy500: 0.3163 - 160s/epoch - 104ms/step
Epoch 9/50
1542/1542 - 160s - loss: 3.1392 - accuracy500: 0.4569 - val_loss: 3.4743 - val_accuracy500: 0.3235 - 160s/epoch - 104ms/step
Epoch 10/50
1542/1542 - 162s - loss: 3.1263 - accuracy500: 0.4622 - val_loss: 3.4479 - val_accuracy500: 0.3055 - 162s/epoch - 105ms/step
Epoch 11/50
1542/1542 - 163s - loss: 3.1160 - accuracy500: 0.4647 - val_loss: 3.4590 - val_accuracy500: 0.3028 - 163s/epoch - 106ms/step
Epoch 12/50
1542/1542 - 161s - loss: 3.1050 - accuracy500: 0.4699 - val_loss: 3.4667 - val_accuracy500: 0.3081 - 161s/epoch - 104ms/step
testing model: results/WBA/W2/deepLOB_L2/h500
Evaluating performance on  test set...
4353/4353 - 202s - 202s/epoch - 46ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1357667
{'0': {'precision': 0.4063060836297594, 'recall': 0.16917542195414437, 'f1-score': 0.23888518561811098, 'support': 446968}, '1': {'precision': 0.25440106161559495, 'recall': 0.6150512046912846, 'f1-score': 0.3599270149378995, 'support': 282396}, '2': {'precision': 0.3436314672294448, 'recall': 0.2191185792520082, 'f1-score': 0.2676002937943091, 'support': 384924}, 'accuracy': 0.2994270780983013, 'macro avg': {'precision': 0.33477953749159967, 'recall': 0.33444840196581244, 'f1-score': 0.28880416478343984, 'support': 1114288}, 'weighted avg': {'precision': 0.34615795797464444, 'recall': 0.2994270780983013, 'f1-score': 0.27948049197715447, 'support': 1114288}}
[[ 75616 273733  97619]
 [ 45222 173688  63486]
 [ 65268 235312  84344]]
Evaluating performance on  train set...
1542/1542 - 74s - 74s/epoch - 48ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1268821
{'0': {'precision': 0.3499100576086709, 'recall': 0.3254042760441298, 'f1-score': 0.3372125343788402, 'support': 141673}, '1': {'precision': 0.29525582277655593, 'recall': 0.41374469393010527, 'f1-score': 0.3445992693861737, 'support': 120381}, '2': {'precision': 0.34978378895251855, 'recall': 0.2484510486080191, 'f1-score': 0.290535233640736, 'support': 132509}, 'accuracy': 0.3265131297156601, 'macro avg': {'precision': 0.3316498897792484, 'recall': 0.32920000619408474, 'f1-score': 0.32411567913524997, 'support': 394563}, 'weighted avg': {'precision': 0.3331926685562688, 'recall': 0.3265131297156601, 'f1-score': 0.3237902421299784, 'support': 394563}}
[[46101 61361 34211]
 [43586 49807 26988]
 [42064 57523 32922]]
Evaluating performance on  val set...
482/482 - 24s - 24s/epoch - 49ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.1395518
{'0': {'precision': 0.3710544196676756, 'recall': 0.401653776717855, 'f1-score': 0.385748228696192, 'support': 44867}, '1': {'precision': 0.3021693939555461, 'recall': 0.500294169559334, 'f1-score': 0.37677370758886536, 'support': 33994}, '2': {'precision': 0.3547670639219935, 'recall': 0.14733739791671355, 'f1-score': 0.20820550318714331, 'support': 44449}, 'accuracy': 0.33717460060011356, 'macro avg': {'precision': 0.34266362584840504, 'recall': 0.3497617813979676, 'f1-score': 0.32357581315740025, 'support': 123310}, 'weighted avg': {'precision': 0.3461932223633373, 'recall': 0.33717460060011356, 'f1-score': 0.3192761138906274, 'support': 123310}}
[[18021 20598  6248]
 [11324 17007  5663]
 [19222 18678  6549]]
training model: results/WBA/W2/deepLOB_L2/h1000
Epoch 1/50
1542/1542 - 177s - loss: 3.2826 - accuracy1000: 0.3872 - val_loss: 3.4532 - val_accuracy1000: 0.3426 - 177s/epoch - 115ms/step
Epoch 2/50
1542/1542 - 168s - loss: 3.2546 - accuracy1000: 0.3931 - val_loss: 3.4492 - val_accuracy1000: 0.3121 - 168s/epoch - 109ms/step
Epoch 3/50
1542/1542 - 162s - loss: 3.2152 - accuracy1000: 0.4150 - val_loss: 3.4921 - val_accuracy1000: 0.3027 - 162s/epoch - 105ms/step
Epoch 4/50
1542/1542 - 164s - loss: 3.1901 - accuracy1000: 0.4278 - val_loss: 3.4336 - val_accuracy1000: 0.3294 - 164s/epoch - 107ms/step
Epoch 5/50
1542/1542 - 160s - loss: 3.1641 - accuracy1000: 0.4408 - val_loss: 3.4895 - val_accuracy1000: 0.3303 - 160s/epoch - 104ms/step
Epoch 6/50
1542/1542 - 155s - loss: 3.1505 - accuracy1000: 0.4474 - val_loss: 3.5368 - val_accuracy1000: 0.3300 - 155s/epoch - 100ms/step
Epoch 7/50
1542/1542 - 160s - loss: 3.1371 - accuracy1000: 0.4485 - val_loss: 3.6277 - val_accuracy1000: 0.3305 - 160s/epoch - 104ms/step
Epoch 8/50
1542/1542 - 161s - loss: 3.1258 - accuracy1000: 0.4562 - val_loss: 3.6604 - val_accuracy1000: 0.3372 - 161s/epoch - 105ms/step
Epoch 9/50
1542/1542 - 159s - loss: 3.1134 - accuracy1000: 0.4603 - val_loss: 3.8000 - val_accuracy1000: 0.3169 - 159s/epoch - 103ms/step
Epoch 10/50
1542/1542 - 156s - loss: 3.1144 - accuracy1000: 0.4588 - val_loss: 3.6531 - val_accuracy1000: 0.3179 - 156s/epoch - 101ms/step
Epoch 11/50
1542/1542 - 166s - loss: 3.1079 - accuracy1000: 0.4620 - val_loss: 3.7599 - val_accuracy1000: 0.3216 - 166s/epoch - 108ms/step
Epoch 12/50
1542/1542 - 159s - loss: 3.0905 - accuracy1000: 0.4689 - val_loss: 3.9639 - val_accuracy1000: 0.3151 - 159s/epoch - 103ms/step
Epoch 13/50
1542/1542 - 158s - loss: 3.0862 - accuracy1000: 0.4707 - val_loss: 3.9148 - val_accuracy1000: 0.3146 - 158s/epoch - 103ms/step
Epoch 14/50
1542/1542 - 169s - loss: 3.0788 - accuracy1000: 0.4722 - val_loss: 3.7447 - val_accuracy1000: 0.3120 - 169s/epoch - 110ms/step
testing model: results/WBA/W2/deepLOB_L2/h1000
Evaluating performance on  test set...
4353/4353 - 206s - 206s/epoch - 47ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1203189
{'0': {'precision': 0.363803555078458, 'recall': 0.11719550552655467, 'f1-score': 0.17728160007692678, 'support': 393283}, '1': {'precision': 0.3497792749015797, 'recall': 0.43977260371848836, 'f1-score': 0.3896472077783563, 'support': 386286}, '2': {'precision': 0.29975454451271505, 'recall': 0.44949345570463584, 'f1-score': 0.3596611696984257, 'support': 334719}, 'accuracy': 0.32884047930158095, 'macro avg': {'precision': 0.3377791248309176, 'recall': 0.3354871883165596, 'f1-score': 0.30886332585123627, 'support': 1114288}, 'weighted avg': {'precision': 0.33970224207862265, 'recall': 0.32884047930158095, 'f1-score': 0.3056862569526115, 'support': 1114288}}
[[ 46091 169567 177625]
 [ 42563 169878 173845]
 [ 38038 146227 150454]]
Evaluating performance on  train set...
1542/1542 - 83s - 83s/epoch - 54ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1266896
{'0': {'precision': 0.3495564516129032, 'recall': 0.1266721705522638, 'f1-score': 0.1859572163262242, 'support': 136873}, '1': {'precision': 0.3345445656721399, 'recall': 0.5439814107071881, 'f1-score': 0.41429856298335943, 'support': 130828}, '2': {'precision': 0.3246793514429185, 'recall': 0.33842285317904497, 'f1-score': 0.33140867793156153, 'support': 126862}, 'accuracy': 0.3331255084739319, 'macro avg': {'precision': 0.33626012290932056, 'recall': 0.3363588114794989, 'f1-score': 0.31055481908038174, 'support': 394563}, 'weighted avg': {'precision': 0.33658023819293537, 'recall': 0.3331255084739319, 'f1-score': 0.3084362754945598, 'support': 394563}}
[[17338 73373 46162]
 [16523 71168 43137]
 [15739 68190 42933]]
Evaluating performance on  val set...
482/482 - 26s - 26s/epoch - 53ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1429598
{'0': {'precision': 0.32788257258739456, 'recall': 0.1220611144397843, 'f1-score': 0.17789653847497294, 'support': 41725}, '1': {'precision': 0.33109406298118194, 'recall': 0.611762928646961, 'f1-score': 0.4296538614561691, 'support': 39718}, '2': {'precision': 0.3266065716778133, 'recall': 0.2682781188047866, 'f1-score': 0.2945827923993863, 'support': 41867}, 'accuracy': 0.3294380017841213, 'macro avg': {'precision': 0.32852773574879657, 'recall': 0.334034053963844, 'f1-score': 0.30071106411017606, 'support': 123310}, 'weighted avg': {'precision': 0.3284837537193304, 'recall': 0.3294380017841213, 'f1-score': 0.2986053272773455, 'support': 123310}}
[[ 5093 24003 12629]
 [ 4891 24298 10529]
 [ 5549 25086 11232]]
training model: results/WBA/W2/deepOF_L2/h10
Epoch 1/50
1542/1542 - 127s - loss: 2.9030 - accuracy10: 0.5107 - val_loss: 3.0689 - val_accuracy10: 0.6749 - 127s/epoch - 82ms/step
Epoch 2/50
1542/1542 - 123s - loss: 2.6515 - accuracy10: 0.5874 - val_loss: 2.9949 - val_accuracy10: 0.6871 - 123s/epoch - 80ms/step
Epoch 3/50
1542/1542 - 127s - loss: 2.5811 - accuracy10: 0.6021 - val_loss: 2.9317 - val_accuracy10: 0.6872 - 127s/epoch - 82ms/step
Epoch 4/50
1542/1542 - 125s - loss: 2.5478 - accuracy10: 0.6084 - val_loss: 2.9454 - val_accuracy10: 0.6897 - 125s/epoch - 81ms/step
Epoch 5/50
1542/1542 - 124s - loss: 2.5274 - accuracy10: 0.6127 - val_loss: 2.9188 - val_accuracy10: 0.6880 - 124s/epoch - 80ms/step
Epoch 6/50
1542/1542 - 122s - loss: 2.5117 - accuracy10: 0.6159 - val_loss: 2.9348 - val_accuracy10: 0.6883 - 122s/epoch - 79ms/step
Epoch 7/50
1542/1542 - 124s - loss: 2.5004 - accuracy10: 0.6173 - val_loss: 2.9188 - val_accuracy10: 0.6848 - 124s/epoch - 81ms/step
Epoch 8/50
1542/1542 - 122s - loss: 2.4890 - accuracy10: 0.6180 - val_loss: 2.9292 - val_accuracy10: 0.6860 - 122s/epoch - 79ms/step
Epoch 9/50
1542/1542 - 124s - loss: 2.4797 - accuracy10: 0.6198 - val_loss: 2.9739 - val_accuracy10: 0.6889 - 124s/epoch - 80ms/step
Epoch 10/50
1542/1542 - 121s - loss: 2.4708 - accuracy10: 0.6204 - val_loss: 2.9733 - val_accuracy10: 0.6879 - 121s/epoch - 79ms/step
Epoch 11/50
1542/1542 - 122s - loss: 2.4642 - accuracy10: 0.6213 - val_loss: 2.9429 - val_accuracy10: 0.6853 - 122s/epoch - 79ms/step
Epoch 12/50
1542/1542 - 124s - loss: 2.4571 - accuracy10: 0.6222 - val_loss: 2.9433 - val_accuracy10: 0.6842 - 124s/epoch - 81ms/step
Epoch 13/50
1542/1542 - 117s - loss: 2.4469 - accuracy10: 0.6234 - val_loss: 2.9402 - val_accuracy10: 0.6826 - 117s/epoch - 76ms/step
Epoch 14/50
1542/1542 - 122s - loss: 2.4420 - accuracy10: 0.6233 - val_loss: 2.9031 - val_accuracy10: 0.6802 - 122s/epoch - 79ms/step
Epoch 15/50
1542/1542 - 123s - loss: 2.4344 - accuracy10: 0.6241 - val_loss: 2.8940 - val_accuracy10: 0.6789 - 123s/epoch - 79ms/step
Epoch 16/50
1542/1542 - 120s - loss: 2.4297 - accuracy10: 0.6249 - val_loss: 2.9159 - val_accuracy10: 0.6791 - 120s/epoch - 78ms/step
Epoch 17/50
1542/1542 - 116s - loss: 2.4237 - accuracy10: 0.6263 - val_loss: 2.9266 - val_accuracy10: 0.6794 - 116s/epoch - 75ms/step
Epoch 18/50
1542/1542 - 118s - loss: 2.4182 - accuracy10: 0.6266 - val_loss: 2.9141 - val_accuracy10: 0.6767 - 118s/epoch - 77ms/step
Epoch 19/50
1542/1542 - 124s - loss: 2.4117 - accuracy10: 0.6273 - val_loss: 2.9256 - val_accuracy10: 0.6784 - 124s/epoch - 80ms/step
Epoch 20/50
1542/1542 - 122s - loss: 2.4065 - accuracy10: 0.6279 - val_loss: 2.9272 - val_accuracy10: 0.6793 - 122s/epoch - 79ms/step
Epoch 21/50
1542/1542 - 121s - loss: 2.4015 - accuracy10: 0.6274 - val_loss: 2.9433 - val_accuracy10: 0.6785 - 121s/epoch - 79ms/step
Epoch 22/50
1542/1542 - 123s - loss: 2.3955 - accuracy10: 0.6284 - val_loss: 2.8878 - val_accuracy10: 0.6741 - 123s/epoch - 79ms/step
Epoch 23/50
1542/1542 - 118s - loss: 2.3920 - accuracy10: 0.6282 - val_loss: 2.9108 - val_accuracy10: 0.6746 - 118s/epoch - 76ms/step
Epoch 24/50
1542/1542 - 120s - loss: 2.3880 - accuracy10: 0.6291 - val_loss: 2.9336 - val_accuracy10: 0.6762 - 120s/epoch - 78ms/step
Epoch 25/50
1542/1542 - 114s - loss: 2.3842 - accuracy10: 0.6294 - val_loss: 2.9336 - val_accuracy10: 0.6744 - 114s/epoch - 74ms/step
Epoch 26/50
1542/1542 - 112s - loss: 2.3780 - accuracy10: 0.6298 - val_loss: 2.9553 - val_accuracy10: 0.6757 - 112s/epoch - 73ms/step
Epoch 27/50
1542/1542 - 122s - loss: 2.3729 - accuracy10: 0.6304 - val_loss: 2.9589 - val_accuracy10: 0.6769 - 122s/epoch - 79ms/step
Epoch 28/50
1542/1542 - 120s - loss: 2.3686 - accuracy10: 0.6305 - val_loss: 2.9339 - val_accuracy10: 0.6698 - 120s/epoch - 78ms/step
Epoch 29/50
1542/1542 - 120s - loss: 2.3654 - accuracy10: 0.6313 - val_loss: 2.9518 - val_accuracy10: 0.6724 - 120s/epoch - 78ms/step
Epoch 30/50
1542/1542 - 120s - loss: 2.3592 - accuracy10: 0.6318 - val_loss: 2.9550 - val_accuracy10: 0.6726 - 120s/epoch - 78ms/step
Epoch 31/50
1542/1542 - 120s - loss: 2.3563 - accuracy10: 0.6326 - val_loss: 2.9537 - val_accuracy10: 0.6705 - 120s/epoch - 78ms/step
Epoch 32/50
1542/1542 - 125s - loss: 2.3500 - accuracy10: 0.6330 - val_loss: 2.9432 - val_accuracy10: 0.6732 - 125s/epoch - 81ms/step
testing model: results/WBA/W2/deepOF_L2/h10
Evaluating performance on  test set...
4353/4353 - 148s - 148s/epoch - 34ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.73336244
{'0': {'precision': 0.48239865936965876, 'recall': 0.46281587676332814, 'f1-score': 0.47240441180479453, 'support': 187217}, '1': {'precision': 0.8125536842334163, 'recall': 0.8076929312143007, 'f1-score': 0.8101160165745707, 'support': 740212}, '2': {'precision': 0.4552448185356141, 'recall': 0.4845494343177026, 'f1-score': 0.469440238919883, 'support': 186854}, 'accuracy': 0.6955602840571022, 'macro avg': {'precision': 0.5833990540462298, 'recall': 0.5850194140984438, 'f1-score': 0.5839868890997494, 'support': 1114283}, 'weighted avg': {'precision': 0.6971653815481782, 'recall': 0.6955602840571022, 'f1-score': 0.6962472908845331, 'support': 1114283}}
[[ 86647  65082  35488]
 [ 69494 597864  72854]
 [ 23476  72838  90540]]
Evaluating performance on  train set...
1542/1542 - 53s - 53s/epoch - 35ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.80250216
{'0': {'precision': 0.47862100482705433, 'recall': 0.4477727600673383, 'f1-score': 0.46268327028743406, 'support': 74846}, '1': {'precision': 0.7884016869682515, 'recall': 0.7843195110811105, 'f1-score': 0.786355301149891, 'support': 247403}, '2': {'precision': 0.4571654467086638, 'recall': 0.495761481338072, 'f1-score': 0.4756818438144775, 'support': 72313}, 'accuracy': 0.6675934327177985, 'macro avg': {'precision': 0.5747293795013232, 'recall': 0.5759512508288402, 'f1-score': 0.5749068050839342, 'support': 394562}, 'weighted avg': {'precision': 0.6689311571720936, 'recall': 0.6675934327177985, 'f1-score': 0.668018293170848, 'support': 394562}}
[[ 33514  26244  15088]
 [ 25880 194043  27480]
 [ 10628  25835  35850]]
Evaluating performance on  val set...
482/482 - 17s - 17s/epoch - 34ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.7928432
{'0': {'precision': 0.47862315246503323, 'recall': 0.43623705980742283, 'f1-score': 0.4564482179599367, 'support': 22121}, '1': {'precision': 0.7903960346215781, 'recall': 0.7926796956812475, 'f1-score': 0.7915362180072695, 'support': 79259}, '2': {'precision': 0.44959634811276894, 'recall': 0.4850654384604861, 'f1-score': 0.4666578924278319, 'support': 21929}, 'accuracy': 0.6740302816501634, 'macro avg': {'precision': 0.5728718450664602, 'recall': 0.5713273979830521, 'f1-score': 0.571547442798346, 'support': 123309}, 'weighted avg': {'precision': 0.6738585211259159, 'recall': 0.6740302816501634, 'f1-score': 0.6736475119867962, 'support': 123309}}
[[ 9650  8294  4177]
 [ 7587 62827  8845]
 [ 2925  8367 10637]]
training model: results/WBA/W2/deepOF_L2/h20
Epoch 1/50
1542/1542 - 123s - loss: 2.9729 - accuracy20: 0.4970 - val_loss: 3.1927 - val_accuracy20: 0.6024 - 123s/epoch - 80ms/step
Epoch 2/50
1542/1542 - 118s - loss: 2.7450 - accuracy20: 0.5651 - val_loss: 3.1741 - val_accuracy20: 0.6187 - 118s/epoch - 76ms/step
Epoch 3/50
1542/1542 - 124s - loss: 2.6752 - accuracy20: 0.5825 - val_loss: 3.0861 - val_accuracy20: 0.6249 - 124s/epoch - 80ms/step
Epoch 4/50
1542/1542 - 122s - loss: 2.6423 - accuracy20: 0.5914 - val_loss: 3.0682 - val_accuracy20: 0.6282 - 122s/epoch - 79ms/step
Epoch 5/50
1542/1542 - 121s - loss: 2.6218 - accuracy20: 0.5956 - val_loss: 3.0741 - val_accuracy20: 0.6291 - 121s/epoch - 78ms/step
Epoch 6/50
1542/1542 - 125s - loss: 2.6076 - accuracy20: 0.5982 - val_loss: 3.0811 - val_accuracy20: 0.6306 - 125s/epoch - 81ms/step
Epoch 7/50
1542/1542 - 119s - loss: 2.5973 - accuracy20: 0.5996 - val_loss: 3.0909 - val_accuracy20: 0.6287 - 119s/epoch - 77ms/step
Epoch 8/50
1542/1542 - 124s - loss: 2.5863 - accuracy20: 0.6017 - val_loss: 3.0713 - val_accuracy20: 0.6309 - 124s/epoch - 80ms/step
Epoch 9/50
1542/1542 - 123s - loss: 2.5795 - accuracy20: 0.6026 - val_loss: 3.0942 - val_accuracy20: 0.6312 - 123s/epoch - 80ms/step
Epoch 10/50
1542/1542 - 117s - loss: 2.5728 - accuracy20: 0.6041 - val_loss: 3.0976 - val_accuracy20: 0.6322 - 117s/epoch - 76ms/step
Epoch 11/50
1542/1542 - 121s - loss: 2.5667 - accuracy20: 0.6051 - val_loss: 3.1201 - val_accuracy20: 0.6320 - 121s/epoch - 78ms/step
Epoch 12/50
1542/1542 - 120s - loss: 2.5600 - accuracy20: 0.6058 - val_loss: 3.0730 - val_accuracy20: 0.6300 - 120s/epoch - 78ms/step
Epoch 13/50
1542/1542 - 119s - loss: 2.5531 - accuracy20: 0.6070 - val_loss: 3.0947 - val_accuracy20: 0.6317 - 119s/epoch - 77ms/step
Epoch 14/50
1542/1542 - 115s - loss: 2.5478 - accuracy20: 0.6074 - val_loss: 3.0944 - val_accuracy20: 0.6304 - 115s/epoch - 75ms/step
testing model: results/WBA/W2/deepOF_L2/h20
Evaluating performance on  test set...
4353/4353 - 150s - 150s/epoch - 35ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.8044407
{'0': {'precision': 0.5944004052713819, 'recall': 0.34650899683052017, 'f1-score': 0.43780004256761546, 'support': 240418}, '1': {'precision': 0.6907566436661862, 'recall': 0.8953659955335279, 'f1-score': 0.779864046628362, 'support': 630923}, '2': {'precision': 0.539671573237121, 'recall': 0.34725160737953914, 'f1-score': 0.4225886195314867, 'support': 242942}, 'accuracy': 0.6574416014603113, 'macro avg': {'precision': 0.6082762073915631, 'recall': 0.5297088665811956, 'f1-score': 0.5467509029091547, 'support': 1114283}, 'weighted avg': {'precision': 0.6370264123851023, 'recall': 0.6574416014603113, 'f1-score': 0.6281651061096198, 'support': 1114283}}
[[ 83307 122272  34839]
 [ 28896 564907  37120]
 [ 27950 130630  84362]]
Evaluating performance on  train set...
1542/1542 - 49s - 49s/epoch - 32ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.8791976
{'0': {'precision': 0.5633726982303744, 'recall': 0.32963340229136695, 'f1-score': 0.4159130809235152, 'support': 95227}, '1': {'precision': 0.651526875528603, 'recall': 0.8753148919092725, 'f1-score': 0.74702066552225, 'support': 206817}, '2': {'precision': 0.5272918067192445, 'recall': 0.3475972243239153, 'f1-score': 0.41899066492081793, 'support': 92518}, 'accuracy': 0.6198746964989026, 'macro avg': {'precision': 0.5807304601594073, 'recall': 0.5175151728415183, 'f1-score': 0.5273081371221944, 'support': 394562}, 'weighted avg': {'precision': 0.6011199992007188, 'recall': 0.6198746964989026, 'f1-score': 0.5901909111256608, 'support': 394562}}
[[ 31390  49382  14455]
 [ 11412 181030  14375]
 [ 12916  47443  32159]]
Evaluating performance on  val set...
482/482 - 19s - 19s/epoch - 39ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.87022054
{'0': {'precision': 0.5778345576493134, 'recall': 0.31473105559807946, 'f1-score': 0.4075050115998829, 'support': 28742}, '1': {'precision': 0.6564518114766025, 'recall': 0.8861023401973078, 'f1-score': 0.7541822577119418, 'support': 66191}, '2': {'precision': 0.5356967280275304, 'recall': 0.345608965322808, 'f1-score': 0.4201529464687359, 'support': 28376}, 'accuracy': 0.6285429287399946, 'macro avg': {'precision': 0.5899943657178154, 'recall': 0.5154807870393985, 'f1-score': 0.5272800719268536, 'support': 123309}, 'weighted avg': {'precision': 0.6103386862590205, 'recall': 0.6285429287399946, 'f1-score': 0.5965083398017325, 'support': 123309}}
[[ 9046 15597  4099]
 [ 3138 58652  4401]
 [ 3471 15098  9807]]
training model: results/WBA/W2/deepOF_L2/h30
Epoch 1/50
1542/1542 - 125s - loss: 3.0337 - accuracy30: 0.4812 - val_loss: 3.2603 - val_accuracy30: 0.5446 - 125s/epoch - 81ms/step
Epoch 2/50
1542/1542 - 120s - loss: 2.8305 - accuracy30: 0.5433 - val_loss: 3.2846 - val_accuracy30: 0.5600 - 120s/epoch - 78ms/step
Epoch 3/50
1542/1542 - 121s - loss: 2.7655 - accuracy30: 0.5573 - val_loss: 3.2049 - val_accuracy30: 0.5700 - 121s/epoch - 79ms/step
Epoch 4/50
1542/1542 - 117s - loss: 2.7324 - accuracy30: 0.5659 - val_loss: 3.1485 - val_accuracy30: 0.5743 - 117s/epoch - 76ms/step
Epoch 5/50
1542/1542 - 118s - loss: 2.7140 - accuracy30: 0.5707 - val_loss: 3.2235 - val_accuracy30: 0.5729 - 118s/epoch - 77ms/step
Epoch 6/50
1542/1542 - 124s - loss: 2.7001 - accuracy30: 0.5737 - val_loss: 3.1732 - val_accuracy30: 0.5751 - 124s/epoch - 80ms/step
Epoch 7/50
1542/1542 - 122s - loss: 2.6895 - accuracy30: 0.5758 - val_loss: 3.1748 - val_accuracy30: 0.5759 - 122s/epoch - 79ms/step
Epoch 8/50
1542/1542 - 120s - loss: 2.6794 - accuracy30: 0.5776 - val_loss: 3.1798 - val_accuracy30: 0.5752 - 120s/epoch - 78ms/step
Epoch 9/50
1542/1542 - 117s - loss: 2.6719 - accuracy30: 0.5792 - val_loss: 3.1732 - val_accuracy30: 0.5763 - 117s/epoch - 76ms/step
Epoch 10/50
1542/1542 - 119s - loss: 2.6649 - accuracy30: 0.5814 - val_loss: 3.1856 - val_accuracy30: 0.5763 - 119s/epoch - 77ms/step
Epoch 11/50
1542/1542 - 115s - loss: 2.6578 - accuracy30: 0.5826 - val_loss: 3.1937 - val_accuracy30: 0.5770 - 115s/epoch - 74ms/step
Epoch 12/50
1542/1542 - 122s - loss: 2.6519 - accuracy30: 0.5834 - val_loss: 3.1639 - val_accuracy30: 0.5789 - 122s/epoch - 79ms/step
Epoch 13/50
1542/1542 - 121s - loss: 2.6456 - accuracy30: 0.5843 - val_loss: 3.1579 - val_accuracy30: 0.5785 - 121s/epoch - 78ms/step
Epoch 14/50
1542/1542 - 111s - loss: 2.6395 - accuracy30: 0.5858 - val_loss: 3.1675 - val_accuracy30: 0.5787 - 111s/epoch - 72ms/step
testing model: results/WBA/W2/deepOF_L2/h30
Evaluating performance on  test set...
4353/4353 - 160s - 160s/epoch - 37ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.8846092
{'0': {'precision': 0.6055108248344964, 'recall': 0.3046227186150927, 'f1-score': 0.4053303055128371, 'support': 277737}, '1': {'precision': 0.614978944275781, 'recall': 0.9040754697966045, 'f1-score': 0.7320177247247088, 'support': 555666}, '2': {'precision': 0.5539517244003602, 'recall': 0.3109726573625748, 'f1-score': 0.3983327176793035, 'support': 280880}, 'accuracy': 0.6051559612773416, 'macro avg': {'precision': 0.5914804978368792, 'recall': 0.506556948591424, 'f1-score': 0.5118935826389498, 'support': 1114283}, 'weighted avg': {'precision': 0.5972357205095814, 'recall': 0.6051559612773416, 'f1-score': 0.5664775266524408, 'support': 1114283}}
[[ 84605 151684  41448]
 [ 24418 502364  28884]
 [ 30702 162832  87346]]
Evaluating performance on  train set...
1542/1542 - 58s - 58s/epoch - 37ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.956846
{'0': {'precision': 0.5662078868109547, 'recall': 0.29748378490270944, 'f1-score': 0.3900411934645332, 'support': 108695}, '1': {'precision': 0.5737408504705472, 'recall': 0.8803061701985427, 'f1-score': 0.6947060219988921, 'support': 179508}, '2': {'precision': 0.5459616314686442, 'recall': 0.31841217010314127, 'f1-score': 0.40223530040560845, 'support': 106359}, 'accuracy': 0.5682833116214943, 'macro avg': {'precision': 0.5619701229167154, 'recall': 0.4987340417347978, 'f1-score': 0.49566083862301125, 'support': 394562}, 'weighted avg': {'precision': 0.5641774220643581, 'recall': 0.5682833116214943, 'f1-score': 0.5319370857721845, 'support': 394562}}
[[ 32335  59546  16814]
 [ 10136 158022  11350]
 [ 14637  57856  33866]]
Evaluating performance on  val set...
482/482 - 18s - 18s/epoch - 38ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.9481981
{'0': {'precision': 0.5877070063694267, 'recall': 0.2787276462058966, 'f1-score': 0.378124743873453, 'support': 33104}, '1': {'precision': 0.5774818537756488, 'recall': 0.8961837111320032, 'f1-score': 0.7023707999317755, 'support': 57438}, '2': {'precision': 0.5493720225205717, 'recall': 0.30970183416241953, 'f1-score': 0.3961045297527275, 'support': 32767}, 'accuracy': 0.5745728211241677, 'macro avg': {'precision': 0.5715202942218824, 'recall': 0.49487106383343976, 'f1-score': 0.4922000245193187, 'support': 123309}, 'weighted avg': {'precision': 0.5727572887457589, 'recall': 0.5745728211241677, 'f1-score': 0.5339380957924866, 'support': 123309}}
[[ 9227 19028  4849]
 [ 2488 51475  3475]
 [ 3985 18634 10148]]
training model: results/WBA/W2/deepOF_L2/h50
Epoch 1/50
1542/1542 - 129s - loss: 3.1071 - accuracy50: 0.4554 - val_loss: 3.3599 - val_accuracy50: 0.4563 - 129s/epoch - 83ms/step
Epoch 2/50
1542/1542 - 121s - loss: 2.9512 - accuracy50: 0.5029 - val_loss: 3.4455 - val_accuracy50: 0.4658 - 121s/epoch - 79ms/step
Epoch 3/50
1542/1542 - 119s - loss: 2.8924 - accuracy50: 0.5177 - val_loss: 3.3258 - val_accuracy50: 0.4774 - 119s/epoch - 77ms/step
Epoch 4/50
1542/1542 - 124s - loss: 2.8635 - accuracy50: 0.5248 - val_loss: 3.2713 - val_accuracy50: 0.4835 - 124s/epoch - 80ms/step
Epoch 5/50
1542/1542 - 122s - loss: 2.8480 - accuracy50: 0.5296 - val_loss: 3.2667 - val_accuracy50: 0.4835 - 122s/epoch - 79ms/step
Epoch 6/50
1542/1542 - 126s - loss: 2.8356 - accuracy50: 0.5326 - val_loss: 3.2626 - val_accuracy50: 0.4869 - 126s/epoch - 82ms/step
Epoch 7/50
1542/1542 - 123s - loss: 2.8268 - accuracy50: 0.5345 - val_loss: 3.2875 - val_accuracy50: 0.4868 - 123s/epoch - 80ms/step
Epoch 8/50
1542/1542 - 124s - loss: 2.8191 - accuracy50: 0.5363 - val_loss: 3.2261 - val_accuracy50: 0.4921 - 124s/epoch - 80ms/step
Epoch 9/50
1542/1542 - 127s - loss: 2.8110 - accuracy50: 0.5385 - val_loss: 3.2406 - val_accuracy50: 0.4920 - 127s/epoch - 83ms/step
Epoch 10/50
1542/1542 - 122s - loss: 2.8050 - accuracy50: 0.5403 - val_loss: 3.2513 - val_accuracy50: 0.4924 - 122s/epoch - 79ms/step
Epoch 11/50
1542/1542 - 123s - loss: 2.8000 - accuracy50: 0.5412 - val_loss: 3.2764 - val_accuracy50: 0.4918 - 123s/epoch - 80ms/step
Epoch 12/50
1542/1542 - 123s - loss: 2.7934 - accuracy50: 0.5430 - val_loss: 3.2282 - val_accuracy50: 0.4931 - 123s/epoch - 80ms/step
Epoch 13/50
1542/1542 - 132s - loss: 2.7897 - accuracy50: 0.5442 - val_loss: 3.2540 - val_accuracy50: 0.4929 - 132s/epoch - 86ms/step
Epoch 14/50
1542/1542 - 135s - loss: 2.7828 - accuracy50: 0.5462 - val_loss: 3.2584 - val_accuracy50: 0.4954 - 135s/epoch - 87ms/step
Epoch 15/50
1542/1542 - 132s - loss: 2.7769 - accuracy50: 0.5471 - val_loss: 3.2688 - val_accuracy50: 0.4950 - 132s/epoch - 86ms/step
Epoch 16/50
1542/1542 - 139s - loss: 2.7732 - accuracy50: 0.5480 - val_loss: 3.2314 - val_accuracy50: 0.4969 - 139s/epoch - 90ms/step
Epoch 17/50
1542/1542 - 130s - loss: 2.7678 - accuracy50: 0.5494 - val_loss: 3.2553 - val_accuracy50: 0.4966 - 130s/epoch - 84ms/step
Epoch 18/50
1542/1542 - 138s - loss: 2.7629 - accuracy50: 0.5505 - val_loss: 3.2247 - val_accuracy50: 0.5007 - 138s/epoch - 90ms/step
Epoch 19/50
1542/1542 - 131s - loss: 2.7574 - accuracy50: 0.5520 - val_loss: 3.2792 - val_accuracy50: 0.4976 - 131s/epoch - 85ms/step
Epoch 20/50
1542/1542 - 129s - loss: 2.7529 - accuracy50: 0.5534 - val_loss: 3.2764 - val_accuracy50: 0.5010 - 129s/epoch - 83ms/step
Epoch 21/50
1542/1542 - 129s - loss: 2.7480 - accuracy50: 0.5546 - val_loss: 3.3296 - val_accuracy50: 0.4953 - 129s/epoch - 84ms/step
Epoch 22/50
1542/1542 - 129s - loss: 2.7428 - accuracy50: 0.5560 - val_loss: 3.2826 - val_accuracy50: 0.4986 - 129s/epoch - 84ms/step
Epoch 23/50
1542/1542 - 124s - loss: 2.7380 - accuracy50: 0.5567 - val_loss: 3.2749 - val_accuracy50: 0.4987 - 124s/epoch - 81ms/step
Epoch 24/50
1542/1542 - 131s - loss: 2.7332 - accuracy50: 0.5578 - val_loss: 3.2695 - val_accuracy50: 0.4983 - 131s/epoch - 85ms/step
Epoch 25/50
1542/1542 - 126s - loss: 2.7274 - accuracy50: 0.5596 - val_loss: 3.2891 - val_accuracy50: 0.4981 - 126s/epoch - 82ms/step
Epoch 26/50
1542/1542 - 128s - loss: 2.7236 - accuracy50: 0.5608 - val_loss: 3.2826 - val_accuracy50: 0.4977 - 128s/epoch - 83ms/step
Epoch 27/50
1542/1542 - 126s - loss: 2.7185 - accuracy50: 0.5614 - val_loss: 3.3030 - val_accuracy50: 0.4994 - 126s/epoch - 81ms/step
Epoch 28/50
1542/1542 - 132s - loss: 2.7133 - accuracy50: 0.5627 - val_loss: 3.3078 - val_accuracy50: 0.4990 - 132s/epoch - 85ms/step
testing model: results/WBA/W2/deepOF_L2/h50
Evaluating performance on  test set...
4353/4353 - 174s - 174s/epoch - 40ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0119635
{'0': {'precision': 0.5659844296037825, 'recall': 0.32176654260834125, 'f1-score': 0.4102836466176186, 'support': 333714}, '1': {'precision': 0.5080817057628053, 'recall': 0.8240419403208542, 'f1-score': 0.6285912511037546, 'support': 447493}, '2': {'precision': 0.5259295031415219, 'recall': 0.313889322557014, 'f1-score': 0.39314111663674045, 'support': 333076}, 'accuracy': 0.5211243463285359, 'macro avg': {'precision': 0.5333318795027032, 'recall': 0.48656593516206986, 'f1-score': 0.47733867145270453, 'support': 1114283}, 'weighted avg': {'precision': 0.5307578325129947, 'recall': 0.5211243463285359, 'f1-score': 0.492831221639766, 'support': 1114283}}
[[107378 172809  53527]
 [ 38027 368753  40713]
 [ 44314 184213 104549]]
Evaluating performance on  train set...
1542/1542 - 66s - 66s/epoch - 43ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.058066
{'0': {'precision': 0.5518740106779706, 'recall': 0.3236439444597412, 'f1-score': 0.40801146478496086, 'support': 127115}, '1': {'precision': 0.47247594293117356, 'recall': 0.8130525312151655, 'f1-score': 0.5976495566829941, 'support': 142639}, '2': {'precision': 0.5409479868022211, 'recall': 0.3231523620280751, 'f1-score': 0.4046025902109687, 'support': 124808}, 'accuracy': 0.5004156507722487, 'macro avg': {'precision': 0.5217659801371217, 'recall': 0.4866162792343273, 'f1-score': 0.4700878705596412, 'support': 394562}, 'weighted avg': {'precision': 0.5197145118584696, 'recall': 0.5004156507722487, 'f1-score': 0.4754896633251466, 'support': 394562}}
[[ 41140  64886  21089]
 [ 13529 115973  13137]
 [ 19877  64599  40332]]
Evaluating performance on  val set...
482/482 - 18s - 18s/epoch - 38ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0554351
{'0': {'precision': 0.5640152274093369, 'recall': 0.2899147763845619, 'f1-score': 0.38297365780657444, 'support': 38839}, '1': {'precision': 0.4768023823227647, 'recall': 0.8334499803158217, 'f1-score': 0.6065868644742287, 'support': 45722}, '2': {'precision': 0.5289245613286087, 'recall': 0.31973263136161867, 'f1-score': 0.3985459458590018, 'support': 38748}, 'accuracy': 0.5008231353753578, 'macro avg': {'precision': 0.52324739035357, 'recall': 0.48103246268733413, 'f1-score': 0.46270215604660164, 'support': 123309}, 'weighted avg': {'precision': 0.5206506811690437, 'recall': 0.5008231353753578, 'f1-score': 0.470781020227111, 'support': 123309}}
[[11260 20786  6793]
 [ 3374 38107  4241]
 [ 5330 21029 12389]]
training model: results/WBA/W2/deepOF_L2/h100
Epoch 1/50
1542/1542 - 138s - loss: 3.2308 - accuracy100: 0.4076 - val_loss: 3.3148 - val_accuracy100: 0.3816 - 138s/epoch - 89ms/step
Epoch 2/50
1542/1542 - 124s - loss: 3.1700 - accuracy100: 0.4344 - val_loss: 3.3068 - val_accuracy100: 0.3913 - 124s/epoch - 80ms/step
Epoch 3/50
1542/1542 - 127s - loss: 3.1412 - accuracy100: 0.4457 - val_loss: 3.2956 - val_accuracy100: 0.3995 - 127s/epoch - 82ms/step
Epoch 4/50
1542/1542 - 132s - loss: 3.1259 - accuracy100: 0.4515 - val_loss: 3.2722 - val_accuracy100: 0.4057 - 132s/epoch - 86ms/step
Epoch 5/50
1542/1542 - 129s - loss: 3.1140 - accuracy100: 0.4552 - val_loss: 3.2772 - val_accuracy100: 0.4065 - 129s/epoch - 84ms/step
Epoch 6/50
1542/1542 - 124s - loss: 3.1051 - accuracy100: 0.4584 - val_loss: 3.2695 - val_accuracy100: 0.4112 - 124s/epoch - 80ms/step
Epoch 7/50
1542/1542 - 128s - loss: 3.0971 - accuracy100: 0.4609 - val_loss: 3.2711 - val_accuracy100: 0.4140 - 128s/epoch - 83ms/step
Epoch 8/50
1542/1542 - 128s - loss: 3.0909 - accuracy100: 0.4632 - val_loss: 3.2727 - val_accuracy100: 0.4117 - 128s/epoch - 83ms/step
Epoch 9/50
1542/1542 - 125s - loss: 3.0865 - accuracy100: 0.4647 - val_loss: 3.2754 - val_accuracy100: 0.4125 - 125s/epoch - 81ms/step
Epoch 10/50
1542/1542 - 126s - loss: 3.0793 - accuracy100: 0.4667 - val_loss: 3.2855 - val_accuracy100: 0.4130 - 126s/epoch - 82ms/step
Epoch 11/50
1542/1542 - 129s - loss: 3.0744 - accuracy100: 0.4682 - val_loss: 3.2812 - val_accuracy100: 0.4149 - 129s/epoch - 84ms/step
Epoch 12/50
1542/1542 - 128s - loss: 3.0690 - accuracy100: 0.4697 - val_loss: 3.2862 - val_accuracy100: 0.4138 - 128s/epoch - 83ms/step
Epoch 13/50
1542/1542 - 126s - loss: 3.0654 - accuracy100: 0.4713 - val_loss: 3.2685 - val_accuracy100: 0.4180 - 126s/epoch - 82ms/step
Epoch 14/50
1542/1542 - 126s - loss: 3.0585 - accuracy100: 0.4740 - val_loss: 3.2857 - val_accuracy100: 0.4176 - 126s/epoch - 82ms/step
Epoch 15/50
1542/1542 - 125s - loss: 3.0537 - accuracy100: 0.4758 - val_loss: 3.2972 - val_accuracy100: 0.4150 - 125s/epoch - 81ms/step
Epoch 16/50
1542/1542 - 129s - loss: 3.0497 - accuracy100: 0.4771 - val_loss: 3.2782 - val_accuracy100: 0.4191 - 129s/epoch - 83ms/step
Epoch 17/50
1542/1542 - 128s - loss: 3.0435 - accuracy100: 0.4795 - val_loss: 3.2929 - val_accuracy100: 0.4195 - 128s/epoch - 83ms/step
Epoch 18/50
1542/1542 - 127s - loss: 3.0375 - accuracy100: 0.4819 - val_loss: 3.2964 - val_accuracy100: 0.4190 - 127s/epoch - 83ms/step
Epoch 19/50
1542/1542 - 128s - loss: 3.0319 - accuracy100: 0.4842 - val_loss: 3.3086 - val_accuracy100: 0.4197 - 128s/epoch - 83ms/step
Epoch 20/50
1542/1542 - 128s - loss: 3.0271 - accuracy100: 0.4856 - val_loss: 3.3200 - val_accuracy100: 0.4196 - 128s/epoch - 83ms/step
Epoch 21/50
1542/1542 - 128s - loss: 3.0207 - accuracy100: 0.4880 - val_loss: 3.3155 - val_accuracy100: 0.4206 - 128s/epoch - 83ms/step
Epoch 22/50
1542/1542 - 125s - loss: 3.0147 - accuracy100: 0.4895 - val_loss: 3.3411 - val_accuracy100: 0.4193 - 125s/epoch - 81ms/step
Epoch 23/50
1542/1542 - 129s - loss: 3.0076 - accuracy100: 0.4917 - val_loss: 3.3399 - val_accuracy100: 0.4209 - 129s/epoch - 83ms/step
testing model: results/WBA/W2/deepOF_L2/h100
Evaluating performance on  test set...
4353/4353 - 171s - 171s/epoch - 39ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0646877
{'0': {'precision': 0.5537945515907942, 'recall': 0.21294761582450847, 'f1-score': 0.30761117473270905, 'support': 375266}, '1': {'precision': 0.40677919143861363, 'recall': 0.8427250930740392, 'f1-score': 0.5487024513875794, 'support': 383297}, '2': {'precision': 0.4943180203175542, 'recall': 0.2444450691555156, 'f1-score': 0.3271240926439026, 'support': 355720}, 'accuracy': 0.4396369683464614, 'macro avg': {'precision': 0.484963921115654, 'recall': 0.4333725926846877, 'f1-score': 0.3944792395880637, 'support': 1114283}, 'weighted avg': {'precision': 0.4842363350472704, 'recall': 0.4396369683464614, 'f1-score': 0.39677227494455075, 'support': 1114283}}
[[ 79912 239373  55981]
 [ 27311 323014  32972]
 [ 37076 231690  86954]]
Evaluating performance on  train set...
1542/1542 - 60s - 60s/epoch - 39ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0903767
{'0': {'precision': 0.5151927129358983, 'recall': 0.2245762711864407, 'f1-score': 0.3128005117728389, 'support': 134992}, '1': {'precision': 0.38386374356098446, 'recall': 0.8057030159880888, 'f1-score': 0.5199879257433214, 'support': 128283}, '2': {'precision': 0.4882412241765848, 'recall': 0.24716080038389177, 'f1-score': 0.32818536723506686, 'support': 131287}, 'accuracy': 0.42103142218459966, 'macro avg': {'precision': 0.4624325602244892, 'recall': 0.42581336251947377, 'f1-score': 0.3869912682504091, 'support': 394562}, 'weighted avg': {'precision': 0.46352617058497225, 'recall': 0.42103142218459966, 'f1-score': 0.3852820344370715, 'support': 394562}}
[[ 30316  83639  21037]
 [ 11950 103358  12975]
 [ 16578  82260  32449]]
Evaluating performance on  val set...
482/482 - 20s - 20s/epoch - 42ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0930119
{'0': {'precision': 0.5126668314384577, 'recall': 0.2010175651120533, 'f1-score': 0.28879722932873875, 'support': 41275}, '1': {'precision': 0.3858192419825073, 'recall': 0.8096718141993589, 'f1-score': 0.5226086201040984, 'support': 40861}, '2': {'precision': 0.4749473684210526, 'recall': 0.24656935370266922, 'f1-score': 0.3246146959135384, 'support': 41173}, 'accuracy': 0.41791758914596666, 'macro avg': {'precision': 0.4578111472806725, 'recall': 0.41908624433802716, 'f1-score': 0.3786735151154585, 'support': 123309}, 'weighted avg': {'precision': 0.4580386793686557, 'recall': 0.41791758914596666, 'f1-score': 0.3782349815622978, 'support': 123309}}
[[ 8297 26189  6789]
 [ 3343 33084  4434]
 [ 4544 26477 10152]]
training model: results/WBA/W2/deepOF_L2/h200
Epoch 1/50
1542/1542 - 136s - loss: 3.2795 - accuracy200: 0.3751 - val_loss: 3.2850 - val_accuracy200: 0.3573 - 136s/epoch - 88ms/step
Epoch 2/50
1542/1542 - 131s - loss: 3.2514 - accuracy200: 0.3895 - val_loss: 3.2742 - val_accuracy200: 0.3699 - 131s/epoch - 85ms/step
Epoch 3/50
1542/1542 - 130s - loss: 3.2404 - accuracy200: 0.3970 - val_loss: 3.2735 - val_accuracy200: 0.3710 - 130s/epoch - 84ms/step
Epoch 4/50
1542/1542 - 128s - loss: 3.2321 - accuracy200: 0.4005 - val_loss: 3.2658 - val_accuracy200: 0.3797 - 128s/epoch - 83ms/step
Epoch 5/50
1542/1542 - 126s - loss: 3.2255 - accuracy200: 0.4037 - val_loss: 3.2625 - val_accuracy200: 0.3845 - 126s/epoch - 82ms/step
Epoch 6/50
1542/1542 - 127s - loss: 3.2198 - accuracy200: 0.4067 - val_loss: 3.2640 - val_accuracy200: 0.3812 - 127s/epoch - 82ms/step
Epoch 7/50
1542/1542 - 128s - loss: 3.2145 - accuracy200: 0.4090 - val_loss: 3.2638 - val_accuracy200: 0.3826 - 128s/epoch - 83ms/step
Epoch 8/50
1542/1542 - 126s - loss: 3.2100 - accuracy200: 0.4115 - val_loss: 3.2600 - val_accuracy200: 0.3875 - 126s/epoch - 82ms/step
Epoch 9/50
1542/1542 - 126s - loss: 3.2055 - accuracy200: 0.4132 - val_loss: 3.2624 - val_accuracy200: 0.3870 - 126s/epoch - 82ms/step
Epoch 10/50
1542/1542 - 124s - loss: 3.2022 - accuracy200: 0.4154 - val_loss: 3.2641 - val_accuracy200: 0.3889 - 124s/epoch - 80ms/step
Epoch 11/50
1542/1542 - 131s - loss: 3.1978 - accuracy200: 0.4170 - val_loss: 3.2575 - val_accuracy200: 0.3914 - 131s/epoch - 85ms/step
Epoch 12/50
1542/1542 - 129s - loss: 3.1939 - accuracy200: 0.4188 - val_loss: 3.2570 - val_accuracy200: 0.3948 - 129s/epoch - 83ms/step
Epoch 13/50
1542/1542 - 129s - loss: 3.1904 - accuracy200: 0.4211 - val_loss: 3.2578 - val_accuracy200: 0.3965 - 129s/epoch - 84ms/step
Epoch 14/50
1542/1542 - 126s - loss: 3.1855 - accuracy200: 0.4233 - val_loss: 3.2606 - val_accuracy200: 0.3931 - 126s/epoch - 82ms/step
Epoch 15/50
1542/1542 - 127s - loss: 3.1813 - accuracy200: 0.4250 - val_loss: 3.2684 - val_accuracy200: 0.3943 - 127s/epoch - 82ms/step
Epoch 16/50
1542/1542 - 128s - loss: 3.1766 - accuracy200: 0.4285 - val_loss: 3.2751 - val_accuracy200: 0.3920 - 128s/epoch - 83ms/step
Epoch 17/50
1542/1542 - 127s - loss: 3.1723 - accuracy200: 0.4299 - val_loss: 3.2779 - val_accuracy200: 0.3969 - 127s/epoch - 82ms/step
Epoch 18/50
1542/1542 - 125s - loss: 3.1689 - accuracy200: 0.4325 - val_loss: 3.2891 - val_accuracy200: 0.3942 - 125s/epoch - 81ms/step
Epoch 19/50
1542/1542 - 133s - loss: 3.1627 - accuracy200: 0.4359 - val_loss: 3.2922 - val_accuracy200: 0.3969 - 133s/epoch - 87ms/step
Epoch 20/50
1542/1542 - 131s - loss: 3.1581 - accuracy200: 0.4373 - val_loss: 3.2846 - val_accuracy200: 0.3939 - 131s/epoch - 85ms/step
Epoch 21/50
1542/1542 - 128s - loss: 3.1524 - accuracy200: 0.4400 - val_loss: 3.2865 - val_accuracy200: 0.3982 - 128s/epoch - 83ms/step
Epoch 22/50
1542/1542 - 129s - loss: 3.1476 - accuracy200: 0.4421 - val_loss: 3.2944 - val_accuracy200: 0.3956 - 129s/epoch - 84ms/step
testing model: results/WBA/W2/deepOF_L2/h200
Evaluating performance on  test set...
4353/4353 - 174s - 174s/epoch - 40ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0761876
{'0': {'precision': 0.42126970853620704, 'recall': 0.41011399714810176, 'f1-score': 0.4156170078002539, 'support': 380799}, '1': {'precision': 0.37764519036785854, 'recall': 0.4371299763603272, 'f1-score': 0.40521616239480956, 'support': 382408}, '2': {'precision': 0.40921492066129433, 'recall': 0.350758810058221, 'f1-score': 0.37773868444987047, 'support': 351076}, 'accuracy': 0.4006845657700961, 'macro avg': {'precision': 0.40270993985511994, 'recall': 0.3993342611888833, 'f1-score': 0.39952395154831133, 'support': 1114283}, 'weighted avg': {'precision': 0.40250022946159614, 'recall': 0.4006845657700961, 'f1-score': 0.4001132832182901, 'support': 1114283}}
[[156171 145271  79357]
 [116821 167162  98425]
 [ 97723 130210 123143]]
Evaluating performance on  train set...
1542/1542 - 61s - 61s/epoch - 40ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0818231
{'0': {'precision': 0.41100389421497946, 'recall': 0.39328953472710676, 'f1-score': 0.40195163732582867, 'support': 133642}, '1': {'precision': 0.3686482812440998, 'recall': 0.4448866441347359, 'f1-score': 0.40319522024786697, 'support': 131665}, '2': {'precision': 0.4224017961516338, 'recall': 0.35224169277784223, 'f1-score': 0.38414451508388847, 'support': 129255}, 'accuracy': 0.39706053801430446, 'macro avg': {'precision': 0.400684657203571, 'recall': 0.3968059572132283, 'f1-score': 0.3964304575525281, 'support': 394562}, 'weighted avg': {'precision': 0.40060371384538324, 'recall': 0.39706053801430446, 'f1-score': 0.3965331650959844, 'support': 394562}}
[[52560 51831 29251]
 [40083 58576 33006]
 [35239 48487 45529]]
Evaluating performance on  val set...
482/482 - 22s - 22s/epoch - 46ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0848397
{'0': {'precision': 0.4023601160225104, 'recall': 0.3946312641330513, 'f1-score': 0.3984582146715113, 'support': 41127}, '1': {'precision': 0.3660458452722063, 'recall': 0.43534881456598995, 'f1-score': 0.3977007404771964, 'support': 41082}, '2': {'precision': 0.42084896810506567, 'recall': 0.349294403892944, 'f1-score': 0.38174759346912723, 'support': 41100}, 'accuracy': 0.39308566284699414, 'macro avg': {'precision': 0.3964183097999275, 'recall': 0.3930914941973284, 'f1-score': 0.39263551620594495, 'support': 123309}, 'weighted avg': {'precision': 0.39642404444321794, 'recall': 0.39308566284699414, 'f1-score': 0.3926360517615142, 'support': 123309}}
[[16230 15598  9299]
 [12740 17885 10457]
 [11367 15377 14356]]
training model: results/WBA/W2/deepOF_L2/h300
Epoch 1/50
1542/1542 - 144s - loss: 3.2808 - accuracy300: 0.3795 - val_loss: 3.2965 - val_accuracy300: 0.3590 - 144s/epoch - 94ms/step
Epoch 2/50
1542/1542 - 133s - loss: 3.2600 - accuracy300: 0.3887 - val_loss: 3.2825 - val_accuracy300: 0.3781 - 133s/epoch - 86ms/step
Epoch 3/50
1542/1542 - 131s - loss: 3.2513 - accuracy300: 0.3937 - val_loss: 3.2837 - val_accuracy300: 0.3747 - 131s/epoch - 85ms/step
Epoch 4/50
1542/1542 - 127s - loss: 3.2433 - accuracy300: 0.3967 - val_loss: 3.2831 - val_accuracy300: 0.3752 - 127s/epoch - 82ms/step
Epoch 5/50
1542/1542 - 129s - loss: 3.2372 - accuracy300: 0.3998 - val_loss: 3.2915 - val_accuracy300: 0.3604 - 129s/epoch - 84ms/step
Epoch 6/50
1542/1542 - 124s - loss: 3.2324 - accuracy300: 0.4020 - val_loss: 3.2889 - val_accuracy300: 0.3652 - 124s/epoch - 80ms/step
Epoch 7/50
1542/1542 - 123s - loss: 3.2284 - accuracy300: 0.4042 - val_loss: 3.2886 - val_accuracy300: 0.3657 - 123s/epoch - 80ms/step
Epoch 8/50
1542/1542 - 124s - loss: 3.2250 - accuracy300: 0.4065 - val_loss: 3.2888 - val_accuracy300: 0.3702 - 124s/epoch - 80ms/step
Epoch 9/50
1542/1542 - 128s - loss: 3.2219 - accuracy300: 0.4093 - val_loss: 3.2855 - val_accuracy300: 0.3778 - 128s/epoch - 83ms/step
Epoch 10/50
1542/1542 - 124s - loss: 3.2195 - accuracy300: 0.4095 - val_loss: 3.2873 - val_accuracy300: 0.3761 - 124s/epoch - 80ms/step
Epoch 11/50
1542/1542 - 123s - loss: 3.2161 - accuracy300: 0.4123 - val_loss: 3.2866 - val_accuracy300: 0.3755 - 123s/epoch - 80ms/step
Epoch 12/50
1542/1542 - 125s - loss: 3.2138 - accuracy300: 0.4134 - val_loss: 3.2873 - val_accuracy300: 0.3771 - 125s/epoch - 81ms/step
testing model: results/WBA/W2/deepOF_L2/h300
Evaluating performance on  test set...
4353/4353 - 167s - 167s/epoch - 38ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0881331
{'0': {'precision': 0.41074772276112576, 'recall': 0.5738055551458116, 'f1-score': 0.47877414127324386, 'support': 406758}, '1': {'precision': 0.33867327503225675, 'recall': 0.23914848077284626, 'f1-score': 0.2803397358740062, 'support': 345735}, '2': {'precision': 0.38635580757561705, 'recall': 0.3224163188590066, 'f1-score': 0.3515020204729203, 'support': 361790}, 'accuracy': 0.38834748443618006, 'macro avg': {'precision': 0.3785922684563332, 'recall': 0.37845678492588813, 'f1-score': 0.37020529920672346, 'support': 1114283}, 'weighted avg': {'precision': 0.3804651013978763, 'recall': 0.38834748443618006, 'f1-score': 0.3758815190802691, 'support': 1114283}}
[[233400  81141  92217]
 [170001  82682  93052]
 [164831  80312 116647]]
Evaluating performance on  train set...
1542/1542 - 61s - 61s/epoch - 40ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0924003
{'0': {'precision': 0.37632424070338966, 'recall': 0.5693389029610867, 'f1-score': 0.45313393420300274, 'support': 135018}, '1': {'precision': 0.3531574199368516, 'recall': 0.23990562496648613, 'f1-score': 0.2857181956272837, 'support': 130543}, '2': {'precision': 0.38202413053319423, 'recall': 0.30092014790583016, 'f1-score': 0.3366563319818745, 'support': 129001}, 'accuracy': 0.37258529711426847, 'macro avg': {'precision': 0.37050193039114515, 'recall': 0.37005489194446767, 'f1-score': 0.35850282060405364, 'support': 394562}, 'weighted avg': {'precision': 0.37052293496337524, 'recall': 0.37258529711426847, 'f1-score': 0.359661476325615, 'support': 394562}}
[[76871 28419 29728]
 [66158 31318 33067]
 [61239 28943 38819]]
Evaluating performance on  val set...
482/482 - 19s - 19s/epoch - 39ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0933073
{'0': {'precision': 0.3870097072054297, 'recall': 0.5674380930340199, 'f1-score': 0.46016984938769767, 'support': 43210}, '1': {'precision': 0.33330966917506744, 'recall': 0.2518911958796073, 'f1-score': 0.28693659281894573, 'support': 37278}, '2': {'precision': 0.406487949153609, 'recall': 0.3016977651152472, 'f1-score': 0.3463399595190542, 'support': 42821}, 'accuracy': 0.3797614123867682, 'macro avg': {'precision': 0.3756024418447021, 'recall': 0.3736756846762915, 'f1-score': 0.3644821339085658, 'support': 123309}, 'weighted avg': {'precision': 0.37753957753741796, 'recall': 0.3797614123867682, 'f1-score': 0.3682698335540187, 'support': 123309}}
[[24519  9033  9658]
 [18683  9390  9205]
 [20153  9749 12919]]
training model: results/WBA/W2/deepOF_L2/h500
Epoch 1/50
1542/1542 - 127s - loss: 3.2627 - accuracy500: 0.3913 - val_loss: 3.2882 - val_accuracy500: 0.3611 - 127s/epoch - 82ms/step
Epoch 2/50
1542/1542 - 131s - loss: 3.2454 - accuracy500: 0.3990 - val_loss: 3.2827 - val_accuracy500: 0.3705 - 131s/epoch - 85ms/step
Epoch 3/50
1542/1542 - 123s - loss: 3.2421 - accuracy500: 0.3996 - val_loss: 3.2850 - val_accuracy500: 0.3611 - 123s/epoch - 80ms/step
Epoch 4/50
1542/1542 - 124s - loss: 3.2376 - accuracy500: 0.4020 - val_loss: 3.2749 - val_accuracy500: 0.3855 - 124s/epoch - 81ms/step
Epoch 5/50
1542/1542 - 125s - loss: 3.2303 - accuracy500: 0.4065 - val_loss: 3.2717 - val_accuracy500: 0.3888 - 125s/epoch - 81ms/step
Epoch 6/50
1542/1542 - 128s - loss: 3.2285 - accuracy500: 0.4081 - val_loss: 3.2678 - val_accuracy500: 0.3913 - 128s/epoch - 83ms/step
Epoch 7/50
1542/1542 - 126s - loss: 3.2232 - accuracy500: 0.4117 - val_loss: 3.2709 - val_accuracy500: 0.3880 - 126s/epoch - 82ms/step
Epoch 8/50
1542/1542 - 122s - loss: 3.2214 - accuracy500: 0.4113 - val_loss: 3.2699 - val_accuracy500: 0.3917 - 122s/epoch - 79ms/step
Epoch 9/50
1542/1542 - 121s - loss: 3.2174 - accuracy500: 0.4158 - val_loss: 3.2696 - val_accuracy500: 0.3910 - 121s/epoch - 78ms/step
Epoch 10/50
1542/1542 - 128s - loss: 3.2152 - accuracy500: 0.4171 - val_loss: 3.2691 - val_accuracy500: 0.3909 - 128s/epoch - 83ms/step
Epoch 11/50
1542/1542 - 127s - loss: 3.2132 - accuracy500: 0.4186 - val_loss: 3.2686 - val_accuracy500: 0.3916 - 127s/epoch - 82ms/step
Epoch 12/50
1542/1542 - 122s - loss: 3.2113 - accuracy500: 0.4200 - val_loss: 3.2668 - val_accuracy500: 0.3936 - 122s/epoch - 79ms/step
Epoch 13/50
1542/1542 - 130s - loss: 3.2085 - accuracy500: 0.4219 - val_loss: 3.2671 - val_accuracy500: 0.3927 - 130s/epoch - 85ms/step
Epoch 14/50
1542/1542 - 121s - loss: 3.2063 - accuracy500: 0.4228 - val_loss: 3.2685 - val_accuracy500: 0.3923 - 121s/epoch - 79ms/step
Epoch 15/50
1542/1542 - 125s - loss: 3.2042 - accuracy500: 0.4240 - val_loss: 3.2675 - val_accuracy500: 0.3922 - 125s/epoch - 81ms/step
Epoch 16/50
1542/1542 - 125s - loss: 3.2013 - accuracy500: 0.4253 - val_loss: 3.2673 - val_accuracy500: 0.3933 - 125s/epoch - 81ms/step
Epoch 17/50
1542/1542 - 125s - loss: 3.1992 - accuracy500: 0.4270 - val_loss: 3.2669 - val_accuracy500: 0.3940 - 125s/epoch - 81ms/step
Epoch 18/50
1542/1542 - 123s - loss: 3.1956 - accuracy500: 0.4291 - val_loss: 3.2690 - val_accuracy500: 0.3925 - 123s/epoch - 80ms/step
Epoch 19/50
1542/1542 - 128s - loss: 3.1934 - accuracy500: 0.4301 - val_loss: 3.2698 - val_accuracy500: 0.3907 - 128s/epoch - 83ms/step
Epoch 20/50
1542/1542 - 124s - loss: 3.1913 - accuracy500: 0.4322 - val_loss: 3.2725 - val_accuracy500: 0.3901 - 124s/epoch - 80ms/step
Epoch 21/50
1542/1542 - 125s - loss: 3.1873 - accuracy500: 0.4345 - val_loss: 3.2749 - val_accuracy500: 0.3878 - 125s/epoch - 81ms/step
Epoch 22/50
1542/1542 - 123s - loss: 3.1848 - accuracy500: 0.4369 - val_loss: 3.2784 - val_accuracy500: 0.3853 - 123s/epoch - 80ms/step
testing model: results/WBA/W2/deepOF_L2/h500
Evaluating performance on  test set...
4353/4353 - 166s - 166s/epoch - 38ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0818992
{'0': {'precision': 0.4386845797729774, 'recall': 0.5840677275951021, 'f1-score': 0.5010431241135364, 'support': 446967}, '1': {'precision': 0.32928905565565236, 'recall': 0.07054278389212312, 'f1-score': 0.11619368141081914, 'support': 282396}, '2': {'precision': 0.38954328731106563, 'recall': 0.4642003533201704, 'f1-score': 0.42360756320152304, 'support': 384920}, 'accuracy': 0.41251638946299996, 'macro avg': {'precision': 0.3858389742465651, 'recall': 0.37293695493579854, 'f1-score': 0.3469481229086262, 'support': 1114283}, 'weighted avg': {'precision': 0.3939846922910045, 'recall': 0.41251638946299996, 'f1-score': 0.3767601194121017, 'support': 1114283}}
[[261059  21134 164774]
 [147238  19921 115237]
 [186798  19442 178680]]
Evaluating performance on  train set...
1542/1542 - 65s - 65s/epoch - 42ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0900301
{'0': {'precision': 0.39332329077960093, 'recall': 0.5824726620685761, 'f1-score': 0.4695655143173405, 'support': 141653}, '1': {'precision': 0.3482782730291907, 'recall': 0.06620976116303219, 'f1-score': 0.11126700591236852, 'support': 120375}, '2': {'precision': 0.3794903152485423, 'recall': 0.4635867022801696, 'f1-score': 0.4173442286661369, 'support': 132534}, 'accuracy': 0.38503454463430337, 'macro avg': {'precision': 0.3736972930191113, 'recall': 0.3707563751705926, 'f1-score': 0.332725582965282, 'support': 394562}, 'weighted avg': {'precision': 0.3749342072116472, 'recall': 0.38503454463430337, 'f1-score': 0.3427127539862769, 'support': 394562}}
[[82509  7592 51552]
 [63494  7970 48911]
 [63771  7322 61441]]
Evaluating performance on  val set...
482/482 - 19s - 19s/epoch - 39ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0883477
{'0': {'precision': 0.39362223310916133, 'recall': 0.591051962816826, 'f1-score': 0.47254451157568306, 'support': 44859}, '1': {'precision': 0.3288920056100982, 'recall': 0.05522032202042799, 'f1-score': 0.0945636010787106, 'support': 33973}, '2': {'precision': 0.4018031286072523, 'recall': 0.45392000359736495, 'f1-score': 0.42627450566388314, 'support': 44477}, 'accuracy': 0.3939615113252074, 'macro avg': {'precision': 0.37477245577550394, 'recall': 0.3667307628115397, 'f1-score': 0.3311275394394256, 'support': 123309}, 'weighted avg': {'precision': 0.378739148097061, 'recall': 0.3939615113252074, 'f1-score': 0.35171718733128265, 'support': 123309}}
[[26514  1833 16512]
 [18552  1876 13545]
 [22293  1995 20189]]
training model: results/WBA/W2/deepOF_L2/h1000
Epoch 1/50
1542/1542 - 132s - loss: 3.3058 - accuracy1000: 0.3663 - val_loss: 3.4143 - val_accuracy1000: 0.3330 - 132s/epoch - 86ms/step
Epoch 2/50
1542/1542 - 126s - loss: 3.2869 - accuracy1000: 0.3672 - val_loss: 3.3950 - val_accuracy1000: 0.3314 - 126s/epoch - 81ms/step
Epoch 3/50
1542/1542 - 120s - loss: 3.2742 - accuracy1000: 0.3743 - val_loss: 3.3992 - val_accuracy1000: 0.3320 - 120s/epoch - 78ms/step
Epoch 4/50
1542/1542 - 127s - loss: 3.2662 - accuracy1000: 0.3789 - val_loss: 3.4015 - val_accuracy1000: 0.3324 - 127s/epoch - 82ms/step
Epoch 5/50
1542/1542 - 130s - loss: 3.2617 - accuracy1000: 0.3808 - val_loss: 3.3991 - val_accuracy1000: 0.3323 - 130s/epoch - 85ms/step
Epoch 6/50
1542/1542 - 127s - loss: 3.2593 - accuracy1000: 0.3828 - val_loss: 3.4027 - val_accuracy1000: 0.3323 - 127s/epoch - 82ms/step
Epoch 7/50
1542/1542 - 124s - loss: 3.2560 - accuracy1000: 0.3848 - val_loss: 3.4130 - val_accuracy1000: 0.3307 - 124s/epoch - 80ms/step
Epoch 8/50
1542/1542 - 121s - loss: 3.2545 - accuracy1000: 0.3865 - val_loss: 3.4090 - val_accuracy1000: 0.3320 - 121s/epoch - 79ms/step
Epoch 9/50
1542/1542 - 129s - loss: 3.2525 - accuracy1000: 0.3868 - val_loss: 3.4007 - val_accuracy1000: 0.3322 - 129s/epoch - 84ms/step
Epoch 10/50
1542/1542 - 130s - loss: 3.2505 - accuracy1000: 0.3883 - val_loss: 3.4107 - val_accuracy1000: 0.3312 - 130s/epoch - 85ms/step
Epoch 11/50
1542/1542 - 127s - loss: 3.2490 - accuracy1000: 0.3901 - val_loss: 3.4085 - val_accuracy1000: 0.3313 - 127s/epoch - 82ms/step
Epoch 12/50
1542/1542 - 131s - loss: 3.2473 - accuracy1000: 0.3909 - val_loss: 3.4070 - val_accuracy1000: 0.3323 - 131s/epoch - 85ms/step
testing model: results/WBA/W2/deepOF_L2/h1000
Evaluating performance on  test set...
4353/4353 - 164s - 164s/epoch - 38ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1202574
{'0': {'precision': 0.37689111270978065, 'recall': 0.08925170552353152, 'f1-score': 0.14432561562783966, 'support': 393281}, '1': {'precision': 0.35212612997082465, 'recall': 0.9142138208477656, 'f1-score': 0.5084236258879288, 'support': 386286}, '2': {'precision': 0.3501753616834722, 'recall': 0.01909081131466676, 'f1-score': 0.03620765857141237, 'support': 334716}, 'accuracy': 0.3541640678355499, 'macro avg': {'precision': 0.3597308681213591, 'recall': 0.34085211256198794, 'f1-score': 0.22965230002906026, 'support': 1114283}, 'weighted avg': {'precision': 0.3602808301847648, 'recall': 0.3541640678355499, 'f1-score': 0.23806944361160112, 'support': 1114283}}
[[ 35101 351712   6468]
 [ 27748 353148   5390]
 [ 30284 298042   6390]]
Evaluating performance on  train set...
1542/1542 - 64s - 64s/epoch - 41ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1220169
{'0': {'precision': 0.3883933148774736, 'recall': 0.11070439617444418, 'f1-score': 0.17229831533821166, 'support': 136869}, '1': {'precision': 0.34097963726913344, 'recall': 0.908394729601663, 'f1-score': 0.4958387391483912, 'support': 130844}, '2': {'precision': 0.38267355134825015, 'recall': 0.02103288161514872, 'f1-score': 0.03987416025885324, 'support': 126849}, 'accuracy': 0.34640436737445574, 'macro avg': {'precision': 0.37068216783161906, 'recall': 0.3467106691304187, 'f1-score': 0.2360037382484854, 'support': 394562}, 'weighted avg': {'precision': 0.3708312041904228, 'recall': 0.34640436737445574, 'f1-score': 0.23701679194102082, 'support': 394562}}
[[ 15152 119247   2470]
 [ 10152 118858   1834]
 [ 13708 110473   2668]]
Evaluating performance on  val set...
482/482 - 19s - 19s/epoch - 39ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1313248
{'0': {'precision': 0.3564762971257932, 'recall': 0.09158036056770234, 'f1-score': 0.14572365911345084, 'support': 41712}, '1': {'precision': 0.3283982511923688, 'recall': 0.9138325415378428, 'f1-score': 0.48316465874128656, 'support': 39783}, '2': {'precision': 0.3737427210164108, 'recall': 0.01688429712536471, 'f1-score': 0.03230899480584857, 'support': 41814}, 'accuracy': 0.33153297812811716, 'macro avg': {'precision': 0.3528724231115243, 'recall': 0.34076573307696995, 'f1-score': 0.22039910422019535, 'support': 123309}, 'weighted avg': {'precision': 0.3532725516343275, 'recall': 0.33153297812811716, 'f1-score': 0.21613291159977469, 'support': 123309}}
[[ 3820 37220   672]
 [ 2917 36355   511]
 [ 3979 37129   706]]
training model: results/WBA/W2/deepVOL_L2/h10
Epoch 1/50
1542/1542 - 128s - loss: 2.9157 - accuracy10: 0.5081 - val_loss: 2.8865 - val_accuracy10: 0.6560 - 128s/epoch - 83ms/step
Epoch 2/50
1542/1542 - 119s - loss: 2.7056 - accuracy10: 0.5735 - val_loss: 2.8553 - val_accuracy10: 0.6604 - 119s/epoch - 77ms/step
Epoch 3/50
1542/1542 - 118s - loss: 2.6345 - accuracy10: 0.5940 - val_loss: 2.8360 - val_accuracy10: 0.6551 - 118s/epoch - 76ms/step
Epoch 4/50
1542/1542 - 111s - loss: 2.5999 - accuracy10: 0.6030 - val_loss: 2.8107 - val_accuracy10: 0.6557 - 111s/epoch - 72ms/step
Epoch 5/50
1542/1542 - 113s - loss: 2.5744 - accuracy10: 0.6081 - val_loss: 2.7645 - val_accuracy10: 0.6578 - 113s/epoch - 73ms/step
Epoch 6/50
1542/1542 - 111s - loss: 2.5602 - accuracy10: 0.6119 - val_loss: 2.7601 - val_accuracy10: 0.6613 - 111s/epoch - 72ms/step
Epoch 7/50
1542/1542 - 117s - loss: 2.5451 - accuracy10: 0.6142 - val_loss: 2.7469 - val_accuracy10: 0.6658 - 117s/epoch - 76ms/step
Epoch 8/50
1542/1542 - 116s - loss: 2.5317 - accuracy10: 0.6157 - val_loss: 2.7456 - val_accuracy10: 0.6672 - 116s/epoch - 75ms/step
Epoch 9/50
1542/1542 - 116s - loss: 2.5226 - accuracy10: 0.6175 - val_loss: 2.7644 - val_accuracy10: 0.6619 - 116s/epoch - 75ms/step
Epoch 10/50
1542/1542 - 119s - loss: 2.5129 - accuracy10: 0.6182 - val_loss: 2.7264 - val_accuracy10: 0.6600 - 119s/epoch - 77ms/step
Epoch 11/50
1542/1542 - 113s - loss: 2.5038 - accuracy10: 0.6198 - val_loss: 2.7552 - val_accuracy10: 0.6596 - 113s/epoch - 73ms/step
Epoch 12/50
1542/1542 - 115s - loss: 2.4966 - accuracy10: 0.6211 - val_loss: 2.7486 - val_accuracy10: 0.6592 - 115s/epoch - 75ms/step
Epoch 13/50
1542/1542 - 116s - loss: 2.4899 - accuracy10: 0.6224 - val_loss: 2.7678 - val_accuracy10: 0.6596 - 116s/epoch - 75ms/step
Epoch 14/50
1542/1542 - 115s - loss: 2.4813 - accuracy10: 0.6234 - val_loss: 2.7583 - val_accuracy10: 0.6606 - 115s/epoch - 75ms/step
Epoch 15/50
1542/1542 - 114s - loss: 2.4764 - accuracy10: 0.6240 - val_loss: 2.7478 - val_accuracy10: 0.6586 - 114s/epoch - 74ms/step
Epoch 16/50
1542/1542 - 113s - loss: 2.4701 - accuracy10: 0.6246 - val_loss: 2.7190 - val_accuracy10: 0.6520 - 113s/epoch - 73ms/step
Epoch 17/50
1542/1542 - 110s - loss: 2.4644 - accuracy10: 0.6249 - val_loss: 2.7420 - val_accuracy10: 0.6519 - 110s/epoch - 71ms/step
Epoch 18/50
1542/1542 - 113s - loss: 2.4589 - accuracy10: 0.6259 - val_loss: 2.7491 - val_accuracy10: 0.6558 - 113s/epoch - 73ms/step
Epoch 19/50
1542/1542 - 108s - loss: 2.4536 - accuracy10: 0.6266 - val_loss: 2.7346 - val_accuracy10: 0.6613 - 108s/epoch - 70ms/step
Epoch 20/50
1542/1542 - 115s - loss: 2.4476 - accuracy10: 0.6278 - val_loss: 2.7169 - val_accuracy10: 0.6583 - 115s/epoch - 74ms/step
Epoch 21/50
1542/1542 - 115s - loss: 2.4439 - accuracy10: 0.6285 - val_loss: 2.7090 - val_accuracy10: 0.6546 - 115s/epoch - 74ms/step
Epoch 22/50
1542/1542 - 110s - loss: 2.4392 - accuracy10: 0.6291 - val_loss: 2.7116 - val_accuracy10: 0.6555 - 110s/epoch - 71ms/step
Epoch 23/50
1542/1542 - 116s - loss: 2.4349 - accuracy10: 0.6291 - val_loss: 2.7044 - val_accuracy10: 0.6619 - 116s/epoch - 75ms/step
Epoch 24/50
1542/1542 - 111s - loss: 2.4296 - accuracy10: 0.6296 - val_loss: 2.7035 - val_accuracy10: 0.6589 - 111s/epoch - 72ms/step
Epoch 25/50
1542/1542 - 116s - loss: 2.4268 - accuracy10: 0.6296 - val_loss: 2.7139 - val_accuracy10: 0.6610 - 116s/epoch - 75ms/step
Epoch 26/50
1542/1542 - 111s - loss: 2.4229 - accuracy10: 0.6304 - val_loss: 2.6909 - val_accuracy10: 0.6567 - 111s/epoch - 72ms/step
Epoch 27/50
1542/1542 - 111s - loss: 2.4180 - accuracy10: 0.6311 - val_loss: 2.6970 - val_accuracy10: 0.6520 - 111s/epoch - 72ms/step
Epoch 28/50
1542/1542 - 111s - loss: 2.4136 - accuracy10: 0.6306 - val_loss: 2.6906 - val_accuracy10: 0.6534 - 111s/epoch - 72ms/step
Epoch 29/50
1542/1542 - 111s - loss: 2.4103 - accuracy10: 0.6321 - val_loss: 2.7118 - val_accuracy10: 0.6658 - 111s/epoch - 72ms/step
Epoch 30/50
1542/1542 - 108s - loss: 2.4081 - accuracy10: 0.6321 - val_loss: 2.6932 - val_accuracy10: 0.6594 - 108s/epoch - 70ms/step
Epoch 31/50
1542/1542 - 112s - loss: 2.4047 - accuracy10: 0.6325 - val_loss: 2.7035 - val_accuracy10: 0.6571 - 112s/epoch - 73ms/step
Epoch 32/50
1542/1542 - 111s - loss: 2.4009 - accuracy10: 0.6334 - val_loss: 2.6798 - val_accuracy10: 0.6556 - 111s/epoch - 72ms/step
Epoch 33/50
1542/1542 - 113s - loss: 2.3965 - accuracy10: 0.6329 - val_loss: 2.6979 - val_accuracy10: 0.6552 - 113s/epoch - 74ms/step
Epoch 34/50
1542/1542 - 111s - loss: 2.3904 - accuracy10: 0.6339 - val_loss: 2.6801 - val_accuracy10: 0.6537 - 111s/epoch - 72ms/step
Epoch 35/50
1542/1542 - 114s - loss: 2.3889 - accuracy10: 0.6340 - val_loss: 2.6796 - val_accuracy10: 0.6573 - 114s/epoch - 74ms/step
Epoch 36/50
1542/1542 - 117s - loss: 2.3866 - accuracy10: 0.6343 - val_loss: 2.6959 - val_accuracy10: 0.6559 - 117s/epoch - 76ms/step
Epoch 37/50
1542/1542 - 111s - loss: 2.3818 - accuracy10: 0.6346 - val_loss: 2.6893 - val_accuracy10: 0.6573 - 111s/epoch - 72ms/step
Epoch 38/50
1542/1542 - 113s - loss: 2.3786 - accuracy10: 0.6352 - val_loss: 2.7003 - val_accuracy10: 0.6563 - 113s/epoch - 73ms/step
Epoch 39/50
1542/1542 - 114s - loss: 2.3765 - accuracy10: 0.6348 - val_loss: 2.6845 - val_accuracy10: 0.6535 - 114s/epoch - 74ms/step
Epoch 40/50
1542/1542 - 118s - loss: 2.3712 - accuracy10: 0.6351 - val_loss: 2.6902 - val_accuracy10: 0.6604 - 118s/epoch - 77ms/step
Epoch 41/50
1542/1542 - 112s - loss: 2.3673 - accuracy10: 0.6364 - val_loss: 2.7018 - val_accuracy10: 0.6524 - 112s/epoch - 72ms/step
Epoch 42/50
1542/1542 - 114s - loss: 2.3646 - accuracy10: 0.6362 - val_loss: 2.6812 - val_accuracy10: 0.6508 - 114s/epoch - 74ms/step
Epoch 43/50
1542/1542 - 110s - loss: 2.3615 - accuracy10: 0.6367 - val_loss: 2.6993 - val_accuracy10: 0.6578 - 110s/epoch - 71ms/step
Epoch 44/50
1542/1542 - 112s - loss: 2.3579 - accuracy10: 0.6370 - val_loss: 2.6902 - val_accuracy10: 0.6453 - 112s/epoch - 73ms/step
Epoch 45/50
1542/1542 - 106s - loss: 2.3550 - accuracy10: 0.6373 - val_loss: 2.6915 - val_accuracy10: 0.6533 - 106s/epoch - 69ms/step
testing model: results/WBA/W2/deepVOL_L2/h10
Evaluating performance on  test set...
4353/4353 - 155s - 155s/epoch - 36ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.7536309
{'0': {'precision': 0.4590825601657797, 'recall': 0.5206604065848369, 'f1-score': 0.4879363680959484, 'support': 187218}, '1': {'precision': 0.8311035654674219, 'recall': 0.7446599830048919, 'f1-score': 0.7855107037299884, 'support': 740213}, '2': {'precision': 0.4323454876746183, 'recall': 0.5523796272015499, 'f1-score': 0.4850467114043497, 'support': 186857}, 'accuracy': 0.6747806671165802, 'macro avg': {'precision': 0.57417720443594, 'recall': 0.605900005597093, 'f1-score': 0.5861645944100955, 'support': 1114288}, 'weighted avg': {'precision': 0.7017296812357935, 'recall': 0.6747806671165802, 'f1-score': 0.6851281525558525, 'support': 1114288}}
[[ 97477  54219  35522]
 [ 89009 551207  99997]
 [ 25844  57797 103216]]
Evaluating performance on  train set...
1542/1542 - 57s - 57s/epoch - 37ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.80570894
{'0': {'precision': 0.4476093477190312, 'recall': 0.534308617234469, 'f1-score': 0.4871313901509154, 'support': 74850}, '1': {'precision': 0.8014131207073498, 'recall': 0.7383326733633417, 'f1-score': 0.7685807542503343, 'support': 247486}, '2': {'precision': 0.46657773057545104, 'recall': 0.49876085120522795, 'f1-score': 0.48213281940094754, 'support': 72227}, 'accuracy': 0.6557736026946267, 'macro avg': {'precision': 0.5718667330006107, 'recall': 0.5904673806010129, 'f1-score': 0.5792816546007324, 'support': 394563}, 'weighted avg': {'precision': 0.6730017690823057, 'recall': 0.6557736026946267, 'f1-score': 0.6627528892624663, 'support': 394563}}
[[ 39993  21779  13078]
 [ 36652 182727  28107]
 [ 12703  23500  36024]]
Evaluating performance on  val set...
482/482 - 17s - 17s/epoch - 36ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.80143785
{'0': {'precision': 0.4459599172896453, 'recall': 0.5063434015079687, 'f1-score': 0.4742372666342475, 'support': 22149}, '1': {'precision': 0.8002630461289748, 'recall': 0.7374973170208199, 'f1-score': 0.7675992483277921, 'support': 79203}, '2': {'precision': 0.45063763855230227, 'recall': 0.5165771017396849, 'f1-score': 0.4813596723885506, 'support': 21958}, 'accuracy': 0.6566377422755656, 'macro avg': {'precision': 0.5656202006569742, 'recall': 0.5868059400894912, 'f1-score': 0.5743987291168634, 'support': 123310}, 'weighted avg': {'precision': 0.674364621830614, 'recall': 0.6566377422755656, 'f1-score': 0.6639343132778839, 'support': 123310}}
[[11215  7111  3823]
 [10786 58412 10005]
 [ 3147  7468 11343]]
training model: results/WBA/W2/deepVOL_L2/h20
Epoch 1/50
1542/1542 - 119s - loss: 2.9841 - accuracy20: 0.5031 - val_loss: 2.9886 - val_accuracy20: 0.5880 - 119s/epoch - 77ms/step
Epoch 2/50
1542/1542 - 117s - loss: 2.8013 - accuracy20: 0.5587 - val_loss: 2.9784 - val_accuracy20: 0.6031 - 117s/epoch - 76ms/step
Epoch 3/50
1542/1542 - 113s - loss: 2.7416 - accuracy20: 0.5722 - val_loss: 2.9915 - val_accuracy20: 0.6048 - 113s/epoch - 73ms/step
Epoch 4/50
1542/1542 - 110s - loss: 2.7053 - accuracy20: 0.5828 - val_loss: 2.9723 - val_accuracy20: 0.6134 - 110s/epoch - 71ms/step
Epoch 5/50
1542/1542 - 112s - loss: 2.6839 - accuracy20: 0.5864 - val_loss: 2.9749 - val_accuracy20: 0.6193 - 112s/epoch - 72ms/step
Epoch 6/50
1542/1542 - 113s - loss: 2.6675 - accuracy20: 0.5904 - val_loss: 2.9742 - val_accuracy20: 0.6163 - 113s/epoch - 73ms/step
Epoch 7/50
1542/1542 - 114s - loss: 2.6540 - accuracy20: 0.5933 - val_loss: 2.9996 - val_accuracy20: 0.6136 - 114s/epoch - 74ms/step
Epoch 8/50
1542/1542 - 111s - loss: 2.6415 - accuracy20: 0.5953 - val_loss: 2.9885 - val_accuracy20: 0.6219 - 111s/epoch - 72ms/step
Epoch 9/50
1542/1542 - 112s - loss: 2.6283 - accuracy20: 0.5978 - val_loss: 3.0082 - val_accuracy20: 0.6109 - 112s/epoch - 72ms/step
Epoch 10/50
1542/1542 - 112s - loss: 2.6191 - accuracy20: 0.5985 - val_loss: 2.9834 - val_accuracy20: 0.6224 - 112s/epoch - 72ms/step
Epoch 11/50
1542/1542 - 115s - loss: 2.6115 - accuracy20: 0.5996 - val_loss: 2.9870 - val_accuracy20: 0.6200 - 115s/epoch - 74ms/step
Epoch 12/50
1542/1542 - 113s - loss: 2.6037 - accuracy20: 0.6005 - val_loss: 2.9386 - val_accuracy20: 0.6225 - 113s/epoch - 73ms/step
Epoch 13/50
1542/1542 - 110s - loss: 2.5986 - accuracy20: 0.6019 - val_loss: 2.9512 - val_accuracy20: 0.6301 - 110s/epoch - 71ms/step
Epoch 14/50
1542/1542 - 113s - loss: 2.5921 - accuracy20: 0.6026 - val_loss: 2.9442 - val_accuracy20: 0.6240 - 113s/epoch - 73ms/step
Epoch 15/50
1542/1542 - 113s - loss: 2.5860 - accuracy20: 0.6030 - val_loss: 2.9405 - val_accuracy20: 0.6269 - 113s/epoch - 73ms/step
Epoch 16/50
1542/1542 - 106s - loss: 2.5794 - accuracy20: 0.6035 - val_loss: 2.9406 - val_accuracy20: 0.6282 - 106s/epoch - 69ms/step
Epoch 17/50
1542/1542 - 111s - loss: 2.5752 - accuracy20: 0.6047 - val_loss: 2.9339 - val_accuracy20: 0.6270 - 111s/epoch - 72ms/step
Epoch 18/50
1542/1542 - 107s - loss: 2.5709 - accuracy20: 0.6055 - val_loss: 2.9413 - val_accuracy20: 0.6256 - 107s/epoch - 69ms/step
Epoch 19/50
1542/1542 - 113s - loss: 2.5651 - accuracy20: 0.6063 - val_loss: 2.9557 - val_accuracy20: 0.6258 - 113s/epoch - 73ms/step
Epoch 20/50
1542/1542 - 108s - loss: 2.5602 - accuracy20: 0.6072 - val_loss: 2.9285 - val_accuracy20: 0.6227 - 108s/epoch - 70ms/step
Epoch 21/50
1542/1542 - 111s - loss: 2.5568 - accuracy20: 0.6075 - val_loss: 2.9501 - val_accuracy20: 0.6278 - 111s/epoch - 72ms/step
Epoch 22/50
1542/1542 - 110s - loss: 2.5526 - accuracy20: 0.6081 - val_loss: 2.9378 - val_accuracy20: 0.6276 - 110s/epoch - 71ms/step
Epoch 23/50
1542/1542 - 114s - loss: 2.5502 - accuracy20: 0.6084 - val_loss: 2.9216 - val_accuracy20: 0.6242 - 114s/epoch - 74ms/step
Epoch 24/50
1542/1542 - 116s - loss: 2.5443 - accuracy20: 0.6093 - val_loss: 2.9340 - val_accuracy20: 0.6291 - 116s/epoch - 75ms/step
Epoch 25/50
1542/1542 - 109s - loss: 2.5420 - accuracy20: 0.6095 - val_loss: 2.9273 - val_accuracy20: 0.6254 - 109s/epoch - 71ms/step
Epoch 26/50
1542/1542 - 110s - loss: 2.5381 - accuracy20: 0.6099 - val_loss: 2.9412 - val_accuracy20: 0.6262 - 110s/epoch - 72ms/step
Epoch 27/50
1542/1542 - 112s - loss: 2.5358 - accuracy20: 0.6104 - val_loss: 2.9449 - val_accuracy20: 0.6241 - 112s/epoch - 73ms/step
Epoch 28/50
1542/1542 - 116s - loss: 2.5314 - accuracy20: 0.6111 - val_loss: 2.9278 - val_accuracy20: 0.6257 - 116s/epoch - 75ms/step
Epoch 29/50
1542/1542 - 113s - loss: 2.5273 - accuracy20: 0.6111 - val_loss: 2.9548 - val_accuracy20: 0.6240 - 113s/epoch - 73ms/step
Epoch 30/50
1542/1542 - 114s - loss: 2.5237 - accuracy20: 0.6120 - val_loss: 2.9358 - val_accuracy20: 0.6267 - 114s/epoch - 74ms/step
Epoch 31/50
1542/1542 - 113s - loss: 2.5226 - accuracy20: 0.6122 - val_loss: 2.9432 - val_accuracy20: 0.6259 - 113s/epoch - 74ms/step
Epoch 32/50
1542/1542 - 110s - loss: 2.5159 - accuracy20: 0.6126 - val_loss: 2.9393 - val_accuracy20: 0.6234 - 110s/epoch - 71ms/step
Epoch 33/50
1542/1542 - 106s - loss: 2.5116 - accuracy20: 0.6132 - val_loss: 2.9410 - val_accuracy20: 0.6239 - 106s/epoch - 68ms/step
testing model: results/WBA/W2/deepVOL_L2/h20
Evaluating performance on  test set...
4353/4353 - 154s - 154s/epoch - 35ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.8167721
{'0': {'precision': 0.5824199426795627, 'recall': 0.36092405342339834, 'f1-score': 0.4456685310447194, 'support': 240419}, '1': {'precision': 0.7218199678539048, 'recall': 0.8164263841603743, 'f1-score': 0.7662138975308302, 'support': 630924}, '2': {'precision': 0.4873531889194387, 'recall': 0.5048838214410669, 'f1-score': 0.49596364143630883, 'support': 242945}, 'accuracy': 0.650222384159212, 'macro avg': {'precision': 0.5971976998176354, 'recall': 0.5607447530082799, 'f1-score': 0.5692820233372862, 'support': 1114288}, 'weighted avg': {'precision': 0.6406228749473815, 'recall': 0.650222384159212, 'f1-score': 0.6381310814795869, 'support': 1114288}}
[[ 86773  98931  54715]
 [ 41511 515103  74310]
 [ 20703  99583 122659]]
Evaluating performance on  train set...
1542/1542 - 56s - 56s/epoch - 36ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.8866297
{'0': {'precision': 0.5532815588377197, 'recall': 0.37367165245908535, 'f1-score': 0.4460756634669678, 'support': 95137}, '1': {'precision': 0.679765690105747, 'recall': 0.812315694824469, 'f1-score': 0.740153110216451, 'support': 206858}, '2': {'precision': 0.5115260599643872, 'recall': 0.45929478869587764, 'f1-score': 0.4840053732838506, 'support': 92568}, 'accuracy': 0.6237280231547306, 'macro avg': {'precision': 0.581524436302618, 'recall': 0.5484273786598106, 'f1-score': 0.5567447156557566, 'support': 394563}, 'weighted avg': {'precision': 0.6097973279446428, 'recall': 0.6237280231547306, 'f1-score': 0.609150634657966, 'support': 394563}}
[[ 35550  39939  19648]
 [ 17872 168034  20952]
 [ 10831  39221  42516]]
Evaluating performance on  val set...
482/482 - 16s - 16s/epoch - 34ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.8805286
{'0': {'precision': 0.5532528856243442, 'recall': 0.36661683412717727, 'f1-score': 0.4410011918951132, 'support': 28763}, '1': {'precision': 0.6819065401437451, 'recall': 0.8057452852998066, 'f1-score': 0.7386714691417885, 'support': 66176}, '2': {'precision': 0.5034924777402517, 'recall': 0.4624087977159776, 'f1-score': 0.48207691035699196, 'support': 28371}, 'accuracy': 0.6243208174519503, 'macro avg': {'precision': 0.5795506345027803, 'recall': 0.5449236390476538, 'f1-score': 0.5539165237979645, 'support': 123310}, 'weighted avg': {'precision': 0.6108478228508164, 'recall': 0.6243208174519503, 'f1-score': 0.6102006686249644, 'support': 123310}}
[[10545 12619  5599]
 [ 5517 53321  7338]
 [ 2998 12254 13119]]
training model: results/WBA/W2/deepVOL_L2/h30
Epoch 1/50
1542/1542 - 117s - loss: 3.0648 - accuracy30: 0.4755 - val_loss: 3.1711 - val_accuracy30: 0.5544 - 117s/epoch - 76ms/step
Epoch 2/50
1542/1542 - 111s - loss: 2.9037 - accuracy30: 0.5278 - val_loss: 3.0974 - val_accuracy30: 0.5614 - 111s/epoch - 72ms/step
Epoch 3/50
1542/1542 - 110s - loss: 2.8297 - accuracy30: 0.5471 - val_loss: 3.1497 - val_accuracy30: 0.5673 - 110s/epoch - 71ms/step
Epoch 4/50
1542/1542 - 112s - loss: 2.7938 - accuracy30: 0.5558 - val_loss: 3.1330 - val_accuracy30: 0.5667 - 112s/epoch - 73ms/step
Epoch 5/50
1542/1542 - 108s - loss: 2.7701 - accuracy30: 0.5610 - val_loss: 3.1385 - val_accuracy30: 0.5686 - 108s/epoch - 70ms/step
Epoch 6/50
1542/1542 - 111s - loss: 2.7555 - accuracy30: 0.5651 - val_loss: 3.0958 - val_accuracy30: 0.5762 - 111s/epoch - 72ms/step
Epoch 7/50
1542/1542 - 109s - loss: 2.7422 - accuracy30: 0.5685 - val_loss: 3.1102 - val_accuracy30: 0.5709 - 109s/epoch - 71ms/step
Epoch 8/50
1542/1542 - 109s - loss: 2.7335 - accuracy30: 0.5693 - val_loss: 3.0930 - val_accuracy30: 0.5746 - 109s/epoch - 71ms/step
Epoch 9/50
1542/1542 - 105s - loss: 2.7211 - accuracy30: 0.5722 - val_loss: 3.0945 - val_accuracy30: 0.5730 - 105s/epoch - 68ms/step
Epoch 10/50
1542/1542 - 110s - loss: 2.7129 - accuracy30: 0.5733 - val_loss: 3.0903 - val_accuracy30: 0.5745 - 110s/epoch - 72ms/step
Epoch 11/50
1542/1542 - 110s - loss: 2.7044 - accuracy30: 0.5756 - val_loss: 3.0928 - val_accuracy30: 0.5688 - 110s/epoch - 71ms/step
Epoch 12/50
1542/1542 - 110s - loss: 2.6978 - accuracy30: 0.5761 - val_loss: 3.0891 - val_accuracy30: 0.5707 - 110s/epoch - 72ms/step
Epoch 13/50
1542/1542 - 112s - loss: 2.6905 - accuracy30: 0.5774 - val_loss: 3.0550 - val_accuracy30: 0.5720 - 112s/epoch - 72ms/step
Epoch 14/50
1542/1542 - 109s - loss: 2.6842 - accuracy30: 0.5781 - val_loss: 3.0553 - val_accuracy30: 0.5745 - 109s/epoch - 71ms/step
Epoch 15/50
1542/1542 - 113s - loss: 2.6782 - accuracy30: 0.5792 - val_loss: 3.0503 - val_accuracy30: 0.5716 - 113s/epoch - 73ms/step
Epoch 16/50
1542/1542 - 113s - loss: 2.6734 - accuracy30: 0.5801 - val_loss: 3.0559 - val_accuracy30: 0.5727 - 113s/epoch - 73ms/step
Epoch 17/50
1542/1542 - 114s - loss: 2.6687 - accuracy30: 0.5800 - val_loss: 3.0609 - val_accuracy30: 0.5716 - 114s/epoch - 74ms/step
Epoch 18/50
1542/1542 - 110s - loss: 2.6636 - accuracy30: 0.5815 - val_loss: 3.0537 - val_accuracy30: 0.5736 - 110s/epoch - 71ms/step
Epoch 19/50
1542/1542 - 111s - loss: 2.6593 - accuracy30: 0.5816 - val_loss: 3.0605 - val_accuracy30: 0.5733 - 111s/epoch - 72ms/step
Epoch 20/50
1542/1542 - 111s - loss: 2.6554 - accuracy30: 0.5824 - val_loss: 3.0424 - val_accuracy30: 0.5721 - 111s/epoch - 72ms/step
Epoch 21/50
1542/1542 - 117s - loss: 2.6512 - accuracy30: 0.5829 - val_loss: 3.0408 - val_accuracy30: 0.5722 - 117s/epoch - 76ms/step
Epoch 22/50
1542/1542 - 108s - loss: 2.6471 - accuracy30: 0.5839 - val_loss: 3.0608 - val_accuracy30: 0.5693 - 108s/epoch - 70ms/step
Epoch 23/50
1542/1542 - 112s - loss: 2.6429 - accuracy30: 0.5855 - val_loss: 3.0535 - val_accuracy30: 0.5704 - 112s/epoch - 73ms/step
Epoch 24/50
1542/1542 - 108s - loss: 2.6395 - accuracy30: 0.5849 - val_loss: 3.0524 - val_accuracy30: 0.5706 - 108s/epoch - 70ms/step
Epoch 25/50
1542/1542 - 112s - loss: 2.6359 - accuracy30: 0.5863 - val_loss: 3.0621 - val_accuracy30: 0.5726 - 112s/epoch - 73ms/step
Epoch 26/50
1542/1542 - 110s - loss: 2.6326 - accuracy30: 0.5869 - val_loss: 3.0513 - val_accuracy30: 0.5703 - 110s/epoch - 72ms/step
Epoch 27/50
1542/1542 - 110s - loss: 2.6267 - accuracy30: 0.5881 - val_loss: 3.0585 - val_accuracy30: 0.5687 - 110s/epoch - 71ms/step
Epoch 28/50
1542/1542 - 113s - loss: 2.6241 - accuracy30: 0.5882 - val_loss: 3.0847 - val_accuracy30: 0.5709 - 113s/epoch - 73ms/step
Epoch 29/50
1542/1542 - 112s - loss: 2.6208 - accuracy30: 0.5886 - val_loss: 3.0735 - val_accuracy30: 0.5686 - 112s/epoch - 72ms/step
Epoch 30/50
1542/1542 - 109s - loss: 2.6174 - accuracy30: 0.5894 - val_loss: 3.0702 - val_accuracy30: 0.5708 - 109s/epoch - 71ms/step
Epoch 31/50
1542/1542 - 109s - loss: 2.6140 - accuracy30: 0.5905 - val_loss: 3.0643 - val_accuracy30: 0.5704 - 109s/epoch - 71ms/step
testing model: results/WBA/W2/deepVOL_L2/h30
Evaluating performance on  test set...
4353/4353 - 149s - 149s/epoch - 34ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.88312334
{'0': {'precision': 0.5492985690712271, 'recall': 0.40870025455553594, 'f1-score': 0.4686821308537784, 'support': 277739}, '1': {'precision': 0.6509180816638185, 'recall': 0.8054388787509044, 'f1-score': 0.7199810817049953, 'support': 555666}, '2': {'precision': 0.5259515413697833, 'recall': 0.41206837010427827, 'f1-score': 0.46209678868223586, 'support': 280883}, 'accuracy': 0.6073923438105768, 'macro avg': {'precision': 0.5753893973682763, 'recall': 0.5420691678035728, 'f1-score': 0.5502533337470031, 'support': 1114288}, 'weighted avg': {'precision': 0.5940883585174117, 'recall': 0.6073923438105768, 'f1-score': 0.5923382881116174, 'support': 1114288}}
[[113512 115434  48793]
 [ 52583 447555  55528]
 [ 40554 124586 115743]]
Evaluating performance on  train set...
1542/1542 - 52s - 52s/epoch - 34ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.9552562
{'0': {'precision': 0.5180532873984922, 'recall': 0.42645758903907777, 'f1-score': 0.467814106643233, 'support': 108604}, '1': {'precision': 0.6038169498450747, 'recall': 0.7897570072647313, 'f1-score': 0.6843822888802592, 'support': 179635}, '2': {'precision': 0.5481348545058325, 'recall': 0.3619502652270419, 'f1-score': 0.43599780211065353, 'support': 106324}, 'accuracy': 0.5744760659261006, 'macro avg': {'precision': 0.5566683639164665, 'recall': 0.526054953843617, 'f1-score': 0.5293980658780485, 'support': 394563}, 'weighted avg': {'precision': 0.565205574979215, 'recall': 0.5744760659261006, 'f1-score': 0.5578387380785835, 'support': 394563}}
[[ 46315  45713  16576]
 [ 22618 141868  15149]
 [ 20469  47371  38484]]
Evaluating performance on  val set...
482/482 - 17s - 17s/epoch - 34ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.9510573
{'0': {'precision': 0.5234854494593127, 'recall': 0.3786313945763121, 'f1-score': 0.43942872163322527, 'support': 33114}, '1': {'precision': 0.6012735635851214, 'recall': 0.7873718294657313, 'f1-score': 0.6818527870953153, 'support': 57443}, '2': {'precision': 0.5308033309856237, 'recall': 0.3911702744786737, 'f1-score': 0.4504130778695728, 'support': 32753}, 'accuracy': 0.5723704484632228, 'macro avg': {'precision': 0.5518541146766859, 'recall': 0.5190578328402391, 'f1-score': 0.5238981955327044, 'support': 123310}, 'weighted avg': {'precision': 0.5616661745696857, 'recall': 0.5723704484632228, 'f1-score': 0.5552776893742675, 'support': 123310}}
[[12538 14878  5698]
 [ 6587 45229  5627]
 [ 4826 15115 12812]]
training model: results/WBA/W2/deepVOL_L2/h50
Epoch 1/50
1542/1542 - 121s - loss: 3.1252 - accuracy50: 0.4510 - val_loss: 3.2544 - val_accuracy50: 0.4851 - 121s/epoch - 79ms/step
Epoch 2/50
1542/1542 - 106s - loss: 2.9984 - accuracy50: 0.4899 - val_loss: 3.1882 - val_accuracy50: 0.4945 - 106s/epoch - 69ms/step
Epoch 3/50
1542/1542 - 112s - loss: 2.9375 - accuracy50: 0.5073 - val_loss: 3.2622 - val_accuracy50: 0.4909 - 112s/epoch - 73ms/step
Epoch 4/50
1542/1542 - 107s - loss: 2.9073 - accuracy50: 0.5146 - val_loss: 3.2573 - val_accuracy50: 0.4943 - 107s/epoch - 69ms/step
Epoch 5/50
1542/1542 - 108s - loss: 2.8907 - accuracy50: 0.5192 - val_loss: 3.2812 - val_accuracy50: 0.4955 - 108s/epoch - 70ms/step
Epoch 6/50
1542/1542 - 114s - loss: 2.8808 - accuracy50: 0.5212 - val_loss: 3.2919 - val_accuracy50: 0.4947 - 114s/epoch - 74ms/step
Epoch 7/50
1542/1542 - 109s - loss: 2.8717 - accuracy50: 0.5236 - val_loss: 3.2412 - val_accuracy50: 0.4993 - 109s/epoch - 71ms/step
Epoch 8/50
1542/1542 - 109s - loss: 2.8643 - accuracy50: 0.5255 - val_loss: 3.2301 - val_accuracy50: 0.5017 - 109s/epoch - 70ms/step
Epoch 9/50
1542/1542 - 113s - loss: 2.8555 - accuracy50: 0.5277 - val_loss: 3.2484 - val_accuracy50: 0.5016 - 113s/epoch - 73ms/step
Epoch 10/50
1542/1542 - 111s - loss: 2.8504 - accuracy50: 0.5289 - val_loss: 3.2394 - val_accuracy50: 0.5013 - 111s/epoch - 72ms/step
Epoch 11/50
1542/1542 - 110s - loss: 2.8446 - accuracy50: 0.5301 - val_loss: 3.2502 - val_accuracy50: 0.5010 - 110s/epoch - 71ms/step
Epoch 12/50
1542/1542 - 108s - loss: 2.8386 - accuracy50: 0.5312 - val_loss: 3.2240 - val_accuracy50: 0.5033 - 108s/epoch - 70ms/step
testing model: results/WBA/W2/deepVOL_L2/h50
Evaluating performance on  test set...
4353/4353 - 152s - 152s/epoch - 35ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0070289
{'0': {'precision': 0.49854605360255605, 'recall': 0.3745242932571004, 'f1-score': 0.42772637749802794, 'support': 333714}, '1': {'precision': 0.5252246146865575, 'recall': 0.8070633349273957, 'f1-score': 0.636333202950183, 'support': 447494}, '2': {'precision': 0.5234558359711086, 'recall': 0.2765461750930707, 'f1-score': 0.36189836341884574, 'support': 333080}, 'accuracy': 0.518943038065563, 'macro avg': {'precision': 0.5157421680867407, 'recall': 0.4860446010925223, 'f1-score': 0.4753193146223522, 'support': 1114288}, 'weighted avg': {'precision': 0.5167060322840473, 'recall': 0.518943038065563, 'f1-score': 0.4918249838003418, 'support': 1114288}}
[[124984 156753  51977]
 [ 54458 361156  31880]
 [ 71255 169713  92112]]
Evaluating performance on  train set...
1542/1542 - 55s - 55s/epoch - 36ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0671703
{'0': {'precision': 0.47811477497599875, 'recall': 0.3838711960924657, 'f1-score': 0.42584101528246154, 'support': 127139}, '1': {'precision': 0.47793148463984164, 'recall': 0.7952686936352998, 'f1-score': 0.597052928395945, 'support': 142709}, '2': {'precision': 0.5425299890948746, 'recall': 0.23934570821472959, 'f1-score': 0.33215567363062287, 'support': 124715}, 'accuracy': 0.48698686901711513, 'macro avg': {'precision': 0.499525416236905, 'recall': 0.4728285326474984, 'f1-score': 0.45168320576967647, 'support': 394563}, 'weighted avg': {'precision': 0.49840909108838877, 'recall': 0.48698686901711513, 'f1-score': 0.4581540135220406, 'support': 394563}}
[[ 48805  61363  16971]
 [ 21018 113492   8199]
 [ 32255  62610  29850]]
Evaluating performance on  val set...
482/482 - 16s - 16s/epoch - 33ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 1.0462492
{'0': {'precision': 0.477050222504768, 'recall': 0.38632619439868204, 'f1-score': 0.4269215452011151, 'support': 38848}, '1': {'precision': 0.49046867494681945, 'recall': 0.7826296426068675, 'f1-score': 0.603025419939424, 'support': 45664}, '2': {'precision': 0.5364761653937319, 'recall': 0.2625135316253415, 'f1-score': 0.3525258293961892, 'support': 38798}, 'accuracy': 0.49412861892790527, 'macro avg': {'precision': 0.5013316876151065, 'recall': 0.477156456210297, 'f1-score': 0.4608242648455761, 'support': 123310}, 'weighted avg': {'precision': 0.5007169806307907, 'recall': 0.49412861892790527, 'f1-score': 0.46872839261211685, 'support': 123310}}
[[15008 18070  5770]
 [ 6896 35738  3030]
 [ 9556 19057 10185]]
training model: results/WBA/W2/deepVOL_L2/h100
Epoch 1/50
1542/1542 - 122s - loss: 3.2537 - accuracy100: 0.3951 - val_loss: 3.3845 - val_accuracy100: 0.3347 - 122s/epoch - 79ms/step
Epoch 2/50
1542/1542 - 114s - loss: 3.1958 - accuracy100: 0.4221 - val_loss: 3.2956 - val_accuracy100: 0.4064 - 114s/epoch - 74ms/step
Epoch 3/50
1542/1542 - 108s - loss: 3.1611 - accuracy100: 0.4345 - val_loss: 3.2959 - val_accuracy100: 0.4144 - 108s/epoch - 70ms/step
Epoch 4/50
1542/1542 - 105s - loss: 3.1424 - accuracy100: 0.4429 - val_loss: 3.3052 - val_accuracy100: 0.4121 - 105s/epoch - 68ms/step
Epoch 5/50
1542/1542 - 107s - loss: 3.1313 - accuracy100: 0.4460 - val_loss: 3.3011 - val_accuracy100: 0.4152 - 107s/epoch - 70ms/step
Epoch 6/50
1542/1542 - 110s - loss: 3.1216 - accuracy100: 0.4477 - val_loss: 3.3146 - val_accuracy100: 0.4196 - 110s/epoch - 72ms/step
Epoch 7/50
1542/1542 - 113s - loss: 3.1142 - accuracy100: 0.4505 - val_loss: 3.3137 - val_accuracy100: 0.4188 - 113s/epoch - 74ms/step
Epoch 8/50
1542/1542 - 109s - loss: 3.1074 - accuracy100: 0.4522 - val_loss: 3.3185 - val_accuracy100: 0.4218 - 109s/epoch - 71ms/step
Epoch 9/50
1542/1542 - 112s - loss: 3.1032 - accuracy100: 0.4543 - val_loss: 3.3181 - val_accuracy100: 0.4233 - 112s/epoch - 73ms/step
Epoch 10/50
1542/1542 - 109s - loss: 3.0976 - accuracy100: 0.4565 - val_loss: 3.3301 - val_accuracy100: 0.4219 - 109s/epoch - 71ms/step
Epoch 11/50
1542/1542 - 107s - loss: 3.0918 - accuracy100: 0.4585 - val_loss: 3.3216 - val_accuracy100: 0.4260 - 107s/epoch - 70ms/step
Epoch 12/50
1542/1542 - 109s - loss: 3.0874 - accuracy100: 0.4601 - val_loss: 3.3219 - val_accuracy100: 0.4225 - 109s/epoch - 70ms/step
testing model: results/WBA/W2/deepVOL_L2/h100
Evaluating performance on  test set...
4353/4353 - 150s - 150s/epoch - 34ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0820402
{'0': {'precision': 0.47641138352487006, 'recall': 0.15653429833771246, 'f1-score': 0.23564335385214027, 'support': 375266}, '1': {'precision': 0.40214843826164726, 'recall': 0.8071391114462153, 'f1-score': 0.5368280409508936, 'support': 383297}, '2': {'precision': 0.4454629111708558, 'recall': 0.27760770257923956, 'f1-score': 0.342052167527697, 'support': 355725}, 'accuracy': 0.4189832431112962, 'macro avg': {'precision': 0.4413409109857911, 'recall': 0.41376037078772243, 'f1-score': 0.3715078541102437, 'support': 1114288}, 'weighted avg': {'precision': 0.44098615283164777, 'recall': 0.4189832431112962, 'f1-score': 0.3732159223942301, 'support': 1114288}}
[[ 58742 240936  75588]
 [ 26579 309374  47344]
 [ 37980 218993  98752]]
Evaluating performance on  train set...
1542/1542 - 55s - 55s/epoch - 36ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.1110262
{'0': {'precision': 0.45086093753060785, 'recall': 0.17052678372971772, 'f1-score': 0.24745859293943093, 'support': 134970}, '1': {'precision': 0.3728514026341246, 'recall': 0.7812329471928156, 'f1-score': 0.5047877136337764, 'support': 128278}, '2': {'precision': 0.44450986164262585, 'recall': 0.252979476830522, 'f1-score': 0.322447573150076, 'support': 131315}, 'accuracy': 0.3965171594903729, 'macro avg': {'precision': 0.42274073393578604, 'recall': 0.4015797359176851, 'f1-score': 0.3582312932410945, 'support': 394563}, 'weighted avg': {'precision': 0.42338522732037165, 'recall': 0.3965171594903729, 'f1-score': 0.35607709716002467, 'support': 394563}}
[[ 23016  86420  25534]
 [ 12083 100215  15980]
 [ 15950  82145  33220]]
Evaluating performance on  val set...
482/482 - 17s - 17s/epoch - 35ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.1006392
{'0': {'precision': 0.4383784411662214, 'recall': 0.18270278120688402, 'f1-score': 0.25791460935230903, 'support': 41313}, '1': {'precision': 0.387889565528888, 'recall': 0.7435501275259957, 'f1-score': 0.5098200773499244, 'support': 40776}, '2': {'precision': 0.4332211400744772, 'recall': 0.29351544115863276, 'f1-score': 0.3499399846707834, 'support': 41221}, 'accuracy': 0.40520639039818346, 'macro avg': {'precision': 0.4198297155898622, 'recall': 0.40658944996383745, 'f1-score': 0.3725582237910056, 'support': 123310}, 'weighted avg': {'precision': 0.4199588198760528, 'recall': 0.40520639039818346, 'f1-score': 0.371977340347959, 'support': 123310}}
[[ 7548 24348  9417]
 [ 4045 30319  6412]
 [ 5625 23497 12099]]
training model: results/WBA/W2/deepVOL_L2/h200
Epoch 1/50
1542/1542 - 120s - loss: 3.2897 - accuracy200: 0.3708 - val_loss: 3.3009 - val_accuracy200: 0.3467 - 120s/epoch - 78ms/step
Epoch 2/50
1542/1542 - 114s - loss: 3.2691 - accuracy200: 0.3755 - val_loss: 3.2913 - val_accuracy200: 0.3574 - 114s/epoch - 74ms/step
Epoch 3/50
1542/1542 - 108s - loss: 3.2648 - accuracy200: 0.3802 - val_loss: 3.2999 - val_accuracy200: 0.3594 - 108s/epoch - 70ms/step
Epoch 4/50
1542/1542 - 108s - loss: 3.2574 - accuracy200: 0.3850 - val_loss: 3.3001 - val_accuracy200: 0.3551 - 108s/epoch - 70ms/step
Epoch 5/50
1542/1542 - 110s - loss: 3.2498 - accuracy200: 0.3903 - val_loss: 3.2973 - val_accuracy200: 0.3578 - 110s/epoch - 71ms/step
Epoch 6/50
1542/1542 - 112s - loss: 3.2414 - accuracy200: 0.3938 - val_loss: 3.3034 - val_accuracy200: 0.3559 - 112s/epoch - 72ms/step
Epoch 7/50
1542/1542 - 112s - loss: 3.2329 - accuracy200: 0.3984 - val_loss: 3.3117 - val_accuracy200: 0.3540 - 112s/epoch - 73ms/step
Epoch 8/50
1542/1542 - 111s - loss: 3.2253 - accuracy200: 0.4044 - val_loss: 3.3232 - val_accuracy200: 0.3600 - 111s/epoch - 72ms/step
Epoch 9/50
1542/1542 - 110s - loss: 3.2193 - accuracy200: 0.4080 - val_loss: 3.3440 - val_accuracy200: 0.3555 - 110s/epoch - 71ms/step
Epoch 10/50
1542/1542 - 108s - loss: 3.2124 - accuracy200: 0.4116 - val_loss: 3.3682 - val_accuracy200: 0.3534 - 108s/epoch - 70ms/step
Epoch 11/50
1542/1542 - 118s - loss: 3.2073 - accuracy200: 0.4131 - val_loss: 3.3513 - val_accuracy200: 0.3603 - 118s/epoch - 76ms/step
Epoch 12/50
1542/1542 - 113s - loss: 3.2005 - accuracy200: 0.4171 - val_loss: 3.3540 - val_accuracy200: 0.3576 - 113s/epoch - 73ms/step
testing model: results/WBA/W2/deepVOL_L2/h200
Evaluating performance on  test set...
4353/4353 - 148s - 148s/epoch - 34ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0903836
{'0': {'precision': 0.38449707782220854, 'recall': 0.5449068931378497, 'f1-score': 0.45085907666233915, 'support': 380799}, '1': {'precision': 0.34308582620206385, 'recall': 0.36463410807305285, 'f1-score': 0.35353192179850257, 'support': 382408}, '2': {'precision': 0.39745297153321124, 'recall': 0.1904118992483216, 'f1-score': 0.2574733716301704, 'support': 351081}, 'accuracy': 0.37134834082391627, 'macro avg': {'precision': 0.3750119585191612, 'recall': 0.36665096681974135, 'f1-score': 0.3539547900303374, 'support': 1114288}, 'weighted avg': {'precision': 0.3743673575078879, 'recall': 0.37134834082391627, 'f1-score': 0.3565273335711735, 'support': 1114288}}
[[207500 129419  43880]
 [185503 139439  57466]
 [146663 137568  66850]]
Evaluating performance on  train set...
1542/1542 - 53s - 53s/epoch - 35ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0955918
{'0': {'precision': 0.36461689578103723, 'recall': 0.5750217020384949, 'f1-score': 0.4462622725174015, 'support': 133628}, '1': {'precision': 0.3284848389803264, 'recall': 0.3180696546121315, 'f1-score': 0.32319335899829504, 'support': 131707}, '2': {'precision': 0.3927131259659283, 'recall': 0.17106973720865448, 'f1-score': 0.2383234243023701, 'support': 129228}, 'accuracy': 0.35694679937044277, 'macro avg': {'precision': 0.3619382869090973, 'recall': 0.3547203646197603, 'f1-score': 0.3359263519393556, 'support': 394563}, 'weighted avg': {'precision': 0.3617579729456012, 'recall': 0.35694679937044277, 'f1-score': 0.3370767714187353, 'support': 394563}}
[[76839 40677 16112]
 [71741 41892 18074]
 [62159 44962 22107]]
Evaluating performance on  val set...
482/482 - 17s - 17s/epoch - 36ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0956225
{'0': {'precision': 0.3633130681147444, 'recall': 0.5984540968863178, 'f1-score': 0.45213894168526014, 'support': 41141}, '1': {'precision': 0.32474604057495826, 'recall': 0.2701195607178513, 'f1-score': 0.2949246271236009, 'support': 41067}, '2': {'precision': 0.3949866716550531, 'recall': 0.20548878400077855, 'f1-score': 0.27033688085140434, 'support': 41102}, 'accuracy': 0.35812180682831884, 'macro avg': {'precision': 0.3610152601149186, 'recall': 0.3580208138683159, 'f1-score': 0.33913348322008846, 'support': 123310}, 'weighted avg': {'precision': 0.3610262814205377, 'recall': 0.35812180682831884, 'f1-score': 0.33918177227080226, 'support': 123310}}
[[24621 10551  5969]
 [23006 11093  6968]
 [20141 12515  8446]]
training model: results/WBA/W2/deepVOL_L2/h300
Epoch 1/50
1542/1542 - 121s - loss: 3.2834 - accuracy300: 0.3774 - val_loss: 3.3155 - val_accuracy300: 0.3134 - 121s/epoch - 78ms/step
Epoch 2/50
1542/1542 - 109s - loss: 3.2721 - accuracy300: 0.3755 - val_loss: 3.3007 - val_accuracy300: 0.3469 - 109s/epoch - 71ms/step
Epoch 3/50
1542/1542 - 104s - loss: 3.2665 - accuracy300: 0.3798 - val_loss: 3.3024 - val_accuracy300: 0.3449 - 104s/epoch - 68ms/step
Epoch 4/50
1542/1542 - 114s - loss: 3.2535 - accuracy300: 0.3876 - val_loss: 3.3141 - val_accuracy300: 0.3360 - 114s/epoch - 74ms/step
Epoch 5/50
1542/1542 - 118s - loss: 3.2507 - accuracy300: 0.3925 - val_loss: 3.3182 - val_accuracy300: 0.3298 - 118s/epoch - 77ms/step
Epoch 6/50
1542/1542 - 83s - loss: 3.2402 - accuracy300: 0.3972 - val_loss: 3.3374 - val_accuracy300: 0.3231 - 83s/epoch - 54ms/step
Epoch 7/50
1542/1542 - 44s - loss: 3.2343 - accuracy300: 0.3988 - val_loss: 3.3336 - val_accuracy300: 0.3272 - 44s/epoch - 29ms/step
Epoch 8/50
1542/1542 - 44s - loss: 3.2274 - accuracy300: 0.4029 - val_loss: 3.3411 - val_accuracy300: 0.3281 - 44s/epoch - 28ms/step
Epoch 9/50
1542/1542 - 45s - loss: 3.2222 - accuracy300: 0.4053 - val_loss: 3.3496 - val_accuracy300: 0.3299 - 45s/epoch - 29ms/step
Epoch 10/50
1542/1542 - 46s - loss: 3.2186 - accuracy300: 0.4091 - val_loss: 3.3309 - val_accuracy300: 0.3358 - 46s/epoch - 30ms/step
Epoch 11/50
1542/1542 - 46s - loss: 3.2169 - accuracy300: 0.4085 - val_loss: 3.3316 - val_accuracy300: 0.3393 - 46s/epoch - 30ms/step
Epoch 12/50
1542/1542 - 46s - loss: 3.2128 - accuracy300: 0.4115 - val_loss: 3.3385 - val_accuracy300: 0.3407 - 46s/epoch - 30ms/step
testing model: results/WBA/W2/deepVOL_L2/h300
Evaluating performance on  test set...
4353/4353 - 62s - 62s/epoch - 14ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0964983
{'0': {'precision': 0.39144463720374506, 'recall': 0.42769164958034017, 'f1-score': 0.40876617311711605, 'support': 406758}, '1': {'precision': 0.31382837047447254, 'recall': 0.4191794293317136, 'f1-score': 0.35893314444504987, 'support': 345735}, '2': {'precision': 0.3557058269411923, 'recall': 0.20456612169875205, 'f1-score': 0.25975015047476324, 'support': 361795}, 'accuracy': 0.35260453311890644, 'macro avg': {'precision': 0.35365961153980335, 'recall': 0.3504790668702686, 'f1-score': 0.34248315601230966, 'support': 1114288}, 'weighted avg': {'precision': 0.35575836683505646, 'recall': 0.35260453311890644, 'f1-score': 0.3449206734977835, 'support': 1114288}}
[[173967 161491  71300]
 [138053 144925  62757]
 [132403 155381  74011]]
Evaluating performance on  train set...
1542/1542 - 22s - 22s/epoch - 14ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0967727
{'0': {'precision': 0.3615645371577575, 'recall': 0.46203572063266396, 'f1-score': 0.4056718775904272, 'support': 135048}, '1': {'precision': 0.3375894650387538, 'recall': 0.37457402571544535, 'f1-score': 0.35512139164779, 'support': 130583}, '2': {'precision': 0.36328616454169316, 'recall': 0.21723854434895915, 'f1-score': 0.27189112318049224, 'support': 128932}, 'accuracy': 0.3530969705725068, 'macro avg': {'precision': 0.35414672224606814, 'recall': 0.35128276356568944, 'f1-score': 0.3442281308062365, 'support': 394563}, 'weighted avg': {'precision': 0.3541924217271412, 'recall': 0.3530969705725068, 'f1-score': 0.3452261329731439, 'support': 394563}}
[[62397 47581 25070]
 [57650 48913 24020]
 [52528 48395 28009]]
Evaluating performance on  val set...
482/482 - 7s - 7s/epoch - 14ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0993867
{'0': {'precision': 0.37094705623021124, 'recall': 0.428049485489652, 'f1-score': 0.3974577817857795, 'support': 43245}, '1': {'precision': 0.30963180908013566, 'recall': 0.40656775682129154, 'f1-score': 0.3515397552630053, 'support': 37273}, '2': {'precision': 0.37668601324286766, 'recall': 0.2153673583847448, 'f1-score': 0.27404918374022424, 'support': 42792}, 'accuracy': 0.34774957424377584, 'macro avg': {'precision': 0.35242162618440487, 'recall': 0.3499948668985628, 'f1-score': 0.34101557359633633, 'support': 123310}, 'weighted avg': {'precision': 0.3544048312805788, 'recall': 0.34774957424377584, 'f1-score': 0.34075189150803425, 'support': 123310}}
[[18511 16571  8163]
 [15032 15154  7087]
 [16359 17217  9216]]
training model: results/WBA/W2/deepVOL_L2/h500
Epoch 1/50
1542/1542 - 49s - loss: 3.2545 - accuracy500: 0.3995 - val_loss: 3.2889 - val_accuracy500: 0.3497 - 49s/epoch - 32ms/step
Epoch 2/50
1542/1542 - 43s - loss: 3.2470 - accuracy500: 0.3991 - val_loss: 3.2932 - val_accuracy500: 0.3592 - 43s/epoch - 28ms/step
Epoch 3/50
1542/1542 - 43s - loss: 3.2530 - accuracy500: 0.3973 - val_loss: 3.2969 - val_accuracy500: 0.3618 - 43s/epoch - 28ms/step
Epoch 4/50
1542/1542 - 44s - loss: 3.2474 - accuracy500: 0.3985 - val_loss: 3.2947 - val_accuracy500: 0.3701 - 44s/epoch - 28ms/step
Epoch 5/50
1542/1542 - 43s - loss: 3.2296 - accuracy500: 0.4082 - val_loss: 3.3114 - val_accuracy500: 0.3284 - 43s/epoch - 28ms/step
Epoch 6/50
1542/1542 - 42s - loss: 3.2224 - accuracy500: 0.4125 - val_loss: 3.3158 - val_accuracy500: 0.3264 - 42s/epoch - 27ms/step
Epoch 7/50
1542/1542 - 43s - loss: 3.2175 - accuracy500: 0.4129 - val_loss: 3.3089 - val_accuracy500: 0.3389 - 43s/epoch - 28ms/step
Epoch 8/50
1542/1542 - 43s - loss: 3.2087 - accuracy500: 0.4172 - val_loss: 3.3006 - val_accuracy500: 0.3452 - 43s/epoch - 28ms/step
Epoch 9/50
1542/1542 - 43s - loss: 3.2058 - accuracy500: 0.4177 - val_loss: 3.2959 - val_accuracy500: 0.3511 - 43s/epoch - 28ms/step
Epoch 10/50
1542/1542 - 42s - loss: 3.2032 - accuracy500: 0.4197 - val_loss: 3.2994 - val_accuracy500: 0.3384 - 42s/epoch - 27ms/step
Epoch 11/50
1542/1542 - 43s - loss: 3.1994 - accuracy500: 0.4226 - val_loss: 3.2950 - val_accuracy500: 0.3615 - 43s/epoch - 28ms/step
testing model: results/WBA/W2/deepVOL_L2/h500
Evaluating performance on  test set...
4353/4353 - 60s - 60s/epoch - 14ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0972123
{'0': {'precision': 0.4069329467051267, 'recall': 0.5387768251865905, 'f1-score': 0.46366453558167453, 'support': 446968}, '1': {'precision': 0.2505428761356082, 'recall': 0.24023711384013938, 'f1-score': 0.24528179096707015, 'support': 282396}, '2': {'precision': 0.36791737014599263, 'recall': 0.24060333988008023, 'f1-score': 0.2909421046762031, 'support': 384924}, 'accuracy': 0.36011515873813593, 'macro avg': {'precision': 0.3417977309955758, 'recall': 0.33987242630227005, 'f1-score': 0.33329614374164923, 'support': 1114288}, 'weighted avg': {'precision': 0.3538210383295561, 'recall': 0.36011515873813593, 'f1-score': 0.3486534948614626, 'support': 1114288}}
[[240816 109139  97013]
 [152456  67842  62098]
 [198511  93799  92614]]
Evaluating performance on  train set...
1542/1542 - 21s - 21s/epoch - 13ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0979843
{'0': {'precision': 0.37208559720159273, 'recall': 0.5428416141396032, 'f1-score': 0.44152921386373944, 'support': 141673}, '1': {'precision': 0.320663515182488, 'recall': 0.2501889833113199, 'f1-score': 0.2810760364900492, 'support': 120381}, '2': {'precision': 0.3502182011708356, 'recall': 0.24830766212106348, 'f1-score': 0.29058681703972905, 'support': 132509}, 'accuracy': 0.35463791587148313, 'macro avg': {'precision': 0.3476557711849721, 'recall': 0.3471127531906622, 'f1-score': 0.3377306891311726, 'support': 394563}, 'weighted avg': {'precision': 0.3490528535429591, 'recall': 0.35463791587148313, 'f1-score': 0.34188292162099243, 'support': 394563}}
[[76906 32606 32161]
 [61377 30118 28886]
 [68406 31200 32903]]
Evaluating performance on  val set...
482/482 - 7s - 7s/epoch - 14ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0994918
{'0': {'precision': 0.3766891891891892, 'recall': 0.477143557625872, 'f1-score': 0.4210070895485698, 'support': 44867}, '1': {'precision': 0.2851118942200536, 'recall': 0.2784609048655645, 'f1-score': 0.2817471538060868, 'support': 33994}, '2': {'precision': 0.3648165399525198, 'recall': 0.2731220049944881, 'f1-score': 0.31237938398991333, 'support': 44449}, 'accuracy': 0.3488281566782905, 'macro avg': {'precision': 0.34220587445392087, 'recall': 0.34290882249530824, 'f1-score': 0.3383778757815233, 'support': 123310}, 'weighted avg': {'precision': 0.3471635550062234, 'recall': 0.3488281566782905, 'f1-score': 0.3434594848124844, 'support': 123310}}
[[21408 11862 11597]
 [14988  9466  9540]
 [20436 11873 12140]]
training model: results/WBA/W2/deepVOL_L2/h1000
Epoch 1/50
1542/1542 - 48s - loss: 3.3103 - accuracy1000: 0.3601 - val_loss: 3.3327 - val_accuracy1000: 0.3221 - 48s/epoch - 31ms/step
Epoch 2/50
1542/1542 - 43s - loss: 3.2930 - accuracy1000: 0.3516 - val_loss: 3.3933 - val_accuracy1000: 0.3221 - 43s/epoch - 28ms/step
Epoch 3/50
1542/1542 - 43s - loss: 3.2857 - accuracy1000: 0.3631 - val_loss: 3.3323 - val_accuracy1000: 0.3212 - 43s/epoch - 28ms/step
Epoch 4/50
1542/1542 - 43s - loss: 3.2831 - accuracy1000: 0.3644 - val_loss: 3.3539 - val_accuracy1000: 0.3240 - 43s/epoch - 28ms/step
Epoch 5/50
1542/1542 - 43s - loss: 3.2729 - accuracy1000: 0.3751 - val_loss: 3.3514 - val_accuracy1000: 0.3252 - 43s/epoch - 28ms/step
Epoch 6/50
1542/1542 - 43s - loss: 3.2754 - accuracy1000: 0.3696 - val_loss: 3.3354 - val_accuracy1000: 0.3263 - 43s/epoch - 28ms/step
Epoch 7/50
1542/1542 - 43s - loss: 3.2653 - accuracy1000: 0.3802 - val_loss: 3.3497 - val_accuracy1000: 0.3299 - 43s/epoch - 28ms/step
Epoch 8/50
1542/1542 - 43s - loss: 3.2561 - accuracy1000: 0.3888 - val_loss: 3.3480 - val_accuracy1000: 0.3281 - 43s/epoch - 28ms/step
Epoch 9/50
1542/1542 - 43s - loss: 3.2511 - accuracy1000: 0.3916 - val_loss: 3.3677 - val_accuracy1000: 0.3280 - 43s/epoch - 28ms/step
Epoch 10/50
1542/1542 - 42s - loss: 3.2542 - accuracy1000: 0.3889 - val_loss: 3.3741 - val_accuracy1000: 0.3296 - 42s/epoch - 27ms/step
Epoch 11/50
1542/1542 - 42s - loss: 3.2528 - accuracy1000: 0.3901 - val_loss: 3.3679 - val_accuracy1000: 0.3288 - 42s/epoch - 27ms/step
Epoch 12/50
1542/1542 - 42s - loss: 3.2407 - accuracy1000: 0.3992 - val_loss: 3.4176 - val_accuracy1000: 0.3258 - 42s/epoch - 27ms/step
Epoch 13/50
1542/1542 - 43s - loss: 3.2363 - accuracy1000: 0.4012 - val_loss: 3.3973 - val_accuracy1000: 0.3283 - 43s/epoch - 28ms/step
testing model: results/WBA/W2/deepVOL_L2/h1000
Evaluating performance on  test set...
4353/4353 - 63s - 63s/epoch - 14ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1004
{'0': {'precision': 0.3877382875605816, 'recall': 0.06102730095122342, 'f1-score': 0.1054564867317101, 'support': 393283}, '1': {'precision': 0.34687935759279803, 'recall': 0.9447197154439975, 'f1-score': 0.5074388404878161, 'support': 386286}, '2': {'precision': 0.22318840579710145, 'recall': 0.00023004370830457787, 'f1-score': 0.0004596136857436191, 'support': 334719}, 'accuracy': 0.3491108223367747, 'macro avg': {'precision': 0.31926868365016037, 'recall': 0.33532568670117513, 'f1-score': 0.20445164696842325, 'support': 1114288}, 'weighted avg': {'precision': 0.3241450293584601, 'recall': 0.3491108223367747, 'f1-score': 0.21327036173885214, 'support': 1114288}}
[[ 24001 369140    142]
 [ 21228 364932    126]
 [ 16671 317971     77]]
Evaluating performance on  train set...
1542/1542 - 20s - 20s/epoch - 13ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1043582
{'0': {'precision': 0.3916464232623908, 'recall': 0.07891987462830508, 'f1-score': 0.1313680421272818, 'support': 136873}, '1': {'precision': 0.334828790179046, 'recall': 0.9389809520897667, 'f1-score': 0.4936339325359592, 'support': 130828}, '2': {'precision': 0.3333333333333333, 'recall': 0.0002443600132427362, 'f1-score': 0.0004883620180378875, 'support': 126862}, 'accuracy': 0.33880014091539246, 'macro avg': {'precision': 0.35326951559159, 'recall': 0.33938172891043816, 'f1-score': 0.20849677889375964, 'support': 394563}, 'weighted avg': {'precision': 0.3540578695571322, 'recall': 0.33880014091539246, 'f1-score': 0.20940593197596896, 'support': 394563}}
[[ 10802 126043     28]
 [  7949 122845     34]
 [  8830 118001     31]]
Evaluating performance on  val set...
482/482 - 6s - 6s/epoch - 13ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.10923
{'0': {'precision': 0.34546472564389696, 'recall': 0.05914919113241462, 'f1-score': 0.10100472692299822, 'support': 41725}, '1': {'precision': 0.31932114657688765, 'recall': 0.9337076388539202, 'f1-score': 0.4758910525809246, 'support': 39718}, '2': {'precision': 0.27586206896551724, 'recall': 0.00019108128119999044, 'f1-score': 0.00038189803322512885, 'support': 41867}, 'accuracy': 0.3208255615927338, 'macro avg': {'precision': 0.3135493137287673, 'recall': 0.3310159704225116, 'f1-score': 0.19242589251238265, 'support': 123310}, 'weighted avg': {'precision': 0.3134119716049934, 'recall': 0.3208255615927338, 'f1-score': 0.18759104681070718, 'support': 123310}}
[[ 2468 39245    12]
 [ 2624 37085     9]
 [ 2052 39807     8]]
training model: results/WBA/W2/deepVOL_L3/h10
Epoch 1/50
1542/1542 - 67s - loss: 3.1586 - accuracy10: 0.4181 - val_loss: 3.4439 - val_accuracy10: 0.6343 - 67s/epoch - 43ms/step
Epoch 2/50
1542/1542 - 62s - loss: 2.8567 - accuracy10: 0.4923 - val_loss: 2.7816 - val_accuracy10: 0.5846 - 62s/epoch - 40ms/step
Epoch 3/50
1542/1542 - 62s - loss: 2.6702 - accuracy10: 0.5811 - val_loss: 2.7784 - val_accuracy10: 0.5846 - 62s/epoch - 40ms/step
Epoch 4/50
1542/1542 - 61s - loss: 2.6109 - accuracy10: 0.5989 - val_loss: 2.7375 - val_accuracy10: 0.6002 - 61s/epoch - 40ms/step
Epoch 5/50
1542/1542 - 62s - loss: 2.5825 - accuracy10: 0.6053 - val_loss: 2.7441 - val_accuracy10: 0.6070 - 62s/epoch - 40ms/step
Epoch 6/50
1542/1542 - 62s - loss: 2.5547 - accuracy10: 0.6102 - val_loss: 2.7289 - val_accuracy10: 0.6070 - 62s/epoch - 40ms/step
Epoch 7/50
1542/1542 - 61s - loss: 2.5395 - accuracy10: 0.6125 - val_loss: 2.6831 - val_accuracy10: 0.6142 - 61s/epoch - 40ms/step
Epoch 8/50
1542/1542 - 61s - loss: 2.5255 - accuracy10: 0.6144 - val_loss: 2.6819 - val_accuracy10: 0.6253 - 61s/epoch - 40ms/step
Epoch 9/50
1542/1542 - 63s - loss: 2.5117 - accuracy10: 0.6165 - val_loss: 2.6508 - val_accuracy10: 0.6238 - 63s/epoch - 41ms/step
Epoch 10/50
1542/1542 - 62s - loss: 2.4994 - accuracy10: 0.6183 - val_loss: 2.6410 - val_accuracy10: 0.6280 - 62s/epoch - 40ms/step
Epoch 11/50
1542/1542 - 62s - loss: 2.4897 - accuracy10: 0.6200 - val_loss: 2.6193 - val_accuracy10: 0.6250 - 62s/epoch - 40ms/step
Epoch 12/50
1542/1542 - 61s - loss: 2.4815 - accuracy10: 0.6201 - val_loss: 2.6316 - val_accuracy10: 0.6211 - 61s/epoch - 40ms/step
Epoch 13/50
1542/1542 - 63s - loss: 2.4709 - accuracy10: 0.6224 - val_loss: 2.5897 - val_accuracy10: 0.6271 - 63s/epoch - 41ms/step
Epoch 14/50
1542/1542 - 62s - loss: 2.4623 - accuracy10: 0.6233 - val_loss: 2.5722 - val_accuracy10: 0.6251 - 62s/epoch - 40ms/step
Epoch 15/50
1542/1542 - 61s - loss: 2.4568 - accuracy10: 0.6234 - val_loss: 2.5756 - val_accuracy10: 0.6219 - 61s/epoch - 40ms/step
Epoch 16/50
1542/1542 - 63s - loss: 2.4507 - accuracy10: 0.6245 - val_loss: 2.5591 - val_accuracy10: 0.6281 - 63s/epoch - 41ms/step
Epoch 17/50
1542/1542 - 63s - loss: 2.4455 - accuracy10: 0.6254 - val_loss: 2.5651 - val_accuracy10: 0.6150 - 63s/epoch - 41ms/step
Epoch 18/50
1542/1542 - 61s - loss: 2.4391 - accuracy10: 0.6262 - val_loss: 2.5547 - val_accuracy10: 0.6162 - 61s/epoch - 40ms/step
Epoch 19/50
1542/1542 - 60s - loss: 2.4342 - accuracy10: 0.6270 - val_loss: 2.5525 - val_accuracy10: 0.6170 - 60s/epoch - 39ms/step
Epoch 20/50
1542/1542 - 61s - loss: 2.4291 - accuracy10: 0.6281 - val_loss: 2.5344 - val_accuracy10: 0.6270 - 61s/epoch - 40ms/step
Epoch 21/50
1542/1542 - 61s - loss: 2.4219 - accuracy10: 0.6289 - val_loss: 2.5313 - val_accuracy10: 0.6152 - 61s/epoch - 39ms/step
Epoch 22/50
1542/1542 - 60s - loss: 2.4187 - accuracy10: 0.6289 - val_loss: 2.5386 - val_accuracy10: 0.6276 - 60s/epoch - 39ms/step
Epoch 23/50
1542/1542 - 61s - loss: 2.4131 - accuracy10: 0.6306 - val_loss: 2.5306 - val_accuracy10: 0.6177 - 61s/epoch - 40ms/step
Epoch 24/50
1542/1542 - 62s - loss: 2.4104 - accuracy10: 0.6297 - val_loss: 2.5356 - val_accuracy10: 0.6078 - 62s/epoch - 40ms/step
Epoch 25/50
1542/1542 - 60s - loss: 2.4046 - accuracy10: 0.6307 - val_loss: 2.5522 - val_accuracy10: 0.6082 - 60s/epoch - 39ms/step
Epoch 26/50
1542/1542 - 61s - loss: 2.4013 - accuracy10: 0.6307 - val_loss: 2.5532 - val_accuracy10: 0.6045 - 61s/epoch - 39ms/step
Epoch 27/50
1542/1542 - 62s - loss: 2.3979 - accuracy10: 0.6317 - val_loss: 2.5434 - val_accuracy10: 0.6150 - 62s/epoch - 40ms/step
Epoch 28/50
1542/1542 - 61s - loss: 2.3940 - accuracy10: 0.6319 - val_loss: 2.5407 - val_accuracy10: 0.6184 - 61s/epoch - 39ms/step
Epoch 29/50
1542/1542 - 61s - loss: 2.3888 - accuracy10: 0.6326 - val_loss: 2.5348 - val_accuracy10: 0.6150 - 61s/epoch - 39ms/step
Epoch 30/50
1542/1542 - 60s - loss: 2.3866 - accuracy10: 0.6328 - val_loss: 2.5329 - val_accuracy10: 0.6178 - 60s/epoch - 39ms/step
Epoch 31/50
1542/1542 - 61s - loss: 2.3838 - accuracy10: 0.6330 - val_loss: 2.5363 - val_accuracy10: 0.6087 - 61s/epoch - 39ms/step
Epoch 32/50
1542/1542 - 61s - loss: 2.3796 - accuracy10: 0.6330 - val_loss: 2.5364 - val_accuracy10: 0.6090 - 61s/epoch - 39ms/step
Epoch 33/50
1542/1542 - 61s - loss: 2.3764 - accuracy10: 0.6334 - val_loss: 2.5376 - val_accuracy10: 0.6181 - 61s/epoch - 39ms/step
testing model: results/WBA/W2/deepVOL_L3/h10
Evaluating performance on  test set...
4353/4353 - 81s - 81s/epoch - 19ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.8103985
{'0': {'precision': 0.4421644426018142, 'recall': 0.5183903257165443, 'f1-score': 0.4772528896439978, 'support': 187218}, '1': {'precision': 0.8594680048176223, 'recall': 0.6661596054108749, 'f1-score': 0.7505669969709424, 'support': 740213}, '2': {'precision': 0.3826510271967309, 'recall': 0.657492092883863, 'f1-score': 0.4837603976965102, 'support': 186857}, 'accuracy': 0.6398785592234683, 'macro avg': {'precision': 0.5614278248720558, 'recall': 0.6140140080037607, 'f1-score': 0.5705267614371502, 'support': 1114288}, 'weighted avg': {'precision': 0.7093960949539011, 'recall': 0.6398785592234681, 'f1-score': 0.6599046177061936, 'support': 1114288}}
[[ 97052  39961  50205]
 [ 99107 493100 148006]
 [ 23334  40666 122857]]
Evaluating performance on  train set...
1542/1542 - 28s - 28s/epoch - 18ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.8742872
{'0': {'precision': 0.41028605035540816, 'recall': 0.5405744822979291, 'f1-score': 0.4665041015974036, 'support': 74850}, '1': {'precision': 0.8464332007330264, 'recall': 0.6121477578529695, 'f1-score': 0.7104743592749784, 'support': 247486}, '2': {'precision': 0.40268467852257184, 'recall': 0.6520830160466308, 'f1-score': 0.49789890425874933, 'support': 72227}, 'accuracy': 0.605880429741258, 'macro avg': {'precision': 0.5531346432036689, 'recall': 0.6016017520658431, 'f1-score': 0.5582924550437104, 'support': 394563}, 'weighted avg': {'precision': 0.6824638505419055, 'recall': 0.605880429741258, 'f1-score': 0.6252791910087607, 'support': 394563}}
[[ 40462  13668  20720]
 [ 46846 151498  49142]
 [ 11311  13818  47098]]
Evaluating performance on  val set...
482/482 - 9s - 9s/epoch - 18ms/step
Prediction horizon: 10  orderbook updates
Categorical crossentropy: 0.85874814
{'0': {'precision': 0.42412300763519933, 'recall': 0.5442232154950563, 'f1-score': 0.4767253312240459, 'support': 22149}, '1': {'precision': 0.8495304240723951, 'recall': 0.627009077938967, 'f1-score': 0.7215022519250327, 'support': 79203}, '2': {'precision': 0.3929512516469038, 'recall': 0.6519719464432098, 'f1-score': 0.4903579380030827, 'support': 21958}, 'accuracy': 0.6165842186359581, 'macro avg': {'precision': 0.5555348944514994, 'recall': 0.6077347466257442, 'f1-score': 0.5628618403840537, 'support': 123310}, 'weighted avg': {'precision': 0.6918147940765603, 'recall': 0.6165842186359581, 'f1-score': 0.6363750857446392, 'support': 123310}}
[[12054  4411  5684]
 [13110 49661 16432]
 [ 3257  4385 14316]]
training model: results/WBA/W2/deepVOL_L3/h20
Epoch 1/50
1542/1542 - 64s - loss: 3.1711 - accuracy20: 0.4404 - val_loss: 3.3284 - val_accuracy20: 0.5397 - 64s/epoch - 42ms/step
Epoch 2/50
1542/1542 - 63s - loss: 2.9353 - accuracy20: 0.5140 - val_loss: 2.8793 - val_accuracy20: 0.5529 - 63s/epoch - 41ms/step
Epoch 3/50
1542/1542 - 61s - loss: 2.7666 - accuracy20: 0.5673 - val_loss: 2.8793 - val_accuracy20: 0.5873 - 61s/epoch - 40ms/step
Epoch 4/50
1542/1542 - 62s - loss: 2.7140 - accuracy20: 0.5797 - val_loss: 2.8834 - val_accuracy20: 0.5870 - 62s/epoch - 40ms/step
Epoch 5/50
1542/1542 - 61s - loss: 2.6829 - accuracy20: 0.5861 - val_loss: 2.8662 - val_accuracy20: 0.5958 - 61s/epoch - 40ms/step
Epoch 6/50
1542/1542 - 61s - loss: 2.6589 - accuracy20: 0.5913 - val_loss: 2.8532 - val_accuracy20: 0.5945 - 61s/epoch - 40ms/step
Epoch 7/50
1542/1542 - 61s - loss: 2.6420 - accuracy20: 0.5935 - val_loss: 2.8622 - val_accuracy20: 0.5986 - 61s/epoch - 40ms/step
Epoch 8/50
1542/1542 - 62s - loss: 2.6311 - accuracy20: 0.5946 - val_loss: 2.8308 - val_accuracy20: 0.6027 - 62s/epoch - 40ms/step
Epoch 9/50
1542/1542 - 61s - loss: 2.6175 - accuracy20: 0.5969 - val_loss: 2.8440 - val_accuracy20: 0.6017 - 61s/epoch - 39ms/step
Epoch 10/50
1542/1542 - 61s - loss: 2.6080 - accuracy20: 0.5988 - val_loss: 2.7824 - val_accuracy20: 0.6073 - 61s/epoch - 40ms/step
Epoch 11/50
1542/1542 - 60s - loss: 2.5982 - accuracy20: 0.5998 - val_loss: 2.7647 - val_accuracy20: 0.6077 - 60s/epoch - 39ms/step
Epoch 12/50
1542/1542 - 61s - loss: 2.5890 - accuracy20: 0.6013 - val_loss: 2.7653 - val_accuracy20: 0.6065 - 61s/epoch - 39ms/step
Epoch 13/50
1542/1542 - 61s - loss: 2.5793 - accuracy20: 0.6030 - val_loss: 2.7265 - val_accuracy20: 0.6161 - 61s/epoch - 39ms/step
Epoch 14/50
1542/1542 - 62s - loss: 2.5734 - accuracy20: 0.6043 - val_loss: 2.7530 - val_accuracy20: 0.6144 - 62s/epoch - 40ms/step
Epoch 15/50
1542/1542 - 60s - loss: 2.5664 - accuracy20: 0.6045 - val_loss: 2.7364 - val_accuracy20: 0.6149 - 60s/epoch - 39ms/step
Epoch 16/50
1542/1542 - 61s - loss: 2.5605 - accuracy20: 0.6058 - val_loss: 2.7510 - val_accuracy20: 0.6127 - 61s/epoch - 40ms/step
Epoch 17/50
1542/1542 - 60s - loss: 2.5559 - accuracy20: 0.6066 - val_loss: 2.7190 - val_accuracy20: 0.6156 - 60s/epoch - 39ms/step
Epoch 18/50
1542/1542 - 60s - loss: 2.5502 - accuracy20: 0.6070 - val_loss: 2.7301 - val_accuracy20: 0.6169 - 60s/epoch - 39ms/step
Epoch 19/50
1542/1542 - 61s - loss: 2.5448 - accuracy20: 0.6081 - val_loss: 2.7237 - val_accuracy20: 0.6120 - 61s/epoch - 39ms/step
Epoch 20/50
1542/1542 - 61s - loss: 2.5398 - accuracy20: 0.6090 - val_loss: 2.6982 - val_accuracy20: 0.6172 - 61s/epoch - 39ms/step
Epoch 21/50
1542/1542 - 60s - loss: 2.5345 - accuracy20: 0.6100 - val_loss: 2.7079 - val_accuracy20: 0.6168 - 60s/epoch - 39ms/step
Epoch 22/50
1542/1542 - 60s - loss: 2.5306 - accuracy20: 0.6104 - val_loss: 2.6661 - val_accuracy20: 0.6104 - 60s/epoch - 39ms/step
Epoch 23/50
1542/1542 - 62s - loss: 2.5274 - accuracy20: 0.6099 - val_loss: 2.6918 - val_accuracy20: 0.6147 - 62s/epoch - 40ms/step
Epoch 24/50
1542/1542 - 64s - loss: 2.5233 - accuracy20: 0.6115 - val_loss: 2.6830 - val_accuracy20: 0.6076 - 64s/epoch - 42ms/step
Epoch 25/50
1542/1542 - 63s - loss: 2.5201 - accuracy20: 0.6121 - val_loss: 2.6815 - val_accuracy20: 0.6146 - 63s/epoch - 41ms/step
Epoch 26/50
1542/1542 - 63s - loss: 2.5173 - accuracy20: 0.6120 - val_loss: 2.6857 - val_accuracy20: 0.6097 - 63s/epoch - 41ms/step
Epoch 27/50
1542/1542 - 64s - loss: 2.5137 - accuracy20: 0.6128 - val_loss: 2.6977 - val_accuracy20: 0.6099 - 64s/epoch - 41ms/step
Epoch 28/50
1542/1542 - 64s - loss: 2.5095 - accuracy20: 0.6135 - val_loss: 2.6606 - val_accuracy20: 0.6075 - 64s/epoch - 42ms/step
Epoch 29/50
1542/1542 - 62s - loss: 2.5089 - accuracy20: 0.6137 - val_loss: 2.6741 - val_accuracy20: 0.6090 - 62s/epoch - 40ms/step
Epoch 30/50
1542/1542 - 61s - loss: 2.5040 - accuracy20: 0.6143 - val_loss: 2.6973 - val_accuracy20: 0.6069 - 61s/epoch - 40ms/step
Epoch 31/50
1542/1542 - 63s - loss: 2.5002 - accuracy20: 0.6147 - val_loss: 2.6916 - val_accuracy20: 0.6146 - 63s/epoch - 41ms/step
Epoch 32/50
1542/1542 - 61s - loss: 2.4968 - accuracy20: 0.6153 - val_loss: 2.7049 - val_accuracy20: 0.6051 - 61s/epoch - 40ms/step
Epoch 33/50
1542/1542 - 62s - loss: 2.4948 - accuracy20: 0.6156 - val_loss: 2.7236 - val_accuracy20: 0.5912 - 62s/epoch - 40ms/step
Epoch 34/50
1542/1542 - 63s - loss: 2.4929 - accuracy20: 0.6162 - val_loss: 2.6927 - val_accuracy20: 0.6065 - 63s/epoch - 41ms/step
Epoch 35/50
1542/1542 - 63s - loss: 2.4902 - accuracy20: 0.6164 - val_loss: 2.6964 - val_accuracy20: 0.5971 - 63s/epoch - 41ms/step
Epoch 36/50
1542/1542 - 63s - loss: 2.4876 - accuracy20: 0.6166 - val_loss: 2.6814 - val_accuracy20: 0.5997 - 63s/epoch - 41ms/step
Epoch 37/50
1542/1542 - 60s - loss: 2.4839 - accuracy20: 0.6171 - val_loss: 2.6932 - val_accuracy20: 0.6028 - 60s/epoch - 39ms/step
Epoch 38/50
1542/1542 - 59s - loss: 2.4808 - accuracy20: 0.6177 - val_loss: 2.6867 - val_accuracy20: 0.6054 - 59s/epoch - 38ms/step
testing model: results/WBA/W2/deepVOL_L3/h20
Evaluating performance on  test set...
4353/4353 - 80s - 80s/epoch - 18ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.8212585
{'0': {'precision': 0.5248011829496014, 'recall': 0.4605792387456898, 'f1-score': 0.49059738556589577, 'support': 240419}, '1': {'precision': 0.7677716938052855, 'recall': 0.7120619916186418, 'f1-score': 0.7388682211849995, 'support': 630924}, '2': {'precision': 0.4585127582933622, 'recall': 0.6004404289036613, 'f1-score': 0.5199655670827014, 'support': 242945}, 'accuracy': 0.633465495455394, 'macro avg': {'precision': 0.5836952116827497, 'recall': 0.5910272197559977, 'f1-score': 0.5831437246111989, 'support': 1114288}, 'weighted avg': {'precision': 0.6479214940926825, 'recall': 0.633465495455394, 'f1-score': 0.6375745418762462, 'support': 1114288}}
[[110732  67022  62665]
 [ 72060 449257 109607]
 [ 28206  68865 145874]]
Evaluating performance on  train set...
1542/1542 - 29s - 29s/epoch - 19ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.87915885
{'0': {'precision': 0.46866076182178984, 'recall': 0.5088976949031396, 'f1-score': 0.487951139375737, 'support': 95137}, '1': {'precision': 0.7544271413315973, 'recall': 0.6386506685745778, 'f1-score': 0.6917279060452234, 'support': 206858}, '2': {'precision': 0.4739506651168798, 'recall': 0.5946655431682655, 'f1-score': 0.5274899024018629, 'support': 92568}, 'accuracy': 0.5970453387671931, 'macro avg': {'precision': 0.5656795227567556, 'recall': 0.5807379688819942, 'f1-score': 0.5690563159409411, 'support': 394563}, 'weighted avg': {'precision': 0.6197208903712474, 'recall': 0.5970453387671931, 'f1-score': 0.6040615669006671, 'support': 394563}}
[[ 48415  20906  25816]
 [ 39466 132110  35282]
 [ 15424  22097  55047]]
Evaluating performance on  val set...
482/482 - 9s - 9s/epoch - 18ms/step
Prediction horizon: 20  orderbook updates
Categorical crossentropy: 0.8663948
{'0': {'precision': 0.4925615270442857, 'recall': 0.4961234919862323, 'f1-score': 0.4943360931167076, 'support': 28763}, '1': {'precision': 0.755709294921438, 'recall': 0.663563829787234, 'f1-score': 0.7066453175414175, 'support': 66176}, '2': {'precision': 0.46414771472731287, 'recall': 0.5927531634415424, 'f1-score': 0.5206259771218055, 'support': 28371}, 'accuracy': 0.6082150677155137, 'macro avg': {'precision': 0.5708061788976789, 'recall': 0.584146828405003, 'f1-score': 0.5738691292599768, 'support': 123310}, 'weighted avg': {'precision': 0.6272459680287443, 'recall': 0.6082150677155137, 'f1-score': 0.6143234869585552, 'support': 123310}}
[[14270  6945  7548]
 [10397 43912 11867]
 [ 4304  7250 16817]]
training model: results/WBA/W2/deepVOL_L3/h30
Epoch 1/50
1542/1542 - 65s - loss: 3.1968 - accuracy30: 0.4354 - val_loss: 3.3606 - val_accuracy30: 0.5065 - 65s/epoch - 42ms/step
Epoch 2/50
1542/1542 - 63s - loss: 3.1069 - accuracy30: 0.4687 - val_loss: 3.1450 - val_accuracy30: 0.5077 - 63s/epoch - 41ms/step
Epoch 3/50
1542/1542 - 62s - loss: 2.9563 - accuracy30: 0.5136 - val_loss: 2.9515 - val_accuracy30: 0.5508 - 62s/epoch - 40ms/step
Epoch 4/50
1542/1542 - 62s - loss: 2.8526 - accuracy30: 0.5437 - val_loss: 2.9113 - val_accuracy30: 0.5561 - 62s/epoch - 40ms/step
Epoch 5/50
1542/1542 - 61s - loss: 2.7980 - accuracy30: 0.5564 - val_loss: 2.9072 - val_accuracy30: 0.5589 - 61s/epoch - 40ms/step
Epoch 6/50
1542/1542 - 62s - loss: 2.7660 - accuracy30: 0.5623 - val_loss: 2.8817 - val_accuracy30: 0.5631 - 62s/epoch - 40ms/step
Epoch 7/50
1542/1542 - 61s - loss: 2.7444 - accuracy30: 0.5677 - val_loss: 2.8724 - val_accuracy30: 0.5653 - 61s/epoch - 40ms/step
Epoch 8/50
1542/1542 - 60s - loss: 2.7285 - accuracy30: 0.5699 - val_loss: 2.8644 - val_accuracy30: 0.5674 - 60s/epoch - 39ms/step
Epoch 9/50
1542/1542 - 61s - loss: 2.7143 - accuracy30: 0.5736 - val_loss: 2.8874 - val_accuracy30: 0.5595 - 61s/epoch - 40ms/step
Epoch 10/50
1542/1542 - 61s - loss: 2.7057 - accuracy30: 0.5742 - val_loss: 2.8639 - val_accuracy30: 0.5616 - 61s/epoch - 40ms/step
Epoch 11/50
1542/1542 - 61s - loss: 2.6946 - accuracy30: 0.5760 - val_loss: 2.8280 - val_accuracy30: 0.5740 - 61s/epoch - 40ms/step
Epoch 12/50
1542/1542 - 60s - loss: 2.6865 - accuracy30: 0.5780 - val_loss: 2.8506 - val_accuracy30: 0.5685 - 60s/epoch - 39ms/step
Epoch 13/50
1542/1542 - 61s - loss: 2.6779 - accuracy30: 0.5792 - val_loss: 2.8696 - val_accuracy30: 0.5670 - 61s/epoch - 40ms/step
Epoch 14/50
1542/1542 - 62s - loss: 2.6705 - accuracy30: 0.5800 - val_loss: 2.8412 - val_accuracy30: 0.5713 - 62s/epoch - 40ms/step
Epoch 15/50
1542/1542 - 61s - loss: 2.6654 - accuracy30: 0.5816 - val_loss: 2.8421 - val_accuracy30: 0.5680 - 61s/epoch - 40ms/step
Epoch 16/50
1542/1542 - 61s - loss: 2.6586 - accuracy30: 0.5820 - val_loss: 2.8181 - val_accuracy30: 0.5709 - 61s/epoch - 39ms/step
Epoch 17/50
1542/1542 - 60s - loss: 2.6519 - accuracy30: 0.5832 - val_loss: 2.8451 - val_accuracy30: 0.5708 - 60s/epoch - 39ms/step
Epoch 18/50
1542/1542 - 60s - loss: 2.6465 - accuracy30: 0.5845 - val_loss: 2.8881 - val_accuracy30: 0.5705 - 60s/epoch - 39ms/step
Epoch 19/50
1542/1542 - 62s - loss: 2.6425 - accuracy30: 0.5848 - val_loss: 2.8377 - val_accuracy30: 0.5695 - 62s/epoch - 40ms/step
Epoch 20/50
1542/1542 - 61s - loss: 2.6381 - accuracy30: 0.5860 - val_loss: 2.8332 - val_accuracy30: 0.5715 - 61s/epoch - 40ms/step
Epoch 21/50
1542/1542 - 61s - loss: 2.6329 - accuracy30: 0.5868 - val_loss: 2.8212 - val_accuracy30: 0.5746 - 61s/epoch - 40ms/step
Epoch 22/50
1542/1542 - 61s - loss: 2.6293 - accuracy30: 0.5877 - val_loss: 2.8283 - val_accuracy30: 0.5773 - 61s/epoch - 39ms/step
Epoch 23/50
1542/1542 - 61s - loss: 2.6244 - accuracy30: 0.5889 - val_loss: 2.8147 - val_accuracy30: 0.5775 - 61s/epoch - 40ms/step
Epoch 24/50
1542/1542 - 61s - loss: 2.6204 - accuracy30: 0.5888 - val_loss: 2.8160 - val_accuracy30: 0.5716 - 61s/epoch - 39ms/step
Epoch 25/50
1542/1542 - 61s - loss: 2.6167 - accuracy30: 0.5890 - val_loss: 2.8202 - val_accuracy30: 0.5702 - 61s/epoch - 40ms/step
Epoch 26/50
1542/1542 - 61s - loss: 2.6149 - accuracy30: 0.5899 - val_loss: 2.8241 - val_accuracy30: 0.5723 - 61s/epoch - 40ms/step
Epoch 27/50
1542/1542 - 60s - loss: 2.6100 - accuracy30: 0.5905 - val_loss: 2.8276 - val_accuracy30: 0.5717 - 60s/epoch - 39ms/step
Epoch 28/50
1542/1542 - 61s - loss: 2.6066 - accuracy30: 0.5915 - val_loss: 2.8239 - val_accuracy30: 0.5737 - 61s/epoch - 40ms/step
Epoch 29/50
1542/1542 - 60s - loss: 2.6041 - accuracy30: 0.5922 - val_loss: 2.8094 - val_accuracy30: 0.5733 - 60s/epoch - 39ms/step
Epoch 30/50
1542/1542 - 62s - loss: 2.6009 - accuracy30: 0.5924 - val_loss: 2.8161 - val_accuracy30: 0.5701 - 62s/epoch - 40ms/step
Epoch 31/50
1542/1542 - 61s - loss: 2.5967 - accuracy30: 0.5934 - val_loss: 2.8056 - val_accuracy30: 0.5754 - 61s/epoch - 39ms/step
Epoch 32/50
1542/1542 - 61s - loss: 2.5922 - accuracy30: 0.5949 - val_loss: 2.8291 - val_accuracy30: 0.5725 - 61s/epoch - 40ms/step
Epoch 33/50
1542/1542 - 60s - loss: 2.5918 - accuracy30: 0.5942 - val_loss: 2.8308 - val_accuracy30: 0.5736 - 60s/epoch - 39ms/step
Epoch 34/50
1542/1542 - 61s - loss: 2.5876 - accuracy30: 0.5952 - val_loss: 2.8283 - val_accuracy30: 0.5727 - 61s/epoch - 40ms/step
Epoch 35/50
1542/1542 - 61s - loss: 2.5839 - accuracy30: 0.5951 - val_loss: 2.8269 - val_accuracy30: 0.5711 - 61s/epoch - 40ms/step
Epoch 36/50
1542/1542 - 60s - loss: 2.5803 - accuracy30: 0.5960 - val_loss: 2.8430 - val_accuracy30: 0.5701 - 60s/epoch - 39ms/step
Epoch 37/50
1542/1542 - 63s - loss: 2.5778 - accuracy30: 0.5967 - val_loss: 2.8413 - val_accuracy30: 0.5763 - 63s/epoch - 41ms/step
Epoch 38/50
1542/1542 - 63s - loss: 2.5744 - accuracy30: 0.5968 - val_loss: 2.8206 - val_accuracy30: 0.5771 - 63s/epoch - 41ms/step
Epoch 39/50
1542/1542 - 63s - loss: 2.5730 - accuracy30: 0.5978 - val_loss: 2.8334 - val_accuracy30: 0.5703 - 63s/epoch - 41ms/step
Epoch 40/50
1542/1542 - 63s - loss: 2.5687 - accuracy30: 0.5976 - val_loss: 2.8439 - val_accuracy30: 0.5715 - 63s/epoch - 41ms/step
Epoch 41/50
1542/1542 - 63s - loss: 2.5657 - accuracy30: 0.5988 - val_loss: 2.8370 - val_accuracy30: 0.5748 - 63s/epoch - 41ms/step
testing model: results/WBA/W2/deepVOL_L3/h30
Evaluating performance on  test set...
4353/4353 - 86s - 86s/epoch - 20ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.8799377
{'0': {'precision': 0.5781365116334339, 'recall': 0.3503469084284166, 'f1-score': 0.4362993137494479, 'support': 277739}, '1': {'precision': 0.6834045862154335, 'recall': 0.7402018478726429, 'f1-score': 0.7106702041359363, 'support': 555666}, '2': {'precision': 0.4623328771143715, 'recall': 0.5664422553162705, 'f1-score': 0.5091197665339767, 'support': 280883}, 'accuracy': 0.5992292836322387, 'macro avg': {'precision': 0.5746246583210797, 'recall': 0.5523303372057766, 'f1-score': 0.5520297614731203, 'support': 1114288}, 'weighted avg': {'precision': 0.6014398386512817, 'recall': 0.5992292836322387, 'f1-score': 0.5914769719643576, 'support': 1114288}}
[[ 97305  93157  87277]
 [ 46609 411305  97752]
 [ 24394  97385 159104]]
Evaluating performance on  train set...
1542/1542 - 30s - 30s/epoch - 19ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.92599756
{'0': {'precision': 0.5232167865939055, 'recall': 0.3990368678870023, 'f1-score': 0.4527665176146099, 'support': 108604}, '1': {'precision': 0.6713725857756272, 'recall': 0.6380048431541737, 'f1-score': 0.6542635481900542, 'support': 179635}, '2': {'precision': 0.46366678957370167, 'recall': 0.6150069598585456, 'f1-score': 0.5287202044050584, 'support': 106324}, 'accuracy': 0.5660312801757894, 'macro avg': {'precision': 0.5527520539810781, 'recall': 0.5506828902999072, 'f1-score': 0.5452500900699074, 'support': 394563}, 'weighted avg': {'precision': 0.5746214370624807, 'recall': 0.5660312801757894, 'f1-score': 0.5649707001703173, 'support': 394563}}
[[ 43337  28512  36755]
 [ 26144 114608  38883]
 [ 13347  27587  65390]]
Evaluating performance on  val set...
482/482 - 10s - 10s/epoch - 20ms/step
Prediction horizon: 30  orderbook updates
Categorical crossentropy: 0.914746
{'0': {'precision': 0.5503285608599155, 'recall': 0.3818928549858066, 'f1-score': 0.4508940509510991, 'support': 33114}, '1': {'precision': 0.6767028367422311, 'recall': 0.6698466305729157, 'f1-score': 0.6732572788353863, 'support': 57443}, '2': {'precision': 0.4575569358178054, 'recall': 0.6072726162488933, 'f1-score': 0.5218897183264893, 'support': 32753}, 'accuracy': 0.5758981428918984, 'macro avg': {'precision': 0.5615294444733173, 'recall': 0.5530040339358718, 'f1-score': 0.5486803493709916, 'support': 123310}, 'weighted avg': {'precision': 0.5845574838548359, 'recall': 0.5758981428918984, 'f1-score': 0.5733377456466086, 'support': 123310}}
[[12646  9365 11103]
 [ 6488 38478 12477]
 [ 3845  9018 19890]]
training model: results/WBA/W2/deepVOL_L3/h50
Epoch 1/50
1542/1542 - 67s - loss: 3.2751 - accuracy50: 0.3841 - val_loss: 3.4517 - val_accuracy50: 0.3704 - 67s/epoch - 43ms/step
Epoch 2/50
1542/1542 - 64s - loss: 3.2252 - accuracy50: 0.4095 - val_loss: 3.2693 - val_accuracy50: 0.4386 - 64s/epoch - 42ms/step
Epoch 3/50
1542/1542 - 62s - loss: 3.1753 - accuracy50: 0.4381 - val_loss: 3.1738 - val_accuracy50: 0.4553 - 62s/epoch - 40ms/step
Epoch 4/50
1542/1542 - 64s - loss: 3.1180 - accuracy50: 0.4589 - val_loss: 3.1254 - val_accuracy50: 0.4707 - 64s/epoch - 41ms/step
Epoch 5/50
1542/1542 - 63s - loss: 3.0212 - accuracy50: 0.4898 - val_loss: 3.0809 - val_accuracy50: 0.5038 - 63s/epoch - 41ms/step
Epoch 6/50
1542/1542 - 63s - loss: 2.9536 - accuracy50: 0.5069 - val_loss: 3.0758 - val_accuracy50: 0.5096 - 63s/epoch - 41ms/step
Epoch 7/50
1542/1542 - 62s - loss: 2.9167 - accuracy50: 0.5137 - val_loss: 3.0395 - val_accuracy50: 0.5080 - 62s/epoch - 40ms/step
Epoch 8/50
1542/1542 - 62s - loss: 2.8916 - accuracy50: 0.5200 - val_loss: 3.0075 - val_accuracy50: 0.5116 - 62s/epoch - 40ms/step
Epoch 9/50
1542/1542 - 61s - loss: 2.8749 - accuracy50: 0.5235 - val_loss: 2.9970 - val_accuracy50: 0.5144 - 61s/epoch - 40ms/step
Epoch 10/50
1542/1542 - 62s - loss: 2.8597 - accuracy50: 0.5264 - val_loss: 3.0135 - val_accuracy50: 0.5141 - 62s/epoch - 40ms/step
Epoch 11/50
1542/1542 - 63s - loss: 2.8490 - accuracy50: 0.5286 - val_loss: 2.9849 - val_accuracy50: 0.5163 - 63s/epoch - 41ms/step
Epoch 12/50
1542/1542 - 62s - loss: 2.8405 - accuracy50: 0.5320 - val_loss: 3.0176 - val_accuracy50: 0.5147 - 62s/epoch - 40ms/step
Epoch 13/50
1542/1542 - 63s - loss: 2.8321 - accuracy50: 0.5336 - val_loss: 2.9690 - val_accuracy50: 0.5181 - 63s/epoch - 41ms/step
Epoch 14/50
1542/1542 - 61s - loss: 2.8253 - accuracy50: 0.5342 - val_loss: 2.9849 - val_accuracy50: 0.5182 - 61s/epoch - 39ms/step
Epoch 15/50
1542/1542 - 63s - loss: 2.8171 - accuracy50: 0.5362 - val_loss: 2.9736 - val_accuracy50: 0.5189 - 63s/epoch - 41ms/step
Epoch 16/50
1542/1542 - 61s - loss: 2.8120 - accuracy50: 0.5377 - val_loss: 2.9471 - val_accuracy50: 0.5217 - 61s/epoch - 40ms/step
Epoch 17/50
1542/1542 - 67s - loss: 2.8058 - accuracy50: 0.5382 - val_loss: 2.9534 - val_accuracy50: 0.5190 - 67s/epoch - 44ms/step
Epoch 18/50
1542/1542 - 64s - loss: 2.8012 - accuracy50: 0.5391 - val_loss: 2.9503 - val_accuracy50: 0.5207 - 64s/epoch - 42ms/step
Epoch 19/50
1542/1542 - 63s - loss: 2.7955 - accuracy50: 0.5412 - val_loss: 2.9673 - val_accuracy50: 0.5203 - 63s/epoch - 41ms/step
Epoch 20/50
1542/1542 - 62s - loss: 2.7908 - accuracy50: 0.5415 - val_loss: 2.9559 - val_accuracy50: 0.5181 - 62s/epoch - 40ms/step
Epoch 21/50
1542/1542 - 63s - loss: 2.7862 - accuracy50: 0.5428 - val_loss: 2.9698 - val_accuracy50: 0.5200 - 63s/epoch - 41ms/step
Epoch 22/50
1542/1542 - 63s - loss: 2.7819 - accuracy50: 0.5450 - val_loss: 2.9609 - val_accuracy50: 0.5194 - 63s/epoch - 41ms/step
Epoch 23/50
1542/1542 - 62s - loss: 2.7775 - accuracy50: 0.5452 - val_loss: 2.9469 - val_accuracy50: 0.5212 - 62s/epoch - 40ms/step
Epoch 24/50
1542/1542 - 62s - loss: 2.7725 - accuracy50: 0.5463 - val_loss: 2.9511 - val_accuracy50: 0.5197 - 62s/epoch - 40ms/step
Epoch 25/50
1542/1542 - 60s - loss: 2.7708 - accuracy50: 0.5464 - val_loss: 2.9405 - val_accuracy50: 0.5215 - 60s/epoch - 39ms/step
Epoch 26/50
1542/1542 - 62s - loss: 2.7651 - accuracy50: 0.5481 - val_loss: 2.9589 - val_accuracy50: 0.5160 - 62s/epoch - 40ms/step
Epoch 27/50
1542/1542 - 61s - loss: 2.7622 - accuracy50: 0.5490 - val_loss: 2.9594 - val_accuracy50: 0.5184 - 61s/epoch - 39ms/step
Epoch 28/50
1542/1542 - 62s - loss: 2.7584 - accuracy50: 0.5499 - val_loss: 2.9374 - val_accuracy50: 0.5203 - 62s/epoch - 40ms/step
Epoch 29/50
1542/1542 - 61s - loss: 2.7538 - accuracy50: 0.5503 - val_loss: 2.9545 - val_accuracy50: 0.5194 - 61s/epoch - 40ms/step
Epoch 30/50
1542/1542 - 62s - loss: 2.7517 - accuracy50: 0.5505 - val_loss: 2.9539 - val_accuracy50: 0.5190 - 62s/epoch - 40ms/step
Epoch 31/50
1542/1542 - 61s - loss: 2.7472 - accuracy50: 0.5518 - val_loss: 2.9518 - val_accuracy50: 0.5192 - 61s/epoch - 39ms/step
Epoch 32/50
1542/1542 - 61s - loss: 2.7446 - accuracy50: 0.5520 - val_loss: 2.9517 - val_accuracy50: 0.5197 - 61s/epoch - 40ms/step
Epoch 33/50
1542/1542 - 62s - loss: 2.7399 - accuracy50: 0.5537 - val_loss: 2.9546 - val_accuracy50: 0.5187 - 62s/epoch - 40ms/step
Epoch 34/50
1542/1542 - 61s - loss: 2.7374 - accuracy50: 0.5540 - val_loss: 2.9522 - val_accuracy50: 0.5182 - 61s/epoch - 40ms/step
Epoch 35/50
1542/1542 - 61s - loss: 2.7347 - accuracy50: 0.5545 - val_loss: 2.9543 - val_accuracy50: 0.5174 - 61s/epoch - 40ms/step
Epoch 36/50
1542/1542 - 62s - loss: 2.7306 - accuracy50: 0.5554 - val_loss: 2.9359 - val_accuracy50: 0.5180 - 62s/epoch - 40ms/step
Epoch 37/50
1542/1542 - 67s - loss: 2.7272 - accuracy50: 0.5568 - val_loss: 2.9477 - val_accuracy50: 0.5201 - 67s/epoch - 43ms/step
Epoch 38/50
1542/1542 - 61s - loss: 2.7244 - accuracy50: 0.5570 - val_loss: 2.9517 - val_accuracy50: 0.5188 - 61s/epoch - 39ms/step
Epoch 39/50
1542/1542 - 61s - loss: 2.7193 - accuracy50: 0.5577 - val_loss: 2.9651 - val_accuracy50: 0.5190 - 61s/epoch - 40ms/step
Epoch 40/50
1542/1542 - 65s - loss: 2.7162 - accuracy50: 0.5583 - val_loss: 2.9761 - val_accuracy50: 0.5171 - 65s/epoch - 42ms/step
Epoch 41/50
1542/1542 - 61s - loss: 2.7125 - accuracy50: 0.5595 - val_loss: 2.9670 - val_accuracy50: 0.5190 - 61s/epoch - 40ms/step
Epoch 42/50
1542/1542 - 61s - loss: 2.7099 - accuracy50: 0.5604 - val_loss: 2.9720 - val_accuracy50: 0.5190 - 61s/epoch - 40ms/step
Epoch 43/50
1542/1542 - 61s - loss: 2.7068 - accuracy50: 0.5611 - val_loss: 2.9836 - val_accuracy50: 0.5155 - 61s/epoch - 39ms/step
Epoch 44/50
1542/1542 - 62s - loss: 2.7004 - accuracy50: 0.5625 - val_loss: 2.9833 - val_accuracy50: 0.5157 - 62s/epoch - 40ms/step
Epoch 45/50
1542/1542 - 61s - loss: 2.6996 - accuracy50: 0.5629 - val_loss: 2.9815 - val_accuracy50: 0.5157 - 61s/epoch - 39ms/step
Epoch 46/50
1542/1542 - 61s - loss: 2.6946 - accuracy50: 0.5635 - val_loss: 3.0042 - val_accuracy50: 0.5160 - 61s/epoch - 40ms/step
testing model: results/WBA/W2/deepVOL_L3/h50
Evaluating performance on  test set...
4353/4353 - 80s - 80s/epoch - 18ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.96192276
{'0': {'precision': 0.5645406186516995, 'recall': 0.32310601293323027, 'f1-score': 0.41098892721693886, 'support': 333714}, '1': {'precision': 0.5496681122506049, 'recall': 0.7687030440631606, 'f1-score': 0.6409902842427336, 'support': 447494}, '2': {'precision': 0.4905068610115706, 'recall': 0.4380779392338177, 'f1-score': 0.46281230275406865, 'support': 333080}, 'accuracy': 0.5364232586189567, 'macro avg': {'precision': 0.5349051973046249, 'recall': 0.5099623320767361, 'f1-score': 0.5049305047379137, 'support': 1114288}, 'weighted avg': {'precision': 0.5364379007060466, 'recall': 0.5364232586189567, 'f1-score': 0.5188475393394855, 'support': 1114288}}
[[107825 144527  81362]
 [ 33303 343990  70201]
 [ 49868 137297 145915]]
Evaluating performance on  train set...
1542/1542 - 28s - 28s/epoch - 18ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.9674499
{'0': {'precision': 0.5247889630842888, 'recall': 0.3931366457184656, 'f1-score': 0.4495217709986825, 'support': 127139}, '1': {'precision': 0.5356632670010963, 'recall': 0.6779109937004674, 'f1-score': 0.598450427601565, 'support': 142709}, '2': {'precision': 0.4943182296799845, 'recall': 0.47052880567694344, 'f1-score': 0.48213023974234687, 'support': 124715}, 'accuracy': 0.5205987383510364, 'macro avg': {'precision': 0.51825681992179, 'recall': 0.5138588150319588, 'f1-score': 0.5100341461141981, 'support': 394563}, 'weighted avg': {'precision': 0.5190907691865991, 'recall': 0.5205987383510364, 'f1-score': 0.5136946022943358, 'support': 394563}}
[[49983 44095 33061]
 [18995 96744 26970]
 [26266 39767 58682]]
Evaluating performance on  val set...
482/482 - 9s - 9s/epoch - 18ms/step
Prediction horizon: 50  orderbook updates
Categorical crossentropy: 0.9732795
{'0': {'precision': 0.5187328328145029, 'recall': 0.3646004942339374, 'f1-score': 0.42821943071364876, 'support': 38848}, '1': {'precision': 0.5393848332556171, 'recall': 0.6839523475823406, 'f1-score': 0.6031264785114949, 'support': 45664}, '2': {'precision': 0.4874022361030917, 'recall': 0.47865869374710035, 'f1-score': 0.4829908972691807, 'support': 38798}, 'accuracy': 0.5187494931473522, 'macro avg': {'precision': 0.5151733007244039, 'recall': 0.5090705118544595, 'f1-score': 0.5047789354981081, 'support': 123310}, 'weighted avg': {'precision': 0.5165228616599632, 'recall': 0.5187494931473522, 'f1-score': 0.5102239623012116, 'support': 123310}}
[[14164 13851 10833]
 [ 5734 31232  8698]
 [ 7407 12820 18571]]
training model: results/WBA/W2/deepVOL_L3/h100
Epoch 1/50
1542/1542 - 65s - loss: 3.2671 - accuracy100: 0.3860 - val_loss: 3.5141 - val_accuracy100: 0.3308 - 65s/epoch - 42ms/step
Epoch 2/50
1542/1542 - 62s - loss: 3.2449 - accuracy100: 0.3920 - val_loss: 3.3351 - val_accuracy100: 0.3346 - 62s/epoch - 40ms/step
Epoch 3/50
1542/1542 - 63s - loss: 3.2350 - accuracy100: 0.3993 - val_loss: 3.2716 - val_accuracy100: 0.3756 - 63s/epoch - 41ms/step
Epoch 4/50
1542/1542 - 63s - loss: 3.2295 - accuracy100: 0.3975 - val_loss: 3.2903 - val_accuracy100: 0.3702 - 63s/epoch - 41ms/step
Epoch 5/50
1542/1542 - 62s - loss: 3.2226 - accuracy100: 0.4047 - val_loss: 3.2631 - val_accuracy100: 0.3815 - 62s/epoch - 40ms/step
Epoch 6/50
1542/1542 - 61s - loss: 3.2001 - accuracy100: 0.4195 - val_loss: 3.2364 - val_accuracy100: 0.3879 - 61s/epoch - 40ms/step
Epoch 7/50
1542/1542 - 62s - loss: 3.1831 - accuracy100: 0.4244 - val_loss: 3.2254 - val_accuracy100: 0.3997 - 62s/epoch - 40ms/step
Epoch 8/50
1542/1542 - 61s - loss: 3.1635 - accuracy100: 0.4339 - val_loss: 3.2051 - val_accuracy100: 0.4149 - 61s/epoch - 40ms/step
Epoch 9/50
1542/1542 - 61s - loss: 3.1466 - accuracy100: 0.4417 - val_loss: 3.2008 - val_accuracy100: 0.4245 - 61s/epoch - 40ms/step
Epoch 10/50
1542/1542 - 61s - loss: 3.1330 - accuracy100: 0.4487 - val_loss: 3.2087 - val_accuracy100: 0.4287 - 61s/epoch - 39ms/step
Epoch 11/50
1542/1542 - 61s - loss: 3.1197 - accuracy100: 0.4519 - val_loss: 3.2057 - val_accuracy100: 0.4344 - 61s/epoch - 40ms/step
Epoch 12/50
1542/1542 - 61s - loss: 3.1084 - accuracy100: 0.4550 - val_loss: 3.2275 - val_accuracy100: 0.4335 - 61s/epoch - 40ms/step
Epoch 13/50
1542/1542 - 63s - loss: 3.0986 - accuracy100: 0.4582 - val_loss: 3.2364 - val_accuracy100: 0.4330 - 63s/epoch - 41ms/step
Epoch 14/50
1542/1542 - 63s - loss: 3.0924 - accuracy100: 0.4594 - val_loss: 3.2403 - val_accuracy100: 0.4329 - 63s/epoch - 41ms/step
Epoch 15/50
1542/1542 - 63s - loss: 3.0856 - accuracy100: 0.4618 - val_loss: 3.2464 - val_accuracy100: 0.4352 - 63s/epoch - 41ms/step
Epoch 16/50
1542/1542 - 64s - loss: 3.0782 - accuracy100: 0.4645 - val_loss: 3.2394 - val_accuracy100: 0.4348 - 64s/epoch - 42ms/step
Epoch 17/50
1542/1542 - 64s - loss: 3.0727 - accuracy100: 0.4664 - val_loss: 3.2257 - val_accuracy100: 0.4377 - 64s/epoch - 41ms/step
Epoch 18/50
1542/1542 - 64s - loss: 3.0686 - accuracy100: 0.4674 - val_loss: 3.2303 - val_accuracy100: 0.4373 - 64s/epoch - 41ms/step
Epoch 19/50
1542/1542 - 63s - loss: 3.0628 - accuracy100: 0.4694 - val_loss: 3.2326 - val_accuracy100: 0.4368 - 63s/epoch - 41ms/step
testing model: results/WBA/W2/deepVOL_L3/h100
Evaluating performance on  test set...
4353/4353 - 81s - 81s/epoch - 19ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0560707
{'0': {'precision': 0.48372896878739086, 'recall': 0.17452686894096453, 'f1-score': 0.25650726510789956, 'support': 375266}, '1': {'precision': 0.43085916550466585, 'recall': 0.6287917724375615, 'f1-score': 0.5113395150194604, 'support': 383297}, '2': {'precision': 0.42004319283742614, 'recall': 0.4953658022348724, 'f1-score': 0.45460561194676735, 'support': 355725}, 'accuracy': 0.4332111626437689, 'macro avg': {'precision': 0.44487710904316097, 'recall': 0.4328948145377995, 'f1-score': 0.40748413069137573, 'support': 1114288}, 'weighted avg': {'precision': 0.44521158401912647, 'recall': 0.4332111626437689, 'f1-score': 0.4074062888105759, 'support': 1114288}}
[[ 65494 174596 135176]
 [ 34159 241014 108124]
 [ 35741 143770 176214]]
Evaluating performance on  train set...
1542/1542 - 29s - 29s/epoch - 19ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.0705366
{'0': {'precision': 0.44271626476632614, 'recall': 0.2218567088982737, 'f1-score': 0.2955870231531981, 'support': 134970}, '1': {'precision': 0.41095336350207506, 'recall': 0.5465239557835326, 'f1-score': 0.46914084196015715, 'support': 128278}, '2': {'precision': 0.41794281327960087, 'recall': 0.4975593039637513, 'f1-score': 0.454289141128822, 'support': 131315}, 'accuracy': 0.41916753471562207, 'macro avg': {'precision': 0.42387081384933406, 'recall': 0.42197998954851923, 'f1-score': 0.4063390020807258, 'support': 394563}, 'weighted avg': {'precision': 0.42414481424928596, 'recall': 0.41916753471562207, 'f1-score': 0.40482966727058406, 'support': 394563}}
[[29944 53904 51122]
 [18300 70107 39871]
 [19393 46585 65337]]
Evaluating performance on  val set...
482/482 - 9s - 9s/epoch - 19ms/step
Prediction horizon: 100  orderbook updates
Categorical crossentropy: 1.067969
{'0': {'precision': 0.44107029093225736, 'recall': 0.2010989276983032, 'f1-score': 0.27624731915742573, 'support': 41313}, '1': {'precision': 0.42831401285362486, 'recall': 0.5246468510888758, 'f1-score': 0.47161138851228457, 'support': 40776}, '2': {'precision': 0.41241953527610176, 'recall': 0.5455471725576769, 'f1-score': 0.46973304925429255, 'support': 41221}, 'accuracy': 0.42323412537507094, 'macro avg': {'precision': 0.4272679463539946, 'recall': 0.42376431711495194, 'f1-score': 0.4058639189746676, 'support': 123310}, 'weighted avg': {'precision': 0.42727446906998573, 'recall': 0.42323412537507094, 'f1-score': 0.40552994483528376, 'support': 123310}}
[[ 8308 15228 17777]
 [ 5121 21393 14262]
 [ 5407 13326 22488]]
training model: results/WBA/W2/deepVOL_L3/h200
Epoch 1/50
1542/1542 - 65s - loss: 3.2973 - accuracy200: 0.3653 - val_loss: 3.3110 - val_accuracy200: 0.3336 - 65s/epoch - 42ms/step
Epoch 2/50
1542/1542 - 62s - loss: 3.2954 - accuracy200: 0.3483 - val_loss: 3.3011 - val_accuracy200: 0.3391 - 62s/epoch - 40ms/step
Epoch 3/50
1542/1542 - 62s - loss: 3.2833 - accuracy200: 0.3593 - val_loss: 3.3114 - val_accuracy200: 0.3456 - 62s/epoch - 40ms/step
Epoch 4/50
1542/1542 - 63s - loss: 3.2741 - accuracy200: 0.3697 - val_loss: 3.2998 - val_accuracy200: 0.3482 - 63s/epoch - 41ms/step
Epoch 5/50
1542/1542 - 62s - loss: 3.2666 - accuracy200: 0.3755 - val_loss: 3.2912 - val_accuracy200: 0.3524 - 62s/epoch - 40ms/step
Epoch 6/50
1542/1542 - 61s - loss: 3.2641 - accuracy200: 0.3772 - val_loss: 3.2841 - val_accuracy200: 0.3573 - 61s/epoch - 40ms/step
Epoch 7/50
1542/1542 - 61s - loss: 3.2564 - accuracy200: 0.3832 - val_loss: 3.2934 - val_accuracy200: 0.3533 - 61s/epoch - 40ms/step
Epoch 8/50
1542/1542 - 63s - loss: 3.2502 - accuracy200: 0.3887 - val_loss: 3.2870 - val_accuracy200: 0.3571 - 63s/epoch - 41ms/step
Epoch 9/50
1542/1542 - 66s - loss: 3.2461 - accuracy200: 0.3901 - val_loss: 3.2886 - val_accuracy200: 0.3586 - 66s/epoch - 43ms/step
Epoch 10/50
1542/1542 - 66s - loss: 3.2391 - accuracy200: 0.3954 - val_loss: 3.2872 - val_accuracy200: 0.3636 - 66s/epoch - 43ms/step
Epoch 11/50
1542/1542 - 62s - loss: 3.2309 - accuracy200: 0.4004 - val_loss: 3.3018 - val_accuracy200: 0.3561 - 62s/epoch - 40ms/step
Epoch 12/50
1542/1542 - 61s - loss: 3.2240 - accuracy200: 0.4055 - val_loss: 3.2918 - val_accuracy200: 0.3647 - 61s/epoch - 40ms/step
Epoch 13/50
1542/1542 - 62s - loss: 3.2159 - accuracy200: 0.4095 - val_loss: 3.2998 - val_accuracy200: 0.3633 - 62s/epoch - 40ms/step
Epoch 14/50
1542/1542 - 62s - loss: 3.2091 - accuracy200: 0.4135 - val_loss: 3.2984 - val_accuracy200: 0.3668 - 62s/epoch - 40ms/step
Epoch 15/50
1542/1542 - 62s - loss: 3.2035 - accuracy200: 0.4161 - val_loss: 3.3072 - val_accuracy200: 0.3628 - 62s/epoch - 40ms/step
Epoch 16/50
1542/1542 - 61s - loss: 3.1973 - accuracy200: 0.4191 - val_loss: 3.3241 - val_accuracy200: 0.3634 - 61s/epoch - 40ms/step
testing model: results/WBA/W2/deepVOL_L3/h200
Evaluating performance on  test set...
4353/4353 - 81s - 81s/epoch - 19ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0925167
{'0': {'precision': 0.37605911852190443, 'recall': 0.29814416529455173, 'f1-score': 0.3325994835220689, 'support': 380799}, '1': {'precision': 0.34761801410743354, 'recall': 0.2512996590029497, 'f1-score': 0.2917138442577915, 'support': 382408}, '2': {'precision': 0.34720936828278004, 'recall': 0.5300258344940342, 'f1-score': 0.4195680578838963, 'support': 351081}, 'accuracy': 0.3551272202518559, 'macro avg': {'precision': 0.356962166970706, 'recall': 0.3598232195971785, 'f1-score': 0.3479604618879189, 'support': 1114288}, 'weighted avg': {'precision': 0.3572087808886974, 'recall': 0.3551272202518559, 'f1-score': 0.3459694727131496, 'support': 1114288}}
[[113533 100043 167223]
 [103678  96099 182631]
 [ 84691  80308 186082]]
Evaluating performance on  train set...
1542/1542 - 33s - 33s/epoch - 22ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0915852
{'0': {'precision': 0.36680269945586885, 'recall': 0.31075074086269344, 'f1-score': 0.3364582151712068, 'support': 133628}, '1': {'precision': 0.34754170416727714, 'recall': 0.25214301441836806, 'f1-score': 0.2922542803208646, 'support': 131707}, '2': {'precision': 0.3659775781615815, 'recall': 0.5261940136812455, 'f1-score': 0.43169993873579887, 'support': 129228}, 'accuracy': 0.36174958118221934, 'macro avg': {'precision': 0.3601073272615758, 'recall': 0.36302925632076904, 'f1-score': 0.3534708114092901, 'support': 394563}, 'weighted avg': {'precision': 0.3601030426682514, 'recall': 0.36174958118221934, 'f1-score': 0.3528964767554686, 'support': 394563}}
[[41525 33555 58548]
 [39244 33209 59254]
 [32439 28790 67999]]
Evaluating performance on  val set...
482/482 - 11s - 11s/epoch - 22ms/step
Prediction horizon: 200  orderbook updates
Categorical crossentropy: 1.0945891
{'0': {'precision': 0.35183357573239143, 'recall': 0.32928222454485795, 'f1-score': 0.3401845690250487, 'support': 41141}, '1': {'precision': 0.3458301453710788, 'recall': 0.25314729588233864, 'f1-score': 0.2923180744573164, 'support': 41067}, '2': {'precision': 0.36584162937254544, 'recall': 0.48727555836698944, 'f1-score': 0.4179160537106012, 'support': 41102}, 'accuracy': 0.35658908442137704, 'macro avg': {'precision': 0.35450178349200523, 'recall': 0.356568359598062, 'f1-score': 0.35013956573098876, 'support': 123310}, 'weighted avg': {'precision': 0.3545034009377242, 'recall': 0.35658908442137704, 'f1-score': 0.3501528291104636, 'support': 123310}}
[[13547 10434 17160]
 [13114 10396 17557]
 [11843  9231 20028]]
training model: results/WBA/W2/deepVOL_L3/h300
Epoch 1/50
1542/1542 - 65s - loss: 3.2839 - accuracy300: 0.3721 - val_loss: 3.2948 - val_accuracy300: 0.3492 - 65s/epoch - 42ms/step
Epoch 2/50
1542/1542 - 66s - loss: 3.2834 - accuracy300: 0.3679 - val_loss: 3.3037 - val_accuracy300: 0.3540 - 66s/epoch - 43ms/step
Epoch 3/50
1542/1542 - 66s - loss: 3.2875 - accuracy300: 0.3654 - val_loss: 3.2992 - val_accuracy300: 0.3526 - 66s/epoch - 43ms/step
Epoch 4/50
1542/1542 - 63s - loss: 3.2833 - accuracy300: 0.3666 - val_loss: 3.2942 - val_accuracy300: 0.3575 - 63s/epoch - 41ms/step
Epoch 5/50
1542/1542 - 63s - loss: 3.2803 - accuracy300: 0.3712 - val_loss: 3.3025 - val_accuracy300: 0.3531 - 63s/epoch - 41ms/step
Epoch 6/50
1542/1542 - 63s - loss: 3.2726 - accuracy300: 0.3763 - val_loss: 3.2934 - val_accuracy300: 0.3624 - 63s/epoch - 41ms/step
Epoch 7/50
1542/1542 - 63s - loss: 3.2686 - accuracy300: 0.3801 - val_loss: 3.2906 - val_accuracy300: 0.3640 - 63s/epoch - 41ms/step
Epoch 8/50
1542/1542 - 64s - loss: 3.2612 - accuracy300: 0.3868 - val_loss: 3.2903 - val_accuracy300: 0.3658 - 64s/epoch - 41ms/step
Epoch 9/50
1542/1542 - 64s - loss: 3.2544 - accuracy300: 0.3897 - val_loss: 3.2912 - val_accuracy300: 0.3663 - 64s/epoch - 41ms/step
Epoch 10/50
1542/1542 - 62s - loss: 3.2508 - accuracy300: 0.3933 - val_loss: 3.3033 - val_accuracy300: 0.3630 - 62s/epoch - 40ms/step
Epoch 11/50
1542/1542 - 63s - loss: 3.2471 - accuracy300: 0.3951 - val_loss: 3.2935 - val_accuracy300: 0.3658 - 63s/epoch - 41ms/step
Epoch 12/50
1542/1542 - 63s - loss: 3.2363 - accuracy300: 0.4010 - val_loss: 3.3082 - val_accuracy300: 0.3623 - 63s/epoch - 41ms/step
Epoch 13/50
1542/1542 - 61s - loss: 3.2306 - accuracy300: 0.4039 - val_loss: 3.3144 - val_accuracy300: 0.3635 - 61s/epoch - 39ms/step
Epoch 14/50
1542/1542 - 61s - loss: 3.2274 - accuracy300: 0.4054 - val_loss: 3.3368 - val_accuracy300: 0.3539 - 61s/epoch - 40ms/step
Epoch 15/50
1542/1542 - 62s - loss: 3.2189 - accuracy300: 0.4090 - val_loss: 3.3358 - val_accuracy300: 0.3587 - 62s/epoch - 40ms/step
Epoch 16/50
1542/1542 - 63s - loss: 3.2087 - accuracy300: 0.4154 - val_loss: 3.3410 - val_accuracy300: 0.3567 - 63s/epoch - 41ms/step
Epoch 17/50
1542/1542 - 63s - loss: 3.2013 - accuracy300: 0.4197 - val_loss: 3.3495 - val_accuracy300: 0.3558 - 63s/epoch - 41ms/step
Epoch 18/50
1542/1542 - 63s - loss: 3.1942 - accuracy300: 0.4243 - val_loss: 3.3480 - val_accuracy300: 0.3599 - 63s/epoch - 41ms/step
testing model: results/WBA/W2/deepVOL_L3/h300
Evaluating performance on  test set...
4353/4353 - 83s - 83s/epoch - 19ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0981487
{'0': {'precision': 0.402216580380728, 'recall': 0.30808244705697246, 'f1-score': 0.3489118344356755, 'support': 406758}, '1': {'precision': 0.30218945652576595, 'recall': 0.04718642891231724, 'f1-score': 0.08162693478701394, 'support': 345735}, '2': {'precision': 0.3431253263812186, 'recall': 0.7101037880567724, 'f1-score': 0.4626810837289381, 'support': 361795}, 'accuracy': 0.3576642663297101, 'macro avg': {'precision': 0.3491771210959042, 'recall': 0.3551242213420207, 'f1-score': 0.29773995098387585, 'support': 1114288}, 'weighted avg': {'precision': 0.3519945570736944, 'recall': 0.3576642663297101, 'f1-score': 0.30291959613464914, 'support': 1114288}}
[[125315  21460 259983]
 [ 97575  16314 231846]
 [ 88671  16212 256912]]
Evaluating performance on  train set...
1542/1542 - 30s - 30s/epoch - 19ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0952861
{'0': {'precision': 0.37288618499337994, 'recall': 0.32949766009122683, 'f1-score': 0.3498517976900882, 'support': 135048}, '1': {'precision': 0.3717086976297569, 'recall': 0.05632433011954083, 'f1-score': 0.09782536410188203, 'support': 130583}, '2': {'precision': 0.3518450372295864, 'recall': 0.6970806316507927, 'f1-score': 0.46764869632181155, 'support': 128932}, 'accuracy': 0.35920499387930444, 'macro avg': {'precision': 0.36547997328424103, 'recall': 0.3609675406205201, 'f1-score': 0.3051086193712606, 'support': 394563}, 'weighted avg': {'precision': 0.3656208380249987, 'recall': 0.35920499387930444, 'f1-score': 0.304934818543885, 'support': 394563}}
[[44498  6979 83571]
 [41233  7355 81995]
 [33603  5453 89876]]
Evaluating performance on  val set...
482/482 - 9s - 9s/epoch - 18ms/step
Prediction horizon: 300  orderbook updates
Categorical crossentropy: 1.0969718
{'0': {'precision': 0.3732730044278836, 'recall': 0.35673488264539255, 'f1-score': 0.36481661030576773, 'support': 43245}, '1': {'precision': 0.3157796451914099, 'recall': 0.045367960722238615, 'f1-score': 0.07933752463169748, 'support': 37273}, '2': {'precision': 0.365306814919218, 'recall': 0.6541409609272761, 'f1-score': 0.4688070475137751, 'support': 42792}, 'accuracy': 0.365825967074852, 'macro avg': {'precision': 0.3514531548461705, 'recall': 0.3520812680983025, 'f1-score': 0.3043203941504134, 'support': 123310}, 'weighted avg': {'precision': 0.35312995714643114, 'recall': 0.365825967074852, 'f1-score': 0.3146122215998674, 'support': 123310}}
[[15427  1904 25914]
 [12862  1691 22720]
 [13040  1760 27992]]
training model: results/WBA/W2/deepVOL_L3/h500
Epoch 1/50
1542/1542 - 66s - loss: 3.2525 - accuracy500: 0.4024 - val_loss: 3.2974 - val_accuracy500: 0.3330 - 66s/epoch - 43ms/step
Epoch 2/50
1542/1542 - 62s - loss: 3.2548 - accuracy500: 0.3938 - val_loss: 3.2949 - val_accuracy500: 0.3593 - 62s/epoch - 40ms/step
Epoch 3/50
1542/1542 - 67s - loss: 3.2482 - accuracy500: 0.3983 - val_loss: 3.2939 - val_accuracy500: 0.3476 - 67s/epoch - 43ms/step
Epoch 4/50
1542/1542 - 67s - loss: 3.2627 - accuracy500: 0.3898 - val_loss: 3.3045 - val_accuracy500: 0.3587 - 67s/epoch - 44ms/step
Epoch 5/50
1542/1542 - 68s - loss: 3.2710 - accuracy500: 0.3830 - val_loss: 3.3003 - val_accuracy500: 0.3550 - 68s/epoch - 44ms/step
Epoch 6/50
1542/1542 - 67s - loss: 3.2668 - accuracy500: 0.3840 - val_loss: 3.2954 - val_accuracy500: 0.3558 - 67s/epoch - 44ms/step
Epoch 7/50
1542/1542 - 67s - loss: 3.2574 - accuracy500: 0.3962 - val_loss: 3.3143 - val_accuracy500: 0.3419 - 67s/epoch - 44ms/step
Epoch 8/50
1542/1542 - 68s - loss: 3.2589 - accuracy500: 0.3939 - val_loss: 3.2967 - val_accuracy500: 0.3621 - 68s/epoch - 44ms/step
Epoch 9/50
1542/1542 - 68s - loss: 3.2536 - accuracy500: 0.3963 - val_loss: 3.2996 - val_accuracy500: 0.3577 - 68s/epoch - 44ms/step
Epoch 10/50
1542/1542 - 67s - loss: 3.2453 - accuracy500: 0.3993 - val_loss: 3.3027 - val_accuracy500: 0.3582 - 67s/epoch - 44ms/step
Epoch 11/50
1542/1542 - 65s - loss: 3.2406 - accuracy500: 0.4035 - val_loss: 3.2982 - val_accuracy500: 0.3550 - 65s/epoch - 42ms/step
Epoch 12/50
1542/1542 - 66s - loss: 3.2361 - accuracy500: 0.4080 - val_loss: 3.3036 - val_accuracy500: 0.3592 - 66s/epoch - 43ms/step
Epoch 13/50
1542/1542 - 67s - loss: 3.2264 - accuracy500: 0.4143 - val_loss: 3.2929 - val_accuracy500: 0.3581 - 67s/epoch - 44ms/step
Epoch 14/50
1542/1542 - 62s - loss: 3.2211 - accuracy500: 0.4173 - val_loss: 3.3074 - val_accuracy500: 0.3593 - 62s/epoch - 40ms/step
Epoch 15/50
1542/1542 - 61s - loss: 3.2140 - accuracy500: 0.4198 - val_loss: 3.3217 - val_accuracy500: 0.3544 - 61s/epoch - 40ms/step
Epoch 16/50
1542/1542 - 61s - loss: 3.2082 - accuracy500: 0.4230 - val_loss: 3.3274 - val_accuracy500: 0.3545 - 61s/epoch - 40ms/step
Epoch 17/50
1542/1542 - 62s - loss: 3.1988 - accuracy500: 0.4286 - val_loss: 3.3356 - val_accuracy500: 0.3571 - 62s/epoch - 40ms/step
Epoch 18/50
1542/1542 - 62s - loss: 3.1927 - accuracy500: 0.4299 - val_loss: 3.3317 - val_accuracy500: 0.3617 - 62s/epoch - 40ms/step
Epoch 19/50
1542/1542 - 62s - loss: 3.1816 - accuracy500: 0.4382 - val_loss: 3.3194 - val_accuracy500: 0.3617 - 62s/epoch - 40ms/step
Epoch 20/50
1542/1542 - 63s - loss: 3.1731 - accuracy500: 0.4417 - val_loss: 3.3210 - val_accuracy500: 0.3651 - 63s/epoch - 41ms/step
Epoch 21/50
1542/1542 - 62s - loss: 3.1665 - accuracy500: 0.4455 - val_loss: 3.3312 - val_accuracy500: 0.3616 - 62s/epoch - 40ms/step
Epoch 22/50
1542/1542 - 61s - loss: 3.1567 - accuracy500: 0.4485 - val_loss: 3.3466 - val_accuracy500: 0.3617 - 61s/epoch - 40ms/step
Epoch 23/50
1542/1542 - 62s - loss: 3.1531 - accuracy500: 0.4495 - val_loss: 3.3425 - val_accuracy500: 0.3632 - 62s/epoch - 40ms/step
testing model: results/WBA/W2/deepVOL_L3/h500
Evaluating performance on  test set...
4353/4353 - 81s - 81s/epoch - 19ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.098413
{'0': {'precision': 0.39695271135047366, 'recall': 0.40037989296772925, 'f1-score': 0.39865893661693363, 'support': 446968}, '1': {'precision': 0.23610748192666145, 'recall': 0.03839643621014462, 'f1-score': 0.06605141325536062, 'support': 282396}, '2': {'precision': 0.343838506842505, 'recall': 0.551623177562324, 'f1-score': 0.4236234626583977, 'support': 384924}, 'accuracy': 0.36088784946082164, 'macro avg': {'precision': 0.32563290003988005, 'recall': 0.3301331689133993, 'f1-score': 0.296111270843564, 'support': 1114288}, 'weighted avg': {'precision': 0.33784143898247526, 'recall': 0.36088784946082164, 'f1-score': 0.3229894607316775, 'support': 1114288}}
[[178957  18679 249332]
 [115681  10843 155872]
 [156189  16402 212333]]
Evaluating performance on  train set...
1542/1542 - 29s - 29s/epoch - 19ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0976615
{'0': {'precision': 0.3760334903192046, 'recall': 0.43114072547344945, 'f1-score': 0.4017059728780564, 'support': 141673}, '1': {'precision': 0.3653329869230103, 'recall': 0.07008581088377734, 'f1-score': 0.11760933960620318, 'support': 120381}, '2': {'precision': 0.3490484801515543, 'recall': 0.5506267498811401, 'f1-score': 0.4272551333214266, 'support': 132509}, 'accuracy': 0.3611108999069857, 'macro avg': {'precision': 0.36347165246458973, 'recall': 0.35061776207945566, 'f1-score': 0.3155234819352287, 'support': 394563}, 'weighted avg': {'precision': 0.36370619654953423, 'recall': 0.3611108999069857, 'f1-score': 0.3236085762425168, 'support': 394563}}
[[61081  7257 73335]
 [49208  8437 62736]
 [52146  7400 72963]]
Evaluating performance on  val set...
482/482 - 10s - 10s/epoch - 21ms/step
Prediction horizon: 500  orderbook updates
Categorical crossentropy: 1.0976943
{'0': {'precision': 0.36944838331320135, 'recall': 0.4703679764637707, 'f1-score': 0.41384449455829, 'support': 44867}, '1': {'precision': 0.312008123889312, 'recall': 0.07230687768429724, 'f1-score': 0.11740542606037449, 'support': 33994}, '2': {'precision': 0.35394193006225455, 'recall': 0.46430740849062974, 'f1-score': 0.4016816208956967, 'support': 44449}, 'accuracy': 0.3584461925229097, 'macro avg': {'precision': 0.34513281242158933, 'recall': 0.33566075421289926, 'f1-score': 0.31097718050478707, 'support': 123310}, 'weighted avg': {'precision': 0.3480237582267766, 'recall': 0.3584461925229097, 'f1-score': 0.3277381182226583, 'support': 123310}}
[[21104  2680 21083]
 [14948  2458 16588]
 [21071  2740 20638]]
training model: results/WBA/W2/deepVOL_L3/h1000
Epoch 1/50
1542/1542 - 65s - loss: 3.2913 - accuracy1000: 0.3738 - val_loss: 3.4303 - val_accuracy1000: 0.3247 - 65s/epoch - 42ms/step
Epoch 2/50
1542/1542 - 61s - loss: 3.2903 - accuracy1000: 0.3636 - val_loss: 3.3397 - val_accuracy1000: 0.3427 - 61s/epoch - 40ms/step
Epoch 3/50
1542/1542 - 62s - loss: 3.2826 - accuracy1000: 0.3712 - val_loss: 3.3646 - val_accuracy1000: 0.3419 - 62s/epoch - 40ms/step
Epoch 4/50
1542/1542 - 62s - loss: 3.2757 - accuracy1000: 0.3797 - val_loss: 3.4223 - val_accuracy1000: 0.3396 - 62s/epoch - 40ms/step
Epoch 5/50
1542/1542 - 61s - loss: 3.2723 - accuracy1000: 0.3830 - val_loss: 3.4535 - val_accuracy1000: 0.3339 - 61s/epoch - 40ms/step
Epoch 6/50
1542/1542 - 62s - loss: 3.2657 - accuracy1000: 0.3891 - val_loss: 3.3606 - val_accuracy1000: 0.3464 - 62s/epoch - 40ms/step
Epoch 7/50
1542/1542 - 63s - loss: 3.2568 - accuracy1000: 0.3943 - val_loss: 3.5244 - val_accuracy1000: 0.3242 - 63s/epoch - 41ms/step
Epoch 8/50
1542/1542 - 62s - loss: 3.2511 - accuracy1000: 0.3990 - val_loss: 3.3909 - val_accuracy1000: 0.3326 - 62s/epoch - 41ms/step
Epoch 9/50
1542/1542 - 62s - loss: 3.2454 - accuracy1000: 0.4010 - val_loss: 3.4590 - val_accuracy1000: 0.3335 - 62s/epoch - 41ms/step
Epoch 10/50
1542/1542 - 62s - loss: 3.2409 - accuracy1000: 0.4052 - val_loss: 3.3961 - val_accuracy1000: 0.3350 - 62s/epoch - 40ms/step
Epoch 11/50
1542/1542 - 63s - loss: 3.2337 - accuracy1000: 0.4093 - val_loss: 3.4066 - val_accuracy1000: 0.3298 - 63s/epoch - 41ms/step
Epoch 12/50
1542/1542 - 60s - loss: 3.2238 - accuracy1000: 0.4155 - val_loss: 3.4170 - val_accuracy1000: 0.3277 - 60s/epoch - 39ms/step
testing model: results/WBA/W2/deepVOL_L3/h1000
Evaluating performance on  test set...
4353/4353 - 80s - 80s/epoch - 18ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.113556
{'0': {'precision': 0.3762774041400996, 'recall': 0.010953944106406837, 'f1-score': 0.021288161054722633, 'support': 393283}, '1': {'precision': 0.36155958370137103, 'recall': 0.4874445359138048, 'f1-score': 0.4151693482061945, 'support': 386286}, '2': {'precision': 0.30968510065130855, 'recall': 0.5385263459797621, 'f1-score': 0.3932358760790508, 'support': 334719}, 'accuracy': 0.33461367258733826, 'macro avg': {'precision': 0.3491740294975931, 'recall': 0.3456416086666579, 'f1-score': 0.27656446177998933, 'support': 1114288}, 'weighted avg': {'precision': 0.3511716889053853, 'recall': 0.33461367258733826, 'f1-score': 0.2695621759280961, 'support': 1114288}}
[[  4308 181670 207305]
 [  3494 188293 194499]
 [  3647 150817 180255]]
Evaluating performance on  train set...
1542/1542 - 28s - 28s/epoch - 18ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1092705
{'0': {'precision': 0.37541686517389233, 'recall': 0.01151432349696434, 'f1-score': 0.022343359017799547, 'support': 136873}, '1': {'precision': 0.3559933407325194, 'recall': 0.4609181520775369, 'f1-score': 0.40171743011698247, 'support': 130828}, '2': {'precision': 0.3396281060924893, 'recall': 0.591587709479592, 'f1-score': 0.4315214797650638, 'support': 126862}, 'accuracy': 0.3470345673567973, 'macro avg': {'precision': 0.3570127706663004, 'recall': 0.35467339501803113, 'f1-score': 0.2851940896332819, 'support': 394563}, 'weighted avg': {'precision': 0.3574694793059805, 'recall': 0.3470345673567973, 'f1-score': 0.27969619171626176, 'support': 394563}}
[[ 1576 58505 76792]
 [ 1392 60301 69135]
 [ 1230 50582 75050]]
Evaluating performance on  val set...
482/482 - 9s - 9s/epoch - 18ms/step
Prediction horizon: 1000  orderbook updates
Categorical crossentropy: 1.1135259
{'0': {'precision': 0.33154793786823783, 'recall': 0.014835230677052128, 'f1-score': 0.028399706368140945, 'support': 41725}, '1': {'precision': 0.34141676122548226, 'recall': 0.5302885341658694, 'f1-score': 0.4153912906279584, 'support': 39718}, '2': {'precision': 0.34923769517848474, 'recall': 0.4984355220101751, 'f1-score': 0.41070655382798665, 'support': 41867}, 'accuracy': 0.34505717297867167, 'macro avg': {'precision': 0.34073413142406833, 'recall': 0.3478530956176989, 'f1-score': 0.28483251694136197, 'support': 123310}, 'weighted avg': {'precision': 0.3407328133480135, 'recall': 0.34505717297867167, 'f1-score': 0.28285248818821057, 'support': 123310}}
[[  619 20209 20897]
 [  668 21062 17988]
 [  580 20419 20868]]

============================================

        Job resource usage summary 

                 Memory (GB)    NCPUs
 Requested  :        96            32
 Used       :        24 (peak)  15.46 (ave)

============================================
