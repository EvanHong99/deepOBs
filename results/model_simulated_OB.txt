##################### deepLOB #####################
[[ 7.42437777e-02 -1.24483992e-01  7.47185590e-02 ... -7.57766119e-02
   9.44742729e-02 -6.14102911e-02]
 [ 7.15664497e-02 -5.71592329e-01  7.20410209e-02 ... -2.84740301e-02
   9.88874472e-02 -6.14102911e-02]
 [ 6.62117937e-02  1.04070743e+00  6.40084066e-02 ... -2.84740301e-02
   8.12347499e-02  2.28482059e-04]
 ...
 [ 8.22757616e-02  3.22624346e-01  8.27511732e-02 ... -7.57766119e-02
   1.05507209e-01  2.28482059e-04]
 [ 8.49530895e-02 -6.86756598e-01  8.00736351e-02 ... -1.23079194e-01
   1.05507209e-01  6.18672552e-02]
 [ 7.95984336e-02 -2.39648260e-01  8.00736351e-02 ... -1.23079194e-01
   9.88874472e-02 -6.14102911e-02]]
[0. 1. 0.]
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 100, 40, 1)  0           []                               
                                ]                                                                 
                                                                                                  
 conv2d (Conv2D)                (None, 100, 20, 32)  96          ['input_1[0][0]']                
                                                                                                  
 leaky_re_lu (LeakyReLU)        (None, 100, 20, 32)  0           ['conv2d[0][0]']                 
                                                                                                  
 conv2d_1 (Conv2D)              (None, 100, 20, 32)  4128        ['leaky_re_lu[0][0]']            
                                                                                                  
 leaky_re_lu_1 (LeakyReLU)      (None, 100, 20, 32)  0           ['conv2d_1[0][0]']               
                                                                                                  
 conv2d_2 (Conv2D)              (None, 100, 20, 32)  4128        ['leaky_re_lu_1[0][0]']          
                                                                                                  
 leaky_re_lu_2 (LeakyReLU)      (None, 100, 20, 32)  0           ['conv2d_2[0][0]']               
                                                                                                  
 conv2d_3 (Conv2D)              (None, 100, 10, 32)  2080        ['leaky_re_lu_2[0][0]']          
                                                                                                  
 leaky_re_lu_3 (LeakyReLU)      (None, 100, 10, 32)  0           ['conv2d_3[0][0]']               
                                                                                                  
 conv2d_4 (Conv2D)              (None, 100, 10, 32)  4128        ['leaky_re_lu_3[0][0]']          
                                                                                                  
 leaky_re_lu_4 (LeakyReLU)      (None, 100, 10, 32)  0           ['conv2d_4[0][0]']               
                                                                                                  
 conv2d_5 (Conv2D)              (None, 100, 10, 32)  4128        ['leaky_re_lu_4[0][0]']          
                                                                                                  
 leaky_re_lu_5 (LeakyReLU)      (None, 100, 10, 32)  0           ['conv2d_5[0][0]']               
                                                                                                  
 conv2d_6 (Conv2D)              (None, 100, 1, 32)   10272       ['leaky_re_lu_5[0][0]']          
                                                                                                  
 leaky_re_lu_6 (LeakyReLU)      (None, 100, 1, 32)   0           ['conv2d_6[0][0]']               
                                                                                                  
 conv2d_7 (Conv2D)              (None, 100, 1, 32)   4128        ['leaky_re_lu_6[0][0]']          
                                                                                                  
 leaky_re_lu_7 (LeakyReLU)      (None, 100, 1, 32)   0           ['conv2d_7[0][0]']               
                                                                                                  
 conv2d_8 (Conv2D)              (None, 100, 1, 32)   4128        ['leaky_re_lu_7[0][0]']          
                                                                                                  
 leaky_re_lu_8 (LeakyReLU)      (None, 100, 1, 32)   0           ['conv2d_8[0][0]']               
                                                                                                  
 conv2d_9 (Conv2D)              (None, 100, 1, 64)   2112        ['leaky_re_lu_8[0][0]']          
                                                                                                  
 conv2d_11 (Conv2D)             (None, 100, 1, 64)   2112        ['leaky_re_lu_8[0][0]']          
                                                                                                  
 leaky_re_lu_9 (LeakyReLU)      (None, 100, 1, 64)   0           ['conv2d_9[0][0]']               
                                                                                                  
 leaky_re_lu_11 (LeakyReLU)     (None, 100, 1, 64)   0           ['conv2d_11[0][0]']              
                                                                                                  
 max_pooling2d (MaxPooling2D)   (None, 100, 1, 32)   0           ['leaky_re_lu_8[0][0]']          
                                                                                                  
 conv2d_10 (Conv2D)             (None, 100, 1, 64)   12352       ['leaky_re_lu_9[0][0]']          
                                                                                                  
 conv2d_12 (Conv2D)             (None, 100, 1, 64)   20544       ['leaky_re_lu_11[0][0]']         
                                                                                                  
 conv2d_13 (Conv2D)             (None, 100, 1, 64)   2112        ['max_pooling2d[0][0]']          
                                                                                                  
 leaky_re_lu_10 (LeakyReLU)     (None, 100, 1, 64)   0           ['conv2d_10[0][0]']              
                                                                                                  
 leaky_re_lu_12 (LeakyReLU)     (None, 100, 1, 64)   0           ['conv2d_12[0][0]']              
                                                                                                  
 leaky_re_lu_13 (LeakyReLU)     (None, 100, 1, 64)   0           ['conv2d_13[0][0]']              
                                                                                                  
 concatenate (Concatenate)      (None, 100, 1, 192)  0           ['leaky_re_lu_10[0][0]',         
                                                                  'leaky_re_lu_12[0][0]',         
                                                                  'leaky_re_lu_13[0][0]']         
                                                                                                  
 reshape (Reshape)              (None, 100, 192)     0           ['concatenate[0][0]']            
                                                                                                  
 dropout (Dropout)              (None, 100, 192)     0           ['reshape[0][0]']                
                                                                                                  
 lstm (LSTM)                    (None, 64)           65792       ['dropout[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 3)            195         ['lstm[0][0]']                   
                                                                                                  
==================================================================================================
Total params: 142,435
Trainable params: 142,435
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/50
28107/28107 - 755s - loss: 1.0965 - accuracy10: 0.3512 - val_loss: 1.0910 - val_accuracy10: 0.3752 - 755s/epoch - 27ms/step
Epoch 2/50
28107/28107 - 748s - loss: 1.0873 - accuracy10: 0.3887 - val_loss: 1.0821 - val_accuracy10: 0.4014 - 748s/epoch - 27ms/step
Epoch 3/50
28107/28107 - 744s - loss: 1.0821 - accuracy10: 0.4009 - val_loss: 1.0801 - val_accuracy10: 0.4038 - 744s/epoch - 26ms/step
Epoch 4/50
28107/28107 - 745s - loss: 1.0801 - accuracy10: 0.4041 - val_loss: 1.0794 - val_accuracy10: 0.4049 - 745s/epoch - 26ms/step
Epoch 5/50
28107/28107 - 744s - loss: 1.0790 - accuracy10: 0.4062 - val_loss: 1.0797 - val_accuracy10: 0.4061 - 744s/epoch - 26ms/step
Epoch 6/50
28107/28107 - 745s - loss: 1.0784 - accuracy10: 0.4075 - val_loss: 1.0776 - val_accuracy10: 0.4087 - 745s/epoch - 26ms/step
Epoch 7/50
28107/28107 - 744s - loss: 1.0778 - accuracy10: 0.4080 - val_loss: 1.0772 - val_accuracy10: 0.4086 - 744s/epoch - 26ms/step
Epoch 8/50
28107/28107 - 748s - loss: 1.0775 - accuracy10: 0.4084 - val_loss: 1.0770 - val_accuracy10: 0.4088 - 748s/epoch - 27ms/step
Epoch 9/50
28107/28107 - 746s - loss: 1.0771 - accuracy10: 0.4092 - val_loss: 1.0780 - val_accuracy10: 0.4085 - 746s/epoch - 27ms/step
Epoch 10/50
28107/28107 - 749s - loss: 1.0769 - accuracy10: 0.4094 - val_loss: 1.0778 - val_accuracy10: 0.4067 - 749s/epoch - 27ms/step
Epoch 11/50
28107/28107 - 750s - loss: 1.0767 - accuracy10: 0.4094 - val_loss: 1.0816 - val_accuracy10: 0.4024 - 750s/epoch - 27ms/step
Epoch 12/50
28107/28107 - 745s - loss: 1.0766 - accuracy10: 0.4095 - val_loss: 1.0761 - val_accuracy10: 0.4098 - 745s/epoch - 27ms/step
Epoch 13/50
28107/28107 - 748s - loss: 1.0764 - accuracy10: 0.4103 - val_loss: 1.0779 - val_accuracy10: 0.4078 - 748s/epoch - 27ms/step
Epoch 14/50
28107/28107 - 748s - loss: 1.0763 - accuracy10: 0.4104 - val_loss: 1.0767 - val_accuracy10: 0.4086 - 748s/epoch - 27ms/step
Epoch 15/50
28107/28107 - 764s - loss: 1.0761 - accuracy10: 0.4104 - val_loss: 1.0768 - val_accuracy10: 0.4081 - 764s/epoch - 27ms/step
Epoch 16/50
28107/28107 - 763s - loss: 1.0759 - accuracy10: 0.4107 - val_loss: 1.0775 - val_accuracy10: 0.4069 - 763s/epoch - 27ms/step
Epoch 17/50
28107/28107 - 761s - loss: 1.0758 - accuracy10: 0.4111 - val_loss: 1.0788 - val_accuracy10: 0.4072 - 761s/epoch - 27ms/step
(149901, 3)
(149901, 3)
Prediction horizon: 10  orderbook updates
accuracy_score: 0.41123808380197596
              precision    recall  f1-score   support

           0     0.3986    0.4212    0.4096     49807
           1     0.3879    0.3364    0.3603     49172
           2     0.4416    0.4738    0.4571     50922

    accuracy                         0.4112    149901
   macro avg     0.4094    0.4105    0.4090    149901
weighted avg     0.4097    0.4112    0.4096    149901

[[ 7.42437777e-02 -1.24483992e-01  7.47185590e-02 ... -7.57766119e-02
   9.44742729e-02 -6.14102911e-02]
 [ 7.15664497e-02 -5.71592329e-01  7.20410209e-02 ... -2.84740301e-02
   9.88874472e-02 -6.14102911e-02]
 [ 6.62117937e-02  1.04070743e+00  6.40084066e-02 ... -2.84740301e-02
   8.12347499e-02  2.28482059e-04]
 ...
 [ 8.22757616e-02  3.22624346e-01  8.27511732e-02 ... -7.57766119e-02
   1.05507209e-01  2.28482059e-04]
 [ 8.49530895e-02 -6.86756598e-01  8.00736351e-02 ... -1.23079194e-01
   1.05507209e-01  6.18672552e-02]
 [ 7.95984336e-02 -2.39648260e-01  8.00736351e-02 ... -1.23079194e-01
   9.88874472e-02 -6.14102911e-02]]
[1. 0. 0.]
Model: "model_1"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_2 (InputLayer)           [(None, 100, 40, 1)  0           []                               
                                ]                                                                 
                                                                                                  
 conv2d_14 (Conv2D)             (None, 100, 20, 32)  96          ['input_2[0][0]']                
                                                                                                  
 leaky_re_lu_14 (LeakyReLU)     (None, 100, 20, 32)  0           ['conv2d_14[0][0]']              
                                                                                                  
 conv2d_15 (Conv2D)             (None, 100, 20, 32)  4128        ['leaky_re_lu_14[0][0]']         
                                                                                                  
 leaky_re_lu_15 (LeakyReLU)     (None, 100, 20, 32)  0           ['conv2d_15[0][0]']              
                                                                                                  
 conv2d_16 (Conv2D)             (None, 100, 20, 32)  4128        ['leaky_re_lu_15[0][0]']         
                                                                                                  
 leaky_re_lu_16 (LeakyReLU)     (None, 100, 20, 32)  0           ['conv2d_16[0][0]']              
                                                                                                  
 conv2d_17 (Conv2D)             (None, 100, 10, 32)  2080        ['leaky_re_lu_16[0][0]']         
                                                                                                  
 leaky_re_lu_17 (LeakyReLU)     (None, 100, 10, 32)  0           ['conv2d_17[0][0]']              
                                                                                                  
 conv2d_18 (Conv2D)             (None, 100, 10, 32)  4128        ['leaky_re_lu_17[0][0]']         
                                                                                                  
 leaky_re_lu_18 (LeakyReLU)     (None, 100, 10, 32)  0           ['conv2d_18[0][0]']              
                                                                                                  
 conv2d_19 (Conv2D)             (None, 100, 10, 32)  4128        ['leaky_re_lu_18[0][0]']         
                                                                                                  
 leaky_re_lu_19 (LeakyReLU)     (None, 100, 10, 32)  0           ['conv2d_19[0][0]']              
                                                                                                  
 conv2d_20 (Conv2D)             (None, 100, 1, 32)   10272       ['leaky_re_lu_19[0][0]']         
                                                                                                  
 leaky_re_lu_20 (LeakyReLU)     (None, 100, 1, 32)   0           ['conv2d_20[0][0]']              
                                                                                                  
 conv2d_21 (Conv2D)             (None, 100, 1, 32)   4128        ['leaky_re_lu_20[0][0]']         
                                                                                                  
 leaky_re_lu_21 (LeakyReLU)     (None, 100, 1, 32)   0           ['conv2d_21[0][0]']              
                                                                                                  
 conv2d_22 (Conv2D)             (None, 100, 1, 32)   4128        ['leaky_re_lu_21[0][0]']         
                                                                                                  
 leaky_re_lu_22 (LeakyReLU)     (None, 100, 1, 32)   0           ['conv2d_22[0][0]']              
                                                                                                  
 conv2d_23 (Conv2D)             (None, 100, 1, 64)   2112        ['leaky_re_lu_22[0][0]']         
                                                                                                  
 conv2d_25 (Conv2D)             (None, 100, 1, 64)   2112        ['leaky_re_lu_22[0][0]']         
                                                                                                  
 leaky_re_lu_23 (LeakyReLU)     (None, 100, 1, 64)   0           ['conv2d_23[0][0]']              
                                                                                                  
 leaky_re_lu_25 (LeakyReLU)     (None, 100, 1, 64)   0           ['conv2d_25[0][0]']              
                                                                                                  
 max_pooling2d_1 (MaxPooling2D)  (None, 100, 1, 32)  0           ['leaky_re_lu_22[0][0]']         
                                                                                                  
 conv2d_24 (Conv2D)             (None, 100, 1, 64)   12352       ['leaky_re_lu_23[0][0]']         
                                                                                                  
 conv2d_26 (Conv2D)             (None, 100, 1, 64)   20544       ['leaky_re_lu_25[0][0]']         
                                                                                                  
 conv2d_27 (Conv2D)             (None, 100, 1, 64)   2112        ['max_pooling2d_1[0][0]']        
                                                                                                  
 leaky_re_lu_24 (LeakyReLU)     (None, 100, 1, 64)   0           ['conv2d_24[0][0]']              
                                                                                                  
 leaky_re_lu_26 (LeakyReLU)     (None, 100, 1, 64)   0           ['conv2d_26[0][0]']              
                                                                                                  
 leaky_re_lu_27 (LeakyReLU)     (None, 100, 1, 64)   0           ['conv2d_27[0][0]']              
                                                                                                  
 concatenate_1 (Concatenate)    (None, 100, 1, 192)  0           ['leaky_re_lu_24[0][0]',         
                                                                  'leaky_re_lu_26[0][0]',         
                                                                  'leaky_re_lu_27[0][0]']         
                                                                                                  
 reshape_1 (Reshape)            (None, 100, 192)     0           ['concatenate_1[0][0]']          
                                                                                                  
 dropout_1 (Dropout)            (None, 100, 192)     0           ['reshape_1[0][0]']              
                                                                                                  
 lstm_1 (LSTM)                  (None, 64)           65792       ['dropout_1[0][0]']              
                                                                                                  
 dense_1 (Dense)                (None, 3)            195         ['lstm_1[0][0]']                 
                                                                                                  
==================================================================================================
Total params: 142,435
Trainable params: 142,435
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/50
28107/28107 - 761s - loss: 1.0989 - accuracy20: 0.3403 - val_loss: 1.0974 - val_accuracy20: 0.3521 - 761s/epoch - 27ms/step
Epoch 2/50
28107/28107 - 752s - loss: 1.0966 - accuracy20: 0.3533 - val_loss: 1.0935 - val_accuracy20: 0.3653 - 752s/epoch - 27ms/step
Epoch 3/50
28107/28107 - 752s - loss: 1.0939 - accuracy20: 0.3665 - val_loss: 1.0904 - val_accuracy20: 0.3783 - 752s/epoch - 27ms/step
Epoch 4/50
28107/28107 - 755s - loss: 1.0910 - accuracy20: 0.3769 - val_loss: 1.0905 - val_accuracy20: 0.3761 - 755s/epoch - 27ms/step
Epoch 5/50
28107/28107 - 756s - loss: 1.0897 - accuracy20: 0.3807 - val_loss: 1.0887 - val_accuracy20: 0.3817 - 756s/epoch - 27ms/step
Epoch 6/50
28107/28107 - 759s - loss: 1.0889 - accuracy20: 0.3827 - val_loss: 1.0870 - val_accuracy20: 0.3881 - 759s/epoch - 27ms/step
Epoch 7/50
28107/28107 - 758s - loss: 1.0881 - accuracy20: 0.3846 - val_loss: 1.0861 - val_accuracy20: 0.3887 - 758s/epoch - 27ms/step
Epoch 8/50
28107/28107 - 759s - loss: 1.0878 - accuracy20: 0.3848 - val_loss: 1.0860 - val_accuracy20: 0.3890 - 759s/epoch - 27ms/step
Epoch 9/50
28107/28107 - 764s - loss: 1.0874 - accuracy20: 0.3860 - val_loss: 1.0878 - val_accuracy20: 0.3864 - 764s/epoch - 27ms/step
Epoch 10/50
28107/28107 - 762s - loss: 1.0870 - accuracy20: 0.3865 - val_loss: 1.0860 - val_accuracy20: 0.3895 - 762s/epoch - 27ms/step
Epoch 11/50
28107/28107 - 764s - loss: 1.0869 - accuracy20: 0.3869 - val_loss: 1.0856 - val_accuracy20: 0.3901 - 764s/epoch - 27ms/step
Epoch 12/50
28107/28107 - 765s - loss: 1.0867 - accuracy20: 0.3872 - val_loss: 1.0854 - val_accuracy20: 0.3907 - 765s/epoch - 27ms/step
Epoch 13/50
28107/28107 - 764s - loss: 1.0865 - accuracy20: 0.3877 - val_loss: 1.0853 - val_accuracy20: 0.3904 - 764s/epoch - 27ms/step
Epoch 14/50
28107/28107 - 766s - loss: 1.0864 - accuracy20: 0.3879 - val_loss: 1.0857 - val_accuracy20: 0.3885 - 766s/epoch - 27ms/step
Epoch 15/50
28107/28107 - 765s - loss: 1.0862 - accuracy20: 0.3886 - val_loss: 1.0869 - val_accuracy20: 0.3880 - 765s/epoch - 27ms/step
Epoch 16/50
28107/28107 - 767s - loss: 1.0862 - accuracy20: 0.3881 - val_loss: 1.0857 - val_accuracy20: 0.3904 - 767s/epoch - 27ms/step
Epoch 17/50
28107/28107 - 768s - loss: 1.0861 - accuracy20: 0.3885 - val_loss: 1.0852 - val_accuracy20: 0.3900 - 768s/epoch - 27ms/step
Epoch 18/50
28107/28107 - 765s - loss: 1.0859 - accuracy20: 0.3892 - val_loss: 1.0854 - val_accuracy20: 0.3908 - 765s/epoch - 27ms/step
Epoch 19/50
28107/28107 - 759s - loss: 1.0858 - accuracy20: 0.3896 - val_loss: 1.0871 - val_accuracy20: 0.3867 - 759s/epoch - 27ms/step
Epoch 20/50
28107/28107 - 758s - loss: 1.0860 - accuracy20: 0.3890 - val_loss: 1.0857 - val_accuracy20: 0.3893 - 758s/epoch - 27ms/step
Epoch 21/50
28107/28107 - 767s - loss: 1.0857 - accuracy20: 0.3898 - val_loss: 1.0853 - val_accuracy20: 0.3909 - 767s/epoch - 27ms/step
Epoch 22/50
28107/28107 - 760s - loss: 1.0858 - accuracy20: 0.3894 - val_loss: 1.0854 - val_accuracy20: 0.3890 - 760s/epoch - 27ms/step
(149901, 3)
(149901, 3)
Prediction horizon: 20  orderbook updates
accuracy_score: 0.38887665859467246
              precision    recall  f1-score   support

           0     0.3755    0.4713    0.4180     49837
           1     0.3740    0.2625    0.3085     49392
           2     0.4145    0.4310    0.4226     50672

    accuracy                         0.3889    149901
   macro avg     0.3880    0.3883    0.3830    149901
weighted avg     0.3882    0.3889    0.3835    149901

[[ 7.42437777e-02 -1.24483992e-01  7.47185590e-02 ... -7.57766119e-02
   9.44742729e-02 -6.14102911e-02]
 [ 7.15664497e-02 -5.71592329e-01  7.20410209e-02 ... -2.84740301e-02
   9.88874472e-02 -6.14102911e-02]
 [ 6.62117937e-02  1.04070743e+00  6.40084066e-02 ... -2.84740301e-02
   8.12347499e-02  2.28482059e-04]
 ...
 [ 8.22757616e-02  3.22624346e-01  8.27511732e-02 ... -7.57766119e-02
   1.05507209e-01  2.28482059e-04]
 [ 8.49530895e-02 -6.86756598e-01  8.00736351e-02 ... -1.23079194e-01
   1.05507209e-01  6.18672552e-02]
 [ 7.95984336e-02 -2.39648260e-01  8.00736351e-02 ... -1.23079194e-01
   9.88874472e-02 -6.14102911e-02]]
[1. 0. 0.]
Model: "model_2"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_3 (InputLayer)           [(None, 100, 40, 1)  0           []                               
                                ]                                                                 
                                                                                                  
 conv2d_28 (Conv2D)             (None, 100, 20, 32)  96          ['input_3[0][0]']                
                                                                                                  
 leaky_re_lu_28 (LeakyReLU)     (None, 100, 20, 32)  0           ['conv2d_28[0][0]']              
                                                                                                  
 conv2d_29 (Conv2D)             (None, 100, 20, 32)  4128        ['leaky_re_lu_28[0][0]']         
                                                                                                  
 leaky_re_lu_29 (LeakyReLU)     (None, 100, 20, 32)  0           ['conv2d_29[0][0]']              
                                                                                                  
 conv2d_30 (Conv2D)             (None, 100, 20, 32)  4128        ['leaky_re_lu_29[0][0]']         
                                                                                                  
 leaky_re_lu_30 (LeakyReLU)     (None, 100, 20, 32)  0           ['conv2d_30[0][0]']              
                                                                                                  
 conv2d_31 (Conv2D)             (None, 100, 10, 32)  2080        ['leaky_re_lu_30[0][0]']         
                                                                                                  
 leaky_re_lu_31 (LeakyReLU)     (None, 100, 10, 32)  0           ['conv2d_31[0][0]']              
                                                                                                  
 conv2d_32 (Conv2D)             (None, 100, 10, 32)  4128        ['leaky_re_lu_31[0][0]']         
                                                                                                  
 leaky_re_lu_32 (LeakyReLU)     (None, 100, 10, 32)  0           ['conv2d_32[0][0]']              
                                                                                                  
 conv2d_33 (Conv2D)             (None, 100, 10, 32)  4128        ['leaky_re_lu_32[0][0]']         
                                                                                                  
 leaky_re_lu_33 (LeakyReLU)     (None, 100, 10, 32)  0           ['conv2d_33[0][0]']              
                                                                                                  
 conv2d_34 (Conv2D)             (None, 100, 1, 32)   10272       ['leaky_re_lu_33[0][0]']         
                                                                                                  
 leaky_re_lu_34 (LeakyReLU)     (None, 100, 1, 32)   0           ['conv2d_34[0][0]']              
                                                                                                  
 conv2d_35 (Conv2D)             (None, 100, 1, 32)   4128        ['leaky_re_lu_34[0][0]']         
                                                                                                  
 leaky_re_lu_35 (LeakyReLU)     (None, 100, 1, 32)   0           ['conv2d_35[0][0]']              
                                                                                                  
 conv2d_36 (Conv2D)             (None, 100, 1, 32)   4128        ['leaky_re_lu_35[0][0]']         
                                                                                                  
 leaky_re_lu_36 (LeakyReLU)     (None, 100, 1, 32)   0           ['conv2d_36[0][0]']              
                                                                                                  
 conv2d_37 (Conv2D)             (None, 100, 1, 64)   2112        ['leaky_re_lu_36[0][0]']         
                                                                                                  
 conv2d_39 (Conv2D)             (None, 100, 1, 64)   2112        ['leaky_re_lu_36[0][0]']         
                                                                                                  
 leaky_re_lu_37 (LeakyReLU)     (None, 100, 1, 64)   0           ['conv2d_37[0][0]']              
                                                                                                  
 leaky_re_lu_39 (LeakyReLU)     (None, 100, 1, 64)   0           ['conv2d_39[0][0]']              
                                                                                                  
 max_pooling2d_2 (MaxPooling2D)  (None, 100, 1, 32)  0           ['leaky_re_lu_36[0][0]']         
                                                                                                  
 conv2d_38 (Conv2D)             (None, 100, 1, 64)   12352       ['leaky_re_lu_37[0][0]']         
                                                                                                  
 conv2d_40 (Conv2D)             (None, 100, 1, 64)   20544       ['leaky_re_lu_39[0][0]']         
                                                                                                  
 conv2d_41 (Conv2D)             (None, 100, 1, 64)   2112        ['max_pooling2d_2[0][0]']        
                                                                                                  
 leaky_re_lu_38 (LeakyReLU)     (None, 100, 1, 64)   0           ['conv2d_38[0][0]']              
                                                                                                  
 leaky_re_lu_40 (LeakyReLU)     (None, 100, 1, 64)   0           ['conv2d_40[0][0]']              
                                                                                                  
 leaky_re_lu_41 (LeakyReLU)     (None, 100, 1, 64)   0           ['conv2d_41[0][0]']              
                                                                                                  
 concatenate_2 (Concatenate)    (None, 100, 1, 192)  0           ['leaky_re_lu_38[0][0]',         
                                                                  'leaky_re_lu_40[0][0]',         
                                                                  'leaky_re_lu_41[0][0]']         
                                                                                                  
 reshape_2 (Reshape)            (None, 100, 192)     0           ['concatenate_2[0][0]']          
                                                                                                  
 dropout_2 (Dropout)            (None, 100, 192)     0           ['reshape_2[0][0]']              
                                                                                                  
 lstm_2 (LSTM)                  (None, 64)           65792       ['dropout_2[0][0]']              
                                                                                                  
 dense_2 (Dense)                (None, 3)            195         ['lstm_2[0][0]']                 
                                                                                                  
==================================================================================================
Total params: 142,435
Trainable params: 142,435
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/50
28107/28107 - 781s - loss: 1.0994 - accuracy30: 0.3359 - val_loss: 1.0967 - val_accuracy30: 0.3444 - 781s/epoch - 28ms/step
Epoch 2/50
28107/28107 - 770s - loss: 1.0982 - accuracy30: 0.3433 - val_loss: 1.0968 - val_accuracy30: 0.3460 - 770s/epoch - 27ms/step
Epoch 3/50
28107/28107 - 767s - loss: 1.0973 - accuracy30: 0.3491 - val_loss: 1.0981 - val_accuracy30: 0.3457 - 767s/epoch - 27ms/step
Epoch 4/50
28107/28107 - 768s - loss: 1.0965 - accuracy30: 0.3537 - val_loss: 1.0944 - val_accuracy30: 0.3599 - 768s/epoch - 27ms/step
Epoch 5/50
28107/28107 - 763s - loss: 1.0953 - accuracy30: 0.3606 - val_loss: 1.0927 - val_accuracy30: 0.3704 - 763s/epoch - 27ms/step
Epoch 6/50
28107/28107 - 773s - loss: 1.0940 - accuracy30: 0.3669 - val_loss: 1.0920 - val_accuracy30: 0.3751 - 773s/epoch - 27ms/step
Epoch 7/50
28107/28107 - 773s - loss: 1.0935 - accuracy30: 0.3701 - val_loss: 1.0916 - val_accuracy30: 0.3738 - 773s/epoch - 28ms/step
Epoch 8/50
28107/28107 - 778s - loss: 1.0928 - accuracy30: 0.3719 - val_loss: 1.0907 - val_accuracy30: 0.3766 - 778s/epoch - 28ms/step
Epoch 9/50
28107/28107 - 785s - loss: 1.0923 - accuracy30: 0.3734 - val_loss: 1.0995 - val_accuracy30: 0.3565 - 785s/epoch - 28ms/step
Epoch 10/50
28107/28107 - 789s - loss: 1.0919 - accuracy30: 0.3741 - val_loss: 1.0917 - val_accuracy30: 0.3741 - 789s/epoch - 28ms/step
Epoch 11/50
28107/28107 - 783s - loss: 1.0917 - accuracy30: 0.3739 - val_loss: 1.0913 - val_accuracy30: 0.3743 - 783s/epoch - 28ms/step
Epoch 12/50
28107/28107 - 764s - loss: 1.0914 - accuracy30: 0.3752 - val_loss: 1.0921 - val_accuracy30: 0.3713 - 764s/epoch - 27ms/step
Epoch 13/50
28107/28107 - 805s - loss: 1.0912 - accuracy30: 0.3759 - val_loss: 1.0906 - val_accuracy30: 0.3772 - 805s/epoch - 29ms/step
Epoch 14/50
28107/28107 - 785s - loss: 1.0910 - accuracy30: 0.3760 - val_loss: 1.0915 - val_accuracy30: 0.3734 - 785s/epoch - 28ms/step
Epoch 15/50
28107/28107 - 787s - loss: 1.0908 - accuracy30: 0.3762 - val_loss: 1.0910 - val_accuracy30: 0.3762 - 787s/epoch - 28ms/step
Epoch 16/50
28107/28107 - 780s - loss: 1.0908 - accuracy30: 0.3762 - val_loss: 1.0904 - val_accuracy30: 0.3764 - 780s/epoch - 28ms/step
Epoch 17/50
28107/28107 - 782s - loss: 1.0907 - accuracy30: 0.3764 - val_loss: 1.0900 - val_accuracy30: 0.3788 - 782s/epoch - 28ms/step
Epoch 18/50
28107/28107 - 782s - loss: 1.0904 - accuracy30: 0.3770 - val_loss: 1.0902 - val_accuracy30: 0.3778 - 782s/epoch - 28ms/step
Epoch 19/50
28107/28107 - 779s - loss: 1.0904 - accuracy30: 0.3771 - val_loss: 1.0896 - val_accuracy30: 0.3799 - 779s/epoch - 28ms/step
Epoch 20/50
28107/28107 - 786s - loss: 1.0905 - accuracy30: 0.3778 - val_loss: 1.0899 - val_accuracy30: 0.3792 - 786s/epoch - 28ms/step
Epoch 21/50
28107/28107 - 776s - loss: 1.0903 - accuracy30: 0.3778 - val_loss: 1.0908 - val_accuracy30: 0.3760 - 776s/epoch - 28ms/step
Epoch 22/50
28107/28107 - 767s - loss: 1.0902 - accuracy30: 0.3779 - val_loss: 1.0901 - val_accuracy30: 0.3783 - 767s/epoch - 27ms/step
Epoch 23/50
28107/28107 - 774s - loss: 1.0901 - accuracy30: 0.3779 - val_loss: 1.0906 - val_accuracy30: 0.3764 - 774s/epoch - 28ms/step
Epoch 24/50
28107/28107 - 786s - loss: 1.0901 - accuracy30: 0.3781 - val_loss: 1.0896 - val_accuracy30: 0.3794 - 786s/epoch - 28ms/step
Epoch 25/50
28107/28107 - 785s - loss: 1.0900 - accuracy30: 0.3785 - val_loss: 1.0907 - val_accuracy30: 0.3767 - 785s/epoch - 28ms/step
Epoch 26/50
28107/28107 - 785s - loss: 1.0901 - accuracy30: 0.3783 - val_loss: 1.0904 - val_accuracy30: 0.3765 - 785s/epoch - 28ms/step
Epoch 27/50
28107/28107 - 772s - loss: 1.0899 - accuracy30: 0.3781 - val_loss: 1.0901 - val_accuracy30: 0.3775 - 772s/epoch - 27ms/step
Epoch 28/50
28107/28107 - 765s - loss: 1.0896 - accuracy30: 0.3796 - val_loss: 1.0903 - val_accuracy30: 0.3782 - 765s/epoch - 27ms/step
Epoch 29/50
28107/28107 - 773s - loss: 1.0898 - accuracy30: 0.3790 - val_loss: 1.0907 - val_accuracy30: 0.3754 - 773s/epoch - 27ms/step
(149901, 3)
(149901, 3)
Prediction horizon: 30  orderbook updates
accuracy_score: 0.3797906618368123
              precision    recall  f1-score   support

           0     0.3747    0.3937    0.3840     49929
           1     0.3644    0.3140    0.3373     49442
           2     0.3967    0.4304    0.4128     50530

    accuracy                         0.3798    149901
   macro avg     0.3786    0.3794    0.3780    149901
weighted avg     0.3787    0.3798    0.3783    149901

[[ 7.42437777e-02 -1.24483992e-01  7.47185590e-02 ... -7.57766119e-02
   9.44742729e-02 -6.14102911e-02]
 [ 7.15664497e-02 -5.71592329e-01  7.20410209e-02 ... -2.84740301e-02
   9.88874472e-02 -6.14102911e-02]
 [ 6.62117937e-02  1.04070743e+00  6.40084066e-02 ... -2.84740301e-02
   8.12347499e-02  2.28482059e-04]
 ...
 [ 8.22757616e-02  3.22624346e-01  8.27511732e-02 ... -7.57766119e-02
   1.05507209e-01  2.28482059e-04]
 [ 8.49530895e-02 -6.86756598e-01  8.00736351e-02 ... -1.23079194e-01
   1.05507209e-01  6.18672552e-02]
 [ 7.95984336e-02 -2.39648260e-01  8.00736351e-02 ... -1.23079194e-01
   9.88874472e-02 -6.14102911e-02]]
[1. 0. 0.]
Model: "model_3"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_4 (InputLayer)           [(None, 100, 40, 1)  0           []                               
                                ]                                                                 
                                                                                                  
 conv2d_42 (Conv2D)             (None, 100, 20, 32)  96          ['input_4[0][0]']                
                                                                                                  
 leaky_re_lu_42 (LeakyReLU)     (None, 100, 20, 32)  0           ['conv2d_42[0][0]']              
                                                                                                  
 conv2d_43 (Conv2D)             (None, 100, 20, 32)  4128        ['leaky_re_lu_42[0][0]']         
                                                                                                  
 leaky_re_lu_43 (LeakyReLU)     (None, 100, 20, 32)  0           ['conv2d_43[0][0]']              
                                                                                                  
 conv2d_44 (Conv2D)             (None, 100, 20, 32)  4128        ['leaky_re_lu_43[0][0]']         
                                                                                                  
 leaky_re_lu_44 (LeakyReLU)     (None, 100, 20, 32)  0           ['conv2d_44[0][0]']              
                                                                                                  
 conv2d_45 (Conv2D)             (None, 100, 10, 32)  2080        ['leaky_re_lu_44[0][0]']         
                                                                                                  
 leaky_re_lu_45 (LeakyReLU)     (None, 100, 10, 32)  0           ['conv2d_45[0][0]']              
                                                                                                  
 conv2d_46 (Conv2D)             (None, 100, 10, 32)  4128        ['leaky_re_lu_45[0][0]']         
                                                                                                  
 leaky_re_lu_46 (LeakyReLU)     (None, 100, 10, 32)  0           ['conv2d_46[0][0]']              
                                                                                                  
 conv2d_47 (Conv2D)             (None, 100, 10, 32)  4128        ['leaky_re_lu_46[0][0]']         
                                                                                                  
 leaky_re_lu_47 (LeakyReLU)     (None, 100, 10, 32)  0           ['conv2d_47[0][0]']              
                                                                                                  
 conv2d_48 (Conv2D)             (None, 100, 1, 32)   10272       ['leaky_re_lu_47[0][0]']         
                                                                                                  
 leaky_re_lu_48 (LeakyReLU)     (None, 100, 1, 32)   0           ['conv2d_48[0][0]']              
                                                                                                  
 conv2d_49 (Conv2D)             (None, 100, 1, 32)   4128        ['leaky_re_lu_48[0][0]']         
                                                                                                  
 leaky_re_lu_49 (LeakyReLU)     (None, 100, 1, 32)   0           ['conv2d_49[0][0]']              
                                                                                                  
 conv2d_50 (Conv2D)             (None, 100, 1, 32)   4128        ['leaky_re_lu_49[0][0]']         
                                                                                                  
 leaky_re_lu_50 (LeakyReLU)     (None, 100, 1, 32)   0           ['conv2d_50[0][0]']              
                                                                                                  
 conv2d_51 (Conv2D)             (None, 100, 1, 64)   2112        ['leaky_re_lu_50[0][0]']         
                                                                                                  
 conv2d_53 (Conv2D)             (None, 100, 1, 64)   2112        ['leaky_re_lu_50[0][0]']         
                                                                                                  
 leaky_re_lu_51 (LeakyReLU)     (None, 100, 1, 64)   0           ['conv2d_51[0][0]']              
                                                                                                  
 leaky_re_lu_53 (LeakyReLU)     (None, 100, 1, 64)   0           ['conv2d_53[0][0]']              
                                                                                                  
 max_pooling2d_3 (MaxPooling2D)  (None, 100, 1, 32)  0           ['leaky_re_lu_50[0][0]']         
                                                                                                  
 conv2d_52 (Conv2D)             (None, 100, 1, 64)   12352       ['leaky_re_lu_51[0][0]']         
                                                                                                  
 conv2d_54 (Conv2D)             (None, 100, 1, 64)   20544       ['leaky_re_lu_53[0][0]']         
                                                                                                  
 conv2d_55 (Conv2D)             (None, 100, 1, 64)   2112        ['max_pooling2d_3[0][0]']        
                                                                                                  
 leaky_re_lu_52 (LeakyReLU)     (None, 100, 1, 64)   0           ['conv2d_52[0][0]']              
                                                                                                  
 leaky_re_lu_54 (LeakyReLU)     (None, 100, 1, 64)   0           ['conv2d_54[0][0]']              
                                                                                                  
 leaky_re_lu_55 (LeakyReLU)     (None, 100, 1, 64)   0           ['conv2d_55[0][0]']              
                                                                                                  
 concatenate_3 (Concatenate)    (None, 100, 1, 192)  0           ['leaky_re_lu_52[0][0]',         
                                                                  'leaky_re_lu_54[0][0]',         
                                                                  'leaky_re_lu_55[0][0]']         
                                                                                                  
 reshape_3 (Reshape)            (None, 100, 192)     0           ['concatenate_3[0][0]']          
                                                                                                  
 dropout_3 (Dropout)            (None, 100, 192)     0           ['reshape_3[0][0]']              
                                                                                                  
 lstm_3 (LSTM)                  (None, 64)           65792       ['dropout_3[0][0]']              
                                                                                                  
 dense_3 (Dense)                (None, 3)            195         ['lstm_3[0][0]']                 
                                                                                                  
==================================================================================================
Total params: 142,435
Trainable params: 142,435
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/50
28107/28107 - 796s - loss: 1.0996 - accuracy50: 0.3358 - val_loss: 1.0985 - val_accuracy50: 0.3412 - 796s/epoch - 28ms/step
Epoch 2/50
28107/28107 - 787s - loss: 1.0988 - accuracy50: 0.3404 - val_loss: 1.0973 - val_accuracy50: 0.3427 - 787s/epoch - 28ms/step
Epoch 3/50
28107/28107 - 785s - loss: 1.0982 - accuracy50: 0.3462 - val_loss: 1.0966 - val_accuracy50: 0.3464 - 785s/epoch - 28ms/step
Epoch 4/50
28107/28107 - 784s - loss: 1.0980 - accuracy50: 0.3443 - val_loss: 1.0976 - val_accuracy50: 0.3480 - 784s/epoch - 28ms/step
Epoch 5/50
28107/28107 - 785s - loss: 1.0973 - accuracy50: 0.3508 - val_loss: 1.0962 - val_accuracy50: 0.3572 - 785s/epoch - 28ms/step
Epoch 6/50
28107/28107 - 786s - loss: 1.0971 - accuracy50: 0.3505 - val_loss: 1.0961 - val_accuracy50: 0.3577 - 786s/epoch - 28ms/step
Epoch 7/50
28107/28107 - 788s - loss: 1.0966 - accuracy50: 0.3545 - val_loss: 1.0955 - val_accuracy50: 0.3590 - 788s/epoch - 28ms/step
Epoch 8/50
28107/28107 - 782s - loss: 1.0964 - accuracy50: 0.3561 - val_loss: 1.0949 - val_accuracy50: 0.3639 - 782s/epoch - 28ms/step
Epoch 9/50
28107/28107 - 781s - loss: 1.0961 - accuracy50: 0.3569 - val_loss: 1.0955 - val_accuracy50: 0.3611 - 781s/epoch - 28ms/step
Epoch 10/50
28107/28107 - 777s - loss: 1.0956 - accuracy50: 0.3606 - val_loss: 1.0943 - val_accuracy50: 0.3647 - 777s/epoch - 28ms/step
Epoch 11/50
28107/28107 - 768s - loss: 1.0956 - accuracy50: 0.3606 - val_loss: 1.0950 - val_accuracy50: 0.3639 - 768s/epoch - 27ms/step
Epoch 12/50
28107/28107 - 782s - loss: 1.0956 - accuracy50: 0.3615 - val_loss: 1.0946 - val_accuracy50: 0.3653 - 782s/epoch - 28ms/step
Epoch 13/50
28107/28107 - 786s - loss: 1.0952 - accuracy50: 0.3626 - val_loss: 1.0967 - val_accuracy50: 0.3606 - 786s/epoch - 28ms/step
Epoch 14/50
28107/28107 - 787s - loss: 1.0949 - accuracy50: 0.3634 - val_loss: 1.0942 - val_accuracy50: 0.3664 - 787s/epoch - 28ms/step
Epoch 15/50
28107/28107 - 788s - loss: 1.0951 - accuracy50: 0.3636 - val_loss: 1.0955 - val_accuracy50: 0.3612 - 788s/epoch - 28ms/step
Epoch 16/50
28107/28107 - 786s - loss: 1.0948 - accuracy50: 0.3636 - val_loss: 1.0966 - val_accuracy50: 0.3599 - 786s/epoch - 28ms/step
Epoch 17/50
28107/28107 - 782s - loss: 1.0949 - accuracy50: 0.3642 - val_loss: 1.0942 - val_accuracy50: 0.3644 - 782s/epoch - 28ms/step
Epoch 18/50
28107/28107 - 791s - loss: 1.0947 - accuracy50: 0.3637 - val_loss: 1.0936 - val_accuracy50: 0.3667 - 791s/epoch - 28ms/step
Epoch 19/50
28107/28107 - 788s - loss: 1.0945 - accuracy50: 0.3648 - val_loss: 1.0952 - val_accuracy50: 0.3635 - 788s/epoch - 28ms/step
Epoch 20/50
28107/28107 - 788s - loss: 1.0945 - accuracy50: 0.3655 - val_loss: 1.0939 - val_accuracy50: 0.3680 - 788s/epoch - 28ms/step
Epoch 21/50
28107/28107 - 787s - loss: 1.0944 - accuracy50: 0.3659 - val_loss: 1.0935 - val_accuracy50: 0.3661 - 787s/epoch - 28ms/step
Epoch 22/50
28107/28107 - 791s - loss: 1.0944 - accuracy50: 0.3655 - val_loss: 1.0936 - val_accuracy50: 0.3672 - 791s/epoch - 28ms/step
Epoch 23/50
28107/28107 - 783s - loss: 1.0942 - accuracy50: 0.3660 - val_loss: 1.0952 - val_accuracy50: 0.3607 - 783s/epoch - 28ms/step
Epoch 24/50
28107/28107 - 793s - loss: 1.0943 - accuracy50: 0.3651 - val_loss: 1.0961 - val_accuracy50: 0.3617 - 793s/epoch - 28ms/step
Epoch 25/50
28107/28107 - 791s - loss: 1.0941 - accuracy50: 0.3669 - val_loss: 1.0941 - val_accuracy50: 0.3679 - 791s/epoch - 28ms/step
Epoch 26/50
28107/28107 - 793s - loss: 1.0941 - accuracy50: 0.3675 - val_loss: 1.0944 - val_accuracy50: 0.3638 - 793s/epoch - 28ms/step
(149901, 3)
(149901, 3)
Prediction horizon: 50  orderbook updates
accuracy_score: 0.36337983068825425
              precision    recall  f1-score   support

           0     0.3570    0.4362    0.3926     49871
           1     0.3503    0.2304    0.2780     49564
           2     0.3779    0.4219    0.3987     50466

    accuracy                         0.3634    149901
   macro avg     0.3617    0.3629    0.3564    149901
weighted avg     0.3618    0.3634    0.3568    149901

[[ 7.42437777e-02 -1.24483992e-01  7.47185590e-02 ... -7.57766119e-02
   9.44742729e-02 -6.14102911e-02]
 [ 7.15664497e-02 -5.71592329e-01  7.20410209e-02 ... -2.84740301e-02
   9.88874472e-02 -6.14102911e-02]
 [ 6.62117937e-02  1.04070743e+00  6.40084066e-02 ... -2.84740301e-02
   8.12347499e-02  2.28482059e-04]
 ...
 [ 8.22757616e-02  3.22624346e-01  8.27511732e-02 ... -7.57766119e-02
   1.05507209e-01  2.28482059e-04]
 [ 8.49530895e-02 -6.86756598e-01  8.00736351e-02 ... -1.23079194e-01
   1.05507209e-01  6.18672552e-02]
 [ 7.95984336e-02 -2.39648260e-01  8.00736351e-02 ... -1.23079194e-01
   9.88874472e-02 -6.14102911e-02]]
[1. 0. 0.]
Model: "model_4"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_5 (InputLayer)           [(None, 100, 40, 1)  0           []                               
                                ]                                                                 
                                                                                                  
 conv2d_56 (Conv2D)             (None, 100, 20, 32)  96          ['input_5[0][0]']                
                                                                                                  
 leaky_re_lu_56 (LeakyReLU)     (None, 100, 20, 32)  0           ['conv2d_56[0][0]']              
                                                                                                  
 conv2d_57 (Conv2D)             (None, 100, 20, 32)  4128        ['leaky_re_lu_56[0][0]']         
                                                                                                  
 leaky_re_lu_57 (LeakyReLU)     (None, 100, 20, 32)  0           ['conv2d_57[0][0]']              
                                                                                                  
 conv2d_58 (Conv2D)             (None, 100, 20, 32)  4128        ['leaky_re_lu_57[0][0]']         
                                                                                                  
 leaky_re_lu_58 (LeakyReLU)     (None, 100, 20, 32)  0           ['conv2d_58[0][0]']              
                                                                                                  
 conv2d_59 (Conv2D)             (None, 100, 10, 32)  2080        ['leaky_re_lu_58[0][0]']         
                                                                                                  
 leaky_re_lu_59 (LeakyReLU)     (None, 100, 10, 32)  0           ['conv2d_59[0][0]']              
                                                                                                  
 conv2d_60 (Conv2D)             (None, 100, 10, 32)  4128        ['leaky_re_lu_59[0][0]']         
                                                                                                  
 leaky_re_lu_60 (LeakyReLU)     (None, 100, 10, 32)  0           ['conv2d_60[0][0]']              
                                                                                                  
 conv2d_61 (Conv2D)             (None, 100, 10, 32)  4128        ['leaky_re_lu_60[0][0]']         
                                                                                                  
 leaky_re_lu_61 (LeakyReLU)     (None, 100, 10, 32)  0           ['conv2d_61[0][0]']              
                                                                                                  
 conv2d_62 (Conv2D)             (None, 100, 1, 32)   10272       ['leaky_re_lu_61[0][0]']         
                                                                                                  
 leaky_re_lu_62 (LeakyReLU)     (None, 100, 1, 32)   0           ['conv2d_62[0][0]']              
                                                                                                  
 conv2d_63 (Conv2D)             (None, 100, 1, 32)   4128        ['leaky_re_lu_62[0][0]']         
                                                                                                  
 leaky_re_lu_63 (LeakyReLU)     (None, 100, 1, 32)   0           ['conv2d_63[0][0]']              
                                                                                                  
 conv2d_64 (Conv2D)             (None, 100, 1, 32)   4128        ['leaky_re_lu_63[0][0]']         
                                                                                                  
 leaky_re_lu_64 (LeakyReLU)     (None, 100, 1, 32)   0           ['conv2d_64[0][0]']              
                                                                                                  
 conv2d_65 (Conv2D)             (None, 100, 1, 64)   2112        ['leaky_re_lu_64[0][0]']         
                                                                                                  
 conv2d_67 (Conv2D)             (None, 100, 1, 64)   2112        ['leaky_re_lu_64[0][0]']         
                                                                                                  
 leaky_re_lu_65 (LeakyReLU)     (None, 100, 1, 64)   0           ['conv2d_65[0][0]']              
                                                                                                  
 leaky_re_lu_67 (LeakyReLU)     (None, 100, 1, 64)   0           ['conv2d_67[0][0]']              
                                                                                                  
 max_pooling2d_4 (MaxPooling2D)  (None, 100, 1, 32)  0           ['leaky_re_lu_64[0][0]']         
                                                                                                  
 conv2d_66 (Conv2D)             (None, 100, 1, 64)   12352       ['leaky_re_lu_65[0][0]']         
                                                                                                  
 conv2d_68 (Conv2D)             (None, 100, 1, 64)   20544       ['leaky_re_lu_67[0][0]']         
                                                                                                  
 conv2d_69 (Conv2D)             (None, 100, 1, 64)   2112        ['max_pooling2d_4[0][0]']        
                                                                                                  
 leaky_re_lu_66 (LeakyReLU)     (None, 100, 1, 64)   0           ['conv2d_66[0][0]']              
                                                                                                  
 leaky_re_lu_68 (LeakyReLU)     (None, 100, 1, 64)   0           ['conv2d_68[0][0]']              
                                                                                                  
 leaky_re_lu_69 (LeakyReLU)     (None, 100, 1, 64)   0           ['conv2d_69[0][0]']              
                                                                                                  
 concatenate_4 (Concatenate)    (None, 100, 1, 192)  0           ['leaky_re_lu_66[0][0]',         
                                                                  'leaky_re_lu_68[0][0]',         
                                                                  'leaky_re_lu_69[0][0]']         
                                                                                                  
 reshape_4 (Reshape)            (None, 100, 192)     0           ['concatenate_4[0][0]']          
                                                                                                  
 dropout_4 (Dropout)            (None, 100, 192)     0           ['reshape_4[0][0]']              
                                                                                                  
 lstm_4 (LSTM)                  (None, 64)           65792       ['dropout_4[0][0]']              
                                                                                                  
 dense_4 (Dense)                (None, 3)            195         ['lstm_4[0][0]']                 
                                                                                                  
==================================================================================================
Total params: 142,435
Trainable params: 142,435
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/50
28107/28107 - 805s - loss: 1.1003 - accuracy100: 0.3330 - val_loss: 1.0996 - val_accuracy100: 0.3227 - 805s/epoch - 29ms/step
Epoch 2/50
28107/28107 - 787s - loss: 1.0998 - accuracy100: 0.3356 - val_loss: 1.0986 - val_accuracy100: 0.3325 - 787s/epoch - 28ms/step
Epoch 3/50
28107/28107 - 794s - loss: 1.0996 - accuracy100: 0.3315 - val_loss: 1.1038 - val_accuracy100: 0.3341 - 794s/epoch - 28ms/step
Epoch 4/50
28107/28107 - 799s - loss: 1.0996 - accuracy100: 0.3351 - val_loss: 1.0989 - val_accuracy100: 0.3432 - 799s/epoch - 28ms/step
Epoch 5/50
28107/28107 - 800s - loss: 1.0994 - accuracy100: 0.3363 - val_loss: 1.0991 - val_accuracy100: 0.3432 - 800s/epoch - 28ms/step
Epoch 6/50
28107/28107 - 802s - loss: 1.0993 - accuracy100: 0.3358 - val_loss: 1.1000 - val_accuracy100: 0.3432 - 802s/epoch - 29ms/step
Epoch 7/50
28107/28107 - 799s - loss: 1.0994 - accuracy100: 0.3323 - val_loss: 1.0980 - val_accuracy100: 0.3430 - 799s/epoch - 28ms/step
Epoch 8/50
28107/28107 - 807s - loss: 1.0992 - accuracy100: 0.3370 - val_loss: 1.0986 - val_accuracy100: 0.3340 - 807s/epoch - 29ms/step
Epoch 9/50
28107/28107 - 801s - loss: 1.0990 - accuracy100: 0.3354 - val_loss: 1.0992 - val_accuracy100: 0.3435 - 801s/epoch - 29ms/step
Epoch 10/50
28107/28107 - 807s - loss: 1.0990 - accuracy100: 0.3377 - val_loss: 1.0987 - val_accuracy100: 0.3435 - 807s/epoch - 29ms/step
Epoch 11/50
28107/28107 - 803s - loss: 1.0989 - accuracy100: 0.3388 - val_loss: 1.0980 - val_accuracy100: 0.3400 - 803s/epoch - 29ms/step
Epoch 12/50
28107/28107 - 804s - loss: 1.0987 - accuracy100: 0.3401 - val_loss: 1.0986 - val_accuracy100: 0.3358 - 804s/epoch - 29ms/step
(149901, 3)
(149901, 3)
Prediction horizon: 100  orderbook updates
accuracy_score: 0.3356148391271573
              precision    recall  f1-score   support

           0     0.3354    0.9905    0.5011     50280
           1     0.0000    0.0000    0.0000     48996
           2     0.3617    0.0100    0.0194     50625

    accuracy                         0.3356    149901
   macro avg     0.2324    0.3335    0.1735    149901
weighted avg     0.2347    0.3356    0.1746    149901

##################### deepLOB seq2seq #####################
Epoch 1/50
28107/28107 - 1427s - loss: 1.0993 - accuracy10: 0.3348 - accuracy20: 0.3348 - accuracy30: 0.3348 - accuracy50: 0.3348 - accuracy100: 0.3348 - val_loss: 1.0988 - val_accuracy10: 0.3357 - val_accuracy20: 0.3357 - val_accuracy30: 0.3357 - val_accuracy50: 0.3357 - val_accuracy100: 0.3357 - 1427s/epoch - 51ms/step
Epoch 2/50
28107/28107 - 1381s - loss: 1.0978 - accuracy10: 0.3462 - accuracy20: 0.3462 - accuracy30: 0.3462 - accuracy50: 0.3462 - accuracy100: 0.3462 - val_loss: 1.0955 - val_accuracy10: 0.3548 - val_accuracy20: 0.3548 - val_accuracy30: 0.3548 - val_accuracy50: 0.3548 - val_accuracy100: 0.3548 - 1381s/epoch - 49ms/step
Epoch 3/50
28107/28107 - 1407s - loss: 1.0966 - accuracy10: 0.3534 - accuracy20: 0.3534 - accuracy30: 0.3534 - accuracy50: 0.3534 - accuracy100: 0.3534 - val_loss: 1.0948 - val_accuracy10: 0.3582 - val_accuracy20: 0.3582 - val_accuracy30: 0.3582 - val_accuracy50: 0.3582 - val_accuracy100: 0.3582 - 1407s/epoch - 50ms/step
Epoch 4/50
28107/28107 - 1413s - loss: 1.0948 - accuracy10: 0.3618 - accuracy20: 0.3618 - accuracy30: 0.3618 - accuracy50: 0.3618 - accuracy100: 0.3618 - val_loss: 1.0922 - val_accuracy10: 0.3716 - val_accuracy20: 0.3716 - val_accuracy30: 0.3716 - val_accuracy50: 0.3716 - val_accuracy100: 0.3716 - 1413s/epoch - 50ms/step
Epoch 5/50
28107/28107 - 1371s - loss: 1.0933 - accuracy10: 0.3683 - accuracy20: 0.3683 - accuracy30: 0.3683 - accuracy50: 0.3683 - accuracy100: 0.3683 - val_loss: 1.0929 - val_accuracy10: 0.3687 - val_accuracy20: 0.3687 - val_accuracy30: 0.3687 - val_accuracy50: 0.3687 - val_accuracy100: 0.3687 - 1371s/epoch - 49ms/step
Epoch 6/50
28107/28107 - 1405s - loss: 1.0923 - accuracy10: 0.3715 - accuracy20: 0.3715 - accuracy30: 0.3715 - accuracy50: 0.3715 - accuracy100: 0.3715 - val_loss: 1.0906 - val_accuracy10: 0.3763 - val_accuracy20: 0.3763 - val_accuracy30: 0.3763 - val_accuracy50: 0.3763 - val_accuracy100: 0.3763 - 1405s/epoch - 50ms/step
Epoch 7/50
28107/28107 - 1355s - loss: 1.0916 - accuracy10: 0.3739 - accuracy20: 0.3739 - accuracy30: 0.3739 - accuracy50: 0.3739 - accuracy100: 0.3739 - val_loss: 1.0901 - val_accuracy10: 0.3763 - val_accuracy20: 0.3763 - val_accuracy30: 0.3763 - val_accuracy50: 0.3763 - val_accuracy100: 0.3763 - 1355s/epoch - 48ms/step
Epoch 8/50
28107/28107 - 1361s - loss: 1.0911 - accuracy10: 0.3750 - accuracy20: 0.3750 - accuracy30: 0.3750 - accuracy50: 0.3750 - accuracy100: 0.3750 - val_loss: 1.0907 - val_accuracy10: 0.3772 - val_accuracy20: 0.3772 - val_accuracy30: 0.3772 - val_accuracy50: 0.3772 - val_accuracy100: 0.3772 - 1361s/epoch - 48ms/step
Epoch 9/50
28107/28107 - 1367s - loss: 1.0907 - accuracy10: 0.3759 - accuracy20: 0.3759 - accuracy30: 0.3759 - accuracy50: 0.3759 - accuracy100: 0.3759 - val_loss: 1.0899 - val_accuracy10: 0.3783 - val_accuracy20: 0.3783 - val_accuracy30: 0.3783 - val_accuracy50: 0.3783 - val_accuracy100: 0.3783 - 1367s/epoch - 49ms/step
Epoch 10/50
28107/28107 - 1359s - loss: 1.0903 - accuracy10: 0.3765 - accuracy20: 0.3765 - accuracy30: 0.3765 - accuracy50: 0.3765 - accuracy100: 0.3765 - val_loss: 1.0955 - val_accuracy10: 0.3685 - val_accuracy20: 0.3685 - val_accuracy30: 0.3685 - val_accuracy50: 0.3685 - val_accuracy100: 0.3685 - 1359s/epoch - 48ms/step
Epoch 11/50
28107/28107 - 1350s - loss: 1.0900 - accuracy10: 0.3772 - accuracy20: 0.3772 - accuracy30: 0.3772 - accuracy50: 0.3772 - accuracy100: 0.3772 - val_loss: 1.0904 - val_accuracy10: 0.3756 - val_accuracy20: 0.3756 - val_accuracy30: 0.3756 - val_accuracy50: 0.3756 - val_accuracy100: 0.3756 - 1350s/epoch - 48ms/step
Epoch 12/50
28107/28107 - 1349s - loss: 1.0899 - accuracy10: 0.3771 - accuracy20: 0.3771 - accuracy30: 0.3771 - accuracy50: 0.3771 - accuracy100: 0.3771 - val_loss: 1.0893 - val_accuracy10: 0.3797 - val_accuracy20: 0.3797 - val_accuracy30: 0.3797 - val_accuracy50: 0.3797 - val_accuracy100: 0.3797 - 1349s/epoch - 48ms/step
Epoch 13/50
28107/28107 - 1373s - loss: 1.0897 - accuracy10: 0.3774 - accuracy20: 0.3774 - accuracy30: 0.3774 - accuracy50: 0.3774 - accuracy100: 0.3774 - val_loss: 1.0886 - val_accuracy10: 0.3798 - val_accuracy20: 0.3798 - val_accuracy30: 0.3798 - val_accuracy50: 0.3798 - val_accuracy100: 0.3798 - 1373s/epoch - 49ms/step
Epoch 14/50
28107/28107 - 1379s - loss: 1.0893 - accuracy10: 0.3784 - accuracy20: 0.3784 - accuracy30: 0.3784 - accuracy50: 0.3784 - accuracy100: 0.3784 - val_loss: 1.0895 - val_accuracy10: 0.3765 - val_accuracy20: 0.3765 - val_accuracy30: 0.3765 - val_accuracy50: 0.3765 - val_accuracy100: 0.3765 - 1379s/epoch - 49ms/step
Epoch 15/50
28107/28107 - 1365s - loss: 1.0892 - accuracy10: 0.3788 - accuracy20: 0.3788 - accuracy30: 0.3788 - accuracy50: 0.3788 - accuracy100: 0.3788 - val_loss: 1.0896 - val_accuracy10: 0.3789 - val_accuracy20: 0.3789 - val_accuracy30: 0.3789 - val_accuracy50: 0.3789 - val_accuracy100: 0.3789 - 1365s/epoch - 49ms/step
Epoch 16/50
28107/28107 - 1350s - loss: 1.0891 - accuracy10: 0.3790 - accuracy20: 0.3790 - accuracy30: 0.3790 - accuracy50: 0.3790 - accuracy100: 0.3790 - val_loss: 1.0884 - val_accuracy10: 0.3807 - val_accuracy20: 0.3807 - val_accuracy30: 0.3807 - val_accuracy50: 0.3807 - val_accuracy100: 0.3807 - 1350s/epoch - 48ms/step
Epoch 17/50
28107/28107 - 1376s - loss: 1.0890 - accuracy10: 0.3794 - accuracy20: 0.3794 - accuracy30: 0.3794 - accuracy50: 0.3794 - accuracy100: 0.3794 - val_loss: 1.0922 - val_accuracy10: 0.3735 - val_accuracy20: 0.3735 - val_accuracy30: 0.3735 - val_accuracy50: 0.3735 - val_accuracy100: 0.3735 - 1376s/epoch - 49ms/step
Epoch 18/50
28107/28107 - 1366s - loss: 1.0890 - accuracy10: 0.3794 - accuracy20: 0.3794 - accuracy30: 0.3794 - accuracy50: 0.3794 - accuracy100: 0.3794 - val_loss: 1.0898 - val_accuracy10: 0.3779 - val_accuracy20: 0.3779 - val_accuracy30: 0.3779 - val_accuracy50: 0.3779 - val_accuracy100: 0.3779 - 1366s/epoch - 49ms/step
Epoch 19/50
28107/28107 - 1361s - loss: 1.0888 - accuracy10: 0.3795 - accuracy20: 0.3795 - accuracy30: 0.3795 - accuracy50: 0.3795 - accuracy100: 0.3795 - val_loss: 1.0888 - val_accuracy10: 0.3773 - val_accuracy20: 0.3773 - val_accuracy30: 0.3773 - val_accuracy50: 0.3773 - val_accuracy100: 0.3773 - 1361s/epoch - 48ms/step
Epoch 20/50
28107/28107 - 1371s - loss: 1.0888 - accuracy10: 0.3799 - accuracy20: 0.3799 - accuracy30: 0.3799 - accuracy50: 0.3799 - accuracy100: 0.3799 - val_loss: 1.0890 - val_accuracy10: 0.3780 - val_accuracy20: 0.3780 - val_accuracy30: 0.3780 - val_accuracy50: 0.3780 - val_accuracy100: 0.3780 - 1371s/epoch - 49ms/step
Epoch 21/50
28107/28107 - 1346s - loss: 1.0888 - accuracy10: 0.3797 - accuracy20: 0.3797 - accuracy30: 0.3797 - accuracy50: 0.3797 - accuracy100: 0.3797 - val_loss: 1.0894 - val_accuracy10: 0.3785 - val_accuracy20: 0.3785 - val_accuracy30: 0.3785 - val_accuracy50: 0.3785 - val_accuracy100: 0.3785 - 1346s/epoch - 48ms/step
Epoch 22/50
28107/28107 - 1354s - loss: 1.0887 - accuracy10: 0.3801 - accuracy20: 0.3801 - accuracy30: 0.3801 - accuracy50: 0.3801 - accuracy100: 0.3801 - val_loss: 1.0884 - val_accuracy10: 0.3799 - val_accuracy20: 0.3799 - val_accuracy30: 0.3799 - val_accuracy50: 0.3799 - val_accuracy100: 0.3799 - 1354s/epoch - 48ms/step
Epoch 23/50
28107/28107 - 1382s - loss: 1.0887 - accuracy10: 0.3805 - accuracy20: 0.3805 - accuracy30: 0.3805 - accuracy50: 0.3805 - accuracy100: 0.3805 - val_loss: 1.0900 - val_accuracy10: 0.3766 - val_accuracy20: 0.3766 - val_accuracy30: 0.3766 - val_accuracy50: 0.3766 - val_accuracy100: 0.3766 - 1382s/epoch - 49ms/step
Epoch 24/50
28107/28107 - 1380s - loss: 1.0887 - accuracy10: 0.3800 - accuracy20: 0.3800 - accuracy30: 0.3800 - accuracy50: 0.3800 - accuracy100: 0.3800 - val_loss: 1.0882 - val_accuracy10: 0.3799 - val_accuracy20: 0.3799 - val_accuracy30: 0.3799 - val_accuracy50: 0.3799 - val_accuracy100: 0.3799 - 1380s/epoch - 49ms/step
Epoch 25/50
28107/28107 - 1384s - loss: 1.0884 - accuracy10: 0.3808 - accuracy20: 0.3808 - accuracy30: 0.3808 - accuracy50: 0.3808 - accuracy100: 0.3808 - val_loss: 1.0891 - val_accuracy10: 0.3775 - val_accuracy20: 0.3775 - val_accuracy30: 0.3775 - val_accuracy50: 0.3775 - val_accuracy100: 0.3775 - 1384s/epoch - 49ms/step
Epoch 26/50
28107/28107 - 1401s - loss: 1.0885 - accuracy10: 0.3805 - accuracy20: 0.3805 - accuracy30: 0.3805 - accuracy50: 0.3805 - accuracy100: 0.3805 - val_loss: 1.0880 - val_accuracy10: 0.3810 - val_accuracy20: 0.3810 - val_accuracy30: 0.3810 - val_accuracy50: 0.3810 - val_accuracy100: 0.3810 - 1401s/epoch - 50ms/step
Epoch 27/50
28107/28107 - 1395s - loss: 1.0885 - accuracy10: 0.3805 - accuracy20: 0.3805 - accuracy30: 0.3805 - accuracy50: 0.3805 - accuracy100: 0.3805 - val_loss: 1.0884 - val_accuracy10: 0.3797 - val_accuracy20: 0.3797 - val_accuracy30: 0.3797 - val_accuracy50: 0.3797 - val_accuracy100: 0.3797 - 1395s/epoch - 50ms/step
Epoch 28/50
28107/28107 - 1385s - loss: 1.0884 - accuracy10: 0.3805 - accuracy20: 0.3805 - accuracy30: 0.3805 - accuracy50: 0.3805 - accuracy100: 0.3805 - val_loss: 1.0887 - val_accuracy10: 0.3796 - val_accuracy20: 0.3796 - val_accuracy30: 0.3796 - val_accuracy50: 0.3796 - val_accuracy100: 0.3796 - 1385s/epoch - 49ms/step
Epoch 29/50
28107/28107 - 1393s - loss: 1.0884 - accuracy10: 0.3801 - accuracy20: 0.3801 - accuracy30: 0.3801 - accuracy50: 0.3801 - accuracy100: 0.3801 - val_loss: 1.0879 - val_accuracy10: 0.3814 - val_accuracy20: 0.3814 - val_accuracy30: 0.3814 - val_accuracy50: 0.3814 - val_accuracy100: 0.3814 - 1393s/epoch - 50ms/step
Epoch 30/50
28107/28107 - 1405s - loss: 1.0884 - accuracy10: 0.3806 - accuracy20: 0.3806 - accuracy30: 0.3806 - accuracy50: 0.3806 - accuracy100: 0.3806 - val_loss: 1.0882 - val_accuracy10: 0.3817 - val_accuracy20: 0.3817 - val_accuracy30: 0.3817 - val_accuracy50: 0.3817 - val_accuracy100: 0.3817 - 1405s/epoch - 50ms/step
Epoch 31/50
28107/28107 - 1408s - loss: 1.0883 - accuracy10: 0.3810 - accuracy20: 0.3810 - accuracy30: 0.3810 - accuracy50: 0.3810 - accuracy100: 0.3810 - val_loss: 1.0890 - val_accuracy10: 0.3785 - val_accuracy20: 0.3785 - val_accuracy30: 0.3785 - val_accuracy50: 0.3785 - val_accuracy100: 0.3785 - 1408s/epoch - 50ms/step
Epoch 32/50
28107/28107 - 1386s - loss: 1.0884 - accuracy10: 0.3801 - accuracy20: 0.3801 - accuracy30: 0.3801 - accuracy50: 0.3801 - accuracy100: 0.3801 - val_loss: 1.0893 - val_accuracy10: 0.3787 - val_accuracy20: 0.3787 - val_accuracy30: 0.3787 - val_accuracy50: 0.3787 - val_accuracy100: 0.3787 - 1386s/epoch - 49ms/step
Epoch 33/50
28107/28107 - 1378s - loss: 1.0883 - accuracy10: 0.3803 - accuracy20: 0.3803 - accuracy30: 0.3803 - accuracy50: 0.3803 - accuracy100: 0.3803 - val_loss: 1.0888 - val_accuracy10: 0.3802 - val_accuracy20: 0.3802 - val_accuracy30: 0.3802 - val_accuracy50: 0.3802 - val_accuracy100: 0.3802 - 1378s/epoch - 49ms/step
Epoch 34/50
28107/28107 - 1411s - loss: 1.0883 - accuracy10: 0.3805 - accuracy20: 0.3805 - accuracy30: 0.3805 - accuracy50: 0.3805 - accuracy100: 0.3805 - val_loss: 1.0894 - val_accuracy10: 0.3772 - val_accuracy20: 0.3772 - val_accuracy30: 0.3772 - val_accuracy50: 0.3772 - val_accuracy100: 0.3772 - 1411s/epoch - 50ms/step
Epoch 35/50
28107/28107 - 1392s - loss: 1.0883 - accuracy10: 0.3807 - accuracy20: 0.3807 - accuracy30: 0.3807 - accuracy50: 0.3807 - accuracy100: 0.3807 - val_loss: 1.0880 - val_accuracy10: 0.3809 - val_accuracy20: 0.3809 - val_accuracy30: 0.3809 - val_accuracy50: 0.3809 - val_accuracy100: 0.3809 - 1392s/epoch - 50ms/step
Epoch 36/50
28107/28107 - 1394s - loss: 1.0882 - accuracy10: 0.3804 - accuracy20: 0.3804 - accuracy30: 0.3804 - accuracy50: 0.3804 - accuracy100: 0.3804 - val_loss: 1.0887 - val_accuracy10: 0.3785 - val_accuracy20: 0.3785 - val_accuracy30: 0.3785 - val_accuracy50: 0.3785 - val_accuracy100: 0.3785 - 1394s/epoch - 50ms/step
Epoch 37/50
28107/28107 - 1338s - loss: 1.0882 - accuracy10: 0.3812 - accuracy20: 0.3812 - accuracy30: 0.3812 - accuracy50: 0.3812 - accuracy100: 0.3812 - val_loss: 1.0892 - val_accuracy10: 0.3772 - val_accuracy20: 0.3772 - val_accuracy30: 0.3772 - val_accuracy50: 0.3772 - val_accuracy100: 0.3772 - 1338s/epoch - 48ms/step
Epoch 38/50
28107/28107 - 1330s - loss: 1.0881 - accuracy10: 0.3812 - accuracy20: 0.3812 - accuracy30: 0.3812 - accuracy50: 0.3812 - accuracy100: 0.3812 - val_loss: 1.0884 - val_accuracy10: 0.3805 - val_accuracy20: 0.3805 - val_accuracy30: 0.3805 - val_accuracy50: 0.3805 - val_accuracy100: 0.3805 - 1330s/epoch - 47ms/step
Epoch 39/50
28107/28107 - 1336s - loss: 1.0881 - accuracy10: 0.3817 - accuracy20: 0.3817 - accuracy30: 0.3817 - accuracy50: 0.3817 - accuracy100: 0.3817 - val_loss: 1.0884 - val_accuracy10: 0.3807 - val_accuracy20: 0.3807 - val_accuracy30: 0.3807 - val_accuracy50: 0.3807 - val_accuracy100: 0.3807 - 1336s/epoch - 48ms/step
Prediction horizon: 10  orderbook updates
accuracy_score: 0.4102841208530964
              precision    recall  f1-score   support

           0     0.4035    0.3727    0.3875     49807
           1     0.3836    0.3848    0.3842     49172
           2     0.4402    0.4716    0.4553     50922

    accuracy                         0.4103    149901
   macro avg     0.4091    0.4097    0.4090    149901
weighted avg     0.4094    0.4103    0.4095    149901

Prediction horizon: 20  orderbook updates
accuracy_score: 0.38937031774304376
              precision    recall  f1-score   support

           0     0.3807    0.3951    0.3878     49837
           1     0.3703    0.3295    0.3487     49392
           2     0.4130    0.4420    0.4270     50672

    accuracy                         0.3894    149901
   macro avg     0.3880    0.3889    0.3879    149901
weighted avg     0.3882    0.3894    0.3882    149901

Prediction horizon: 30  orderbook updates
accuracy_score: 0.3803843870287723
              precision    recall  f1-score   support

           0     0.3725    0.4438    0.4051     49929
           1     0.3662    0.2737    0.3132     49442
           2     0.3989    0.4221    0.4102     50530

    accuracy                         0.3804    149901
   macro avg     0.3792    0.3799    0.3762    149901
weighted avg     0.3793    0.3804    0.3765    149901

Prediction horizon: 50  orderbook updates
accuracy_score: 0.36618835097831237
              precision    recall  f1-score   support

           0     0.3582    0.5076    0.4200     49871
           1     0.3531    0.1941    0.2505     49564
           2     0.3839    0.3955    0.3896     50466

    accuracy                         0.3662    149901
   macro avg     0.3651    0.3657    0.3534    149901
weighted avg     0.3652    0.3662    0.3537    149901

Prediction horizon: 100  orderbook updates
accuracy_score: 0.3572824730989119
              precision    recall  f1-score   support

           0     0.3500    0.5863    0.4383     50280
           1     0.3497    0.1139    0.1719     48996
           2     0.3721    0.3654    0.3687     50625

    accuracy                         0.3573    149901
   macro avg     0.3573    0.3552    0.3263    149901
weighted avg     0.3574    0.3573    0.3277    149901

##################### deepLOB attention #####################
Epoch 1/50
28107/28107 - 1631s - loss: 1.0992 - accuracy10: 0.3356 - accuracy20: 0.3356 - accuracy30: 0.3356 - accuracy50: 0.3356 - accuracy100: 0.3356 - val_loss: 1.1029 - val_accuracy10: 0.3311 - val_accuracy20: 0.3311 - val_accuracy30: 0.3311 - val_accuracy50: 0.3311 - val_accuracy100: 0.3311 - 1631s/epoch - 58ms/step
Epoch 2/50
28107/28107 - 1615s - loss: 1.0986 - accuracy10: 0.3389 - accuracy20: 0.3389 - accuracy30: 0.3389 - accuracy50: 0.3389 - accuracy100: 0.3389 - val_loss: 1.1077 - val_accuracy10: 0.3344 - val_accuracy20: 0.3344 - val_accuracy30: 0.3344 - val_accuracy50: 0.3344 - val_accuracy100: 0.3344 - 1615s/epoch - 57ms/step
Epoch 3/50
28107/28107 - 1615s - loss: 1.0954 - accuracy10: 0.3576 - accuracy20: 0.3576 - accuracy30: 0.3576 - accuracy50: 0.3576 - accuracy100: 0.3576 - val_loss: 1.1114 - val_accuracy10: 0.3314 - val_accuracy20: 0.3314 - val_accuracy30: 0.3314 - val_accuracy50: 0.3314 - val_accuracy100: 0.3314 - 1615s/epoch - 57ms/step
Epoch 4/50
28107/28107 - 1605s - loss: 1.0927 - accuracy10: 0.3692 - accuracy20: 0.3692 - accuracy30: 0.3692 - accuracy50: 0.3692 - accuracy100: 0.3692 - val_loss: 1.1455 - val_accuracy10: 0.3310 - val_accuracy20: 0.3310 - val_accuracy30: 0.3310 - val_accuracy50: 0.3310 - val_accuracy100: 0.3310 - 1605s/epoch - 57ms/step
Epoch 5/50
28107/28107 - 1609s - loss: 1.0897 - accuracy10: 0.3799 - accuracy20: 0.3799 - accuracy30: 0.3799 - accuracy50: 0.3799 - accuracy100: 0.3799 - val_loss: 1.1288 - val_accuracy10: 0.3424 - val_accuracy20: 0.3424 - val_accuracy30: 0.3424 - val_accuracy50: 0.3424 - val_accuracy100: 0.3424 - 1609s/epoch - 57ms/step
Epoch 6/50
28107/28107 - 1616s - loss: 1.0882 - accuracy10: 0.3842 - accuracy20: 0.3842 - accuracy30: 0.3842 - accuracy50: 0.3842 - accuracy100: 0.3842 - val_loss: 1.1107 - val_accuracy10: 0.3526 - val_accuracy20: 0.3526 - val_accuracy30: 0.3526 - val_accuracy50: 0.3526 - val_accuracy100: 0.3526 - 1616s/epoch - 57ms/step
Epoch 7/50
28107/28107 - 1624s - loss: 1.0868 - accuracy10: 0.3877 - accuracy20: 0.3877 - accuracy30: 0.3877 - accuracy50: 0.3877 - accuracy100: 0.3877 - val_loss: 1.1268 - val_accuracy10: 0.3556 - val_accuracy20: 0.3556 - val_accuracy30: 0.3556 - val_accuracy50: 0.3556 - val_accuracy100: 0.3556 - 1624s/epoch - 58ms/step
Epoch 8/50
28107/28107 - 1629s - loss: 1.0859 - accuracy10: 0.3899 - accuracy20: 0.3899 - accuracy30: 0.3899 - accuracy50: 0.3899 - accuracy100: 0.3899 - val_loss: 1.1088 - val_accuracy10: 0.3634 - val_accuracy20: 0.3634 - val_accuracy30: 0.3634 - val_accuracy50: 0.3634 - val_accuracy100: 0.3634 - 1629s/epoch - 58ms/step
Epoch 9/50
28107/28107 - 1636s - loss: 1.0851 - accuracy10: 0.3915 - accuracy20: 0.3915 - accuracy30: 0.3915 - accuracy50: 0.3915 - accuracy100: 0.3915 - val_loss: 1.1070 - val_accuracy10: 0.3655 - val_accuracy20: 0.3655 - val_accuracy30: 0.3655 - val_accuracy50: 0.3655 - val_accuracy100: 0.3655 - 1636s/epoch - 58ms/step
Epoch 10/50
28107/28107 - 1636s - loss: 1.0844 - accuracy10: 0.3928 - accuracy20: 0.3928 - accuracy30: 0.3928 - accuracy50: 0.3928 - accuracy100: 0.3928 - val_loss: 1.1667 - val_accuracy10: 0.3435 - val_accuracy20: 0.3435 - val_accuracy30: 0.3435 - val_accuracy50: 0.3435 - val_accuracy100: 0.3435 - 1636s/epoch - 58ms/step
Epoch 11/50
28107/28107 - 1639s - loss: 1.0839 - accuracy10: 0.3935 - accuracy20: 0.3935 - accuracy30: 0.3935 - accuracy50: 0.3935 - accuracy100: 0.3935 - val_loss: 1.1276 - val_accuracy10: 0.3503 - val_accuracy20: 0.3503 - val_accuracy30: 0.3503 - val_accuracy50: 0.3503 - val_accuracy100: 0.3503 - 1639s/epoch - 58ms/step
Prediction horizon: 10  orderbook updates
accuracy_score: 0.3330598194808574
              precision    recall  f1-score   support

           0     0.3334    0.0296    0.0543     49807
           1     0.3075    0.1267    0.1794     49172
           2     0.3372    0.8292    0.4794     50922

    accuracy                         0.3331    149901
   macro avg     0.3260    0.3285    0.2377    149901
weighted avg     0.3262    0.3331    0.2398    149901

Prediction horizon: 20  orderbook updates
accuracy_score: 0.3323193307583005
              precision    recall  f1-score   support

           0     0.3406    0.0698    0.1159     49837
           1     0.3062    0.1169    0.1692     49392
           2     0.3357    0.8004    0.4730     50672

    accuracy                         0.3323    149901
   macro avg     0.3275    0.3291    0.2527    149901
weighted avg     0.3276    0.3323    0.2542    149901

Prediction horizon: 30  orderbook updates
accuracy_score: 0.3333800308203414
              precision    recall  f1-score   support

           0     0.3353    0.3723    0.3528     49929
           1     0.3088    0.1208    0.1737     49442
           2     0.3383    0.5029    0.4045     50530

    accuracy                         0.3334    149901
   macro avg     0.3275    0.3320    0.3103    149901
weighted avg     0.3276    0.3334    0.3112    149901

Prediction horizon: 50  orderbook updates
accuracy_score: 0.3317055923576227
              precision    recall  f1-score   support

           0     0.3342    0.5587    0.4182     49871
           1     0.3061    0.1245    0.1770     49564
           2     0.3383    0.3109    0.3240     50466

    accuracy                         0.3317    149901
   macro avg     0.3262    0.3314    0.3064    149901
weighted avg     0.3263    0.3317    0.3068    149901

Prediction horizon: 100  orderbook updates
accuracy_score: 0.3335334654205109
              precision    recall  f1-score   support

           0     0.3372    0.7038    0.4559     50280
           1     0.2983    0.1188    0.1699     48996
           2     0.3455    0.1736    0.2311     50625

    accuracy                         0.3335    149901
   macro avg     0.3270    0.3321    0.2856    149901
weighted avg     0.3273    0.3335    0.2865    149901

